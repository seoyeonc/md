{"title":"Principal Component Analysis","markdown":{"yaml":{"title":"Principal Component Analysis","author":"SEOYEON CHOI","date":"2023-03-28","categories":["Machine learning basic","비지도학습"]},"headingText":"차원 축소","containsRefs":false,"markdown":"\n\n> Principal Component Analysis\n\n- 주성분 분석은 최대 분산 순으로 특징을 나열함으로써 차원축소하는 비지도학습이다.\n- 변수 사이 상관관계 있을때\n\nRefernece: [핸즈 온 머신러닝](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/), [최규빈교수님 통계전산강의노트](https://guebin.github.io/SC2022/) [사이킷런 홈페이지](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n\n\n차원 축소가 필요한 이유\n\n- 특성이 너무 많으면 [차원의 저주 curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality) 에 빠지게 된다.\n\n차원 축소를 위한 접근 방법\n\n1. [투영 Projection](https://en.wikipedia.org/wiki/Projection_(linear_algebra))\n\n- ex) 3d 공간 안에 있는 저차원 부분 공간 subspace이 있는데 여기에 수직^[샘플과 평면 사이의 가장 짧은 직선을 따라] 투영하면 평면에 투영된 좌표를 얻음.\n- ex) 아래 그림 처럼 부분 공간 subspace가 휘어있기도 함.(swiss roll 예제) 오른쪽은 왼쪽의 스위스 롤을 펼쳐서 2D 데이터 셋을 얻은 것임.\n\n![image](https://www.researchgate.net/publication/200688576/figure/fig1/AS:305995638165506@1449966453759/The-Swiss-roll-data-set-On-the-left-the-data-is-presented-in-its-original-form-On.png)\n\n2. [매니폴드](https://en.wikipedia.org/wiki/Manifold)\n\n- 위 스위스 롤 예제는 2D 매니폴드의 한 예\n- 매니폴드를 펼쳐서 보느냐, 어떻게 경계선을 그어서 보느냐 등 저차원의 매니폴드 공간에 가깝게 놓여있다고 가정^[이를 매니폴드 가설 또는 매니폴드 가정이라 한다.]\n- 저차원으로 차원축소 할 수 있지만, 오히려 복잡해지는 경우^[무조건적인 차원축소는 피할 것]도 있다.\n\n$\\star$ 2D 매니폴드는 곡선, 3D 매니폴드는 곡면이라 생각\n\n![image](https://www.researchgate.net/publication/11580034/figure/fig1/AS:281957268246529@1444235259540/A-The-Swiss-roll-data-used-by-Tenenbaum-et-al-1-to-illustrate-their-algorithm.png)\n\n# PCA\n\n[주성분 분석 principal component analysis](https://en.wikipedia.org/wiki/Principal_component_analysis)\n\nPCA is a statistical technique for reducing the dimensionality of a dataset. \n\n## 1. 분산 보존\n\n분산이 최대로 보존되는 차원 축소가 정보를 가장 적게 손실되어 합리적으로 보임\n\n## 2. 주성분\n\n분산이 큰 순서대로 차원의 수만큼 찾음\n\ni번째 축 = 주성분 PC principal component\n\n[특이값 분해 SVD singular value decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition)= training set에서 주성분 찾는 방법\n\n[교수님 lecture note with julia](https://guebin.github.io/SC2022/0510.html)\n\n- 이론 : $X_{n \\times m} = U_{n \\times n} D_{n \\times m} (V_{m \\times m})^\\top$\n    - ver 1 = $U, V$가 모두 직교 행렬\n    - ver 2 = $U$ 또는 $V$가 직교 행렬\n\n- 왜?\n    - 데이터 매트릭스 $X$가 존재할때 정보는 유지하면서 비용을 줄이는 $Z$^[X로 복원 가능해야 함]를 찾고 싶다.\n    - $Z$ 구하는 법\n        - $Z = \\tilde{U} \\tilde{D}$ $\\to$ $\\tilde{U} \\tilde{D} = X\\tilde{V}$ $\\to$ $Z = X\\tilde{V}$\n        - $X^\\top X = \\psi \\lambda \\psi^\\top$을 구해서 $Z = X\\tilde{\\psi}$ $\\to$ $\\hat{X} = Z\\tilde{\\psi}^\\top$\n\n$\\star$ PCA는 데이터셋의 평균이 0이라고 가정\n\n## 3. d차원으로 투영하기\n\n$X_{d-proj,n \\times d} = X_{n \\times M} W_{d,n \\times d}$\n\n## 4. 설명된 분산의 비율\n\n설명된 분산의 비율 explained variance ratio\n\n- 공분산 행렬의 고유값\n- 투영한 분산의 비율\n- 주성분 선택된 순으로 작아짐\n\n## 5. 적절한 차원 수 선택하기\n\n차원 수를 임의로 정하는 것보다는 충분한 분산^[예를 들어 설명된 분산의 비율이 약 95%까지]이 될 떄까지 선택\n\n## 6. 압축을 위한 PCA\n\n[참고](https://guebin.github.io/SC2022/0512.html)\n\n중요한 특징만을 살리기 위해 PCA를 시도하여 차원 축소하였다.\n\n이후 원본 데이터로 돌아가려 할 때 특징은 살아있지만 완벽히 데이터셋이 일치하지 않는데,\n\n여기서 이 오류를 재구성 오차 = 재건 오류 reconstruction error 라고 한다.\n\n$X_{n \\times M} = X_{d-proj,n \\times d} (W_{d,n \\times d})^\\top$\n\n## 7. 커널 PCA\n\n차원 축소를 통해 비선형 투영 수행\n\n$\\zeta = \\Psi \\alpha$\n\n- 이 때, $||\\alpha_j|| = 1$로 정규화한다.\n- 그러기 위해 $\\alpha_j$를 $||\\zeta_j||$로 나누어 정규화\n    - $||\\zeta_j|| = \\sqrt{\\lambda}_j$\n    - $\\alpha_j \\to \\frac{1}{\\sqrt{\\lambda}_j} \\alpha_j, j=1, \\dots, m$\n\n특징 벡터로 내적하여 나오는 커널$K$ 행렬로 중심화\n\n- $K = HKH$\n- $H = I_n - 1_{n \\times 1} /n$\n\n$\\alpha$ 정규화 한 후 중심화하면\n\n$(z_1, \\dots, z_n) = (\\frac{1}{\\sqrt{\\lambda_1}} \\alpha_1,\\dots , \\frac{1}{\\sqrt{\\lambda_m}}\\alpha_m)^\\top HKH$\n\n- 여기서 m개가 주성분!\n\n![image](https://tekworld.org/wp-content/uploads/2018/12/Screen-Shot-2018-12-08-at-1.17.16-PM.png)\n\n$\\star$ 고유벡터\n\n- 선형 $C = \\psi \\psi^\\top$\n- 비선형 $K = \\psi^\\top \\psi$\n    - $\\psi$의 길이에 따라 고유값 문제의 표현을 다르게 하여 계산 시간 줄이기\n    - 차원 수가 표본 수보다 큰 경우에는 커널 행렬을 사용하는 것이 효율적\n","srcMarkdownNoYaml":"\n\n> Principal Component Analysis\n\n- 주성분 분석은 최대 분산 순으로 특징을 나열함으로써 차원축소하는 비지도학습이다.\n- 변수 사이 상관관계 있을때\n\nRefernece: [핸즈 온 머신러닝](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/), [최규빈교수님 통계전산강의노트](https://guebin.github.io/SC2022/) [사이킷런 홈페이지](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n\n# 차원 축소\n\n차원 축소가 필요한 이유\n\n- 특성이 너무 많으면 [차원의 저주 curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality) 에 빠지게 된다.\n\n차원 축소를 위한 접근 방법\n\n1. [투영 Projection](https://en.wikipedia.org/wiki/Projection_(linear_algebra))\n\n- ex) 3d 공간 안에 있는 저차원 부분 공간 subspace이 있는데 여기에 수직^[샘플과 평면 사이의 가장 짧은 직선을 따라] 투영하면 평면에 투영된 좌표를 얻음.\n- ex) 아래 그림 처럼 부분 공간 subspace가 휘어있기도 함.(swiss roll 예제) 오른쪽은 왼쪽의 스위스 롤을 펼쳐서 2D 데이터 셋을 얻은 것임.\n\n![image](https://www.researchgate.net/publication/200688576/figure/fig1/AS:305995638165506@1449966453759/The-Swiss-roll-data-set-On-the-left-the-data-is-presented-in-its-original-form-On.png)\n\n2. [매니폴드](https://en.wikipedia.org/wiki/Manifold)\n\n- 위 스위스 롤 예제는 2D 매니폴드의 한 예\n- 매니폴드를 펼쳐서 보느냐, 어떻게 경계선을 그어서 보느냐 등 저차원의 매니폴드 공간에 가깝게 놓여있다고 가정^[이를 매니폴드 가설 또는 매니폴드 가정이라 한다.]\n- 저차원으로 차원축소 할 수 있지만, 오히려 복잡해지는 경우^[무조건적인 차원축소는 피할 것]도 있다.\n\n$\\star$ 2D 매니폴드는 곡선, 3D 매니폴드는 곡면이라 생각\n\n![image](https://www.researchgate.net/publication/11580034/figure/fig1/AS:281957268246529@1444235259540/A-The-Swiss-roll-data-used-by-Tenenbaum-et-al-1-to-illustrate-their-algorithm.png)\n\n# PCA\n\n[주성분 분석 principal component analysis](https://en.wikipedia.org/wiki/Principal_component_analysis)\n\nPCA is a statistical technique for reducing the dimensionality of a dataset. \n\n## 1. 분산 보존\n\n분산이 최대로 보존되는 차원 축소가 정보를 가장 적게 손실되어 합리적으로 보임\n\n## 2. 주성분\n\n분산이 큰 순서대로 차원의 수만큼 찾음\n\ni번째 축 = 주성분 PC principal component\n\n[특이값 분해 SVD singular value decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition)= training set에서 주성분 찾는 방법\n\n[교수님 lecture note with julia](https://guebin.github.io/SC2022/0510.html)\n\n- 이론 : $X_{n \\times m} = U_{n \\times n} D_{n \\times m} (V_{m \\times m})^\\top$\n    - ver 1 = $U, V$가 모두 직교 행렬\n    - ver 2 = $U$ 또는 $V$가 직교 행렬\n\n- 왜?\n    - 데이터 매트릭스 $X$가 존재할때 정보는 유지하면서 비용을 줄이는 $Z$^[X로 복원 가능해야 함]를 찾고 싶다.\n    - $Z$ 구하는 법\n        - $Z = \\tilde{U} \\tilde{D}$ $\\to$ $\\tilde{U} \\tilde{D} = X\\tilde{V}$ $\\to$ $Z = X\\tilde{V}$\n        - $X^\\top X = \\psi \\lambda \\psi^\\top$을 구해서 $Z = X\\tilde{\\psi}$ $\\to$ $\\hat{X} = Z\\tilde{\\psi}^\\top$\n\n$\\star$ PCA는 데이터셋의 평균이 0이라고 가정\n\n## 3. d차원으로 투영하기\n\n$X_{d-proj,n \\times d} = X_{n \\times M} W_{d,n \\times d}$\n\n## 4. 설명된 분산의 비율\n\n설명된 분산의 비율 explained variance ratio\n\n- 공분산 행렬의 고유값\n- 투영한 분산의 비율\n- 주성분 선택된 순으로 작아짐\n\n## 5. 적절한 차원 수 선택하기\n\n차원 수를 임의로 정하는 것보다는 충분한 분산^[예를 들어 설명된 분산의 비율이 약 95%까지]이 될 떄까지 선택\n\n## 6. 압축을 위한 PCA\n\n[참고](https://guebin.github.io/SC2022/0512.html)\n\n중요한 특징만을 살리기 위해 PCA를 시도하여 차원 축소하였다.\n\n이후 원본 데이터로 돌아가려 할 때 특징은 살아있지만 완벽히 데이터셋이 일치하지 않는데,\n\n여기서 이 오류를 재구성 오차 = 재건 오류 reconstruction error 라고 한다.\n\n$X_{n \\times M} = X_{d-proj,n \\times d} (W_{d,n \\times d})^\\top$\n\n## 7. 커널 PCA\n\n차원 축소를 통해 비선형 투영 수행\n\n$\\zeta = \\Psi \\alpha$\n\n- 이 때, $||\\alpha_j|| = 1$로 정규화한다.\n- 그러기 위해 $\\alpha_j$를 $||\\zeta_j||$로 나누어 정규화\n    - $||\\zeta_j|| = \\sqrt{\\lambda}_j$\n    - $\\alpha_j \\to \\frac{1}{\\sqrt{\\lambda}_j} \\alpha_j, j=1, \\dots, m$\n\n특징 벡터로 내적하여 나오는 커널$K$ 행렬로 중심화\n\n- $K = HKH$\n- $H = I_n - 1_{n \\times 1} /n$\n\n$\\alpha$ 정규화 한 후 중심화하면\n\n$(z_1, \\dots, z_n) = (\\frac{1}{\\sqrt{\\lambda_1}} \\alpha_1,\\dots , \\frac{1}{\\sqrt{\\lambda_m}}\\alpha_m)^\\top HKH$\n\n- 여기서 m개가 주성분!\n\n![image](https://tekworld.org/wp-content/uploads/2018/12/Screen-Shot-2018-12-08-at-1.17.16-PM.png)\n\n$\\star$ 고유벡터\n\n- 선형 $C = \\psi \\psi^\\top$\n- 비선형 $K = \\psi^\\top \\psi$\n    - $\\psi$의 길이에 따라 고유값 문제의 표현을 다르게 하여 계산 시간 줄이기\n    - 차원 수가 표본 수보다 큰 경우에는 커널 행렬을 사용하는 것이 효율적\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"2023-03-28-Principal Component Analysis.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.315","theme":"pulse","code-copy":false,"title-block-banner":true,"comments":{"utterances":{"repo":"seoyeonc/md"}},"title":"Principal Component Analysis","author":"SEOYEON CHOI","date":"2023-03-28","categories":["Machine learning basic","비지도학습"]},"extensions":{"book":{"multiFile":true}}},"ipynb":{"identifier":{"display-name":"Jupyter","target-format":"ipynb","base-format":"ipynb"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"png","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"ipynb","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"default-image-extension":"png","to":"ipynb","output-file":"2023-03-28-Principal Component Analysis.ipynb"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"title-block-banner":true,"comments":{"utterances":{"repo":"seoyeonc/md"}},"title":"Principal Component Analysis","author":"SEOYEON CHOI","date":"2023-03-28","categories":["Machine learning basic","비지도학습"]}}},"projectFormats":["html"]}