{"title":"CNN (8주차) 2","markdown":{"yaml":{"title":"CNN (8주차) 2","author":"SEOYEON CHOI","date":"2022-10-26","categories":["Special Topics in Machine Learning","이미지자료분석","Transfer Learning","CAM","XAI"]},"headingText":"imports","containsRefs":false,"markdown":"\n\n기계학습 특강 (8주차) 10월26일--(2) [이미지자료분석 - Transfer Learning, CAM (설명가능한 인공지능모형, XAI)]\n\n\n## Transfer Learning \n\n### 수제네트워크\n\n(1) dls\n\n(2) lrnr 생성 \n\nnet는 cpu에 있고 X는 gpu에 있으니 cpu로 불러오자\n\n(3) 학습\n\n- 이게 생각보다 잘 안맞아요.. 70넘기 힘듬 \n\n### 전이학습 (남이 만든 네트워크)\n\n(2) lrnr 생성 \n\n학습되어 있는 파라메터까지 같이 가져오기\n\n- $k=1000$ 즉 1000개의 물체를 구분하는 모형임 \n\n(3) 학습\n\n- CIFAR10을 맞추기 위한 네트워크가 아님에도 불구하고 상당히 잘맞음\n- 일반인이 거의 밑바닥에서 설계하는것보다 전이학습을 이용하는 것이 효율적일 경우가 많다. \n\n### 전이학습 다른 구현: 순수 fastai 이용 \n\n`-` 예전코드 복습\n\nlrnr = cnn_learner(dls,resnet34,metrics=accuracy) \n\n`-` 사실 위의 코드가 transfer learning 이었음. \n\n#### XAI(설명가능한 인공지능)\n**딥러닝 연구의 네가지 축**\n- step 1. 아키텍처\n    - 최근 연구 특징 : 비전문가 + 블랙박스(안 보이는 의미)\n        - 설명가능한 딥러닝에 대한 요구\n- step 2. 손실함수\n- step 3. 미분계산\n- step 4. 옵티마이저\n\n## CAM\n\n### CAM이란? \n\n- ref: http://cnnlocalization.csail.mit.edu/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf\n\n`-` Class Activation Mapping (CAM)은 설명가능한 인공지능모형 (eXplainable Artificial Intelligence, XAI) 중 하나로 CNN의 판단근거를 시각화하는 기술\n\n### 학습에 사용할 데이터 Load\n\n### 구현0단계-- 예비학습\n\n#### `#` 하나의 이미지 선택 \n\n#### `#` AP layer \n\n#### `#` torch.einsum\n\n(예시1)\n\n(예시2)\n\n(예시3)\n\n`torch,einsum`을 사용하여 shape을 아래로 변경\n\n### 구현1단계-- 이미지분류 잘하는 네트워크 선택 \n\nlrnr = cnn_learner(dls,resnet34,metrics=accuracy) \n\n### 구현2단계-- 네트워크의 끝 부분 수정 \n\n`-` 모형의 분해 \n\nnet1이 2d part, net1이 1d part\n\n`-` net2를 좀더 살펴보자. \n\n`-` net2를 아래와 같이 수정하고 재학습하자 (왜?) \n\n### 구현3단계-- 수정된 net2에서 Linear와 AP의 순서를 바꿈 \n\n`-` 1개의 observation을 고정하였을 경우 출력과정 상상 \n\n`-` 최종결과 확인 \n\n아마 모델 달라서 값이 다른 것일까..!\n\n- net(x)에서 뒤쪽의 값이 클수록 'dog'를 의미한다. \n\n`-` net2의 순서 바꾸기 전 전체 네트워크: \n\n$$\\underset{(1,3,512,512)}{\\boldsymbol x} \\overset{net_1}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{ap}{\\to} \\underset{(1,512,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,512)}{{\\boldsymbol \\sharp}}\\overset{linear}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}}\\right) = [-9.0358,  9.0926]$$\n\n`-` 아래와 같이 순서를 바꿔서 한번 계산해보고 싶다. (왜???..)\n\n$$\\underset{(1,3,224,224)}{\\boldsymbol x} \\overset{net_1}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{linear}{\\to} \\underset{(1,2,16,16)}{{\\bf why}}\\overset{ap}{\\to} \\underset{(1,2,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}}\\right) = [−9.0358,9.0926]$$\n\n- 여기에서 (1,512,16,16) -> (1,2,16,16) 로 가는 선형변환을 적용하는 방법? **(16,16) each pixel에 대하여 (512 $\\to$ 2)로 가는 변환을 수행**\n\n`-` 통찰: 이 경우 특이하게도 레이어의 순서를 바꿨을때 출력이 동일함 (선형변환하고 평균내거나 평균내고 선형변환하는건 같으니까) \n\n`-` 구현해보자. \n\n### 잠깐 멈추고 생각\n\n`-` 이미지\n\n`-` 네트워크의 결과\n\n- -9.0358 << 9.0926 이므로 'ximg'는 높은 확률로 개라는 뜻이다. \n\n내거에서는 9.0926이 10.2985\n\n`-` 아래의 네트워크를 관찰 \n\n$$\\underset{(1,2,16,16)}{{\\bf why}}\\overset{ap}{\\to} \\underset{(1,2,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}} = [-9.0358,9.0926]$$\n\n더 파고들어서 분석해보자. \n\n***`why[0,0,:,:]`***\n\n- 이 값들의 평균은 -9.0358 이다. (이 값이 클수록 이 그림이 고양이라는 의미 = 이 값이 작을수록 이 그림이 고양이가 아니라는 의미) \n- 그런데 살펴보니 대부분의 위치에서 0에 가까운 값을 가짐. 다만 특정위치에서 엄청 큰 작은값이 있어서 -9.0358이라는 평균값이 나옴 $\\to$ 특정위치에 존재하는 엄청 작은 값들은 ximg가 고양이가 아니라고 판단하는 근거가 된다. \n\n***`why[0,1,:,:]`***\n\n- 이 값들의 평균은 9.0926 이다. (이 값이 클수록 이 그림이 강아지라는 의미) \n- 그런데 살펴보니 대부분의 위치에서 0에 가까운 값을 가짐. 다만 특정위치에서 엄청 큰 값들이 있어서 9.0926이라는 평균값이 나옴 $\\to$ 특정위치에 존재하는 엄청 큰 값들은 결국 ximg를 강아지라고 판단하는 근거가 된다. \n\n`-` 시각화\n\n- magma = 검은색 < 보라색 < 빨간색 < 노란색\n- 왼쪽그림의 검은 부분은 고양이가 아니라는 근거, 오른쪽그림의 노란부분은 강아지라는 근거 \n\n`-` why_cat, why_dog를 (16,16) $\\to$ (512,512) 로 resize \n\n`-` 겹쳐그리기\n\n`-` 하니이미지 시각화\n\n`-` 하니이미지 시각화 with prob\n\n### 구현4단계-- CAM 시각화 \n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"2022-10-26-ml_8w_2.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","theme":"pulse","code-copy":false,"title-block-banner":true,"title":"CNN (8주차) 2","author":"SEOYEON CHOI","date":"2022-10-26","categories":["Special Topics in Machine Learning","이미지자료분석","Transfer Learning","CAM","XAI"]},"extensions":{"book":{"multiFile":true}}}}}