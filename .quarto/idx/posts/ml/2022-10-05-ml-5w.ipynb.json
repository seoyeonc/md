{"title":"DNN (5주차)","markdown":{"yaml":{"title":"DNN (5주차)","author":"SEOYEON CHOI","date":"2022-10-05","categories":["Special Topics in Machine Learning","로지스틱","깊은신경망"]},"headingText":"imports","containsRefs":false,"markdown":"\n\n기계학습 특강 (5주차) 10월5일 [딥러닝의 기초 - 로지스틱(2), 깊은신경망(1)]\n\n\n### 시각화를 위한 준비함수들 \n\n**준비1** loss_fn을 plot하는 함수\n\n- $y_i \\sim Ber(\\pi_i),\\quad$ where $\\pi_i = \\frac{\\exp(-1+5x_i)}{1+\\exp(-1+5x_i)}$ 에서 생성된 데이터 한정하여 손실함수가 그려지게 되어있음. \n\n**준비2: for문 대신 돌려주고 epoch마다 필요한 정보를 기록하는 함수**\n\n- 20에폭마다 yhat, loss, what을 기록\n\n**준비3: 애니메이션을 만들어주는 함수**\n\n- 준비1에서 그려진 loss 함수위에, 준비2의 정보를 조합하여 애니메이션을 만들어주는 함수 \n\n## Logistic intro (review + $\\alpha$)\n\n`-` 모델: $x$가 커질수록 $y=1$이 잘나오는 모형은 아래와 같이 설계할 수 있음 <--- 외우세요!!!\n\n- $y_i \\sim Ber(\\pi_i),\\quad$ where $\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}$\n\n- $\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}$ \n\n- $loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)$ <--- 외우세요!!\n\n`-` toy example \n\n- note: $(w_0,w_1)$의 true는 $(-1,5)$이다. -> $(\\hat{w}_0, \\hat{w}_1)$을 적당히 $(-1,5)$근처로 추정하면 된다는 의미\n\n`-` step1: yhat을 만들기 \n\n(방법1)\n\n뒤의 1이 input feature로서 입력\n\n(방법2)\n\n$x \\overset{l1}{\\to} u \\overset{a1}{\\to} v = \\hat{y}$\n\n$x \\overset{net}{\\to} \\hat{y}$\n\n(방법3)\n\n중간과정보기 힘들다.\n\n---\n\n---\n\n`-` step2: loss (일단 MSE로..)\n\n(방법1)\n\n(방법2)\n\n`-` step3~4는 동일 \n\n`-` 반복 (준비+for문)\n\n## 로지스틱--BCEloss \n\n`-` BCEloss로 바꾸어서 적합하여 보자. \n\n`-` 왜 잘맞지? -> \"linear -> sigmoid\" 와 같은 net에 BCEloss를 이용하면 손실함수의 모양이 convex 하기 때문에 \n- \"linear -> sigmoid\" 로 $\\hat{y}$을 구하고 BCEloss로 loss를 계산하면 그 모영아 convex하므로\n\nBCSloss에는 local error에 빠지지 않아, loss는 있아.\n\n- plot_loss 함수소개 = 이 예제에 한정하여 $\\hat{w}_0,\\hat{w}_1,loss(\\hat{w}_0,\\hat{w}_1)$를 각각 $x,y,z$ 축에 그려줍니다.\n\n### 시각화1: MSE, 좋은초기값\n\n### 시각화2: MSE, 나쁜초기값\n\n### 시각화3: BCE, 좋은초기값\n\n### 시각화4: BCE, 나쁜초기값\n\n## 로지스틱--Adam (국민옵티마이저)\n\n### 시각화1: MSE, 좋은초기값 --> 이걸 아담으로!\n\n### 시각화2: MSE, 나쁜초기값 --> 이걸 아담으로!\n\n### 시각화3: BCE, 좋은초기값 --> 이걸 아담으로! (혼자해봐요..)\n\n### 시각화4: BCE, 나쁜초기값 --> 이걸 아담으로! (혼자해봐요..)\n\n(참고) Adam이 우수한 이유? SGD보다 두 가지 측면에서 개선이 있었음. \n1. 그런게 있음.. \n2. 가속도의 개념을 적용!! \n\n## 깊은신경망--로지스틱 회귀의 한계 \n\n### 신문기사 (데이터의 모티브)\n\n`-` [스펙이 높아도 취업이 안된다고 합니다..](https://www.joongang.co.kr/article/23637092#home)\n\n**중소·지방 기업 \"뽑아봤자 그만두니까\"**\n\n중소기업 관계자들은 고스펙 지원자를 꺼리는 이유로 높은 퇴직률을 꼽는다. 여건이 좋은 대기업으로 이직하거나 회사를 관두는 경우가 많다는 하소연이다. 고용정보원이 지난 3일 공개한 자료에 따르면 중소기업 청년취업자 가운데 49.5%가 2년 내에 회사를 그만두는 것으로 나타났다.\n\n중소 IT업체 관계자는 \"기업 입장에서 가장 뼈아픈 게 신입사원이 그만둬서 새로 뽑는 일\"이라며 \"명문대 나온 스펙 좋은 지원자를 뽑아놔도 1년을 채우지 않고 그만두는 사원이 대부분이라 우리도 눈을 낮춰 사람을 뽑는다\"고 말했다.\n\n### 가짜데이터 \n\n`-` 위의 기사를 모티브로 한 데이터 \n\n### 로지스틱 회귀로 적합\n\n`-` 이건 `epoc=6억번`으로 설정해도 못 맞출 것 같다 (증가하다가 감소하는 underlying을 설계하는 것이 불가능) $\\to$ 모형의 표현력이 너무 낮다. \n\n### 해결책\n\n`-` sigmoid 넣기 전의 상태가 꺽인 그래프 이어야 한다. \n\n## 깊은신경망--DNN을 이용한 해결 \n\n`-` 목표: 아래와 같은 벡터 ${\\boldsymbol u}$를 만들어보자. \n\n${\\boldsymbol u} = [u_1,u_2,\\dots,u_{2000}], \\quad u_i = \\begin{cases} 9x_i +4.5& x_i <0 \\\\ -4.5x_i + 4.5& x_i >0 \\end{cases}$\n\n### 꺽인 그래프를 만드는 방법1\n\n### 꺽인 그래프를 만드는 방법2\n\n`-` 전략: 선형변환 $\\to$ ReLU $\\to$ 선형변환 \n\n(예비학습) ReLU 함수란?\n\n$ReLU(x) = \\max(0,x)$\n\n- 빨간색: `x`, 파란색: `relu(x)`\n\n예비학습끝\n\n우리 전략 다시 확인: 선형변환1 -> 렐루 -> 선형변환2\n\n***(선형변환1)***\n\n***(렐루)***\n\n***(선형변환2)***\n\n이제 초록색선에 sig를 취하기만 하면?\n\n정리하면!\n\n- 이런느낌으로 $\\hat{\\boldsymbol y}$을 만들면 된다. \n\n### torch.nn.Linear()를 이용한 꺽인 그래프 구현 \n\n`-` 수식표현\n\n1. ${\\bf X}=\\begin{bmatrix} x_1 \\\\ \\dots \\\\ x_n \\end{bmatrix}$\n\n2. $l_1({\\bf X})={\\bf X}{\\bf W}^{(1)}\\overset{bc}{+} {\\boldsymbol b}^{(1)}=\\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\  x_n & -x_n\\end{bmatrix}$\n    - ${\\bf W}^{(1)}=\\begin{bmatrix} 1 & -1 \\end{bmatrix}$\n    - ${\\boldsymbol b}^{(1)}=\\begin{bmatrix} 0 & 0 \\end{bmatrix}$\n\n3. $(a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big)=\\begin{bmatrix} \\text{relu}(x_1) & \\text{relu}(-x_1) \\\\ \\text{relu}(x_2) & \\text{relu}(-x_2) \\\\ \\dots & \\dots \\\\  \\text{relu}(x_n) & \\text{relu}(-x_n)\\end{bmatrix}$\n\n4. $(l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\\\ =\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots  \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}$ \n    - ${\\bf W}^{(2)}=\\begin{bmatrix} -4.5 \\\\ -9 \\end{bmatrix}$\n    - $b^{(2)}=4.5$\n\n5. $net({\\bf X})=(a_2 \\circ l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{sig}\\Big(\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\Big)\\\\=\\begin{bmatrix} \\text{sig}\\Big(-4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5\\Big) \\\\ \\text{sig}\\Big(-4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\Big)\\\\ \\dots  \\\\ \\text{sig}\\Big(-4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\Big)\\end{bmatrix}$ \n\n\n`-` 차원만 따지자\n\n$\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}$\n\n### Step1 ~ Step4\n\n`-` 준비\n\n`-` 반복 \n\n## 깊은신경망--DNN으로 해결가능한 다양한 예제\n\n### 예제1\n\n`-` 언뜻 생각하면 방금 배운 기술은 sig를 취하기 전이 꺽은선인 형태만 가능할 듯 하다. $\\to$ 그래서 이 역시 표현력이 부족할 듯 하다. $\\to$ 그런데 생각보다 표현력이 풍부한 편이다. 즉 생각보다 쓸 만하다. \n\n- 이거 시그모이드 취하기 직전은 step이 포함된 듯 $\\to$ 그래서 꺽은선으로는 표현할 수 없는 구조임 $\\to$ 그런데 사실 대충은 표현가능 \n\n- $\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,16)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,16)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}$\n\n### 예제2\n\n`-` 사실 꺽은선의 조합으로 꽤 많은걸 표현할 수 있거든요? $\\to$ 심지어 곡선도 대충 맞게 적합된다. \n\n(풀이1)\n\n- $\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}$\n\n(풀이2) -- 풀이1보다 좀 더 잘맞음. 잘 맞는 이유? 좋은초기값 (=운) \n\n- $\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}$\n\n- 풀이1에서 에폭을 많이 반복하면 풀이2의 적합선이 나올까? --> 안나옴!! (local min에 빠졌다) \n\n### 예제3\n\n- $\\underset{(n,2)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}$\n\n`-` 결과시각화 \n\n`-` 교훈: underlying이 엄청 이상해보여도 생각보다 잘 맞춤\n","srcMarkdownNoYaml":"\n\n기계학습 특강 (5주차) 10월5일 [딥러닝의 기초 - 로지스틱(2), 깊은신경망(1)]\n\n## imports\n\n### 시각화를 위한 준비함수들 \n\n**준비1** loss_fn을 plot하는 함수\n\n- $y_i \\sim Ber(\\pi_i),\\quad$ where $\\pi_i = \\frac{\\exp(-1+5x_i)}{1+\\exp(-1+5x_i)}$ 에서 생성된 데이터 한정하여 손실함수가 그려지게 되어있음. \n\n**준비2: for문 대신 돌려주고 epoch마다 필요한 정보를 기록하는 함수**\n\n- 20에폭마다 yhat, loss, what을 기록\n\n**준비3: 애니메이션을 만들어주는 함수**\n\n- 준비1에서 그려진 loss 함수위에, 준비2의 정보를 조합하여 애니메이션을 만들어주는 함수 \n\n## Logistic intro (review + $\\alpha$)\n\n`-` 모델: $x$가 커질수록 $y=1$이 잘나오는 모형은 아래와 같이 설계할 수 있음 <--- 외우세요!!!\n\n- $y_i \\sim Ber(\\pi_i),\\quad$ where $\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}$\n\n- $\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}$ \n\n- $loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)$ <--- 외우세요!!\n\n`-` toy example \n\n- note: $(w_0,w_1)$의 true는 $(-1,5)$이다. -> $(\\hat{w}_0, \\hat{w}_1)$을 적당히 $(-1,5)$근처로 추정하면 된다는 의미\n\n`-` step1: yhat을 만들기 \n\n(방법1)\n\n뒤의 1이 input feature로서 입력\n\n(방법2)\n\n$x \\overset{l1}{\\to} u \\overset{a1}{\\to} v = \\hat{y}$\n\n$x \\overset{net}{\\to} \\hat{y}$\n\n(방법3)\n\n중간과정보기 힘들다.\n\n---\n\n---\n\n`-` step2: loss (일단 MSE로..)\n\n(방법1)\n\n(방법2)\n\n`-` step3~4는 동일 \n\n`-` 반복 (준비+for문)\n\n## 로지스틱--BCEloss \n\n`-` BCEloss로 바꾸어서 적합하여 보자. \n\n`-` 왜 잘맞지? -> \"linear -> sigmoid\" 와 같은 net에 BCEloss를 이용하면 손실함수의 모양이 convex 하기 때문에 \n- \"linear -> sigmoid\" 로 $\\hat{y}$을 구하고 BCEloss로 loss를 계산하면 그 모영아 convex하므로\n\nBCSloss에는 local error에 빠지지 않아, loss는 있아.\n\n- plot_loss 함수소개 = 이 예제에 한정하여 $\\hat{w}_0,\\hat{w}_1,loss(\\hat{w}_0,\\hat{w}_1)$를 각각 $x,y,z$ 축에 그려줍니다.\n\n### 시각화1: MSE, 좋은초기값\n\n### 시각화2: MSE, 나쁜초기값\n\n### 시각화3: BCE, 좋은초기값\n\n### 시각화4: BCE, 나쁜초기값\n\n## 로지스틱--Adam (국민옵티마이저)\n\n### 시각화1: MSE, 좋은초기값 --> 이걸 아담으로!\n\n### 시각화2: MSE, 나쁜초기값 --> 이걸 아담으로!\n\n### 시각화3: BCE, 좋은초기값 --> 이걸 아담으로! (혼자해봐요..)\n\n### 시각화4: BCE, 나쁜초기값 --> 이걸 아담으로! (혼자해봐요..)\n\n(참고) Adam이 우수한 이유? SGD보다 두 가지 측면에서 개선이 있었음. \n1. 그런게 있음.. \n2. 가속도의 개념을 적용!! \n\n## 깊은신경망--로지스틱 회귀의 한계 \n\n### 신문기사 (데이터의 모티브)\n\n`-` [스펙이 높아도 취업이 안된다고 합니다..](https://www.joongang.co.kr/article/23637092#home)\n\n**중소·지방 기업 \"뽑아봤자 그만두니까\"**\n\n중소기업 관계자들은 고스펙 지원자를 꺼리는 이유로 높은 퇴직률을 꼽는다. 여건이 좋은 대기업으로 이직하거나 회사를 관두는 경우가 많다는 하소연이다. 고용정보원이 지난 3일 공개한 자료에 따르면 중소기업 청년취업자 가운데 49.5%가 2년 내에 회사를 그만두는 것으로 나타났다.\n\n중소 IT업체 관계자는 \"기업 입장에서 가장 뼈아픈 게 신입사원이 그만둬서 새로 뽑는 일\"이라며 \"명문대 나온 스펙 좋은 지원자를 뽑아놔도 1년을 채우지 않고 그만두는 사원이 대부분이라 우리도 눈을 낮춰 사람을 뽑는다\"고 말했다.\n\n### 가짜데이터 \n\n`-` 위의 기사를 모티브로 한 데이터 \n\n### 로지스틱 회귀로 적합\n\n`-` 이건 `epoc=6억번`으로 설정해도 못 맞출 것 같다 (증가하다가 감소하는 underlying을 설계하는 것이 불가능) $\\to$ 모형의 표현력이 너무 낮다. \n\n### 해결책\n\n`-` sigmoid 넣기 전의 상태가 꺽인 그래프 이어야 한다. \n\n## 깊은신경망--DNN을 이용한 해결 \n\n`-` 목표: 아래와 같은 벡터 ${\\boldsymbol u}$를 만들어보자. \n\n${\\boldsymbol u} = [u_1,u_2,\\dots,u_{2000}], \\quad u_i = \\begin{cases} 9x_i +4.5& x_i <0 \\\\ -4.5x_i + 4.5& x_i >0 \\end{cases}$\n\n### 꺽인 그래프를 만드는 방법1\n\n### 꺽인 그래프를 만드는 방법2\n\n`-` 전략: 선형변환 $\\to$ ReLU $\\to$ 선형변환 \n\n(예비학습) ReLU 함수란?\n\n$ReLU(x) = \\max(0,x)$\n\n- 빨간색: `x`, 파란색: `relu(x)`\n\n예비학습끝\n\n우리 전략 다시 확인: 선형변환1 -> 렐루 -> 선형변환2\n\n***(선형변환1)***\n\n***(렐루)***\n\n***(선형변환2)***\n\n이제 초록색선에 sig를 취하기만 하면?\n\n정리하면!\n\n- 이런느낌으로 $\\hat{\\boldsymbol y}$을 만들면 된다. \n\n### torch.nn.Linear()를 이용한 꺽인 그래프 구현 \n\n`-` 수식표현\n\n1. ${\\bf X}=\\begin{bmatrix} x_1 \\\\ \\dots \\\\ x_n \\end{bmatrix}$\n\n2. $l_1({\\bf X})={\\bf X}{\\bf W}^{(1)}\\overset{bc}{+} {\\boldsymbol b}^{(1)}=\\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\  x_n & -x_n\\end{bmatrix}$\n    - ${\\bf W}^{(1)}=\\begin{bmatrix} 1 & -1 \\end{bmatrix}$\n    - ${\\boldsymbol b}^{(1)}=\\begin{bmatrix} 0 & 0 \\end{bmatrix}$\n\n3. $(a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big)=\\begin{bmatrix} \\text{relu}(x_1) & \\text{relu}(-x_1) \\\\ \\text{relu}(x_2) & \\text{relu}(-x_2) \\\\ \\dots & \\dots \\\\  \\text{relu}(x_n) & \\text{relu}(-x_n)\\end{bmatrix}$\n\n4. $(l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\\\ =\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots  \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}$ \n    - ${\\bf W}^{(2)}=\\begin{bmatrix} -4.5 \\\\ -9 \\end{bmatrix}$\n    - $b^{(2)}=4.5$\n\n5. $net({\\bf X})=(a_2 \\circ l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{sig}\\Big(\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\Big)\\\\=\\begin{bmatrix} \\text{sig}\\Big(-4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5\\Big) \\\\ \\text{sig}\\Big(-4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\Big)\\\\ \\dots  \\\\ \\text{sig}\\Big(-4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\Big)\\end{bmatrix}$ \n\n\n`-` 차원만 따지자\n\n$\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}$\n\n### Step1 ~ Step4\n\n`-` 준비\n\n`-` 반복 \n\n## 깊은신경망--DNN으로 해결가능한 다양한 예제\n\n### 예제1\n\n`-` 언뜻 생각하면 방금 배운 기술은 sig를 취하기 전이 꺽은선인 형태만 가능할 듯 하다. $\\to$ 그래서 이 역시 표현력이 부족할 듯 하다. $\\to$ 그런데 생각보다 표현력이 풍부한 편이다. 즉 생각보다 쓸 만하다. \n\n- 이거 시그모이드 취하기 직전은 step이 포함된 듯 $\\to$ 그래서 꺽은선으로는 표현할 수 없는 구조임 $\\to$ 그런데 사실 대충은 표현가능 \n\n- $\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,16)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,16)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}$\n\n### 예제2\n\n`-` 사실 꺽은선의 조합으로 꽤 많은걸 표현할 수 있거든요? $\\to$ 심지어 곡선도 대충 맞게 적합된다. \n\n(풀이1)\n\n- $\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}$\n\n(풀이2) -- 풀이1보다 좀 더 잘맞음. 잘 맞는 이유? 좋은초기값 (=운) \n\n- $\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}$\n\n- 풀이1에서 에폭을 많이 반복하면 풀이2의 적합선이 나올까? --> 안나옴!! (local min에 빠졌다) \n\n### 예제3\n\n- $\\underset{(n,2)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}$\n\n`-` 결과시각화 \n\n`-` 교훈: underlying이 엄청 이상해보여도 생각보다 잘 맞춤\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"2022-10-05-ml-5w.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.315","theme":"pulse","code-copy":false,"title-block-banner":true,"comments":{"utterances":{"repo":"seoyeonc/md"}},"title":"DNN (5주차)","author":"SEOYEON CHOI","date":"2022-10-05","categories":["Special Topics in Machine Learning","로지스틱","깊은신경망"]},"extensions":{"book":{"multiFile":true}}},"ipynb":{"identifier":{"display-name":"Jupyter","target-format":"ipynb","base-format":"ipynb"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"png","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"ipynb","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"default-image-extension":"png","to":"ipynb","output-file":"2022-10-05-ml-5w.ipynb"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"title-block-banner":true,"comments":{"utterances":{"repo":"seoyeonc/md"}},"title":"DNN (5주차)","author":"SEOYEON CHOI","date":"2022-10-05","categories":["Special Topics in Machine Learning","로지스틱","깊은신경망"]}}},"projectFormats":["html"]}