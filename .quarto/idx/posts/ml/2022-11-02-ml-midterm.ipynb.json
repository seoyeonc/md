{"title":"Midterm","markdown":{"yaml":{"title":"Midterm","author":"SEOYEON CHOI","date":"2022-11-02","categories":["Special Topics in Machine Learning"]},"headingText":"`1`. 크롤링을 통한 이미지 분석 및 CAM","containsRefs":false,"markdown":"\n\n중간고사 대체과제\n\n\n`(1)` 두 가지 키워드로 크롤링을 수행하여 이미지자료를 모아라. (키워드는 각자 마음에 드는 것으로 설정할 것) \n\n***힌트1: `hynn`, `iu` 라는 키워드로 크롤링하여 이미지자료를 모으는 코드***\n\n```python\n# \n# 폴더만드는코드 -- 사실 손으로 만들어도 무방함.. \n!mkdir images\n!mkdir images/train\n!mkdir images/test \n!mkdir images/train/iu\n!mkdir images/train/hynn\n!mkdir images/test/iu\n!mkdir images/test/hynn\n```\n\n```python\ndownload_images(dest='./images/train/iu',urls=search_images('iu',max_images=200)) # iu 라는 키워드로 200개 이미지 크롤링 -> ./images/train/iu 에 저장\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/train/hynn',urls=search_images('hynn',max_images=200)) # hynn 이라는 키워드로 200개 이미지 크롤링 -> ./images/train/hynn 에 저장\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/train/iu',urls=search_images('iu kpop',max_images=200))  # iu kpop 이라는 키워드로 200개 이미지 크롤링 -> ./images/train/iu 에 저장\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/train/hynn',urls=search_images('hynn kpop',max_images=200)) # hynn kpop 이라는 키워드로 200개 이미지 크롤링 -> ./images/train/hynn 에 저장\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \n```\n\n```python\ndownload_images(dest='./images/test/iu',urls=search_images('iu photo',max_images=50)) # iu photo 라는 키워드로 50개 이미지 크롤링 -> ./images/test/iu 에 저장\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/test/hynn',urls=search_images('hynn photo',max_images=50)) # hynn photo 라는 키워드로 50개 이미지 크롤링 -> ./images/test/hynn 에 저장 \ntime.sleep(10) # 서버과부하를 위한 휴식코드 \n```\n\n***힌트2: 불량이미지 삭제***\n\n```python\nbad_images = verify_images(get_image_files('./images'))\nbad_images\n```\n\n- 불량이미지 목록 \n\n```python\nbad_images.map(Path.unlink)\n```\n\n- 불량이미지는 dls를 불러올때 방해되므로 제거 \n\n`(2)` ImageDataLoaders.from_folder 를 이용하여 dls를 만들어라. \n\n***힌트1: dls를 만드는 코드***\n\n```pythpn\ndls = ImageDataLoaders.from_folder(path = './images', train='train',valid='test',item_tfms=Resize(512),bs=8) \n```\n\n```python\ndls.show_batch()\n```\n\n`(3)` resnet34를 이용하여 학습하라. \n\n`(4)` CAM (class activation mapping)을 이용하여 (3)의 모형의 판단근거를 시각화하라. \n\n## `2`. Overparameterized Model  \n\n(풀이 있음)\n\n아래와 같은 자료가 있다고 가정하자. \n\n`(1)` 아래의 모형을 가정하고 $\\beta_0,\\beta_1$을 파이토치를 이용하여 추정하라. \n\n- $y_i = \\beta_0  + \\beta_1 x_i + \\epsilon_i,\\quad \\epsilon_i \\sim N(0,\\sigma^2)$\n\n`(2)` 아래의 모형을 가정하고 $\\beta_0$를 파이토치를 이용하여 추정하라. \n\n- $y_i = \\beta_0  + \\epsilon_i,\\quad \\epsilon_i \\sim N(0,\\sigma^2)$\n\n`(3)` 아래의 모형을 가정하고 $\\beta_1$을 파이토치를 이용하여 추정하라. \n\n- $y_i = \\beta_1x_i  + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)$\n\n`(4)` 아래의 모형을 가정하고 $\\alpha_0,\\beta_0,\\beta_1$을 파이토치를 이용하여 추정하라. \n\n- $y_i = \\alpha_0+\\beta_0+ \\beta_1x_i  + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)$\n\n$\\hat{\\alpha}_0+\\hat{\\beta}_0$은 얼마인가? 이 값과  문제 (1)에서 추정된 $\\hat{\\beta_0}$의 값과 비교하여 보라. \n\n`(5)` 아래의 모형을 가정하고 $\\alpha_0,\\alpha_1,\\beta_0,\\beta_1$을 파이토치를 이용하여 추정하라. -- 이거 제가 힌트를 잘못줬어요.. 문제가 좀 어렵게나왔네요 ㅠㅠ\n\n- $y_i = \\alpha_0+\\beta_0+ \\beta_1x_i + \\alpha_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)$ \n\n$\\hat{\\alpha}_0+\\hat{\\beta}_0$, $\\hat{\\alpha}_1 + \\hat{\\beta}_1$의 값은 각각 얼마인가? 이 값들을 (1) 에서 추정된 $\\hat{\\beta}_0$, $\\hat{\\beta}_1$ 값들과 비교하라. \n\n`(6)` 다음은 위의 모형에 대하여 학생들이 discussion한 결과이다. 올바르게 해석한 학생을 모두 골라라. \n\n**민정**: $(x_i,y_i)$의 산점도는 직선모양이고 직선의 절펴과 기울기 모두 유의미해 보이므로 $y_i = \\beta_0 + \\beta_1 x_i$ 꼴을 적합하는게 좋겠다. \n\n**슬기**: 나도 그렇게 생각해. 그래서 (2)-(3)과 같이 기울기를 제외하고 적합하거나 절편을 제외하고 적합하면 underfitting의 상황에 빠질 수 있어. \n\n**성재**: (2)의 경우 사실상 $\\bar{y}=\\frac{1}{n}\\sum_{i=1}^{n}y_i$를 추정하는 것과 같아지게 되지. \n\n**세민**: (4)의 경우 ${\\bf X}=\\begin{bmatrix} 1  & x_1 \\\\ 1 & x_2 \\\\ \\dots & \\dots \\\\ 1 & x_n \\end{bmatrix}$ 와 같이 설정하고 네트워크를 아래와 같이 설정할 경우 얻어지는 모형이야. \n```python\nnet = torch.nn.Linear(in_features=2,out_features=1,bias=True)\n```\n\n**구환**: 모델 (4)-(5)는 표현력은 (1)과 동일하지만 추정할 파라메터는 (1)보다 많으므로 효율적인 모델이라고 볼 수 없어. \n\n**answer** : 민정, 슬기, 세민, 구환\n\n***이 문제의 경우 풀이를 [여기](https://guebin.github.io/DL2022/2022/10/26/Assignment-2.html)에서 확인할 수 있습니다.***\n\n## `3`. 차원축소기법과 표현학습\n\n다음은 아이리스데이터를 불러오는 코드이다. (아이리스 데이터에 대한 자세한 설명은 생략한다. 잘 모르는 학생은 구글검색을 해볼 것)\n\n`(1)` 아래를 만족하도록 적당한 아키텍처, 손실함수를 설계하라. (손실함수는 MSE를 이용)\n\n- $\\underset{(150,4)}{\\bf X} \\overset{l_1}{\\to} \\underset{(150,2)}{\\bf Z} \\overset{l_2}{\\to} \\underset{(150,4)}{\\bf \\hat X}$\n\n- ${\\bf \\hat X} \\approx {\\bf X}$\n\n\n차원축소\n\n`(2)` 아래코드를 이용하여 ${\\bf X}$, ${\\bf Z}$, ${\\bf \\hat{X}}$를 시각화 하라. \n\n(시각화예시)\n\n```python\nfig,ax = plt.subplots(figsize=(10,10)) \nax.imshow(torch.concat([X,Z,Xhat],axis=1)[:10])\nax.set_xticks(np.arange(0,10)) \nax.set_xticklabels([r'$X_1$',r'$X_2$',r'$X_3$',r'$X_4$',r'$Z_1$',r'$Z_2$',r'$\\hat{X}_1$',r'$\\hat{X}_2$',r'$\\hat{X}_3$',r'$\\hat{X}_4$'])\nax.vlines([3.5,5.5],ymin=-0.5,ymax=9.5,lw=2,color='red',linestyle='dashed')\nax.set_title(r'First 10 obs of $\\bf [X, Z, \\hat{X}]$ // before learning',size=25);\n```\n\n`(3)` 네트워크를 학습시키고 ${\\bf X}, {\\bf Z}, {\\bf \\hat{X}}$를 시각화하라. \n\n(시각화예시)\n\n```python\nfig,ax = plt.subplots(figsize=(10,10)) \nax.imshow(torch.concat([X,Z,Xhat],axis=1)[:10])\nax.set_xticks(np.arange(0,10)) \nax.set_xticklabels([r'$X_1$',r'$X_2$',r'$X_3$',r'$X_4$',r'$Z_1$',r'$Z_2$',r'$\\hat{X}_1$',r'$\\hat{X}_2$',r'$\\hat{X}_3$',r'$\\hat{X}_4$'])\nax.vlines([3.5,5.5],ymin=-0.5,ymax=9.5,lw=2,color='red',linestyle='dashed')\nax.set_title(r'First 10 obs of $\\bf [X, Z, \\hat{X}]$ // after learning',size=25);\n```\n\n`(4)` (3)의 결과로 학습된 $Z$를 입력벡터로 하고 $Z \\to y=\\text{Species}$ 로 향하는 적당한 네트워크를 설계한 뒤 학습하라. \n\nx->y가는 mapping 안 찾아도\n- z->y 가는 mapping 적절히 잘 찾으면\n- x->y 적용가능한 linear function 찾기 가능\n\n`(5)` (1)~(4)의 결과를 토의한 내용이다. 적절하게 토의한 사람을 모두 고르라. \n\n**규빈**: ${\\bf Z}$는 ${\\bf X}$보다 적은 feature를 가지고 있다. 또한 적절한 선형변환을 하면 ${\\bf X}$와 비슷한 ${\\bf \\hat X}$을 만들 수 있으므로 ${\\bf X}$의 정보량 대부분 유지한채로 효과적으로 차원을 줄인 방법이라 볼 수 있다. \n\n**민정**: 즉 ${\\bf X}$에서 ${\\bf y}$로 가는 맵핑을 학습하는 과업은 ${\\bf Z}$에서 ${\\bf y}$로 가는 맵핑을 학습하는 과업은 거의 동등하다고 볼 수 있다. \n\n**성재**: ${\\bf Z}$의 차원을 (n,4)로 설정한다면 이론상 ${\\bf X}$와 동일한 ${\\bf \\hat X}$을 만들어 낼 수 있다. \n\n**슬기**: ${\\bf Z}$의 차원이 (n,2)일지라도 경우에 따라서 ${\\bf X}$와 동일한 ${\\bf \\hat X}$을 만들어 낼 수 있다. \n\n**answer** :  규빈, 민정, 성재, 슬기\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"2022-11-02-ml-midterm.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","theme":"pulse","code-copy":false,"title-block-banner":true,"title":"Midterm","author":"SEOYEON CHOI","date":"2022-11-02","categories":["Special Topics in Machine Learning"]},"extensions":{"book":{"multiFile":true}}}}}