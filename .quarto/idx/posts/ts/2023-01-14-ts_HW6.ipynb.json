{"title":"Theoritical Statistics HW6","markdown":{"yaml":{"title":"Theoritical Statistics HW6","author":"SEOYEON CHOI","date":"2023-01-14","categories":["Theoritical Statistics"]},"headingText":"2.","containsRefs":false,"markdown":"\n\n> 4장 모수의 추정\n\n\n$X_1, \\dots, X_n$이 확률밀도함수 $f_X(x:\\theta) = (\\theta + 1) x^{\\theta},0<x<1$로부터의 랜덤표본이라고 할 때, 적률을 이용한 $\\theta$의 추정량이 $\\frac{2\\bar{X}_n-1}{1-\\bar{X}_n}$ 이 됨을 보여라.\n\n**answer**\n\n$\\mu = E(X) = \\int^{\\infty}_{-\\infty}xf(x:\\theta) dx = \\int^{1}_0 (\\theta + 1) x^{\\theta +1 } dx = (\\theta+1)[\\frac{x^{\\theta+2}}{\\theta+2}]^1_0 = \\frac{\\theta + 1}{\\theta + 2}$\n\n$\\mu_1 = \\frac{\\theta + 1}{\\theta + 2} \\sim \\bar{X} = \\frac{\\theta + 1}{\\theta + 2}$\n\n$\\bar{X} \\theta + 2 \\bar{X} = \\theta +1$\n\n$\\hat{\\theta}(1-\\bar{X}) = 2\\bar{X} - 1$\n\n$\\hat{\\theta} =  \\frac{2\\bar{X} - 1}{1-\\bar{X}}$\n\n# 4.\n\n$X_1, \\dots X_n$이 $U(0,\\theta)$로부터의 랜덤표본이라고 할 때, 적률을 이용한 $\\theta$의 추정량을 구하고, 최대가능도 추정량과 비교하라.\n\n**answer**\n\n$\\mu_1 = E(X) = \\frac{a+b}{2} = \\frac{\\theta}{2}$\n\n$\\hat{\\theta}^{MME} = 2\\mu_1 = 2\\bar{X}$\n\n$f(x) = \\frac{1}{\\theta} I(0<x<\\theta)$\n\n$L(\\theta) = f(x_1 | \\theta) \\dots f(X_n | \\theta) = \\frac{1}{\\theta}I(0<x_1< \\theta) \\dots \\frac{1}{\\theta} I(0<X_n< \\theta) = \\frac{1}{\\theta^n} I(0<x_{(1)}, x_{(n)} < \\theta)$\n\n$x_{(n)}$일 때, $L(\\theta)$가 최대가 된다.\n\n![image.png](attachment:7538cbc0-e811-4973-873c-bc7a0f6f58bd.png)\n\n$\\hat{\\theta}^{MME}$와 $\\hat{\\theta}^{MLE}$ 모두 비편향 추정량이 아니다.\n\n$\\hat{\\theta}^{MME}$에서는 $\\theta$가 $2\\bar{X}$가 될 때 기댓값이 최대가 되고, $\\hat{\\theta}^{MLE}$에서는 $\\theta$가 $X_{(n)}$이 될 때, $L(\\theta)$가 최대가 되었다.\n\n# 7.\n\n확률변수 $X$의 분포가 $P(X=1)=\\theta^2$, $P(X=2) = 2\\theta(1-\\theta)$, $P(X=3)=(1-\\theta)^2$(단, $0<\\theta<1$)이라고 하자. 이제 세 개의 관찰값 $2,2,3$을 얻었을 때, 모수 $\\theta$의 최대가능도 추정값을 구하라.\n\n**answer**\n\n$f(x) = x\\theta^{3-x}(1-\\theta)^{x-1}$\n\n$L(\\theta) = 2\\theta (1-\\theta) \\times 2\\theta(1-\\theta)\\times (1-\\theta)^2 = 4\\theta^2 (1-\\theta)^4$\n\n$L'(\\theta) = 8\\theta(1-\\theta)^4 - 16\\theta^2 (1-\\theta)^3 = 8\\theta(1-\\theta)^3(1-\\theta - 2\\theta) = 8\\theta(1-\\theta)^3(1-3\\theta) = 0$\n\n$\\theta = \\frac{1}{3}$일때, $L(\\theta)$가 최대이다.\n\n$\\therefore L(\\theta|2,2,3)$에서의 모수 $\\theta$의 최대가능도 추정값은 $\\frac{1}{3}$\n\n# 14.\n\n$X_1,\\dots,X_n$ 이 평균이 $\\mu$이고, 분산이 $\\sigma^2$인 분포로부터 얻은 랜덤표본이라고 할 때 모평균 $\\mu$가 알려져 있다면, $\\frac{1}{n}\\sum(X_i - \\mu)^2$이 $\\sigma^2$의 비편향 추정량임을 보여라.\n\n**answer**\n\n$E(\\frac{1}{n}\\sum(X_i - \\mu)^2) = \\frac{n\\sigma^2}{n} = \\sigma^2$\n\n# 15.\n\n$X \\sim U(0,\\theta)$일때, $\\theta^2$의 비편향추정량을 구하라.\n\n**answer**\n\n$E(X) = \\frac{\\theta}{2}$, $var(X) = \\frac{\\theta^2}{12}$\n\n$E(X^2) = var(X) + (E(X))^2 = \\frac{\\theta^2}{12}+\\frac{\\theta^2}{4} = \\frac{\\theta^2}{3}$\n\n$\\hat{\\theta}^2 = 3X^2$\n\n# 19.\n\n$X \\sim Bernoulli(p)$일때, $p$에 대한 추정량으로 $T_1(x) = X$와 $T_2(X) = \\frac{1}{2}$을 고려하였다.\n\n## (1)\n\n$T_1(X)$와 $T_2(X)$의 비평향성을 점검하라.\n\n**answer**\n\n$E(T_1(X)) = E(X) = p \\to T_1(X)$ 비편향성 만족\n\n$E(T_2(X)) = E(\\frac{1}{2}) = \\frac{1}{2} \\to T_2(X)$ 비편향성 불만족\n\n## (2)\n\n$T_1(X)$와 $T_2(X)$의 평균제곱오차를 비교하라.\n\n**answer**\n\n$MSE(T_1(X)) = MSE(X)$\n\n$= E(X-P)^2 = E(X^2 - 2PX + P^2)$\n\n$= P(1-P) + P^2 -2P^2 + P^2 = P-P^2+P^2-2P^2+P^2 = P-P^2 = P(1-P)$\n\n$MSE(T_2(X)) = MSE(\\frac{1}{2} - E(\\frac{1}{2} - P)^2) = (\\frac{1}{2}-P)^2$\n\n$\\star$\n\n$P-P^2 = \\frac{1}{4}-2P+P^2$\n\n$2P^2 -3P+\\frac{1}{4} = 0$\n\n$P = \\frac{3 \\pm \\sqrt{9-1}}{4} = \\frac{3 \\pm \\sqrt{7}}{4}$\n\n![image.png](attachment:ffe6ef6c-92bc-4dfc-9d0a-a0a8dad14610.png)\n\n# 20.\n\n$X_1,X_2,\\dots,X_n$이 $EXP(\\lambda)$로부터 얻은 랜덤표본이라고 하자, 모수 $\\lambda$에 대한 추정량으로 $\\hat{\\lambda_1} = \\bar{X}_n$과 $\\hat{\\lambda}_2 = \\frac{n\\bar{X}_n }{ (n+1)}$을 비교할 때,\n\n## (1)\n\n$\\hat{\\lambda}_1$과 $\\hat{\\lambda}_2$의 분산을 구하라.\n\n**answer**\n\n$E(X_i) = \\lambda, Var(X_i) = \\lambda^2$\n\n$E(\\hat{\\lambda}_1) = E(\\bar{X}) = \\lambda \\to$, 비편향추정량이다.\n\n$Var(\\hat{\\lambda}_1) = E(\\bar{X})  = \\frac{\\lambda^2}{n}$\n\n$E(\\hat{\\lambda_2}) = E(\\frac{n\\bar{X}_n}{n+1}) = \\frac{n}{n+1}E(\\bar{X}_n) = \\frac{n}{n+1}\\lambda \\to$비편향 추정량이 아니다., 즉, 분산에 bias존재\n\n$Var(\\hat{\\lambda_2}) = Var(\\frac{n}{n+1}\\bar{X}_n) = E(\\frac{n}{n+1}\\bar{X} - \\lambda)^2$\n\n$= E(\\frac{n}{n+1} \\bar{X} - \\frac{n}{n+1} \\lambda + \\frac{n}{n+1}\\lambda -\\lambda)^2$\n\n$= E(\\frac{n}{n+1}(\\bar{X}-\\lambda) - \\frac{1}{n+1}\\lambda)^2$\n\n$= (\\frac{n}{n+1})^2E(\\bar{X} - \\lambda)^2 + \\frac{1}{(n+1)^2}\\lambda^2 - \\frac{2n}{(n+1)^2}\\lambda(\\bar{X} - \\lambda)$\n\n$= (\\frac{n}{n+1})^2 \\lambda^2 + \\frac{1}{(n+1)^2}\\lambda^2$\n\n$= \\frac{n^2+1}{(n+1)^2}\\lambda^2$\n\n## (2)\n\n$\\hat{\\lambda}_1$과 $\\hat{\\lambda}_2$의 평균제곱오차를 구하라.\n\n**answer**\n\n$MSE(\\hat{\\lambda}_1) = E(\\hat{\\lambda}_1 - \\lambda)^2 = var(\\hat{\\lambda}_1) = \\frac{\\lambda^2}{n}$\n\n$\\star$ 비편향추정량이라 분산과 일치하는 $\\hat{\\lambda}_1$\n\n$MSE(\\hat{\\lambda}_2) = E(\\hat{\\lambda}_2 - \\lambda)^2 = var(\\hat{\\lambda}_2) + (bias(\\hat{\\lambda}_2))^2$\n\n$\\star$ 비편향추정량이 아니라 bias까지 고려해줘야 하는 $\\hat{\\lambda}_2$\n\n$var(\\hat{\\lambda}_2) = \\frac{n^2+1}{(n+1)^2}\\lambda^2$\n\n$bias(\\hat{\\lambda}_2) = E(\\hat{\\lambda}_2) - \\lambda = \\frac{n}{n+1}\\lambda - \\lambda = -\\frac{1}{n+1}\\lambda$\n\n$\\star var(\\hat{\\lambda}_2) + (bias(\\hat{\\lambda}_2))^2$\n\n$= \\frac{n^2+1}{(n+1)^2}\\lambda^2 + \\frac{1}{(n+1)^2}\\lambda^2 = \\frac{n^2+2}{(n+1)^2}\\lambda^2$\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"2023-01-14-ts_HW6.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","theme":"pulse","code-copy":false,"title-block-banner":true,"title":"Theoritical Statistics HW6","author":"SEOYEON CHOI","date":"2023-01-14","categories":["Theoritical Statistics"]},"extensions":{"book":{"multiFile":true}}}}}