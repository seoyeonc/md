<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="SEOYEON CHOI">
<meta name="dcterms.date" content="2022-10-12">

<title>Seoyeon’s Blog for classes - DNN (6주차)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Seoyeon’s Blog for classes</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../about.html" aria-current="page">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/seoyeonc/md/"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">DNN (6주차)</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title d-none d-lg-block">DNN (6주차)</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Special Topics in Machine Learning</div>
                <div class="quarto-category">딥러닝의 기초</div>
                <div class="quarto-category">깊은신경망</div>
                <div class="quarto-category">시벤코정리</div>
                <div class="quarto-category">신경망의표현</div>
                <div class="quarto-category">확률적경사하강법</div>
                <div class="quarto-category">오버피팅</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>SEOYEON CHOI </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 12, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../about.html" class="sidebar-item-text sidebar-link">About</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Posts</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ap/index.html" class="sidebar-item-text sidebar-link">Advanced Probability Theory</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-07-ap_1wk.html" class="sidebar-item-text sidebar-link">1주차: 측도론</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-14-ap-2wk.html" class="sidebar-item-text sidebar-link">2주차: 측도론</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-21-ap-3wk.html" class="sidebar-item-text sidebar-link">3주차: 측도론</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-28-ap-4wk.html" class="sidebar-item-text sidebar-link">4주차: 측도론</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/rl/index.html" class="sidebar-item-text sidebar-link">Advanced Regression Analysis</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2023-02-23-rl-final_term.html" class="sidebar-item-text sidebar-link">Advanced Regression Analysis Final Term</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2023-03-02-graduation_test.html" class="sidebar-item-text sidebar-link">Advanced Regression Analysis GT</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2023-02-22-rl-mid_term.html" class="sidebar-item-text sidebar-link">Advanced Regression Analysis Mid Term</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-09-21-rl_HW1.html" class="sidebar-item-text sidebar-link">Regression HW 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-10-23-rl-HW2.html" class="sidebar-item-text sidebar-link">Regression HW 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-21-rl-HW3.html" class="sidebar-item-text sidebar-link">Regression HW 3</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-12-08-rl-HW4.html" class="sidebar-item-text sidebar-link">Regression HW 4</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-12-11-rl-Ch10.html" class="sidebar-item-text sidebar-link">고급회귀분석 CH10</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-09-21-rl_CH03, CH04.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH03, CH04</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-14-rl_CH06, CH07.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH06, CH07</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-23-rl-CH10.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH10</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-12-05-rl-CH11.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH11</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-28-rl-CH13.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH13</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ct/index.html" class="sidebar-item-text sidebar-link">Coding Test</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-15-Coding_Test_Algorithm.html" class="sidebar-item-text sidebar-link">Algorithm</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-02-12-Coding_Test.html" class="sidebar-item-text sidebar-link">ArrayList &amp; LinkedList</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-01-Coding_Test_Greedy.html" class="sidebar-item-text sidebar-link">Chapter 03 Greedy</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/Untitled.html" class="sidebar-item-text sidebar-link">Map</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-03-12-Coding_Test_Queue.html" class="sidebar-item-text sidebar-link">Queue</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-03-05-Coding_Test_Stack.html" class="sidebar-item-text sidebar-link">Stack</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-03-22-Coding_Test_Tree.html" class="sidebar-item-text sidebar-link">Tree</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-15-Coding_Test_interfunction.html" class="sidebar-item-text sidebar-link">내장함수</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-23-Coding_Test_Q2.html" class="sidebar-item-text sidebar-link">두 큐 합 같게 만들기(Done)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-21-Coding_Test_Q1.html" class="sidebar-item-text sidebar-link">성격 유형 검사하기(Done)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-30-Coding_Test_Q3.html" class="sidebar-item-text sidebar-link">코딩 테스트 공부(Done)</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ml_basic/index.html" class="sidebar-item-text sidebar-link">Machine Learning basic</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-29-Lasso and Ridge.html" class="sidebar-item-text sidebar-link">Lasso and Ridge</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-28-Linear Regression, Logistic Regression.html" class="sidebar-item-text sidebar-link">Linear Regression, Logistic Regression</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-28-Principal Component Analysis.html" class="sidebar-item-text sidebar-link">Principal Component Analysis</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-23-Support Vector Machine.html" class="sidebar-item-text sidebar-link">Support Vector Machine</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ml/index.html" class="sidebar-item-text sidebar-link">Special Topics in Machine Learning</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-07-13wk.html" class="sidebar-item-text sidebar-link">A1: 깊은복사와 얕은복사 (12주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-19-Assignment-1-Copy1.html" class="sidebar-item-text sidebar-link">Assignment 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-19-ml_7w.html" class="sidebar-item-text sidebar-link">CNN (7주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-26-ml_8w_1.html" class="sidebar-item-text sidebar-link">CNN (8주차) 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-26-ml_8w_2.html" class="sidebar-item-text sidebar-link">CNN (8주차) 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-29-13wk-2-final.html" class="sidebar-item-text sidebar-link">Deep Learning final example</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-07-ml_1w.html" class="sidebar-item-text sidebar-link">DNN (1주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-14-ml_2w.html" class="sidebar-item-text sidebar-link">DNN (2주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-21-ml_3w.html" class="sidebar-item-text sidebar-link">DNN (3주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-29-ml_4w.html" class="sidebar-item-text sidebar-link">DNN (4주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-05-ml-5w.html" class="sidebar-item-text sidebar-link">DNN (5주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-12-ml-6w.html" class="sidebar-item-text sidebar-link active">DNN (6주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-21-Extra-1.html" class="sidebar-item-text sidebar-link">Extra-1: 추천시스템</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-21-Extra-2.html" class="sidebar-item-text sidebar-link">Extra-2: 생성모형(GAN)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-23-Extra-3.html" class="sidebar-item-text sidebar-link">Extra-3: 딥러닝의 기초 (5)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-13-final_seoyeon.html" class="sidebar-item-text sidebar-link">Finalterm</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-05-ml-HW.html" class="sidebar-item-text sidebar-link">Homework</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-07-ml.html" class="sidebar-item-text sidebar-link">Intro</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-02-ml-midterm.html" class="sidebar-item-text sidebar-link">Midterm</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-09-ml-10w.html" class="sidebar-item-text sidebar-link">RNN (10주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-21-ml-11w.html" class="sidebar-item-text sidebar-link">RNN (11주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-30-12wk.html" class="sidebar-item-text sidebar-link">RNN (12주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-08-13wk.html" class="sidebar-item-text sidebar-link">RNN (13주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-02-ml_9w.html" class="sidebar-item-text sidebar-link">RNN (9주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-14-study.html" class="sidebar-item-text sidebar-link">study</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ts/index.html" class="sidebar-item-text sidebar-link">Theoritical Statistics</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-25-ts-final term.html" class="sidebar-item-text sidebar-link">Theoritical Statistics Final term</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-03-03-ts-final_qanda.html" class="sidebar-item-text sidebar-link">Theoritical Statistics Final term 6 Explanation</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-03-03-graduation_test.html" class="sidebar-item-text sidebar-link">Theoritical Statistics GT</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-05-ts_HW1.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-05-ts_HW2.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-05-ts_HW3.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW3</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-09-ts_HW4.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW4</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-12-ts_HW5.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW5</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-14-ts_HW6.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW6</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-18-ts_HW7.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW7</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-18-ts-HW8.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW8</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-21-ts-HW9.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW9</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-14-ts_Mid term.html" class="sidebar-item-text sidebar-link">Theoritical Statistics Mid term</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2022-12-31-ts_1.html" class="sidebar-item-text sidebar-link">확률변수와 확률분포</a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#imports" id="toc-imports" class="nav-link active" data-scroll-target="#imports">imports</a></li>
  <li><a href="#시벤코정리" id="toc-시벤코정리" class="nav-link" data-scroll-target="#시벤코정리">시벤코정리</a>
  <ul class="collapse">
  <li><a href="#지난시간-논리전개" id="toc-지난시간-논리전개" class="nav-link" data-scroll-target="#지난시간-논리전개">지난시간 논리전개</a></li>
  <li><a href="#시벤코정리-1" id="toc-시벤코정리-1" class="nav-link" data-scroll-target="#시벤코정리-1">시벤코정리</a></li>
  </ul></li>
  <li><a href="#시벤코정리-proof" id="toc-시벤코정리-proof" class="nav-link" data-scroll-target="#시벤코정리-proof">시벤코정리 proof</a>
  <ul class="collapse">
  <li><a href="#그림으로-보는-증명과정" id="toc-그림으로-보는-증명과정" class="nav-link" data-scroll-target="#그림으로-보는-증명과정">그림으로 보는 증명과정</a></li>
  </ul></li>
  <li><a href="#시벤코정리-활용" id="toc-시벤코정리-활용" class="nav-link" data-scroll-target="#시벤코정리-활용">시벤코정리 활용</a>
  <ul class="collapse">
  <li><a href="#예제1-sin-exp" id="toc-예제1-sin-exp" class="nav-link" data-scroll-target="#예제1-sin-exp">예제1 (sin, exp)</a></li>
  <li><a href="#예제2-스펙높아도-취업x" id="toc-예제2-스펙높아도-취업x" class="nav-link" data-scroll-target="#예제2-스펙높아도-취업x">예제2 (스펙높아도 취업X)</a></li>
  <li><a href="#예제3-mnist-data-with-dnn" id="toc-예제3-mnist-data-with-dnn" class="nav-link" data-scroll-target="#예제3-mnist-data-with-dnn">예제3 (MNIST data with DNN)</a></li>
  </ul></li>
  <li><a href="#신경망의-표현-boldsymbol-x-to-hatboldsymbol-y-로-가는-과정을-그림으로-표현" id="toc-신경망의-표현-boldsymbol-x-to-hatboldsymbol-y-로-가는-과정을-그림으로-표현" class="nav-link" data-scroll-target="#신경망의-표현-boldsymbol-x-to-hatboldsymbol-y-로-가는-과정을-그림으로-표현">신경망의 표현 (<span class="math inline">\({\boldsymbol x} \to \hat{\boldsymbol y}\)</span> 로 가는 과정을 그림으로 표현)</a>
  <ul class="collapse">
  <li><a href="#예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y" id="toc-예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y" class="nav-link" data-scroll-target="#예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y">예제1: <span class="math inline">\(\underset{(n,1)}{\bf X} \overset{l_1}{\to} \underset{(n,1)}{\boldsymbol u^{(1)}} \overset{sig}{\to} \underset{(n,1)}{\boldsymbol v^{(1)}} =\underset{(n,1)}{\hat{\boldsymbol y}}\)</span></a></li>
  <li><a href="#예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y" id="toc-예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y" class="nav-link" data-scroll-target="#예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y">예제2: <span class="math inline">\(\underset{(n,1)}{\bf X} \overset{l_1}{\to} \underset{(n,2)}{\boldsymbol u^{(1)}} \overset{relu}{\to} \underset{(n,2)}{\boldsymbol v^{(1)}} \overset{l_2}{\to} \underset{(n,1)}{\boldsymbol u^{(2)}} \overset{sig}{\to} \underset{(n,1)}{\boldsymbol v^{(2)}} =\underset{(n,1)}{\hat{\boldsymbol y}}\)</span></a></li>
  <li><a href="#예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y" id="toc-예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y" class="nav-link" data-scroll-target="#예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y">예제3: <span class="math inline">\(\underset{(n,784)}{\bf X} \overset{l_1}{\to} \underset{(n,32)}{\boldsymbol u^{(1)}} \overset{relu}{\to} \underset{(n,32)}{\boldsymbol v^{(1)}} \overset{l_1}{\to} \underset{(n,1)}{\boldsymbol u^{(2)}} \overset{sig}{\to} \underset{(n,1)}{\boldsymbol v^{(2)}}=\underset{(n,1)}{\hat{\boldsymbol y}}\)</span></a></li>
  </ul></li>
  <li><a href="#cpu-vs-gpu" id="toc-cpu-vs-gpu" class="nav-link" data-scroll-target="#cpu-vs-gpu">CPU vs GPU</a>
  <ul class="collapse">
  <li><a href="#gpu-사용방법" id="toc-gpu-사용방법" class="nav-link" data-scroll-target="#gpu-사용방법">GPU 사용방법</a></li>
  <li><a href="#시간측정-예비학습" id="toc-시간측정-예비학습" class="nav-link" data-scroll-target="#시간측정-예비학습">시간측정 (예비학습)</a></li>
  <li><a href="#cpu-512" id="toc-cpu-512" class="nav-link" data-scroll-target="#cpu-512">CPU (512)</a></li>
  <li><a href="#gpu-512" id="toc-gpu-512" class="nav-link" data-scroll-target="#gpu-512">GPU (512)</a></li>
  <li><a href="#cpu-vs-gpu-20480" id="toc-cpu-vs-gpu-20480" class="nav-link" data-scroll-target="#cpu-vs-gpu-20480">CPU vs GPU (20480)</a></li>
  <li><a href="#cpu-vs-gpu-204800" id="toc-cpu-vs-gpu-204800" class="nav-link" data-scroll-target="#cpu-vs-gpu-204800">CPU vs GPU (204800)</a></li>
  </ul></li>
  <li><a href="#확률적경사하강법-배치-에폭" id="toc-확률적경사하강법-배치-에폭" class="nav-link" data-scroll-target="#확률적경사하강법-배치-에폭">확률적경사하강법, 배치, 에폭</a>
  <ul class="collapse">
  <li><a href="#좀-이상하지-않아요" id="toc-좀-이상하지-않아요" class="nav-link" data-scroll-target="#좀-이상하지-않아요">좀 이상하지 않아요?</a></li>
  <li><a href="#xy-데이터를-굳이-모두-gpu에-넘겨야-하는가" id="toc-xy-데이터를-굳이-모두-gpu에-넘겨야-하는가" class="nav-link" data-scroll-target="#xy-데이터를-굳이-모두-gpu에-넘겨야-하는가">X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?</a></li>
  <li><a href="#경사하강법-확률적경사하강법-미니배치-경사하강법" id="toc-경사하강법-확률적경사하강법-미니배치-경사하강법" class="nav-link" data-scroll-target="#경사하강법-확률적경사하강법-미니배치-경사하강법">경사하강법, 확률적경사하강법, 미니배치 경사하강법</a></li>
  <li><a href="#용어의-정리" id="toc-용어의-정리" class="nav-link" data-scroll-target="#용어의-정리">용어의 정리</a></li>
  <li><a href="#ds-dl" id="toc-ds-dl" class="nav-link" data-scroll-target="#ds-dl">ds, dl</a></li>
  <li><a href="#ds-dl을-이용한-mnist-구현" id="toc-ds-dl을-이용한-mnist-구현" class="nav-link" data-scroll-target="#ds-dl을-이용한-mnist-구현">ds, dl을 이용한 MNIST 구현</a></li>
  </ul></li>
  <li><a href="#오버피팅" id="toc-오버피팅" class="nav-link" data-scroll-target="#오버피팅">오버피팅</a>
  <ul class="collapse">
  <li><a href="#오버피팅-예시" id="toc-오버피팅-예시" class="nav-link" data-scroll-target="#오버피팅-예시">오버피팅 예시</a></li>
  <li><a href="#오버피팅이라는-뚜렷한-증거-train-test" id="toc-오버피팅이라는-뚜렷한-증거-train-test" class="nav-link" data-scroll-target="#오버피팅이라는-뚜렷한-증거-train-test">오버피팅이라는 뚜렷한 증거! (train / test)</a></li>
  </ul></li>
  <li><a href="#숙제-해설-및-풀이는-여기참고" id="toc-숙제-해설-및-풀이는-여기참고" class="nav-link" data-scroll-target="#숙제-해설-및-풀이는-여기참고">숙제 (해설 및 풀이는 여기참고)</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>기계학습 특강 (6주차) 10월5일 [딥러닝의 기초 - 깊은신경망(2)– 시벤코정리, 신경망의표현, CPU vs GPU, 확률적경사하강법, 오버피팅]</p>
<section id="imports" class="level2">
<h2 class="anchored" data-anchor-id="imports">imports</h2>
<div class="cell" data-tags="[]" data-execution_count="198">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.data.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code></pre></div>
</div>
<div class="cell" data-execution_count="199">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> graphviz</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gv(s): <span class="cf">return</span> graphviz.Source(<span class="st">'digraph G{ rankdir="LR"'</span><span class="op">+</span>s <span class="op">+</span> <span class="st">'; }'</span>)<span class="op">;</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="3b13c07c-827d-435a-fbf2-c4eb2245cf46" data-execution_count="200">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">#hide</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>graphviz.set_jupyter_format(<span class="st">'png'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="200">
<pre><code>'png'</code></pre>
</div>
</div>
<hr>
</section>
<section id="시벤코정리" class="level2">
<h2 class="anchored" data-anchor-id="시벤코정리">시벤코정리</h2>
<section id="지난시간-논리전개" class="level3">
<h3 class="anchored" data-anchor-id="지난시간-논리전개">지난시간 논리전개</h3>
<p><code>-</code> 아이디어: linear -&gt; relu -&gt; linear (-&gt; sigmoid) 조합으로 꺽은선으로 표현되는 underlying 을 표현할 수 있었다. - 아이디어의 실용성: 실제자료에서 꺾은선으로 표현되는 underlying은 몇개 없을 것 같음. 그건 맞는데 꺾이는 점을 많이 설정하면 얼추 비슷하게는 “근사” 시킬 수 있음. - 아이디어의 확장성: 이러한 논리전개는 X:(n,2)인 경우도 가능했음. (이 경우 꺾인선은 꺾인평면이 된다) - 아이디어에 해당하는 용어정리: 이 구조가 x-&gt;y 로 바로 가는 것이 아니라 x-&gt;(u1-&gt;v1)-&gt;(u2-&gt;v2)=y 의 구조인데 이러한 네트워크를 하나의 은닉층을 포함하는 네트워크라고 표현한다. (이 용어는 이따가..)</p>
</section>
<section id="시벤코정리-1" class="level3">
<h3 class="anchored" data-anchor-id="시벤코정리-1">시벤코정리</h3>
<p><strong>universal approximation thm: (범용근사정리,보편근사정리,시벤코정리)</strong>, 1989</p>
<blockquote class="blockquote">
<p>하나의 은닉층을 가지는 “linear -&gt; sigmoid -&gt; linear” 꼴의 네트워크를 이용하여 세상에 존재하는 모든 (다차원) 연속함수를 원하는 정확도로 근사시킬 수 있다. (계수를 잘 추정한다면)</p>
</blockquote>
<p><code>-</code> 사실 엄청 이해안되는 정리임. 왜냐햐면, - 그렇게 잘 맞추면 1989년에 세상의 모든 문제를 다 풀어야 한거 아니야? - 요즘은 “linear -&gt; sigmoid -&gt; linear” 가 아니라 “linear -&gt; relu -&gt; linear” 조합으로 많이 쓰던데? - 요즘은 하나의 은닉층을 포함하는 네트워크는 잘 안쓰지 않나? 은닉층이 여러개일수록 좋다고 어디서 본 것 같은데?</p>
<p><code>-</code> 약간의 의구심이 있지만 아무튼 universal approximation thm에 따르면 우리는 아래와 같은 무기를 가진 꼴이 된다. - 우리의 무기: <span class="math inline">\({\bf X}: (n,p)\)</span> 꼴의 입력에서 <span class="math inline">\({\bf y}:(n,1)\)</span> 꼴의 출력으로 향하는 맵핑을 “linear -&gt; relu -&gt; linear”와 같은 네트워크를 이용해서 “근사”시킬 수 있다.</p>
<p>(서연 필기) 한 층만 있어도 노드가 충분히 크면 은닉층 한 층으로 충분히 맞출 수 있다.</p>
</section>
</section>
<section id="시벤코정리-proof" class="level2">
<h2 class="anchored" data-anchor-id="시벤코정리-proof">시벤코정리 proof</h2>
<section id="그림으로-보는-증명과정" class="level3">
<h3 class="anchored" data-anchor-id="그림으로-보는-증명과정">그림으로 보는 증명과정</h3>
<p><code>-</code> 데이터</p>
<div class="cell" data-execution_count="201">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.linspace(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>,<span class="dv">200</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span></code></pre></div>
</div>
<p><code>-</code> 아래와 같은 네트워크를 고려하자.</p>
<div class="cell" data-execution_count="202">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>l1 <span class="op">=</span> torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>a1 <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>l2 <span class="op">=</span> torch.nn.Linear(in_features<span class="op">=</span><span class="dv">2</span>,out_features<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<p><code>-</code> 직관1: <span class="math inline">\(l_1\)</span>,<span class="math inline">\(l_2\)</span>의 가중치를 잘 결합하다보면 우연히 아래와 같이 만들 수 있다.</p>
<div class="cell" data-execution_count="203">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>l1.weight.data <span class="op">=</span> torch.tensor([[<span class="op">-</span><span class="fl">5.00</span>],[<span class="fl">5.00</span>]])</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>l1.bias.data <span class="op">=</span> torch.tensor([<span class="op">+</span><span class="fl">10.00</span>,<span class="op">+</span><span class="fl">10.00</span>])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="204">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>l2.weight.data <span class="op">=</span> torch.tensor([[<span class="fl">1.00</span>,<span class="fl">1.00</span>]])</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>l2.bias.data <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="fl">1.00</span>])</span></code></pre></div>
</div>
<div class="cell" data-outputid="a20d86dd-b30e-44ff-ffd9-cf08798298a8" data-execution_count="205">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">3</span>,figsize<span class="op">=</span>(<span class="dv">9</span>,<span class="dv">3</span>))</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].plot(x,l1(x).data)<span class="op">;</span> ax[<span class="dv">0</span>].set_title(<span class="st">'$l_1(x)$'</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].plot(x,a1(l1(x)).data)<span class="op">;</span> ax[<span class="dv">1</span>].set_title(<span class="st">'$(a_1 \circ l_1)(x)$'</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">2</span>].plot(x,l2(a1(l1(x))).data,color<span class="op">=</span><span class="st">'C2'</span>)<span class="op">;</span> ax[<span class="dv">2</span>].set_title(<span class="st">'$(l_2 \circ a_1 \circ \l_1)(x)$'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="205">
<pre><code>Text(0.5, 1.0, '$(l_2 \\circ a_1 \\circ \\l_1)(x)$')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-9-output-2.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 직관2: 아래들도 가능할듯?</p>
<div class="cell" data-outputid="aa209df8-9881-4bf3-ea4f-7c18204f2c3c" data-tags="[]" data-execution_count="206">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>l1.weight.data <span class="op">=</span> torch.tensor([[<span class="op">-</span><span class="fl">5.00</span>],[<span class="fl">5.00</span>]])</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>l1.bias.data <span class="op">=</span> torch.tensor([<span class="op">+</span><span class="fl">0.00</span>,<span class="op">+</span><span class="fl">20.00</span>])</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>l2.weight.data <span class="op">=</span> torch.tensor([[<span class="fl">1.00</span>,<span class="fl">1.00</span>]])</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>l2.bias.data <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="fl">1.00</span>])</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">3</span>,figsize<span class="op">=</span>(<span class="dv">9</span>,<span class="dv">3</span>))</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].plot(x,l1(x).data,<span class="st">'--'</span>,color<span class="op">=</span><span class="st">'C0'</span>)<span class="op">;</span> ax[<span class="dv">0</span>].set_title(<span class="st">'$l_1(x)$'</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].plot(x,a1(l1(x)).data,<span class="st">'--'</span>,color<span class="op">=</span><span class="st">'C0'</span>)<span class="op">;</span> ax[<span class="dv">1</span>].set_title(<span class="st">'$(a_1 \circ l_1)(x)$'</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">2</span>].plot(x,l2(a1(l1(x))).data,<span class="st">'--'</span>,color<span class="op">=</span><span class="st">'C0'</span>)<span class="op">;</span> ax[<span class="dv">2</span>].set_title(<span class="st">'$(l_2 \circ a_1 \circ \l_1)(x)$'</span>)<span class="op">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-10-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>(서연 필기) 밑에 fig 다시 정의 안 해줬잖아. 그러니까 덮어쓴 거라 생각하면 돼</p>
<div class="cell" data-outputid="2bd6c1d3-568b-4424-afd5-b69075ed2d35" data-execution_count="215">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>l1.weight.data <span class="op">=</span> torch.tensor([[<span class="op">-</span><span class="fl">5.00</span>],[<span class="fl">5.00</span>]])</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>l1.bias.data <span class="op">=</span> torch.tensor([<span class="op">+</span><span class="fl">20.00</span>,<span class="op">+</span><span class="fl">0.00</span>])</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>l2.weight.data <span class="op">=</span> torch.tensor([[<span class="fl">2.50</span>,<span class="fl">2.50</span>]])</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>l2.bias.data <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="fl">2.50</span>])</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].plot(x,l1(x).data,<span class="st">'--'</span>,color<span class="op">=</span><span class="st">'C1'</span>)<span class="op">;</span> ax[<span class="dv">0</span>].set_title(<span class="st">'$l_1(x)$'</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].plot(x,a1(l1(x)).data,<span class="st">'--'</span>,color<span class="op">=</span><span class="st">'C1'</span>)<span class="op">;</span> ax[<span class="dv">1</span>].set_title(<span class="st">'$(a_1 \circ l_1)(x)$'</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">2</span>].plot(x,l2(a1(l1(x))).data,<span class="st">'--'</span>,color<span class="op">=</span><span class="st">'C1'</span>)<span class="op">;</span> ax[<span class="dv">2</span>].set_title(<span class="st">'$(l_2 \circ a_1 \circ \l_1)(x)$'</span>)<span class="op">;</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>fig</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="215">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> <code>은닉층의노드수=4</code>로 하고 적당한 가중치를 조정하면 <span class="math inline">\((l_2\circ a_1 \circ l_1)(x)\)</span>의 결과로 주황색선 + 파란색선도 가능할 것 같다. <span class="math inline">\(\to\)</span> 실제로 가능함</p>
<div class="cell" data-execution_count="216">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>l1 <span class="op">=</span> torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>a1 <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>l2 <span class="op">=</span> torch.nn.Linear(in_features<span class="op">=</span><span class="dv">4</span>,out_features<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="217">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>l1.weight.data <span class="op">=</span> torch.tensor([[<span class="op">-</span><span class="fl">5.00</span>],[<span class="fl">5.00</span>],[<span class="op">-</span><span class="fl">5.00</span>],[<span class="fl">5.00</span>]])</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>l1.bias.data <span class="op">=</span> torch.tensor([<span class="fl">0.00</span>, <span class="fl">20.00</span>, <span class="fl">20.00</span>, <span class="dv">0</span>])</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>l2.weight.data <span class="op">=</span> torch.tensor([[<span class="fl">1.00</span>,  <span class="fl">1.00</span>, <span class="fl">2.50</span>,  <span class="fl">2.50</span>]])</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>l2.bias.data <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="fl">1.0</span><span class="op">-</span><span class="fl">2.5</span>])</span></code></pre></div>
</div>
<div class="cell" data-outputid="c3189372-7eb0-408a-e7ea-50e2bd137957" data-execution_count="218">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>plt.plot(l2(a1(l1(x))).data)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 2개의 시그모이드를 우연히 잘 결합하면 아래와 같은 함수 <span class="math inline">\(h\)</span>를 만들 수 있다.</p>
<div class="cell" data-execution_count="219">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> <span class="kw">lambda</span> x: torch.sigmoid(<span class="dv">200</span><span class="op">*</span>(x<span class="op">+</span><span class="fl">0.5</span>))<span class="op">+</span>torch.sigmoid(<span class="op">-</span><span class="dv">200</span><span class="op">*</span>(x<span class="op">-</span><span class="fl">0.5</span>))<span class="op">-</span><span class="fl">1.0</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="b9661d7a-c598-4bec-a00f-0b52940e4fd4" data-execution_count="220">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>plt.plot(x,h(x))</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"$h(x)$"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="220">
<pre><code>Text(0.5, 1.0, '$h(x)$')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-16-output-2.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 위와 같은 함수 <span class="math inline">\(h\)</span>를 활성화함수로 하고 <span class="math inline">\(m\)</span>개의 노드를 가지는 은닉층을 생각해보자. 이러한 은닉층을 사용한다면 전체 네트워크를 아래와 같이 표현할 수 있다.</p>
<p><span class="math inline">\(\underset{(n,1)}{\bf X} \overset{l_1}{\to} \underset{(n,m)}{\boldsymbol u^{(1)}} \overset{h}{\to} \underset{(n,m)}{\boldsymbol v^{(1)}} \overset{l_2}{\to} \underset{(n,1)}{\hat{\boldsymbol y}}\)</span></p>
<p>그리고 위의 네트워크와 동일한 효과를 주는 아래의 네트워크가 항상 존재함.</p>
<p><span class="math inline">\(\underset{(n,1)}{\bf X} \overset{l_1}{\to} \underset{(n,2m)}{\boldsymbol u^{(1)}} \overset{sig}{\to} \underset{(n,2m)}{\boldsymbol v^{(1)}} \overset{l_2}{\to} \underset{(n,1)}{\hat{\boldsymbol y}}\)</span></p>
<p><code>-</code> <span class="math inline">\(h(x)\)</span>를 활성화함수로 가지는 네트워크를 설계하여 보자.</p>
<div class="cell" data-execution_count="221">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyActivation(torch.nn.Module): <span class="co">## 사용자정의 활성화함수를 선언하는 방법</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>() </span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>):</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> h(<span class="bu">input</span>) <span class="co"># activation 의 출력 </span></span></code></pre></div>
</div>
<p>forward 순전파</p>
<p>backward 역전파</p>
<div class="cell" data-execution_count="222">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>a1<span class="op">=</span>MyActivation()</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># a1 = torch.nn.Sigmoid(), a1 = torch.nn.ReLU() 대신에 a1 = MyActivation()</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="1bdbd832-391c-493e-b8c0-a65842b735ec" data-execution_count="223">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>plt.plot(x,a1(x)) </span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><strong>히든레이어가 1개의 노드를 가지는 경우</strong></p>
<div class="cell" data-outputid="ade72678-8b41-476f-a378-77a806465705" data-execution_count="224">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">4</span>,<span class="dv">4</span>,figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">12</span>))</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>        net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">1</span>,<span class="dv">1</span>),</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>            MyActivation(),</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>        ax[i,j].plot(x,net(x).data,<span class="st">'--'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-20-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><strong>히든레이어가 2개의 노드를 가지는 경우</strong></p>
<div class="cell" data-outputid="124a59c4-e94a-4b0d-cb67-1f041dc6a404" data-execution_count="225">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">4</span>,<span class="dv">4</span>,figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">12</span>))</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">1</span>,<span class="dv">2</span>),</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>            MyActivation(),</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">2</span>,<span class="dv">1</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>        ax[i,j].plot(x,net(x).data,<span class="st">'--'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><strong>히든레이어가 3개의 노드를 가지는 경우</strong></p>
<div class="cell" data-outputid="2962c4d5-4c84-456a-aa1e-4246e98b4754" data-execution_count="226">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">4</span>,<span class="dv">4</span>,figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">12</span>))</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">1</span>,<span class="dv">3</span>),</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>            MyActivation(),</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">3</span>,<span class="dv">1</span>)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>        ax[i,j].plot(x,net(x).data,<span class="st">'--'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-22-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><strong>히든레이어가 1024개의 노드를 가지는 경우</strong></p>
<div class="cell" data-outputid="8c4698a7-450b-4cd8-d2d7-196061c58c18" data-execution_count="227">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">4</span>,<span class="dv">4</span>,figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">12</span>))</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>        net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">1</span>,<span class="dv">1024</span>),</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>            MyActivation(),</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">1024</span>,<span class="dv">1</span>)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>        ax[i,j].plot(x,net(x).data,<span class="st">'--'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-23-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="8c4698a7-450b-4cd8-d2d7-196061c58c18" data-execution_count="228">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">4</span>,<span class="dv">4</span>,figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">12</span>))</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>        net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">1</span>,<span class="dv">2048</span>),</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>            MyActivation(),</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">2048</span>,<span class="dv">1</span>)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>        ax[i,j].plot(x,net(x).data,<span class="st">'--'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-24-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="시벤코정리-활용" class="level2">
<h2 class="anchored" data-anchor-id="시벤코정리-활용">시벤코정리 활용</h2>
<p><code>-</code> 아래와 같이 하나의 은닉층을 가지고 있더라도 많은 노드수만 보장되면 매우 충분한 표현력을 가짐</p>
<p><span class="math inline">\(\underset{(n,1)}{\bf X} \overset{l_1}{\to} \underset{(n,m)}{\boldsymbol u^{(1)}} \overset{h}{\to} \underset{(n,m)}{\boldsymbol v^{(1)}} \overset{l_2}{\to} \underset{(n,1)}{\hat{\boldsymbol y}}\)</span></p>
<section id="예제1-sin-exp" class="level3">
<h3 class="anchored" data-anchor-id="예제1-sin-exp">예제1 (sin, exp)</h3>
<div class="cell" data-outputid="c1f59e2b-3422-4349-d69e-e1790b58783a" data-execution_count="229">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.linspace(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>,<span class="dv">200</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>underlying <span class="op">=</span> torch.sin(<span class="dv">2</span><span class="op">*</span>x) <span class="op">+</span> torch.sin(<span class="fl">0.5</span><span class="op">*</span>x) <span class="op">+</span> torch.exp(<span class="op">-</span><span class="fl">0.2</span><span class="op">*</span>x)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>eps <span class="op">=</span> torch.randn(<span class="dv">200</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="op">*</span><span class="fl">0.1</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> underlying <span class="op">+</span> eps </span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>plt.plot(x,y,<span class="st">'o'</span>,alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>plt.plot(x,underlying,lw<span class="op">=</span><span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="230">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> <span class="kw">lambda</span> x: torch.sigmoid(<span class="dv">200</span><span class="op">*</span>(x<span class="op">+</span><span class="fl">0.5</span>))<span class="op">+</span>torch.sigmoid(<span class="op">-</span><span class="dv">200</span><span class="op">*</span>(x<span class="op">-</span><span class="fl">0.5</span>))<span class="op">-</span><span class="fl">1.0</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyActivation(torch.nn.Module): <span class="co">## 사용자정의 활성화함수를 선언하는 방법</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>() </span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>):</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> h(<span class="bu">input</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="231">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>net<span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">1</span>,<span class="dv">2048</span>),</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    MyActivation(),</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">2048</span>,<span class="dv">1</span>)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters()) </span></code></pre></div>
</div>
<p>mseloss쓴 거 확인</p>
<div class="cell" data-execution_count="232">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200</span>):</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x) </span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div class="cell" data-outputid="dbaeb77c-188d-49ef-c45d-c9bc46af77f3" data-execution_count="233">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>plt.plot(x,y,<span class="st">'o'</span>,alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>plt.plot(x,underlying,lw<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>plt.plot(x,net(x).data,<span class="st">'--'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-29-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="예제2-스펙높아도-취업x" class="level3">
<h3 class="anchored" data-anchor-id="예제2-스펙높아도-취업x">예제2 (스펙높아도 취업X)</h3>
<div class="cell" data-outputid="edc1bdba-f6b8-48a7-b7f1-6443b4ccd4e8" data-execution_count="234">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>pd.read_csv(<span class="st">'https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex0.csv'</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="234">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>x</th>
      <th>underlying</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.000000</td>
      <td>0.000045</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.998999</td>
      <td>0.000046</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.997999</td>
      <td>0.000047</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.996998</td>
      <td>0.000047</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.995998</td>
      <td>0.000048</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>0.995998</td>
      <td>0.505002</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1996</th>
      <td>0.996998</td>
      <td>0.503752</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1997</th>
      <td>0.997999</td>
      <td>0.502501</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1998</th>
      <td>0.998999</td>
      <td>0.501251</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>1.000000</td>
      <td>0.500000</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>2000 rows × 3 columns</p>
</div>
</div>
</div>
<div class="cell" data-outputid="beb0e9d8-bf53-4a56-cbf9-537228041c25" data-execution_count="235">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(df.x).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>).<span class="bu">float</span>()</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor(df.y).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>).<span class="bu">float</span>()</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>plt.plot(x,y,<span class="st">'o'</span>,alpha<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>plt.plot(df.x,df.underlying,lw<span class="op">=</span><span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-31-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="236">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> <span class="kw">lambda</span> x: torch.sigmoid(<span class="dv">200</span><span class="op">*</span>(x<span class="op">+</span><span class="fl">0.5</span>))<span class="op">+</span>torch.sigmoid(<span class="op">-</span><span class="dv">200</span><span class="op">*</span>(x<span class="op">-</span><span class="fl">0.5</span>))<span class="op">-</span><span class="fl">1.0</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyActivation(torch.nn.Module): <span class="co">## 사용자정의 활성화함수를 선언하는 방법</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>() </span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>):</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> h(<span class="bu">input</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="237">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>net<span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">1</span>,<span class="dv">2048</span>),</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    MyActivation(),</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">2048</span>,<span class="dv">1</span>),</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    torch.nn.Sigmoid()</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.BCELoss()</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters()) </span></code></pre></div>
</div>
<p>BCEloss쓴 거 확인</p>
<div class="cell" data-execution_count="238">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x) </span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div class="cell" data-outputid="58780ca6-72c5-4bf2-f287-edc93a08f277" data-execution_count="239">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>plt.plot(x,y,<span class="st">'o'</span>,alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>plt.plot(df.x,df.underlying,lw<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>plt.plot(x,net(x).data,<span class="st">'--'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-35-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="예제3-mnist-data-with-dnn" class="level3">
<h3 class="anchored" data-anchor-id="예제3-mnist-data-with-dnn">예제3 (MNIST data with DNN)</h3>
<section id="예비학습" class="level4">
<h4 class="anchored" data-anchor-id="예비학습"><code>#</code> 예비학습</h4>
<p><strong>(예비학습1) Path</strong></p>
<div class="cell" data-outputid="a1d0d536-3ca0-4ef4-95bf-b14238bc6787" data-execution_count="240">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.MNIST) </span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>path</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="240">
<pre><code>Path('/home/csy/.fastai/data/mnist_png')</code></pre>
</div>
</div>
<ul>
<li>path 도 오브젝트임</li>
<li>path 도 정보+기능이 있음</li>
</ul>
<p><code>-</code> path의 정보</p>
<div class="cell" data-outputid="37061b00-eeec-4b2c-d9d2-ccfcce0f19cc" data-execution_count="241">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>path._str <span class="co"># 숨겨놓았네?</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="241">
<pre><code>'/home/csy/.fastai/data/mnist_png'</code></pre>
</div>
</div>
<p><code>-</code> 기능1</p>
<p>path는 객체,</p>
<div class="cell" data-outputid="36ff6080-4dc4-43e8-e2dd-be1177e3c09d" data-execution_count="242">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>path.ls()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="242">
<pre><code>(#2) [Path('/home/csy/.fastai/data/mnist_png/training'),Path('/home/csy/.fastai/data/mnist_png/testing')]</code></pre>
</div>
</div>
<p>path object의 list 보여주는 역할</p>
<p><code>-</code> 기능2</p>
<div class="cell" data-outputid="d72de685-c448-4ec5-caef-31bfede29bb6" data-execution_count="243">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>path<span class="op">/</span><span class="st">'training'</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="243">
<pre><code>Path('/home/csy/.fastai/data/mnist_png/training')</code></pre>
</div>
</div>
<div class="cell" data-outputid="a4dca518-7ecd-4a19-cc81-6f57c471f8ef" data-execution_count="244">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>path<span class="op">/</span><span class="st">'testing'</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="244">
<pre><code>Path('/home/csy/.fastai/data/mnist_png/testing')</code></pre>
</div>
</div>
<p><code>-</code> 기능1과 기능2의 결합</p>
<div class="cell" data-outputid="1b3d08f5-e9b5-4190-d90a-87199c710dbe" data-execution_count="245">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>(path<span class="op">/</span><span class="st">'training/3'</span>).ls()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="245">
<pre><code>(#6131) [Path('/home/csy/.fastai/data/mnist_png/training/3/35407.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/26671.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/16171.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/15346.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/34710.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/48873.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/28796.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/15651.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/6894.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/37927.png')...]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="246">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> ls <span class="op">/</span>home<span class="op">/</span>csy<span class="op">/</span>.fastai<span class="op">/</span>data<span class="op">/</span>mnist_png</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>testing  training</code></pre>
</div>
</div>
<div class="cell" data-execution_count="247">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> ls <span class="op">/</span>home<span class="op">/</span>csy<span class="op">/</span>.fastai<span class="op">/</span>data<span class="op">/</span>mnist_png<span class="op">/</span>training</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0  1  2  3  4  5  6  7  8  9</code></pre>
</div>
</div>
<div class="cell" data-execution_count="248">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> ls <span class="op">/</span>home<span class="op">/</span>csy<span class="op">/</span>.fastai<span class="op">/</span>data<span class="op">/</span>mnist_png<span class="op">/</span>testing</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0  1  2  3  4  5  6  7  8  9</code></pre>
</div>
</div>
<ul>
<li>‘/home/cgb4/.fastai/data/mnist_png/training/3/37912.png’ 이 파일을 더블클릭하면 이미지가 보인단 말임</li>
</ul>
<p><strong>(예비학습2)</strong> plt.imshow</p>
<div class="cell" data-outputid="f1d433d5-e7bc-4989-e5f8-c326767e8921" data-execution_count="249">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>imgtsr <span class="op">=</span> torch.tensor([[<span class="fl">1.0</span>,<span class="dv">2</span>],[<span class="fl">2.0</span>,<span class="fl">4.0</span>]])</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>imgtsr</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="249">
<pre><code>tensor([[1., 2.],
        [2., 4.]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="74169e85-ab82-4256-cdf8-4e7642022e7a" data-execution_count="250">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>plt.imshow(imgtsr,cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="250">
<pre><code>&lt;matplotlib.colorbar.Colorbar at 0x7fa03ee40f10&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-46-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="f1d433d5-e7bc-4989-e5f8-c326767e8921" data-execution_count="251">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>imgtsr <span class="op">=</span> torch.tensor([<span class="fl">0.1</span>,<span class="fl">0.2</span>,<span class="fl">0.3</span>,<span class="fl">0.4</span>]).reshape(<span class="dv">2</span>,<span class="dv">2</span>)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>imgtsr</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="251">
<pre><code>tensor([[0.1000, 0.2000],
        [0.3000, 0.4000]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="74169e85-ab82-4256-cdf8-4e7642022e7a" data-execution_count="252">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>plt.imshow(imgtsr,cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="252">
<pre><code>&lt;matplotlib.colorbar.Colorbar at 0x7fa03ebb70a0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-48-output-2.png" class="img-fluid"></p>
</div>
</div>
<p><strong>(예비학습3)</strong> torchvision</p>
<p><code>-</code> ’/home/cgb4/.fastai/data/mnist_png/training/3/37912.png’의 이미지파일을 torchvision.io.read_image 를 이용하여 텐서로 만듬</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>ls <span class="st">'/home/csy/.fastai/data/mnist_png/training/3'</span></span></code></pre></div>
<div class="cell" data-outputid="5247d76f-8e12-4283-903c-4db9c96dd78e" data-execution_count="253">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>imgtsr <span class="op">=</span> torchvision.io.read_image(<span class="st">'/home/csy/.fastai/data/mnist_png/training/3/37912.png'</span>)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>imgtsr</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="253">
<pre><code>tensor([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66, 138,
          149, 180, 138, 138,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,  22, 162, 161, 228, 252, 252,
          253, 252, 252, 252, 252,  74,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0, 116, 253, 252, 252, 252, 189,
          184, 110, 119, 252, 252,  32,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,  74, 161, 160,  77,  45,   4,
            0,   0,  70, 252, 210,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
            0,  22, 205, 252,  32,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
            0, 162, 253, 245,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           36, 219, 252, 139,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          222, 252, 202,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43,
          253, 252,  89,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 240,
          253, 157,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7, 160, 253,
          231,  42,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 142, 252, 252,
           42,  30,  78, 161,  36,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 184, 252, 252,
          185, 228, 252, 252, 168,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 184, 252, 252,
          253, 252, 252, 252, 116,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 101, 179, 252,
          253, 252, 252, 210,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  22,
          255, 253, 215,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  34,  89, 244,
          253, 223,  98,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0, 116, 123, 142, 234, 252, 252,
          184,  67,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0, 230, 253, 252, 252, 252, 168,
            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0, 126, 253, 252, 168,  43,   2,
            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]],
       dtype=torch.uint8)</code></pre>
</div>
</div>
<p><code>-</code> 이 텐서는 (1,28,28)의 shape을 가짐</p>
<div class="cell" data-outputid="4d697c1b-b86c-4f17-bb46-f53642c7661e" data-execution_count="254">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>imgtsr.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="254">
<pre><code>torch.Size([1, 28, 28])</code></pre>
</div>
</div>
<p><code>-</code> imgtsr를 plt.imshow 로 시각화</p>
<div class="cell" data-outputid="8e1aec5a-18c0-49cb-add4-a9adc2c2ef95" data-execution_count="255">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>plt.imshow(imgtsr.reshape(<span class="dv">28</span>,<span class="dv">28</span>),cmap<span class="op">=</span><span class="st">'gray'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="255">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7fa03e223370&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-51-output-2.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>진짜 숫자3이 있음</li>
</ul>
</section>
<section id="데이터정리" class="level4">
<h4 class="anchored" data-anchor-id="데이터정리"><code>#</code> 데이터정리</h4>
<p><code>-</code> 데이터정리</p>
<div class="cell" data-outputid="1d71f1ae-79e6-4e6a-d221-7f6a29d70ee5" data-execution_count="264">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>threes_fnames <span class="op">=</span> (path<span class="op">/</span><span class="st">'training/3'</span>).ls()</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>sevens_fnames <span class="op">=</span> (path<span class="op">/</span><span class="st">'training/7'</span>).ls()</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(threes_fnames),<span class="bu">len</span>(sevens_fnames)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="264">
<pre><code>(6131, 6265)</code></pre>
</div>
</div>
<ul>
<li>6131, 1, 28, 28</li>
<li>6265, 1, 28, 28</li>
</ul>
<div class="cell" data-execution_count="272">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>torch.stack([torchvision.io.read_image(<span class="bu">str</span>(threes_fnames[i])) <span class="cf">for</span> i <span class="kw">in</span> [<span class="dv">0</span>,<span class="dv">1</span>]]).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="272">
<pre><code>torch.Size([2, 1, 28, 28])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="285">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>torch.stack([torchvision.io.read_image(<span class="bu">str</span>(fn)) <span class="cf">for</span> fn <span class="kw">in</span> threes_fnames]).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="285">
<pre><code>torch.Size([6131, 1, 28, 28])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="287">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>torch.stack([torchvision.io.read_image(<span class="bu">str</span>(fn)) <span class="cf">for</span> fn <span class="kw">in</span> sevens_fnames]).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="287">
<pre><code>torch.Size([6265, 1, 28, 28])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="273">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>X3 <span class="op">=</span> torch.stack([torchvision.io.read_image(<span class="bu">str</span>(threes_fnames[i])) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">6131</span>)])</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>X7 <span class="op">=</span> torch.stack([torchvision.io.read_image(<span class="bu">str</span>(sevens_fnames[i])) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">6265</span>)])</span></code></pre></div>
</div>
<div class="cell" data-outputid="12dc8093-16fe-489b-86b7-17ec3bf65599" data-execution_count="274">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>X3.shape,X7.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="274">
<pre><code>(torch.Size([6131, 1, 28, 28]), torch.Size([6265, 1, 28, 28]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="275">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(threes_fnames) <span class="op">+</span> <span class="bu">len</span>(sevens_fnames)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="275">
<pre><code>12396</code></pre>
</div>
</div>
<div class="cell" data-outputid="099299b4-7f5b-4b25-e969-12a291ea1501" data-execution_count="276">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>X<span class="op">=</span>torch.concat([X3,X7])</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>X.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="276">
<pre><code>torch.Size([12396, 1, 28, 28])</code></pre>
</div>
</div>
<div class="cell" data-outputid="10d3be69-8f86-45b1-835f-9ad18a5a4654" data-execution_count="289">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>Xnp <span class="op">=</span> X.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span><span class="op">*</span><span class="dv">28</span><span class="op">*</span><span class="dv">28</span>).<span class="bu">float</span>() <span class="co"># Xnp = X.reshape(-1,784).float()</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>Xnp.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="289">
<pre><code>torch.Size([12396, 784])</code></pre>
</div>
</div>
<p><span class="math inline">\(\star\)</span> float형으로 바꿔주기</p>
<div class="cell" data-outputid="355c26b4-f724-4716-c2ef-64c013f80305" data-execution_count="278">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor([<span class="fl">0.0</span>]<span class="op">*</span><span class="dv">6131</span> <span class="op">+</span> [<span class="fl">1.0</span>]<span class="op">*</span><span class="dv">6265</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) </span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>y.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="278">
<pre><code>torch.Size([12396, 1])</code></pre>
</div>
</div>
<div class="cell" data-outputid="355c26b4-f724-4716-c2ef-64c013f80305" data-execution_count="288">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor([<span class="fl">0.0</span>]<span class="op">*</span><span class="bu">len</span>(threes_fnames) <span class="op">+</span> [<span class="fl">1.0</span>]<span class="op">*</span><span class="bu">len</span>(sevens_fnames)).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) </span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>y.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="288">
<pre><code>torch.Size([12396, 1])</code></pre>
</div>
</div>
<div class="cell" data-outputid="113ec0e0-c624-4dca-a6ec-7fea108c9203" data-execution_count="279">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>plt.plot(y,<span class="st">'o'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-63-output-1.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>“y=0”은 숫자3을 의미, “y=1”은 숫자7을 의미</li>
<li>숫자3은 6131개, 숫자7은 6265개 있음</li>
</ul>
</section>
<section id="학습" class="level4">
<h4 class="anchored" data-anchor-id="학습"><code>#</code> 학습</h4>
<p><code>-</code> 네트워크의 설계</p>
<div class="cell" data-execution_count="298">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span><span class="op">*</span><span class="dv">28</span><span class="op">*</span><span class="dv">28</span>,out_features<span class="op">=</span><span class="dv">30</span>),</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(in_features<span class="op">=</span><span class="dv">30</span>,out_features<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>    torch.nn.Sigmoid()</span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<ul>
<li><span class="math inline">\(\underset{(n,784)}{\bf X} \overset{l_1}{\to} \underset{(n,30)}{\boldsymbol u^{(1)}} \overset{a_1}{\to} \underset{(n,30)}{\boldsymbol v^{(1)}} \overset{l_1}{\to} \underset{(n,1)}{\boldsymbol u^{(2)}} \overset{a_2}{\to} \underset{(n,1)}{\boldsymbol v^{(2)}}=\underset{(n,1)}{\hat{\boldsymbol y}}\)</span></li>
</ul>
<div class="cell" data-execution_count="299">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.BCELoss()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="300">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span></code></pre></div>
</div>
<div class="cell" data-outputid="b649bbc3-8e29-41e5-c8f2-4ec2ca4769da" data-execution_count="301">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>plt.plot(y,<span class="st">'o'</span>)</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>plt.plot(net(Xnp).data,<span class="st">'.'</span>,alpha<span class="op">=</span><span class="fl">0.2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-67-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="302">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200</span>):</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1</span></span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(Xnp) </span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2</span></span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb97-6"><a href="#cb97-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb97-7"><a href="#cb97-7" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb97-8"><a href="#cb97-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb97-9"><a href="#cb97-9" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb97-10"><a href="#cb97-10" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div class="cell" data-outputid="b649bbc3-8e29-41e5-c8f2-4ec2ca4769da" data-execution_count="303">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>plt.plot(y,<span class="st">'o'</span>)</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>plt.plot(net(Xnp).data,<span class="st">'.'</span>,alpha<span class="op">=</span><span class="fl">0.2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-69-output-1.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>대부분 잘 적합되었음</li>
</ul>
</section>
</section>
</section>
<section id="신경망의-표현-boldsymbol-x-to-hatboldsymbol-y-로-가는-과정을-그림으로-표현" class="level2">
<h2 class="anchored" data-anchor-id="신경망의-표현-boldsymbol-x-to-hatboldsymbol-y-로-가는-과정을-그림으로-표현">신경망의 표현 (<span class="math inline">\({\boldsymbol x} \to \hat{\boldsymbol y}\)</span> 로 가는 과정을 그림으로 표현)</h2>
<section id="예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y" class="level3">
<h3 class="anchored" data-anchor-id="예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y">예제1: <span class="math inline">\(\underset{(n,1)}{\bf X} \overset{l_1}{\to} \underset{(n,1)}{\boldsymbol u^{(1)}} \overset{sig}{\to} \underset{(n,1)}{\boldsymbol v^{(1)}} =\underset{(n,1)}{\hat{\boldsymbol y}}\)</span></h3>
<p><code>-</code> 모든 observation과 가중치를 명시한 버전</p>
<p><strong>(표현1)</strong></p>
<div class="cell" data-outputid="80207fa5-164f-4af2-f810-5c3170f4d5ec" data-execution_count="304">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse</span></span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a>gv(<span class="st">''' </span></span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a><span class="st">    "1" -&gt; "ŵ₀ + xₙ*ŵ₁,    bias=False"[label="* ŵ₀"]</span></span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a><span class="st">    "xₙ" -&gt; "ŵ₀ + xₙ*ŵ₁,    bias=False"[label="* ŵ₁"]</span></span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a><span class="st">    "ŵ₀ + xₙ*ŵ₁,    bias=False" -&gt; "ŷₙ"[label="sigmoid"]</span></span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a><span class="st">    "." -&gt; "...................................."[label="* ŵ₀"]</span></span>
<span id="cb99-8"><a href="#cb99-8" aria-hidden="true" tabindex="-1"></a><span class="st">    ".." -&gt; "...................................."[label="* ŵ₁"]</span></span>
<span id="cb99-9"><a href="#cb99-9" aria-hidden="true" tabindex="-1"></a><span class="st">    "...................................." -&gt; "..."[label=" "]</span></span>
<span id="cb99-10"><a href="#cb99-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-11"><a href="#cb99-11" aria-hidden="true" tabindex="-1"></a><span class="st">    "1 " -&gt; "ŵ₀ + x₂*ŵ₁,    bias=False"[label="* ŵ₀"]</span></span>
<span id="cb99-12"><a href="#cb99-12" aria-hidden="true" tabindex="-1"></a><span class="st">    "x₂" -&gt; "ŵ₀ + x₂*ŵ₁,    bias=False"[label="* ŵ₁"]</span></span>
<span id="cb99-13"><a href="#cb99-13" aria-hidden="true" tabindex="-1"></a><span class="st">    "ŵ₀ + x₂*ŵ₁,    bias=False" -&gt; "ŷ₂"[label="sigmoid"]</span></span>
<span id="cb99-14"><a href="#cb99-14" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb99-15"><a href="#cb99-15" aria-hidden="true" tabindex="-1"></a><span class="st">    "1  " -&gt; "ŵ₀ + x₁*ŵ₁,    bias=False"[label="* ŵ₀"]</span></span>
<span id="cb99-16"><a href="#cb99-16" aria-hidden="true" tabindex="-1"></a><span class="st">    "x₁" -&gt; "ŵ₀ + x₁*ŵ₁,    bias=False"[label="* ŵ₁"]</span></span>
<span id="cb99-17"><a href="#cb99-17" aria-hidden="true" tabindex="-1"></a><span class="st">    "ŵ₀ + x₁*ŵ₁,    bias=False" -&gt; "ŷ₁"[label="sigmoid"]</span></span>
<span id="cb99-18"><a href="#cb99-18" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="304">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-70-output-1.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>단점: 똑같은 그림의 반복이 너무 많음</li>
</ul>
<p><code>-</code> observation 반복을 생략한 버전들</p>
<p><strong>(표현2)</strong> 모든 <span class="math inline">\(i\)</span>에 대하여 아래의 그림을 반복한다고 하면 (표현1)과 같다.</p>
<div class="cell" data-outputid="c9d561a0-a813-45e0-ff50-4458de4dd948" data-execution_count="305">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse</span></span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>gv(<span class="st">''' </span></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a><span class="st">    "1" -&gt; "ŵ₀ + xᵢ*ŵ₁,    bias=False"[label="* ŵ₀"]</span></span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a><span class="st">    "xᵢ" -&gt; "ŵ₀ + xᵢ*ŵ₁,    bias=False"[label="* ŵ₁"]</span></span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a><span class="st">    "ŵ₀ + xᵢ*ŵ₁,    bias=False" -&gt; "ŷᵢ"[label="sigmoid"]</span></span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="305">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-71-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><strong>(표현3)</strong> 그런데 (표현2)에서 아래와 같이 <span class="math inline">\(x_i\)</span>, <span class="math inline">\(y_i\)</span> 대신에 간단히 <span class="math inline">\(x\)</span>, <span class="math inline">\(y\)</span>로 쓰는 경우도 많음</p>
<div class="cell" data-outputid="9e63245f-1f02-4124-dbf2-1b91ca77354c" data-execution_count="306">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse</span></span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>gv(<span class="st">''' </span></span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a><span class="st">    "1" -&gt; "ŵ₀ + x*ŵ₁,    bias=False"[label="* ŵ₀"]</span></span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a><span class="st">    "x" -&gt; "ŵ₀ + x*ŵ₁,    bias=False"[label="* ŵ₁"]</span></span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a><span class="st">    "ŵ₀ + x*ŵ₁,    bias=False" -&gt; "ŷ"[label="sigmoid"]</span></span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="306">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-72-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 1을 생략한 버전들</p>
<p><strong>(표현4)</strong> bais=False 대신에 bias=True를 주면 1을 생략할 수 있음</p>
<div class="cell" data-outputid="375d210c-03eb-4cd6-bc2c-7560281f7483" data-execution_count="307">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse</span></span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>gv(<span class="st">'''</span></span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a><span class="st">"x" -&gt; "x*ŵ₁,    bias=True"[label="*ŵ₁"] ;</span></span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a><span class="st">"x*ŵ₁,    bias=True" -&gt; "ŷ"[label="sigmoid"] '''</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="307">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-73-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><strong>(표현4의 수정)</strong> <span class="math inline">\(\hat{w}_1\)</span>대신에 <span class="math inline">\(\hat{w}\)</span>를 쓰는 것이 더 자연스러움</p>
<div class="cell" data-outputid="13d8efe1-5430-4208-b1df-d87c4a86c0dd" data-execution_count="308">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>gv(<span class="st">'''</span></span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a><span class="st">"x" -&gt; "x*ŵ,    bias=True"[label="*ŵ"] ;</span></span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a><span class="st">"x*ŵ,    bias=True" -&gt; "ŷ"[label="sigmoid"] '''</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="308">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-74-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><strong>(표현5)</strong> 선형변환의 결과는 아래와 같이 <span class="math inline">\(u\)</span>로 표현하기도 한다.</p>
<div class="cell" data-outputid="41921d7d-3616-40a4-fa5f-1b7f9d35648d" data-execution_count="309">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse</span></span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>gv(<span class="st">'''</span></span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a><span class="st">"x" -&gt; "u";</span></span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a><span class="st">"u" -&gt; "y"[label="sigmoid"] '''</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="309">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-75-output-1.png" class="img-fluid"></p>
</div>
</div>
<blockquote class="blockquote">
<p>다이어그램은 그리는 사람의 취향에 따라 그리는 방법이 조금씩 다릅니다. 즉 교재마다 달라요.</p>
</blockquote>
</section>
<section id="예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y" class="level3">
<h3 class="anchored" data-anchor-id="예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y">예제2: <span class="math inline">\(\underset{(n,1)}{\bf X} \overset{l_1}{\to} \underset{(n,2)}{\boldsymbol u^{(1)}} \overset{relu}{\to} \underset{(n,2)}{\boldsymbol v^{(1)}} \overset{l_2}{\to} \underset{(n,1)}{\boldsymbol u^{(2)}} \overset{sig}{\to} \underset{(n,1)}{\boldsymbol v^{(2)}} =\underset{(n,1)}{\hat{\boldsymbol y}}\)</span></h3>
<p><strong>참고: 코드로 표현</strong></p>
<div class="sourceCode" id="cb105"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>torch.nn.Sequential(</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(in_features<span class="op">=</span><span class="dv">2</span>,out_features<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Sigmoid()</span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><code>-</code> 이해를 위해서 10월4일 강의노트에서 다루었던 아래의 상황을 고려하자.</p>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAi8AAAEYCAYAAACUQxbMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABHAUlEQVR4nO3dd3xUVf7/8dcnlRIIJaGX0FR6ERBXVFQUdFUUcVdRQRFZ1rZ+d3V11/25ruu6a1ldsYOgYMGOomBBEMQCEpBeQ++EEloIaZ/fH3fQMSQkJDNzZiaf5+NxH5m5c+fed8gh+cy9554jqooxxhhjTKSIcR3AGGOMMeZkWPFijDHGmIhixYsxxhhjIooVL8YYY4yJKFa8GGOMMSaiWPFijDHGmIhixYsxFSAiM0Vk+Els/zsR+V8ZtksUkZUiklqhgMYYE4WseDEmREQkAfgb8Hhp26rqUWAccF+wcxljTKSx4sWYExCRuADubgCwUlW3lnH7N4GhIpIYwAzGGBPxrHgphYi0EpG9ItLN97yRiGSKSB+3yUywiMgGEblXRBYDh0Wkt4h8JyJZIrKopJ+9iDwoIq/7PU8TEfUrgC4GZvm9/lsRWS8iNX3PLxaRHccuFanqFmAf0Cso36gxxkQoK15KoaprgXuB10WkGvAKMF5VZzoNZoLtWuDXQEvgI+BhoA5wN/B+OfuidARWHXuiqm8D3wGjRKQuMBYYrqqZfu9ZAXQu13dgjDFRyoqXMlDVMUAGMBdoCNzvNpEJgVGquhm4HpiqqlNVtVBVpwHpwCXl2Gct4GCRdbcB5wMzgY9V9ZMirx/0vc8YY4yPFS9lNwboADzj60xpottm39fmwNW+S0ZZIpIF9MYrYk/WPqCG/wpVzQLexWtb/y3mPTWArHIcyxhjopYVL2UgIknA//BO6z8oInXcJjIhcGy69c3Aa6pay2+prqr/KeY9h4Fqfs8bFHl9MXCK/woR6QIMAyYCo4rZZ1tgUTnyG2NM1LLipWyeBtJVdTgwBXjRcR4TOq8Dl4lIPxGJFZEqItJHRJoUs+1C4BwRaSYiycBfirw+FTj32BMRqeLb/1+Bm4DGInKr3+uN8frZzAnod2SMMRHOipdSiMgAoD/we9+qPwLdROQ6d6lMqPj6vQzAKzAy8c7E3EMx/3d8/WHexjvDMh8o2n/lY+A0EWnke/5vYLOqvuC7FHk98LCItPG9Phivc7hdpjTGGD+iqqVvZYwJCBEZAbRT1btK2S4R73LROaq6KxTZjDEmUljxYowxxpiIYpeNjDHGGBNRrHgxxhhjTESx4sUYY4wxESWQk86VWUpKiqalpbk4dKU1f/783apaniHtw4K1mdCK9PZijIluToqXtLQ00tPTXRy60hKRja4zVIS1mdCK9PZijIluAblsJCLjRGSXiCwNxP5M5CqtLYhnlIhkiMjiY7N1G2OMMWUVqD4vr+IN5GbMq5y4LVwMtPEtI4AXQpDJGGNMFAlI8aKqXwN7A7EvU36qyv++XM3KHQdcZiitLQwAJqhnDlBLRMozyaEJkHfTN7M164jrGMYYU2Yhu9tIREaISLqIpGdmZobqsJWKKuw8cJSPF21zHeVEGvPzjM0AW3zrjmNtJvjW7z7Mve8vZvx3G1xHMcaYMgtZh11VHQ2MBujevbsN6xtg+4/kkVw1nkeu7OA6SsBYmwm+0V+vJT42huFnt3AdxRhjyszGeYkCz85YwyVPz2bXgRxEBBFxHelEtgJN/Z438a0zDtx90ak8N7gb9WpUcR3FGGPKzIqXCPfSrLU88cVqeraoQ92kRNdxymIyMMR311EvYL+qbncdqrKqm5RI33b1XccwxpiTEqhbpScC3wOnisgWEbk5EPs1Jzb2m/X8+9OVXNqpIY8P6kRsjPszLsW1BREZKSIjfZtMBdYBGcAY4FZHUSu1Hftz+M1L37N8m7vO3cYYU14B6fOiqtcGYj+m7D5etI1/frKc/u0b8NRvuxAXGx4n0UprC+pNY35biOKYErw4ay0LNu6jRhUn41QaY0yF2G+uCHXOKanc2qcVd/U9hfgwKVxMZNh1MIeJP2ziyq6NaVqnmus4xhhz0uyvXoSZtTqTnLwCkqvG8+f+p5EQZz9Cc3Jenr2evIJCbjuvtesoxhhTLvaXL4J8tHArN77yA8/MWOM6iolQew/n8vqcjVzeuRFpKdVdxzHGmHKxy0YRYuqS7fzxnUWc0aIOt5/XxnUcE6GqJcRyb//TOKt1XddRjDGm3Kx4iQBfLNvBnRN/pGvTWowd2oOqCbGuI5kIVSU+lqG/SnMdwxhjKsQuG4W5nLwCHvhoGR0aJ/PKTT2onmj1pimf1+ZsZOIPm/Bu+DLGmMhlfwnDXJX4WF4ffgapNRKpUSXedRwToQ7m5PH4Zys5o2Vdru3ZzHUcY4ypEDvzEqa+y9jN/75cjarSul4SyVWtcDHlN+H7jRzIyefO862/lDEm8lnxEobmrtvDzePTmbpkO9m5Ba7jmAiXnZvP2G/W0+fUVDo2SXYdxxhjKsyKlzAzf+M+hr06j0a1qvDG8F7Wx8VU2BtzNrH3cC532FkXY0yUsOIljCzanMWN434gtUYib97Si9QaETHRoglzbeonceOv0ji9eW3XUYwxJiDsY30Y2bwvm5Qaibwx/Azq16ziOo6JEn1OrUefU+u5jmGMMQFjZ17CQE6e16/l0k6N+Oyus2lUq6rjRCYaHM0v4PmZGWRl57qOYowxAWXFi2Nrdh7kvCdmMmPlTgAS42wAOhMY783fwmOfrWLJ1v2uoxhjTEDZZSOH1mYe4toxc4kRaJGS5DqOiSJ5BYW8MHMtXZrWonfrFNdxjDEmoOzMiyMbdh9m8Jg5gPLmLWfQwibJMwE06cetbNl3hDsvaI2IuI5jjDEBZcWLA3sOHWXwmDnk5hfyxvBetK5Xw3UkE0XyCwp5/qsMOjSuyXnWUdcYE4XsspEDdaonMLBbEy7u2IBTG1jhYgLrQE4+rVKTuLp7UzvrYoyJSla8hNDOAzkcyS0gLaU6d/c71XUcE6XqVE9g7I09XMcwxpigsctGIbLrYA7XjpnDsPHzyC8odB3HRKlFm7PYuOew6xjGGBNUVryEwJ5DR7luzFy2Z+Xw6FWdiIu1f3YTeIWFyr3vL2b4+HRU1XUcY4wJGvsrGmT7Dudy3ctz2bwvm3E39qBHWh3XkUyU+nLFTlbuOMjIc1tZXxdjTFSzPi9B9tjnq1i3+zBjh3bnzFZ1XccxUUpVeWZGBs3qVGNAl0au4xhjTFBZ8RJk9/+6LQO7NbYzLiaoZq7OZMnW/fxnYEe7LGmMiXr2Wy4IDh/N55+fLOfw0XySEuOscDFBt3bXIVqkVGdgtyauoxhjTNDZmZcAy87N56ZX5zF/4z7OO7UevdvY0Owm+Iaf3ZIhZ6aREGefR4wx0c9+0wVQTl4Bt0xIJ33DXp76bRcrXExIrNh+AMAKF2NMpWG/7QIkJ6+AEa/N57u1e3ji6s5c3tk6TZrg+2H9Xi5+ejafLN7mOooxxoSMFS8BsuvAUVbtOMCjAztZvwMTMs/MWENKUgIXnFbfdRRjjAkZ6/NSQfkFhcTGCM3qVmP6n/qQlGj/pCY0fty0j9lrdnPfxadRNSHWdRxjjAkZO/NSAfkFhfzhrYX8a8oKACtcTEg9MyODWtXiub5Xc9dRjDEmpKx4KaeCQuXudxcxZcl26tes4jqOqWT2Hs5lwaZ93HxWCyuajTGVjv3WK4djc8h8uHAb9/Q7lVvOaek6kqlk6lRP4Jt7z8cmATDGVEZWvJTD3ycv4735W7irbxtuO6+16zimktl/JI+kxDg742KMqbQCctlIRPqLyCoRyRCR+wKxz3B2VusU7jy/NX+4oI3rKGGptPYgIjeKSKaILPQtw13kjFR/+3ApA1/4zmaONsZUWhUuXkQkFngOuBhoB1wrIu0qut9wo6o/DQbWv0MD/njRqTZzbzFOoj28rapdfMvLIQ0ZwdZmHuKTxds4s2Vda3/GmEorEGdeegIZqrpOVXOBt4ABAdhv2FBVHv1sFZc+8w1Ltux3HSfcRX17cOm5rzJIjIth+NktXEcxxhhnAlG8NAY2+z3f4lv3CyIyQkTSRSQ9MzMzAIcNnae+XMOLs9Zybc+mdGhc03WccFem9gBcJSKLReQ9EWla3I4iuc0Ew6Y92Xy0cBvXndGclKRE13GMMcaZkN0qraqjVbW7qnZPTU0N1WEr7Jnpaxg1fQ2/7d6Uhy7vYKfqA+NjIE1VOwHTgPHFbRSpbSZY3vxhE7Exwu/s7jZjTCUXiNsVtgL+n5yb+NZFvO8ydvPfaasZ2K0x/x7YkZgYK1zKoNT2oKp7/J6+DDwWglwR7+6LTuHiDg2oZ+MKGWMquUAUL/OANiLSAu+P1DXA4ADs17kzW9XlmWu7cknHhla4lF2p7UFEGqrqdt/Ty4EVoY0YeQoKlbjYGDo3reU6ijHGOFfhy0aqmg/cDnyO90foHVVdVtH9uvTOvM1k7DqIiHBZ50bEWuFSZiW1BxF5SEQu9212p4gsE5FFwJ3AjW7SRoadB3I4+9EZzFpt/X6MMQYCNEidqk4FpgZiX65N/GETf/lgCb/p3oTHBnV2HSciFdceVPUBv8d/Af4S6lyR6qVZ69h58Cgt6lZ3HcUYY8KCzW3k5930zfx10hL6nJrKP6/o4DqOMew+dJQ3f9jIFV0a06xuNddxjDEmLFjx4jPpxy38+f3F9G6dwovXn05iXKzrSMYwZvY6cvMLue28Vq6jGGMcEpGZNhr5z6x4wRuE7v35WzmjRR1G39CdKvFWuBj39h/J4/XvN3Jpp0a0TE1yHccYE6FE5FURedh1jkCq9DO7qSoiwpgh3SlUpWqCFS4mPNSsEsfLQ3tQv6YNSGeMMf4q9ZmX6St2cu2YORzIyaNqQizVbZZeE0ZEhDNb1bWzLpWAiKiItPZ7HnWflE3pROQeEXm/yLpRIvK072lzEflWRA6KyBcikuK33bsiskNE9ovI1yLS3rd+BHAd8GcROSQiH4fsGwqiSlu8zFqdye9fX0B2bgE2Oa8JNy/NWsuDk5dRWGiN05hK5HWgv4jUAhCROLyxsib4Xh8M3ATUAxKAu/3e+ynQxvfaAuAN8EYq9z1+TFWTVPWy4H8bwVcpi5dvM3YzYkI6reslMWFYT5KrxruOZMxPDh3N54VZa9myL9sGRzSmEvEN3vk1cLVvVX9gt6rO9z1/RVVXq+oR4B2gi997x6nqQVU9CjwIdBaR5JCFD7FKV7zM27CX4ePTSatbndeHn0GtagmuIxnzC699v5Gs7DzuOL+N6yjGmNAbD1zve3w98Jrfazv8HmcDSQAiEisi/xGRtSJyANjg2yaFKFXpipfUpER6tKjDG7ecQZ3qVriY8JKdm8/Ls9dxzimpNhVA5ZIN+A/k08BVEOPch0AnEekAXIrv8k8pBgMDgL5AMpDmW3/s1G3UXX+uNMXL5r3ZqCppKdWZMKwnKUl2B4cJP2/O3cSew7nceX7r0jc20WQhMNj3Cbo/cK7jPMYRVc0B3gPeBH5Q1U1leFsN4CiwB68IfqTI6zuBqJqOvlIUL0u37ueSUbN5evoa11GMOaHzTqvHPf1OpXtaHddRTGj9AbgMyMK7M+RDl2GMc+OBjvzyktGJTAA24k2GuxyYU+T1sUA7EckSkQ8DFdKlqL83ePm2A1w/di41q8Qz6PQmruMYc0KtUpO47Tw761LZqGo60N51DhM2NgFHgJ9um1bVPv4bqOqrwKu+x4fwLhv5m+C37Rr8OvdGg6g+87J650GuHzuXqvGxTLylF01q29wwJjzl5hfylw8Ws3rnQddRjDEOiUgM8EfgLVU94DpPuIra4uVofgE3vTKPuBjhzVt62aR2Jqx9sGALE3/YzLasI66jGGMcEZHqwAHgQuDvjuOEtai9bJQYF8u/ruxAk9pVaZFS3XUcY0qUX1DI8zPX0qlJMueekuo6jjHGEVU9jO/2Z3NiUXfmZfPebD5dsh2APqfWo3W9Go4TGXNiHy3cxqa92dxxfhtEbFA6Y4wpTVSdedmadYRrx8whO7eA3m1SqFHFRs414a2gUHnuqwzaNqxJ37b1XMeJKikpKZqWluY6RqUxf/783aoaklOHIjIObwyUXaraoZjXBXgauARvDJ0bVXXBifZp7SX0KtJmoqZ42bE/h8Fj5rD/SB5vDu9lhYuJCLn5hfTr0IBuzWrbWZcAS0tLIz093XWMSkNENobwcK8Cz+J3R00RF+PN89MGOAN4wfe1RNZeQq8ibSYqipddB73CZc+hXF67uScdm0TtdA4mylRNiOXe/qe5jmFMRFHVr0Uk7QSbDAAmqKoCc0Sklog09M0dZKJAVPR5mbp4OzsO5PDqTT3o2qy26zjGlMn3a/cwY+VO1KY1Nz7PLXyOT9Z94jpGNGgMbPZ7vsW37hdEZISIpItIemZmZsjCVVShFrI4czEvLXqJJZlLAMjMzmTSmknM2zGPzOzI+V7KKyrOvNx4Vgv6tqtv47iYiKGqPDxlOdm5BZx7Sj1i7YpRpaeqrN+/nhcXvUheQR5XtrnSdaSop6qjgdEA3bt3D/tPEYfzDjNx5UTeW/0eWw9tBaBlrZZ0pCNLdy/lge8e+GnblKoptK3Tlj+e/kda146+gS8jtnjZn53HHW/9yH39T6Ndo5pWuJiIMmPlLpZtO8DjgzoRG2OViwER4ZHej3Ao9xB//+7vxMXEcVmry1zHilRbgaZ+z5v41kWsnPwcBnw4gJ3ZO+nZoCe3dbmNsxqfRZ0q3lQivZv0ZurAqWw+uJn1+9ezfM9ylu9ZTmKsN4/fRxkf8emGT+nXvB99m/elRkJk34kbkcXLgZw8hoyby4rtB9l1MId21HQdyZgyU1VGzcigSe2qXNH1uDPZphJasWcFizIXMbDNQP533v+4ffrt/O3bvxEXE8fFLS52HS8STQZuF5G38Drq7o/U/i6qiohQJa4KN3e8mfZ129MptdNx28XHxNO0RlOa1mjKrxr96rjXC7WQjfs38sB3D/DwnIe5oPkFDG0/lPZ1I3NWiojr83LoaD43jvuBZdsO8Px13ehzqt1eaiLL7DW7WbQ5i1v7tCY+NuL+C5ogeH7h8zzz4zPkFeZRJa4Ko84fRdd6Xdl8cHPpb66ERGQi8D1wqohsEZGbRWSkiIz0bTIVWAdkAGOAWx1FrZAj+Ue4fcbtfL3lawCuPe3aYguXsriyzZVMHTiVNy55g6tOuYrZW2bzwLcPRGyfu4g685Kdm8+wV+axaMt+nhvclb7t6ruOZMxJO5JXQLdmtbjqdDvrYmDl3pXM3DKT27rcRvV4bzTwavHVGHPhGOJjvSEfjuQfoWpcVZcxw4qqXlvK6wrcFqI4QVGohdz/zf3M3jKbC5tfGJB9igidUjvRKbUTd3a9kx2HdyAiHMw9yH/T/8vIziNpUL1BQI4VbBH1sS9GhOqJsfzvt13o36Gh6zjGlEu/9g344NazSIyLdR3FhIHRi0eTFJ/E4LaDf7H+WOGyau8qLvngEmZvme0innFk7JKxTNs4jT91/xNXtL4i4PtPSkj6qSPvkt1LmLJuCgMnD2TKuikRcTYmIoqXnLwCDuTkUSU+lnE39uCyzo1cRzKmXKYt38nR/ALXMUyYyNiXwbSN0xjcdjA1E4rvu9egegNSq6Zy11d38f2270Oc0Liwau8qnl/0PP3S+jGk3ZCgH+9XjX7F+5e/T8vkltw3+z7+9u3fOFpwNOjHrYiwL15y8wu59Y0F3PDyXPILCm0UUhOx5m/cyy0T0nl7nvVjMJ6jBUfp0aAHN7S9ocRtkhOTGX3haJonN+fOGXcyb8e8ECY0LkzfNJ3khGTuP+P+kP3Na1azGeP7j+fWzrcyee1kHp/3eEiOW15hXbzkFRRy+5sLmLFyF7/t0Yw469xoItio6RnUqZ7AoNObuI5iwkT7lPaM6zeOWlVqnXC7WlVqMebCMTROasxt029j1d5VoQlonLi1y618fOXH1K4S2kFXY2Ni+X2X3zPqvFGM7Dyy9Dc4FLbVQH5BIXe9tZAvlu/kH5e3Z/AZzVxHMqbcFm3OYtbqTIaf3YJqCRHVT94EybSN09iXs6/M29etWpeX+73MwDYDaZHcIojJjCv5hfms278OwOk4LOc1O4+UqinkFeTx8JyHfxoQL5yEbfHyn09XMmXJdv7267YM/VWa6zjGVMizX2WQXDWeIWemuY5iwsDmg5u5Z9Y9jF0y9qTel1I1hft63kdCbAJZOVl2BibKTN80nSs/upJlu5e5jgLAlkNbmLp+KiOnjSQrJ8t1nF8I2+LlxrPSePiKDgw/u6XrKMZUSE5eATv25zDsrBYkJdpZF+PdSRIrsQxpX/7OmP/vu//HsM+HWQETRd5Y8QYNqzfktDrhMVlri+QWPHv+s2w7tI07v7qTnPwc15F+ElbFS2GhMunHLRQWKk1qV+P6Xs1dRzKmwqrExzL59rP4fZ9WrqOYMLD90HY+WvsRV7a5knrVyj/I5r097qVqXFVu+eIW1uxbE8CExoVlu5fx464fGXzaYGJjwmcYhW71u/Hvs//Nwl0L+eecf4bNbdRhU7yoKg9MXsr/vb2IL5bvcB3HmIDYeSCHrOxcRISEuLD572YcGrd0HAA3d7i5QvtpUqMJ4/qNIy4mjuFfDP+pr4SJTJMyJpEYmxiWE3JelHYRIzuPZObmmezM3uk6DlDB4kVErhaRZSJSKCLdy7sfVeWhT5bz+pxN/O6clvRrHxkj/JniiUh/EVklIhkicl8xryeKyNu+1+eKSJqDmCHxyNQVXPTU1+TmF7qOYsKAqrL/6H4GtBpAw6SKD7TZrGYzXu73MoLwj+/+ETafis3JKSgs4MuNX3J+0/PDdsLE33X6HR9c/kHYjMBb0QvwS4GBwEvl3YGq8p9PV/LKtxu46aw07rv4NBvLJYKJSCzwHHAhsAWYJyKTVXW532Y3A/tUtbWIXAM8Cvw29GmDa/3uw3y8aBu3nN3SzroYwBue/bFzH6OgMHADFbZMbsnYfmNJik+y350RKjYmlvcvf58j+UdcRylRbEws9avXp1ALmbJuCv3T+v80CrQLFSpeVHUFUKH/MBv2ZPPqdxu4vlczHri0nf3ni3w9gQxVXQfgm9V1AOBfvAwAHvQ9fg94VkREy/ix8UhuAf3+9/Vx64ec2ZzhZ7dkz6GjDHju2+Nev7VPawaf0YzNe7O5ZvQcgF98Ur2n/6lc2bUJK3cc4KZX5vle//n9D17ejv4dGrJg0z5+//r8415//OrOnHtKKt+s2c3/vbOQnNwCEuJirNP5CYhIU2ACUB9QYLSqPl1kmz7AR8B636oPVPWhEMYMiH05+9h/dD9pyWkB79PQqpbXn6qgsICnf3yaa069hkZJNhJ5JKlbta7rCGUyf+d8/vrNX9l8cDO3dnE332XIbn0QkRHACIBmzX4es6VFSnU+vqM3rVPtU0OUaAz4DyG7BW9K+mK3UdV8EdkP1AV2+29UUpsRgdObHz94U+Na3sR1cbEx9GxR57jXGyZXAbwOtGe2+vkXxbFWV7+m93pSYhxnt0nxe93bop7v9VpV4znPbzbzY802JSnB+1ojgb5tvUlDz2xVl9QaicdlMT/JB/6kqgtEpAYwX0SmFTlTBzBbVS91kC9gXln2Cq8tf41pg6aRUjWl9DeUw9ZDW3lv9XtM2zCNV/u/Sv3qNnltuMstyOWPM//IDe1u4IyGRX9Vhp8eDXrw65a/ZsziMVzQ7AJOrXOqmyCqesIF+BLv8lDRZYDfNjOB7qXt69hy+umnqwktIF3L+POpyAIMAl72e34D8GyRbZYCTfyerwVSTrRfazOhFar2UnTBO8NyYZF1fYBPTnZf4dRm9h3Zpz1f76n3zLwn6MdavGuxnvHGGXrpB5fqrsO7gn68Y1y1mUAtrtrLt1u+1Q6vdtCZm2Y6OX55ZOVk6dkTz9YhU4doYWFhufdTkTZT6oV4Ve2rqh2KWT6qcOVkotFWoKnf8ya+dcVuIyJxQDKwJyTpTNjyddzuCswt5uUzRWSRiHwqIu1PsI8RIpIuIumZmZnBinrSXl/xOtn52dzS6ZagH6tjakde6PsCO7N3MvyL4ew5Yv+1wtnMLTOpElslIs66HJOcmMwfuv2BBbsWMGX9FCcZrBehCbR5QBsRaSEiCcA1wOQi20wGhvoeDwJm+KpwU0mJSBLwPnCXqh4o8vICoLmqdgaeAT4saT+qOlpVu6tq99TU1KDlPRkHcw/y5oo36dusL21qtwnJMbvW68pzFzzHvpx9bDywMSTHNCdPVZm1eRa9GvaiSlwV13FOypVtruTiFheTWtXN/7MK9XkRkSvxfpmkAlNEZKGq9ivtffPnz98tIv7/o1Io0t8hTEVyzpCM+KdeH5bbgc+BWGCcqi4TkYfwThFOBsYCr4lIBrAXr8A5IWszQVc0Z8hGiBSReLzC5Q1V/aDo6/7FjKpOFZHnRSRFVSPh35VFmYvILcxlRKcRIT1ujwY9+Oyqz6gWXw3w5s2Ji7ERnsNJRlYG2w5vC8kZuUCLkRgeO+cxZ8ev6N1Gk4BJ5XjfL0o1EUlX1XKPExMqlrNsVHUqMLXIugf8HucAV5/kPq3NBJGrnOL10h8LrFDVJ0vYpgGwU1VVRHrinTGOmGshvRv3ZvrV00lOTA75sY8VLu+seodJayYx+qLRYTuOSGWUnZ9Nt3rdOKvRWa6jlNvB3IOMXzaea067Jmgd0Ytjl42MMS6dhdep+3wRWehbLhGRkSIy0rfNIGCpiCwCRgHXRMplxsxsr9+Ni8LFX/1q9Vm5byUjvxzJ4bzDTrOYn3VO7cz4i8cHZMBCV/bm7OXlJS8zevHokB7XihdjjDOq+o2qiqp2UtUuvmWqqr6oqi/6tnlWVduramdV7aWq37nOXRbZedkM+ngQT84v9oRSSJ3b9FyeOOcJlu1exq1f3kp2XrbrSJVeoRZGxc+hec3mXNnmSt5d/S5bDm4J2XHDpXgJbclWfpYzfETK92g5K6n317zP3py99GnSx3UUAC5ofgH/Oec/LMxcyB0z7iC/MN91pEpt5d6VnPXWWXy79fgBNSPNyE4jiSGGFxe9GLJjhkXvLVWNiF+cljN8RMr3aDkrp6MFR3ll6Sv0aNCDbvW7uY7zk/5p/ckvzGfPkT3WedexH7b/QH5hPqfUPsV1lAqrX70+vzn1N0xcOZHfd/k9jZMaB/2Y1nqNMSbAJq2ZROaRTP599r9dRznOpS1/Hqg4Y18GzWo2IyE2wWGiymnujrm0SG5BarXwuKW/ooa2H8qOwztCdkYvXC4bGWNMVFBVJmVMoktqF3o26Ok6Ton25uxlyKdDuHvW3eQV5rmOU6kUFBawYOcCetTv4TpKwDSo3oCnznuK5jVDM8qC8+JFRPqLyCoRyRCR+xwcf5yI7BKRpX7r6ojINBFZ4/ta27deRGSUL+tiEenm956hvu3XiMjQ4o5VwZxNReQrEVkuIstE5A/hmjWYXLcXX4awbzPWXtwREV7p9wqPnP1IWM/XVqdKHW7vejtfbf6Ke7++1/rAhFBGVgbZ+dl0rd/VdZSA23RgE9M2Tgv+gco7r0AgFrxBzNYCLYEEYBHQLsQZzgG6AUv91j0G3Od7fB/wqO/xJcCneHP59QLm+tbXAdb5vtb2Pa4d4JwNgW6+xzWA1UC7cMwaze0lUtqMtRc3c9XkF+RrfkF+yI9bEeOXjtcOr3bQe2bdU6Hs2NxGZbbr8C59demruuPQjpAdM1T+POvP2vP1npqVk1XqthVpM67PvPQEMlR1narmAm8BA0IZQFW/xhvl1d8AYLzv8XjgCr/1E3z/7nOAWiLSEOgHTFPVvaq6D5gG9A9wzu2qusD3+CCwAm925rDLGkTO2wtERpux9uLGJ+s+4YqPrmBX9i7XUcpsSPsh3NXtLj5d/ynvrH7HdZxKIbVaKkPbD43KWb9v7ngz2fnZvLv63aAex3Xx0hjY7Pd8i2+da/VVdbvv8Q7gWAsrKW9Ivw/55QR2YZ01wMI5e9j+HCpxewmpgsICXl7yMlXiqjib76W8bu54M0/2eZJBpwxyHaVSmL1lNntzin7+iQ6n1D6FXg17MXHFRPIKgteXynXxEvZ8p7bCZjTPE01gF25ZK6tw+jlYewmdzzd8zoYDGxjRaURY93UpyYXNLyQ+Jp49R/bw8pKXj11+NAG2L2cft06/lQ/WHDeNV9S4od0N7Dqyi883fh60Y7guXrYCTf2eN/Gtc22n75Q5vq/HzgGXlDck30cJE9iFZdYgCefsYfdzsPYSOoVayJglY2hdqzUXNLvAdZwK+WTdJzy94Gkem/eYFTBBsDhzMeBNDRCtejfuTds6bYN6+dR18TIPaCMiLUQkAW924cmOM4GX4dhdFUOBj/zWD/HdmdEL2O87Bf85cJGI1PbdvXGRb13AiJQ4gV3YZQ2icG0vEGY/B2svoTV7y2wysjK4peMtxIjrX6sVM6TdEK5vez2vr3idp+Y/ZQVMgC3KXESsxNK+bnvXUYImRmKY+OuJDOswLHgHKW9P30AteHc5rMa7i+R+B8efCGwH8vCu598M1AWmA2uAL4E6vm0FeM6XdQnQ3W8/w4AM33JTEHL2xjvFvxhY6FsuCces0dxeIqXNWHsJ7d0j+QX5+uWGLyPuTqOSFBYW6j+//6d2eLWDjlowqkzvwe42KpNhnw3TqydfHZJjhYP1WetLfK0ibUa89xtjTHTp3r27pqenu44RsQq1kIe+f4gFuxYw8dcTqR5f/YTbi8h8Ve0eongBF4r2UlBYwJkTz2RAqwHc3+v+oB4rHExcOZH//PAfplw5hSY1mhz3ekXaTGSf3zTGGIdUlVu/vJX3Vr/nOkrAxUgMD5z5AK9d/BrV46tjH3QrLkZieOfSdxjSfojrKCFxftPziSGGiSsnBnzfVrwYY0w5fbftO2Zvne06RtDESAzJicnkFebx56//zIRlE1xHimgiQlpyGk1rNC194yhQv3p9+jbvy6SMSWTnZQd031a8GGOcKm3KBxFJFJG3fa/P9Y1b45yq8tLil2hQvQEDWoV8rMSQEoQCLeDx9MeD8in6pPOU3mZuFJFMEVnoW4a7yFnUpDWTmLJuiusYITW47WAO5h7kk3WfBHS/VrwYY5wRkVi8jsIX401fcK2ItCuy2c3APlVtDTwFPBralMWbt2MeP+76kWEdhhEfG+86TlDFxcTx6DmPcl7T83hk7iNBHz31RMrYZgDeVtUuvuXlkIYswSvLXuGz9Z+5jhFSXVK70LZO24AXbVa8GGNcKsuUD/5TGrwHXCBhMArcS4tfIrVqKgPbDHQdJSTiY+J54twnOLvx2Tz0/UOs2LPCVZSwmCbkZB3IPcD6/evpmNrRdZSQEhEeO+cxXuj7QkD3GxfQvRljzMkpbvqBM0raRlXzRWQ/3i3fu4vuTERGACMAmjVrFoy8P7m1y61k5WSRGJsY1OOEk4TYBJ467ymmb5xO27ptXcUoS5sBuEpEzsEbWuH/VHVz0Q1C2V6WZnqT0HdMqVzFC0BaclrA92lnXowxUUNVR6tqd1Xtnpoa3PmFTq9/Ohc0j+zRdMsjMTaRS1pe4jpGaT4G0lS1E95kouOL2yiU7WXx7sUIQoeUDkE9TmVhxYsxxqWyTD/w0zYiEgckA3tCkq4YS3cv5eE5D5OVk+UqQmVXaptR1T2qetT39GXg9BBlK9GOwztomdySGgk1XEeJCla8GGNcKsuUD/5TGgwCZqjDQUdeWvQSn234LOo76YaxUtvMsfm7fC4HnHXQOebBXz3I25e97TpG1LA+L8YYZ3x9WG7Hmy8pFhinqstE5CG8ocMn483R9JqIZAB78f5YObFy70pmbpnJbV1uK3XEWRMcZWwzd4rI5UA+Xpu50VlgP5Wpf1SwWfFijHFKVacCU4use8DvcQ5wdahzFWf04tEkxScxuO1g11EqtTK0mb8Afwl1rpLM2DSDSWsm8Y+z/kGdKnVcx4kKdtnIGGPKIGNfBtM2TmNw28HUTKjpOo6JID/s+IG5O+ZauwkgK16MKQcRmXkyo3aKyO9E5H/lPNZ/ReT35XmvCZzq8dUZdMogbmh7g+soJsIsyVxC2zptiYuxix2BYsWLMUHm61T4N+Dxcu7iCeCvvv0YRxomNeTvZ/6dWlVquY5iIkhuQS4r9q6gc2pn11GiihUvxhTDd0tuoAwAVqpq0VuAy0RVtwMr8e6aMA68seINlu1e5jqGiUCr9q4irzCv0o2sG2xWvJSRiEwVkf/6PX9LRMa5zGQCS0Q2iMi9IrIYOCwivUXkOxHJEpFFItKnhPc9KCKv+z1PExH1K4AuBmad4Lh1RGSLiFzme57km3BuiN9mM4FfV+w7NOWx+eBmHp/3OFPWV64J9Uxg5Gs+XVK7VMqRdYPJLsCV3TBgsYhMARriza9h5wGjz7V4RUIhsBi4AfgMuAB4X0ROU9XMk9xnR+DTkl5U1b0iMgyYICKdgH8BC1V1gt9mK4CrTvK4JgDGLhlLrMRyU/ubXEcxEahrva68dslrrmNEHSteykhVd/g6TY4HqgJXqOpBx7FM4I1S1c0ici8w1XdLJsA0EUkHLqGEocZPoBZwwraiql+IyLvAdKAO0KnIJgd9+zEhtP3Qdj5a+xGD2gwitVpwh4830UdVyS3MtfFdgsAuG5VARK4TkUO+5din5o/xBkVaparfOIxngufY5G3Ngat9l4yyRCQL6I131u1k7QN+GhNcRF70a1t/9dtuNNABeFVViw5/XwPIKsexTQWMW+pdGR7WYZjjJCYSbT64mTPfPJPpm6a7jhJ1rHgpgaq+oapJvuVi3+p/4Z2+bygi1zqMZ4Ln2LDzm4HXVLWW31JdVf9TzHsOA9X8njco8vpi4JSfDqA60q9tPQIgIrF4xcsE4FYRaV1kH22BReX/tkx5pFRN4brTrqNhUnlqVlPZzd85n7zCPNJqprmOEnWseCkj39TqNwFD8OZZeUZEGrtNZYLodeAyEeknIrEiUkVE+ohIk2K2XQicIyLNRCSZ40f2nAqcW8rx/opXOA3Du6V6gq+gOeZcTtBvxgTH7zr/jrt73O06holQC3YtIDkxmRbJLVxHiTpWvJSBiNTE+0R8u6puVdXZePOtvCIi4jadCQZV3Yx3i/NfgUy8MzH3UMz/GVWdBryNd4ZlPvBJkU0+Bk4TkUbFHUtETgf+CAxR1QLgUbxC5j7f6w2BdsCHFf2+TNnsObKHGZtm4HD+RxMFftz1I13rdSVG7E9toFmH3TJQ1QNAWpF197pJY4JFVdOKPJ9LCWdMVLVPkee3Abf5rRrj91qeiDwM/Bm4q5h9zQdq+z0vAM7y2+Ru4BFVzS3bd2Iqavzy8YxfNp5PrviEpjWbuo5jItDuI7vZeGAjV7WxmwSDwYoXY0JAVUdX4L1/CmQWc2JZOVm8tfIt+qX1s8LFlFusxPKHbn/g3KalXTE25WHFizHG+HltxWscyT/CiI4jXEcxEax2ldoM71jm6c/MSbILccYY43Mg9wBvrniTvs360rp20Ru+jCkbVWXm5pkczLWhwILFihdjjBMi8riIrBSRxSIySURqlbDdBhFZIiILfQMFBs3mg5tJTkxmRCc762LKLyMrgztm3MG0jdNcR4laTi4bpaSkaFpamotDV1rz58/fraoRO0SotZnQClF7mQb8RVXzReRRvFvMS+oIf56q7g5yHtrXbc+UK6cQGxNb+sbGlOD7bd8DcGbDMx0niV4BKV58ExReCuxS1Q6lbZ+WlkZ6elA/QJkiRGRjiI5zwrbgu7X8abxh9rOBG1V1QWn7tTYTWqFoL6r6hd/TOcCgYB/zRFbsWUHLWi1tKHdTYV9v+ZoWyS1scMMgCtRlo1eB/gHal4lsr3LitnAx0Ma3jABeCEEmE/6GUfIgfAp8ISLzReSE13NEZISIpItIemZm2efPzM7LZuSXI3ng2wfKntiYYmTlZJG+M50Lml3gOkpUC0jxoqpfA3vLvYOjhwIRw4SBMrSFAcAE9cwBavkGYTvZA5UzoQklEflSRJYWswzw2+Z+IB94o4Td9FbVbniF722+0a6LpaqjVbW7qnZPTS37Va/3Vr/H3py9XHPaNWV+jzHFmbNjDgVaYMVLkIWsw26Jn4iyNsFzPSH9lVBFMW415ufJDwG2+NYdp8Q2s/gdePkCKMgLalBTcaraV1U7FLN8BCAiN+JdZrxOSxjOVlW3+r7uAiYBPQOZ8WjBUV5d9io9G/Ska72ugdy1qYT6Ne/HB5d/QPu67V1HiWohK15K/ESUVB/qt4dP7oIfXw9VHBMBSmwziTVh63xY8q67cKbCRKQ/3qjDl6tqdgnbVBeRGsceAxcBSwOZ44M1H5B5JNPuMDIBISK0qd0GmzkmuNzfKh2XCL95DVqeBx/d7n2qNtFsK+A/bGkT37qyO6UfNOgEXz8BhQWBzGZC61mgBjDNdxv0iwAi0khEpvq2qQ98IyKLgB+AKar6WSBD/LD9B7qkdqFng4Ce0DGV0MdrP+b+b+7nSP4R11GiXniMsBtfBa55E978DUz6HVSrA637uk5lgmMycLuIvAWcAexX1e0ntQcROOceeOcGWPoBdLo6GDlNkKlqsaPAqeo2vLvRUNV1QOdg5niyz5McyD1gn5RNhb2z6h0O5h6kSmwV11GiXkDOvIjIROB74FQR2SIiN5/0ThKqweC34YzfQ9MzAhHLOFBcWxCRkSIy0rfJVGAdkIE3eeGt5TrQaZdCvXbw9eNQWBiI6KaSySvMY1/OPkSE5MRk13FMhFuXtY6FmQsZ0HqAFcIhEJAzL6p6bSD2Q0J16P+I9zj3MGxfBM1/FZBdm9AorS34OmXedqJtyiQmBi5+FCTGe2zMSZq6bir/mvsv3rr0LVomt3Qdx0S4CcsnkBibyOWtLncdpVII39/60/4OEwZAxpeuk5hw1eIcSOvtOoWJQAWFBby85GWa12xOi5otXMcxEW7PkT18vPZjLmt1GXWr1nUdp1II3+Ll/Psh9VR46zpYN9N1GhOujh6EqffAqoD24TRR7vMNn7PhwAZGdBphp/hNhcXFxDGwzUBuaHeD6yiVRvgWL1Vrww0fQZ1W8OY1sOEb14lMOIqrCmumwcxHbOA6UyaFWsjoxaNpXau1DSRmAiI5MZn7e91vlx9DKHyLF4DqdWHIR1CrGUy+AwryXScy4SY2Ds7+k9c/ao3N4GpKtyhzEWv3r2VEpxHESHj/CjThTVUZtWAUC3aWOj2bCbDw/5+blApDJ8Pgd70/VMYU1fkaSG4Gsx61sy+mVF3rdeWDyz/gouYXuY5iItznGz5nzJIxLNhlxUuohX/xAlCjAaS09v4wzfgXbPvRdSITTmLjofddsDUd1n3lOo0JY3m+KSXa1G5DbEys4zQmkq3NWss/vv8HnVI6cWP7G13HqXQio3g55sg+WPQWvHYl7FjiOo0JJ12vh56/g9pprpOYMKWq3Pj5jTyZ/qTrKCbCbTu0jdum30ZibCJPnPsEcTF2VSDUIqt4qVbHu4QUX827jXrXCteJTLiIS4RLHoM61mHOFO+7bd+xOHMxzWo2cx3FRLjxy8Zz4OgBnr3gWRomNXQdp1KKrOIFoE4LGPoxxMTD+Mshc7XrRCacbF8MX/3bdQoTZlSVlxa/RIPqDRjQaoDrOCYC5eTnsH7/egDu7n43b/76TTqkdHCcqvKKvOIFoG4rr4CJjYc9a1ynMeFk/SyY9R/YNNd1EhNG5u2Yx4+7fmRYh2HEx8a7jmMqSET6i8gqEckQkfuKeT1RRN72vT5XRNLKe6wdh3cwevFoLp10KXfOuJOCwgLiY+NJSy73Lk0ARO6FutRT4I75EF/Ve56fC3EJbjMZ97oPg2+egq8fg+vfd53GhIlxS8eRWjWVgW0Guo5iKkhEYoHngAuBLcA8EZmsqsv9NrsZ2KeqrUXkGuBR4Lcnc5xP1n3C2CVjycjKAKBng56M7DzSOnqHicgtXuDnwmX5R/DlgzBkMtRq6jSScSyhOpx5O0z/B2ydD41Pd53IhIGHznqIjQc2khib6DqKqbieQIZvxnF8M9QPAPyLlwHAg77H7wHPioj45lYrk7iYOOpVq8elLS/louYX0bSm/W0JJ5F52aioWs3g8B4Yfykc2OY6jXGt5y1QpRbMetx1EhMm6lWrR48GPVzHMIHRGNjs93yLb12x26hqPrAfOG7SIREZISLpIpKemZn5i9f6p/XnpQtf4uaON1vhEoaio3hp1BVu+MBXwFwGB3e4TmRcSqwB59wD9dtDYaHrNMaYMKWqo1W1u6p2T01NdR3HnIToKF4AmnSH69+DA9u9u5ByDrhOZFz61e1wwf+DmOhp4sYYALYC/qdCmvjWFbuNiMQBycCekKQzIRHZfV6KatYLrnvHm4U6sYbrNMY1VVj9GdRtDSltXKcxITZ//vzdIrLRb1UKsNtVnpMQqTmbh+i484A2ItICr0i5BhhcZJvJwFDge2AQMKO0/i7z588/ICJFb1+N1J9FuCqas9y/mKOreAFI6+0tALszvIHtqtVxm8m4cWQfvD8cTukPg8a6TmNCTFV/cR1ARNJVtburPGVlOU9MVfNF5HbgcyAWGKeqy0TkISBdVScDY4HXRCQD2ItX4JTme1Xt77/CfhaBVTSniHxW3n1FX/FyTP5RbxTepFRvZuoqya4TmVCrVgd63AzfjoI+99nZF2OihKpOBaYWWfeA3+Mc4OqT3Gf/0rcygVSRf/Po7RAQlwi//i/sWAqvD4KjB10nMi6ceQfEVYHZ/3WdxBhjTIBEb/ECcGp/uPoVb7yPN34DuYddJzKhlpTqDVy3+B3Yu851GuPWaNcByshyho9I+R4rXc7oLl4A2l4GV42BzXNg1qOu0xgXzrrTmxNr/xbXSYxDqhoRv+AtZ/iIlO+xMuaM3j4v/jpc5Q1a1uxM10mMCzUawO3pIOI6iTHGmACI/jMvx7S+ABKqeeO/fPkPr0OvqTxEvJ/5hm9dJzHGGFNBlad4OWbdTPjmSXj3JijIc53GhNKMf8JrV9gUEpVMaTMQh+D440Rkl4gs9VtXR0Smicga39favvUiIqN8WReLSDe/9wz1bb9GRIYGIWdTEflKRJaLyDIR+UO4Zg02azNlzumuzahqyJfTTz9dnZo7WvXvNVXfvkE1P89tlhDBG//Ayc87EEtA2sze9aoP1lad+ueK7yvKRXp7ObbgjQOyFmgJJACLgHYhznAO0A1Y6rfuMeA+3+P7gEd9jy8BPgUE6AXM9a2vA6zzfa3te1w7wDkbAt18j2sAq4F24ZjV2kx4/BxctpnKd+YFvIn7+j3izUY96XdQWOA6kQmF2mnQ+VqY/yoc3Ok6jQmNn2YgVtVc4NgMxCGjql/jDZTmbwAw3vd4PHCF3/oJ6pkD1BKRhkA/YJqq7lXVfcA0IKDjkqjqdlVd4Ht8EFiBN8Fh2GUNMmszZc/prM1UzuIF4MzboO+DsOl7OGR/yCqNs/8IBbnw/TOuk5jQKMsMxC7UV9Xtvsc7gPq+xyXlDen3ISJpQFdgbrhnDYJwzR/WP4dQt5nKcbdRSXr/H5x+E1St5c2Do2oT+UW7uq2gwyDYttD7edsdSMYxVVUROeG8O6EkIknA+8BdqnpA/P6PhFvWyircfg4u2oz9pT5WuEy921s0bNqDCZbL/gdDP7bCpXIoywzELuz0nS7H93WXb31JeUPyfYhIPN4foTdU9YNwzhpE4Zo/LH8OrtqMFS/HxFeD9LHw2V+sgIl2CdW9wiV7r3frvIlmP81ALCIJeBP0TXacCX6e9Rjf14/81g/x3ZXRC9jvO/3+OXCRiNT23blxkW9dwIj3cXkssEJVnwznrEFmbaaMnLaZUPagPrY4v9uoOIWFqp/e592F9Pn93vMoQoTfPRLwNnNot+q/GqvOeCSw+40Skd5e/Be8OxxW491Bcr+D408EtgN5eNfybwbqAtOBNcCXQB3ftgI858u6BOjut59hQIZvuSkIOXsDCiwGFvqWS8Ixq7WZ8Pg5uGwz4ntTSHXv3l3T09NDftxSqe/y0byX4dx74by/uk4UMCIyXyNgyvSSBKXNvHUdrJ8N/7fEZh0vItLbizEmutllI38icPHj0HMENOpW+vYmsp1zDxzdDz9ExLQgxhhjfKx4KSomBi553JuRGiBztds8JngadYE2/eD75+DoQddpjDHGlFFAihfXQykHzYZv4fkz4LtnXSeJKKW1BxG5UUQyRWShbxnuIicA5/4ZjuyDtTOcRTDGGHNyKjzOi4jE4nXAuRCvY9E8EZmsqssrum/nmp4BbS+DL+6H2AQ4Y4TrRGHvJNrD26p6e8gDFtWkO9z5I9Rp6TqJMcaYMgrEIHU/DaUMICLHhlKO/OIlNg6uGgsF+fDpPd7z7sNcpwp3kdcejhUuuYe926iNMcaEtUBcNirTsL4iMkJE0kUkPTMzMwCHDZHYeLj6Fa9vxCf/B9t+dJ0o3JV1mOerfLOKviciTYt5PbRt5pun4NkekJcT3OMYY4ypsJB12FXV0araXVW7p6amhuqwgRGXCL+ZAFeOhoZdXKeJBh8DaaraCW8CrvHFbRTSNtP4dDiwFX58LbjHMcYYU2GBKF7CdSjlwIqvAp1/691OvWOpNyO1KU6p7UFV96jqUd/Tl4HTQ5StZGlnQ9Ne3hmY/KOlb2+MMcaZQBQv4TqUcvDM/De8exMsj+5vs5xKbQ/H5rzwuRxvGnW3RODce7yzLwvfdJ3GGGPMCVS4eFHVfOB2vHkIVgDvqOqyiu43rF35oneZ4b2bYNWnrtOElZLag4g8JCKX+za7U0SWicgi4E7gRjdpi2h1gfdznfO8zW9ljDFhzKYHKK+c/TDhCti5FK6ZCG36uk50QpE+3HvI2szOZVC1NtRsFPxjhbFIby/GmOhmI+yWV5VkuOEDSD3Nm43aRIf67X8uXOzsizHGhKVAjPNSeVWtDUM+gvhq3nNVr++EiWyH98C7Q6HbEOj0G9dpjDHGFGFnXiqqWh3vTqTsvTD+Mtg0x3UiU1FVa0P2Hvj6CSgsdJ3GGGNMEVa8BEphPhzcAa8Pgi0R3p+nsouJgXPuht2rYIXdEm+MMeHGipdASaoHQydD9RR4baCNxBvp2l0BddvY2RdjjAlDVrwEUs1GMPRjqJrs3Ym0Y4nrRKa8YmK9sy87l8Jqux3eGGPCiXXYDbRaTb0C5sPbILGm6zSmIjoMgqMHocW5rpMYY4zxY8VLMNROg5umeI8LC+HQjko/bkhEio2Dnre4TmGMMaYIu2wUbF8+AKPPgz1rXScx5bVyCnwwwsZ9McaYMGHFS7B1uQ4K87zbqPeud53GlMfBHbD4bVj3leskxhhjsOIl+Oq19Qayy8uG8ZdD1ibXiczJ6no91GgEsx53ncQYYwxWvIRGg45ww4dwdD+8cTUU5LtOZE5GXCL0vgs2fQcbvnGdxhhjKj0rXkKlURe4fhL0/4/XEdRElm5DoHo9mPWo6yTGGFPp2V/RUGpy+s+Pl30IzX/lDW5nwl98Vej3L5AYm8PKGGMcs+LFhUOZ8OGtULs5DP0Eqtd1nciUhU3SaIwxYcEuG7mQlArXvgl718FrA7xJHU1kyD0Ms/9r0z8YY4xDVry40rIPXPMGZK6C1wdCzn7XiUxZaCF8OwpmWt8XY4xxxYoXl1r3hd+8BjuWwoqPXacxZZFYA868zZvvaPti12mMMaZSsuLFtVP7w21zvbFETGToOcKbt+prG/fFGGNcsOIlHNRt5X3dugDevh5ys93mMSdWtRac8TtYMRl2LnedxhhjKh0rXsLJvvWw4hN4azDk5bhOY06k161wysWAzXdkjDGhZsVLOOlwFVzxPKybCe/cAPlHXScyJalWBwa/BfXbu05ijDGVjhUv4abLYLjsf7DmC3j3RsjPdZ3InMj+LbDoLdcpjDGmUrFB6sLR6TdCQR6snYFdlghzc17wlqY9oU5L12mMMaZSsDMv4arnLfDbN7xJAY9kQWGB60SmOL+6A2LiYPaTrpMYY0ylYcVLOIuJgbwj8OqvvekErIAJPzUawOlDYdFEyNrkOo0xxlQKVryEu/iq0P4KWPwWfPwHKCx0ncgUddYfAIFvnnKdxBhjKgXr8xIJzrnH6wMz61GIjYdfP2mzGoeT5CZeP6XCfJtx2hhjQsCKl0jR5y/erdPf/g9qNIJz73GdyPi75HErWowxJkSseIkUItD3QahaGzpe7TqNKepY4bLtR6jZGJLquc1jjDFRzPq8RBIR6H0XJDf2Ou8u+9C7TGHCw4HtMOYC+PZp10mMMSaqWfESqRa+Ce8O9frBmPBQsyF0HATp4+DwbtdpjDEmalnxEqm6XOctM/8NXz/hOo055uy7vdvbv3/WdRJjjIlaVrxEqpgYuPwZ6PgbmPFP+HaU60QGIPUUaH8l/DAGsve6TmOMMVGpQsWLiFwtIstEpFBEugcqlCmjmFi44gXvj+XMf8OBba4TASAi/UVklYhkiMh9xbyeKCJv+16fKyJpDmIGzzl3g8TCjsWukxhjTFSq6N1GS4GBwEsByGLKIzYOBo6BzFVQs5HrNIhILPAccCGwBZgnIpNVdbnfZjcD+1S1tYhcAzwK/Db0aYOkfnv400pIqOY6iTHGRKUKFS+qugJAbHwLt2LjoUEH7/G8sd7zbkNcpekJZKjqOgAReQsYAPgXLwOAB32P3wOeFRFRjaJbpxKqeXeCrZoKCUm/fK1pT2/k5KxNsHf98e9tdibEJcDedZC1+fjX03p7Z912Z8CBrb98TQRanOM9zlwFB3f88vWYOEg7y3u8czkczvQds5c3j5YxxkSAkI3zIiIjgBEAzZo1C9VhK5fCQsiYDl2udZmiMeD/F3cLcEZJ26hqvojsB+oCv7hFJ+LbzOd/hTnPH7/+zoVQpwUsfR++fPD41+/OgKRU+PENmF1MZ+z7d0BMVZg3Bua++MvXJBb+7utr8+0oWPj6L1+vkgz3+eZgmvUoLP/Qe/ynVd48TcYYEwFKLV5E5EuguN9q96vqR2U9kKqOBkYDdO/ePXo+YYeTmBi45o2oGek14ttMn7/AaZcev/5YkdDxamjS8/jXqyR7X7sNgVbnH/96bIL3tecIaHt5ycfvfRd0GfzLdTF+/+X7/MXbB3iDHxpjTIQotXhR1b6hCGICxH3hshVo6ve8iW9dcdtsEZE4IBnYE5p4IVSl5s+XaIqT3MRbSlK7ubeUpG4rbylJShtvKUm900p+zRhjwpjdKm0CbR7QRkRaiEgCcA0wucg2k4GhvseDgBlR1d/FGGNMUFX0VukrRWQLcCYwRUQ+D0wsE6lUNR+4HfgcWAG8o6rLROQhETl2jWMsUFdEMoA/AsfdTm2MMcaURFx84BWRTGCj36oUinTWDFORnLO5qqa6CBMI1maCrmjOiG4vxpjo5qR4OS6ESLqqhv0gd5YzfETK92g5jTEm8KzPizHGGGMiihUvxhhjjIko4VK8jHYdoIwsZ/iIlO/RchpjTICFRZ8XY4wxxpiyCpczL8YYY4wxZWLFizHGGGMiivPiRUT6i8gqEckQkZAPViYi40Rkl4gs9VtXR0Smicga39favvUiIqN8WReLSDe/9wz1bb9GRIYWd6wK5mwqIl+JyHIRWSYifwjXrMHkur34MoR9m7H2YoyJaqrqbAFigbVASyABWAS0C3GGc4BuwFK/dY8B9/ke3wc86nt8CfApIEAvYK5vfR1gne9rbd/j2gHO2RDo5ntcA1gNtAvHrNHcXiKlzVh7scUWW6J5cX3mpSeQoarrVDUXeAsYEMoAqvo1sLfI6gHAeN/j8cAVfusnqGcOUEtEGgL9gGmquldV9wHTgP4BzrldVRf4Hh/EG3q/cThmDSLn7QUio81YezHGRDPXxUtjYLPf8y2+da7VV9Xtvsc7gPq+xyXlDen3ISJpQFdgbrhnDbBwzh62P4dK3F6MMVHKdfES9lRVgbC5n1xEkoD3gbtU9YD/a+GWtbIKp5+DtRdjTDRyXbxsBZr6PW/iW+faTt8pc3xfd/nWl5Q3JN+HiMTj/SF6Q1U/COesQRLO2cPu52DtxRgTrVwXL/OANiLSQkQSgGuAyY4zgZfh2F0VQ4GP/NYP8d2Z0QvY7zsF/zlwkYjU9t29cZFvXcCIiABjgRWq+mQ4Zw2icG0vEGY/B2svxpio5rrHMN5dDqvx7iK538HxJwLbgTy86/k3A3WB6cAa4Eugjm9bAZ7zZV0CdPfbzzAgw7fcFIScvfFO8S8GFvqWS8IxazS3l0hpM9ZebLHFlmhebHoAY4wxxkQU15eNjDHGGGNOihUvxhhjjIkoVrwYY4wxJqJY8WKMMcaYiGLFizHGGGMiihUvxhhjjIkoVrwYY4wxJqL8fyhLEK3Ty+IOAAAAAElFTkSuQmCC%0A.png" class="img-fluid"></p>
<p><strong>(강의노트의 표현)</strong></p>
<div class="cell" data-outputid="beaa45e6-2a3a-43b5-ad23-ec6ca24c14d1" data-execution_count="310">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse</span></span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>gv(<span class="st">'''</span></span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a><span class="st">"x" -&gt; " -x"[label="*(-1)"];</span></span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a><span class="st">"x" -&gt; " x"[label="*1"]</span></span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a><span class="st">" x" -&gt; "rlu(x)"[label="relu"] </span></span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a><span class="st">" -x" -&gt; "rlu(-x)"[label="relu"] </span></span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a><span class="st">"rlu(x)" -&gt; "u"[label="*(-4.5)"] </span></span>
<span id="cb106-8"><a href="#cb106-8" aria-hidden="true" tabindex="-1"></a><span class="st">"rlu(-x)" -&gt; "u"[label="*(-9.0)"] </span></span>
<span id="cb106-9"><a href="#cb106-9" aria-hidden="true" tabindex="-1"></a><span class="st">"u" -&gt; "sig(u)=yhat"[label="sig"] </span></span>
<span id="cb106-10"><a href="#cb106-10" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span></span>
<span id="cb106-11"><a href="#cb106-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="310">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-76-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><strong>(좀 더 일반화된 표현)</strong> 10월4일 강의노트 상황을 일반화하면 아래와 같다.</p>
<div class="cell" data-outputid="ef54cfec-0910-4f25-99e2-610534ba231a" data-execution_count="311">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse</span></span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>gv(<span class="st">'''</span></span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a><span class="st">"x" -&gt; "u1[:,0]"[label="*(-1)"];</span></span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a><span class="st">"x" -&gt; "u1[:,1]"[label="*1"]</span></span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a><span class="st">"u1[:,0]" -&gt; "v1[:,0]"[label="relu"] </span></span>
<span id="cb107-6"><a href="#cb107-6" aria-hidden="true" tabindex="-1"></a><span class="st">"u1[:,1]" -&gt; "v1[:,1]"[label="relu"] </span></span>
<span id="cb107-7"><a href="#cb107-7" aria-hidden="true" tabindex="-1"></a><span class="st">"v1[:,0]" -&gt; "u2"[label="*(-9.0)"] </span></span>
<span id="cb107-8"><a href="#cb107-8" aria-hidden="true" tabindex="-1"></a><span class="st">"v1[:,1]" -&gt; "u2"[label="*(-4.5)"] </span></span>
<span id="cb107-9"><a href="#cb107-9" aria-hidden="true" tabindex="-1"></a><span class="st">"u2" -&gt; "v2=yhat"[label="sig"] </span></span>
<span id="cb107-10"><a href="#cb107-10" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span></span>
<span id="cb107-11"><a href="#cb107-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="311">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-77-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>*</code> Layer의 개념: <span class="math inline">\({\bf X}\)</span>에서 <span class="math inline">\(\hat{\boldsymbol y}\)</span>로 가는 과정은 “선형변환+비선형변환”이 반복되는 구조이다. “선형변환+비선형변환”을 하나의 세트로 보면 아래와 같이 표현할 수 있다.</p>
<p><span class="math inline">\(\underset{(n,1)}{\bf X} \overset{l_1}{\to} \left( \underset{(n,2)}{\boldsymbol u^{(1)}} \overset{relu}{\to} \underset{(n,2)}{\boldsymbol v^{(1)}} \right) \overset{l_2}{\to} \left(\underset{(n,1)}{\boldsymbol u^{(2)}} \overset{sig}{\to} \underset{(n,1)}{\boldsymbol v^{(2)}}\right), \quad \underset{(n,1)}{\boldsymbol v^{(2)}}=\underset{(n,1)}{net({\bf X})}=\underset{(n,1)}{\hat{\boldsymbol y}}\)</span></p>
<p>이것을 다이어그램으로 표현한다면 아래와 같다.</p>
<p><strong>(선형+비선형을 하나의 Layer로 묶은 표현)</strong></p>
<div class="cell" data-outputid="b217b4e0-edfb-472b-a09c-2d20732a0d43" data-execution_count="312">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse</span></span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>gv(<span class="st">'''</span></span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a><span class="st">subgraph cluster_1{</span></span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a><span class="st">    style=filled;</span></span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a><span class="st">    color=lightgrey;</span></span>
<span id="cb108-6"><a href="#cb108-6" aria-hidden="true" tabindex="-1"></a><span class="st">    "X" </span></span>
<span id="cb108-7"><a href="#cb108-7" aria-hidden="true" tabindex="-1"></a><span class="st">    label = "Layer 0"</span></span>
<span id="cb108-8"><a href="#cb108-8" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb108-9"><a href="#cb108-9" aria-hidden="true" tabindex="-1"></a><span class="st">subgraph cluster_2{</span></span>
<span id="cb108-10"><a href="#cb108-10" aria-hidden="true" tabindex="-1"></a><span class="st">    style=filled;</span></span>
<span id="cb108-11"><a href="#cb108-11" aria-hidden="true" tabindex="-1"></a><span class="st">    color=lightgrey;</span></span>
<span id="cb108-12"><a href="#cb108-12" aria-hidden="true" tabindex="-1"></a><span class="st">    "X" -&gt; "u1[:,0]"</span></span>
<span id="cb108-13"><a href="#cb108-13" aria-hidden="true" tabindex="-1"></a><span class="st">    "X" -&gt; "u1[:,1]"</span></span>
<span id="cb108-14"><a href="#cb108-14" aria-hidden="true" tabindex="-1"></a><span class="st">    "u1[:,0]" -&gt; "v1[:,0]"[label="relu"]</span></span>
<span id="cb108-15"><a href="#cb108-15" aria-hidden="true" tabindex="-1"></a><span class="st">    "u1[:,1]" -&gt; "v1[:,1]"[label="relu"]</span></span>
<span id="cb108-16"><a href="#cb108-16" aria-hidden="true" tabindex="-1"></a><span class="st">    label = "Layer 1"</span></span>
<span id="cb108-17"><a href="#cb108-17" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb108-18"><a href="#cb108-18" aria-hidden="true" tabindex="-1"></a><span class="st">subgraph cluster_3{</span></span>
<span id="cb108-19"><a href="#cb108-19" aria-hidden="true" tabindex="-1"></a><span class="st">    style=filled;</span></span>
<span id="cb108-20"><a href="#cb108-20" aria-hidden="true" tabindex="-1"></a><span class="st">    color=lightgrey;</span></span>
<span id="cb108-21"><a href="#cb108-21" aria-hidden="true" tabindex="-1"></a><span class="st">    "v1[:,0]" -&gt; "u2"</span></span>
<span id="cb108-22"><a href="#cb108-22" aria-hidden="true" tabindex="-1"></a><span class="st">    "v1[:,1]" -&gt; "u2"</span></span>
<span id="cb108-23"><a href="#cb108-23" aria-hidden="true" tabindex="-1"></a><span class="st">    "u2" -&gt; "v2=yhat"[label="sigmoid"]</span></span>
<span id="cb108-24"><a href="#cb108-24" aria-hidden="true" tabindex="-1"></a><span class="st">    label = "Layer 2"</span></span>
<span id="cb108-25"><a href="#cb108-25" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb108-26"><a href="#cb108-26" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="312">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-78-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><strong><em>Layer를 세는 방법</em></strong> - 정석: <strong>학습가능한 파라메터</strong>가 몇층으로 있는지… - 일부 교재 설명: 입력층은 계산하지 않음, activation layer는 계산하지 않음. - 위의 예제의 경우 <code>number of layer = 2</code> 이다.</p>
<blockquote class="blockquote">
<p>사실 input layer, activation layer 등의 표현을 자주 사용해서 layer를 세는 방법이 처음에는 헷갈립니다..</p>
</blockquote>
<p><strong><em>Hidden Layer의 수를 세는 방법</em></strong> - <code>Layer의 수 = Hidden Layer의 수 + 출력층의 수 = Hidden Layer의 수 + 1</code> - 위의 예제의 경우 <code>number of hidden layer = 1</code> 이다.</p>
<p><code>*</code> node의 개념: <span class="math inline">\(u\to v\)</span>로 가는 쌍을 간단히 노드라는 개념을 이용하여 나타낼 수 있음.</p>
<p><strong>(노드의 개념이 포함된 그림)</strong></p>
<div class="cell" data-outputid="9975facf-dcfd-44fa-9807-8573b36e70bf" data-tags="[]" data-execution_count="313">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse</span></span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>gv(<span class="st">'''</span></span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a><span class="st">subgraph cluster_1{</span></span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a><span class="st">    style=filled;</span></span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a><span class="st">    color=lightgrey;</span></span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a><span class="st">    "X" </span></span>
<span id="cb109-7"><a href="#cb109-7" aria-hidden="true" tabindex="-1"></a><span class="st">    label = "Layer 0"</span></span>
<span id="cb109-8"><a href="#cb109-8" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb109-9"><a href="#cb109-9" aria-hidden="true" tabindex="-1"></a><span class="st">subgraph cluster_2{</span></span>
<span id="cb109-10"><a href="#cb109-10" aria-hidden="true" tabindex="-1"></a><span class="st">    style=filled;</span></span>
<span id="cb109-11"><a href="#cb109-11" aria-hidden="true" tabindex="-1"></a><span class="st">    color=lightgrey;</span></span>
<span id="cb109-12"><a href="#cb109-12" aria-hidden="true" tabindex="-1"></a><span class="st">    "X" -&gt; "node1"</span></span>
<span id="cb109-13"><a href="#cb109-13" aria-hidden="true" tabindex="-1"></a><span class="st">    "X" -&gt; "node2"</span></span>
<span id="cb109-14"><a href="#cb109-14" aria-hidden="true" tabindex="-1"></a><span class="st">    label = "Layer 1:relu"</span></span>
<span id="cb109-15"><a href="#cb109-15" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb109-16"><a href="#cb109-16" aria-hidden="true" tabindex="-1"></a><span class="st">subgraph cluster_3{</span></span>
<span id="cb109-17"><a href="#cb109-17" aria-hidden="true" tabindex="-1"></a><span class="st">    style=filled;</span></span>
<span id="cb109-18"><a href="#cb109-18" aria-hidden="true" tabindex="-1"></a><span class="st">    color=lightgrey;</span></span>
<span id="cb109-19"><a href="#cb109-19" aria-hidden="true" tabindex="-1"></a><span class="st">    "node1" -&gt; "yhat "</span></span>
<span id="cb109-20"><a href="#cb109-20" aria-hidden="true" tabindex="-1"></a><span class="st">    "node2" -&gt; "yhat "</span></span>
<span id="cb109-21"><a href="#cb109-21" aria-hidden="true" tabindex="-1"></a><span class="st">    label = "Layer 2:sigmoid"</span></span>
<span id="cb109-22"><a href="#cb109-22" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb109-23"><a href="#cb109-23" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="313">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-79-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>여기에서 <code>node의 숫자 = feature의 숫자</code>와 같이 이해할 수 있다. 즉 아래와 같이 이해할 수 있다.</p>
<p><strong>(“number of nodes = number of features”로 이해한 그림)</strong></p>
<div class="cell" data-outputid="200b02a6-953b-479c-d9f8-597a0d0c1808" data-execution_count="314">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse</span></span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>gv(<span class="st">'''</span></span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a><span class="st">subgraph cluster_1{</span></span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true" tabindex="-1"></a><span class="st">    style=filled;</span></span>
<span id="cb110-5"><a href="#cb110-5" aria-hidden="true" tabindex="-1"></a><span class="st">    color=lightgrey;</span></span>
<span id="cb110-6"><a href="#cb110-6" aria-hidden="true" tabindex="-1"></a><span class="st">    "X" </span></span>
<span id="cb110-7"><a href="#cb110-7" aria-hidden="true" tabindex="-1"></a><span class="st">    label = "Layer 0"</span></span>
<span id="cb110-8"><a href="#cb110-8" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb110-9"><a href="#cb110-9" aria-hidden="true" tabindex="-1"></a><span class="st">subgraph cluster_2{</span></span>
<span id="cb110-10"><a href="#cb110-10" aria-hidden="true" tabindex="-1"></a><span class="st">    style=filled;</span></span>
<span id="cb110-11"><a href="#cb110-11" aria-hidden="true" tabindex="-1"></a><span class="st">    color=lightgrey;</span></span>
<span id="cb110-12"><a href="#cb110-12" aria-hidden="true" tabindex="-1"></a><span class="st">    "X" -&gt; "feature1"</span></span>
<span id="cb110-13"><a href="#cb110-13" aria-hidden="true" tabindex="-1"></a><span class="st">    "X" -&gt; "feature2"</span></span>
<span id="cb110-14"><a href="#cb110-14" aria-hidden="true" tabindex="-1"></a><span class="st">    label = "Layer 1:relu"</span></span>
<span id="cb110-15"><a href="#cb110-15" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb110-16"><a href="#cb110-16" aria-hidden="true" tabindex="-1"></a><span class="st">subgraph cluster_3{</span></span>
<span id="cb110-17"><a href="#cb110-17" aria-hidden="true" tabindex="-1"></a><span class="st">    style=filled;</span></span>
<span id="cb110-18"><a href="#cb110-18" aria-hidden="true" tabindex="-1"></a><span class="st">    color=lightgrey;</span></span>
<span id="cb110-19"><a href="#cb110-19" aria-hidden="true" tabindex="-1"></a><span class="st">    "feature1" -&gt; "yhat "</span></span>
<span id="cb110-20"><a href="#cb110-20" aria-hidden="true" tabindex="-1"></a><span class="st">    "feature2" -&gt; "yhat "</span></span>
<span id="cb110-21"><a href="#cb110-21" aria-hidden="true" tabindex="-1"></a><span class="st">    label = "Layer 2:sigmoid"</span></span>
<span id="cb110-22"><a href="#cb110-22" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb110-23"><a href="#cb110-23" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="314">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-80-output-1.png" class="img-fluid"></p>
</div>
</div>
<blockquote class="blockquote">
<p>다이어그램의 표현방식은 교재마다 달라서 모든 예시를 달달 외울 필요는 없습니다. 다만 임의의 다이어그램을 보고 대응하는 네트워크를 pytorch로 구현하는 능력은 매우 중요합니다.</p>
</blockquote>
</section>
<section id="예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y" class="level3">
<h3 class="anchored" data-anchor-id="예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y">예제3: <span class="math inline">\(\underset{(n,784)}{\bf X} \overset{l_1}{\to} \underset{(n,32)}{\boldsymbol u^{(1)}} \overset{relu}{\to} \underset{(n,32)}{\boldsymbol v^{(1)}} \overset{l_1}{\to} \underset{(n,1)}{\boldsymbol u^{(2)}} \overset{sig}{\to} \underset{(n,1)}{\boldsymbol v^{(2)}}=\underset{(n,1)}{\hat{\boldsymbol y}}\)</span></h3>
<p><strong>(다이어그램표현)</strong></p>
<div class="cell" data-outputid="783b1085-ef94-4fd6-a36d-e80417c1d910" data-execution_count="315">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse</span></span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a>gv(<span class="st">'''</span></span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a><span class="st">splines=line</span></span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a><span class="st">subgraph cluster_1{</span></span>
<span id="cb111-5"><a href="#cb111-5" aria-hidden="true" tabindex="-1"></a><span class="st">    style=filled;</span></span>
<span id="cb111-6"><a href="#cb111-6" aria-hidden="true" tabindex="-1"></a><span class="st">    color=lightgrey;</span></span>
<span id="cb111-7"><a href="#cb111-7" aria-hidden="true" tabindex="-1"></a><span class="st">    "x1"</span></span>
<span id="cb111-8"><a href="#cb111-8" aria-hidden="true" tabindex="-1"></a><span class="st">    "x2"</span></span>
<span id="cb111-9"><a href="#cb111-9" aria-hidden="true" tabindex="-1"></a><span class="st">    ".."</span></span>
<span id="cb111-10"><a href="#cb111-10" aria-hidden="true" tabindex="-1"></a><span class="st">    "x784"</span></span>
<span id="cb111-11"><a href="#cb111-11" aria-hidden="true" tabindex="-1"></a><span class="st">    label = "Input Layer"</span></span>
<span id="cb111-12"><a href="#cb111-12" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb111-13"><a href="#cb111-13" aria-hidden="true" tabindex="-1"></a><span class="st">subgraph cluster_2{</span></span>
<span id="cb111-14"><a href="#cb111-14" aria-hidden="true" tabindex="-1"></a><span class="st">    style=filled;</span></span>
<span id="cb111-15"><a href="#cb111-15" aria-hidden="true" tabindex="-1"></a><span class="st">    color=lightgrey;</span></span>
<span id="cb111-16"><a href="#cb111-16" aria-hidden="true" tabindex="-1"></a><span class="st">    "x1" -&gt; "node1"</span></span>
<span id="cb111-17"><a href="#cb111-17" aria-hidden="true" tabindex="-1"></a><span class="st">    "x2" -&gt; "node1"</span></span>
<span id="cb111-18"><a href="#cb111-18" aria-hidden="true" tabindex="-1"></a><span class="st">    ".." -&gt; "node1"</span></span>
<span id="cb111-19"><a href="#cb111-19" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb111-20"><a href="#cb111-20" aria-hidden="true" tabindex="-1"></a><span class="st">    "x784" -&gt; "node1"</span></span>
<span id="cb111-21"><a href="#cb111-21" aria-hidden="true" tabindex="-1"></a><span class="st">    "x1" -&gt; "node2"</span></span>
<span id="cb111-22"><a href="#cb111-22" aria-hidden="true" tabindex="-1"></a><span class="st">    "x2" -&gt; "node2"</span></span>
<span id="cb111-23"><a href="#cb111-23" aria-hidden="true" tabindex="-1"></a><span class="st">    ".." -&gt; "node2"</span></span>
<span id="cb111-24"><a href="#cb111-24" aria-hidden="true" tabindex="-1"></a><span class="st">    "x784" -&gt; "node2"</span></span>
<span id="cb111-25"><a href="#cb111-25" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb111-26"><a href="#cb111-26" aria-hidden="true" tabindex="-1"></a><span class="st">    "x1" -&gt; "..."</span></span>
<span id="cb111-27"><a href="#cb111-27" aria-hidden="true" tabindex="-1"></a><span class="st">    "x2" -&gt; "..."</span></span>
<span id="cb111-28"><a href="#cb111-28" aria-hidden="true" tabindex="-1"></a><span class="st">    ".." -&gt; "..."</span></span>
<span id="cb111-29"><a href="#cb111-29" aria-hidden="true" tabindex="-1"></a><span class="st">    "x784" -&gt; "..."</span></span>
<span id="cb111-30"><a href="#cb111-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-31"><a href="#cb111-31" aria-hidden="true" tabindex="-1"></a><span class="st">    "x1" -&gt; "node32"</span></span>
<span id="cb111-32"><a href="#cb111-32" aria-hidden="true" tabindex="-1"></a><span class="st">    "x2" -&gt; "node32"</span></span>
<span id="cb111-33"><a href="#cb111-33" aria-hidden="true" tabindex="-1"></a><span class="st">    ".." -&gt; "node32"</span></span>
<span id="cb111-34"><a href="#cb111-34" aria-hidden="true" tabindex="-1"></a><span class="st">    "x784" -&gt; "node32"</span></span>
<span id="cb111-35"><a href="#cb111-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-36"><a href="#cb111-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-37"><a href="#cb111-37" aria-hidden="true" tabindex="-1"></a><span class="st">    label = "Hidden Layer: relu"</span></span>
<span id="cb111-38"><a href="#cb111-38" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb111-39"><a href="#cb111-39" aria-hidden="true" tabindex="-1"></a><span class="st">subgraph cluster_3{</span></span>
<span id="cb111-40"><a href="#cb111-40" aria-hidden="true" tabindex="-1"></a><span class="st">    style=filled;</span></span>
<span id="cb111-41"><a href="#cb111-41" aria-hidden="true" tabindex="-1"></a><span class="st">    color=lightgrey;</span></span>
<span id="cb111-42"><a href="#cb111-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-43"><a href="#cb111-43" aria-hidden="true" tabindex="-1"></a><span class="st">    "node1" -&gt; "yhat"</span></span>
<span id="cb111-44"><a href="#cb111-44" aria-hidden="true" tabindex="-1"></a><span class="st">    "node2" -&gt; "yhat"</span></span>
<span id="cb111-45"><a href="#cb111-45" aria-hidden="true" tabindex="-1"></a><span class="st">    "..." -&gt; "yhat"</span></span>
<span id="cb111-46"><a href="#cb111-46" aria-hidden="true" tabindex="-1"></a><span class="st">    "node32" -&gt; "yhat"</span></span>
<span id="cb111-47"><a href="#cb111-47" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb111-48"><a href="#cb111-48" aria-hidden="true" tabindex="-1"></a><span class="st">    label = "Outplut Layer: sigmoid"</span></span>
<span id="cb111-49"><a href="#cb111-49" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb111-50"><a href="#cb111-50" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="315">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-81-output-1.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>Layer0,1,2 대신에 Input Layer, Hidden Layer, Output Layer로 표현함</li>
</ul>
<p><code>-</code> 위의 다이어그램에 대응하는 코드</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(in_features<span class="op">=</span><span class="dv">28</span><span class="op">*</span><span class="dv">28</span><span class="op">*</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">32</span>),</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(in_features<span class="op">=</span><span class="dv">32</span>,out_features<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb112-5"><a href="#cb112-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Sigmoid() </span>
<span id="cb112-6"><a href="#cb112-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</section>
</section>
<section id="cpu-vs-gpu" class="level2">
<h2 class="anchored" data-anchor-id="cpu-vs-gpu">CPU vs GPU</h2>
<p><code>-</code> 파이토치에서 GPU를 쓰는 방법을 알아보자. (사실 지금까지 우리는 CPU만 쓰고 있었음)</p>
<section id="gpu-사용방법" class="level3">
<h3 class="anchored" data-anchor-id="gpu-사용방법">GPU 사용방법</h3>
<p><code>-</code> cpu 연산이 가능한 메모리에 데이터 저장</p>
<div class="cell" data-execution_count="325">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>x_cpu <span class="op">=</span> torch.tensor([<span class="fl">0.0</span>,<span class="fl">0.1</span>,<span class="fl">0.2</span>]).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) </span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>y_cpu <span class="op">=</span> torch.tensor([<span class="fl">0.0</span>,<span class="fl">0.2</span>,<span class="fl">0.4</span>]).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) </span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a>net_cpu <span class="op">=</span> torch.nn.Linear(<span class="dv">1</span>,<span class="dv">1</span>) </span></code></pre></div>
</div>
<p>연산되게끔 reshape으로 shape 변경해주세요</p>
<div class="cell" data-execution_count="349">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>x_cpu, y_cpu</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="349">
<pre><code>(tensor([[0.0000],
         [0.1000],
         [0.2000]]),
 tensor([[0.0000],
         [0.2000],
         [0.4000]]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="327">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>net_cpu.weight, net_cpu.bias</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="327">
<pre><code>(Parameter containing:
 tensor([[-0.3467]], requires_grad=True),
 Parameter containing:
 tensor([-0.8470], requires_grad=True))</code></pre>
</div>
</div>
<p><code>-</code> gpu 연산이 가능한 메모리에 데이터 저장</p>
<div class="cell" data-execution_count="328">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>x_gpu <span class="op">=</span> x_cpu.to(<span class="st">"cuda:0"</span>)</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a>y_gpu <span class="op">=</span> y_cpu.to(<span class="st">"cuda:0"</span>)</span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a>net_gpu <span class="op">=</span> torch.nn.Linear(<span class="dv">1</span>,<span class="dv">1</span>).to(<span class="st">"cuda:0"</span>) </span></code></pre></div>
</div>
<p>cpu있는 자체는 못 넣고</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>net_gpu <span class="op">=</span> net_cpu.to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
<p>cpu에 있는 net을 가져와서 정의해줘야 한다.</p>
<hr>
<div class="cell" data-execution_count="337">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>_a <span class="op">=</span> torch.nn.Linear(<span class="dv">1</span>,<span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="338">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>_a.weight, _a.bias</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="338">
<pre><code>(Parameter containing:
 tensor([[0.4074]], requires_grad=True),
 Parameter containing:
 tensor([-0.8885], requires_grad=True))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="339">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>_a.to(<span class="st">"cuda:0"</span>) </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="339">
<pre><code>Linear(in_features=1, out_features=1, bias=True)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="340">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>_a.weight, _a.bias</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="340">
<pre><code>(Parameter containing:
 tensor([[0.4074]], device='cuda:0', requires_grad=True),
 Parameter containing:
 tensor([-0.8885], device='cuda:0', requires_grad=True))</code></pre>
</div>
</div>
<hr>
<div class="cell" data-execution_count="341">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>x_gpu, y_gpu</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="341">
<pre><code>(tensor([[0.0000],
         [0.1000],
         [0.2000]], device='cuda:0'),
 tensor([[0.0000],
         [0.2000],
         [0.4000]], device='cuda:0'))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="342">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>net_gpu.weight, net_gpu.bias</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="342">
<pre><code>(Parameter containing:
 tensor([[-0.3467]], device='cuda:0', requires_grad=True),
 Parameter containing:
 tensor([-0.8470], device='cuda:0', requires_grad=True))</code></pre>
</div>
</div>
<p><code>-</code> cpu 혹은 gpu 연산이 가능한 메모리에 저장된 값들을 확인</p>
<div class="cell" data-outputid="e7e1bd27-b71e-491b-9f14-9dec00ff05eb" data-execution_count="343">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>x_cpu, y_cpu, net_cpu.weight, net_cpu.bias</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="343">
<pre><code>(tensor([[0.0000],
         [0.1000],
         [0.2000]]),
 tensor([[0.0000],
         [0.2000],
         [0.4000]]),
 Parameter containing:
 tensor([[-0.3467]], requires_grad=True),
 Parameter containing:
 tensor([-0.8470], requires_grad=True))</code></pre>
</div>
</div>
<div class="cell" data-outputid="8b3f5e5c-b561-45dc-8ee6-5cb8e01188ab" data-execution_count="344">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>x_gpu, y_gpu, net_gpu.weight, net_gpu.bias</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="344">
<pre><code>(tensor([[0.0000],
         [0.1000],
         [0.2000]], device='cuda:0'),
 tensor([[0.0000],
         [0.2000],
         [0.4000]], device='cuda:0'),
 Parameter containing:
 tensor([[-0.3467]], device='cuda:0', requires_grad=True),
 Parameter containing:
 tensor([-0.8470], device='cuda:0', requires_grad=True))</code></pre>
</div>
</div>
<p><code>-</code> gpu는 gpu끼리 연산가능하고 cpu는 cpu끼리 연산가능함</p>
<p>(예시1)</p>
<div class="cell" data-outputid="7e203259-4d15-4790-8cce-52cd2e29592b" data-execution_count="345">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>net_cpu(x_cpu) </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="345">
<pre><code>tensor([[-0.8470],
        [-0.8817],
        [-0.9164]], grad_fn=&lt;AddmmBackward0&gt;)</code></pre>
</div>
</div>
<p>(예시2)</p>
<div class="cell" data-outputid="4f4d0830-b05a-4b9f-e56a-c2c4efc3048d" data-execution_count="346">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>net_gpu(x_gpu) </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="346">
<pre><code>tensor([[-0.8470],
        [-0.8817],
        [-0.9163]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)</code></pre>
</div>
</div>
<p>(예시3)</p>
<div class="cell" data-outputid="1155fdef-64ab-4921-9bc3-3d3358de5721" data-execution_count="347">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>net_cpu(x_gpu) </span></code></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)</code></pre>
</div>
</div>
<p>(예시4)</p>
<div class="cell" data-outputid="92ea04b7-c728-49be-d67d-7059bd75fa76" data-execution_count="348">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>net_gpu(x_cpu)</span></code></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)</code></pre>
</div>
</div>
<p>(예시5)</p>
<div class="cell" data-outputid="51817def-fcba-45d4-ba1b-f9367addcf24" data-execution_count="350">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>torch.mean((y_cpu<span class="op">-</span>net_cpu(x_cpu))<span class="op">**</span><span class="dv">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="350">
<pre><code>tensor(1.2068, grad_fn=&lt;MeanBackward0&gt;)</code></pre>
</div>
</div>
<p>(예시6)</p>
<div class="cell" data-outputid="1c7da7dc-8cdf-488a-f204-2c2c706ece84" data-execution_count="351">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a>torch.mean((y_gpu<span class="op">-</span>net_gpu(x_gpu))<span class="op">**</span><span class="dv">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="351">
<pre><code>tensor(1.2068, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)</code></pre>
</div>
</div>
<p>(예시7)</p>
<div class="cell" data-outputid="8aea67eb-540e-4668-9b04-3210b6b8f050" data-execution_count="352">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a>torch.mean((y_gpu<span class="op">-</span>net_cpu(x_cpu))<span class="op">**</span><span class="dv">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!</code></pre>
</div>
</div>
<p>(예시8)</p>
<div class="cell" data-outputid="166a181e-4e08-4237-bd67-f94ab9d09149" data-execution_count="353">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>torch.mean((y_cpu<span class="op">-</span>net_gpu(x_gpu))<span class="op">**</span><span class="dv">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!</code></pre>
</div>
</div>
<p>둘다 cpu에 있던가 둘 다 gpu에 있던가</p>
</section>
<section id="시간측정-예비학습" class="level3">
<h3 class="anchored" data-anchor-id="시간측정-예비학습">시간측정 (예비학습)</h3>
<div class="cell" data-execution_count="354">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time </span></code></pre></div>
</div>
<div class="cell" data-execution_count="355">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="356">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span></code></pre></div>
</div>
<div class="cell" data-outputid="22aa871c-a51e-4814-d37e-832efc0d8570" data-execution_count="357">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a>t2<span class="op">-</span>t1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="357">
<pre><code>0.42019009590148926</code></pre>
</div>
</div>
</section>
<section id="cpu-512" class="level3">
<h3 class="anchored" data-anchor-id="cpu-512">CPU (512)</h3>
<p><code>-</code> 데이터준비</p>
<div class="cell" data-execution_count="364">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">5</span>) </span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>torch.linspace(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb156-3"><a href="#cb156-3" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>torch.randn(<span class="dv">100</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="op">*</span><span class="fl">0.01</span></span></code></pre></div>
</div>
<p><code>-</code> for문 준비</p>
<div class="cell" data-execution_count="365">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">1</span>,<span class="dv">512</span>),</span>
<span id="cb157-3"><a href="#cb157-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb157-4"><a href="#cb157-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">512</span>,<span class="dv">1</span>)</span>
<span id="cb157-5"><a href="#cb157-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb157-6"><a href="#cb157-6" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb157-7"><a href="#cb157-7" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span></code></pre></div>
</div>
<p><code>-</code> for문 + 학습시간측정</p>
<div class="cell" data-outputid="931ca04e-f810-40c6-d665-cff36bb240c7" data-execution_count="366">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>t1<span class="op">=</span> time.time()</span>
<span id="cb158-2"><a href="#cb158-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb158-3"><a href="#cb158-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb158-4"><a href="#cb158-4" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x) </span>
<span id="cb158-5"><a href="#cb158-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb158-6"><a href="#cb158-6" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb158-7"><a href="#cb158-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb158-8"><a href="#cb158-8" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb158-9"><a href="#cb158-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb158-10"><a href="#cb158-10" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb158-11"><a href="#cb158-11" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb158-12"><a href="#cb158-12" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb158-13"><a href="#cb158-13" aria-hidden="true" tabindex="-1"></a>t2<span class="op">-</span>t1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="366">
<pre><code>0.5373966693878174</code></pre>
</div>
</div>
</section>
<section id="gpu-512" class="level3">
<h3 class="anchored" data-anchor-id="gpu-512">GPU (512)</h3>
<p><code>-</code> 데이터준비</p>
<div class="cell" data-execution_count="367">
<div class="sourceCode cell-code" id="cb160"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">5</span>) </span>
<span id="cb160-2"><a href="#cb160-2" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>torch.linspace(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb160-3"><a href="#cb160-3" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>(torch.randn(<span class="dv">100</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="op">*</span><span class="fl">0.01</span>).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<p><code>-</code> for문돌릴준비</p>
<div class="cell" data-execution_count="368">
<div class="sourceCode cell-code" id="cb161"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb161-2"><a href="#cb161-2" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">1</span>,<span class="dv">512</span>),</span>
<span id="cb161-3"><a href="#cb161-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb161-4"><a href="#cb161-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">512</span>,<span class="dv">1</span>)</span>
<span id="cb161-5"><a href="#cb161-5" aria-hidden="true" tabindex="-1"></a>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb161-6"><a href="#cb161-6" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb161-7"><a href="#cb161-7" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span></code></pre></div>
</div>
<p><code>-</code> for문 + 학습시간측정</p>
<div class="cell" data-outputid="52ca0d78-9bcb-4c01-8fc7-279215bda5f1" data-execution_count="369">
<div class="sourceCode cell-code" id="cb162"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a>t1<span class="op">=</span> time.time()</span>
<span id="cb162-2"><a href="#cb162-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb162-3"><a href="#cb162-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb162-4"><a href="#cb162-4" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x) </span>
<span id="cb162-5"><a href="#cb162-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb162-6"><a href="#cb162-6" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb162-7"><a href="#cb162-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb162-8"><a href="#cb162-8" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb162-9"><a href="#cb162-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb162-10"><a href="#cb162-10" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb162-11"><a href="#cb162-11" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb162-12"><a href="#cb162-12" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb162-13"><a href="#cb162-13" aria-hidden="true" tabindex="-1"></a>t2<span class="op">-</span>t1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="369">
<pre><code>1.4511945247650146</code></pre>
</div>
</div>
<ul>
<li>!! CPU가 더 빠르다?</li>
</ul>
</section>
<section id="cpu-vs-gpu-20480" class="level3">
<h3 class="anchored" data-anchor-id="cpu-vs-gpu-20480">CPU vs GPU (20480)</h3>
<p><code>-</code> CPU (20480)</p>
<div class="cell" data-outputid="c47309f9-faa8-492a-a1ee-17d35ec441b4" data-execution_count="370">
<div class="sourceCode cell-code" id="cb164"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">5</span>) </span>
<span id="cb164-2"><a href="#cb164-2" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>torch.linspace(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb164-3"><a href="#cb164-3" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>torch.randn(<span class="dv">100</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="op">*</span><span class="fl">0.01</span></span>
<span id="cb164-4"><a href="#cb164-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb164-5"><a href="#cb164-5" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb164-6"><a href="#cb164-6" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">1</span>,<span class="dv">20480</span>),</span>
<span id="cb164-7"><a href="#cb164-7" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb164-8"><a href="#cb164-8" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">20480</span>,<span class="dv">1</span>)</span>
<span id="cb164-9"><a href="#cb164-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb164-10"><a href="#cb164-10" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb164-11"><a href="#cb164-11" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span>
<span id="cb164-12"><a href="#cb164-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb164-13"><a href="#cb164-13" aria-hidden="true" tabindex="-1"></a>t1<span class="op">=</span> time.time()</span>
<span id="cb164-14"><a href="#cb164-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb164-15"><a href="#cb164-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb164-16"><a href="#cb164-16" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x) </span>
<span id="cb164-17"><a href="#cb164-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb164-18"><a href="#cb164-18" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb164-19"><a href="#cb164-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb164-20"><a href="#cb164-20" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb164-21"><a href="#cb164-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb164-22"><a href="#cb164-22" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb164-23"><a href="#cb164-23" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb164-24"><a href="#cb164-24" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb164-25"><a href="#cb164-25" aria-hidden="true" tabindex="-1"></a>t2<span class="op">-</span>t1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="370">
<pre><code>3.806452512741089</code></pre>
</div>
</div>
<p><code>-</code> GPU (20480)</p>
<div class="cell" data-outputid="a6ee0060-d64f-4597-f553-95620e2edadd" data-execution_count="371">
<div class="sourceCode cell-code" id="cb166"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">5</span>) </span>
<span id="cb166-2"><a href="#cb166-2" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>torch.linspace(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb166-3"><a href="#cb166-3" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>(torch.randn(<span class="dv">100</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="op">*</span><span class="fl">0.01</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb166-4"><a href="#cb166-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-5"><a href="#cb166-5" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb166-6"><a href="#cb166-6" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">1</span>,<span class="dv">20480</span>),</span>
<span id="cb166-7"><a href="#cb166-7" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb166-8"><a href="#cb166-8" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">20480</span>,<span class="dv">1</span>)</span>
<span id="cb166-9"><a href="#cb166-9" aria-hidden="true" tabindex="-1"></a>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb166-10"><a href="#cb166-10" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb166-11"><a href="#cb166-11" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span>
<span id="cb166-12"><a href="#cb166-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-13"><a href="#cb166-13" aria-hidden="true" tabindex="-1"></a>t1<span class="op">=</span> time.time()</span>
<span id="cb166-14"><a href="#cb166-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb166-15"><a href="#cb166-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb166-16"><a href="#cb166-16" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x) </span>
<span id="cb166-17"><a href="#cb166-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb166-18"><a href="#cb166-18" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb166-19"><a href="#cb166-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb166-20"><a href="#cb166-20" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb166-21"><a href="#cb166-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb166-22"><a href="#cb166-22" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb166-23"><a href="#cb166-23" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb166-24"><a href="#cb166-24" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb166-25"><a href="#cb166-25" aria-hidden="true" tabindex="-1"></a>t2<span class="op">-</span>t1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="371">
<pre><code>1.308497667312622</code></pre>
</div>
</div>
<p><code>-</code> 왜 이런 차이가 나는가? 연산을 하는 주체는 코어인데 CPU는 수는 적지만 일을 잘하는 코어들을 가지고 있고 GPU는 일은 못하지만 다수의 코어를 가지고 있기 때문</p>
</section>
<section id="cpu-vs-gpu-204800" class="level3">
<h3 class="anchored" data-anchor-id="cpu-vs-gpu-204800">CPU vs GPU (204800)</h3>
<p><code>-</code> CPU (204800)</p>
<div class="cell" data-outputid="433d0956-bc47-42d1-ce9d-b60245d6333e" data-execution_count="372">
<div class="sourceCode cell-code" id="cb168"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">5</span>) </span>
<span id="cb168-2"><a href="#cb168-2" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>torch.linspace(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb168-3"><a href="#cb168-3" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>torch.randn(<span class="dv">100</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="op">*</span><span class="fl">0.01</span></span>
<span id="cb168-4"><a href="#cb168-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb168-5"><a href="#cb168-5" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb168-6"><a href="#cb168-6" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">1</span>,<span class="dv">204800</span>),</span>
<span id="cb168-7"><a href="#cb168-7" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb168-8"><a href="#cb168-8" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">204800</span>,<span class="dv">1</span>)</span>
<span id="cb168-9"><a href="#cb168-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb168-10"><a href="#cb168-10" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb168-11"><a href="#cb168-11" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span>
<span id="cb168-12"><a href="#cb168-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb168-13"><a href="#cb168-13" aria-hidden="true" tabindex="-1"></a>t1<span class="op">=</span> time.time()</span>
<span id="cb168-14"><a href="#cb168-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb168-15"><a href="#cb168-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb168-16"><a href="#cb168-16" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x) </span>
<span id="cb168-17"><a href="#cb168-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb168-18"><a href="#cb168-18" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb168-19"><a href="#cb168-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb168-20"><a href="#cb168-20" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb168-21"><a href="#cb168-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb168-22"><a href="#cb168-22" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb168-23"><a href="#cb168-23" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb168-24"><a href="#cb168-24" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb168-25"><a href="#cb168-25" aria-hidden="true" tabindex="-1"></a>t2<span class="op">-</span>t1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="372">
<pre><code>65.33969926834106</code></pre>
</div>
</div>
<p><code>-</code> GPU (204800)</p>
<div class="cell" data-outputid="32d23220-edd7-44d0-c004-36bee360d22a" data-execution_count="373">
<div class="sourceCode cell-code" id="cb170"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">5</span>) </span>
<span id="cb170-2"><a href="#cb170-2" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>torch.linspace(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb170-3"><a href="#cb170-3" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>(torch.randn(<span class="dv">100</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="op">*</span><span class="fl">0.01</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb170-4"><a href="#cb170-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb170-5"><a href="#cb170-5" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb170-6"><a href="#cb170-6" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">1</span>,<span class="dv">204800</span>),</span>
<span id="cb170-7"><a href="#cb170-7" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb170-8"><a href="#cb170-8" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">204800</span>,<span class="dv">1</span>)</span>
<span id="cb170-9"><a href="#cb170-9" aria-hidden="true" tabindex="-1"></a>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb170-10"><a href="#cb170-10" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb170-11"><a href="#cb170-11" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span>
<span id="cb170-12"><a href="#cb170-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb170-13"><a href="#cb170-13" aria-hidden="true" tabindex="-1"></a>t1<span class="op">=</span> time.time()</span>
<span id="cb170-14"><a href="#cb170-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb170-15"><a href="#cb170-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb170-16"><a href="#cb170-16" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x) </span>
<span id="cb170-17"><a href="#cb170-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb170-18"><a href="#cb170-18" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb170-19"><a href="#cb170-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb170-20"><a href="#cb170-20" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb170-21"><a href="#cb170-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb170-22"><a href="#cb170-22" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb170-23"><a href="#cb170-23" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb170-24"><a href="#cb170-24" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb170-25"><a href="#cb170-25" aria-hidden="true" tabindex="-1"></a>t2<span class="op">-</span>t1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="373">
<pre><code>2.077875852584839</code></pre>
</div>
</div>
<div class="cell" data-execution_count="377">
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>nvidia<span class="op">-</span>smi</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Wed Oct 12 21:15:05 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 495.46       Driver Version: 495.46       CUDA Version: 11.5     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:65:00.0 Off |                  N/A |
|  0%   41C    P8    28W / 420W |  12812MiB / 24268MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A    482816      C   ...onda3/envs/csy/bin/python     4261MiB |
|    0   N/A  N/A    580526      C   ...onda3/envs/csy/bin/python     3249MiB |
|    0   N/A  N/A    605977      C   ...onda3/envs/csy/bin/python     2979MiB |
|    0   N/A  N/A   1035719      C   ...onda3/envs/csy/bin/python     2321MiB |
+-----------------------------------------------------------------------------+</code></pre>
</div>
</div>
</section>
</section>
<section id="확률적경사하강법-배치-에폭" class="level2">
<h2 class="anchored" data-anchor-id="확률적경사하강법-배치-에폭">확률적경사하강법, 배치, 에폭</h2>
<section id="좀-이상하지-않아요" class="level3">
<h3 class="anchored" data-anchor-id="좀-이상하지-않아요">좀 이상하지 않아요?</h3>
<p><code>-</code> 우리가 쓰는 GPU: <a href="http://shop.danawa.com/virtualestimate/?controller=estimateMain&amp;methods=index&amp;marketPlaceSeq=16">다나와 PC견적</a> - GPU 메모리 끽해봐야 24GB</p>
<p><code>-</code> 우리가 분석하는 데이터: 빅데이터..?</p>
<p><code>-</code> 데이터의 크기가 커지는순간 <code>X.to("cuda:0")</code>, <code>y.to("cuda:0")</code> 쓰면 난리나겠는걸?</p>
<div class="cell" data-execution_count="378">
<div class="sourceCode cell-code" id="cb174"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb174-1"><a href="#cb174-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.linspace(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>,<span class="dv">100000</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb174-2"><a href="#cb174-2" aria-hidden="true" tabindex="-1"></a>eps <span class="op">=</span> torch.randn(<span class="dv">100000</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb174-3"><a href="#cb174-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> eps </span></code></pre></div>
</div>
<div class="cell" data-outputid="ccd8813e-7ee0-4827-b037-976d46f7441d" data-execution_count="379">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>plt.plot(x,y,<span class="st">'o'</span>,alpha<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb175-2"><a href="#cb175-2" aria-hidden="true" tabindex="-1"></a>plt.plot(x,<span class="dv">2</span><span class="op">*</span>x)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-118-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 데이터를 100개중에 1개만 꼴로만 쓰면 어떨까?</p>
<div class="cell" data-outputid="3f5b6d41-84f8-48f5-dc10-eefae2b724d3" data-execution_count="380">
<div class="sourceCode cell-code" id="cb176"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb176-1"><a href="#cb176-1" aria-hidden="true" tabindex="-1"></a>plt.plot(x[::<span class="dv">100</span>],y[::<span class="dv">100</span>],<span class="st">'o'</span>,alpha<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb176-2"><a href="#cb176-2" aria-hidden="true" tabindex="-1"></a>plt.plot(x,<span class="dv">2</span><span class="op">*</span>x)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-119-output-1.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>대충 이거만 가지고 적합해도 충분히 정확할것 같은데</li>
</ul>
</section>
<section id="xy-데이터를-굳이-모두-gpu에-넘겨야-하는가" class="level3">
<h3 class="anchored" data-anchor-id="xy-데이터를-굳이-모두-gpu에-넘겨야-하는가">X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?</h3>
<p><code>-</code> 데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나?</p>
<p><code>-</code> 아래의 알고리즘을 생각해보자. 1. 데이터를 반으로 나눈다. 2. 짝수obs의 x,y 그리고 net의 모든 파라메터를 GPU에 올린다. 3. yhat, loss, grad, update 수행 4. 짝수obs의 x,y를 GPU메모리에서 내린다. 그리고 홀수obs의 x,y를 GPU메모리에 올린다. 5. yhat, loss, grad, update 수행 6. 홀수obs의 x,y를 GPU메모리에서 내린다. 그리고 짝수obs의 x,y를 GPU메모리에 올린다. 7. 반복</p>
<p>(서연 필기) 전체 다 올리면 경사하강법 부분적으로 올리면 확률적 경사하강법</p>
</section>
<section id="경사하강법-확률적경사하강법-미니배치-경사하강법" class="level3">
<h3 class="anchored" data-anchor-id="경사하강법-확률적경사하강법-미니배치-경사하강법">경사하강법, 확률적경사하강법, 미니배치 경사하강법</h3>
<p>10개의 샘플이 있다고 가정. <span class="math inline">\(\{(x_i,y_i)\}_{i=1}^{10}\)</span></p>
<p><code>-</code> ver1: 모든 샘플을 이용하여 slope 계산</p>
<p>(epoch1) <span class="math inline">\(loss=\sum_{i=1}^{10}(y_i-\beta_0-\beta_1x_i)^2 \to slope \to update\)</span></p>
<p>(epoch2) <span class="math inline">\(loss=\sum_{i=1}^{10}(y_i-\beta_0-\beta_1x_i)^2 \to slope \to update\)</span></p>
<p>…</p>
<p><code>-</code> ver2: 하나의 샘플만을 이용하여 slope 계산</p>
<p>(epoch1) - <span class="math inline">\(loss=(y_1-\beta_0-\beta_1x_1)^2 \to slope \to update\)</span> - <span class="math inline">\(loss=(y_2-\beta_0-\beta_1x_2)^2 \to slope \to update\)</span> - … - <span class="math inline">\(loss=(y_{10}-\beta_0-\beta_1x_{10})^2 \to slope \to update\)</span></p>
<p>(epoch2) - <span class="math inline">\(loss=(y_1-\beta_0-\beta_1x_1)^2 \to slope \to update\)</span> - <span class="math inline">\(loss=(y_2-\beta_0-\beta_1x_2)^2 \to slope \to update\)</span> - … - <span class="math inline">\(loss=(y_{10}-\beta_0-\beta_1x_{10})^2 \to slope \to update\)</span></p>
<p>…</p>
<p>(서연 필기) 불안해 - for 문도 많이 돌아야 해.</p>
<p><code>-</code> ver3: <span class="math inline">\(m (\leq n)\)</span> 개의 샘플을 이용하여 slope 계산</p>
<p><span class="math inline">\(m=3\)</span>이라고 하자.</p>
<p>(epoch1) - <span class="math inline">\(loss=\sum_{i=1}^{3}(y_i-\beta_0-\beta_1x_i)^2 \to slope \to update\)</span> - <span class="math inline">\(loss=\sum_{i=4}^{6}(y_i-\beta_0-\beta_1x_i)^2 \to slope \to update\)</span> - <span class="math inline">\(loss=\sum_{i=7}^{9}(y_i-\beta_0-\beta_1x_i)^2 \to slope \to update\)</span> - <span class="math inline">\(loss=(y_{10}-\beta_0-\beta_1x_{10})^2 \to slope \to update\)</span></p>
<p>(epoch2) - <span class="math inline">\(loss=\sum_{i=1}^{3}(y_i-\beta_0-\beta_1x_i)^2 \to slope \to update\)</span> - <span class="math inline">\(loss=\sum_{i=4}^{6}(y_i-\beta_0-\beta_1x_i)^2 \to slope \to update\)</span> - <span class="math inline">\(loss=\sum_{i=7}^{9}(y_i-\beta_0-\beta_1x_i)^2 \to slope \to update\)</span> - <span class="math inline">\(loss=(y_{10}-\beta_0-\beta_1x_{10})^2 \to slope \to update\)</span></p>
<p>…</p>
<p>(서연 필기) 미니배치하고 남은 것도 계산된다.</p>
</section>
<section id="용어의-정리" class="level3">
<h3 class="anchored" data-anchor-id="용어의-정리">용어의 정리</h3>
<p><strong>옛날</strong></p>
<p><code>-</code> ver1: gradient descent, batch gradient descent</p>
<p><code>-</code> ver2: stochastic gradient descent</p>
<p><code>-</code> ver3: mini-batch gradient descent, mini-batch stochastic gradient descent</p>
<p><strong>요즘</strong></p>
<p><code>-</code> ver1: gradient descent</p>
<p><code>-</code> ver2: stochastic gradient descent with batch size = 1</p>
<p><code>-</code> <strong>ver3: stochastic gradient descent</strong> - https://www.deeplearningbook.org/contents/optimization.html, 알고리즘 8-1 참고.</p>
</section>
<section id="ds-dl" class="level3">
<h3 class="anchored" data-anchor-id="ds-dl">ds, dl</h3>
<p><code>-</code> ds</p>
<div class="cell" data-execution_count="381">
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>torch.tensor(<span class="bu">range</span>(<span class="dv">10</span>)).<span class="bu">float</span>()<span class="co">#.reshape(-1,1)</span></span>
<span id="cb177-2"><a href="#cb177-2" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>torch.tensor([<span class="fl">1.0</span>]<span class="op">*</span><span class="dv">5</span><span class="op">+</span>[<span class="fl">0.0</span>]<span class="op">*</span><span class="dv">5</span>)<span class="co">#.reshape(-1,1)</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="c4e3487d-49ae-41d6-dcf5-7c5a0abfec90" data-execution_count="382">
<div class="sourceCode cell-code" id="cb178"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a>ds<span class="op">=</span>torch.utils.data.TensorDataset(x,y)</span>
<span id="cb178-2"><a href="#cb178-2" aria-hidden="true" tabindex="-1"></a>ds</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="382">
<pre><code>&lt;torch.utils.data.dataset.TensorDataset at 0x7fa03d24f940&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="62a0d1f5-fd78-49f2-c9df-aa272779cc61" data-execution_count="383">
<div class="sourceCode cell-code" id="cb180"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb180-1"><a href="#cb180-1" aria-hidden="true" tabindex="-1"></a>ds.tensors <span class="co"># 그냥 (x,y)의 튜플</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="383">
<pre><code>(tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]),
 tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.]))</code></pre>
</div>
</div>
<p><code>-</code> dl</p>
<div class="cell" data-execution_count="387">
<div class="sourceCode cell-code" id="cb182"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a>dl<span class="op">=</span>torch.utils.data.DataLoader(ds,batch_size<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb182-2"><a href="#cb182-2" aria-hidden="true" tabindex="-1"></a><span class="co">#set(dir(dl)) &amp; {'__iter__'}</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="388">
<div class="sourceCode cell-code" id="cb183"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a><span class="bu">set</span>(<span class="bu">dir</span>(dl)) <span class="op">&amp;</span> {<span class="st">'__iter__'</span>}</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="388">
<pre><code>{'__iter__'}</code></pre>
</div>
</div>
<p>dir에 __iter__있으면 for문 쓰기 가능</p>
<div class="cell" data-outputid="afdea381-7197-40eb-fb5c-cc9e1b1a615d" data-execution_count="389">
<div class="sourceCode cell-code" id="cb185"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb185-1"><a href="#cb185-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> xx,yy <span class="kw">in</span> dl:</span>
<span id="cb185-2"><a href="#cb185-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(xx,yy)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([0., 1., 2.]) tensor([1., 1., 1.])
tensor([3., 4., 5.]) tensor([1., 1., 0.])
tensor([6., 7., 8.]) tensor([0., 0., 0.])
tensor([9.]) tensor([0.])</code></pre>
</div>
</div>
</section>
<section id="ds-dl을-이용한-mnist-구현" class="level3">
<h3 class="anchored" data-anchor-id="ds-dl을-이용한-mnist-구현">ds, dl을 이용한 MNIST 구현</h3>
<p><code>-</code> 데이터정리</p>
<div class="cell" data-execution_count="390">
<div class="sourceCode cell-code" id="cb187"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.MNIST)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="391">
<div class="sourceCode cell-code" id="cb188"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb188-1"><a href="#cb188-1" aria-hidden="true" tabindex="-1"></a>zero_fnames <span class="op">=</span> (path<span class="op">/</span><span class="st">'training/0'</span>).ls()</span>
<span id="cb188-2"><a href="#cb188-2" aria-hidden="true" tabindex="-1"></a>one_fnames <span class="op">=</span> (path<span class="op">/</span><span class="st">'training/1'</span>).ls()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="392">
<div class="sourceCode cell-code" id="cb189"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a>X0 <span class="op">=</span> torch.stack([torchvision.io.read_image(<span class="bu">str</span>(zf)) <span class="cf">for</span> zf <span class="kw">in</span> zero_fnames])</span>
<span id="cb189-2"><a href="#cb189-2" aria-hidden="true" tabindex="-1"></a>X1 <span class="op">=</span> torch.stack([torchvision.io.read_image(<span class="bu">str</span>(of)) <span class="cf">for</span> of <span class="kw">in</span> one_fnames])</span>
<span id="cb189-3"><a href="#cb189-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.concat([X0,X1],axis<span class="op">=</span><span class="dv">0</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span><span class="op">*</span><span class="dv">28</span><span class="op">*</span><span class="dv">28</span>)<span class="op">/</span><span class="dv">255</span></span>
<span id="cb189-4"><a href="#cb189-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor([<span class="fl">0.0</span>]<span class="op">*</span><span class="bu">len</span>(X0) <span class="op">+</span> [<span class="fl">1.0</span>]<span class="op">*</span><span class="bu">len</span>(X1)).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="80068acf-d2da-419f-9a5a-468811f13d0b" data-execution_count="393">
<div class="sourceCode cell-code" id="cb190"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb190-1"><a href="#cb190-1" aria-hidden="true" tabindex="-1"></a>X.shape,y.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="393">
<pre><code>(torch.Size([12665, 784]), torch.Size([12665, 1]))</code></pre>
</div>
</div>
<p><code>-</code> ds <span class="math inline">\(\to\)</span> dl</p>
<div class="cell" data-tags="[]" data-execution_count="394">
<div class="sourceCode cell-code" id="cb192"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb192-1"><a href="#cb192-1" aria-hidden="true" tabindex="-1"></a>ds <span class="op">=</span> torch.utils.data.TensorDataset(X,y)</span>
<span id="cb192-2"><a href="#cb192-2" aria-hidden="true" tabindex="-1"></a>dl <span class="op">=</span> torch.utils.data.DataLoader(ds,batch_size<span class="op">=</span><span class="dv">2048</span>) </span></code></pre></div>
</div>
<div class="cell" data-outputid="780325f8-2cec-4b74-d9ec-788014085cac" data-execution_count="395">
<div class="sourceCode cell-code" id="cb193"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb193-1"><a href="#cb193-1" aria-hidden="true" tabindex="-1"></a><span class="dv">12665</span><span class="op">/</span><span class="dv">2048</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="395">
<pre><code>6.18408203125</code></pre>
</div>
</div>
<div class="cell" data-outputid="33082740-f5bf-4d86-d026-0220841bbd84" data-execution_count="396">
<div class="sourceCode cell-code" id="cb195"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb195-1"><a href="#cb195-1" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb195-2"><a href="#cb195-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> xx,yy <span class="kw">in</span> dl: <span class="co"># 총 7번 돌아가는 for문 </span></span>
<span id="cb195-3"><a href="#cb195-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(i)</span>
<span id="cb195-4"><a href="#cb195-4" aria-hidden="true" tabindex="-1"></a>    i<span class="op">=</span>i<span class="op">+</span><span class="dv">1</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0
1
2
3
4
5
6</code></pre>
</div>
</div>
<p><code>-</code> 미니배치 안쓰는 학습</p>
<div class="cell" data-execution_count="397">
<div class="sourceCode cell-code" id="cb197"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb197-2"><a href="#cb197-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb197-3"><a href="#cb197-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">784</span>,<span class="dv">32</span>),</span>
<span id="cb197-4"><a href="#cb197-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb197-5"><a href="#cb197-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">32</span>,<span class="dv">1</span>),</span>
<span id="cb197-6"><a href="#cb197-6" aria-hidden="true" tabindex="-1"></a>    torch.nn.Sigmoid()</span>
<span id="cb197-7"><a href="#cb197-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb197-8"><a href="#cb197-8" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.BCELoss()</span>
<span id="cb197-9"><a href="#cb197-9" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span></code></pre></div>
</div>
<div class="cell" data-execution_count="398">
<div class="sourceCode cell-code" id="cb198"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb198-1"><a href="#cb198-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">70</span>): </span>
<span id="cb198-2"><a href="#cb198-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb198-3"><a href="#cb198-3" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(X) </span>
<span id="cb198-4"><a href="#cb198-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb198-5"><a href="#cb198-5" aria-hidden="true" tabindex="-1"></a>    loss<span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb198-6"><a href="#cb198-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb198-7"><a href="#cb198-7" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb198-8"><a href="#cb198-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb198-9"><a href="#cb198-9" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb198-10"><a href="#cb198-10" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad() </span></code></pre></div>
</div>
<div class="cell" data-outputid="94292a3e-328b-48d2-d821-649ebcf69af5" data-execution_count="399">
<div class="sourceCode cell-code" id="cb199"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb199-1"><a href="#cb199-1" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">sum</span>((yhat<span class="op">&gt;</span><span class="fl">0.5</span>) <span class="op">==</span> y) <span class="op">/</span> <span class="bu">len</span>(y) </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="399">
<pre><code>tensor(0.9981)</code></pre>
</div>
</div>
<div class="cell" data-outputid="94292a3e-328b-48d2-d821-649ebcf69af5" data-execution_count="403">
<div class="sourceCode cell-code" id="cb201"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a>torch.mean(((yhat<span class="op">&gt;</span><span class="fl">0.5</span>) <span class="op">==</span> y)<span class="op">*</span><span class="fl">1.0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="403">
<pre><code>tensor(0.9981)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="408">
<div class="sourceCode cell-code" id="cb203"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb203-1"><a href="#cb203-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(y) <span class="op">/</span> <span class="dv">2048</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="408">
<pre><code>6.18408203125</code></pre>
</div>
</div>
<p><code>-</code> 미니배치 쓰는 학습 (GPU 올리고 내리는 과정은 생략)</p>
<div class="cell" data-execution_count="409">
<div class="sourceCode cell-code" id="cb205"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb205-1"><a href="#cb205-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb205-2"><a href="#cb205-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb205-3"><a href="#cb205-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">784</span>,<span class="dv">32</span>),</span>
<span id="cb205-4"><a href="#cb205-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb205-5"><a href="#cb205-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">32</span>,<span class="dv">1</span>),</span>
<span id="cb205-6"><a href="#cb205-6" aria-hidden="true" tabindex="-1"></a>    torch.nn.Sigmoid()</span>
<span id="cb205-7"><a href="#cb205-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb205-8"><a href="#cb205-8" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.BCELoss()</span>
<span id="cb205-9"><a href="#cb205-9" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span></code></pre></div>
</div>
<div class="cell" data-execution_count="410">
<div class="sourceCode cell-code" id="cb206"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb206-1"><a href="#cb206-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb206-2"><a href="#cb206-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> xx,yy <span class="kw">in</span> dl: <span class="co">## 7번</span></span>
<span id="cb206-3"><a href="#cb206-3" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 1</span></span>
<span id="cb206-4"><a href="#cb206-4" aria-hidden="true" tabindex="-1"></a>        <span class="co">#yhat = net(xx)</span></span>
<span id="cb206-5"><a href="#cb206-5" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 2 </span></span>
<span id="cb206-6"><a href="#cb206-6" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fn(net(xx),yy) </span>
<span id="cb206-7"><a href="#cb206-7" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 3 </span></span>
<span id="cb206-8"><a href="#cb206-8" aria-hidden="true" tabindex="-1"></a>        loss.backward() </span>
<span id="cb206-9"><a href="#cb206-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 4 </span></span>
<span id="cb206-10"><a href="#cb206-10" aria-hidden="true" tabindex="-1"></a>        optimizr.step()</span>
<span id="cb206-11"><a href="#cb206-11" aria-hidden="true" tabindex="-1"></a>        optimizr.zero_grad()</span></code></pre></div>
</div>
<p>(서연 필기)xx넣어서 학습 시키고 전체 X넣어서 확인</p>
<div class="cell" data-execution_count="413">
<div class="sourceCode cell-code" id="cb207"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb207-1"><a href="#cb207-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="413">
<pre><code>12665</code></pre>
</div>
</div>
<div class="cell" data-outputid="4fa11909-e755-4e29-8e4b-2c8ebb7848d9" data-execution_count="411">
<div class="sourceCode cell-code" id="cb209"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a>torch.mean(((net(X)<span class="op">&gt;</span><span class="fl">0.5</span>) <span class="op">==</span> y)<span class="op">*</span><span class="fl">1.0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="411">
<pre><code>tensor(0.9949)</code></pre>
</div>
</div>
</section>
</section>
<section id="오버피팅" class="level2">
<h2 class="anchored" data-anchor-id="오버피팅">오버피팅</h2>
<p><code>-</code> 오버피팅이란? - 위키: In mathematical modeling, overfitting is “the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit to additional data or predict future observations reliably”. - 제 개념: 데이터를 “데이터 = 언더라잉 + 오차”라고 생각할때 우리가 데이터로부터 적합할 것은 언더라잉인데 오차항을 적합하고 있는 현상.</p>
<section id="오버피팅-예시" class="level3">
<h3 class="anchored" data-anchor-id="오버피팅-예시">오버피팅 예시</h3>
<p><code>-</code> <span class="math inline">\(m\)</span>이 매우 클때 아래의 네트워크 거의 무엇이든 맞출수 있다고 보면 된다.</p>
<ul>
<li><span class="math inline">\(\underset{(n,1)}{\bf X} \overset{l_1}{\to} \underset{(n,m)}{\boldsymbol u^{(1)}} \overset{h}{\to} \underset{(n,m)}{\boldsymbol v^{(1)}} \overset{l_2}{\to} \underset{(n,1)}{\hat{\boldsymbol y}}\)</span></li>
<li><span class="math inline">\(\underset{(n,1)}{\bf X} \overset{l_1}{\to} \underset{(n,m)}{\boldsymbol u^{(1)}} \overset{sig}{\to} \underset{(n,m)}{\boldsymbol v^{(1)}} \overset{l_2}{\to} \underset{(n,1)}{\hat{\boldsymbol y}}\)</span></li>
<li><span class="math inline">\(\underset{(n,1)}{\bf X} \overset{l_1}{\to} \underset{(n,m)}{\boldsymbol u^{(1)}} \overset{relu}{\to} \underset{(n,m)}{\boldsymbol v^{(1)}} \overset{l_2}{\to} \underset{(n,1)}{\hat{\boldsymbol y}}\)</span></li>
</ul>
<p><code>-</code> 그런데 종종 맞추지 말아야 할 것들도 맞춘다.</p>
<p>model: <span class="math inline">\(y_i = (0\times x_i) + \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i \sim N(0,0.01^2)\)</span></p>
<div class="cell" data-outputid="5f043b75-aef6-4e15-b679-3fd39a961f8a">
<div class="sourceCode cell-code" id="cb211"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb211-1"><a href="#cb211-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">5</span>) </span>
<span id="cb211-2"><a href="#cb211-2" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>torch.linspace(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>).reshape(<span class="dv">100</span>,<span class="dv">1</span>)</span>
<span id="cb211-3"><a href="#cb211-3" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>torch.randn(<span class="dv">100</span>).reshape(<span class="dv">100</span>,<span class="dv">1</span>)<span class="op">*</span><span class="fl">0.01</span></span>
<span id="cb211-4"><a href="#cb211-4" aria-hidden="true" tabindex="-1"></a>plt.plot(x,y)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-142-output-1.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>y는 그냥 정규분포에서 생성한 오차이므로 <span class="math inline">\(X \to y\)</span> 로 항햐는 규칙따위는 없음</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb212"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb212-1"><a href="#cb212-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">1</span>) </span>
<span id="cb212-2"><a href="#cb212-2" aria-hidden="true" tabindex="-1"></a>net<span class="op">=</span>torch.nn.Sequential(</span>
<span id="cb212-3"><a href="#cb212-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">512</span>), </span>
<span id="cb212-4"><a href="#cb212-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb212-5"><a href="#cb212-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(in_features<span class="op">=</span><span class="dv">512</span>,out_features<span class="op">=</span><span class="dv">1</span>)) </span>
<span id="cb212-6"><a href="#cb212-6" aria-hidden="true" tabindex="-1"></a>optimizer<span class="op">=</span> torch.optim.Adam(net.parameters())</span>
<span id="cb212-7"><a href="#cb212-7" aria-hidden="true" tabindex="-1"></a>loss_fn<span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb212-8"><a href="#cb212-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb212-9"><a href="#cb212-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>): </span>
<span id="cb212-10"><a href="#cb212-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb212-11"><a href="#cb212-11" aria-hidden="true" tabindex="-1"></a>    yhat<span class="op">=</span>net(x) </span>
<span id="cb212-12"><a href="#cb212-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb212-13"><a href="#cb212-13" aria-hidden="true" tabindex="-1"></a>    loss<span class="op">=</span>loss_fn(yhat,y) </span>
<span id="cb212-14"><a href="#cb212-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb212-15"><a href="#cb212-15" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb212-16"><a href="#cb212-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb212-17"><a href="#cb212-17" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb212-18"><a href="#cb212-18" aria-hidden="true" tabindex="-1"></a>    net.zero_grad() </span></code></pre></div>
</div>
<div class="cell" data-outputid="a413811e-3512-491d-b5b0-0053b5d28cfc">
<div class="sourceCode cell-code" id="cb213"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb213-1"><a href="#cb213-1" aria-hidden="true" tabindex="-1"></a>plt.plot(x,y)</span>
<span id="cb213-2"><a href="#cb213-2" aria-hidden="true" tabindex="-1"></a>plt.plot(x,net(x).data,<span class="st">'--'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-144-output-1.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>우리는 데이터를 랜덤에서 뽑았는데, 데이터의 추세를 따라간다 <span class="math inline">\(\to\)</span> 오버피팅 (underlying이 아니라 오차항을 따라가고 있음)</li>
</ul>
</section>
<section id="오버피팅이라는-뚜렷한-증거-train-test" class="level3">
<h3 class="anchored" data-anchor-id="오버피팅이라는-뚜렷한-증거-train-test">오버피팅이라는 뚜렷한 증거! (train / test)</h3>
<p><code>-</code> 데이터의 분리하여 보자.</p>
<div class="cell" data-outputid="0e00fb63-42fd-470d-f090-6295d5eb1b89">
<div class="sourceCode cell-code" id="cb214"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb214-1"><a href="#cb214-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">5</span>) </span>
<span id="cb214-2"><a href="#cb214-2" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>torch.linspace(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>).reshape(<span class="dv">100</span>,<span class="dv">1</span>)</span>
<span id="cb214-3"><a href="#cb214-3" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>torch.randn(<span class="dv">100</span>).reshape(<span class="dv">100</span>,<span class="dv">1</span>)<span class="op">*</span><span class="fl">0.01</span></span>
<span id="cb214-4"><a href="#cb214-4" aria-hidden="true" tabindex="-1"></a>xtr <span class="op">=</span> x[:<span class="dv">80</span>] </span>
<span id="cb214-5"><a href="#cb214-5" aria-hidden="true" tabindex="-1"></a>ytr <span class="op">=</span> y[:<span class="dv">80</span>]</span>
<span id="cb214-6"><a href="#cb214-6" aria-hidden="true" tabindex="-1"></a>xtest <span class="op">=</span> x[<span class="dv">80</span>:]</span>
<span id="cb214-7"><a href="#cb214-7" aria-hidden="true" tabindex="-1"></a>ytest <span class="op">=</span> y[<span class="dv">80</span>:]</span>
<span id="cb214-8"><a href="#cb214-8" aria-hidden="true" tabindex="-1"></a>plt.plot(xtr,ytr)</span>
<span id="cb214-9"><a href="#cb214-9" aria-hidden="true" tabindex="-1"></a>plt.plot(xtest,ytest)</span>
<span id="cb214-10"><a href="#cb214-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'train: blue / test: orange'</span>)<span class="op">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-145-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> train만 학습</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb215"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb215-1"><a href="#cb215-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">1</span>) </span>
<span id="cb215-2"><a href="#cb215-2" aria-hidden="true" tabindex="-1"></a>net1<span class="op">=</span>torch.nn.Sequential(</span>
<span id="cb215-3"><a href="#cb215-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">512</span>), </span>
<span id="cb215-4"><a href="#cb215-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb215-5"><a href="#cb215-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(in_features<span class="op">=</span><span class="dv">512</span>,out_features<span class="op">=</span><span class="dv">1</span>)) </span>
<span id="cb215-6"><a href="#cb215-6" aria-hidden="true" tabindex="-1"></a>optimizr1<span class="op">=</span> torch.optim.Adam(net1.parameters())</span>
<span id="cb215-7"><a href="#cb215-7" aria-hidden="true" tabindex="-1"></a>loss_fn<span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb215-8"><a href="#cb215-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb215-9"><a href="#cb215-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>): </span>
<span id="cb215-10"><a href="#cb215-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb215-11"><a href="#cb215-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># net(xtr) </span></span>
<span id="cb215-12"><a href="#cb215-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb215-13"><a href="#cb215-13" aria-hidden="true" tabindex="-1"></a>    loss<span class="op">=</span>loss_fn(net1(xtr),ytr) </span>
<span id="cb215-14"><a href="#cb215-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb215-15"><a href="#cb215-15" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb215-16"><a href="#cb215-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb215-17"><a href="#cb215-17" aria-hidden="true" tabindex="-1"></a>    optimizr1.step()</span>
<span id="cb215-18"><a href="#cb215-18" aria-hidden="true" tabindex="-1"></a>    optimizr1.zero_grad() </span></code></pre></div>
</div>
<p><code>-</code> training data로 학습한 net를 training data 에 적용</p>
<div class="cell" data-outputid="eb40b9e8-c9ce-4850-cf09-0de5c3fed59c">
<div class="sourceCode cell-code" id="cb216"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb216-1"><a href="#cb216-1" aria-hidden="true" tabindex="-1"></a>plt.plot(x,y,alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb216-2"><a href="#cb216-2" aria-hidden="true" tabindex="-1"></a>plt.plot(xtr,net1(xtr).data,<span class="st">'--'</span>) <span class="co"># prediction (train) </span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-147-output-1.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>train에서는 잘 맞추는듯이 보인다.</li>
</ul>
<p><code>-</code> training data로 학습한 net를 test data 에 적용</p>
<div class="cell" data-outputid="adb8ccde-c4a0-4d71-a0ce-900700e238e1">
<div class="sourceCode cell-code" id="cb217"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb217-1"><a href="#cb217-1" aria-hidden="true" tabindex="-1"></a>plt.plot(x,y,alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb217-2"><a href="#cb217-2" aria-hidden="true" tabindex="-1"></a>plt.plot(xtr,net1(xtr).data,<span class="st">'--'</span>) <span class="co"># prediction (train) </span></span>
<span id="cb217-3"><a href="#cb217-3" aria-hidden="true" tabindex="-1"></a>plt.plot(xtest,net1(xtest).data,<span class="st">'--'</span>) <span class="co"># prediction with unseen data (test) </span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-148-output-1.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>train은 그럭저럭 따라가지만 test에서는 엉망이다. <span class="math inline">\(\to\)</span> overfit</li>
</ul>
</section>
</section>
<section id="숙제-해설-및-풀이는-여기참고" class="level2">
<h2 class="anchored" data-anchor-id="숙제-해설-및-풀이는-여기참고">숙제 (해설 및 풀이는 <a href="https://guebin.github.io/DL2022/2022/10/06/(6%EC%A3%BC%EC%B0%A8)-10%EC%9B%946%EC%9D%BC.html#%EC%88%99%EC%A0%9C">여기</a>참고)</h2>
<ol type="1">
<li>숫자0과 숫자1을 구분하는 네트워크를 아래와 같은 구조로 설계하라</li>
</ol>
<p><span class="math display">\[\underset{(n,784)}{\bf X} \overset{l_1}{\to} \underset{(n,64)}{\boldsymbol u^{(1)}} \overset{a_1}{\to} \underset{(n,64)}{\boldsymbol v^{(1)}} \overset{l_1}{\to} \underset{(n,1)}{\boldsymbol u^{(2)}} \overset{a_2}{\to} \underset{(n,1)}{\boldsymbol v^{(2)}}=\underset{(n,1)}{\hat{\boldsymbol y}}\]</span></p>
<p>위에서 <span class="math inline">\(a_1\)</span>은 relu를, <span class="math inline">\(a_2\)</span>는 sigmoid를 의미한다.</p>
<ul>
<li>“y=0”은 숫자0을 의미하도록 하고 “y=1”은 숫자1을 의미하도록 설정하라.</li>
</ul>
<div class="cell" data-execution_count="700">
<div class="sourceCode cell-code" id="cb218"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb218-1"><a href="#cb218-1" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.MNIST)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="701">
<div class="sourceCode cell-code" id="cb219"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb219-1"><a href="#cb219-1" aria-hidden="true" tabindex="-1"></a>zero_fnames <span class="op">=</span> (path<span class="op">/</span><span class="st">'training/0'</span>).ls()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="702">
<div class="sourceCode cell-code" id="cb220"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb220-1"><a href="#cb220-1" aria-hidden="true" tabindex="-1"></a>one_fnames <span class="op">=</span> (path<span class="op">/</span><span class="st">'training/1'</span>).ls()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="703">
<div class="sourceCode cell-code" id="cb221"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb221-1"><a href="#cb221-1" aria-hidden="true" tabindex="-1"></a>X0 <span class="op">=</span> torch.stack([torchvision.io.read_image(<span class="bu">str</span>(zf)) <span class="cf">for</span> zf <span class="kw">in</span> zero_fnames])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="704">
<div class="sourceCode cell-code" id="cb222"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb222-1"><a href="#cb222-1" aria-hidden="true" tabindex="-1"></a>X1 <span class="op">=</span> torch.stack([torchvision.io.read_image(<span class="bu">str</span>(of)) <span class="cf">for</span> of <span class="kw">in</span> one_fnames])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="705">
<div class="sourceCode cell-code" id="cb223"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb223-1"><a href="#cb223-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.concat([X0,X1],axis<span class="op">=</span><span class="dv">0</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span><span class="op">*</span><span class="dv">28</span><span class="op">*</span><span class="dv">28</span>).<span class="bu">float</span>()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="709">
<div class="sourceCode cell-code" id="cb224"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb224-1"><a href="#cb224-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor([<span class="fl">0.0</span>]<span class="op">*</span><span class="bu">len</span>(X0) <span class="op">+</span> [<span class="fl">1.0</span>]<span class="op">*</span><span class="bu">len</span>(X1)).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="710">
<div class="sourceCode cell-code" id="cb225"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb225-1"><a href="#cb225-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">12345</span>)</span>
<span id="cb225-2"><a href="#cb225-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb225-3"><a href="#cb225-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">784</span>,<span class="dv">64</span>),</span>
<span id="cb225-4"><a href="#cb225-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb225-5"><a href="#cb225-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">64</span>,<span class="dv">1</span>),</span>
<span id="cb225-6"><a href="#cb225-6" aria-hidden="true" tabindex="-1"></a>    torch.nn.Sigmoid()</span>
<span id="cb225-7"><a href="#cb225-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<ol start="2" type="1">
<li>아래의 지침에 따라 200 epoch 학습을 진행하라.</li>
</ol>
<ul>
<li>손실함수는 BECLoss를 이용할 것. torch.nn.BCELoss() 를 이용할 것.</li>
<li>옵티마이저는 아담으로 설정할 것. 학습률은 lr=0.002로 설정할 것.</li>
</ul>
<div class="cell" data-execution_count="711">
<div class="sourceCode cell-code" id="cb226"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb226-1"><a href="#cb226-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.BCELoss()</span>
<span id="cb226-2"><a href="#cb226-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.002</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="712">
<div class="sourceCode cell-code" id="cb227"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb227-1"><a href="#cb227-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200</span>):</span>
<span id="cb227-2"><a href="#cb227-2" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(X)</span>
<span id="cb227-3"><a href="#cb227-3" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb227-4"><a href="#cb227-4" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb227-5"><a href="#cb227-5" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb227-6"><a href="#cb227-6" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="713">
<div class="sourceCode cell-code" id="cb228"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb228-1"><a href="#cb228-1" aria-hidden="true" tabindex="-1"></a>plt.plot(y)</span>
<span id="cb228-2"><a href="#cb228-2" aria-hidden="true" tabindex="-1"></a>plt.plot(yhat.data,<span class="st">'.'</span>,alpha<span class="op">=</span><span class="fl">0.4</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-159-output-1.png" class="img-fluid"></p>
</div>
</div>
<ol start="3" type="1">
<li>아래의 지침에 따라 200 epoch 학습을 진행하라. 학습이 잘 되는가?</li>
</ol>
<ul>
<li>손실함수는 BECLoss를 이용할 것. torch.nn.BCELoss()를 사용하지 않고 수식을 직접 입력할 것.</li>
<li>옵티마이저는 아담으로 설정할 것. 학습률은 lr=0.002로 설정할 것.</li>
</ul>
<div class="cell" data-execution_count="714">
<div class="sourceCode cell-code" id="cb229"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb229-1"><a href="#cb229-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">12345</span>)</span>
<span id="cb229-2"><a href="#cb229-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb229-3"><a href="#cb229-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">784</span>,<span class="dv">64</span>),</span>
<span id="cb229-4"><a href="#cb229-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb229-5"><a href="#cb229-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">64</span>,<span class="dv">1</span>),</span>
<span id="cb229-6"><a href="#cb229-6" aria-hidden="true" tabindex="-1"></a>    torch.nn.Sigmoid()</span>
<span id="cb229-7"><a href="#cb229-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="715">
<div class="sourceCode cell-code" id="cb230"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb230-1"><a href="#cb230-1" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.002</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="716">
<div class="sourceCode cell-code" id="cb231"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb231-1"><a href="#cb231-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200</span>):</span>
<span id="cb231-2"><a href="#cb231-2" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(X)</span>
<span id="cb231-3"><a href="#cb231-3" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="op">-</span>torch.mean(y<span class="op">*</span>torch.log(yhat) <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>y)<span class="op">*</span>torch.log(<span class="dv">1</span><span class="op">-</span>yhat))</span>
<span id="cb231-4"><a href="#cb231-4" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb231-5"><a href="#cb231-5" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb231-6"><a href="#cb231-6" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="717">
<div class="sourceCode cell-code" id="cb232"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb232-1"><a href="#cb232-1" aria-hidden="true" tabindex="-1"></a>plt.plot(y)</span>
<span id="cb232-2"><a href="#cb232-2" aria-hidden="true" tabindex="-1"></a>plt.plot(yhat.data,<span class="st">'.'</span>,alpha<span class="op">=</span><span class="fl">0.4</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-163-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="718">
<div class="sourceCode cell-code" id="cb233"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb233-1"><a href="#cb233-1" aria-hidden="true" tabindex="-1"></a>yhat.data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="718">
<pre><code>tensor([[nan],
        [nan],
        [nan],
        ...,
        [nan],
        [nan],
        [nan]])</code></pre>
</div>
</div>
<p>학습이 잘 되지 않았다.</p>
<ol start="4" type="1">
<li>아래의 지침에 따라 200 epoch 학습을 진행하라. 학습이 잘 되는가?</li>
</ol>
<ul>
<li>이미지의 값을 0과 1사이로 규격화 하라. (Xnp = Xnp/255 를 이용하세요!)</li>
<li>손실함수는 BECLoss를 이용할 것. torch.nn.BCELoss()를 사용하지 않고 수식을 직접 입력할 것.</li>
<li>옵티마이저는 아담으로 설정할 것. 학습률은 lr=0.002로 설정할 것.</li>
</ul>
<div class="cell" data-execution_count="719">
<div class="sourceCode cell-code" id="cb235"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb235-1"><a href="#cb235-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X<span class="op">/</span><span class="dv">255</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="720">
<div class="sourceCode cell-code" id="cb236"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb236-1"><a href="#cb236-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">12345</span>)</span>
<span id="cb236-2"><a href="#cb236-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb236-3"><a href="#cb236-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">784</span>,<span class="dv">64</span>),</span>
<span id="cb236-4"><a href="#cb236-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb236-5"><a href="#cb236-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">64</span>,<span class="dv">1</span>),</span>
<span id="cb236-6"><a href="#cb236-6" aria-hidden="true" tabindex="-1"></a>    torch.nn.Sigmoid()</span>
<span id="cb236-7"><a href="#cb236-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="721">
<div class="sourceCode cell-code" id="cb237"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb237-1"><a href="#cb237-1" aria-hidden="true" tabindex="-1"></a>optimizr<span class="op">=</span>torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.002</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="722">
<div class="sourceCode cell-code" id="cb238"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb238-1"><a href="#cb238-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200</span>):</span>
<span id="cb238-2"><a href="#cb238-2" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(X)</span>
<span id="cb238-3"><a href="#cb238-3" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="op">-</span>torch.mean(y<span class="op">*</span>torch.log(yhat) <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>y)<span class="op">*</span>torch.log(<span class="dv">1</span><span class="op">-</span>yhat))</span>
<span id="cb238-4"><a href="#cb238-4" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb238-5"><a href="#cb238-5" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb238-6"><a href="#cb238-6" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="723">
<div class="sourceCode cell-code" id="cb239"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb239-1"><a href="#cb239-1" aria-hidden="true" tabindex="-1"></a>plt.plot(y)</span>
<span id="cb239-2"><a href="#cb239-2" aria-hidden="true" tabindex="-1"></a>plt.plot(yhat.data,<span class="st">'.'</span>,alpha<span class="op">=</span><span class="fl">0.4</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-12-ml-6w_files/figure-html/cell-169-output-1.png" class="img-fluid"></p>
</div>
</div>
<ol start="5" type="1">
<li>아래와 같은 수식을 이용하여 accuracy를 계산하라.</li>
</ol>
<p><span class="math inline">\(\text{accuracy}=\frac{1}{n}\sum_{i=1}^n I(\tilde{y}_i=y_i)\)</span> - <span class="math inline">\(\tilde{y}_i = \begin{cases}  1 &amp; \hat{y}_i &gt; 0.5 \\  0 &amp; \hat{y}_i \leq 0.5 \end{cases}\)</span> - <span class="math inline">\(I(\tilde{y}_i=y_i) = \begin{cases} 1 &amp; \tilde{y}_i=y_i \\ 0 &amp; \tilde{y}_i \neq y_i \end{cases}\)</span></p>
<p>단, <span class="math inline">\(n\)</span>은 0과 1을 의미하는 이미지의 수</p>
<div class="cell" data-execution_count="724">
<div class="sourceCode cell-code" id="cb240"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb240-1"><a href="#cb240-1" aria-hidden="true" tabindex="-1"></a>ytilde <span class="op">=</span> (yhat <span class="op">&gt;</span> <span class="fl">0.5</span>) <span class="op">*</span> <span class="dv">1</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="725">
<div class="sourceCode cell-code" id="cb241"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb241-1"><a href="#cb241-1" aria-hidden="true" tabindex="-1"></a>ytilde</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="725">
<pre><code>tensor([[0],
        [0],
        [0],
        ...,
        [1],
        [1],
        [1]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="726">
<div class="sourceCode cell-code" id="cb243"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb243-1"><a href="#cb243-1" aria-hidden="true" tabindex="-1"></a>(ytilde <span class="op">==</span> y) <span class="op">*</span> <span class="dv">1</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="726">
<pre><code>tensor([[1],
        [1],
        [1],
        ...,
        [1],
        [1],
        [1]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="727">
<div class="sourceCode cell-code" id="cb245"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb245-1"><a href="#cb245-1" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">sum</span>((ytilde <span class="op">==</span> y) <span class="op">*</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="727">
<pre><code>tensor(12661)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="728">
<div class="sourceCode cell-code" id="cb247"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb247-1"><a href="#cb247-1" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">sum</span>((ytilde <span class="op">==</span> y) <span class="op">*</span> <span class="dv">1</span>)<span class="op">/</span><span class="bu">len</span>(y)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="728">
<pre><code>tensor(0.9997)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="730">
<div class="sourceCode cell-code" id="cb249"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb249-1"><a href="#cb249-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"accuraccy: "</span>,torch.<span class="bu">sum</span>((ytilde <span class="op">==</span> y) <span class="op">*</span> <span class="dv">1</span>)<span class="op">/</span><span class="bu">len</span>(y))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>accuraccy:  tensor(0.9997)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="731">
<div class="sourceCode cell-code" id="cb251"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb251-1"><a href="#cb251-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"accuracy: "</span>,((yhat<span class="op">&gt;</span><span class="fl">0.5</span>) <span class="op">==</span> y).<span class="bu">sum</span>() <span class="op">/</span> <span class="bu">len</span>(y))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>accuracy:  tensor(0.9997)</code></pre>
</div>
</div>
<hr>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>