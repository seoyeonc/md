<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="SEOYEON CHOI">
<meta name="dcterms.date" content="2022-11-30">

<title>Seoyeon’s Blog for classes - RNN (12주차)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Seoyeon’s Blog for classes</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../about.html" aria-current="page">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/seoyeonc/md/"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">RNN (12주차)</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title d-none d-lg-block">RNN (12주차)</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Special Topics in Machine Learning</div>
                <div class="quarto-category">순환신경망</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>SEOYEON CHOI </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 30, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../about.html" class="sidebar-item-text sidebar-link">About</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Posts</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ap/index.html" class="sidebar-item-text sidebar-link">Advanced Probability Theory</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-05-09-ap-10wk.html" class="sidebar-item-text sidebar-link">10wk: 확률변수, 분포 (2)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-07-ap_1wk.html" class="sidebar-item-text sidebar-link">1주차: 측도론</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-14-ap-2wk.html" class="sidebar-item-text sidebar-link">2주차: 측도론</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-21-ap-3wk.html" class="sidebar-item-text sidebar-link">3주차: 측도론</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-29-ap-4wk_2.html" class="sidebar-item-text sidebar-link">4wk: 측도론 (1)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-28-ap-4wk.html" class="sidebar-item-text sidebar-link">4wk: 측도론 intro (4)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-04-05-ap-5wk.html" class="sidebar-item-text sidebar-link">5wk: 측도론 (1)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-04-05-ap-5wk_2.html" class="sidebar-item-text sidebar-link">5wk: 측도론 (1)_2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-04-11-ap-6wk.html" class="sidebar-item-text sidebar-link">6wk: 측도론 (2)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-04-18-ap-7wk.html" class="sidebar-item-text sidebar-link">7wk: 측도론 (3)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-04-25-ap-8wk.html" class="sidebar-item-text sidebar-link">8wk: 확률공간,분포,확률변수</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-05-02-ap-9wk.html" class="sidebar-item-text sidebar-link">9wk: 확률변수, 분포 (1)</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/rl/index.html" class="sidebar-item-text sidebar-link">Advanced Regression Analysis</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2023-02-23-rl-final_term.html" class="sidebar-item-text sidebar-link">Advanced Regression Analysis Final Term</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2023-03-02-graduation_test.html" class="sidebar-item-text sidebar-link">Advanced Regression Analysis GT</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2023-02-22-rl-mid_term.html" class="sidebar-item-text sidebar-link">Advanced Regression Analysis Mid Term</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-09-21-rl_HW1.html" class="sidebar-item-text sidebar-link">Regression HW 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-10-23-rl-HW2.html" class="sidebar-item-text sidebar-link">Regression HW 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-21-rl-HW3.html" class="sidebar-item-text sidebar-link">Regression HW 3</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-12-08-rl-HW4.html" class="sidebar-item-text sidebar-link">Regression HW 4</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-12-11-rl-Ch10.html" class="sidebar-item-text sidebar-link">고급회귀분석 CH10</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-09-21-rl_CH03, CH04.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH03, CH04</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-14-rl_CH06, CH07.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH06, CH07</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-23-rl-CH10.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH10</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-12-05-rl-CH11.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH11</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-28-rl-CH13.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH13</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/anything/index.html" class="sidebar-item-text sidebar-link">Anything</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/2023-04-27-Clinical Trial Data and Survival Analysis.html" class="sidebar-item-text sidebar-link">Clinical Trial Data and Survival Analysis</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/2023-04-20-hazard_ratio,odds_ratio.html" class="sidebar-item-text sidebar-link">Hazard ratio, Odds ratio</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/2023-05-25-Survival_R.html" class="sidebar-item-text sidebar-link">Odds Ratio</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/2023-05-04-questions of pytorch geometric temporal.html" class="sidebar-item-text sidebar-link">Questions of PyTorch Geometric Temporal</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/2023-04-17-Survival_Analysis.html" class="sidebar-item-text sidebar-link">Survival Analysis</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ct/index.html" class="sidebar-item-text sidebar-link">Coding Test</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-15-Coding_Test_Algorithm.html" class="sidebar-item-text sidebar-link">Algorithm</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-02-12-Coding_Test.html" class="sidebar-item-text sidebar-link">ArrayList &amp; LinkedList</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-01-Coding_Test_Greedy.html" class="sidebar-item-text sidebar-link">Chapter 03 Greedy</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/Untitled.html" class="sidebar-item-text sidebar-link">Map</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-03-12-Coding_Test_Queue.html" class="sidebar-item-text sidebar-link">Queue</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-03-05-Coding_Test_Stack.html" class="sidebar-item-text sidebar-link">Stack</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-03-22-Coding_Test_Tree.html" class="sidebar-item-text sidebar-link">Tree</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-15-Coding_Test_interfunction.html" class="sidebar-item-text sidebar-link">내장함수</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-23-Coding_Test_Q2.html" class="sidebar-item-text sidebar-link">두 큐 합 같게 만들기(Done)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-21-Coding_Test_Q1.html" class="sidebar-item-text sidebar-link">성격 유형 검사하기(Done)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-30-Coding_Test_Q3.html" class="sidebar-item-text sidebar-link">코딩 테스트 공부(Done)</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ml_basic/index.html" class="sidebar-item-text sidebar-link">Machine Learning basic</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-04-09-Clustering.html" class="sidebar-item-text sidebar-link">Clustering</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-04-02-Ensemble and Random Forest.html" class="sidebar-item-text sidebar-link">Ensemble and Random Forest</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-05-09-EM_algorithm.html" class="sidebar-item-text sidebar-link">Expectation Maximization(EM algorithm)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-29-Lasso and Ridge.html" class="sidebar-item-text sidebar-link">Lasso and Ridge</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-28-Linear Regression, Logistic Regression.html" class="sidebar-item-text sidebar-link">Logistic Regression</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-05-20-Manifold learning Embedding.html" class="sidebar-item-text sidebar-link">Manifold learning Embedding</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-28-Principal Component Analysis.html" class="sidebar-item-text sidebar-link">Principal Component Analysis</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2021-03-31-Ridge Regression_note3_0331.html" class="sidebar-item-text sidebar-link">Ridge Regression</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-05-28-Sequence-to-Sequence, seq2seq.html" class="sidebar-item-text sidebar-link">Sequence-to-Sequence, seq2seq</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-23-Support Vector Machine.html" class="sidebar-item-text sidebar-link">Support Vector Machine</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ml/index.html" class="sidebar-item-text sidebar-link">Special Topics in Machine Learning</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-07-13wk.html" class="sidebar-item-text sidebar-link">A1: 깊은복사와 얕은복사 (12주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-19-Assignment-1-Copy1.html" class="sidebar-item-text sidebar-link">Assignment 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-19-ml_7w.html" class="sidebar-item-text sidebar-link">CNN (7주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-26-ml_8w_1.html" class="sidebar-item-text sidebar-link">CNN (8주차) 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-26-ml_8w_2.html" class="sidebar-item-text sidebar-link">CNN (8주차) 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-29-13wk-2-final.html" class="sidebar-item-text sidebar-link">Deep Learning final example</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-07-ml_1w.html" class="sidebar-item-text sidebar-link">DNN (1주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-14-ml_2w.html" class="sidebar-item-text sidebar-link">DNN (2주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-21-ml_3w.html" class="sidebar-item-text sidebar-link">DNN (3주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-29-ml_4w.html" class="sidebar-item-text sidebar-link">DNN (4주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-05-ml-5w.html" class="sidebar-item-text sidebar-link">DNN (5주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-12-ml-6w.html" class="sidebar-item-text sidebar-link">DNN (6주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-21-Extra-1.html" class="sidebar-item-text sidebar-link">Extra-1: 추천시스템</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-21-Extra-2.html" class="sidebar-item-text sidebar-link">Extra-2: 생성모형(GAN)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-23-Extra-3.html" class="sidebar-item-text sidebar-link">Extra-3: 딥러닝의 기초 (5)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-13-final_seoyeon.html" class="sidebar-item-text sidebar-link">Finalterm</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-05-ml-HW.html" class="sidebar-item-text sidebar-link">Homework</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-07-ml.html" class="sidebar-item-text sidebar-link">Intro</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-02-ml-midterm.html" class="sidebar-item-text sidebar-link">Midterm</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-09-ml-10w.html" class="sidebar-item-text sidebar-link">RNN (10주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-21-ml-11w.html" class="sidebar-item-text sidebar-link">RNN (11주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-30-12wk.html" class="sidebar-item-text sidebar-link active">RNN (12주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-08-13wk.html" class="sidebar-item-text sidebar-link">RNN (13주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-02-ml_9w.html" class="sidebar-item-text sidebar-link">RNN (9주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-14-study.html" class="sidebar-item-text sidebar-link">study</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ts/index.html" class="sidebar-item-text sidebar-link">Theoritical Statistics</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-25-ts-final term.html" class="sidebar-item-text sidebar-link">Theoritical Statistics Final term</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-03-03-ts-final_qanda.html" class="sidebar-item-text sidebar-link">Theoritical Statistics Final term 6 Explanation</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-03-03-graduation_test.html" class="sidebar-item-text sidebar-link">Theoritical Statistics GT</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-05-ts_HW1.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-05-ts_HW2.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-05-ts_HW3.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW3</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-09-ts_HW4.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW4</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-12-ts_HW5.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW5</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-14-ts_HW6.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW6</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-18-ts_HW7.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW7</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-18-ts-HW8.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW8</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-21-ts-HW9.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW9</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-14-ts_Mid term.html" class="sidebar-item-text sidebar-link">Theoritical Statistics Mid term</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2022-12-31-ts_1.html" class="sidebar-item-text sidebar-link">확률변수와 확률분포</a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#imports" id="toc-imports" class="nav-link active" data-scroll-target="#imports">imports</a></li>
  <li><a href="#define-some-funtions" id="toc-define-some-funtions" class="nav-link" data-scroll-target="#define-some-funtions">Define some funtions</a></li>
  <li><a href="#순환신경망-표현력-비교실험-1" id="toc-순환신경망-표현력-비교실험-1" class="nav-link" data-scroll-target="#순환신경망-표현력-비교실험-1">순환신경망 표현력 비교실험 (1)</a>
  <ul class="collapse">
  <li><a href="#data-abcabc" id="toc-data-abcabc" class="nav-link" data-scroll-target="#data-abcabc">data: abcabC</a></li>
  <li><a href="#실험" id="toc-실험" class="nav-link" data-scroll-target="#실험">실험</a></li>
  <li><a href="#결론" id="toc-결론" class="nav-link" data-scroll-target="#결론">결론</a></li>
  </ul></li>
  <li><a href="#순환신경망-표현력-비교실험-2" id="toc-순환신경망-표현력-비교실험-2" class="nav-link" data-scroll-target="#순환신경망-표현력-비교실험-2">순환신경망 표현력 비교실험 (2)</a>
  <ul class="collapse">
  <li><a href="#data-abcc" id="toc-data-abcc" class="nav-link" data-scroll-target="#data-abcc">data: ab(c,C)</a></li>
  <li><a href="#실험-1" id="toc-실험-1" class="nav-link" data-scroll-target="#실험-1">실험</a></li>
  <li><a href="#결론-1" id="toc-결론-1" class="nav-link" data-scroll-target="#결론-1">결론</a></li>
  </ul></li>
  <li><a href="#문자열에서-단어로" id="toc-문자열에서-단어로" class="nav-link" data-scroll-target="#문자열에서-단어로">문자열에서 단어로</a>
  <ul class="collapse">
  <li><a href="#data-human-numbers-5" id="toc-data-human-numbers-5" class="nav-link" data-scroll-target="#data-human-numbers-5">data: human numbers 5</a></li>
  <li><a href="#torch를-이용한-learn" id="toc-torch를-이용한-learn" class="nav-link" data-scroll-target="#torch를-이용한-learn">torch를 이용한 learn</a></li>
  <li><a href="#fastai-이용한-learn" id="toc-fastai-이용한-learn" class="nav-link" data-scroll-target="#fastai-이용한-learn">fastai 이용한 learn</a></li>
  </ul></li>
  <li><a href="#똑같은-코드들-torch.nn.lstm" id="toc-똑같은-코드들-torch.nn.lstm" class="nav-link" data-scroll-target="#똑같은-코드들-torch.nn.lstm">똑같은 코드들: <code>torch.nn.LSTM</code></a>
  <ul class="collapse">
  <li><a href="#data-hihello" id="toc-data-hihello" class="nav-link" data-scroll-target="#data-hihello">data: hi?hello!!</a></li>
  <li><a href="#세트1-_water의-생략" id="toc-세트1-_water의-생략" class="nav-link" data-scroll-target="#세트1-_water의-생략">세트1: _water의 생략</a></li>
  <li><a href="#세트2-x.shape-l-h_in-or-lnh_in" id="toc-세트2-x.shape-l-h_in-or-lnh_in" class="nav-link" data-scroll-target="#세트2-x.shape-l-h_in-or-lnh_in">세트2: x.shape = (<span class="math inline">\(L\)</span>, <span class="math inline">\(H_{in}\)</span>) or (<span class="math inline">\(L\)</span>,<span class="math inline">\(N\)</span>,<span class="math inline">\(H_{in}\)</span>)</a></li>
  <li><a href="#세트3-hidden.shape-dtimes-num_layers-h_out-or-dtimes-num_layers-n-h_out" id="toc-세트3-hidden.shape-dtimes-num_layers-h_out-or-dtimes-num_layers-n-h_out" class="nav-link" data-scroll-target="#세트3-hidden.shape-dtimes-num_layers-h_out-or-dtimes-num_layers-n-h_out">세트3: hidden.shape = (<span class="math inline">\(D\times\)</span> <code>num_layers</code>, <span class="math inline">\(H_{out}\)</span>) or (<span class="math inline">\(D\times\)</span> <code>num_layers</code>, <span class="math inline">\(N\)</span>, <span class="math inline">\(H_{out}\)</span>)</a></li>
  </ul></li>
  <li><a href="#똑같은-코드들-torch.nn.lstmcell" id="toc-똑같은-코드들-torch.nn.lstmcell" class="nav-link" data-scroll-target="#똑같은-코드들-torch.nn.lstmcell">똑같은 코드들: <code>torch.nn.LSTMCell</code></a>
  <ul class="collapse">
  <li><a href="#data-hihello-1" id="toc-data-hihello-1" class="nav-link" data-scroll-target="#data-hihello-1">data: hi?hello!!</a></li>
  <li><a href="#세트1-_water의-생략-1" id="toc-세트1-_water의-생략-1" class="nav-link" data-scroll-target="#세트1-_water의-생략-1">세트1: _water의 생략</a></li>
  <li><a href="#세트2-xt.shape-nh_in-or-h_in" id="toc-세트2-xt.shape-nh_in-or-h_in" class="nav-link" data-scroll-target="#세트2-xt.shape-nh_in-or-h_in">세트2: xt.shape = (<span class="math inline">\(N\)</span>,<span class="math inline">\(H_{in}\)</span>) or (<span class="math inline">\(H_{in}\)</span>)</a></li>
  <li><a href="#세트3-hidden.shape-nh_out-or-h_out" id="toc-세트3-hidden.shape-nh_out-or-h_out" class="nav-link" data-scroll-target="#세트3-hidden.shape-nh_out-or-h_out">세트3: hidden.shape = (<span class="math inline">\(N\)</span>,<span class="math inline">\(H_{out}\)</span>) or (<span class="math inline">\(H_{out}\)</span>)</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a>
  <ul class="collapse">
  <li><a href="#똑같은-코드들-정리" id="toc-똑같은-코드들-정리" class="nav-link" data-scroll-target="#똑같은-코드들-정리">똑같은 코드들 정리</a></li>
  <li><a href="#실제구현시-기억할-것" id="toc-실제구현시-기억할-것" class="nav-link" data-scroll-target="#실제구현시-기억할-것">실제구현시 기억할 것</a></li>
  </ul></li>
  <li><a href="#조각난-시계열로-학습" id="toc-조각난-시계열로-학습" class="nav-link" data-scroll-target="#조각난-시계열로-학습">조각난 시계열로 학습</a>
  <ul class="collapse">
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data">data</a></li>
  <li><a href="#조각내지-않은-시계열" id="toc-조각내지-않은-시계열" class="nav-link" data-scroll-target="#조각내지-않은-시계열">조각내지 않은 시계열</a></li>
  <li><a href="#조각난-시계열" id="toc-조각난-시계열" class="nav-link" data-scroll-target="#조각난-시계열">조각난 시계열</a></li>
  <li><a href="#재미있는-실험" id="toc-재미있는-실험" class="nav-link" data-scroll-target="#재미있는-실험">재미있는 실험</a></li>
  </ul></li>
  <li><a href="#똑같은-코드들-fastai-pytorch" id="toc-똑같은-코드들-fastai-pytorch" class="nav-link" data-scroll-target="#똑같은-코드들-fastai-pytorch">똑같은 코드들 fastai, pytorch</a>
  <ul class="collapse">
  <li><a href="#data-human-numbers-5-1" id="toc-data-human-numbers-5-1" class="nav-link" data-scroll-target="#data-human-numbers-5-1">data: human numbers 5</a></li>
  <li><a href="#fastai-이용한-learn-1" id="toc-fastai-이용한-learn-1" class="nav-link" data-scroll-target="#fastai-이용한-learn-1">fastai 이용한 learn</a></li>
  <li><a href="#torch를-이용한-learn-1" id="toc-torch를-이용한-learn-1" class="nav-link" data-scroll-target="#torch를-이용한-learn-1">torch를 이용한 learn</a></li>
  </ul></li>
  <li><a href="#human-numbers-100" id="toc-human-numbers-100" class="nav-link" data-scroll-target="#human-numbers-100">human numbers 100</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<blockquote class="blockquote">
<p>순환신경망 minor topics</p>
</blockquote>
<section id="imports" class="level1">
<h1>imports</h1>
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.text.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pytorch_lightning <span class="im">as</span> pl </span></code></pre></div>
</div>
</section>
<section id="define-some-funtions" class="level1">
<h1>Define some funtions</h1>
<div class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(txt,mapping):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [mapping[key] <span class="cf">for</span> key <span class="kw">in</span> txt] </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>soft <span class="op">=</span> torch.nn.Softmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>tanh <span class="op">=</span> torch.nn.Tanh()</span></code></pre></div>
</div>
</section>
<section id="순환신경망-표현력-비교실험-1" class="level1">
<h1>순환신경망 표현력 비교실험 (1)</h1>
<section id="data-abcabc" class="level2">
<h2 class="anchored" data-anchor-id="data-abcabc">data: abcabC</h2>
<div class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'abcabC'</span>)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>txt[:<span class="dv">8</span>]</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>txt_x <span class="op">=</span> txt[:<span class="op">-</span><span class="dv">1</span>] </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>txt_y <span class="op">=</span> txt[<span class="dv">1</span>:]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>mapping <span class="op">=</span> {<span class="st">'a'</span>:<span class="dv">0</span>,<span class="st">'b'</span>:<span class="dv">1</span>,<span class="st">'c'</span>:<span class="dv">2</span>,<span class="st">'C'</span>:<span class="dv">3</span>} </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).<span class="bu">float</span>()</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).<span class="bu">float</span>()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.to(<span class="st">"cuda:0"</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y.to(<span class="st">"cuda:0"</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>x.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>torch.Size([599, 4])</code></pre>
</div>
</div>
</section>
<section id="실험" class="level2">
<h2 class="anchored" data-anchor-id="실험">실험</h2>
<p><code>-</code> 실험1</p>
<div class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>HIDDEN <span class="op">=</span> <span class="dv">3</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>        rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,HIDDEN).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>        linr <span class="op">=</span> torch.nn.Linear(HIDDEN,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,HIDDEN).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">500</span>):</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>            hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> linr(hidden)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(output,y)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>        yhat<span class="op">=</span>soft(output)    </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>        combind <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(combind.to(<span class="st">"cpu"</span>).data[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">"experiment1: RNN with </span><span class="sc">{}</span><span class="st"> hidden nodes"</span>.<span class="bu">format</span>(HIDDEN),size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-30-12wk_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 실험2</p>
<div class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>HIDDEN <span class="op">=</span> <span class="dv">4</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,HIDDEN).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>        linr <span class="op">=</span> torch.nn.Linear(HIDDEN,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,HIDDEN).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">500</span>):</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>            hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> linr(hidden)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(output,y)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>        yhat<span class="op">=</span>soft(output)    </span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>        combind <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(combind.to(<span class="st">"cpu"</span>).data[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">"experiment2: RNN with </span><span class="sc">{}</span><span class="st"> hidden nodes"</span>.<span class="bu">format</span>(HIDDEN),size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-30-12wk_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 실험3</p>
<div class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>HIDDEN <span class="op">=</span> <span class="dv">8</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">8</span>))</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>        rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,HIDDEN).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>        linr <span class="op">=</span> torch.nn.Linear(HIDDEN,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>        _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,HIDDEN).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">500</span>):</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>            hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> linr(hidden)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(output,y)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>        yhat<span class="op">=</span>soft(output)    </span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>        combind <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(combind.to(<span class="st">"cpu"</span>).data[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">"experiment3: RNN with </span><span class="sc">{}</span><span class="st"> hidden nodes"</span>.<span class="bu">format</span>(HIDDEN),size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-30-12wk_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="결론" class="level2">
<h2 class="anchored" data-anchor-id="결론">결론</h2>
<p><code>-</code> 노드수가 많으면 학습에 유리함</p>
<p>(서연 필기) c/C를 맞추는 것(error)보다 확실한 규칙을 맞추는 것(underline)이 중요<span class="math inline">\(\to\)</span>오히려 맞추면 과적합으로 볼 수 있다 - 그래서 학습이 잘 되었으면 - 첫 칸 - 둘째 칸 - 셋쨰, 넷째 칸 - 이 순으로 predict 되었을 것</p>
</section>
</section>
<section id="순환신경망-표현력-비교실험-2" class="level1">
<h1>순환신경망 표현력 비교실험 (2)</h1>
<section id="data-abcc" class="level2">
<h2 class="anchored" data-anchor-id="data-abcc">data: ab(c,C)</h2>
<div class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># torch.manual_seed(43052)</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># txta = 'a'*50</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># txtb = 'b'*50</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># prob_upper = torch.bernoulli(torch.zeros(50)+0.5) </span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># txtc = list(map(lambda x: 'c' if x==1 else 'C', prob_upper))</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># txt = ''.join([txta[i]+','+txtb[i]+','+txtc[i]+',' for i in range(50)]).split(',')[:-1]</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co"># txt_x = txt[:-1] </span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># txt_y = txt[1:]</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># pd.DataFrame({'txt_x':txt_x,'txt_y':txt_y}).to_csv("2022-11-25-ab(c,C).csv",index=False)</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span> pd.read_csv(<span class="st">"https://raw.githubusercontent.com/guebin/DL2022/main/posts/IV.%20RNN/2022-11-25-ab(c%2CC).csv"</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="89">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>txt_x</th>
      <th>txt_y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>a</td>
      <td>b</td>
    </tr>
    <tr>
      <th>1</th>
      <td>b</td>
      <td>c</td>
    </tr>
    <tr>
      <th>2</th>
      <td>c</td>
      <td>a</td>
    </tr>
    <tr>
      <th>3</th>
      <td>a</td>
      <td>b</td>
    </tr>
    <tr>
      <th>4</th>
      <td>b</td>
      <td>c</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>144</th>
      <td>a</td>
      <td>b</td>
    </tr>
    <tr>
      <th>145</th>
      <td>b</td>
      <td>C</td>
    </tr>
    <tr>
      <th>146</th>
      <td>C</td>
      <td>a</td>
    </tr>
    <tr>
      <th>147</th>
      <td>a</td>
      <td>b</td>
    </tr>
    <tr>
      <th>148</th>
      <td>b</td>
      <td>c</td>
    </tr>
  </tbody>
</table>
<p>149 rows × 2 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>mapping <span class="op">=</span> {<span class="st">'a'</span>:<span class="dv">0</span>,<span class="st">'b'</span>:<span class="dv">1</span>,<span class="st">'c'</span>:<span class="dv">2</span>,<span class="st">'C'</span>:<span class="dv">3</span>} </span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(df.txt_x,mapping))).<span class="bu">float</span>()</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(df.txt_y,mapping))).<span class="bu">float</span>()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="91">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.to(<span class="st">"cuda:0"</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y.to(<span class="st">"cuda:0"</span>) </span></code></pre></div>
</div>
</section>
<section id="실험-1" class="level2">
<h2 class="anchored" data-anchor-id="실험-1">실험</h2>
<p><code>-</code> 실험1</p>
<div class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>HIDDEN <span class="op">=</span> <span class="dv">3</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>        lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">4</span>,HIDDEN).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>        linr <span class="op">=</span> torch.nn.Linear(HIDDEN,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>        _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,HIDDEN).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">500</span>):</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>            hidden, (hT,cT) <span class="op">=</span> lstm(x,(_water,_water))</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> linr(hidden)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(output,y)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>        yhat<span class="op">=</span>soft(output)    </span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>        combinded <span class="op">=</span> torch.concat([yhat,y],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(combinded.to(<span class="st">"cpu"</span>).data[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">"experiment1: LSTM with </span><span class="sc">{}</span><span class="st"> hidden nodes"</span>.<span class="bu">format</span>(HIDDEN),size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-30-12wk_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 실험2</p>
<div class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>HIDDEN <span class="op">=</span> <span class="dv">16</span></span></code></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="95">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>        lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">4</span>,HIDDEN).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>        linr <span class="op">=</span> torch.nn.Linear(HIDDEN,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>        _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,HIDDEN).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">500</span>):</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>            hidden, (hT,cT) <span class="op">=</span> lstm(x,(_water,_water))</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> linr(hidden)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(output,y)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>        yhat<span class="op">=</span>soft(output)    </span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>        combinded <span class="op">=</span> torch.concat([yhat,y],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(combinded.to(<span class="st">"cpu"</span>).data[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">"experiment2: LSTM with </span><span class="sc">{}</span><span class="st"> hidden nodes"</span>.<span class="bu">format</span>(HIDDEN),size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-30-12wk_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="결론-1" class="level2">
<h2 class="anchored" data-anchor-id="결론-1">결론</h2>
<p><code>-</code> 노드수가 너무 많으면 오버피팅 경향도 있음</p>
</section>
</section>
<section id="문자열에서-단어로" class="level1">
<h1>문자열에서 단어로</h1>
<section id="data-human-numbers-5" class="level2">
<h2 class="anchored" data-anchor-id="data-human-numbers-5">data: human numbers 5</h2>
<div class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> ([<span class="st">'one'</span>,<span class="st">','</span>,<span class="st">'two'</span>,<span class="st">','</span>,<span class="st">'three'</span>,<span class="st">','</span>,<span class="st">'four'</span>,<span class="st">','</span>,<span class="st">'five'</span>,<span class="st">','</span>]<span class="op">*</span><span class="dv">100</span>)[:<span class="op">-</span><span class="dv">1</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>mapping <span class="op">=</span> {<span class="st">','</span>:<span class="dv">0</span>, <span class="st">'one'</span>:<span class="dv">1</span>, <span class="st">'two'</span>:<span class="dv">2</span>, <span class="st">'three'</span>:<span class="dv">3</span>, <span class="st">'four'</span>:<span class="dv">4</span>, <span class="st">'five'</span>:<span class="dv">5</span>} </span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>mapping</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<pre><code>{',': 0, 'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="98">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>txt_x <span class="op">=</span> txt[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>txt_y <span class="op">=</span> txt[<span class="dv">1</span>:] </span></code></pre></div>
</div>
<div class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>txt_x[<span class="dv">0</span>:<span class="dv">5</span>], txt_y[<span class="dv">0</span>:<span class="dv">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="99">
<pre><code>(['one', ',', 'two', ',', 'three'], [',', 'two', ',', 'three', ','])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).<span class="bu">float</span>().to(<span class="st">"cuda:0"</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).<span class="bu">float</span>().to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
</section>
<section id="torch를-이용한-learn" class="level2">
<h2 class="anchored" data-anchor-id="torch를-이용한-learn">torch를 이용한 learn</h2>
<div class="cell" data-execution_count="101">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">6</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>) </span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">6</span>).to(<span class="st">"cuda:0"</span>) </span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="102">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    hidden, (hT,cT) <span class="op">=</span>lstm(x,(_water,_water))</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()     </span></code></pre></div>
</div>
<div class="cell" data-execution_count="103">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(soft(output).data[<span class="op">-</span><span class="dv">10</span>:].to(<span class="st">"cpu"</span>),cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="103">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f568441a1d0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-30-12wk_files/figure-html/cell-29-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="fastai-이용한-learn" class="level2">
<h2 class="anchored" data-anchor-id="fastai-이용한-learn">fastai 이용한 learn</h2>
<div class="cell" data-execution_count="104">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>ds1 <span class="op">=</span> torch.utils.data.TensorDataset(x,y)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>ds2 <span class="op">=</span> torch.utils.data.TensorDataset(x,y) <span class="co"># dummy </span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>dl1 <span class="op">=</span> torch.utils.data.DataLoader(ds1,batch_size<span class="op">=</span><span class="dv">998</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>dl2 <span class="op">=</span> torch.utils.data.DataLoader(ds2,batch_size<span class="op">=</span><span class="dv">998</span>) <span class="co"># dummy </span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> DataLoaders(dl1,dl2) </span></code></pre></div>
</div>
<p>fastai 를 이용하여 class를 사용하기 위한 목차</p>
<div class="cell" data-execution_count="105">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyLSTM(torch.nn.Module):</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">6</span>,<span class="dv">20</span>)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">6</span>) </span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,x):</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>        _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>        hidden, (hT,cT) <span class="op">=</span><span class="va">self</span>.lstm(x,(_water,_water))</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.linr(hidden)</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output         </span></code></pre></div>
</div>
<div class="cell" data-execution_count="106">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> MyLSTM().to(<span class="st">"cuda:0"</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="107">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>lrnr <span class="op">=</span> Learner(dls,net,loss_fn,lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="108">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>lrnr.fit(<span class="dv">50</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.722138</td>
      <td>1.502271</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.611093</td>
      <td>1.973368</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.734299</td>
      <td>1.481888</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.669271</td>
      <td>1.377668</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.608570</td>
      <td>1.368541</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.566517</td>
      <td>1.267919</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>6</td>
      <td>1.521232</td>
      <td>1.106543</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>7</td>
      <td>1.465657</td>
      <td>0.959904</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>8</td>
      <td>1.404815</td>
      <td>0.856123</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>9</td>
      <td>1.344825</td>
      <td>0.802936</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>10</td>
      <td>1.290437</td>
      <td>0.794831</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>11</td>
      <td>1.244395</td>
      <td>0.771966</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>12</td>
      <td>1.203488</td>
      <td>0.735865</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>13</td>
      <td>1.165525</td>
      <td>0.690032</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>14</td>
      <td>1.129149</td>
      <td>0.621654</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>15</td>
      <td>1.092401</td>
      <td>0.555875</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>16</td>
      <td>1.055485</td>
      <td>0.493046</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>17</td>
      <td>1.018588</td>
      <td>0.423167</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>18</td>
      <td>0.981230</td>
      <td>0.349703</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>19</td>
      <td>0.943231</td>
      <td>0.279531</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>20</td>
      <td>0.904838</td>
      <td>0.216544</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>21</td>
      <td>0.866475</td>
      <td>0.166756</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>22</td>
      <td>0.828821</td>
      <td>0.125583</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>23</td>
      <td>0.792214</td>
      <td>0.094763</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>24</td>
      <td>0.757037</td>
      <td>0.072662</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>25</td>
      <td>0.723539</td>
      <td>0.055544</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>26</td>
      <td>0.691763</td>
      <td>0.042442</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>27</td>
      <td>0.661703</td>
      <td>0.032804</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>28</td>
      <td>0.633335</td>
      <td>0.025908</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>29</td>
      <td>0.606606</td>
      <td>0.020872</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>30</td>
      <td>0.581437</td>
      <td>0.017020</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>31</td>
      <td>0.557727</td>
      <td>0.014002</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>32</td>
      <td>0.535379</td>
      <td>0.011625</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>33</td>
      <td>0.514297</td>
      <td>0.009755</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>34</td>
      <td>0.494391</td>
      <td>0.008293</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>35</td>
      <td>0.475579</td>
      <td>0.007180</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>36</td>
      <td>0.457784</td>
      <td>0.006386</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>37</td>
      <td>0.440938</td>
      <td>0.005807</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>38</td>
      <td>0.424976</td>
      <td>0.005199</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>39</td>
      <td>0.409830</td>
      <td>0.004525</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>40</td>
      <td>0.395437</td>
      <td>0.003926</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>41</td>
      <td>0.381747</td>
      <td>0.003398</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>42</td>
      <td>0.368712</td>
      <td>0.002977</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>43</td>
      <td>0.356291</td>
      <td>0.002673</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>44</td>
      <td>0.344447</td>
      <td>0.002432</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>45</td>
      <td>0.333144</td>
      <td>0.002230</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>46</td>
      <td>0.322349</td>
      <td>0.002058</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>47</td>
      <td>0.312030</td>
      <td>0.001911</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>48</td>
      <td>0.302160</td>
      <td>0.001785</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>49</td>
      <td>0.292712</td>
      <td>0.001678</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution_count="109">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(soft(lrnr.model(x)[<span class="op">-</span><span class="dv">10</span>:]).data.to(<span class="st">"cpu"</span>),cmap <span class="op">=</span> <span class="st">'bwr'</span>, vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="109">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f5687137bd0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-30-12wk_files/figure-html/cell-35-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="똑같은-코드들-torch.nn.lstm" class="level1">
<h1>똑같은 코드들: <code>torch.nn.LSTM</code></h1>
<section id="data-hihello" class="level2">
<h2 class="anchored" data-anchor-id="data-hihello">data: hi?hello!!</h2>
<div class="cell" data-execution_count="110">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'hi?hello!!'</span>)<span class="op">*</span><span class="dv">100</span> </span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>txt_x <span class="op">=</span> txt[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>txt_y <span class="op">=</span> txt[<span class="dv">1</span>:]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="111">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>mapping <span class="op">=</span> {<span class="st">'!'</span>:<span class="dv">0</span>, <span class="st">'?'</span>:<span class="dv">1</span>,<span class="st">'h'</span>:<span class="dv">2</span>,<span class="st">'i'</span>:<span class="dv">3</span>,<span class="st">'e'</span>:<span class="dv">4</span>,<span class="st">'l'</span>:<span class="dv">5</span>,<span class="st">'o'</span>:<span class="dv">6</span>} </span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).<span class="bu">float</span>().to(<span class="st">"cuda:0"</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).<span class="bu">float</span>().to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
</section>
<section id="세트1-_water의-생략" class="level2">
<h2 class="anchored" data-anchor-id="세트1-_water의-생략">세트1: _water의 생략</h2>
<p><code>-</code> 코드1: 정석코드</p>
<div class="cell" data-execution_count="112">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">7</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>lstm(x, (_water,_water))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="113">
<pre><code>(tensor([[-0.1547,  0.0673,  0.0695,  0.1563],
         [-0.0786, -0.1430, -0.0250,  0.1189],
         [-0.0300, -0.2256, -0.1324,  0.1439],
         ...,
         [-0.0723,  0.0620,  0.1913,  0.2015],
         [-0.1155,  0.0746,  0.1747,  0.2938],
         [-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',
        grad_fn=&lt;SqueezeBackward1&gt;),
 (tensor([[-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',
         grad_fn=&lt;SqueezeBackward1&gt;),
  tensor([[-0.4451, -0.2456, -0.1900,  0.6232]], device='cuda:0',
         grad_fn=&lt;SqueezeBackward1&gt;)))</code></pre>
</div>
</div>
<p><code>-</code> 코드2: _water 는 사실 없어도 괜찮았어..</p>
<div class="cell" data-execution_count="114">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">7</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="115">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>lstm(x)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="115">
<pre><code>(tensor([[-0.1547,  0.0673,  0.0695,  0.1563],
         [-0.0786, -0.1430, -0.0250,  0.1189],
         [-0.0300, -0.2256, -0.1324,  0.1439],
         ...,
         [-0.0723,  0.0620,  0.1913,  0.2015],
         [-0.1155,  0.0746,  0.1747,  0.2938],
         [-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',
        grad_fn=&lt;SqueezeBackward1&gt;),
 (tensor([[-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',
         grad_fn=&lt;SqueezeBackward1&gt;),
  tensor([[-0.4451, -0.2456, -0.1900,  0.6232]], device='cuda:0',
         grad_fn=&lt;SqueezeBackward1&gt;)))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="116">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>x.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="116">
<pre><code>torch.Size([999, 7])</code></pre>
</div>
</div>
<p>999개, 구별되는 문자 7개</p>
</section>
<section id="세트2-x.shape-l-h_in-or-lnh_in" class="level2">
<h2 class="anchored" data-anchor-id="세트2-x.shape-l-h_in-or-lnh_in">세트2: x.shape = (<span class="math inline">\(L\)</span>, <span class="math inline">\(H_{in}\)</span>) or (<span class="math inline">\(L\)</span>,<span class="math inline">\(N\)</span>,<span class="math inline">\(H_{in}\)</span>)</h2>
<p><code>-</code> 파라메터 설명</p>
<ul>
<li><span class="math inline">\(L\)</span> = sequece length = 시계열의 길이 = 간장을 몇 년 전통으로 이어갈지</li>
<li><span class="math inline">\(N\)</span> = batch size = 전체데이터는 몇 개의 시계열이 있는지 = 전체 데이터를 몇개의 시계열로 쪼갤지 &lt;– 왜 이걸 해야해?</li>
<li><span class="math inline">\(H_{in}\)</span> = input_size = 시점을 고정하였을 경우 입력자료의 차원 = 입력시계열이 시점별로 몇개의 변수로 나타내어 지는지? = 만약에 원핫인코딩으로 단어를 정리하면 단어수를 의미함</li>
</ul>
<p>우리가 실습했던 거 모두 N이 1이었다 그래서 안 썼음 - 1일 때만 아래와 같이 여러 버전 가능</p>
<p><code>-</code> 코드2: _water 는 사실 없어도 괜찮았어..</p>
<div class="cell" data-execution_count="117">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">7</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="118">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>lstm(x)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="118">
<pre><code>(tensor([[-0.1547,  0.0673,  0.0695,  0.1563],
         [-0.0786, -0.1430, -0.0250,  0.1189],
         [-0.0300, -0.2256, -0.1324,  0.1439],
         ...,
         [-0.0723,  0.0620,  0.1913,  0.2015],
         [-0.1155,  0.0746,  0.1747,  0.2938],
         [-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',
        grad_fn=&lt;SqueezeBackward1&gt;),
 (tensor([[-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',
         grad_fn=&lt;SqueezeBackward1&gt;),
  tensor([[-0.4451, -0.2456, -0.1900,  0.6232]], device='cuda:0',
         grad_fn=&lt;SqueezeBackward1&gt;)))</code></pre>
</div>
</div>
<p><code>-</code> 코드3: x의 차원은 사실 엄밀하게는 (<span class="math inline">\(L\)</span>,<span class="math inline">\(N\)</span>,<span class="math inline">\(H_{in}\)</span>) 와 같다…</p>
<div class="cell" data-execution_count="119">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">7</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="120">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>lstm(x.reshape(<span class="dv">999</span>,<span class="dv">1</span>,<span class="dv">7</span>))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="120">
<pre><code>(tensor([[[-0.1547,  0.0673,  0.0695,  0.1563]],
 
         [[-0.0786, -0.1430, -0.0250,  0.1189]],
 
         [[-0.0300, -0.2256, -0.1324,  0.1439]],
 
         ...,
 
         [[-0.0723,  0.0620,  0.1913,  0.2015]],
 
         [[-0.1155,  0.0746,  0.1747,  0.2938]],
 
         [[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',
        grad_fn=&lt;CudnnRnnBackward0&gt;),
 (tensor([[[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',
         grad_fn=&lt;CudnnRnnBackward0&gt;),
  tensor([[[-0.4451, -0.2456, -0.1900,  0.6232]]], device='cuda:0',
         grad_fn=&lt;CudnnRnnBackward0&gt;)))</code></pre>
</div>
</div>
<p><code>-</code> 코드4: <code>batch_first=True</code>옵션을 사용하여 lstm을 만든경우</p>
<div class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">7</span>,<span class="dv">4</span>,batch_first<span class="op">=</span><span class="va">True</span>).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="122">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>lstm(x.reshape(<span class="dv">1</span>,<span class="dv">999</span>,<span class="dv">7</span>))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="122">
<pre><code>(tensor([[[-0.1547,  0.0673,  0.0695,  0.1563],
          [-0.0786, -0.1430, -0.0250,  0.1189],
          [-0.0300, -0.2256, -0.1324,  0.1439],
          ...,
          [-0.0723,  0.0620,  0.1913,  0.2015],
          [-0.1155,  0.0746,  0.1747,  0.2938],
          [-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',
        grad_fn=&lt;CudnnRnnBackward0&gt;),
 (tensor([[[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',
         grad_fn=&lt;CudnnRnnBackward0&gt;),
  tensor([[[-0.4451, -0.2456, -0.1900,  0.6232]]], device='cuda:0',
         grad_fn=&lt;CudnnRnnBackward0&gt;)))</code></pre>
</div>
</div>
</section>
<section id="세트3-hidden.shape-dtimes-num_layers-h_out-or-dtimes-num_layers-n-h_out" class="level2">
<h2 class="anchored" data-anchor-id="세트3-hidden.shape-dtimes-num_layers-h_out-or-dtimes-num_layers-n-h_out">세트3: hidden.shape = (<span class="math inline">\(D\times\)</span> <code>num_layers</code>, <span class="math inline">\(H_{out}\)</span>) or (<span class="math inline">\(D\times\)</span> <code>num_layers</code>, <span class="math inline">\(N\)</span>, <span class="math inline">\(H_{out}\)</span>)</h2>
<p><code>-</code> 파라메터 설명</p>
<ul>
<li><span class="math inline">\(D\)</span> = 2 if bidirectional=True otherwise 1 = 양방향이면 2, 단방향이면 1 (우리는 단방향만 배움)</li>
<li><code>num_layres</code> = 중첩된 RNN일 경우 (우리는 중첩을 안시켰음)</li>
<li><span class="math inline">\(N\)</span> = batch size = 전체데이터는 몇 개의 시계열이 있는지 = 전체 데이터를 몇개의 시계열로 쪼갤지 &lt;– 왜 이걸 해야해?</li>
<li><span class="math inline">\(H_{out}\)</span> = 히든노드의 수</li>
</ul>
<p><code>-</code> 코드5: x.shape = (<span class="math inline">\(L\)</span>,<span class="math inline">\(1\)</span>,<span class="math inline">\(H_{in}\)</span>) <span class="math inline">\(\to\)</span> hidden.shape = (<span class="math inline">\(1\)</span>,<span class="math inline">\(1\)</span>,<span class="math inline">\(H_{out}\)</span>)</p>
<div class="cell" data-execution_count="123">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">7</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="124">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>) </span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>lstm(x.reshape(<span class="dv">999</span>,<span class="dv">1</span>,<span class="dv">7</span>),(_water,_water))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="124">
<pre><code>(tensor([[[-0.1547,  0.0673,  0.0695,  0.1563]],
 
         [[-0.0786, -0.1430, -0.0250,  0.1189]],
 
         [[-0.0300, -0.2256, -0.1324,  0.1439]],
 
         ...,
 
         [[-0.0723,  0.0620,  0.1913,  0.2015]],
 
         [[-0.1155,  0.0746,  0.1747,  0.2938]],
 
         [[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',
        grad_fn=&lt;CudnnRnnBackward0&gt;),
 (tensor([[[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',
         grad_fn=&lt;CudnnRnnBackward0&gt;),
  tensor([[[-0.4451, -0.2456, -0.1900,  0.6232]]], device='cuda:0',
         grad_fn=&lt;CudnnRnnBackward0&gt;)))</code></pre>
</div>
</div>
<p><code>-</code> 사실 _water.shape = (1,<span class="math inline">\(H_{out}\)</span>) 에서 1은 observation의 차원을 의미하는게 아님 (그런데 대충 그렇게 생각해도 무방함)</p>
<ul>
<li>한 시점의 콩물에 대하여 양방향으로 간장을 만들면 _water.shape = (2,h)</li>
<li>한 시점의 콩물에 대하여 3중첩으로 간장을 만들면 _water.shape = (3,h)</li>
<li>한 시점의 콩물에 대하여 3중첩간장을 양방향으로 만들면 _water.shape = (6,h)</li>
</ul>
</section>
</section>
<section id="똑같은-코드들-torch.nn.lstmcell" class="level1">
<h1>똑같은 코드들: <code>torch.nn.LSTMCell</code></h1>
<section id="data-hihello-1" class="level2">
<h2 class="anchored" data-anchor-id="data-hihello-1">data: hi?hello!!</h2>
<div class="cell" data-execution_count="125">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'hi?hello!!'</span>)<span class="op">*</span><span class="dv">100</span> </span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>txt_x <span class="op">=</span> txt[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>txt_y <span class="op">=</span> txt[<span class="dv">1</span>:]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="126">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>mapping <span class="op">=</span> {<span class="st">'!'</span>:<span class="dv">0</span>, <span class="st">'?'</span>:<span class="dv">1</span>,<span class="st">'h'</span>:<span class="dv">2</span>,<span class="st">'i'</span>:<span class="dv">3</span>,<span class="st">'e'</span>:<span class="dv">4</span>,<span class="st">'l'</span>:<span class="dv">5</span>,<span class="st">'o'</span>:<span class="dv">6</span>} </span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).<span class="bu">float</span>().to(<span class="st">"cuda:0"</span>)</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).<span class="bu">float</span>().to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
</section>
<section id="세트1-_water의-생략-1" class="level2">
<h2 class="anchored" data-anchor-id="세트1-_water의-생략-1">세트1: _water의 생략</h2>
<p><code>-</code> 코드1: 정석코드</p>
<div class="cell" data-execution_count="127">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>lstmcell <span class="op">=</span> torch.nn.LSTMCell(<span class="dv">7</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="128">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>xt <span class="op">=</span> x[[<span class="dv">1</span>]]</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>xt.shape, _water.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="128">
<pre><code>(torch.Size([1, 7]), torch.Size([1, 4]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="129">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>lstmcell(xt,(_water,_water))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="129">
<pre><code>(tensor([[-0.0290, -0.1758, -0.0537,  0.0598]], device='cuda:0',
        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;),
 tensor([[-0.0582, -0.4566, -0.1256,  0.1922]], device='cuda:0',
        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;))</code></pre>
</div>
</div>
<p><code>-</code> 코드2: _water의 생략</p>
<div class="cell" data-execution_count="130">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>lstmcell <span class="op">=</span> torch.nn.LSTMCell(<span class="dv">7</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="131">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>xt <span class="op">=</span> x[[<span class="dv">1</span>]]</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>xt.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="131">
<pre><code>torch.Size([1, 7])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="132">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>lstmcell(xt)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="132">
<pre><code>(tensor([[-0.0290, -0.1758, -0.0537,  0.0598]], device='cuda:0',
        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;),
 tensor([[-0.0582, -0.4566, -0.1256,  0.1922]], device='cuda:0',
        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;))</code></pre>
</div>
</div>
</section>
<section id="세트2-xt.shape-nh_in-or-h_in" class="level2">
<h2 class="anchored" data-anchor-id="세트2-xt.shape-nh_in-or-h_in">세트2: xt.shape = (<span class="math inline">\(N\)</span>,<span class="math inline">\(H_{in}\)</span>) or (<span class="math inline">\(H_{in}\)</span>)</h2>
<p>n: timeserie 개수, 1일 경우 생략 가능</p>
<p><code>-</code> 코드2: _water의 생략</p>
<div class="cell" data-execution_count="133">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>lstmcell <span class="op">=</span> torch.nn.LSTMCell(<span class="dv">7</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="134">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>xt <span class="op">=</span> x[[<span class="dv">1</span>]]</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>xt.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="134">
<pre><code>torch.Size([1, 7])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="135">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>lstmcell(xt)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="135">
<pre><code>(tensor([[-0.0290, -0.1758, -0.0537,  0.0598]], device='cuda:0',
        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;),
 tensor([[-0.0582, -0.4566, -0.1256,  0.1922]], device='cuda:0',
        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;))</code></pre>
</div>
</div>
<p><code>-</code> 코드3:</p>
<div class="cell" data-execution_count="136">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>lstmcell <span class="op">=</span> torch.nn.LSTMCell(<span class="dv">7</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="137">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>xt <span class="op">=</span> x[<span class="dv">1</span>]</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>xt.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="137">
<pre><code>torch.Size([7])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="138">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>lstmcell(xt)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="138">
<pre><code>(tensor([-0.0290, -0.1758, -0.0537,  0.0598], device='cuda:0',
        grad_fn=&lt;SqueezeBackward1&gt;),
 tensor([-0.0582, -0.4566, -0.1256,  0.1922], device='cuda:0',
        grad_fn=&lt;SqueezeBackward1&gt;))</code></pre>
</div>
</div>
<p>(1,n)의 형태라면 괄호 하나 빼도 가능</p>
</section>
<section id="세트3-hidden.shape-nh_out-or-h_out" class="level2">
<h2 class="anchored" data-anchor-id="세트3-hidden.shape-nh_out-or-h_out">세트3: hidden.shape = (<span class="math inline">\(N\)</span>,<span class="math inline">\(H_{out}\)</span>) or (<span class="math inline">\(H_{out}\)</span>)</h2>
<p><code>-</code> 코드4: xt.shape = (<span class="math inline">\(H_{out}\)</span>) <span class="math inline">\(\to\)</span> _water.shape = <span class="math inline">\((H_{out})\)</span></p>
<div class="cell" data-execution_count="139">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>lstmcell <span class="op">=</span> torch.nn.LSTMCell(<span class="dv">7</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="140">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>xt <span class="op">=</span> x[<span class="dv">1</span>]</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>xt.shape,_water.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="140">
<pre><code>(torch.Size([7]), torch.Size([4]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="141">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>lstmcell(xt, (_water,_water))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="141">
<pre><code>(tensor([-0.0290, -0.1758, -0.0537,  0.0598], device='cuda:0',
        grad_fn=&lt;SqueezeBackward1&gt;),
 tensor([-0.0582, -0.4566, -0.1256,  0.1922], device='cuda:0',
        grad_fn=&lt;SqueezeBackward1&gt;))</code></pre>
</div>
</div>
</section>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<section id="똑같은-코드들-정리" class="level2">
<h2 class="anchored" data-anchor-id="똑같은-코드들-정리">똑같은 코드들 정리</h2>
<p><code>-</code> 원래 1은 단순히 observation의 차원이 아니다. 즉 <span class="math inline">\({\bf X}_{n \times p}\)</span>에서 <span class="math inline">\(n\)</span>에 대응하는 차원으로 생각할 수 없다.</p>
<p><code>-</code> 그런데 (1) 단방향 (2) 조각내지 않은 시계열 (3) 중첩하지 않은 순환망에 한정하여서는 observation 처럼 생각해도 무방하다. &lt;– 엄밀하게는 이게 위험한 생각임. 하지만 정식으로 모두 따지려면 너무 헷갈림</p>
</section>
<section id="실제구현시-기억할-것" class="level2">
<h2 class="anchored" data-anchor-id="실제구현시-기억할-것">실제구현시 기억할 것</h2>
<p><code>-</code> 현실적으로 (1)-(3)이 아닌 조건에서는 Cell 단위로 연산을 이용할 일이 없다. (느리거든요) // 그냥 이해용으로 구현</p>
<p><code>-</code> torch.nn.RNN 혹은 torch.nn.LSTM 으로 네트워크를 구성할시 _water의 dim을 명시할 일도 없다.</p>
<p><code>-</code> 오로지 고려해야 할 것은 입력시계열을 조각낼지 조각내지 않을지</p>
</section>
</section>
<section id="조각난-시계열로-학습" class="level1">
<h1>조각난 시계열로 학습</h1>
<p>시계열이 무조건 연속으로서 데이터가 존재하지 않는다면? - 댓글 1의 길이는 400 - 댓글 2 의 길이는 100 이럴수도</p>
<section id="data" class="level2">
<h2 class="anchored" data-anchor-id="data">data</h2>
<div class="cell" data-execution_count="142">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'hi!'</span>)<span class="op">*</span><span class="dv">3</span> <span class="op">+</span> <span class="bu">list</span>(<span class="st">'hi?'</span>)<span class="op">*</span><span class="dv">3</span> </span></code></pre></div>
</div>
</section>
<section id="조각내지-않은-시계열" class="level2">
<h2 class="anchored" data-anchor-id="조각내지-않은-시계열">조각내지 않은 시계열</h2>
<div class="cell" data-execution_count="143">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>txt_x <span class="op">=</span> txt[:<span class="op">-</span><span class="dv">1</span>] </span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>txt_y <span class="op">=</span> txt[<span class="dv">1</span>:] </span></code></pre></div>
</div>
<div class="cell" data-execution_count="144">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>mapping <span class="op">=</span> {<span class="st">'!'</span>:<span class="dv">0</span>, <span class="st">'?'</span>:<span class="dv">1</span>, <span class="st">'h'</span>:<span class="dv">2</span>, <span class="st">'i'</span>:<span class="dv">3</span>} </span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).<span class="bu">float</span>().to(<span class="st">"cuda:0"</span>)</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).<span class="bu">float</span>().to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="145">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">4</span>,<span class="dv">10</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">10</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="146">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() </span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="147">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>    hidden, _ <span class="op">=</span> lstm(x) </span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a>    loss.backward() </span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb94-11"><a href="#cb94-11" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="148">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>hidden, _ <span class="op">=</span> lstm(x)</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>plt.matshow(soft(linr(hidden)).to(<span class="st">"cpu"</span>).data,cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="148">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f5686bc0b90&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-30-12wk_files/figure-html/cell-74-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>첫번째 stack은 hi!로 학습 두번째 stack은 hi?로 학습하여 결과가 이럼</p>
</section>
<section id="조각난-시계열" class="level2">
<h2 class="anchored" data-anchor-id="조각난-시계열">조각난 시계열</h2>
<div class="cell" data-execution_count="149">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>txt1<span class="op">=</span> txt[:<span class="dv">9</span>]</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>txt2<span class="op">=</span> txt[<span class="dv">9</span>:]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="150">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>txt1,txt2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="150">
<pre><code>(['h', 'i', '!', 'h', 'i', '!', 'h', 'i', '!'],
 ['h', 'i', '?', 'h', 'i', '?', 'h', 'i', '?'])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="151">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>txt1_x <span class="op">=</span> txt1[:<span class="op">-</span><span class="dv">1</span>] </span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>txt1_y <span class="op">=</span> txt1[<span class="dv">1</span>:] </span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>txt2_x <span class="op">=</span> txt2[:<span class="op">-</span><span class="dv">1</span>] </span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>txt2_y <span class="op">=</span> txt2[<span class="dv">1</span>:] </span></code></pre></div>
</div>
<div class="cell" data-execution_count="152">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>mapping <span class="op">=</span> {<span class="st">'!'</span>:<span class="dv">0</span>, <span class="st">'?'</span>:<span class="dv">1</span>, <span class="st">'h'</span>:<span class="dv">2</span>, <span class="st">'i'</span>:<span class="dv">3</span>} </span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt1_x,mapping))).<span class="bu">float</span>().to(<span class="st">"cuda:0"</span>)</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>y1 <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt1_y,mapping))).<span class="bu">float</span>().to(<span class="st">"cuda:0"</span>)</span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt2_x,mapping))).<span class="bu">float</span>().to(<span class="st">"cuda:0"</span>)</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>y2 <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt2_y,mapping))).<span class="bu">float</span>().to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<p>9에서 하나씩 빼서 x,y 만들었으니까 8</p>
<div class="cell" data-execution_count="153">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>x1.shape, y1.shape, x2.shape, y2.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="153">
<pre><code>(torch.Size([8, 4]),
 torch.Size([8, 4]),
 torch.Size([8, 4]),
 torch.Size([8, 4]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="154">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>xx <span class="op">=</span> torch.stack([x1,x2],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>yy <span class="op">=</span> torch.stack([y1,y2],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>xx.shape, yy.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="154">
<pre><code>(torch.Size([8, 2, 4]), torch.Size([8, 2, 4]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="155">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">4</span>,<span class="dv">10</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">10</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="156">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() </span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="157">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>    hidden, _ <span class="op">=</span> lstm(xx) </span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb108-6"><a href="#cb108-6" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output[:,<span class="dv">0</span>,:],yy[:,<span class="dv">0</span>,:]) <span class="op">+</span> loss_fn(output[:,<span class="dv">1</span>,:],yy[:,<span class="dv">1</span>,:])</span>
<span id="cb108-7"><a href="#cb108-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb108-8"><a href="#cb108-8" aria-hidden="true" tabindex="-1"></a>    loss.backward() </span>
<span id="cb108-9"><a href="#cb108-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb108-10"><a href="#cb108-10" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb108-11"><a href="#cb108-11" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<p>첫번째 stzck 과 두번째 stack의 합</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>  loss <span class="op">=</span> loss_fn(output[:,<span class="dv">0</span>,:],yy[:,<span class="dv">0</span>,:]) <span class="op">+</span> loss_fn(output[:,<span class="dv">1</span>,:],yy[:,<span class="dv">1</span>,:])</span></code></pre></div>
<div class="cell" data-execution_count="158">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>fig , ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>) </span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].matshow(soft(output[:,<span class="dv">0</span>,:]).to(<span class="st">"cpu"</span>).data,cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].matshow(soft(output[:,<span class="dv">1</span>,:]).to(<span class="st">"cpu"</span>).data,cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="158">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f5687aed450&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-30-12wk_files/figure-html/cell-84-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>xx로 학습한 것들인데 만약 x를 넣는다면?</p>
<div class="cell" data-execution_count="159">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>hidden, _ <span class="op">=</span> lstm(x)</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>plt.matshow(soft(linr(hidden)).to(<span class="st">"cpu"</span>).data,cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="159">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f5687accf50&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-30-12wk_files/figure-html/cell-85-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="162">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>hidden, _ <span class="op">=</span> lstm(x1)</span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>plt.matshow(soft(linr(hidden)).to(<span class="st">"cpu"</span>).data,cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="162">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f5687add750&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-30-12wk_files/figure-html/cell-86-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="163">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>hidden, _ <span class="op">=</span> lstm(x2)</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>plt.matshow(soft(linr(hidden)).to(<span class="st">"cpu"</span>).data,cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="163">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f56820f78d0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-30-12wk_files/figure-html/cell-87-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="160">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>hidden.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="160">
<pre><code>torch.Size([17, 10])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="161">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>linr(hidden).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="161">
<pre><code>torch.Size([17, 4])</code></pre>
</div>
</div>
<p><code>-</code> 조각난 시계열로 학습한 경우는 hi!에서 hi?로 바뀔 수 없다. 왜냐햐면 그러한 연결정보가 끊어져 있으니까</p>
</section>
<section id="재미있는-실험" class="level2">
<h2 class="anchored" data-anchor-id="재미있는-실험">재미있는 실험</h2>
<p><code>-</code> x1만 배운다면?</p>
<div class="cell" data-execution_count="172">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">4</span>,<span class="dv">10</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">10</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="173">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() </span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="175">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a>    hidden, _ <span class="op">=</span> lstm(x1) </span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb124-5"><a href="#cb124-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb124-6"><a href="#cb124-6" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y1)</span>
<span id="cb124-7"><a href="#cb124-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb124-8"><a href="#cb124-8" aria-hidden="true" tabindex="-1"></a>    loss.backward() </span>
<span id="cb124-9"><a href="#cb124-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb124-10"><a href="#cb124-10" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb124-11"><a href="#cb124-11" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="176">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>hidden, _ <span class="op">=</span> lstm(x2)</span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>plt.matshow(soft(linr(hidden)).to(<span class="st">"cpu"</span>).data,cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="176">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f6b701ba890&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-30-12wk_files/figure-html/cell-93-output-2.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> x2만 배운다면?</p>
<div class="cell" data-execution_count="191">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">4</span>,<span class="dv">10</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">10</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="192">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() </span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="193">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a>    hidden, _ <span class="op">=</span> lstm(x2) </span>
<span id="cb129-4"><a href="#cb129-4" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb129-5"><a href="#cb129-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb129-6"><a href="#cb129-6" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y2)</span>
<span id="cb129-7"><a href="#cb129-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb129-8"><a href="#cb129-8" aria-hidden="true" tabindex="-1"></a>    loss.backward() </span>
<span id="cb129-9"><a href="#cb129-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb129-10"><a href="#cb129-10" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb129-11"><a href="#cb129-11" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="195">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>hidden, _ <span class="op">=</span> lstm(x1)</span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a>plt.matshow(soft(linr(hidden)).to(<span class="st">"cpu"</span>).data,cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="195">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f6b9809ef50&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-30-12wk_files/figure-html/cell-97-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="똑같은-코드들-fastai-pytorch" class="level1">
<h1>똑같은 코드들 fastai, pytorch</h1>
<section id="data-human-numbers-5-1" class="level2">
<h2 class="anchored" data-anchor-id="data-human-numbers-5-1">data: human numbers 5</h2>
<div class="cell" data-execution_count="196">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> ([<span class="st">'one'</span>,<span class="st">','</span>,<span class="st">'two'</span>,<span class="st">','</span>,<span class="st">'three'</span>,<span class="st">','</span>,<span class="st">'four'</span>,<span class="st">','</span>,<span class="st">'five'</span>,<span class="st">','</span>]<span class="op">*</span><span class="dv">100</span>)[:<span class="op">-</span><span class="dv">1</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="197">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>mapping <span class="op">=</span> {<span class="st">','</span>:<span class="dv">0</span>, <span class="st">'one'</span>:<span class="dv">1</span>, <span class="st">'two'</span>:<span class="dv">2</span>, <span class="st">'three'</span>:<span class="dv">3</span>, <span class="st">'four'</span>:<span class="dv">4</span>, <span class="st">'five'</span>:<span class="dv">5</span>} </span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>mapping</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="197">
<pre><code>{',': 0, 'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="198">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>txt_x <span class="op">=</span> txt[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a>txt_y <span class="op">=</span> txt[<span class="dv">1</span>:] </span></code></pre></div>
</div>
<div class="cell" data-execution_count="199">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>txt_x[<span class="dv">0</span>:<span class="dv">5</span>], txt_y[<span class="dv">0</span>:<span class="dv">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="199">
<pre><code>(['one', ',', 'two', ',', 'three'], [',', 'two', ',', 'three', ','])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="200">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).<span class="bu">float</span>().to(<span class="st">"cuda:0"</span>)</span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).<span class="bu">float</span>().to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
</section>
<section id="fastai-이용한-learn-1" class="level2">
<h2 class="anchored" data-anchor-id="fastai-이용한-learn-1">fastai 이용한 learn</h2>
<div class="sourceCode" id="cb139"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>dl1 <span class="op">=</span> torch.utils.data.DataLoader(ds1,batch_size<span class="op">=</span><span class="dv">998</span>)</span></code></pre></div>
<p>한 뭉치에 몇 개 있는지</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>torch.nn.LSTM(batxh_size)</span></code></pre></div>
<p>몇 개로 나눠져 있는지</p>
<div class="cell" data-execution_count="215">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>ds1 <span class="op">=</span> torch.utils.data.TensorDataset(x,y)</span>
<span id="cb141-2"><a href="#cb141-2" aria-hidden="true" tabindex="-1"></a>ds2 <span class="op">=</span> torch.utils.data.TensorDataset(x,y) <span class="co"># dummy </span></span>
<span id="cb141-3"><a href="#cb141-3" aria-hidden="true" tabindex="-1"></a>dl1 <span class="op">=</span> torch.utils.data.DataLoader(ds1,batch_size<span class="op">=</span><span class="dv">998</span>)</span>
<span id="cb141-4"><a href="#cb141-4" aria-hidden="true" tabindex="-1"></a>dl2 <span class="op">=</span> torch.utils.data.DataLoader(ds2,batch_size<span class="op">=</span><span class="dv">998</span>) <span class="co"># dummy </span></span>
<span id="cb141-5"><a href="#cb141-5" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> DataLoaders(dl1,dl2) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="216">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyLSTM(torch.nn.Module):</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a>        torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb142-5"><a href="#cb142-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">6</span>,<span class="dv">20</span>)</span>
<span id="cb142-6"><a href="#cb142-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">6</span>) </span>
<span id="cb142-7"><a href="#cb142-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,x):</span>
<span id="cb142-8"><a href="#cb142-8" aria-hidden="true" tabindex="-1"></a>        _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb142-9"><a href="#cb142-9" aria-hidden="true" tabindex="-1"></a>        hidden, (hT,cT) <span class="op">=</span><span class="va">self</span>.lstm(x,(_water,_water))</span>
<span id="cb142-10"><a href="#cb142-10" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.linr(hidden)</span>
<span id="cb142-11"><a href="#cb142-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output         </span></code></pre></div>
</div>
<div class="cell" data-execution_count="217">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> MyLSTM().to(<span class="st">"cuda:0"</span>)</span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="218">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>lrnr <span class="op">=</span> Learner(dls,net,loss_fn,lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="219">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a>lrnr.fit(<span class="dv">10</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.762846</td>
      <td>1.502211</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.631212</td>
      <td>1.620583</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.627597</td>
      <td>1.443686</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.580216</td>
      <td>1.368762</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.536200</td>
      <td>1.307310</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.496099</td>
      <td>1.216339</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>6</td>
      <td>1.453670</td>
      <td>1.113821</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>7</td>
      <td>1.408125</td>
      <td>1.019931</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>8</td>
      <td>1.361426</td>
      <td>0.941434</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>9</td>
      <td>1.315507</td>
      <td>0.884034</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution_count="220">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>soft(lrnr.model(x)).data.to(<span class="st">"cpu"</span>).numpy().<span class="bu">round</span>(<span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="220">
<pre><code>array([[0.935, 0.009, 0.015, 0.011, 0.016, 0.014],
       [0.133, 0.164, 0.242, 0.172, 0.141, 0.147],
       [0.982, 0.003, 0.004, 0.003, 0.004, 0.003],
       ...,
       [0.122, 0.171, 0.242, 0.174, 0.146, 0.144],
       [0.984, 0.003, 0.004, 0.002, 0.004, 0.003],
       [0.119, 0.172, 0.244, 0.175, 0.144, 0.145]], dtype=float32)</code></pre>
</div>
</div>
</section>
<section id="torch를-이용한-learn-1" class="level2">
<h2 class="anchored" data-anchor-id="torch를-이용한-learn-1">torch를 이용한 learn</h2>
<div class="cell" data-execution_count="230">
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">6</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>) </span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">6</span>).to(<span class="st">"cuda:0"</span>) </span>
<span id="cb148-4"><a href="#cb148-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb148-5"><a href="#cb148-5" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> Adam(<span class="bu">list</span>(lstm.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<p>optim으로 adam 사용</p>
<div class="cell" data-tags="[]" data-execution_count="231">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb149-3"><a href="#cb149-3" aria-hidden="true" tabindex="-1"></a>    hidden, _ <span class="op">=</span> lstm(x)</span>
<span id="cb149-4"><a href="#cb149-4" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb149-5"><a href="#cb149-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb149-6"><a href="#cb149-6" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb149-7"><a href="#cb149-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb149-8"><a href="#cb149-8" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb149-9"><a href="#cb149-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb149-10"><a href="#cb149-10" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb149-11"><a href="#cb149-11" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()     </span></code></pre></div>
</div>
<div class="cell" data-execution_count="232">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>hidden, _ <span class="op">=</span> lstm(x)</span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> linr(hidden) </span>
<span id="cb150-3"><a href="#cb150-3" aria-hidden="true" tabindex="-1"></a>soft(output).data.to(<span class="st">"cpu"</span>).numpy().<span class="bu">round</span>(<span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="232">
<pre><code>array([[0.935, 0.009, 0.015, 0.011, 0.016, 0.014],
       [0.133, 0.164, 0.242, 0.172, 0.141, 0.147],
       [0.982, 0.003, 0.004, 0.003, 0.004, 0.003],
       ...,
       [0.122, 0.171, 0.242, 0.174, 0.146, 0.144],
       [0.984, 0.003, 0.004, 0.002, 0.004, 0.003],
       [0.119, 0.172, 0.244, 0.175, 0.145, 0.145]], dtype=float32)</code></pre>
</div>
</div>
</section>
</section>
<section id="human-numbers-100" class="level1">
<h1>human numbers 100</h1>
<div class="cell" data-execution_count="789">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'https://raw.githubusercontent.com/guebin/DL2022/main/posts/IV.%20RNN/2022-11-25-human_numbers_100.csv'</span>)</span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a>df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="789">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...</td>
    </tr>
    <tr>
      <th>1996</th>
      <td>one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...</td>
    </tr>
    <tr>
      <th>1997</th>
      <td>one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...</td>
    </tr>
    <tr>
      <th>1998</th>
      <td>one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...</td>
    </tr>
  </tbody>
</table>
<p>2000 rows × 1 columns</p>
</div>
</div>
</div>
<p><code>(1)</code> TextDataLoaders.from_df을 이용하여 dls오브젝트를 만들어라. - is_lm = True 로 설정할 것 - seq_len = 5 로 설정할 것</p>
<p>(풀이)</p>
<div class="cell" data-execution_count="791">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> TextDataLoaders.from_df(df,is_lm<span class="op">=</span><span class="va">True</span>,seq_len<span class="op">=</span><span class="dv">5</span>,text_col<span class="op">=</span><span class="st">'text'</span>)</span>
<span id="cb153-2"><a href="#cb153-2" aria-hidden="true" tabindex="-1"></a>dls.show_batch()</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>text</th>
      <th>text_</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>xxbos one , two ,</td>
      <td>one , two , three</td>
    </tr>
    <tr>
      <th>1</th>
      <td>hundred xxbos one , two</td>
      <td>xxbos one , two ,</td>
    </tr>
    <tr>
      <th>2</th>
      <td>one hundred xxbos one ,</td>
      <td>hundred xxbos one , two</td>
    </tr>
    <tr>
      <th>3</th>
      <td>, one hundred xxbos one</td>
      <td>one hundred xxbos one ,</td>
    </tr>
    <tr>
      <th>4</th>
      <td>nine , one hundred xxbos</td>
      <td>, one hundred xxbos one</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ninety nine , one hundred</td>
      <td>nine , one hundred xxbos</td>
    </tr>
    <tr>
      <th>6</th>
      <td>, ninety nine , one</td>
      <td>ninety nine , one hundred</td>
    </tr>
    <tr>
      <th>7</th>
      <td>eight , ninety nine ,</td>
      <td>, ninety nine , one</td>
    </tr>
    <tr>
      <th>8</th>
      <td>ninety eight , ninety nine</td>
      <td>eight , ninety nine ,</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p><code>(2)</code> lrnr 오브젝트를 만들어라. - arch = AWD_LSTM 이용 - metrics = accuracy 이용</p>
<p>(풀이)</p>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a>lrnr <span class="op">=</span> language_model_learner(dls, arch<span class="op">=</span> AWD_LSTM, metrics<span class="op">=</span>accuracy)</span></code></pre></div>
</div>
<p><code>(3)</code> lrnr오브젝트에서 fine_tune(3) 메소드를 이용하여 모형을 학습하라.</p>
<p>(풀이)</p>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>lrnr.fine_tune(<span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.534681</td>
      <td>0.168856</td>
      <td>0.977650</td>
      <td>00:49</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.018749</td>
      <td>0.003256</td>
      <td>0.999205</td>
      <td>00:54</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.001580</td>
      <td>0.002430</td>
      <td>0.999324</td>
      <td>00:54</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.000651</td>
      <td>0.002244</td>
      <td>0.999315</td>
      <td>00:54</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p><code>(4)</code> ‘one , two ,’ 이후에 이어질 50개의 단어를 생성하라.</p>
<p>(풀이)</p>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>lrnr.predict(<span class="st">'one, two,'</span>, n_words<span class="op">=</span><span class="dv">50</span>) </span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>'one , two , three , four , five , six , seven , eight , nine , ten , eleven , twelve , thirteen , fourteen , fifteen , sixteen , seventeen , eighteen , nineteen , twenty , twenty one , twenty two , twenty three , twenty four , twenty five'</code></pre>
</div>
</div>
<p><code>(5)</code> ‘twenty , twenty one ,’ 이후에 이어질 50개의 단어를 생성하라.</p>
<p>(풀이)</p>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>lrnr.predict(<span class="st">'twenty, twenty one,'</span>, n_words<span class="op">=</span><span class="dv">50</span>) </span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>'twenty , twenty one , twenty two , twenty three , twenty four , twenty five , twenty six , twenty seven , twenty eight , twenty nine , thirty , thirty one , thirty two , thirty three , thirty four , thirty five , thirty six , thirty seven , thirty eight ,'</code></pre>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>