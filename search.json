[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, there :)\nLateX_refers"
  },
  {
    "objectID": "posts/ts/2023-01-21-ts-HW9.html",
    "href": "posts/ts/2023-01-21-ts-HW9.html",
    "title": "Theoritical Statistics HW9",
    "section": "",
    "text": "5장 이표본 검정법"
  },
  {
    "objectID": "posts/ts/2023-01-21-ts-HW9.html#section-1",
    "href": "posts/ts/2023-01-21-ts-HW9.html#section-1",
    "title": "Theoritical Statistics HW9",
    "section": "(1)",
    "text": "(1)\n가설 \\(H_0 : \\sigma^4 = 4\\) vs \\(H_1 : \\sigma^2 = 9\\)에 대한 최강력 검정의 기각역은\n\\[C = \\{ (x_1, \\dots, x_n) : \\sum^n_{i=1} x^2_i \\ge c \\}\\]\n의 꼴로 주어짐을 보이시오.\nanswer\n\\(L(\\sigma^2) = \\Pi^n_{i=1} f(x_2 : \\sigma^2) = \\Pi^n_{i=1} \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{x_i^2}{2\\sigma^2}} * \\mu=0\\)\n\\(= (\\frac{1}{2\\pi\\sigma^2})^{\\frac{n}{2}} e^{-\\frac{\\sum^n_{i=1}x_i^2}{2\\sigma^2}}\\)\n네이만 피어슨 정의에 의하면, \\(LR = \\frac{L(H_0)}{L(H_1)} = \\frac{L(4)}{L(9)} \\le k\\)\n\\(LR = \\frac{L(4)}{L(9)} = \\frac{(\\frac{1}{2\\pi 4})^{\\frac{n}{2}} e^{-\\frac{\\sum^n_{i=1} x_i^2}{2 \\times 4}}}{(\\frac{1}{2\\pi 9})^{\\frac{n}{2}} e^{-\\frac{\\sum^n_{i=1} x_i^2}{2 \\times 9}}}\\)\n\\(= (\\frac{9}{4})^{\\frac{n}{2}}e^{-\\sum^n_{i=1}x^2_i(\\frac{1}{8}-\\frac{1}{18})}\\)\n\\(= (\\frac{9}{4})^{\\frac{n}{2}}e^{-\\frac{5}{72}\\sum^n_{i=1}x^2_i} \\le k\\)\n\\(\\to e^{-\\frac{5}{72}\\sum^n_{i=1}x^2_i} \\le k\\)\n\\(\\to -\\frac{5}{72}\\sum^n_{i=1}x^2_i \\le k\\)\n\\(\\to \\sum^n_{i=1}x^2_i \\ge k\\)\n기각역: \\(\\therefore c = \\{ (x_1, \\dots ,x_n) : \\sum^n_{i=1} x^2_i \\ge c)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-21-ts-HW9.html#section-2",
    "href": "posts/ts/2023-01-21-ts-HW9.html#section-2",
    "title": "Theoritical Statistics HW9",
    "section": "(2)",
    "text": "(2)\n표본의 크기가 \\(n=20\\)일 때 유의수준이 \\(\\alpha=0.05\\)이기 위한 상수 \\(c\\)의 값을 구하시오.\nanswer\n\\(\\alpha = P(\\text{Reject } H_0 | H_0 \\text{True})\\)\n\\(= P(\\sum^n_{i=1}x^2_i \\ge k | \\sigma^2 = 4)\\)\n\\(\\star\\)\n모집단 분포 \\(X_i \\sim N(0,\\sigma^2)\\)\n표준화 \\(\\frac{X_i}{\\sigma} \\sim N(0,1)\\)\n표분화 제곱 분포는 카이제곱 \\((\\frac{X_i^2}{\\sigma})^2 \\sim \\chi^2_1, i=1,2,\\dots, n\\)\n카이제곱의 합의 자유도 합 \\(\\sum^n_{i=1}(\\frac{X_i}{\\sigma})^2 \\sim \\chi^2_{(n)}\\)\n\\(\\star\\)\n\\(= P(\\sum^n_{i=1}\\frac{\\chi^2_i}{\\sigma^2} \\ge \\frac{k}{\\sigma^2}|\\sigma^2 = 4)\\)\n\\(= P(\\sum^{20}_{i=1} \\frac{\\chi^2_i}{4} \\ge \\frac{k}{4} | \\sigma^2 = 4)\\)\n\n\n\nimage.png\n\n\n\\(\\frac{k}{4} = \\chi^2_{0.05(20)}\\)\n\nqchisq(0.95,20)\n\n31.4104328442309\n\n\n\n4*qchisq(0.95,20)\n\n125.641731376924\n\n\n\\(k = 4\\chi^2_{0.05(20)} = 125.64\\)\n\\(c = \\{(x_1,\\dots,x_n) : \\sum^n_{i=1}\\ge 125.64\\}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-21-ts-HW9.html#section-3",
    "href": "posts/ts/2023-01-21-ts-HW9.html#section-3",
    "title": "Theoritical Statistics HW9",
    "section": "(3)",
    "text": "(3)\n표본의 크기가 \\(n=20\\)일 때 (2)에서 찾은 기각역에 대한 제 2종 오류를 범할 확률\n\\[\\beta = P(\\sum^n_{i=1} X^2_i \\le c| \\sigma^2 = 9)\\]\n의 값은?\nanswer\n\\(\\beta = P(\\sum^n_{i=1}\\chi^2_i \\le c|\\sigma^2 = 9)\\)\n\\(= P(\\sum^n_{i=1} \\chi^2_i \\le 125.64 | \\sigma^2 = 9)\\)\n\\(= P(\\sum^n_{i=1} \\frac{\\chi^2_i-0}{\\sigma^2} \\le \\frac{125.64-0}{\\sigma^2} | \\sigma^2 = 9)\\) 표준화, 평균은 0\n\\(= P(\\sum^n_{i=1} \\frac{\\chi^2_i}{9} \\le \\frac{125.64}{9} | \\sigma^2 = 9)\\)\n\\(= P(\\sum^n_{i=1}\\frac{\\chi^2_i}{9} \\le 13.96) = 0.20\\)\n\n125.64/9\n\n13.96\n\n\n\npchisq(13.96,20)\n\n0.167481777665076\n\n\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/ts/2023-01-21-ts-HW9.html#section-5",
    "href": "posts/ts/2023-01-21-ts-HW9.html#section-5",
    "title": "Theoritical Statistics HW9",
    "section": "(1)",
    "text": "(1)\n유의수준 \\(\\alpha \\le \\frac{1}{2}\\)인 검정법의 기각역을 모두 제시하라.\nanswer\n모집단 \\(B(2,p)\\)\n\\(f(x:p) = \\begin{pmatrix} 2 \\\\ x \\end{pmatrix} p^x (1-p)^{2-x}\\)\n\\(\\alpha = P(X \\in c | p =\\frac{1}{2}) \\le \\frac{1}{2}\\), \\(f(x: \\frac{1}{2}) = \\begin{pmatrix} 2 \\\\ x \\end{pmatrix} (\\frac{1}{2})^2\\)\n\\(x = 0,1,2\\)\n8가지 경우 존재\n\n\\(\\{0 \\}\\), \\(P(x = 0 | p = \\frac{1}{2}) = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix} (\\frac{1}{2})^2 = \\frac{1}{4} \\to \\le \\frac{1}{2} \\therefore\\) 가능\n\\(\\{1 \\}\\), \\(P(x = 1 | p = \\frac{1}{2}) = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} (\\frac{1}{2})^2 = \\frac{1}{2} \\to \\le \\frac{1}{2} \\therefore\\) 가능\n\\(\\{2 \\}\\), \\(P(x = 2 | p = \\frac{1}{2}) = \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix} (\\frac{1}{2})^2 = \\frac{1}{4} \\to \\le \\frac{1}{2} \\therefore\\) 가능\n\\(\\{0,1 \\}\\), \\(P(x = 2 | p = \\frac{1}{2}) = f(0:\\frac{1}{2}) + f(1:\\frac{1}{2}) = \\frac{1}{4} + \\frac{1}{2} = \\frac{3}{4} \\to \\text{ NOT } \\le \\frac{1}{2} \\therefore\\) 불가능\n\\(\\{0,2 \\}\\), \\(P(x = 2 | p = \\frac{1}{2}) = f(0:\\frac{1}{2}) + f(2:\\frac{1}{2}) = \\frac{1}{4} + \\frac{1}{4} =\\frac{1}{2} \\to \\le \\frac{1}{2} \\therefore\\) 가능\n\\(\\{1,2 \\}\\), \\(P(x = 2 | p = \\frac{1}{2}) = f(1:\\frac{1}{2}) + f(2:\\frac{1}{2}) = \\frac{1}{2} + \\frac{1}{4} = \\frac{3}{4} \\to \\text{ NOT } \\le \\frac{1}{2} \\therefore\\) 불가능\n\\(\\{0,1,2 \\}\\), \\(P(x = 2 | p = \\frac{1}{2}) = f(0:\\frac{1}{2}) + f(1:\\frac{1}{2}) + f(2:\\frac{1}{2})= \\frac{1}{4} + \\frac{1}{2} + \\frac{1}{4} =1 \\to \\text{ NOT } \\le \\frac{1}{2} \\therefore\\) 불가능\n\\(\\{\\phi\\}\\) 사건이 전혀 발생하지 않는 것이니 제외"
  },
  {
    "objectID": "posts/ts/2023-01-21-ts-HW9.html#section-6",
    "href": "posts/ts/2023-01-21-ts-HW9.html#section-6",
    "title": "Theoritical Statistics HW9",
    "section": "(2)",
    "text": "(2)\n(1)의 기각역들 중 \\(\\alpha + \\beta\\)를 최소화하는 기각역을 구하라.\nanswer\n\\(\\beta = P(\\text{Not Reject } H_0 | H_1 \\text{True})\\)\n\\(= P(X \\notin c | P = \\frac{2}{3})\\)\n\\(= 1-P(X \\in c | P = \\frac{2}{3})\\)\n\n\\(\\{0 \\}\\), \\(\\alpha = \\frac{1}{4}\\)\n\n\n\\(\\beta = 1-f(0:\\frac{2}{3}) = 1-\\begin{pmatrix} 2 \\\\ 0\\end{pmatrix} (\\frac{2}{3})^0 (\\frac{1}{3})^2 = \\frac{8}{9}\\)\n\\(\\alpha + \\beta = \\frac{1}{4} + \\frac{8}{9} = \\frac{41}{36}\\)\n\n\n\\(\\{1 \\}\\), \\(\\alpha = \\frac{1}{2}\\)\n\n\n\\(\\beta = 1-f(1:\\frac{2}{3}) = 1-\\begin{pmatrix} 2 \\\\ 1\\end{pmatrix} (\\frac{2}{3})^1 (\\frac{1}{3})^1 = 1- \\frac{4}{9} = \\frac{5}{9}\\)\n\\(\\alpha + \\beta = \\frac{1}{2} + \\frac{5}{9} = \\frac{19}{18} = \\frac{38}{36}\\)\n\n\n\\(\\{2 \\}\\), \\(\\alpha = \\frac{1}{4}\\)\n\n\n\\(\\beta = 1-f(2:\\frac{2}{3}) = 1-\\begin{pmatrix} 2 \\\\ 2\\end{pmatrix} (\\frac{2}{3})^2 (\\frac{1}{3})^0 = 1-\\frac{4}{9}=\\frac{5}{9}\\)\n\\(\\alpha + \\beta = \\frac{1}{4} + \\frac{5}{9} = \\frac{29}{36}\\)\n\n\n\\(\\{0,2 \\}\\), \\(\\alpha = \\frac{1}{2}\\)\n\n\n\\(\\beta = f(1:\\frac{2}{3}) = \\begin{pmatrix} 2 \\\\ 1\\end{pmatrix} (\\frac{2}{3})^1 (\\frac{1}{3})^1 = \\frac{4}{9}\\)\n\\(\\alpha + \\beta = \\frac{1}{2} + \\frac{4}{9} = \\frac{17}{18} = \\frac{34}{36}\\)\n\n\\(\\therefore\\) 제일 작은 기각역인 3번\\(\\{ 2\\}\\)가 기각역일 때 \\(c = ( x \\in \\{2\\})\\)가 \\(\\alpha + \\beta\\)값이 최솟값이 된다."
  },
  {
    "objectID": "posts/ts/2023-01-21-ts-HW9.html#section-8",
    "href": "posts/ts/2023-01-21-ts-HW9.html#section-8",
    "title": "Theoritical Statistics HW9",
    "section": "(1)",
    "text": "(1)\n유의수준을 구하라.\nanswer\n\\(\\alpha = P(\\text{Reject } H_0 | H_0 \\text{ True})\\)\n= 귀무가설 하에서 \\(p\\)값의 범위 중 기각할 확률의 최댓값\n= \\({max}_{p\\le\\frac{1}{2}} P(\\text{Reject } H_0 | p) \\to \\Pi(p)\\)\n\\(= \\Pi(p) = P(\\text{Reject } H_0 | p)\\)\n\\(= P(X \\ge 7|p)\\)\n\\(= \\sum_{x \\ge7} f(x:p) = \\sum_{x \\ge 7} \\begin{pmatrix} 10 \\\\ x \\end{pmatrix}p^x (1-p)^{10-x}\\)\n\\(\\star p &lt;1\\) 구간에서 증가함수다.\n\\(\\Pi(\\frac{1}{2}) = \\sum_{x\\ge7} \\begin{pmatrix} 10 \\\\ x \\end{pmatrix} (\\frac{1}{2})^2 = \\{ \\begin{pmatrix} 10 \\\\ 7 \\end{pmatrix} + \\begin{pmatrix} 10 \\\\ 8 \\end{pmatrix} + \\begin{pmatrix} 10 \\\\ 9 \\end{pmatrix} + \\begin{pmatrix} 10 \\\\ 10 \\end{pmatrix} \\} \\{ (\\frac{1}{2})^{8}\\}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-21-ts-HW9.html#section-9",
    "href": "posts/ts/2023-01-21-ts-HW9.html#section-9",
    "title": "Theoritical Statistics HW9",
    "section": "(2)",
    "text": "(2)\n검정력함수를 구하라.\nanswer\n검정력 \\(= P(\\text{Reject } H_0 | H_1 \\text{ True})\\)\n= 대립가설 하에서 \\(p\\)값의 범위 중 기각할 확률의 최댓값\n= \\({max}_{p&gt;\\frac{1}{2}} P(\\text{Reject } H_0 | p) \\to \\Pi(p)\\)\n\\(= \\Pi(p) = P(\\text{Reject } H_0 | p)\\)\n\\(= P(X \\ge 7|p)\\)\n\\(= \\sum_{x \\ge7} f(x:p) = \\sum_{x \\ge 7} \\begin{pmatrix} 10 \\\\ x \\end{pmatrix}p^x (1-p)^{10-x}\\)\n\\(\\star \\frac{1}{2}&lt;p &lt;1\\) 구간에서 증가함수다.\n\\(\\Pi(\\frac{1}{2}) = \\sum_{x\\ge7} \\begin{pmatrix} 10 \\\\ x \\end{pmatrix} (\\frac{1}{2})^2 = \\{ \\begin{pmatrix} 10 \\\\ 7 \\end{pmatrix} + \\begin{pmatrix} 10 \\\\ 8 \\end{pmatrix} + \\begin{pmatrix} 10 \\\\ 9 \\end{pmatrix} + \\begin{pmatrix} 10 \\\\ 10 \\end{pmatrix} \\} \\{ (\\frac{1}{2})^{10}\\}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-21-ts-HW9.html#section-11",
    "href": "posts/ts/2023-01-21-ts-HW9.html#section-11",
    "title": "Theoritical Statistics HW9",
    "section": "(1)",
    "text": "(1)\n\\(H_0: \\theta = \\theta_0\\) 대 \\(H_1:\\theta &lt; \\theta_0\\)에 대한 균일 최강력검정의 기각영역을 구하기\nanswer\n\\(H_0 : \\theta = \\theta_0\\), \\(H_1 : \\theta = \\theta_0\\), \\((\\theta_1&lt;\\theta_0)\\) 기각역은 \\(c = \\{ (x_1,\\dots,x_n):\\frac{L(\\theta_0)}{L(\\theta_1)} \\le k\\}\\)\n\\(L(\\theta) = \\Pi^n_{i=1} f(x:\\theta) = \\Pi^n_{i=1} \\frac{1}{\\theta} I(0&lt;x_i &lt; \\theta) = \\frac{1}{\\theta^n}I(0&lt;x_{(1)}&lt;x_{(n)} &lt;\\theta)\\) 모든 값들이 0과 1사이에 존재\n가능도비 \\(LR = \\frac{L(\\theta_0)}{L(\\theta_1)} = \\frac{\\frac{1}{\\theta^2_0} I(0&lt;x_{(n)} &lt; \\theta_0)}{\\frac{1}{\\theta^n_1}I(0&lt;x_{(n)} &lt; \\theta_1)} \\le k\\)\n\\(\\begin{cases} X_{(n)} &lt; \\theta_1 , & LR = (\\frac{\\theta_1}{\\theta_0})^n & \\to \\text{분자, 분모 범위가 모두 1이 됨!} \\le k \\text{이 부분만 남고} \\\\ \\theta_1 \\le X_{(n)} &lt; \\theta_0 & LR = \\frac{1}{0} = \\infty & \\to \\text{ k보다 작을 수 없음} \\\\ X_{(n)} \\ge \\theta_0 & LR = \\frac{0}{0} & \\to \\text{ 고려하지 않을 것이다.어차피 제외될 걸??} \\end{cases}\\)\n\\(c = \\{ x_{(n)} \\le c\\text{ 상수}\\}\\)\n기각역의 모양이 \\(X_{(n)}\\le c\\)일 때, \\(\\le k\\)가 성립\n\\(c = \\{ X_{(n)} \\le c \\}\\)\n\\(\\alpha = P(X_{(n)} \\le c | \\theta = \\theta_0 \\} = \\int^c_{-\\infty} f_n (x : \\theta_0)dx\\)\n\\(\\star\\)\n최댓값\\(X_{(n)}\\)의 확률밀도함수 \\(\\to f_n(x:\\theta) = n(\\{ F(x:\\theta)\\}^{n-1} f(x:\\theta) = n(\\frac{x}{\\theta})^{n-1} \\frac{1}{\\theta} I(0&lt;x&lt;\\theta)\\)\n\\(= \\int^c_{-\\infty} n(\\frac{x}{\\theta_0})^{n-1} \\frac{1}{\\theta_0} I(0&lt;x&lt;\\theta_0)dx \\to c&gt;\\theta_0\\text{ 면 무조건 1이다.}\\)\n\\(\\int^c_0 n(\\frac{x}{\\theta_0})^{n-1} \\frac{1}{\\theta_0}dx = (\\frac{x}{\\theta_0})^n \\to c = \\alpha^{\\frac{1}{n}} \\theta_0\\)\n유의수준 \\(\\alpha\\)인 최강력 기각역 \\(X_{(n))} &lt; \\theta_0 \\alpha^{\\frac{1}{n}} \\to \\theta_1\\text{ 과 관련이 없다.} \\to \\text{모든 }\\theta \\text{에 대한 가설의 균일 최강력 기각역}\\)\n\\(H_0: \\theta=\\theta_0,H_1: \\theta = \\theta_1(\\theta &lt; \\theta_1)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-21-ts-HW9.html#section-12",
    "href": "posts/ts/2023-01-21-ts-HW9.html#section-12",
    "title": "Theoritical Statistics HW9",
    "section": "(2)",
    "text": "(2)\n귀무가설을 \\(H_0: \\theta \\ge \\theta_0\\)으로 택했을 때도 역시 균일 최강력검정이 됨을 보이기\nanswer\n\\(H_0:\\theta \\ge \\theta_0\\) 귀무가설이 복합가설일 때\n\\(\\alpha = {max}_{\\theta\\ge\\theta_0} \\Pi (\\theta)\\) 검정력 함수의 maximum 이다.\n\\(= {max}_{\\theta\\ge\\theta_0} P(\\text{Reject } H_0|\\theta)\\)\n\\(= {max}_{\\theta\\ge\\theta_0} P((x_1, \\dots, x_n) \\in x| \\theta)\\)\n\\(= {max}_{\\theta\\ge\\theta_0} P(x_{(n)} \\le \\theta_0 \\alpha^{\\frac{1}{n}}|\\theta)\\)\n\\(\\star\\)\n\\(\\Pi(\\theta) = P(X_{(n)} \\le c)\\)\n\\(= P(x_{(n)} \\le \\alpha^{\\frac{1}{n}} \\theta_0 | \\theta) = \\int^{\\alpha^{1/n}\\theta_0}_{-\\infty} f_n (x:\\theta) dx\\)\n\\(= \\int^{\\alpha^{1/n}\\theta_0}_{-\\infty} n (\\frac{x}{\\theta})^{n-1} \\frac{1}{\\theta} I (0&lt;x&lt; \\theta)\\)\n\\(= \\int^{\\alpha^{q/n}\\theta_0}_0 n (\\frac{x}{\\theta})^{n-1} \\frac{1}{\\theta} dx = (\\frac{\\alpha^{\\frac{1}{n}}\\theta_0}{\\theta})^n = \\alpha(\\frac{\\theta_0}{\\theta})^n\\)\n\\(\\star\\)\n\\(\\therefore \\alpha = {max}_{\\theta \\ge \\theta_0}\\Pi(\\theta) = {max}_{\\theta \\ge \\theta_0} P(X_{(n)} \\le \\theta_0 \\alpha ^{\\frac{1}{n}}| \\theta)\\)\n\\(= {max}_{\\theta \\ge \\theta_0} \\alpha(\\frac{\\theta_0}{\\theta})^n = \\alpha \\to \\theta\\)가 작을 수록 크다., \\(\\theta_0\\)일 때 \\(\\alpha\\)가 크다.\n복합가설일 때도 균일 최강력 기각역이 된다."
  },
  {
    "objectID": "posts/ts/2023-01-21-ts-HW9.html#section-14",
    "href": "posts/ts/2023-01-21-ts-HW9.html#section-14",
    "title": "Theoritical Statistics HW9",
    "section": "(1)",
    "text": "(1)\n최강력 검정의 기각역을 구하라.\nanswer\nNeyman-Pearson 정리 \\(c = \\{ (x_1,\\dots , x_n) : \\frac{L(\\theta_0)}{L(\\theta_1)} \\le k\\}\\)\n\\(f(x:\\theta) = (\\theta + 1) x^{\\theta} I (0\\le x \\le 1)\\)\n\\(L(\\theta) = \\Pi^n_{i=1}f(x_i : \\theta) = (\\theta+1)^n \\Pi^n_{i=1}x_i^{\\theta} I(0\\le x_i \\le 1)\\)\n\\(\\frac{L(\\theta_0)}{L(\\theta_1)} = \\frac{(\\theta_0 + 1)^n(\\Pi^n_{i=1}x_i)^{\\theta_0} \\Pi^n_{i=1}I(0&lt;x_i &lt;1)}{(\\theta_1+1)^n(\\Pi^n_{i=1}x_i)^{\\theta_1}\\Pi^n_{i=1}I(0&lt;x_i&lt;1)}\\)\n\\(\\star \\uparrow \\Pi^n_{i=1}I(0&lt;x_i&lt;1) \\to \\theta\\)랑 무관한 영역이라 무시\n\\((\\Pi^n_{i=1}x_i)^{\\theta_0 - \\theta_1} \\le k\\)\n\\(log(\\theta_0 - \\theta_1)\\sum^n_{i=1} x_i \\le k\\)\n\\((\\theta_0 - \\theta_1) \\sum^n_{i=1} x_i \\le k\\)\n\\(\\star \\theta_1 &gt; \\theta_0 \\to \\theta_0 - \\theta_1 &lt; 0 \\therefore\\) 부등호 방향 바뀜\n\\(c = \\{ (x_1,\\dots, x_n:\\sum^n_{i=1}log x_i \\ge k \\}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-21-ts-HW9.html#section-15",
    "href": "posts/ts/2023-01-21-ts-HW9.html#section-15",
    "title": "Theoritical Statistics HW9",
    "section": "(2)",
    "text": "(2)\n(1)에서 구한 검정이 대립가설 \\(\\theta&gt;\\theta_0\\)에 대하여 균일최강력 검정이 되는지를 밝혀라.\nanswer\n기각역 \\(\\sum^n_{i=1} x_i \\ge k\\)는 \\(\\theta_1\\)과 무관하다.\n\\(\\theta &gt; \\theta_0\\)에 대해 \\(\\sum^n_{i=1} x_i \\ge k\\)는 최강력 기각역이다.\n\\(H_0 : \\theta = \\theta_0\\) vs \\(H_1 : \\theta &gt; \\theta_0\\)의 균일 최강력 기각역이 될 수 있다."
  },
  {
    "objectID": "posts/ts/2023-01-21-ts-HW9.html#section-18",
    "href": "posts/ts/2023-01-21-ts-HW9.html#section-18",
    "title": "Theoritical Statistics HW9",
    "section": "(1)",
    "text": "(1)\n최강력 검정의 기각역이 \\(\\{(x_1,\\dots,x_n:x_{(n)}&gt;1,\\) 또는 \\(\\sum^n_{i=1} x_i \\le c\\}\\)임을 보여라.\nanswer\n\\(\\star\\) 모집단을 한가지로 정의 가능해서 단순가설 \\(\\to\\) 네이만 피어슨 정리 사용 가능\n\\(LR = \\frac{L_0}{L_1} = \\frac{\\Pi^n_{i=1}f_0(x_i)}{\\Pi^n_{i=1}f_1(x_i)} = \\frac{\\Pi^n_{i=1}I(0&lt;x_i&lt;1)}{\\Pi^n_{i=1}e^{-x_i}I(x_i&gt;0)}\\le k\\)\n\\(= \\frac{I(0&lt;x_{(1)}&lt;x_{(n)}&lt;1)}{e^{-\\sum^n_{i=1}x_i}I(x_{(1)}&gt;0)}\\)\n\\(= \\frac{I(0&lt;x_{(1)} &lt;1)I(0&lt;x_{(n)}&lt;1)}{e^{-\\sum^n_{i=1}x_i}I(x_{(1)}&gt;0)}\\)\n귀무가설을 기각할 기각역 \\(\\to e^{\\sum^n_{i=1}x_i}I(0&lt;x_{(n)}&lt;1)\\le k\\)\n\\(\\star x_{(n)}&gt;1\\)이면 \\(I(0&lt;x_{(n)}&lt;1) \\to 0\\)\n\\(\\star x_{(n)}&lt;1\\)이면 \\(I(0&lt;x_{(n)}&lt;1) \\to 1\\)\n\\(\\star \\sum^n_{i=1}x_i \\le k\\)\n\\(\\therefore \\{ x_{(n)}&gt;1 \\text{ or } \\sum^n_{i=1}x_i \\le k \\}\\)이 기각역"
  },
  {
    "objectID": "posts/ts/2023-01-21-ts-HW9.html#section-19",
    "href": "posts/ts/2023-01-21-ts-HW9.html#section-19",
    "title": "Theoritical Statistics HW9",
    "section": "(2)",
    "text": "(2)\n유의수준이 \\(\\alpha = 0.05\\)이고 \\(n=50\\)일 때 중심극한정리를 이용하여 \\(c\\)의 값을 구하라.\nanswer\n\\(P(x_{(n)}&gt;1 \\text{ or } \\sum^n_{i=1}x_i \\le c | H_0 ) = 0.05\\)\n\\(H_0\\)는 \\(f(x) = I(0&lt;x&lt;1)\\)이었다. 즉, \\(x\\)는 \\(1\\)보다 클 수 없고, 따라서 \\(x_{(n)}\\)도 \\(1\\)보다 클 수 없다.\n\\(P(x_{(n)} &gt;1 | H_0) = 0\\)\n\\(P(\\sum^n_{i=1}x_i \\le c|H_0)\\)\n\\(\\star\\)\n\\(n=50\\), \\(x\\)가 균등분포\n균등분포 평균, 분산 이용한 중심극한정리 \\(\\to \\frac{\\bar{x} - \\frac{1}{2}}{\\sqrt{1/12}/\\sqrt{50}} \\sim N(0,1)\\)\n\\(\\star\\)\n\\(P(\\frac{\\sum^n_{i=1}x_i}{50} = \\bar{x} \\le \\frac{c}{50}|H_0)\\)\n\\(-z_{0.05} = \\frac{c/50 - 1/2}{1/\\sqrt{600}}\\)\n\\(-z_{0.05} = -1.645\\), \\(c=21.6422\\)\n\n\n\nimage.png\n\n\n\nqnorm(0.95)\n\n1.64485362695147\n\n\n\n((-qnorm(0.95)) * 1/sqrt(600) + 1/2 ) * 50\n\n21.6424565936689\n\n\n\\(c = \\{ \\sum^{50}_{i=1}x_i \\le 21.6422 \\}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-21-ts-HW9.html#section-21",
    "href": "posts/ts/2023-01-21-ts-HW9.html#section-21",
    "title": "Theoritical Statistics HW9",
    "section": "(1)",
    "text": "(1)\n모분산 \\(\\sigma^2\\)가 알려져 있지 않은 경우 \\(H_0:\\mu \\le \\mu_0 \\text{ vs } H_1 : \\mu &gt; \\mu_0\\)에 대한 유의수준 \\(\\alpha\\)인 일반화 가능도비 검정법을 구하라.\nanswer\n모평균 가설을 검정할때 \\(\\sigma^2\\)이 알려져 있다면, 균일 최강력 검정이 존재한다. 하지만 알려져 있지 않다. \\(\\to\\) 장애요소\n\\(\\Lambda(x_1,\\dots,x_n) = \\frac{L(\\hat{\\mu}_0,\\hat{\\sigma}_0^2)}{L(\\hat{\\mu},\\hat{\\sigma}^2)}\\) 귀무가설 하 모수가능도 최대치\n\\(L(\\mu, \\hat{\\sigma}^2) = (\\frac{1}{2\\pi \\sigma^2})^{\\frac{n}{2}}e^{-\\frac{\\sum^n_{i=1}(x_i - \\mu)^2}{2\\sigma^2}}\\)\n\\({max}_{\\Omega_0} L(\\mu,\\sigma^2)\\) 최대는 \\(\\bar{x}\\)이긴 하지만, 귀무가설 하 \\(\\mu \\le \\mu_0\\)이라는 제약이 있어서 이 조건이 필요하다.\n최대가능도 추정량\n\n\\(\\Omega_0 = \\{ (\\mu,\\sigma^2):\\mu \\le \\mu_0, \\sigma^2&gt;0\\}\\)\n\n\\(\\hat{\\mu}_0 = {min}(\\bar{x},\\mu_0)\\)\n\\(\\hat{\\sigma}^2_0 = \\frac{1}{n}\\sum^n_{i=1}{x_i}(x_i - \\hat{\\mu}_0)^2\\)\n\n\\(\\Omega = \\{(\\mu,\\sigma^2) : -\\infty \\le \\mu \\le \\infty, \\sigma^2 &gt; 0\\}\\)\n\n\\(\\hat{\\mu} = \\bar{x}\\)\n\\(\\hat{\\sigma}^2 = \\frac{1}{n} \\sum^n_{i=1}(x_i- \\bar{x})^2\\)\n\n\n\\(\\Lambda = \\frac{(\\frac{1}{2\\pi\\hat{\\sigma}^2_0})^{\\frac{n}{2}}e^{-\\frac{\\sum^n_{i=1}(x_i - \\hat{\\mu}_0)^2}{2\\hat{\\sigma}^2_0}}}{(\\frac{1}{2\\pi\\hat{\\sigma}^2})^{\\frac{n}{2}}e^{-\\frac{\\sum^n_{i=1}(x_i - \\hat{\\mu})^2}{2\\hat{\\sigma}^2}}} \\le k\\)\n\\(\\uparrow\\) 각 분자, 분모의 \\(exp\\)에 있는 \\(\\hat{\\sigma}\\)들에 각 값을 대입하면\n\n\\(\\hat{\\sigma}_0\\)대입하면 \\(\\to -\\frac{\\sum^n_{i=1}(x_i - \\hat{\\mu}_0)^2}{2\\frac{1}{n}\\sum^n_{i=1}(x_i - \\hat{\\mu}_0)^2} = \\frac{n}{2}\\)\n\\(\\hat{\\sigma}\\) 대입하면 \\(\\to -\\frac{\\sum^n_{i=1}(x_i - \\hat{\\mu})^2}{2\\frac{1}{n}\\sum^n_{i=1}(x_i - \\bar{x})}^2 = -\\frac{n}{2}\\)\n\n\\(\\to (\\frac{\\hat{\\sigma}^2}{\\hat{\\sigma}^2_0})^{\\frac{n}{2}} \\le k\\)\n$ k $\n대입하면 \\(\\frac{\\sum^n_{i=1}(x_i - \\bar{X})^2}{\\sum^n_{i=1}(x_i - \\hat{\\mu}_0)^2} \\le k\\)\n\\(\\hat{\\mu}_o = {min}(\\bar{X}, \\mu_0)\\)\n\n\\(\\bar{x} &lt; \\mu_0 \\to \\hat{\\mu}_0 = \\bar{x} \\to 1 \\le k\\)\n\n\n\\(k\\)는 1보다 작아야 한다.(일반화 가능도비 기본 성질)\n\\(\\therefore\\) 성립하지 않는다.\n\n\n\\(\\bar{x} &gt; \\mu_0 \\to \\frac{\\sum(x_i - \\bar{x})^2}{\\sum(x_i - \\mu_0)^2} \\le k\\)\n\n\\(c = \\{ (x_1,\\dots,x_n)|\\bar{x} &gt; \\mu_0, \\frac{\\sum^n_{i=1}(x_i - \\bar{x})^2}{\\sum^n_{i=1}(x_i - \\mu_0)^2} \\le k\\)\n\\(\\sum^n_{i=1}(x_i - \\mu_0)^2 = \\sum^n_{i=1}(x_i - \\bar{x} + \\bar{x} - \\mu_0)^2\\)\n\\(= \\sum^n_{i=1}(x_i - \\bar{x})^2 + 2(\\bar{x}-\\mu_0)\\sum(x_i - \\bar{x}) + n(\\bar{x} -\\mu_0)^2\\)\n\\(\\star \\sum(x_i - \\bar{x}) = 0\\)\n\\(= \\sum^n_{i=1}(x_i - \\bar{x})^2 + n(\\bar{x} - \\mu_0)^2\\)\n\\(c = \\{ (x_1,\\dots,x_n)|\\bar{x} &gt; \\mu_0, \\frac{\\sum^n_{i=1}(x_i - \\bar{x})^2}{\\sum^n_{i=1}(x_i - \\bar{x})^2 + n(\\bar{x} - \\mu_0)^2} \\le k\\)\n\\(\\to \\frac{\\sum^n_{i=1}(x_i - \\bar{x})^2}{\\sum^n_{i=1}(x_i - \\bar{x})^2 + n(\\bar{x} - \\mu_0)^2} \\le k\\)\n\\(\\to \\frac{1}{1+\\frac{n(\\bar{x} - \\mu_0)^2}{\\sum^n_{i=1}(x_i - \\bar{x})^2}} \\le k\\)\n\\(\\to \\frac{n(\\bar{x} - \\mu_0)^2}{\\sum^n_{i=1}(x_i - \\bar{x})^2} \\ge k\\)\n\\(c = \\{ (x_1,\\dots,x_n)|\\bar{x} &gt; \\mu_0, \\frac{n(\\bar{x} - \\mu_0)^2}{\\sum^n_{i=1}(x_i - \\bar{x})^2} \\ge k\\)\n\\(\\to \\sum^n_{i=1}(x_i - \\bar{x})^2 = (n-1)S^2\\)\n\\(\\to \\frac{n(\\bar{x} - \\mu_0)^2}{(n-1)S^2} = \\frac{n(\\bar{x} - \\mu_0)^2}{S^2} \\ge k\\)\n\\(\\star N(\\mu, \\sigma^2) \\to \\frac{\\bar{x} -\\mu}{\\sigma/\\sqrt{n}} \\to \\frac{\\bar{x}-\\mu}{s/\\sqrt{n}} \\sim t_{(n-1)}\\)\n\\(c = \\{ (x_1,\\dots, x_n) | \\bar{x} &gt; \\mu_0, |\\frac{\\sqrt{n}(\\bar{x}-\\mu_0)}{S}| \\ge k \\}\\)\n\\(= \\{ (x_1,\\dots, x_n) | \\bar{x} &gt; \\mu_0, \\text{ and } (\\bar{x} &gt; \\mu_0 + \\frac{S}{\\sqrt{n}}k \\text{ or } \\bar{x} \\le \\mu_0 - \\frac{X}{\\sqrt{n}k})\\}\\)\n\\(= \\{ (x_1,\\dots, x_n) | \\bar{x} &gt; \\mu_0 + \\frac{S}{\\sqrt{n}}k\\}\\)\n\\(\\alpha = {max}_{\\Omega_0} \\Pi(\\mu)\\)\n\\(\\Pi(\\mu) = P((x_1,\\dots,x_n) \\in c | \\mu)\\)\n\\(= P(\\bar{x} \\ge \\mu_0 + \\frac{S}{\\sqrt{n}}k | \\mu)\\)\n\\(= P(\\frac{\\bar{x}-\\mu}{S/\\sqrt{n}} \\ge \\frac{\\mu_0 - \\mu}{S/\\sqrt{n}} + k | \\mu)\\)\n\\(= P(t \\ge \\frac{\\mu_0 - \\mu}{S/\\sqrt{n}}+k) \\to \\mu\\)가 커질수록 작아진다 \\(\\to \\mu\\)에 대해 증가 함수.\n\\(\\therefore \\alpha = {max}_{\\mu \\le \\mu_0} \\Pi(\\mu) = \\Pi(\\mu_0) = P(t \\ge 0 + k) = t_{\\alpha(n-1)}\\)\n\\(\\therefore c = \\{ (x_1,\\dots,x_n) | \\bar{x} \\ge \\mu_0 + \\frac{S}{\\sqrt{n}} t_{\\alpha(n-1)}\\}\\)\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/ts/2023-01-21-ts-HW9.html#section-22",
    "href": "posts/ts/2023-01-21-ts-HW9.html#section-22",
    "title": "Theoritical Statistics HW9",
    "section": "(2)",
    "text": "(2)\n모평균 \\(\\mu\\)가 알려져 있지 않은 경우 \\(H_0:\\sigma^2 = \\sigma^2_0 \\text{ vs }H_1 : \\sigma^2 &gt; \\sigma^2_0\\)에 대한 유의수준 \\(\\alpha\\)인 일반화 가능도비 검정법을 구하라.\nanswer\n\\(\\mu\\)가 장애요소\n\\(L(\\mu, \\sigma^2( = (\\frac{1}{2\\pi \\sigma^2})^{\\frac{n}{2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}})\\)\n\\(\\Lambda = \\frac{L(\\hat{\\mu}_0,\\hat{\\sigma}^2_0)}{L(\\hat{\\mu},\\hat{\\sigma}^2)}\\)\n\n\\(\\Omega_0 = \\{ (\\mu,\\sigma^2) : -\\infty &lt; \\mu &lt; \\infty , \\sigma^2 = \\sigma^2_0\\}\\)\n\n\\(\\hat{\\mu}_0 = {argmax}_{(\\mu,\\sigma^2)\\in\\Omega_0} L(\\mu,\\sigma^2) = \\bar{x}\\)\n\\(\\hat{\\sigma}^2_0 = \\sigma^2_0\\)\n\n\\(\\Omega = \\{ (\\mu, \\sigma^2) : -\\infty &lt; \\mu &lt; \\infty , \\sigma^2 \\ge \\sigma^2_0, \\sigma^2 &gt; 0 \\}\\)\n\n\\(\\hat{\\mu} = \\bar{x}\\)\n\\(\\hat{\\sigma}^2 = {max}(\\frac{1}{n}\\sum^n_{i=1}(x_i - \\bar{x})^2, \\sigma^2_0)\\)\n\n왼쪽은 \\(\\sigma^2\\)보다 클때, 오른쪽은 \\(\\sigma^2\\)보다 작을때\n\n\n\n\\(\\Lambda = \\frac{L(\\hat{\\mu}_0, \\hat{\\sigma}^2_0)}{L(\\hat{\\mu},\\hat{\\sigma}^2)}= \\frac{(\\frac{1}{2\\pi\\hat{\\sigma}^2_0})^{\\frac{n}{2}} e^{-\\frac{\\sum(x_i - \\bar{x})^2}{2\\hat{\\sigma}^2_0}}}{(\\frac{1}{2\\pi\\hat{\\sigma}^2})^{\\frac{n}{2}} e^{-\\frac{\\sum(x_i - \\bar{x})^2}{2\\hat{\\sigma}^2}}}\\)\n\\(\\to (\\frac{1}{2\\pi\\hat{\\sigma}^2_0}) = \\frac{1}{2\\pi \\sigma^2}\\)\n\\(\\to -\\frac{\\sum(x_i - \\bar{x})^2}{2\\hat{\\sigma}^2_0} = -\\frac{\\sum(x_i - \\bar{x})^2}{2\\sigma^2_0}\\)\n\\(= (\\frac{\\hat{\\sigma}^2}{\\hat{\\sigma}^2_0})^{\\frac{n}{2}} e^{-\\frac{1}{2}\\sum^n_{i=1}(x_i - \\bar{x})^2 (\\frac{\\hat{\\sigma}^2 - \\sigma^2_0}{\\sigma^2_0\\hat{\\sigma}^2})} \\le k\\)\n\n\\(\\frac{1}{n} \\sum^n_{i=1}(x_i - \\bar{x})^2 &lt; \\sigma^2_0 \\to \\sigma^2_0 \\to \\Lambda = 1\\)\n\n\n\\(k=1\\)이 되어 의미가 없어짐\n\n\n\\(\\frac{1}{n}\\sum^n_{i=1}(x_i-\\bar{x})^2 &gt; \\sigma^2_0 \\to \\hat{\\sigma}^2 = \\frac{1}{n}\\sum^n_{i=1}(x_i - \\bar{x})^2\\)\n\n\n예 5.24에서 다룬 식, \\(\\Lambda\\)는 \\(\\frac{\\hat{\\sigma}}{\\sigma^2_0}\\)의 감소함수이다.\n\n기각역 : \\(\\frac{1}{n}\\sum(x_i - \\bar{x})^2 \\ge k\\)\n\\(\\alpha = P(\\sum^n_{i=1}(x_i - \\bar{x})^2 \\ge k | \\sigma^2 = \\sigma^2_0)\\)\n\\(\\star \\frac{\\sum^n_{i=1}(x_i - \\bar{x})^2}{\\sigma^2} \\sim \\chi^2_{(n-1)}\\)\n\\(= P(\\frac{\\sum^n_{i=1}(x_i - \\bar{x})^2}{\\sigma^2_0} \\ge \\frac{k}{\\sigma^2_0} | \\sigma^2 = \\sigma^2_0)\\)\n\\(\\frac{k}{\\sigma^2_0} = \\chi^2_{0.05(n-1)}\\)\n\\(k = \\sigma^2_0 \\chi^2_{0.05(n-1)}\\)\n\n\n\nimage.png\n\n\n\\(c = \\{ (x_1,\\dots,x_n):\\sum^n_{i=1}(x_i - \\bar{x})^2 \\ge \\sigma^2_0 \\chi^2_{0.05(n-1)}\\)\n유의수준 \\(\\alpha\\) 일반화 가능도비 검정법의 기각역이다."
  },
  {
    "objectID": "posts/ts/2023-01-12-ts_HW5.html",
    "href": "posts/ts/2023-01-12-ts_HW5.html",
    "title": "Theoritical Statistics HW5",
    "section": "",
    "text": "확률변수의 극한"
  },
  {
    "objectID": "posts/ts/2023-01-12-ts_HW5.html#section-3",
    "href": "posts/ts/2023-01-12-ts_HW5.html#section-3",
    "title": "Theoritical Statistics HW5",
    "section": "(1)",
    "text": "(1)\n\\(\\sqrt{n}(\\bar{X}_n^2 - \\mu^2) \\xrightarrow[]{d} N(0,4 \\mu^2 \\sigma^2)\\)임을 보여라, 단 \\(\\mu \\neq 0\\)\nanswer\nDelta Method\n\\(\\sqrt{n}(g(X_n) - g(\\mu) ) \\xrightarrow[]{d} N(0,\\sigma^2 g'(\\mu)^2)\\)\n\\(g(X_n) = \\bar{X}_n^2\\), \\(g'(X_n) = 2\\bar{X}_n\\)\n\\(g(\\mu) = \\mu^2\\), \\((g'(\\mu))^2 = 4\\mu^2\\)\n\\(\\sqrt{n}(\\bar{X}_n^2 - \\mu^2) \\xrightarrow[]{d} N(0,4\\mu^2 \\sigma^2)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-12-ts_HW5.html#section-4",
    "href": "posts/ts/2023-01-12-ts_HW5.html#section-4",
    "title": "Theoritical Statistics HW5",
    "section": "(2)",
    "text": "(2)\n(1)에서 \\(\\mu=0\\)인 경우에 대해 설명하라.\nanswer\n\\(\\mu=0\\)\n\\(\\sqrt{n} \\bar{X}^2_n \\xrightarrow[]{d} N(0,0)\\) 분산 0\n\\(\\sqrt{n}\\bar{X}^2_n \\xrightarrow[]{p} 0\\) 0으로 확률 수렴한다."
  },
  {
    "objectID": "posts/ts/2023-01-18-ts_HW7.html",
    "href": "posts/ts/2023-01-18-ts_HW7.html",
    "title": "Theoritical Statistics HW7",
    "section": "",
    "text": "8장 검정의 기본요소\n\n\n수업시간 과제\n\\(X_1, X_2, \\dots X_n\\) 이 다음 분포로부터의 랜덤샘플일 때 \\(\\theta\\)의 추정량 \\(\\hat{\\theta}=\\bar{X}\\)이 비편향추정량 중에서 분산이 가장 작은 추정량임을 보여라.\n\n\\(Poisson(\\theta)\\)\n\nanswer\n\\(X \\sim Poisson(\\lambda) \\to f(x| \\lambda) = \\frac{\\lambda^x e^{-\\lambda}}{\\lambda!}\\)\n\\(E(X) = \\lambda\\), \\(Var(X) = \\lambda\\)\n\\(Var(\\bar{X}) = \\frac{1}{nI(\\theta)}\\)일까?\n\\(I(\\theta) = E(\\frac{\\partial}{\\partial \\lambda} log f(x|\\lambda)^2)\\)\n\\(= E(-1 + \\frac{X}{\\lambda})^2 = E(\\frac{X-\\lambda}{\\lambda})^2 = \\frac{E(X^2) - 2\\lambda E(X) + \\lambda^2}{\\lambda^2} = \\frac{\\lambda + \\lambda^2-2\\lambda^2 + \\lambda^2}{\\lambda^2} = \\frac{1}{\\lambda}\\)\n\\(\\frac{1}{nI(\\theta)} = \\frac{\\lambda}{n}\\)\n\\(Var(\\bar{X}) = \\frac{\\lambda}{n}\\)\n\\(\\therefore \\bar{X}\\)는 MVUE다.\n\n\n수업시간 과제\n\\(X_1,X_2, \\dots, X_n\\)가 \\(Bernoulli(p)\\)로부터의 랜덤샘플이라고 할 때, \\(Bernoulli(p)\\)의 분산의 최대가능도추정량의 점근분포를 구하시오.\nanswer\n델타 방법 이용\n\\(\\sqrt{n}(g(\\hat{\\theta})-g(\\theta_0) \\xrightarrow[]{d} N(0,\\frac{g'(\\theta_0)^2}{I(\\theta_0)})\\)\n\\(g(\\theta_0) = p(1-p)\\)\n\\(g'(\\theta_0) = 1-2p\\)\n\\(I(p) = \\frac{1}{p(1-p)}\\)\n\\(\\therefore \\frac{(1-2p)^2}{I(p)} = p(1-p)(1-2p)^2\\)\n\\(\\sqrt{n}(\\frac{p(1-p)}{n} - p(1-p) \\xrightarrow[]{d} N(0,p(1-p)(1-2p)^2)\\)\n\n\n4장 23.\n\\(X_1,X_2,X_3\\)이 \\(f_X(x:\\theta)=\\frac{1}{\\theta}exp(-\\frac{x}{\\theta}),x&gt;0\\)으로부터 얻은 랜덤표본이라고 하자. 모수 \\(\\theta\\)를 추정함에 있어 \\(\\frac{X_1 + 2X_2 + X_3}{4}\\)의 \\(\\bar{X}_3\\)에 대한 효율을 구하라.\nanswer\n\\(\\sim \\frac{(X_1 + 2X_2 + X_3)/4}{\\bar{X}_3}\\)\n\\(\\text{eff}((X_1 + 2X_2 + X_3)/4,\\bar{X}_3) = \\frac{1/Var((X_1+2X_2+X_3)/4)}{1/Var(\\bar{X}_3)}\\)\n\\(E(\\frac{X_1 + 2X_2 + X_3}{4}) = \\frac{\\theta + 2\\theta + \\theta}{4} = \\theta \\to\\)비편향추정량\n\\(E(\\bar{X}_3) = \\theta \\to\\) 비편향추정량\n\\(Var(\\frac{X_1 + 2X_2 + X_3}{4}) = \\frac{\\theta^2 + 4\\theta^2 + \\theta^2}{16} = \\frac{6\\theta^2}{16} = \\frac{3\\theta^2}{8}\\)\n\\(Var(\\bar{X}_3) = \\frac{\\theta^2}{3}\\)\n\\(\\therefore \\frac{8}{3\\theta^2} \\times \\frac{\\theta^2}{3} = \\frac{8}{9}\\)\n\\((X_1 + 2X_2 + X_3)/4\\) 가 \\(\\bar{X}_3\\)에 비해 \\(\\frac{8}{9}\\)만큼 효율을 가진다.\n\n\n4장 25.\n\\(X_1,X_2,\\dots,X_n\\)을 베르누이 \\((p)\\)로부터 얻은 랜덤 표본이라고 하자.\n분산 \\(p(1-p)\\)에 대한 비편향추정량의 크래머-라오 하한값을 구하라.\nanswer\n\\(f_X(x|p) = p^x(1-p)^{1-x}\\)\n\\(I(p) = E(\\frac{\\partial}{\\partial p} log f_X(x|p))^2\\)\n\\(= E(\\frac{\\partial}{\\partial p} X log p + (1-x) log(1-p))^2\\)\n\\(= E(\\frac{x}{p} - \\frac{1-x}{1-p})^2\\)\n\\(\\frac{E((x-p)^2}{o(1-p)^2}\\)\n\\(\\star E((x-p)^2 = Var \\sim p(1-p)\\)\n\\(= \\frac{E(x-p)^2}{p^2(1-p)^2} = \\frac{1}{p(1-p)}\\)\nCRLB: \\(\\frac{(g'(p))^2}{nI(p)} = \\frac{p(1-p)(1-2p)^2}{n}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-18-ts-HW8.html",
    "href": "posts/ts/2023-01-18-ts-HW8.html",
    "title": "Theoritical Statistics HW8",
    "section": "",
    "text": "9장 최강력 검정법"
  },
  {
    "objectID": "posts/ts/2023-01-18-ts-HW8.html#section-2",
    "href": "posts/ts/2023-01-18-ts-HW8.html#section-2",
    "title": "Theoritical Statistics HW8",
    "section": "(1)",
    "text": "(1)\n기각영역의 형태가 \\(C = \\{(X_1,X_2,\\dots,X_{16}) | \\bar{X}_{16} &lt; a\\}\\)로 주어질때 상수 \\(a\\)의 값을 구하라.\nanswer\n\\(X_1, \\dots, X_{16} \\sim N(\\mu,4)\\)\n\\(\\bar{X}_{16} \\sim N(\\mu,(\\frac{1}{2})^2)\\)\n\\(\\alpha = P(\\text{Reject } H_0 | H_0 True)\\)\n\\(0.05 = P(\\bar{X}_{16}&lt;a | \\mu = 100)\\)\n\\(0.05 = P(\\frac{\\bar{X}_{16} - 100}{1/2} &lt; \\frac{a-100}{1/2} | \\mu = 100)\\)\n\\(0.05 = P(Z &lt; 2(a-100))\\)\n\n\n\nimage.png\n\n\n\\(a = \\frac{Z_{0.05}}{2} + 100\\)\n\\(= \\frac{-1.645}{2} + 100 = -0.8225 + 100 = 99.1775\\)"
  },
  {
    "objectID": "posts/ts/2023-01-18-ts-HW8.html#section-3",
    "href": "posts/ts/2023-01-18-ts-HW8.html#section-3",
    "title": "Theoritical Statistics HW8",
    "section": "(2)",
    "text": "(2)\n대립가설이 \\(H_1: \\mu = 103\\)인 경우 (1)에서 구한 기각영역에 대하여 제 2종오류를 범할 확률을 구하라.\nanswer\n\\(\\beta = P(\\text{Type 2 error}) = P(\\text{Not Reject }H_0 | H_0 \\text{False})\\)\n\\(= P(\\bar{X}_{16} &gt; a | \\mu = 103)\\)\n\\(= P(\\frac{\\bar{X}_{16} - 103} {1/2} &gt; \\frac{1-103}{1/2} | \\mu = 103)\\)\n\\(= P(Z &gt; -7.645) = 1- \\phi (-7.645)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-18-ts-HW8.html#section-4",
    "href": "posts/ts/2023-01-18-ts-HW8.html#section-4",
    "title": "Theoritical Statistics HW8",
    "section": "(3)",
    "text": "(3)\n대립가설이 \\(H_1 : \\mu = 97(\\)일 경우 (1)에서 구한 기각 영역에 대하여 제 2종 오류를 범할 확률을 구하라.\nanswer\n\\(\\beta = P(\\text{Type 2 error}) = P(\\text{Not Reject }H_0 | H_0 \\text{False})\\)\n\\(= P(\\bar{X}_{16} &gt; a | \\mu = 97)\\)\n\\(= P(\\frac{\\bar{X}_{16} - 97} {1/2} &gt; \\frac{1-97}{1/2} | \\mu = 97)\\)\n\\(= P(Z &gt; 4.355) = 1- \\phi (4.355)\\)"
  },
  {
    "objectID": "posts/ts/2023-03-03-ts-final_qanda.html",
    "href": "posts/ts/2023-03-03-ts-final_qanda.html",
    "title": "Theoritical Statistics Final term 6 Explanation",
    "section": "",
    "text": "Final term 질문\n참고\nusing Distributions, Plots"
  },
  {
    "objectID": "posts/ts/2023-03-03-ts-final_qanda.html#alpha-구해보자.-시뮬레이션",
    "href": "posts/ts/2023-03-03-ts-final_qanda.html#alpha-구해보자.-시뮬레이션",
    "title": "Theoritical Statistics Final term 6 Explanation",
    "section": "\\(\\alpha\\) 구해보자. (시뮬레이션)",
    "text": "\\(\\alpha\\) 구해보자. (시뮬레이션)\n\nθ=2 \nx = rand(Exponential(θ),2)\n\n2-element Vector{Float64}:\n 0.6687906085363371\n 1.5350253919744037\n\n\n\nT(x)\n\n0.7524758613118447\n\n\n\nTs = [rand(Exponential(θ),2) |&gt; T for i in 1:1400000]\nmean(Ts .&lt; 1/2)\n\n0.15347"
  },
  {
    "objectID": "posts/ts/2023-03-03-ts-final_qanda.html#beta를-구해보자.시뮬레이션",
    "href": "posts/ts/2023-03-03-ts-final_qanda.html#beta를-구해보자.시뮬레이션",
    "title": "Theoritical Statistics Final term 6 Explanation",
    "section": "\\(\\beta\\)를 구해보자.(시뮬레이션)",
    "text": "\\(\\beta\\)를 구해보자.(시뮬레이션)\n\nθ=1\nx = rand(Exponential(θ),2)\n\n2-element Vector{Float64}:\n 3.8233540141024713\n 1.6552057743570938\n\n\n\nTs = [rand(Exponential(θ),2) |&gt; T for i in 1:1400000]\nmean(Ts .&gt; 1/2)\n\n0.5970164285714286"
  },
  {
    "objectID": "posts/ts/2023-03-03-ts-final_qanda.html#alpha를-구해보자.-이론",
    "href": "posts/ts/2023-03-03-ts-final_qanda.html#alpha를-구해보자.-이론",
    "title": "Theoritical Statistics Final term 6 Explanation",
    "section": "\\(\\alpha\\)를 구해보자. (이론)",
    "text": "\\(\\alpha\\)를 구해보자. (이론)\n\\(T(X_1,X_2) = \\frac{0.25 exp(-0.5 X_1 - 0.5 X_2)}{exp(-X_1 - X_2)} = 0.25 exp(0.5 X_1 + 0.5 X_2)\\)\n\\(T(X_1,X_2) &lt; \\frac{1}{2} \\iff exp(0.5 X_1 + 0.5 X_2) &lt; 2 \\iff X_1 + X_2 &lt; 2 ln2\\)\n그런데 \\(X_1 + X_2 \\sim \\chi^2(4)\\) under \\(H_0\\)\n\\(P(X_1 + X_2 &lt; 2 ln 2) = \\int^{2ln2}_{0} \\frac{1}{4 \\Gamma(2)} x e^{-x/2} dx = \\int^{ln2}_{0} t e^{-t} dt = [ t(-e^{-t}) -e^{-t}]^{ln 2}_{0}\\)\n\nt = log(2) \nu = t*(-exp(-t)) - exp(-t)\nt = 0\nl = t*(-exp(-t)) - exp(-t)\n\n-1.0\n\n\n\nu-l\n\n0.1534264097200273"
  },
  {
    "objectID": "posts/ts/2023-03-03-ts-final_qanda.html#beta를-구해보자.-이론",
    "href": "posts/ts/2023-03-03-ts-final_qanda.html#beta를-구해보자.-이론",
    "title": "Theoritical Statistics Final term 6 Explanation",
    "section": "\\(\\beta\\)를 구해보자. (이론)",
    "text": "\\(\\beta\\)를 구해보자. (이론)\n\\(T(X_1,X_2) &gt; \\frac{1}{2} \\iff exp(0.5 X_1 + 0.5 X_2) &lt; 2 \\iff 2(X_1 + X_2) &lt; 4 ln2\\)\n그런데 \\(2(X_1 + X_2) \\sim \\chi^2(4)\\) under \\(H_0\\)\n\\(P(2(X_1 + X_2) &lt; 4 ln 2) = \\int_{4ln2}^{\\infty} \\frac{1}{4 \\Gamma(2)} x e^{-x/2} dx = \\int_{2ln2}^{\\infty} t e^{-t} dt = [ t(-e^{-t}) -e^{-t}]_{2ln 2}^{0}\\)\n\nu = 0\nt = 2*log(2)\nl = t*(-exp(-t)) - exp(-t)\n\n-0.5965735902799727\n\n\n\nu-l\n\n0.5965735902799727"
  },
  {
    "objectID": "posts/ts/2023-01-14-ts_HW6.html",
    "href": "posts/ts/2023-01-14-ts_HW6.html",
    "title": "Theoritical Statistics HW6",
    "section": "",
    "text": "4장 모수의 추정"
  },
  {
    "objectID": "posts/ts/2023-01-14-ts_HW6.html#section-6",
    "href": "posts/ts/2023-01-14-ts_HW6.html#section-6",
    "title": "Theoritical Statistics HW6",
    "section": "(1)",
    "text": "(1)\n\\(T_1(X)\\)와 \\(T_2(X)\\)의 비평향성을 점검하라.\nanswer\n\\(E(T_1(X)) = E(X) = p \\to T_1(X)\\) 비편향성 만족\n\\(E(T_2(X)) = E(\\frac{1}{2}) = \\frac{1}{2} \\to T_2(X)\\) 비편향성 불만족"
  },
  {
    "objectID": "posts/ts/2023-01-14-ts_HW6.html#section-7",
    "href": "posts/ts/2023-01-14-ts_HW6.html#section-7",
    "title": "Theoritical Statistics HW6",
    "section": "(2)",
    "text": "(2)\n\\(T_1(X)\\)와 \\(T_2(X)\\)의 평균제곱오차를 비교하라.\nanswer\n\\(MSE(T_1(X)) = MSE(X)\\)\n\\(= E(X-P)^2 = E(X^2 - 2PX + P^2)\\)\n\\(= P(1-P) + P^2 -2P^2 + P^2 = P-P^2+P^2-2P^2+P^2 = P-P^2 = P(1-P)\\)\n\\(MSE(T_2(X)) = MSE(\\frac{1}{2} - E(\\frac{1}{2} - P)^2) = (\\frac{1}{2}-P)^2\\)\n\\(\\star\\)\n\\(P-P^2 = \\frac{1}{4}-2P+P^2\\)\n\\(2P^2 -3P+\\frac{1}{4} = 0\\)\n\\(P = \\frac{3 \\pm \\sqrt{9-1}}{4} = \\frac{3 \\pm \\sqrt{7}}{4}\\)\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/ts/2023-01-14-ts_HW6.html#section-9",
    "href": "posts/ts/2023-01-14-ts_HW6.html#section-9",
    "title": "Theoritical Statistics HW6",
    "section": "(1)",
    "text": "(1)\n\\(\\hat{\\lambda}_1\\)과 \\(\\hat{\\lambda}_2\\)의 분산을 구하라.\nanswer\n\\(E(X_i) = \\lambda, Var(X_i) = \\lambda^2\\)\n\\(E(\\hat{\\lambda}_1) = E(\\bar{X}) = \\lambda \\to\\), 비편향추정량이다.\n\\(Var(\\hat{\\lambda}_1) = E(\\bar{X}) = \\frac{\\lambda^2}{n}\\)\n\\(E(\\hat{\\lambda_2}) = E(\\frac{n\\bar{X}_n}{n+1}) = \\frac{n}{n+1}E(\\bar{X}_n) = \\frac{n}{n+1}\\lambda \\to\\)비편향 추정량이 아니다., 즉, 분산에 bias존재\n\\(Var(\\hat{\\lambda_2}) = Var(\\frac{n}{n+1}\\bar{X}_n) = E(\\frac{n}{n+1}\\bar{X} - \\lambda)^2\\)\n\\(= E(\\frac{n}{n+1} \\bar{X} - \\frac{n}{n+1} \\lambda + \\frac{n}{n+1}\\lambda -\\lambda)^2\\)\n\\(= E(\\frac{n}{n+1}(\\bar{X}-\\lambda) - \\frac{1}{n+1}\\lambda)^2\\)\n\\(= (\\frac{n}{n+1})^2E(\\bar{X} - \\lambda)^2 + \\frac{1}{(n+1)^2}\\lambda^2 - \\frac{2n}{(n+1)^2}\\lambda(\\bar{X} - \\lambda)\\)\n\\(= (\\frac{n}{n+1})^2 \\lambda^2 + \\frac{1}{(n+1)^2}\\lambda^2\\)\n\\(= \\frac{n^2+1}{(n+1)^2}\\lambda^2\\)"
  },
  {
    "objectID": "posts/ts/2023-01-14-ts_HW6.html#section-10",
    "href": "posts/ts/2023-01-14-ts_HW6.html#section-10",
    "title": "Theoritical Statistics HW6",
    "section": "(2)",
    "text": "(2)\n\\(\\hat{\\lambda}_1\\)과 \\(\\hat{\\lambda}_2\\)의 평균제곱오차를 구하라.\nanswer\n\\(MSE(\\hat{\\lambda}_1) = E(\\hat{\\lambda}_1 - \\lambda)^2 = var(\\hat{\\lambda}_1) = \\frac{\\lambda^2}{n}\\)\n\\(\\star\\) 비편향추정량이라 분산과 일치하는 \\(\\hat{\\lambda}_1\\)\n\\(MSE(\\hat{\\lambda}_2) = E(\\hat{\\lambda}_2 - \\lambda)^2 = var(\\hat{\\lambda}_2) + (bias(\\hat{\\lambda}_2))^2\\)\n\\(\\star\\) 비편향추정량이 아니라 bias까지 고려해줘야 하는 \\(\\hat{\\lambda}_2\\)\n\\(var(\\hat{\\lambda}_2) = \\frac{n^2+1}{(n+1)^2}\\lambda^2\\)\n\\(bias(\\hat{\\lambda}_2) = E(\\hat{\\lambda}_2) - \\lambda = \\frac{n}{n+1}\\lambda - \\lambda = -\\frac{1}{n+1}\\lambda\\)\n\\(\\star var(\\hat{\\lambda}_2) + (bias(\\hat{\\lambda}_2))^2\\)\n\\(= \\frac{n^2+1}{(n+1)^2}\\lambda^2 + \\frac{1}{(n+1)^2}\\lambda^2 = \\frac{n^2+2}{(n+1)^2}\\lambda^2\\)"
  },
  {
    "objectID": "posts/ts/2023-01-09-ts_HW4.html",
    "href": "posts/ts/2023-01-09-ts_HW4.html",
    "title": "Theoritical Statistics HW4",
    "section": "",
    "text": "랜덤표본"
  },
  {
    "objectID": "posts/ts/2023-01-09-ts_HW4.html#section",
    "href": "posts/ts/2023-01-09-ts_HW4.html#section",
    "title": "Theoritical Statistics HW4",
    "section": "1.",
    "text": "1.\n\\(X_1 \\sim \\chi^2_m\\), \\(X_2 \\sim \\chi^2_n\\) 이고 서로 독립이면 \\(X_1 + X_2 \\sim \\chi^2_{m+n}\\)\nanswer\n\\(Y = X_1 + X_2\\)\n\\(M_Y(t) = M_{X_1 + X_2}(t) = M_{X_1}(t) \\times M_{X_2}(t) = (1-2t)^{-\\frac{m+n}{2}}\\)\n적률생성함수의 유일성에 의하여 \\(X_1 + X_2 \\sim \\chi^2_{m+n}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-09-ts_HW4.html#section-1",
    "href": "posts/ts/2023-01-09-ts_HW4.html#section-1",
    "title": "Theoritical Statistics HW4",
    "section": "2.",
    "text": "2.\n서로 독립인 \\(X_1\\)과 \\(X_2\\)에 대하여 \\(Y = X_1 + X_2\\) 라고 할 떄 \\(Y \\sim \\chi^2_m\\), \\(X_1 \\sim \\chi^2_n\\)이면 \\(X_2 \\sim \\chi^2_{m-n}\\)\nanswer\n\\(X_2 = Y - X_1\\)\n\\(M_Y (t) = (1-2t)^{\\frac{m}{2}}\\)\n\\(M_{X_1}(t) = (1-2t)^{-\\frac{n}{2}}\\)\n\\(M_{X_2}(t) = M_{Y-X_1}(t) = E(e^{(y-X_1)t}) = E(e^{Yt} \\times e^{-X_1t}) = \\frac{M_Y(t)}{M_{X_1}(t)} = (1-2t)^{-\\frac{m-n}{2}}\\)\n\\(\\therefore X_2 \\sim \\chi^2_{m-n}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-09-ts_HW4.html#section-3",
    "href": "posts/ts/2023-01-09-ts_HW4.html#section-3",
    "title": "Theoritical Statistics HW4",
    "section": "(1)",
    "text": "(1)\n\\(P(\\bar{X}_5 &lt; c) = 0.90\\)을 만족하는 상수 \\(c\\)값을 구하라.\nanswer\n\\(\\bar{X}_5 \\sim N(0,5)\\)\n\\(P(\\bar{X}_t &lt;c) = 0.90\\)\n\\(c = 2.8656\\)\n\nqnorm(0.9,0,1)*sqrt(5)\n\n2.865636417229"
  },
  {
    "objectID": "posts/ts/2023-01-09-ts_HW4.html#section-4",
    "href": "posts/ts/2023-01-09-ts_HW4.html#section-4",
    "title": "Theoritical Statistics HW4",
    "section": "(2)",
    "text": "(2)\n\\(P(\\frac{1}{5}\\sum^5_{i=1} X^2_i &lt;c) = 0.90\\)을 만족하는 상수 \\(c\\)값을 구하라.\nanswer\n\\(P(\\frac{1}{5} \\sum^5_{i=1} X^2_i &lt;c) = 0.90\\)\n\\(\\star\\)\n\\(\\sum^5_{i=1} X^2_i \\sim \\chi^2_5\\)\n\\(\\frac{1}{5} \\sum^5_{i=1} X^2_i \\sim \\chi^2_1\\)\n\\(\\star\\)\n\\(E(\\frac{1}{5}\\sum^5_{i=1} X^2_i ) =\\frac{1}{5} \\times 5 = 1\\)\n\\(var(\\frac{1}{5}\\sum^5_{i=1} X^2_i) = 2\\)\n\\(\\therefore c = 2.7055\\)\n\nqchisq(0.9,df=1)\n\n2.70554345409542"
  },
  {
    "objectID": "posts/ts/2023-01-09-ts_HW4.html#section-9",
    "href": "posts/ts/2023-01-09-ts_HW4.html#section-9",
    "title": "Theoritical Statistics HW4",
    "section": "(1)",
    "text": "(1)\n\\(\\bar{X}_{16} - \\bar{Y}_{25}\\)의 분포를 구하라.\nanswer\n\\(E(\\bar{X}_{16} - \\bar{Y}_{25}) = E(0-2) = -2\\)\n\\(Var(\\bar{X}_{16} - \\bar{Y}_{25}) = \\frac{9}{16} + \\frac{26}{25} = \\frac{481}{400}\\)\n\\(M_{\\bar{X}_{16} - \\bar{Y}_{25}}(t) = exp(t(0-2) + \\frac{t^2}{2}(\\frac{9}{16} + \\frac{16}{25}))\\)\n\\(\\bar{X}_{16} - \\bar{Y}_{25} \\sim N(-2,\\frac{481}{400})\\)"
  },
  {
    "objectID": "posts/ts/2023-01-09-ts_HW4.html#section-10",
    "href": "posts/ts/2023-01-09-ts_HW4.html#section-10",
    "title": "Theoritical Statistics HW4",
    "section": "(2)",
    "text": "(2)\n\\(P(\\bar{X}_{16} - \\bar{Y}_{25} &gt;0)\\)를 계산하라.\nanswer\n\\(P(\\bar{X}_{16} - \\bar{Y}_{25} &gt; 0) = 1-P(\\bar{X}_{16} - \\bar{Y}_{25} &lt;0) = 0.0341\\)\n\n1-pnorm(0,-2,sqrt(481/400))\n\n0.0340879047226217"
  },
  {
    "objectID": "posts/ts/2023-01-09-ts_HW4.html#section-12",
    "href": "posts/ts/2023-01-09-ts_HW4.html#section-12",
    "title": "Theoritical Statistics HW4",
    "section": "(1)",
    "text": "(1)\n\\(P(X_1 - X_2 &lt;2)\\)을 계산하라.\nanswer\n\\(P(X_1 - X_2 &lt; 2)\\), \\(X_1 - X_2 \\sim N(0,2)\\)\n\\(= P(\\frac{(X_1 - X_2) - 0}{\\sqrt{2}} &lt;\\sqrt{2}) = P(z&lt;\\sqrt{2}) = 0.9214\\)\n\npnorm(sqrt(2),0,1)\n\n0.921350396474857"
  },
  {
    "objectID": "posts/ts/2023-01-09-ts_HW4.html#section-13",
    "href": "posts/ts/2023-01-09-ts_HW4.html#section-13",
    "title": "Theoritical Statistics HW4",
    "section": "(2)",
    "text": "(2)\n\\(P(X_1 + X_2 &lt;2)\\)을 계산하라.\nanswer\n\\(P(X_1 + X_2 &lt; 2)\\), \\(X_1 + X_2 \\sim N(0,2)\\)\n\\(= P(\\frac{(X_1 + X_2) - 0}{\\sqrt{2}} &lt;\\sqrt{2}) = P(z&lt;\\sqrt{2}) = 0.9214\\)\n\npnorm(sqrt(2),0,1)\n\n0.921350396474857"
  },
  {
    "objectID": "posts/ts/2023-01-09-ts_HW4.html#section-14",
    "href": "posts/ts/2023-01-09-ts_HW4.html#section-14",
    "title": "Theoritical Statistics HW4",
    "section": "(3)",
    "text": "(3)\n\\(P(X^2_1 + \\dots + X^2_{50} &lt;60)\\)을 계산하라.\nanswer\n\\(P(X^2_1 + \\dots + X^2_{50}&lt;60 ) = 0.8428\\)\n\\(\\star X^2_1 + \\dots X^2_{50} \\sim \\chi^2_{50}\\)\n\npchisq(60,df=50)\n\n0.842757972761609"
  },
  {
    "objectID": "posts/ts/2023-01-09-ts_HW4.html#section-15",
    "href": "posts/ts/2023-01-09-ts_HW4.html#section-15",
    "title": "Theoritical Statistics HW4",
    "section": "(4)",
    "text": "(4)\n\\(P(40&lt;X^2_1 + \\dots + X^2_{50} &lt;60)\\)을 계산하라.\nanswer\n\\(P(40&lt;X^2_1 + X^2_{50} &lt;60) = P(X^2_1 + \\dots + X^2_{50}&lt;60) - P(X^2_1 + \\dots X^2_{50} &lt;40) = 0.6860\\)\n\npchisq(60,df=50) - pchisq(40,df=50)\n\n0.685985350935371"
  },
  {
    "objectID": "posts/ts/2023-01-09-ts_HW4.html#section-16",
    "href": "posts/ts/2023-01-09-ts_HW4.html#section-16",
    "title": "Theoritical Statistics HW4",
    "section": "(5)",
    "text": "(5)\n\\(P(X^2_1 + \\dots + X^2_{50} + c) = 0.9\\) 를 만족하는 상수 \\(c\\)를 구하라.\nanswer\n\\(P(X^2_1 + \\dots + X^2_{50} &lt; 50+ c) = 0.9\\), \\(50+c = 63.1671\\), \\(c=13.1671\\)\n\nqchisq(0.9,df=50)\n\n63.1671210057263"
  },
  {
    "objectID": "posts/ct/2023-03-22-Coding_Test_Tree.html",
    "href": "posts/ct/2023-03-22-Coding_Test_Tree.html",
    "title": "Tree",
    "section": "",
    "text": "Tree\n\n\nTree\n전위 순회(preorder traversal)\n\n노드를 방문한다.\n왼쪽 서브 트리를 전위 순회한다.\n오른쪽 서브 트리를 전위 순회한다.\n\n(쉽게 생각하면 중간-&gt;왼쪽-&gt;오른쪽 순)\n\ndef pre_order(data, left_node, right_node):\n    print(data,end='')\n    if left_node != '.' :\n        pre_order(tree[left_node])\n    if right_node != '.' :\n        pre_order(tree[right_node])\n\n\npre_order()\n\n중위 순회(inorder traversal)\n\n왼쪽 서브 트리를 중위 순회한다.\n노드를 방문한다.\n오른쪽 서브 트리를 중위 순회한다.\n\n(쉽게 생각하면 왼쪽-&gt;중간-&gt;오른쪽 순)\n\ndef in_order(data, left_node, right_node):\n    if left_node != '.' :\n        pre_order(tree[left_node])\n    print(data,end='')\n    if right_node != '.' :\n        pre_order(tree[right_node])\n\n휘위 순회(postorder traversal)\n\n왼쪽 서브 트리를 후위 순회한다.\n오른쪽 서브 트리를 후위 순회한다.\n노드를 방문한다.\n\n(쉽게 생각하면 왼쪽-&gt;오른쪽-&gt;중간 순)\n\ndef post_order(data, left_node, right_node):\n    if left_node != '.' :\n        pre_order(tree[left_node])\n    if right_node != '.' :\n        pre_order(tree[right_node])\n    print(data,end='')\n\n\n\n이진 검색 트리\n이진 검색 트리는 다음과 같은 세 가지 조건을 만족하는 이진 트리이다.\n노드의 왼쪽 서브트리에 있는 모든 노드의 키는 노드의 키보다 작다.\n노드의 오른쪽 서브트리에 있는 모든 노드의 키는 노드의 키보다 크다.\n왼쪽, 오른쪽 서브트리도 이진 검색 트리이다.\n\n\n\nimage.png\n\n\n전위 순회 (루트-왼쪽-오른쪽)은 루트를 방문하고, 왼쪽 서브트리, 오른쪽 서브 트리를 순서대로 방문하면서 노드의 키를 출력한다. 후위 순회 (왼쪽-오른쪽-루트)는 왼쪽 서브트리, 오른쪽 서브트리, 루트 노드 순서대로 키를 출력한다. 예를 들어, 위의 이진 검색 트리의 전위 순회 결과는 50 30 24 5 28 45 98 52 60 이고, 후위 순회 결과는 5 28 24 45 30 60 52 98 50 이다.\n이진 검색 트리를 전위 순회한 결과가 주어졌을 때, 이 트리를 후위 순회한 결과를 구하는 프로그램을 작성하시오.\n\nglobal something\n위 global 에 대한 교수님 수업 자료임!!\n\\(\\star\\)\n(원칙1) global 에서 정의된 이름은 local 에서 정의된 이름이 없을 경우 그를 대신할 수 있다 (local은 경우에 따라서 global에 있는 변수를 빌려 쓸 수 있다)\n(원칙2) local과 global에서 같은 이름 ’x’가 각각 정의되어 있는 경우? global의 변수와 local의 변수는 각각 따로 행동하며 서로 영향을 주지 않는다. (독립적이다)\n만약에 local이 global의 변수를 같이 쓰고 있었다고 할지라도, 추후 새롭게 local에 새롭게 같은 이름의 변수가 정의된다면 그 순간 local과 global의 변수를 각자 따로 행동하며 서로 영향을 주지 않는다.\n\n\nuser_input = input(\"dd: \")\nprint(\"dd{}dd\".format(user_input))\n\ndd:  d\n\n\nddddd\n\n\n\nclass Node:\n    def __init__(self,data):\n        self.data = data\n        self.left = None\n        self.right = None\n\n\nclass Tree:\n    def __init__(self):\n        self.root = None\n        \n    def add(self,data):\n        if(self.root == None):\n            self.root = Node(data)\n            \n        else:\n            current = self.root\n            while(True):\n                if (current.data &gt; data):\n                    if(current.left == None):\n                        current.left = Node(data)\n                        break\n                    current = current.left\n                \n                if (current.data &lt; data):\n                    if(current.right == None):\n                        current.right = Node(data)\n                        break\n                    current = current.right\n    def postorder(self,node=None):\n        global answer\n        if node == None:\n            node = self.root\n        if node.left != None:\n            self.postorder(node.left)\n        if node.right != None:\n            self.postorder(node.right)\n        answer.append(node.data)   \n\n\n# import sys\n# sys.setrecursionlimit(200000)\n\n# input = sys.stdin.readline()\ninput = input()\n\ntree = Tree()\n\nwhile True:\n    try:\n        tree.add(int(input()))\n    except:\n        break\n\nanswer = []\n\ntree.postorder()\nprint('\\n'.join(map(str,answer)))\n\n예제 입력 값\n50\n30\n24\n5\n28\n45\n98\n52\n60\n\ntree = Tree()\n\n\nwhile True:\n    try:\n        tree.add(int(input()))\n    except:\n        break"
  },
  {
    "objectID": "posts/ct/2023-01-23-Coding_Test_Q2.html",
    "href": "posts/ct/2023-01-23-Coding_Test_Q2.html",
    "title": "두 큐 합 같게 만들기(Done)",
    "section": "",
    "text": "2022:KAKAO TECH INTERNSHIP\n\n문제 설명\n길이가 같은 두 개의 큐가 주어집니다.\n하나의 큐를 골라 원소를 추출(pop)하고, 추출된 원소를 다른 큐에 집어넣는(insert) 작업을 통해 각 큐의 원소 합이 같도록 만들려고 합니다.\n이때 필요한 작업의 최소 횟수를 구하고자 합니다.\n한 번의 pop과 한 번의 insert를 합쳐서 작업을 1회 수행한 것으로 간주합니다.\n큐는 먼저 집어넣은 원소가 먼저 나오는 구조입니다.\n이 문제에서는 큐를 배열로 표현하며, 원소가 배열 앞쪽에 있을수록 먼저 집어넣은 원소임을 의미합니다.\n즉, pop을 하면 배열의 첫 번째 원소가 추출되며, insert를 하면 배열의 끝에 원소가 추가됩니다.\n예를 들어 큐 [1, 2, 3, 4]가 주어졌을 때, pop을 하면 맨 앞에 있는 원소 1이 추출되어 [2, 3, 4]가 되며, 이어서 5를 insert하면 [2, 3, 4, 5]가 됩니다.\n다음은 두 큐를 나타내는 예시입니다.\nqueue1 = [3, 2, 7, 2]\nqueue2 = [4, 6, 5, 1]\n두 큐에 담긴 모든 원소의 합은 30입니다.\n따라서, 각 큐의 합을 15로 만들어야 합니다.\n예를 들어, 다음과 같이 2가지 방법이 있습니다.\n\nqueue2의 4, 6, 5를 순서대로 추출하여 queue1에 추가한 뒤, queue1의 3, 2, 7, 2를 순서대로 추출하여 queue2에 추가합니다. 그 결과 queue1은 [4, 6, 5], queue2는 [1, 3, 2, 7, 2]가 되며, 각 큐의 원소 합은 15로 같습니다. 이 방법은 작업을 7번 수행합니다.\nqueue1에서 3을 추출하여 queue2에 추가합니다. 그리고 queue2에서 4를 추출하여 queue1에 추가합니다. 그 결과 queue1은 [2, 7, 2, 4], queue2는 [6, 5, 1, 3]가 되며, 각 큐의 원소 합은 15로 같습니다. 이 방법은 작업을 2번만 수행하며, 이보다 적은 횟수로 목표를 달성할 수 없습니다.\n따라서 각 큐의 원소 합을 같게 만들기 위해 필요한 작업의 최소 횟수는 2입니다.\n\n길이가 같은 두 개의 큐를 나타내는 정수 배열 queue1, queue2가 매개변수로 주어집니다.\n각 큐의 원소 합을 같게 만들기 위해 필요한 작업의 최소 횟수를 return 하도록 solution 함수를 완성해주세요. 단, 어떤 방법으로도 각 큐의 원소 합을 같게 만들 수 없는 경우, -1을 return 해주세요.\n제한사항\n\n1 ≤ queue1의 길이 = queue2의 길이 ≤ 300,000\n1 ≤ queue1의 원소, queue2의 원소 ≤ 109\n주의: 언어에 따라 합 계산 과정 중 산술 오버플로우 발생 가능성이 있으므로 long type 고려가 필요합니다.\n\n입출력 예\n\n\n\nqueue1\nqueue2\nresult\n\n\n\n\n[3, 2, 7, 2]\n[4, 6, 5, 1]\n2\n\n\n[1, 2, 1, 2]\n[1, 10, 1, 2]\n7\n\n\n[1, 1]\n[1, 5]\n1\n\n\n\n입출력 예 설명\n입출력 예 #1\n문제 예시와 같습니다.\n입출력 예 #2\n두 큐에 담긴 모든 원소의 합은 20입니다. 따라서, 각 큐의 합을 10으로 만들어야 합니다. queue2에서 1, 10을 순서대로 추출하여 queue1에 추가하고, queue1에서 1, 2, 1, 2와 1(queue2으로부터 받은 원소)을 순서대로 추출하여 queue2에 추가합니다. 그 결과 queue1은 [10], queue2는 [1, 2, 1, 2, 1, 2, 1]가 되며, 각 큐의 원소 합은 10으로 같습니다. 이때 작업 횟수는 7회이며, 이보다 적은 횟수로 목표를 달성하는 방법은 없습니다. 따라서 7를 return 합니다.\n입출력 예 #3\n어떤 방법을 쓰더라도 각 큐의 원소 합을 같게 만들 수 없습니다. 따라서 -1을 return 합니다.\nanswer\n\nfrom collections import deque\n\ndef solution(queue1, queue2):\n    answer = -1\n    q1, q2 = deque(queue1),deque(queue2)\n    s2 = sum(q1 + q2)/2\n    s1 = sum(q1)\n    count = 0\n    if max(q1) &gt; s2 or max(q2)&gt;s2:\n        return -1\n        \n    while q1 and q2:\n        if s1 &gt; s2:\n            s1 -= q1.popleft()\n            count += 1\n        elif s1 &lt; s2:\n            add = q2.popleft()\n            q1.append(add)\n            s1 += add\n            count += 1\n        elif s1 == s2:\n            return count\n    return answer\n\n\nqueue1 = [3, 2, 7, 2]\n\n\nqueue2 = [4, 6, 5, 1]\n\n\nq1, q2 = deque(queue1),deque(queue2)\n\n\ns2 = sum(q1 + q2)/2\ns2\n\n15.0\n\n\n\ns1 = sum(q1)\ns1\n\n14\n\n\n\ncount = 0\n\n\n# s1&gt;s2\n\n\ns1 -= q1.popleft()\ns1\n\n11\n\n\n\ncount+=1\ncount\n\n1\n\n\n\n# s1&lt;s2\n\n\nadd = q2.popleft()\nadd\n\n4\n\n\n\nq1.append(add)\n\n\ns1 += add\ns1\n\n15\n\n\n\ncount += 1\ncount\n\n2\n\n\n\ns1==s2\n\nTrue\n\n\n\ncount\n\n2"
  },
  {
    "objectID": "posts/ct/2023-01-15-Coding_Test_Algorithm.html",
    "href": "posts/ct/2023-01-15-Coding_Test_Algorithm.html",
    "title": "Algorithm",
    "section": "",
    "text": "Algorithm"
  },
  {
    "objectID": "posts/ct/2023-01-15-Coding_Test_Algorithm.html#순열",
    "href": "posts/ct/2023-01-15-Coding_Test_Algorithm.html#순열",
    "title": "Algorithm",
    "section": "순열",
    "text": "순열\n\nimport itertools\n\ndata = [2,3,4]\n\nfor x in itertools.permutations(data,2):\n    print(list(x))\n\n[2, 3]\n[2, 4]\n[3, 2]\n[3, 4]\n[4, 2]\n[4, 3]"
  },
  {
    "objectID": "posts/ct/2023-01-15-Coding_Test_Algorithm.html#조합",
    "href": "posts/ct/2023-01-15-Coding_Test_Algorithm.html#조합",
    "title": "Algorithm",
    "section": "조합",
    "text": "조합\n\nimport itertools\n\ndata = [2,4,5,2]\n\nfor x in itertools.combinations(data,2):\n    print(list(x),end = '')\n\n[2, 4][2, 5][2, 2][4, 5][4, 2][5, 2]"
  },
  {
    "objectID": "posts/ct/2023-03-12-Coding_Test_Queue.html",
    "href": "posts/ct/2023-03-12-Coding_Test_Queue.html",
    "title": "Queue",
    "section": "",
    "text": "Queue"
  },
  {
    "objectID": "posts/ct/2023-03-12-Coding_Test_Queue.html#queue을-통해-사용하는-기능",
    "href": "posts/ct/2023-03-12-Coding_Test_Queue.html#queue을-통해-사용하는-기능",
    "title": "Queue",
    "section": "Queue을 통해 사용하는 기능",
    "text": "Queue을 통해 사용하는 기능\n\npush: 데이터를 큐에 추가한다.(큐의 전단부터 후단으로 차곡차곡 쌓는다.\npop: 큐의 가장 앞(전단) 데이터를 삭제한다.\nsize: 큐에 데이터가 몇 개 들어있는지 확인한다.\nempty: 큐가 비어 있는지 확인한다.(데이터가 없는지 확인)\nfront: 큐의 가장 앞(전단) 데이터가 무엇인지 확인한다.\nback: 큐의 가장 뒤(후단) 데이터가 무엇인지 확인한다.\n\n\\(\\star\\) 파이썬에서 queue를 사용하기 위해 deque라는 라이브러리를 이용한다. \\(\\to\\) stack과 queue의 기능을 합친 것이다."
  },
  {
    "objectID": "posts/ct/2023-08-26-Coding_Test_pp_hw.html",
    "href": "posts/ct/2023-08-26-Coding_Test_pp_hw.html",
    "title": "[Coding Test]Python Programming HW review",
    "section": "",
    "text": "1.\nHW: 0315\n02wk-1: 파이썬의 자료형 (2)\n아래와 같은 문자열이 있다고 하자.\n\na='Jeonbuk National University' \n\n1. 적당한 인덱싱을 통하여 출력결과가 아래와 같도록 하라.\n\na.find('U')\n\n17\n\n\n\na.find('y')\n\n26\n\n\n\nstr(a)\n\n'Jeonbuk National University'\n\n\n\na[a.find('U'):a.find('y')+1]\n\n'University'\n\n\nhint: University는 10글자이다.\n2. 출력결과가 아래와 같도록 하는 코드를 작성하라. (lower 함수를 이용할 것)\n\na.lower()\n\n'jeonbuk national university'\n\n\n3. 아래의 코드를 관찰하고 isupper()의 기능이 무엇인지 스스로 정리해보라.\n\n'A'.isupper()\n\nTrue\n\n\n\n'AA'.isupper()\n\nTrue\n\n\n\n'Aa'.isupper()\n\nFalse\n\n\n\n'aa'.isupper()\n\nFalse\n\n\n\n'aA'.isupper()\n\nFalse\n\n\n대문자인가 확인하는 코드!\n\n'aA'.islower()\n\nFalse\n\n\n소문자인거 확인하는 코드!\n4. 다음중 실행 불가능한 코드를 모두 골라라.\n\n‘a’*2\n\n\n'a'*2\n\n'aa'\n\n\n\n‘a’*‘2’\n\n\n'a'*'2'\n\nTypeError: can't multiply sequence by non-int of type 'str'\n\n\n\n‘a’+2\n\n\n'a'+2\n\nTypeError: can only concatenate str (not \"int\") to str\n\n\n\n‘a’+‘2’\n\n\n'a'+'2'\n\n'a2'\n\n\n\n\n2.\nHW 0315\n02wk-2: 파이썬의 자료형 (3)\n1. 길이가 0인 리스트를 만들어라. (비어있는 리스트를 만들어라)\n(풀이1)\n\n[]\n\n[]\n\n\n(풀이2)\n\nlist()\n\n[]\n\n\n2. 다음의 실행값 중 가장 큰 숫자가 나오는 보기를 골라라. (에러가 나는 코드는 정답에서 제외함)\n\n(a) len(3.14) \n(b) len([3.14]) \n(c) len('3.14') \n\n\nlen(3.14)\n\nTypeError: object of type 'float' has no len()\n\n\n\na = 3.14;a?\n\n\nType:        float\nString form: 3.14\nDocstring:   Convert a string or number to a floating point number, if possible.\n\n\n\n\n\na.is_integer()\n\nFalse\n\n\n\nlen([3.14])\n\n1\n\n\n\na = [3.14];a?\n\n\nType:        float\nString form: 3.14\nDocstring:   Convert a string or number to a floating point number, if possible.\n\n\n\n\n\na.is_integer()\n\nFalse\n\n\n\nlen('3.14') \n\n4\n\n\n\na = '3.14';a?\n\n\nType:        float\nString form: 3.14\nDocstring:   Convert a string or number to a floating point number, if possible.\n\n\n\n\n\na.is_integer()\n\nFalse\n\n\n3. 아래의 예제를 관찰하라.\n\n'제 이름은 {}입니다'.format('abc')\n\n'제 이름은 abc입니다'\n\n\n\n'제 이름은 {}이고 사는곳은 {}입니다.'.format('abc','de')\n\n'제 이름은 abc이고 사는곳은 de입니다.'\n\n\n이 예제를 바탕으로 문자열에 포함된 .format()함수의 기능을 유추하라. 그리고 아래의 결과를 확인하라.\n\\(\\to\\) .format의 기능은 {}에 문자를 순서대로 넣어주는 역할.\n\nstring = '행사가 {}월{}일-{}월{}일 abc펜션에서 있다고 합니다. 자세한 일정 등은 다시 공지하겠습니다.' \nstring.format(3,24,3,25)\n\n'행사가 3월24일-3월25일 abc펜션에서 있다고 합니다. 자세한 일정 등은 다시 공지하겠습니다.'\n\n\n\nstring.format(1,1,2,2)\n\n'행사가 1월1일-2월2일 abc펜션에서 있다고 합니다. 자세한 일정 등은 다시 공지하겠습니다.'\n\n\n4. 아래의 예제를 관찰하라.\n\n'abcdefg'.replace('g','u')\n\n'abcdefu'\n\n\n이 예제를 바탕으로 문자열의 .replace() 기능을 유추하라.\n\\(\\to\\) .replace의 기능은 ’g’를 ’u’로 바꿔준다.\n5. 리스트자료형의 +와 * 연산을 이용하여 아래와 같은 list를 생성하라.\n\n[1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5]\n\n[1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5]\n\n\n\n[1] + [2] * 2 + [3] * 3 + [4] * 4 + [5] * 5\n\n[1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5]\n\n\nhint: 아래의 코드를 관찰해보세요\n\n[1]*1+[2]*2 \n\n[1, 2, 2]\n\n\n6. 넘파이를 이용하여 아래와 같은 결과가 나오도록 코드가 작성하라.\n\\[\\begin{bmatrix}\n1 \\\\\n2\n\\end{bmatrix} + \\begin{bmatrix}\n11 \\\\\n22\n\\end{bmatrix} =\n\\begin{bmatrix}\n12 \\\\\n24\n\\end{bmatrix}\\]\n\nimport numpy as np\n\n\nnp.array([1,2]) + np.array([11,22]) \n\narray([12, 24])\n\n\n\nnp.array([[1],[2]]) + np.array([[11],[22]])\n\narray([[12],\n       [24]])\n\n\n\n아래와 같은 벡터가 있다고 하자.\n\n\\[\\boldsymbol{a}=\n\\begin{bmatrix}\n12 \\\\\n24\n\\end{bmatrix}\\]\n넘파이를 이용하여 아래의 결과가 나오게 하는 코드를 작성하라.\n\\[2\\boldsymbol{a}=\n\\begin{bmatrix}\n24 \\\\\n48\n\\end{bmatrix}\\]\n\n2 * (np.array([[1],[2]]) + np.array([[11],[22]]))\n\narray([[24],\n       [48]])\n\n\n\n2 * np.array([12, 24])\n\narray([24, 48])\n\n\n\n2 * np.array([[12], [24]])\n\narray([[24],\n       [48]])\n\n\n\n\n3.\nHW 0320\n03wk-1: 파이썬의 자료형 (4)\n1. 아래의 코드를 관찰하고, sum()의 기능을 유추하라.\n\nsum([1,0,1,0])\n\n2\n\n\n\\(\\to\\) 원소의 합\n\nsum([True,False,True,False])\n\n2\n\n\n\\(\\to\\) True는 1로, False는 0으로 인식\n2. 다음과 같은 리스트를 고려하자.\n\nx = [80,60,80,90,55,85,95,100,35,70,75,65,95]\nx\n\n[80, 60, 80, 90, 55, 85, 95, 100, 35, 70, 75, 65, 95]\n\n\n이를 수식으로 표현하면 아래와 같다.\n\\({\\bf x} = [x_1,\\dots,x_{13}]=[80,60,80,90,55,85,95,100,35,70,75,65,95]\\)\n리스트의 원소중 “\\(x_i&gt;80\\)” 의 조건을 만족하는 원소는 모두 몇개인가?\nhint: 리스트컴프리헨션과 sum()함수를 이용할 것\n\nsum([xi &gt;80 for xi in x])\n\n5\n\n\nmy answer\n\nsum([x[i] &gt; 80 for i in range(len(x))])\n\n5\n\n\n3. 다음과 같은 리스트를 고려하자.\n\n['A','B','C','D','A','A','B','A','F','C','C','C','A']\n\n['A', 'B', 'C', 'D', 'A', 'A', 'B', 'A', 'F', 'C', 'C', 'C', 'A']\n\n\n이 리스트에서 ‘A’ 혹은 ’B’의 숫자는 모두 몇개인가?\nhint: 아래를 관찰\n\n'A' &lt; 'C'\n\nTrue\n\n\n\n'B' &lt; 'C'\n\nTrue\n\n\n\nlst = ['A','B','C','D','A','A','B','A','F','C','C','C','A']\nsum([l &lt;'C' for l in lst])\n\n7\n\n\nmy answer\n\nlst = ['A','B','C','D','A','A','B','A','F','C','C','C','A']\nsum([lst[i] &lt; 'C' for i in range(len(lst))])\n\n7\n\n\n4. 아래와 같은 리스트가 있다고 하자.\n\\({\\bf x} = [1,2,1,5,6,2,4,7]\\)\n\\({\\bf y} = [3,2,4,1,2,5,6,7]\\)\n이러한 벡터를 파이썬에서 표현하기 위해서 아래와 같은 리스트를 만들었다고 하자.\n\nx=[1,2,1,5,6,2,4,7]\ny=[3,2,4,1,2,5,6,7] \n\n리스트컴프리헨션을 이용하여\n\\[{\\bf z}=[x_1^2+y_1^2, \\dots, x_{8}^2+y_{8}^2]=[x_i^2+y_i^2: \\text{for $i = 1,2,3,\\dots,8$}]\\]\n와 같은 리스트를 생성하라.\n\n[x[i]**2+y[i]**2 for i in range(8)]\n\n[10, 8, 17, 26, 40, 29, 52, 98]\n\n\nmy answer\n\n[x[i]**2 + y[i]**2 for i in range(len(x))]\n\n[10, 8, 17, 26, 40, 29, 52, 98]\n\n\n5. 아래와 같은 문자열이 있다고 하자.\n\ntest_arr = 'ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSUGPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlELEVf4h9lFX5QVkbPppSwg0cda3Pbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XAt3FaoJoAsncM1Q9x5+3V0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/EnmZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbxNrRFi9wrf+M7Q== schacon@mylaptop.local'\n\n이 문자열에서 대문자의 수를 count하라. (2022년 파이썬입문 중간고사 1-(5) 참고)\n\nsum([s.isupper() for s in test_arr ])\n\n155\n\n\nerror on my answer\n\nsum([test_arr[i] == test_arr.upper()[i] for i in range(len(test_arr))])\n\n230\n\n\n이렇게 비교하면 대문자인 것은 세겠지만, 기호가 같은 것도 세기 때문에 over해서 sum하게 된다.\n6. 리스트컴프리헨션을 이용하여 아래와 같은 리스트를 생성하라. (2022년 파이썬입문 중간고사 1-(7) 참고)\n['a',\n 'aa',\n 'aaa',\n 'aaaa',\n 'aaaaa',\n 'aaaaaa',\n 'aaaaaaa',\n 'aaaaaaaa',\n 'aaaaaaaaa',\n 'aaaaaaaaaa'] &lt;- a가 10개있음\n\n['a'*i for i in range(1,11)]\n\n['a',\n 'aa',\n 'aaa',\n 'aaaa',\n 'aaaaa',\n 'aaaaaa',\n 'aaaaaaa',\n 'aaaaaaaa',\n 'aaaaaaaaa',\n 'aaaaaaaaaa']\n\n\nmy answer\n\n['a' * i for i in range(1,11)]\n\n['a',\n 'aa',\n 'aaa',\n 'aaaa',\n 'aaaaa',\n 'aaaaaa',\n 'aaaaaaa',\n 'aaaaaaaa',\n 'aaaaaaaaa',\n 'aaaaaaaaaa']\n\n\n7. 아래와 같은 list가 있다고 하자.\n\ntest_lst = [['g',1],['u',5],['e',2],['b',8],['i',2],['n',9]]\n\ntest_lst와 리스트컴프리헨션을 이용하여 아래를 출력하는 코드를 구현하라. (2022년 파이썬입문 중간고사 1-(9) 참고)\n\n['g', 'uuuuu', 'ee', 'bbbbbbbb', 'ii', 'nnnnnnnnn']\n\n['g', 'uuuuu', 'ee', 'bbbbbbbb', 'ii', 'nnnnnnnnn']\n\n\n\n[l[0]*l[1] for l in test_lst]\n\n['g', 'uuuuu', 'ee', 'bbbbbbbb', 'ii', 'nnnnnnnnn']\n\n\nmy answer\n\n[test_lst[i][0] * test_lst[i][1] for i in range(len(test_lst))]\n\n['g', 'uuuuu', 'ee', 'bbbbbbbb', 'ii', 'nnnnnnnnn']\n\n\n8. 아래와 같은 list를 생성하라.\n[1,\n 2,2,\n 3,3,3,\n 4,4,4,4,\n 5,5,5,5,5,\n ...\n 9,9,9,9,9,9,9,9,9] &lt;- 9가 9개 있음 \n(풀이1) – 의도한 풀이\n\nlst = list()\nfor i in range(1,10):\n    lst = lst + [i]*i\n\n(풀이2) – 이걸 의도한건 아니었음…\n\nlst = [[i]*i for i in range(1,10)]\n\n\nprint(str(lst).replace(' ','').replace(',[','').replace(']',',\\n ').replace('[[','[').replace(',\\n ,',']'))\n\n[1,\n 2,2,\n 3,3,3,\n 4,4,4,4,\n 5,5,5,5,5,\n 6,6,6,6,6,6,\n 7,7,7,7,7,7,7,\n 8,8,8,8,8,8,8,8,\n 9,9,9,9,9,9,9,9,9]\n \n\n\nerror on my answer\n\n[[i] * i for i in range(1,10)]\n\n[[1],\n [2, 2],\n [3, 3, 3],\n [4, 4, 4, 4],\n [5, 5, 5, 5, 5],\n [6, 6, 6, 6, 6, 6],\n [7, 7, 7, 7, 7, 7, 7],\n [8, 8, 8, 8, 8, 8, 8, 8],\n [9, 9, 9, 9, 9, 9, 9, 9, 9]]\n\n\nright answer\n\nl = []\nfor i in range(1,10):\n    l = l + [i] * i\n\n9. 아래와 같은 리스트를 관찰하라.\n\nlst = ['2022/09/21','2022/10/30','2022/12/25','2023/01/01','2023/01/31','2023/03/20']\n\n이러한 리스트를 아래와 같은 리스트로 변환하는 코드를 작성하라.\n\n['2022-09-21', '2022-10-30', '2022-12-25', '2023-01-01', '2023-01-31', '2023-03-20']\n\n['2022-09-21',\n '2022-10-30',\n '2022-12-25',\n '2023-01-01',\n '2023-01-31',\n '2023-03-20']\n\n\nhint: string의 .replace()기능과 리스트 컴프리헨션의 응용\n\n[s.replace('/','-') for s in lst]\n\n['2022-09-21',\n '2022-10-30',\n '2022-12-25',\n '2023-01-01',\n '2023-01-31',\n '2023-03-20']\n\n\nmy answer\n\nfor i in range(len(lst)):\n    lst[i].replace('/','-')\nlst\n\n['2022/09/21',\n '2022/10/30',\n '2022/12/25',\n '2023/01/01',\n '2023/01/31',\n '2023/03/20']\n\n\n10. 아래와 같은 문자열을 고려하라.\n\n'2021. 01. 05.'\n\n'2021. 01. 05.'\n\n\n띄어쓰기를 제거하는 코드를 구현하라. 즉 출력결과가 아래와 같도록 만드는 코드를 구현하라.\n\n'2021.01.05'\n\n'2021.01.05'\n\n\nhint: 아래코드 관찰\n\n'asdf'.replace('a','')\n\n'sdf'\n\n\n\n'2021. 01. 05.'.replace(' ','')\n\n'2021.01.05.'\n\n\nmy answer\n\na = '2021.01.05';a.replace('. ','.');a\n\n'2021.01.05'\n\n\n11. 아래의 코드를 관찰하라.\n\n'-'.join(['2022','01','05'])\n\n'2022-01-05'\n\n\n\n'.'.join(['2022','01','05'])\n\n'2022.01.05'\n\n\n’dd’에 있는 내용을 이용하여 join의 원소들을 합쳐라.\n12. 아래와 같이 하나의 특수문자로 이루어진 리스트를 고려하자.\n\nblock = ['■'] \n\n이를 이용하여 아래와 같은 결과를 출력하라.\n\n'■-■-■-■-■-■-■-■-■-■' # 여기에서 '■'는 모두 10개 있음\n\n'■-■-■-■-■-■-■-■-■-■'\n\n\nhint: 11번 문제의 코드를 응용할 것\n\n'-'.join(block*10)\n\n'■-■-■-■-■-■-■-■-■-■'\n\n\nmy answer\n\n'-'.join(block*10)\n\n'■-■-■-■-■-■-■-■-■-■'\n\n\n\n\n4.\nHW: 03-22 (2)\n03wk-2: 파이썬의 자료형 (5)\n1. 길이가 1인 튜플을 만들어 자신의 학번을 저장하라. 길이가 1인 튜플을 만들어 자신의 영문이름을 저장하라. 두 튜플을 + 연산자로 합쳐아래와 같은 출력결과를 얻어라. 최종 결과는 예를들면 아래와 같아야 한다.\n\n('2021-43052', 'TomJohn')\n\n('2021-43052', 'TomJohn')\n\n\n\na='2021-43052', \nb='tomJohn',\na+b\n\n('2021-43052', 'tomJohn')\n\n\nmy answer\n\na = '2222-1111';b = 'TomJohn'; (a , b)\n\n('2222-1111', 'TomJohn')\n\n\n2-5. 아래는 파이썬프로그래밍 수강생들의 학번, 이름, 출석점수, 과제점수, 중간고사점수, 기말고사점수를 저장한 중첩리스트이다.\n\nlst = [['2021-43052', 'GuebinChoi', 5, 10, 20, 25],\n       ['2019-12342', 'Heung-min Son', 10, 15, 30, 15],\n       ['2018-32234', 'hynn', 7, 20, 30, 15],\n       ['2022-42323', 'Minji', 8, 20, 20, 35],\n       ['2023-55342', 'Hanni', 7, 20, 30, 35],\n       ['2022-46624', 'Danielle', 3, 15, 30, 40],\n       ['2022-11239', 'Haerin', 10, 20, 30, 40],\n       ['2022-32114', 'Hyein', 10, 20, 20, 35]]\nlst \n\n[['2021-43052', 'GuebinChoi', 5, 10, 20, 25],\n ['2019-12342', 'Heung-min Son', 10, 15, 30, 15],\n ['2018-32234', 'hynn', 7, 20, 30, 15],\n ['2022-42323', 'Minji', 8, 20, 20, 35],\n ['2023-55342', 'Hanni', 7, 20, 30, 35],\n ['2022-46624', 'Danielle', 3, 15, 30, 40],\n ['2022-11239', 'Haerin', 10, 20, 30, 40],\n ['2022-32114', 'Hyein', 10, 20, 20, 35]]\n\n\n2. 파이썬프로그래밍 수강생의 수는 모두 몇명인가?\n\nlen(lst)\n\n8\n\n\n3. 전북대학교 지침에 따라 출석점수가 7보다 작은 학생은 (즉 출석점수 &lt; 7 일 경우) F학점을 부여하게 되어있다. 이 기준에 따르면 F를 받는 학생은 모두 몇명인가?\n\nsum([att&lt;7 for _,_, att, *rest in lst])\n\n2\n\n\nmy answer\n\nsum([lst[i][2] &lt; 7 for i in range(len(lst))])\n\n2\n\n\n풀이 뜯어보기\n\n[att for _,_, att, *rest in lst]\n\n[5, 10, 7, 8, 7, 3, 10, 10]\n\n\n순서대로 학번, 이름, 출석점수, 나머지~\n\n-\n\nfor a,b,c,d,_,_ in lst:\n    print(c,d)\n\n5 10\n10 15\n7 20\n8 20\n7 20\n3 15\n10 20\n10 20\n\n\n-\n\nprint(*[1,2,3])\n\n1 2 3\n\n\n\nprint([1,2,3])\n\n[1, 2, 3]\n\n\n\n4. 파이썬프로그래밍 수업의 경우 출석+레포트 &lt; 21 일 경우 F학점을 부여한다고 한다. 이 기준에 따르면 F를 받는 학생은 모두 몇명인가?\n\nsum([att+rep &lt; 21 for _,_, att,rep, *rest in lst])\n\n2\n\n\nmy answer\n\nsum([c + d &lt; 21 for _,_,c,d,*rest in lst])\n\n2\n\n\n5. 리스트의 정렬순서를 [학번, 이름, …, 기말고사점수] 가 아니라 [이름, 학번, … , 기말고사점수] 와 같이 되도록 변경하는 코드를 작성하라.\n\n[[name,studentid,*rest] for studentid, name, *rest in lst]\n\n[['GuebinChoi', '2021-43052', 5, 10, 20, 25],\n ['Heung-min Son', '2019-12342', 10, 15, 30, 15],\n ['hynn', '2018-32234', 7, 20, 30, 15],\n ['Minji', '2022-42323', 8, 20, 20, 35],\n ['Hanni', '2023-55342', 7, 20, 30, 35],\n ['Danielle', '2022-46624', 3, 15, 30, 40],\n ['Haerin', '2022-11239', 10, 20, 30, 40],\n ['Hyein', '2022-32114', 10, 20, 20, 35]]\n\n\nmy answer\n\n[[b,a,*rest] for a,b,*rest in lst]\n\n[['GuebinChoi', '2021-43052', 5, 10, 20, 25],\n ['Heung-min Son', '2019-12342', 10, 15, 30, 15],\n ['hynn', '2018-32234', 7, 20, 30, 15],\n ['Minji', '2022-42323', 8, 20, 20, 35],\n ['Hanni', '2023-55342', 7, 20, 30, 35],\n ['Danielle', '2022-46624', 3, 15, 30, 40],\n ['Haerin', '2022-11239', 10, 20, 30, 40],\n ['Hyein', '2022-32114', 10, 20, 20, 35]]\n\n\n6. 아래의 코드를 관찰하라.\n\n'2023-03-22'.split('-')\n\n['2023', '03', '22']\n\n\n이 코드를 바탕으로 split의 기능을 유추하라.\n\\(\\to\\) split은 호출한 문자 기준으로 문자 나누는 역할\n7. 6의 실행결과를 되돌리는 코드를 작성하라. 즉\n\n['2023', '03', '22']\n\n['2023', '03', '22']\n\n\n와 같은 리스트를 아래의 string으로 바꾸는 코드를 작성하라.\n\n'2023-03-22'\n\n'2023-03-22'\n\n\nhint: join을 이용할 것\n\n'-'.join(['2023', '03', '22'])\n\n'2023-03-22'\n\n\nmy answer\n\nlst = ['2023', '03', '22'];'-'.join(lst)\n\n'2023-03-22'\n\n\n다음은 인터넷에서 긁어온 어떠한 텍스트이다.\n\ntext = \"국내뿐 아니라 해외 인기도 심상치 않다. 2023년 1월 18일 'Ditto'가 빌보드 핫 100에 96위로 진입했다. 이는 K-pop 역사상 데뷔후 최단 빌보드 Hot 100 차트 입성 기록이다. 다른 뮤지션들이 보통 데뷔 후 수년간 쌓아온 팬덤을 기반으로 빌보드에 입성한데 비해, 뉴진스의 기록은 이례적인 것으로 평가받고 있다. 또한 'OMG'가 빌보드 핫 100에 91위로 진입한 동시에 'Ditto'는 85위로 순위가 상승, 핫 100 주간차트에 두 곡을 올려놓았다. K-Pop 역사상 이 차트에 두 곡 이상을 진입시킨 아티스트는 방탄소년단과 블랙핑크가 유일하다. 'Ditto'는 1월 셋째주 기준, 빌보드뿐만 아니라 영국 오피셜 싱글 차트 '톱 100'에 2주 연속 진입하기도 했다.\"\n\n8. text는 총 몇개의 문장으로 이루어져 있는가?\nhint: 이 텍스트의 문장은 모두 .로 끝난다.\n\nlst = text.split('. ')\nlst \n\n['국내뿐 아니라 해외 인기도 심상치 않다',\n \"2023년 1월 18일 'Ditto'가 빌보드 핫 100에 96위로 진입했다\",\n '이는 K-pop 역사상 데뷔후 최단 빌보드 Hot 100 차트 입성 기록이다',\n '다른 뮤지션들이 보통 데뷔 후 수년간 쌓아온 팬덤을 기반으로 빌보드에 입성한데 비해, 뉴진스의 기록은 이례적인 것으로 평가받고 있다',\n \"또한 'OMG'가 빌보드 핫 100에 91위로 진입한 동시에 'Ditto'는 85위로 순위가 상승, 핫 100 주간차트에 두 곡을 올려놓았다\",\n 'K-Pop 역사상 이 차트에 두 곡 이상을 진입시킨 아티스트는 방탄소년단과 블랙핑크가 유일하다',\n \"'Ditto'는 1월 셋째주 기준, 빌보드뿐만 아니라 영국 오피셜 싱글 차트 '톱 100'에 2주 연속 진입하기도 했다.\"]\n\n\n\nlen(lst)\n\n7\n\n\nerror on my answer\n\nlen(text.split('.'))-1\n\n7\n\n\n\\(\\to\\) . 띄어쓰기를 생각 못 함\n9. 각 문장은 몇개의 단어로 이루어져 있는가?\nhint: 각 단어는 공백으로 구분된다.\n\n[len(s.split(' ')) for s in lst]\n\n[6, 9, 11, 18, 18, 12, 16]\n\n\n\nsum([len(s.split(' ')) for s in lst])\n\n90\n\n\nmy answer\n\n[len(text.split('. ')[i].split(' ')) for i in range(len(text.split('. ')))]\n\n[6, 9, 11, 18, 18, 12, 16]\n\n\n\nsum([len(text.split('. ')[i].split(' ')) for i in range(len(text.split('. ')))])\n\n90\n\n\n10. 100이라는 단어가 포함된 문장은 모두 몇 개 인가?\nhint: 아래의 코드를 관찰\n\n'a' in 'abcd'\n\nTrue\n\n\n\n['100' in s for s in lst]\n\n[False, True, True, False, True, False, True]\n\n\n\nsum(['100' in s for s in lst])\n\n4\n\n\nmy answer\n\nsum(['100' in text.split('. ')[i] for i in range(len(text.split('. ')))])\n\n4\n\n\n\n\n5\nHW 0327 (1)\n04wk-1: 파이썬의 자료형 (6)\nssh코드: 1-2\n아래의 문자열을 고려하자.\n\ntest_arr = 'ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSUGPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlELEVf4h9lFX5QVkbPppSwg0cda3Pbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XAt3FaoJoAsncM1Q9x5+3V0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/EnmZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbxNrRFi9wrf+M7Q== schacon@mylaptop.local'\n\n1. 이 문자열에서 index = 0,2,4,6,8,… 에 해당하는 원소를 출력하는 코드를 작성하라. (2022-파이썬입문 중간고사 1-(2) 참고)\n# 출력결과는 아래와 같아야 한다. \n\n'shraAABNa1cEAAIAAEkOpDrH1SrTpLG9jmBDUP+azHTWhIy5w8HJ9bUriz7lLV49F5VbpSgcaPvkd/TBWFRHoFRtqi1KXHZMiqVRsAwsMvlK7A3aJAnMQx+VW6/Im1uFjJpr8XpDjNyv/bretEm+WOPTI9PVLar2E6/lbg331KtIj2od1rTMVsxrF9r+7= cao@yatplcl'\n\ntest_arr[::2]\n\n'shraAABNa1cEAAIAAEkOpDrH1SrTpLG9jmBDUP+azHTWhIy5w8HJ9bUriz7lLV49F5VbpSgcaPvkd/TBWFRHoFRtqi1KXHZMiqVRsAwsMvlK7A3aJAnMQx+VW6/Im1uFjJpr8XpDjNyv/bretEm+WOPTI9PVLar2E6/lbg331KtIj2od1rTMVsxrF9r+7= cao@yatplcl'\n\n\n2. 위 문자열을 뒤집은 문자열을 구하는 코드를 구현하라. (2022-파이썬입문 중간고사 1-(4) 참고)\n# 출력결과는 아래와 같아야 한다. \n\n'lacol.potpalym@nocahcs ==Q7M+frw9iFRrNxbsSVqMlTarQ10d1os2njkImtaKn1+3r3wg+b8li/Z68Ec2DryauLMVmPZ98IPTnPZO4WA+ZmnE/trewr0bP/wv6ybNYjvDNpyX88XrrpKJQjlFUuz1bmFIe/86wW0V3+5x9Q1McnsAoJoaF3tAX7/KVlSvFMdsdwQANsjR6V8qLicMsZAHpXhKn1XixqBtiRXF3oAH+RCFXWlByTM/JdOk7vbP3adc0gwSppPbkVQ5XFl9h4fVELElx7MzQivrFUhbj9WJ4HJ81we5Zy4Idh7WYTDHlzfan+lPGUSDWB/mojT9KGTLNpITmrbS71YHfrHDkpUOlkAEQAAAwIBAAAAE2cy1CazN3BAAAA asr-hss'\n\ntest_arr[::-1]\n\n'lacol.potpalym@nocahcs ==Q7M+frw9iFRrNxbsSVqMlTarQ10d1os2njkImtaKn1+3r3wg+b8li/Z68Ec2DryauLMVmPZ98IPTnPZO4WA+ZmnE/trewr0bP/wv6ybNYjvDNpyX88XrrpKJQjlFUuz1bmFIe/86wW0V3+5x9Q1McnsAoJoaF3tAX7/KVlSvFMdsdwQANsjR6V8qLicMsZAHpXhKn1XixqBtiRXF3oAH+RCFXWlByTM/JdOk7vbP3adc0gwSppPbkVQ5XFl9h4fVELElx7MzQivrFUhbj9WJ4HJ81we5Zy4Idh7WYTDHlzfan+lPGUSDWB/mojT9KGTLNpITmrbS71YHfrHDkpUOlkAEQAAAwIBAAAAE2cy1CazN3BAAAA asr-hss'\n\n\n파이썬 프로그래밍 시험성적: 3-4\n아래와 같은 dictionary가 있다고 가정하자.\n\ndct={'202212377': {'att': 65, 'rep': 45, 'mid': 0, 'fin': 10},\n     '202212473': {'att': 95, 'rep': 30, 'mid': 60, 'fin': 10},\n     '202212310': {'att': 65, 'rep': 85, 'mid': 15, 'fin': 20},\n     '202212460': {'att': 55, 'rep': 35, 'mid': 35, 'fin': 5},\n     '202212320': {'att': 80, 'rep': 60, 'mid': 55, 'fin': 70},\n     '202212329': {'att': 75, 'rep': 40, 'mid': 75, 'fin': 85},\n     '202212408': {'att': 65, 'rep': 70, 'mid': 60, 'fin': 75},\n     '202212319': {'att': 60, 'rep': 25, 'mid': 20, 'fin': 35},\n     '202212348': {'att': 95, 'rep': 55, 'mid': 65, 'fin': 90},\n     '202212306': {'att': 90, 'rep': 25, 'mid': 95, 'fin': 50},\n     '202212308': {'att': 55, 'rep': 45, 'mid': 75, 'fin': 30},\n     '202212366': {'att': 95, 'rep': 60, 'mid': 25, 'fin': 55},\n     '202212367': {'att': 95, 'rep': 35, 'mid': 0, 'fin': 25},\n     '202212461': {'att': 50, 'rep': 55, 'mid': 90, 'fin': 45}}\n\n여기에서 ‘202212377’ 등은 학번을, att는 출석점수, rep는 레포트점수, mid는 중간고사 점수, fin은 기말고사 점수를 의미한다.\n3. 학생들의 학번을 아래와 같은 방식으로 출력하는 코드를 작성하라.\n# 출력예시\n\n['2022-12377',\n '2022-12473',\n '2022-12310',\n '2022-12460',\n '2022-12320',\n '2022-12329',\n '2022-12408',\n '2022-12319',\n '2022-12348',\n '2022-12306',\n '2022-12308',\n '2022-12366',\n '2022-12367',\n '2022-12461']\n\n[k[:4]+'-'+k[4:] for k in dct]\n\n['2022-12377',\n '2022-12473',\n '2022-12310',\n '2022-12460',\n '2022-12320',\n '2022-12329',\n '2022-12408',\n '2022-12319',\n '2022-12348',\n '2022-12306',\n '2022-12308',\n '2022-12366',\n '2022-12367',\n '2022-12461']\n\n\nerror on my answer\n\nfor k in dct.keys():\n    print(k[:4],'-',k[4:])\n\n2022 - 12377\n2022 - 12473\n2022 - 12310\n2022 - 12460\n2022 - 12320\n2022 - 12329\n2022 - 12408\n2022 - 12319\n2022 - 12348\n2022 - 12306\n2022 - 12308\n2022 - 12366\n2022 - 12367\n2022 - 12461\n\n\n띄어쓰기가 있고, ’’로 묶이지도 않았고, 리스트로 묶이지도 않음\n\nkk = []\nfor k in dct.keys():\n    kk.append(k[:4]+'-'+k[4:])\nkk\n\n['2022-12377',\n '2022-12473',\n '2022-12310',\n '2022-12460',\n '2022-12320',\n '2022-12329',\n '2022-12408',\n '2022-12319',\n '2022-12348',\n '2022-12306',\n '2022-12308',\n '2022-12366',\n '2022-12367',\n '2022-12461']\n\n\n4. 출석점수가 70점 이상인(&gt;=70) 학생들의 학번을 출력하는 코드를 작성하라. (2022-파이썬입문 중간고사 2-(3) 참고)\n# 출력예시 \n\n['2022-12473',\n '2022-12320',\n '2022-12329',\n '2022-12348',\n '2022-12306',\n '2022-12366',\n '2022-12367']\n\n[k[:4]+'-'+k[4:] for k,v in dct.items() if v['att']&gt;70]\n\n['2022-12473',\n '2022-12320',\n '2022-12329',\n '2022-12348',\n '2022-12306',\n '2022-12366',\n '2022-12367']\n\n\nmy answer\n\n[k[:4] + '-' + k[4:] for k in dct if dct[k]['att']&gt;=70]\n\n['2022-12473',\n '2022-12320',\n '2022-12329',\n '2022-12348',\n '2022-12306',\n '2022-12366',\n '2022-12367']\n\n\n\nOxford-III: 5–10 // reference\n아래는 이미지 파일명들이 저장된 string을 불러오는 코드이다.\n\nimport requests\nurl = 'https://raw.githubusercontent.com/guebin/PP2023/main/posts/01_PythonBasic/Oxford-IIIT.txt'\ntxt = requests.get(url).content.decode()\n\ntxt의 출력 일부를 나타내면 아래와 같다.\n\n'Abyssinian_1.jpg\\nAbyssinian_10.jpg\\nAbyssinian_100.jpg\\nAbyssinian_100.mat\\nAbyssinian_101.jpg\\nAbyssinian_101.mat\\nAbyssinian_102.jpg\\nAbyssinian_102.mat\\nAbyssinian_103.jpg\\nAbyssinian_104.jpg\\nAbyssinian_105.jpg\\nAbyssinian_106.jpg\\nAbyssinian_107.jpg\\nAbyssinian_108.jpg\\nAbyssinian_109.jpg\\nAbyssinian_11.jpg\\nAbyssinian_110.jpg\\nAbyssinian_111.jpg\\nAbyssinian_112.jpg\\nAbyssinian_113.jpg\\nAbyssinian_114.jpg\\nAbyssinian_115.jpg\\nAbyssinian_116.jpg\\nAbyssinian_117.jpg\\nAbyssinian_118.jpg\\nAbyssinian_119.jpg\\nAbyssinian_12.jpg\\nAbyssinian_120.jpg\\nAbyssinian_121.jpg\\nAbyssinian_122.jpg\\nAbyssinian_123.jpg\\nAbyssinian_124.jpg\\nAbyssinian_125.jpg\\nAbyssinian_126.jpg\\nAbyssinian_127.jpg\\nAbyssinian_128.jpg\\nAbyssinian_129.jpg\\nAbyssinian_13.jpg\\nAbyssinian_130.jpg\\nAbyssinian_131.jpg\\nAbyssinian_132.jpg\\n ....... \n\n5. 각 파일명은 구분되어있다. 위의 스트링을 분해하여 아래와 같은 리스트를 생성하고 fname_list에 저장하라.\n# fname_list 의 출력결과는 아래와 같아야 한다. \n['Abyssinian_1.jpg','Abyssinian_10.jpg', ... ,'yorkshire_terrier_98.jpg', 'yorkshire_terrier_99.jpg']\n\nfname_list = txt.split('\\n')\nfname_list[:10]\n\n['Abyssinian_1.jpg',\n 'Abyssinian_10.jpg',\n 'Abyssinian_100.jpg',\n 'Abyssinian_100.mat',\n 'Abyssinian_101.jpg',\n 'Abyssinian_101.mat',\n 'Abyssinian_102.jpg',\n 'Abyssinian_102.mat',\n 'Abyssinian_103.jpg',\n 'Abyssinian_104.jpg']\n\n\n6. 각 이미지파일명은 아래와 같은 규칙으로 저장되어 있다.\n\n파일명의 첫글자가 대문자이면 고양이를 의미하고 첫글자가 소문자이면 강아지를 의미한다.\n_ 이전의 영문명은 고양이 혹은 강아지의 종(breed)을 의미한다.\n이미지 파일명이 입력으로 오면 강아지인지 고양이인지 판단하여 ‘cat’ or ’dog’를 리턴하는 함수 f를 구현하라.\n\n(함수사용예시)\n\nf('yorkshire_terrier_99.jpg')\n'dog'\nf('Abyssinian_1.jpg')\n'cat'\n\ndef f(fname): \n    return 'cat' if fname[0].isupper() else 'dog' \n\n\nf('yorkshire_terrier_99.jpg'), f('Abyssinian_1.jpg')\n\n('dog', 'cat')\n\n\nmy answer\n\ndef name(name):\n    if name[0].isupper():\n        return 'cat'\n    elif name[0].islower():\n        return 'dog'\n\n\nname('yorkshire_terrier_99.jpg'), name('Abyssinian_1.jpg')\n\n('dog', 'cat')\n\n\n7. 5의 결과로 나온 fname_list를 입력으로 하고 리스트의 각 원소가 고양이를 의미하는 그림인지 강아지를 의미하는 그림인지 나타내는 리스트를 만들어라.\n## 입력예시 \n['Abyssinian_1.jpg','Abyssinian_10.jpg',...,'yorkshire_terrier_98.jpg', 'yorkshire_terrier_99.jpg']\n## 출력예시\n['cat', 'cat', ... , 'dog', 'dog']\n\nresult = [f(l) for l in fname_list]\nresult[:10]\n\n['cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat']\n\n\nmy answer\n\n[f(fname_list[i]) for i in range(len(fname_list))][:10]\n\n['cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat']\n\n\n8. 강아지 그림과 고양이 그림이 각각 몇 장씩 포함되어 있는지 파악하는 코드를 구현하라.\n\nsum([s=='cat' for s in result]) # 고양이\n\n2403\n\n\n\nsum([s=='dog' for s in result]) # 강아지\n\n4990\n\n\nmy answer\n\nsum([result[i] == 'cat' for i in range(len(result))])\n\n2403\n\n\n\nlen(result) - sum([result[i] == 'cat' for i in range(len(result))])\n\n4990\n\n\n9. 포메라니안 종의 그림이 몇장있는지 파악하는 코드를 구현하라.\nhint: 포메라니안 그림은 파일명에 ‘pomeranian’ 을 포함한다.\n\nsum(['pomeranian'  in s for s in fname_list])\n\n200\n\n\nmy answer\n’pomeranian’을 포함하면 0이 return 되고 아니면 -1이 return되는 코드로 길게 짰다.\n\nlen(fname_list) + sum(fname_list[i].find('pomeranian') for i in range(len(fname_list)))\n\n200\n\n\n10. 아래의 dct는 포메라니안과 사모예드가 각각 몇장씩 포함되어있는지 정리하기 위해 임시로 정리한 dictionary이다. 각 종이 몇 장씩 포함되어있는지 구하여 dct를 수정하라.\n\ndct = {'pomeranian':0, 'samoyed':0} \ndct\n\n{'pomeranian': 0, 'samoyed': 0}\n\n\n예를들어 포메라니안과 사모에예드의 그림이 각각 200장씩 있다면 아래와 같이 딕셔너리를 수정해야한다.\n\ndct['pomeranian'] = sum(['pomeranian'  in s for s in fname_list])\ndct['samoyed'] = sum(['samoyed'  in s for s in fname_list])\ndct\n\n{'pomeranian': 200, 'samoyed': 200}\n\n\nmy answer\n\ndct['pomeranian'] = sum(['pomeranian'  in s for s in fname_list])\n\n\ndct['samoyed'] = sum(['samoyed'  in s for s in fname_list])\n\n\ndct\n\n{'pomeranian': 200, 'samoyed': 200}\n\n\n\n\n6.\nHW 0327 (2)\n04wk-1: 파이썬의 자료형 (6)\n1. 아래와 같은 맵핑을 고려하자.\n\n\n\n문자\n숫자\n\n\n\n\na\n1\n\n\nb\n0\n\n\n\n이를 딕셔너리로 표현하면 아래와 같다.\n\ndct = {'a':0, 'b':1} \n\n위 규칙에 따라서 아래의 리스트의 원소를 문자로 각각 변환하라.\n\nlst = [1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1]\n\n# 출력은 아래와 같아야 한다. \n['b', 'a', 'b', 'a', 'b', 'a', 'b', 'b', 'b', 'b', 'a', 'a', 'b', 'a', 'b']\n\n[k for l in lst for k,v in dct.items() if v==l]\n\n['b', 'a', 'b', 'a', 'b', 'a', 'b', 'b', 'b', 'b', 'a', 'a', 'b', 'a', 'b']\n\n\nerror on my answer\n인덱싱된 값(value)을 가져와서 lst랑 비교한다음 id랑 연결해야 하는데, 연결해서 가져오는 법을 몰랐다.\n\n[v for k,v in dct.items()]\n\n[0, 1]\n\n\n\n[k for k,v in dct.items()]\n\n['a', 'b']\n\n\n\n[k for s in lst for k,v in dct.items() if v==s]\n\n['b', 'a', 'b', 'a', 'b', 'a', 'b', 'b', 'b', 'b', 'a', 'a', 'b', 'a', 'b']\n\n\n2. 아래와 같은 맵핑을 고려하자.\n\n\n\n월\n의미\n\n\n\n\n1,2\n겨울방학\n\n\n3,4,5,6\n1학기\n\n\n7,8\n여름방학\n\n\n9,10,11,12\n2학기\n\n\n\n이러한 규칙에 맞게 아래의 리스트를 적절한 문자열로 변환하라.\n\nmonth = [1,2,2,3,4,5,6,7,8,9,9,10,11,12] \n\n## 출력은 아래와 같아야 한다. \n['겨울방학', '겨울방학', '겨울방학', '1학기', '1학기', '1학기', '1학기', '여름방학', '여름방학', '2학기', '2학기', '2학기', '2학기', '2학기']\n\ndct = {'겨울방학':[1,2], '1학기':[3,4,5,6], '여름방학':[7,8], '2학기':[9,10,11,12]} \n[k for m in month for k,v in dct.items() if m in v] \n\n['겨울방학',\n '겨울방학',\n '겨울방학',\n '1학기',\n '1학기',\n '1학기',\n '1학기',\n '여름방학',\n '여름방학',\n '2학기',\n '2학기',\n '2학기',\n '2학기',\n '2학기']\n\n\nmy answer\nif c in v을 못 씀…..\n\ndct = {'겨울방학':[1,2],'1학기':[3,4,5,6],'여름방학':[7,8],'2학기':[9,10,11,12]}\n\n\n[k for c in month for k,v in dct.items() if c in v]\n\n['겨울방학',\n '겨울방학',\n '겨울방학',\n '1학기',\n '1학기',\n '1학기',\n '1학기',\n '여름방학',\n '여름방학',\n '2학기',\n '2학기',\n '2학기',\n '2학기',\n '2학기']\n\n\n\n합성변환 3-5.\n아래와 같은 맵핑을 고려하자.\n(규칙1)\n\n\n\n문자\n숫자\n\n\n\n\n바나나\n0\n\n\n사과\n1\n\n\n오토바이\n2\n\n\n자동차\n3\n\n\n자전거\n4\n\n\n\n(규칙2)\n\n\n\n아이템\n카테고리\n\n\n\n\n바나나\n과일\n\n\n사과\n과일\n\n\n오토바이\n탈것\n\n\n자동차\n탈것\n\n\n자전거\n탈것\n\n\n\n각각의 규칙을 나타내는 딕셔너리는 아래와 같이 선언되어있다고 하자.\n\ndct1 = {'바나나':0, '사과':1, '오토바이':2, '자동차':3, '자전거':4} \ndct2 = {'과일':['바나나','사과'], '탈것':['오토바이','자동차','자전거']} \n\n3. 규칙1를 이용하여 아래와 같은 리스트를 변환하는 함수를 구현하고 그 함수를 f라 선언하라.\n# 입력 \n[0,1,0,1,4]\n\n# 출력 \n['바나나', '사과', '바나나', '사과', '자전거']\n(사용예시)\n\nf([0,1,0,1,4])\n\n['바나나', '사과', '바나나', '사과', '자전거']\n\ndef f(lst):\n    return [k for l in lst for k,v in dct1.items() if v == l]    \n\nf([0,1,0,1,4])\n\n['바나나', '사과', '바나나', '사과', '자전거']\n\n\nmy answer\n\n[k for i in [0,1,0,1,4] for k,v in dct1.items() if i==v]\n\n['바나나', '사과', '바나나', '사과', '자전거']\n\n\n\ndef f_csy(a):\n    return [k for i in a for k,v in dct1.items() if i==v]\n\n\nf_csy([0,1,0,1,4])\n\n['바나나', '사과', '바나나', '사과', '자전거']\n\n\n4. 규칙2를 이용하여 아래와 같이 리스트를 변환하는 함수를 구현하고 그 함수를 g라고 선언하라.\n# 입력 \n['바나나','바나나','바나나','자동차']\n\n# 출력 \n['과일','과일','과일','탈것']\n\n(사용예시)\n\ng(['바나나','바나나','바나나','자동차'])\n\n['과일', '과일', '과일', '탈것']\n\ndef g(lst):\n    return [k for l in lst for k,v in dct2.items() if l in v] \n\ng(['바나나','바나나','바나나','자동차'])\n\n['과일', '과일', '과일', '탈것']\n\n\nmy answer\n\n[k for a in ['바나나','바나나','바나나','자동차'] for k,v in dct2.items() if a in v]\n\n['과일', '과일', '과일', '탈것']\n\n\n\ndef g_csy(b):\n    return([k for a in b for k,v in dct2.items() if a in v])\n\n\ng_csy(['바나나','바나나','바나나','자동차'])\n\n['과일', '과일', '과일', '탈것']\n\n\n5. 규칙1-2를 이용하여 아래와 같은 숫자로 이루어진 입력을 ‘과일’, ‘탈것’ 중 하나로 바꾸는 코드를 구현하라.\n# 입력 \n[0,1,0,1,3,4,2,2,3,4,1,0]\n\n# 출력 \n['과일', '과일', '과일', '과일', '탈것', '탈것', '탈것', '탈것', '탈것', '탈것', '과일', '과일']\nhint \\(g(f(x))\\) 를 이용하라.\n\ng(f([0,1,0,1,3,4,2,2,3,4,1,0]))\n\n['과일', '과일', '과일', '과일', '탈것', '탈것', '탈것', '탈것', '탈것', '탈것', '과일', '과일']\n\n['과일', '과일', '과일', '과일', '탈것', '탈것', '탈것', '탈것', '탈것', '탈것', '과일', '과일']\n\n\nmy answer\n\ng_csy(f_csy([0,1,0,1,3,4,2,2,3,4,1,0]))\n\n['과일', '과일', '과일', '과일', '탈것', '탈것', '탈것', '탈것', '탈것', '탈것', '과일', '과일']\n\n\n\n\n7.\n04wk-2: 파이썬의 자료형 (7)\nOxford-III: 1–5 // reference\n아래는 이미지 파일명들이 저장된 string을 불러오는 코드이다.\n\nimport requests\nurl = 'https://raw.githubusercontent.com/guebin/PP2023/main/posts/01_PythonBasic/Oxford-IIIT.txt'\ntxt = requests.get(url).content.decode()\n\n이미지파일이 저장된 형식은 아래와 같다.\nAbyssinian_1.jpg\nBritish_Shorthair_129.jpg\nnote: British_Shorthair와 같이 종 이름 사이에 _가 들어있는 경우도 있음.\n1. txt를 적당히 변환하여 아래와 같은 list를 만들어라.\nlst[:10],lst[810:820]\n\n(['Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian'],\n ['BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair'])\nhint1\n\n'Abyssinian_1.jpg\\nAbyssinian_10.jpg'.split('\\n')\n\n['Abyssinian_1.jpg', 'Abyssinian_10.jpg']\n\n\nhint2\n\n''.join(['British', 'Shorthair'])\n\n'BritishShorthair'\n\n\n\n''.join(['Abyssinian'])\n\n'Abyssinian'\n\n\n(풀이1)\n\nlst = [''.join(filename.split('_')[:-1]) for filename in txt.split('\\n')]\n\n\nlst[:10],lst[810:820]\n\n(['Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian'],\n ['BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair'])\n\n\n(풀이2)\n\ndef f(filename): \n    *name, _ = filename.split('_')\n    return ''.join(name)\nlst = [f(filename) for filename in txt.split('\\n')]\n\n\nlst[:10],lst[810:820]\n\n(['Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian'],\n ['BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair'])\n\n\nmy answer\n\nlst = [''.join(txt.split('\\n')[i].split('_')[:-1]) for i in range(len(txt.split('\\n')))]\n\n\nlst[:10],lst[810:820]\n\n(['Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian'],\n ['BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair',\n  'BritishShorthair'])\n\n\n2. 그림파일에는 총 몇가지 종류의 고양이와, 몇가지 종류의 강아지가 있는가?\nnote: 고양이사진은 대문자로 시작하고, 강아지 사진은 소문자로 시작한다.\nnote: 12종의 고양이, 25종의 강아지가 있음\n\n[s[0].isupper() for s in set(lst)].count(True) # 고양이 12\n\n12\n\n\n\n[s[0].isupper() for s in set(lst)].count(False) # 강아지 25 \n\n25\n\n\nmy answer\n\nlen([i for i in set(lst) if i[0].isupper()])\n\n12\n\n\n\nlen([i for i in set(lst) if i[0].islower()])\n\n25\n\n\n3. 아래는 1번의 결과로 얻어진 lst의 첫 10개의 원소와 마지막 10개의 원소이다.\nlst[:10], lst[-10:]\n\n(['Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian',\n  'Abyssinian'],\n ['yorkshireterrier',\n  'yorkshireterrier',\n  'yorkshireterrier',\n  'yorkshireterrier',\n  'yorkshireterrier',\n  'yorkshireterrier',\n  'yorkshireterrier',\n  'yorkshireterrier',\n  'yorkshireterrier',\n  'yorkshireterrier'])\n적당한 변환을 정의하여 lst를 아래와 같이 바꾸어라.\nlst2[:10], lst2[-10:] # 바뀐 lst\n(['cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat'],\n ['dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog'])\n(풀이1)\n\ndct = {'cat':[s for s in set(lst) if s[0].isupper()], 'dog': [s for s in set(lst) if not s[0].isupper()]}\nlst2 = [k for l in lst for k,v in dct.items() if l in v]\n\n(풀이2)\n\ndef f(fname): \n    return 'cat' if fname[0].isupper() else 'dog'\nlst2= [f(fname) for fname in lst]\n\nmy answer\n\nlst2 = []\nfor j in range(len(lst)):\n    if [lst[l][0].isupper() for l in range(len(lst))][j] == True:\n        lst2.append('cat')\n    else:\n        lst2.append('dog')\n\n4. txt에는 강아지사진과 고양이사진이 모두 몇장씩 들어있는가?\n## 출력예시 \n\n{'dog': 4990, 'cat': 2403}\n\n{k:lst2.count(k) for k in ['dog','cat']}\n\n{'dog': 4990, 'cat': 2403}\n\n\nmy answer\n너무 길게 코드를 짰다.. 비.효.율.적.\n\n{'dog':sum((lst2[i] == 'dog' for i in range(len(lst2)))),\n 'cat':sum((lst2[i] == 'cat' for i in range(len(lst2))))}\n\n{'dog': 4990, 'cat': 2403}\n\n\n5. txt에 각 종별로 몇장의 사진이 있는지 조사하라.\n## 출력예시\n\n{'beagle': 200,\n 'scottishterrier': 199,\n 'newfoundland': 200,\n 'Birman': 200,\n 'Bombay': 200,\n 'pug': 200,\n 'germanshorthaired': 200,\n 'samoyed': 200,\n 'Sphynx': 200,\n 'englishsetter': 200,\n 'Bengal': 200,\n 'MaineCoon': 200,\n 'Persian': 200,\n 'boxer': 200,\n 'staffordshirebullterrier': 191,\n 'Siamese': 200,\n 'bassethound': 200,\n 'wheatenterrier': 200,\n 'englishcockerspaniel': 200,\n 'Ragdoll': 200,\n 'yorkshireterrier': 200,\n 'EgyptianMau': 200,\n 'BritishShorthair': 200,\n 'keeshond': 200,\n 'RussianBlue': 200,\n 'saintbernard': 200,\n 'americanbulldog': 200,\n 'Abyssinian': 203,\n 'leonberger': 200,\n 'greatpyrenees': 200,\n 'japanesechin': 200,\n 'pomeranian': 200,\n 'chihuahua': 200,\n 'shibainu': 200,\n 'americanpitbullterrier': 200,\n 'miniaturepinscher': 200,\n 'havanese': 200}\n\n{k:lst.count(k) for k in set(lst)}\n\n{'greatpyrenees': 200,\n 'americanbulldog': 200,\n 'englishcockerspaniel': 200,\n 'japanesechin': 200,\n 'boxer': 200,\n 'Sphynx': 200,\n 'havanese': 200,\n 'saintbernard': 200,\n 'samoyed': 200,\n 'yorkshireterrier': 200,\n 'wheatenterrier': 200,\n 'chihuahua': 200,\n 'MaineCoon': 200,\n 'miniaturepinscher': 200,\n 'RussianBlue': 200,\n 'pug': 200,\n 'Bengal': 200,\n 'americanpitbullterrier': 200,\n 'pomeranian': 200,\n 'EgyptianMau': 200,\n 'englishsetter': 200,\n 'Birman': 200,\n 'shibainu': 200,\n 'germanshorthaired': 200,\n 'Persian': 200,\n 'beagle': 200,\n 'staffordshirebullterrier': 191,\n 'keeshond': 200,\n 'newfoundland': 200,\n 'Bombay': 200,\n 'Siamese': 200,\n 'BritishShorthair': 200,\n 'scottishterrier': 199,\n 'leonberger': 200,\n 'Ragdoll': 200,\n 'Abyssinian': 203,\n 'bassethound': 200}"
  },
  {
    "objectID": "posts/ct/2023-01-01-Coding_Test_Greedy.html",
    "href": "posts/ct/2023-01-01-Coding_Test_Greedy.html",
    "title": "Chapter 03 Greedy",
    "section": "",
    "text": "그리디; 현재 상황에서 가장 좋아 보이는 것만을 선택하는 알고리즘 ~ 탐욕법"
  },
  {
    "objectID": "posts/ct/2023-01-01-Coding_Test_Greedy.html#example-거스름돈",
    "href": "posts/ct/2023-01-01-Coding_Test_Greedy.html#example-거스름돈",
    "title": "Chapter 03 Greedy",
    "section": "Example 거스름돈",
    "text": "Example 거스름돈\n당신은 음식점의 계산을 도와주는 점원이다. 카운터에는 거스름돈으로 사용할 500원, 100원, 50원, 10원짜리 동전이 무한히 존재한다고 가정한다. 손님에게 거슬러 줘야 할 돈이 N원일 때 거슬러 줘야 할 동전의 최소 개수를 구하라. 단, 거슬러 줘야 할 돈 N은 항상 10의 배수이다.\n해설\n\n최소 동전 개수 \\(\\to\\) ‘가장 큰 화폐 단위부터’ 돈을 거슬러 주는 것\n\n이 예제가 그리디 알고리즘이 가능한 이유\n\n가지고 있는 동전 중에서 큰 단위가 항상 작은 단위의 배수이므로 작은 단위의 동전들을 종합해 다른 해가 나올 수 없기 때문이다.\n대부분의 그리디 알고리즘 문제에서는 이처럼 문제 풀이를 위한 최소한의 아이디어를 떠올리고 이것이 정당한지 검토할 수 있어야 답을 도출할 수 있다.\n\n\nAnswer\n\nn = 1260\ncount = 0\n\n# 큰 단위 화폐부터 차례대로 확인\ncoin_types = [500, 100, 50, 10]\n\nfor coin in coin_types:\n    count += n // coin # 해당 화폐로 거슬러 줄 수 있는 동전의 개수 세기\n    n %= coin\n    \nprint(count)\n\n6\n\n\n\n\nstep\n\ncount = 0;count\n\n0\n\n\n\nn = 1260;n\n\n1260\n\n\n\ncount = count + n//500;count\n\n2\n\n\n\nn %= 500;n\n\n260\n\n\n\ncount = count + n//100;count\n\n4\n\n\n\nn %= 100 ; n\n\n60\n\n\n\ncount = count + n//50;count\n\n5\n\n\n\nn %= 50 ; n\n\n10\n\n\n\ncount = count + n//10;count\n\n6\n\n\n\nn %= 10;n\n\n0"
  },
  {
    "objectID": "posts/ct/2023-01-01-Coding_Test_Greedy.html#큰-수의-법칙",
    "href": "posts/ct/2023-01-01-Coding_Test_Greedy.html#큰-수의-법칙",
    "title": "Chapter 03 Greedy",
    "section": "큰 수의 법칙",
    "text": "큰 수의 법칙\n’큰 수의 법칙’은 일반적으로 통계 분야에서 다루어지는 내용이지만 동빈이는 본인만의 방식으로 다르게 사용하고 있다. 동빈이의 큰 수의 법칙은 다양한 수로 이루어진 배열이 있을 때 주어진 수들을 M번 더하여 가장 큰 수를 만드는 법칙이다. 단 배열의 특정한 인덱스(번호)에 해당하는 수가 연속해서 K번 초과하여 더해질 수 없는 것이 이 법칙의 특징이다.\n배열의 크기 N, 숫자가 더해지는 횟수 M, 그리고 K가 주어질 떄 동빈이의 큰 수의 법칙에 따른 결과를 출력하시오.\n입력 조건\n\n첫쨰 줄에 \\(N(2\\le N \\le 1,000), M(1 \\le M \\le 10,000), K(1 \\le K \\le 10,000)\\)의 자연수가 주어지며, 각 자연수는 공백으로 구분한다.\n둘째 줄에 N개의 자연수가 주어진다. 각 자연수는 공백으로 구분한다. 단, 각각의 자연수는 1 이상 10,000 이하의 수로 주어진다.\n입력으로 주어지는 K는 항상 M보다 작거나 같다.\n\n출력 조건\n\n첫째 줄에 동빈이의 큰 수의 법칙에 따라 더해진 답을 출력한다.\n\n해설\n\n’가장 큰 수를 K번 더하고 두 번째로 큰 수를 한 번 더하는 연산’을 반복\n반복되는 수열에 대해서 파악하기\n\n가장 큰 수가 더해지는 횟수 \\[int(M / (K + 1)) * K + M \\% (K + 1)\\]\n\nAnswer 1\n\n# N, M, K를 공백으로 구분하여 입력받기\nn, m, k = map(int, input().split())\n# N개의 수를 공백으로 구분하여 입력받기\ndata = list(map(int, input().split()))\n\ndata.sort() # 입력받은 수들 정렬하기\nfirst = data[n - 1] # 가장 큰 수\nsecond = data[n - 2] # 두 번째로 큰 수\n\nresult = 0\n\nwhile True:\n    for i in range(k): # 가장 큰 수를  K번 더하기\n        if m == 0: # m이 0이라면 반복문 탈출\n            break\n        result += first\n        m -= 1 # 더할 때마다 1씩 빼기\n    if m == 0: # m이 0이라면 반복문 탈출\n        break\n    result += second # 두 번째로 큰 수를 한 번 더하기\n    m -= 1 # 더할 떄마다 1씩 빼기\n    \nprint(result)\n\n 5 8 3 \n 2 4 5 4 6\n\n\n46\n\n\n\n\nstep\n\nn, m, k = map(int, input().split())\n\n 5 8 3\n\n\n\ndata = list(map(int, input().split()))\n\n 2 4 5 4 6\n\n\n\ndata.sort();data\n\n[2, 4, 4, 5, 6]\n\n\n\nrange(k)\n\nrange(0, 3)\n\n\n\nfirst = data[n-1];first\n\n6\n\n\n\nsecond = data[n-2];second\n\n5\n\n\n\nresult = 0; result\n\n0\n\n\n\nresult = result + first*3; result\n\n18\n\n\n\nm = m - 3 ;m\n\n5\n\n\n\nresult = result + second; result\n\n23\n\n\n\nm = m - 1 ;m\n\n4\n\n\n\nresult = result + first*3; result\n\n41\n\n\n\nm = m - 3 ;m\n\n1\n\n\n\nresult = result + second; result\n\n46\n\n\n\nm = m - 1 ;m\n\n0\n\n\n\nint(8 / (6 + 1)) * 3 + 8 % (6 + 1)\n\n4\n\n\n\n\nAnswer 2\n\n# N, M, K를 공백으로 구분하여 입력받기\nn, m, k = map(int, input().split())\n# N개의 수를 공백으로 구분하여 입력받기\ndata = list(map(int, input().split()))\n\ndata.sort() # 입력받은 수 정렬\nfirst = data[n - 1] # 가장 큰 수\nsecond = data[n - 2] # 두 번째로 큰 수\n\n# 가장 큰 수가 더해지는 횟수 계산\ncount = int(m / (k + 1)) * k\ncount += m % (k+1)\n\nresult = 0\nresult += count * first # 가장 큰 수 더하기\nresult += (m - count) * second # 두 번재로 큰 수 더하기\n\nprint(result)\n\n 5 8 3\n 2 4 5 4 6\n\n\n46\n\n\n\nn, m, k = map(int, input().split())\n\n 5 8 3\n\n\n\ndata = list(map(int, input().split()))\n\n 2 4 5 4 6\n\n\n\ndata.sort();data\n\n[2, 4, 4, 5, 6]\n\n\n\nfirst = data[n-1];first\n\n6\n\n\n\nsecond = data[n-2];second\n\n5\n\n\n\ncount = int(m / (k + 1)) * k ; count\n\n6\n\n\n\nm % (k+1)\n\n1\n\n\n\nresult = 0;result\n\n0\n\n\n\nresult += count * first;result\n\n36\n\n\n\nresult += (m - count) * second; result\n\n46"
  },
  {
    "objectID": "posts/ct/2023-01-01-Coding_Test_Greedy.html#숫자-카드-게임",
    "href": "posts/ct/2023-01-01-Coding_Test_Greedy.html#숫자-카드-게임",
    "title": "Chapter 03 Greedy",
    "section": "숫자 카드 게임",
    "text": "숫자 카드 게임\n숫자 카드 게임은 여러 개의 숫자 카드 중에서 가장 높은 숫자가 쓰인 카드 한 장을 뽑는 게임이다. 단, 게임의 룰을 지키며 카드를 뽑아야 하고 룰은 다음과 같다. 1. 숫자가 쓰인 카드들이 \\(N \\times M\\) 형태로 놓여 있다. 이때 N은 행의 개수를 의미하며, M은 열의 개수를 의미한다. 2. 먼저 뽑고자 하는 카드가 포함되어 있는 행을 선택한다. 3. 그다음 선택된 행에 초함된 카드들 중 가장 숫자가 낮은 카드를 뽑아야 한다. 4. 따라서 처음에 카드를 골라낼 행을 선택할 때, 이후에 해당 행에서 가장 숫자가 낮은 카드를 뽑을 것을 고려하여 최종적으로 가장 높은 숫자의 카드를 뽑을 수 있도록 정략을 세워야 한다.\n입력 조건\n\n첫째 줄에 숫자 카드들이 놓인 행의 개수 N과 열의 개수 M이 공백을 기준으로 하여 각각 자연수로 주어진다.(\\(1 \\le N, M \\le 100\\))\n둘째 줄부터 N개의 줄에 걸쳐 각 카드에 적힌 숫자가 주어진다. 각 숫자는 1 이상 10,000 이햐의 자연수이다.\n\n출력 조건\n\n첫째 줄에 게임의 룰에 맞게 선택한 카드에 적힌 숫자를 출력한다.\n\n문제 해설\n\n’각 행마다 가장 작을 수를 찾은 뒤에 그 수 중에서 가장 큰 수’를 찾는 것\n\n\nAnswer 1\n\nmin() 함수를 이용하는 답안 예시\n\n\n# N, M을 공백으로 구분하여 입력받기\nn, m = map(int, input().split())\n\nresult = 0\n# 한 줄씩 입력받아 확인\nfor i in range(n): \n    data = list(map(int, input().split()))\n    # 현재 줄에서 '가장 작은 수' 찾기\n    min_value = min(data)\n    # '가장 작은 수'들 중에서 가장 큰 수 찾기\n    result = max(result, min_value)\n    \nprint(result)\n\n 3 3\n 3 1 2\n 4 1 4\n 2 2 2\n\n\n2\n\n\n\nn, m = map(int, input().split())\n\n 3 3\n\n\n\nresult = 0; result\n\n0\n\n\n\nrange(3)\n\nrange(0, 3)\n\n\n\ndata = list(map(int, input().split()))\n\n 3 1 2\n\n\n\nmin_value = min(data);min_value\n\n1\n\n\n\nresult = max(result, min_value);result\n\n1\n\n\n\ndata = list(map(int, input().split()))\n\n 4 1 4\n\n\n\nmin_value = min(data);min_value\n\n1\n\n\n\nresult = max(result, min_value);result\n\n1\n\n\n\ndata = list(map(int, input().split()))\n\n 2 2 2\n\n\n\nmin_value = min(data);min_value\n\n2\n\n\n\nresult = max(result, min_value);result\n\n2\n\n\n\n\nAnswer 2\n\n2중 반복문 구조를 이용하는 답안 예시\n\n\n# N, M을 공백으로 구분하여 입력받기\nn, m = map(int, input().split())\n\nresult = 0\n# 한 줄씩 입력받아 확인\nfor i in range(n):\n    data = list(map(int, input().split()))\n    # 현재 줄에서 '가장 작은 수'찾기\n    min_value = 10001\n    for a in data:\n        min_value = min(min_value,a)\n    # '가장 작은 수'들 중에서 가장 큰 수 찾기\n    result = max(result, min_value)\n    \nprint(result)\n\n 2 4\n 7 3 1 8\n 3 3 3 4\n\n\n3\n\n\n\nn, m = map(int, input().split())\n\n 2 4\n\n\n\nresult = 0\n\n\nrange(2)\n\nrange(0, 2)\n\n\n\ndata = list(map(int, input().split()))\n\n 7 3 1 8\n\n\n\nmin_value = 10001;min_value\n\n10001\n\n\n\nmin_value = min(min_value,7,3,1,8);min_value\n\n1\n\n\n\nresult = max(result, min_value);result\n\n1\n\n\n\ndata = list(map(int, input().split()))\n\n 3 3 3 4\n\n\n\nmin_value = 10001;min_value\n\n10001\n\n\n\nmin_value = min(min_value,3,3,3,4);min_value\n\n3\n\n\n\nresult = max(result, min_value);result\n\n3"
  },
  {
    "objectID": "posts/ct/2023-01-01-Coding_Test_Greedy.html#이-될-때까지",
    "href": "posts/ct/2023-01-01-Coding_Test_Greedy.html#이-될-때까지",
    "title": "Chapter 03 Greedy",
    "section": "1이 될 때까지",
    "text": "1이 될 때까지\n어떠한 수 N이 1이 될 떄까지 다음의 두 과정 중 하나를 반복적으로 선택하여 수행하려고 한다. 단, 두 번째 연산은 N이 K로 나누어 쩔어질 때만 선택할 수 있다. 1. N에서 1을 뺀다. 2. N을 K로 나눈다.\nN과 K가 주어질 때 N이 1이 될 때까지 1번 혹은 2번의 과정을 수행해야 하는 최소 횟수를 구하는 프로그램을 작성하시오.\n입력 조건\n\n첫째 줄에 \\(N(2 \\le N \\le 100,000)\\)과 \\(K(2 \\le K \\le 100,000)\\)가 공백으로 구분되며 각각 자연수로 주어진다. 이때 입력으로 주어지는 N은 항상 K보다 크거나 같다.\n\n출력 조건\n\n첫째 줄에 N이 1이 될 때까지 1번 혹은 2번의 과정을 수행해야 하는 횟수의 최솟값을 출력한다.\n\n문제 해설\n\n‘최대한 많이 나누기’\n\n\nAnswer 1\n\n단순하기 푸는 답안 예시\n\n\nn, k = map(int, input().split())\nresult = 0\n\n# N이 K 이상이라면 K로 계속 나누기\nwhile n &gt;= k:\n    # N이 K로 나누어 떨어지지 않는다면 N에서 1씩 빼기\n    while n % k != 0:\n        n -= 1\n        result += 1\n    # K 로 나누기\n    n //= k\n    result += 1\n    \n# 마지막으로 남은 수에 대하여 1씩 빼기\nwhile n &gt; 1:\n    n -= 1\n    result += 1\n\nprint(result)\n\n 25 5\n\n\n2\n\n\n\nn, k = map(int, input().split())\n\n 25 5\n\n\n\nresult = 0; result\n\n0\n\n\n\nn%k\n\n0\n\n\n\nn //= k;n\n\n5\n\n\n\nresult += 1 ;result\n\n1\n\n\n\nn%k\n\n0\n\n\n\nn // k ; n\n\n5\n\n\n\nresult += 1 ; result\n\n2\n\n\n\n\nAnswer 2\n\n답안 예시\n\n\n# N, K를 공백으로 구분하여 입력받기\nn, k = map(int, input().split())\nresult = 0\n\nwhile True:\n    # (N == K로 나누어 쩔어지는 수)가 될 때까지 1씩 빼기\n    target = (n // k) * k\n    result += (n - target)\n    n = target\n    # N이 K보다 작을 때(더 이상 나눌 수 없을 떄) 반복문 탈출\n    if n &lt; k:\n        break\n    # K로 나누기\n    result += 1\n    n //= k\n    \n# 마지막으로 남은 수에 대하여 1씩 빼기\nresult += ( n - 1 )\nprint(result)\n\n 25 5\n\n\n2\n\n\n\nn, k = map(int, input().split())\n\n 25 5\n\n\n\nresult = 0\n\n\ntarget = (n // k) * k; target\n\n25\n\n\n\nn = target ; n\n\n25\n\n\n\nresult += 1;result\n\n1\n\n\n\nn //= k ;n\n\n5\n\n\n\ntarget = (n // k) * k; target\n\n5\n\n\n\nn = target ; n\n\n5\n\n\n\nresult += 1;result\n\n2\n\n\n\nn //= k ;n\n\n1"
  },
  {
    "objectID": "posts/as/2023-07-30-multicollinearity.html",
    "href": "posts/as/2023-07-30-multicollinearity.html",
    "title": "Multicollinearity",
    "section": "",
    "text": "library(MASS) #lm.ridge\nlibrary(car) #vif\nlibrary(glmnet) #Ridge, Lasso\n\n완전한 다중공선성 (perfect multicollinearity) 완전한 다중공선성을 갖는 데이터 생성\n\ngen_perfect_collin_data = function(num_samples = 100) {\n    x1 = rnorm(n = num_samples, mean = 80, sd = 10)\n    x2 = rnorm(n = num_samples, mean = 70, sd = 5)\n    x3 = 2 * x1 + 4 * x2 + 3\n    y = 3 + x1 + x2 + rnorm(n = num_samples, mean = 0, sd = 1)\n    data.frame(y, x1, x2, x3) }\n\n\nset.seed(42)\nperfect_collin_data = gen_perfect_collin_data()\nhead(perfect_collin_data)\n\n\nA data.frame: 6 × 4\n\n\n\ny\nx1\nx2\nx3\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n170.7135\n93.70958\n76.00483\n494.4385\n\n\n2\n152.9106\n74.35302\n75.22376\n452.6011\n\n\n3\n152.7866\n83.63128\n64.98396\n430.1984\n\n\n4\n170.6306\n86.32863\n79.24241\n492.6269\n\n\n5\n152.3320\n84.04268\n66.66613\n437.7499\n\n\n6\n151.3155\n78.93875\n70.52757\n442.9878\n\n\n\n\n\n\nround(cor(perfect_collin_data),4)\n\n\nA matrix: 4 × 4 of type dbl\n\n\n\ny\nx1\nx2\nx3\n\n\n\n\ny\n1.0000\n0.9112\n0.4307\n0.9558\n\n\nx1\n0.9112\n1.0000\n0.0313\n0.7639\n\n\nx2\n0.4307\n0.0313\n1.0000\n0.6690\n\n\nx3\n0.9558\n0.7639\n0.6690\n1.0000\n\n\n\n\n\n\nx3이 x1과 y에 영향을 주는것처럼 보임\n\n\nperfect_collin_fit = lm(y ~ x1 + x2 + x3, data = perfect_collin_data)\nsummary(perfect_collin_fit)\n\n\nCall:\nlm(formula = y ~ x1 + x2 + x3, data = perfect_collin_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.57662 -0.66188 -0.08253  0.63706  2.52057 \n\nCoefficients: (1 not defined because of singularities)\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 2.957336   1.735165   1.704   0.0915 .  \nx1          0.985629   0.009788 100.702   &lt;2e-16 ***\nx2          1.017059   0.022545  45.112   &lt;2e-16 ***\nx3                NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.014 on 97 degrees of freedom\nMultiple R-squared:  0.9923,    Adjusted R-squared:  0.9921 \nF-statistic:  6236 on 2 and 97 DF,  p-value: &lt; 2.2e-16\n\n\n\nx3을 아예 추정하지 않아버림. 완벽한 다중공선성이 있는 경우.\n\n\nfit1 = lm(y ~ x1 + x2, data = perfect_collin_data)\nfit2 = lm(y ~ x1 + x3, data = perfect_collin_data)\nfit3 = lm(y ~ x2 + x3, data = perfect_collin_data)\n\n\nsummary(fit1)\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = perfect_collin_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.57662 -0.66188 -0.08253  0.63706  2.52057 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 2.957336   1.735165   1.704   0.0915 .  \nx1          0.985629   0.009788 100.702   &lt;2e-16 ***\nx2          1.017059   0.022545  45.112   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.014 on 97 degrees of freedom\nMultiple R-squared:  0.9923,    Adjusted R-squared:  0.9921 \nF-statistic:  6236 on 2 and 97 DF,  p-value: &lt; 2.2e-16\n\n\n\nsummary(fit2)\n\n\nCall:\nlm(formula = y ~ x1 + x3, data = perfect_collin_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.57662 -0.66188 -0.08253  0.63706  2.52057 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 2.194542   1.750225   1.254    0.213    \nx1          0.477100   0.015158  31.475   &lt;2e-16 ***\nx3          0.254265   0.005636  45.112   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.014 on 97 degrees of freedom\nMultiple R-squared:  0.9923,    Adjusted R-squared:  0.9921 \nF-statistic:  6236 on 2 and 97 DF,  p-value: &lt; 2.2e-16\n\n\n\nsummary(fit3)\n\n\nCall:\nlm(formula = y ~ x2 + x3, data = perfect_collin_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.57662 -0.66188 -0.08253  0.63706  2.52057 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.478892   1.741452   0.849    0.398    \nx2          -0.954200   0.030316 -31.475   &lt;2e-16 ***\nx3           0.492815   0.004894 100.702   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.014 on 97 degrees of freedom\nMultiple R-squared:  0.9923,    Adjusted R-squared:  0.9921 \nF-statistic:  6236 on 2 and 97 DF,  p-value: &lt; 2.2e-16\n\n\n\nfit1, fit2, fit3 의 r square가 같음\ncoeffi가 달라지는 건 당연히…한 설명변수가 설명하던 내용을 다른 설명변수가 가져갔기 때문에\n\n\nall.equal(fitted(fit1), fitted(fit2))\n\nTRUE\n\n\n\nall.equal(fitted(fit2), fitted(fit3))\n\nTRUE\n\n\n\n모형이 같다는 결과\n\n\ncoef(fit1)\n\n(Intercept)2.95733574182584x10.985629075384885x21.01705863569559\n\n\n\ncoef(fit2)\n\n(Intercept)2.19454176505438x10.477099757537093x30.254264658923896\n\n\n\ncoef(fit3)\n\n(Intercept)1.47889212874875x2-0.954199515074185x30.492814537692442"
  },
  {
    "objectID": "posts/as/2023-07-30-multicollinearity.html#완전에-가까운-다중공선성을-갖는-데이터-생성",
    "href": "posts/as/2023-07-30-multicollinearity.html#완전에-가까운-다중공선성을-갖는-데이터-생성",
    "title": "Multicollinearity",
    "section": "완전에 가까운 다중공선성을 갖는 데이터 생성",
    "text": "완전에 가까운 다중공선성을 갖는 데이터 생성\n\ngen_almost_collin_data = function(num_samples = 100) {\n    x1 = rnorm(n = num_samples, mean = 0, sd = 2)\n    x2 = rnorm(n = num_samples, mean = 0, sd = 3)\n    x3 = 3*x1 + 1*x2 + rnorm(num_samples, mean=0, sd=0.5)\n    y = 3 + x1 + x2 + rnorm(n = num_samples, mean = 0, sd = 1) \n    data.frame(y, x1, x2, x3)\n}\n\n\nx3 가 완벽히 상관되어 있지 않고 어느 정도만 상관관계가 있게 만든 시물레이션 데이터\n\n\nset.seed(42)\nalmost_collin_data = gen_almost_collin_data()\nhead(almost_collin_data)\n\n\nA data.frame: 6 × 4\n\n\n\ny\nx1\nx2\nx3\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n9.3401923\n2.7419169\n3.6028961\n10.82818219\n\n\n2\n5.7650991\n-1.1293963\n3.1342533\n-0.08704717\n\n\n3\n0.7556218\n0.7262568\n-3.0096259\n-0.24519291\n\n\n4\n10.5462431\n1.2657252\n5.5454457\n10.37239096\n\n\n5\n1.6617438\n0.8085366\n-2.0003202\n-0.26314109\n\n\n6\n3.0464051\n-0.2122490\n0.3165414\n-0.89563344\n\n\n\n\n\n\nround(cor(almost_collin_data),3)\n\n\nA matrix: 4 × 4 of type dbl\n\n\n\ny\nx1\nx2\nx3\n\n\n\n\ny\n1.000\n0.616\n0.769\n0.863\n\n\nx1\n0.616\n1.000\n0.031\n0.913\n\n\nx2\n0.769\n0.031\n1.000\n0.429\n\n\nx3\n0.863\n0.913\n0.429\n1.000\n\n\n\n\n\n\nm &lt;- lm(y~., almost_collin_data)\nsummary(m)\n\n\nCall:\nlm(formula = y ~ ., data = almost_collin_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.7944 -0.5867 -0.1038  0.6188  2.3280 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.03150    0.08914  34.007  &lt; 2e-16 ***\nx1           1.21854    0.52829   2.307   0.0232 *  \nx2           1.06616    0.18314   5.821 7.71e-08 ***\nx3          -0.06322    0.17765  -0.356   0.7227    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8867 on 96 degrees of freedom\nMultiple R-squared:  0.9419,    Adjusted R-squared:  0.9401 \nF-statistic:   519 on 3 and 96 DF,  p-value: &lt; 2.2e-16\n\n\n\nvif(m)\n## x1 x2 x3 ## 152.42684 31.07349 186.71999\n\nx1152.42683903062x231.0734919101687x3186.719994280611\n\n\n\n다중공선성 vif값이 10을 훨씬 넘음\n되게 불안정\ncar package가 설치가 되지 않아..\n\n\nset.seed(1000)\nnoise &lt;- rnorm(n = 100, mean = 0, sd =0.5)\nm_noise &lt;- lm(y+noise~., almost_collin_data)\nsummary(m_noise)\n\n\nCall:\nlm(formula = y + noise ~ ., data = almost_collin_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.0962 -0.6998 -0.0891  0.7726  2.8462 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.0403     0.1020  29.815  &lt; 2e-16 ***\nx1            0.9894     0.6043   1.637    0.105    \nx2            0.9898     0.2095   4.725 7.88e-06 ***\nx3            0.0158     0.2032   0.078    0.938    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.014 on 96 degrees of freedom\nMultiple R-squared:  0.9259,    Adjusted R-squared:  0.9236 \nF-statistic:   400 on 3 and 96 DF,  p-value: &lt; 2.2e-16\n\n\n\ny 에 noise 살짝 줘보기\n\n\nround(coef(m),3)\n\n(Intercept)3.032x11.219x21.066x3-0.063\n\n\n\nround(coef(m_noise),3)\n\n(Intercept)3.04x10.989x20.99x30.016"
  },
  {
    "objectID": "posts/as/2023-07-30-multicollinearity.html#다중공선성이-없는-경우-비교",
    "href": "posts/as/2023-07-30-multicollinearity.html#다중공선성이-없는-경우-비교",
    "title": "Multicollinearity",
    "section": "다중공선성이 없는 경우 비교",
    "text": "다중공선성이 없는 경우 비교\n\nm1 &lt;- lm(y~x1+x2, almost_collin_data)\nm1_noise &lt;- lm(y+noise~x1+x2, almost_collin_data)\n\n\nvif(m1)\n\nx11.00097938645275x21.00097938645275\n\n\n\nround(coef(m1),3)\n\n(Intercept)3.031x11.031x21.002\n\n\n\nround(coef(m1_noise),3)\n\n(Intercept)3.04x11.036x21.006\n\n\nnoise 주니 비교적 안정적으로 보임\n\\[VIF = \\frac{1}{1-R^2_j}\\]\n\nm_sub &lt;- lm(x3~x1+x2,almost_collin_data)\nc33 &lt;- 1/(1-summary(m_sub)$r.sq);c33 ##vif\n\n186.719994280622\n\n\n\nvif(m)\n\nx1152.42683903062x231.0734919101687x3186.719994280611"
  },
  {
    "objectID": "posts/as/2023-07-30-multicollinearity.html#실제-데이터-분석",
    "href": "posts/as/2023-07-30-multicollinearity.html#실제-데이터-분석",
    "title": "Multicollinearity",
    "section": "실제 데이터 분석",
    "text": "실제 데이터 분석\n\ndt &lt;- data.frame(scale(mtcars))\ndim(dt)\n\n\n3211\n\n\n\nhead(dt)\n\n\nA data.frame: 6 × 11\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nMazda RX4\n0.1508848\n-0.1049878\n-0.57061982\n-0.5350928\n0.5675137\n-0.610399567\n-0.7771651\n-0.8680278\n1.1899014\n0.4235542\n0.7352031\n\n\nMazda RX4 Wag\n0.1508848\n-0.1049878\n-0.57061982\n-0.5350928\n0.5675137\n-0.349785269\n-0.4637808\n-0.8680278\n1.1899014\n0.4235542\n0.7352031\n\n\nDatsun 710\n0.4495434\n-1.2248578\n-0.99018209\n-0.7830405\n0.4739996\n-0.917004624\n0.4260068\n1.1160357\n1.1899014\n0.4235542\n-1.1221521\n\n\nHornet 4 Drive\n0.2172534\n-0.1049878\n0.22009369\n-0.5350928\n-0.9661175\n-0.002299538\n0.8904872\n1.1160357\n-0.8141431\n-0.9318192\n-1.1221521\n\n\nHornet Sportabout\n-0.2307345\n1.0148821\n1.04308123\n0.4129422\n-0.8351978\n0.227654255\n-0.4637808\n-0.8680278\n-0.8141431\n-0.9318192\n-0.5030337\n\n\nValiant\n-0.3302874\n-0.1049878\n-0.04616698\n-0.6080186\n-1.5646078\n0.248094592\n1.3269868\n1.1160357\n-0.8141431\n-0.9318192\n-1.1221521\n\n\n\n\n\n[, 1] mpg Miles/(US) gallon\n[, 2] cyl Number of cylinders\n[, 3] disp Displacement (cu.in.)\n[, 4] hp Gross horsepower\n[, 5] drat Rear axle ratio\n[, 6] wt Weight (1000 lbs)\n[, 7] qsec 1/4 mile time\n[, 8] vs Engine (0 = V-shaped, 1 = straight)\n[, 9] am Transmission (0 = automatic, 1 = manual)\n[,10] gear Number of forward gears\n[,11] carb Number of carburetors\n\npairs(dt)\n\n\n\n\n\nround(cor(dt),2)\n\n\nA matrix: 11 × 11 of type dbl\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nmpg\n1.00\n-0.85\n-0.85\n-0.78\n0.68\n-0.87\n0.42\n0.66\n0.60\n0.48\n-0.55\n\n\ncyl\n-0.85\n1.00\n0.90\n0.83\n-0.70\n0.78\n-0.59\n-0.81\n-0.52\n-0.49\n0.53\n\n\ndisp\n-0.85\n0.90\n1.00\n0.79\n-0.71\n0.89\n-0.43\n-0.71\n-0.59\n-0.56\n0.39\n\n\nhp\n-0.78\n0.83\n0.79\n1.00\n-0.45\n0.66\n-0.71\n-0.72\n-0.24\n-0.13\n0.75\n\n\ndrat\n0.68\n-0.70\n-0.71\n-0.45\n1.00\n-0.71\n0.09\n0.44\n0.71\n0.70\n-0.09\n\n\nwt\n-0.87\n0.78\n0.89\n0.66\n-0.71\n1.00\n-0.17\n-0.55\n-0.69\n-0.58\n0.43\n\n\nqsec\n0.42\n-0.59\n-0.43\n-0.71\n0.09\n-0.17\n1.00\n0.74\n-0.23\n-0.21\n-0.66\n\n\nvs\n0.66\n-0.81\n-0.71\n-0.72\n0.44\n-0.55\n0.74\n1.00\n0.17\n0.21\n-0.57\n\n\nam\n0.60\n-0.52\n-0.59\n-0.24\n0.71\n-0.69\n-0.23\n0.17\n1.00\n0.79\n0.06\n\n\ngear\n0.48\n-0.49\n-0.56\n-0.13\n0.70\n-0.58\n-0.21\n0.21\n0.79\n1.00\n0.27\n\n\ncarb\n-0.55\n0.53\n0.39\n0.75\n-0.09\n0.43\n-0.66\n-0.57\n0.06\n0.27\n1.00\n\n\n\n\n\n\ncars_fit_lm &lt;- lm(mpg~., dt)\nsummary(cars_fit_lm)\n\n\nCall:\nlm(formula = mpg ~ ., data = dt)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.57254 -0.26620 -0.01985  0.20230  0.76773 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) -1.613e-17  7.773e-02   0.000   1.0000  \ncyl         -3.302e-02  3.097e-01  -0.107   0.9161  \ndisp         2.742e-01  3.672e-01   0.747   0.4635  \nhp          -2.444e-01  2.476e-01  -0.987   0.3350  \ndrat         6.983e-02  1.451e-01   0.481   0.6353  \nwt          -6.032e-01  3.076e-01  -1.961   0.0633 .\nqsec         2.434e-01  2.167e-01   1.123   0.2739  \nvs           2.657e-02  1.760e-01   0.151   0.8814  \nam           2.087e-01  1.703e-01   1.225   0.2340  \ngear         8.023e-02  1.828e-01   0.439   0.6652  \ncarb        -5.344e-02  2.221e-01  -0.241   0.8122  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4397 on 21 degrees of freedom\nMultiple R-squared:  0.869, Adjusted R-squared:  0.8066 \nF-statistic: 13.93 on 10 and 21 DF,  p-value: 3.793e-07\n\n\n\\(H_0: \\beta_1 = \\beta_2 = \\dots = 0\\) 모형은 유의하게 나왔는데 각 변수는 모두 유의하지 않게 나옴..\n\nvif(cars_fit_lm)\n\ncyl15.3738334034422disp21.6202410289589hp9.83203684435906drat3.37462000831475wt15.1648869639871qsec7.5279582252911vs4.96587346648472am4.64848745550015gear5.35745210594065carb7.90874675118444"
  },
  {
    "objectID": "posts/as/2023-07-30-multicollinearity.html#lm.ridge-함수-이용",
    "href": "posts/as/2023-07-30-multicollinearity.html#lm.ridge-함수-이용",
    "title": "Multicollinearity",
    "section": "lm.ridge 함수 이용",
    "text": "lm.ridge 함수 이용\n\nrfit &lt;- lm.ridge(mpg~., dt, lambda=seq(0.01,20,0.1))\n\n\nselect(rfit)\n\nmodified HKB estimator is 2.58585 \nmodified L-W estimator is 1.837435 \nsmallest value of GCV  at 14.91 \n\n\n\n람다값 추천 GCV Generated Cross Validation mse를 가장 작게 하는 람다값\n\n\nround(rfit$coef[,rfit$lam=='0.21'],3)\n\ncyl-0.032disp0.185hp-0.211drat0.074wt-0.52qsec0.207vs0.027am0.201gear0.082carb-0.093\n\n\n\\(\\sum \\hat{\\beta_j}^2, \\lambda = 0.21\\)\n\nround(rfit$coef[,rfit$lam=='3.21'],3)\n\ncyl-0.078disp-0.049hp-0.144drat0.086wt-0.291qsec0.085vs0.041am0.169gear0.075carb-0.175\n\n\n\\(\\sum \\hat{\\beta_j}^2, \\lambda = 3.21\\)\n\nround(rfit$coef[,rfit$lam=='14.91'],3)\n\ncyl-0.109disp-0.107hp-0.13drat0.092wt-0.197qsec0.047vs0.063am0.132gear0.066carb-0.144\n\n\n\\(\\sum \\hat{\\beta_j}^2, \\lambda = 14.91\\)\n\nsum(rfit$coef[,rfit$lam=='0.21']^2)\n\n0.455670466366229\n\n\n\nsum(rfit$coef[,rfit$lam=='3.21']^2)\n\n0.195026451544005\n\n\n\nsum(rfit$coef[,rfit$lam=='14.91']^2)\n\n0.135989355255868\n\n\n\n# graphics.off()\nmatplot(rfit$lambda, t(rfit$coef), type='l',\nxlab=expression(lambda),\nylab=expression(bold(beta)(lambda)), lwd=2) \nabline(h=0, col=\"grey\", lty=2)\nabline(v=14.91, col=\"black\", lty=2)"
  },
  {
    "objectID": "posts/as/2023-07-30-multicollinearity.html#glmnet-함수-이용",
    "href": "posts/as/2023-07-30-multicollinearity.html#glmnet-함수-이용",
    "title": "Multicollinearity",
    "section": "glmnet 함수 이용",
    "text": "glmnet 함수 이용\n\n설명변수만 사용 상수항 없이\n\n\nX &lt;- model.matrix(mpg~., dt)[,-1]\ny &lt;- dt$mpg\nhead(X)\n\n\nA matrix: 6 × 10 of type dbl\n\n\n\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n-0.1049878\n-0.57061982\n-0.5350928\n0.5675137\n-0.610399567\n-0.7771651\n-0.8680278\n1.1899014\n0.4235542\n0.7352031\n\n\nMazda RX4 Wag\n-0.1049878\n-0.57061982\n-0.5350928\n0.5675137\n-0.349785269\n-0.4637808\n-0.8680278\n1.1899014\n0.4235542\n0.7352031\n\n\nDatsun 710\n-1.2248578\n-0.99018209\n-0.7830405\n0.4739996\n-0.917004624\n0.4260068\n1.1160357\n1.1899014\n0.4235542\n-1.1221521\n\n\nHornet 4 Drive\n-0.1049878\n0.22009369\n-0.5350928\n-0.9661175\n-0.002299538\n0.8904872\n1.1160357\n-0.8141431\n-0.9318192\n-1.1221521\n\n\nHornet Sportabout\n1.0148821\n1.04308123\n0.4129422\n-0.8351978\n0.227654255\n-0.4637808\n-0.8680278\n-0.8141431\n-0.9318192\n-0.5030337\n\n\nValiant\n-0.1049878\n-0.04616698\n-0.6080186\n-1.5646078\n0.248094592\n1.3269868\n1.1160357\n-0.8141431\n-0.9318192\n-1.1221521\n\n\n\n\n\n\nhead(y)\n\n\n0.1508848246476570.1508848246476570.4495434466306470.217253407310543-0.230734525663942-0.330287399658272\n\n\n\nridge.fit&lt;-glmnet(X,y,alpha=0, lambda=seq(0.01,20,0.1)) ##ridge : alpha=0 plot(ridge.fit, label=TRUE)\n\n\n\\(\\sum \\hat{\\beta}^2 \\le t\\) Ridge, \\(\\sum |\\hat{\\beta}| \\le t\\) Rasso\n\\((1-\\alpha)\\sum \\hat{\\beta}^2 + \\alpha \\sum |\\hat{\\beta}| \\le t\\)\nalpha=0 \\(\\to\\) Ridge 쓰겠다.\nalpha=0 \\(\\to\\) Rasso 쓰겠다.\nalpha=0.5 \\(\\to\\) Ridge, Rasso 반절씩 쓰겠다.\n\n\ncv.fit&lt;-cv.glmnet(X,y,alpha=0,nfolds=length(y))\n## Warning: Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per ## fold\n\nWarning message:\n\"Option grouped=FALSE enforced in cv.glmnet, since &lt; 3 observations per fold\"\n\n\n\ncross validation\n\n\ncv.fit\n\n\nCall:  cv.glmnet(x = X, y = y, nfolds = 10, alpha = 0) \n\nMeasure: Mean-Squared Error \n\n    Lambda Index Measure      SE Nonzero\nmin 0.4558    82  0.2002 0.04900      10\n1se 1.8399    67  0.2444 0.07153      10\n\n\n\nplot(cv.fit)\nabline(h=0, col=\"grey\", lty=2)\n\n\n\n\n\ncv.fit&lt;-cv.glmnet(X,y,alpha=0,nfolds=10)\ncv.fit\n\n\nCall:  cv.glmnet(x = X, y = y, nfolds = 10, alpha = 0) \n\nMeasure: Mean-Squared Error \n\n    Lambda Index Measure     SE Nonzero\nmin 0.4558    82  0.2165 0.0638      10\n1se 2.2161    65  0.2756 0.1059      10\n\n\n\nplot(cv.fit)\n\n\n\n\n\nlam&lt;-cv.fit$lambda.min;lam\n\n0.455751230036319\n\n\n\nlog(lam)\n\n-0.785808166499264\n\n\n\npredict(ridge.fit,type=\"coefficients\",s=lam)\n\n11 x 1 sparse Matrix of class \"dgCMatrix\"\n                       s1\n(Intercept)  8.341243e-17\ncyl         -1.103002e-01\ndisp        -1.078123e-01\nhp          -1.318526e-01\ndrat         9.325727e-02\nwt          -2.004586e-01\nqsec         4.817170e-02\nvs           6.442374e-02\nam           1.345790e-01\ngear         6.679685e-02\ncarb        -1.470291e-01\n\n\n\n\\(\\hat{y}\\)구하고 싶으면 type을 response로 바꾸면 됌"
  },
  {
    "objectID": "posts/as/2023-07-30-multicollinearity.html#lasso",
    "href": "posts/as/2023-07-30-multicollinearity.html#lasso",
    "title": "Multicollinearity",
    "section": "Lasso",
    "text": "Lasso\n\nlasso.fit&lt;-glmnet(X,y,alpha=1, lambda=seq(0.01,20,0.1)) ##lasso : alpha=1 plot(lasso.fit, label=TRUE)\n\n\ncv.lasso.fit&lt;-cv.glmnet(X,y,alpha=1,nfolds=10)\ncv.lasso.fit\n\n\nCall:  cv.glmnet(x = X, y = y, nfolds = 10, alpha = 1) \n\nMeasure: Mean-Squared Error \n\n    Lambda Index Measure      SE Nonzero\nmin 0.1211    22  0.2420 0.07897       3\n1se 0.2796    13  0.3144 0.12750       3\n\n\n\nplot(cv.lasso.fit)"
  },
  {
    "objectID": "posts/anything/2023-06-12-Steady State.html",
    "href": "posts/anything/2023-06-12-Steady State.html",
    "title": "Steady State",
    "section": "",
    "text": "Pharmacokinetic Analysis\nRef: FDA"
  },
  {
    "objectID": "posts/anything/2023-06-12-Steady State.html#winnonlin-guide",
    "href": "posts/anything/2023-06-12-Steady State.html#winnonlin-guide",
    "title": "Steady State",
    "section": "Winnonlin Guide",
    "text": "Winnonlin Guide\n윈놀린 가이드 참고하여 용어 정리\nTmin: Time of minimum observed concentration. For steady-state data, based on observations col-lected during the dosing interval (i.e., after the dosing time, but no later than dosing time plus Tau, where Tau is the dosing interval). If the minimum observed concentration is not unique, then the first minimum is used. - Tmin은 항정상태에서 최소 혈중 농도가 기록된 time을 의미함\nCmin: Minimum observed concentration occurring at time Tmin as defined above.\n\\(\\star\\) Cmin은 측정방법이 한정되지 않는다.\n\n항정상태에서 최소 농도(윈놀린에서는 이 값이 고유하지 않을 시 첫 번째 최소 농도를 기준으로 본다)\n\n\n즉, 반복투여가 끝난 후에 기록된 최소 혈중 농도\n\n\ntau 마지막 시점에서의 농도\n\nFDA 정의\n\nThe minimum concentration\n\nEMA 정의\n\nCmin,ss : Minimum plasma concentration at steady state"
  },
  {
    "objectID": "posts/anything/2023-04-20-hazard_ratio,odds_ratio.html",
    "href": "posts/anything/2023-04-20-hazard_ratio,odds_ratio.html",
    "title": "Hazard ratio, Odds ratio",
    "section": "",
    "text": "Hazard ratio, Odds ratio\n\n\n로지스틱 회귀분석\n\\[log(\\frac{p}{1-p}) = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_k x_k\\]\n\n# 예제 데이터 생성\nset.seed(123)\nn &lt;- 200\nexam1 &lt;- round(rnorm(n, mean = 70, sd = 10))\nexam2 &lt;- round(rnorm(n, mean = 75, sd = 8))\nexam3 &lt;- round(rnorm(n, mean = 80, sd = 6))\npass &lt;- rbinom(n, 1, plogis(0.3 + 0.1 * exam1 + 0.2 * exam2 + 0.3 * exam3))\n\ndata &lt;- data.frame(exam1, exam2, exam3, pass)\n\n# 로지스틱 회귀분석 모델 학습\nmodel &lt;- glm(pass ~ exam1 + exam2 + exam3, data = data, family = binomial)\n\nWarning message:\n“glm.fit: algorithm did not converge”\n\n\nfamily = binomial에서 이항분포의 개념\n\n# 모델 요약 정보 출력\nsummary(model)\n\n\nCall:\nglm(formula = pass ~ exam1 + exam2 + exam3, family = binomial, \n    data = data)\n\nDeviance Residuals: \n      Min         1Q     Median         3Q        Max  \n2.409e-06  2.409e-06  2.409e-06  2.409e-06  2.409e-06  \n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)  2.657e+01  4.810e+05       0        1\nexam1       -3.384e-11  2.676e+03       0        1\nexam2        2.952e-10  3.178e+03       0        1\nexam3        2.546e-10  4.359e+03       0        1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 0.0000e+00  on 199  degrees of freedom\nResidual deviance: 1.1603e-09  on 196  degrees of freedom\nAIC: 8\n\nNumber of Fisher Scoring iterations: 25\n\n\n\n# 각 독립변수의 회귀계수와 p-value 출력\ncoef(summary(model))\n\n\nA matrix: 4 × 4 of type dbl\n\n\n\nEstimate\nStd. Error\nz value\nPr(&gt;|z|)\n\n\n\n\n(Intercept)\n2.656607e+01\n480958.636\n5.523566e-05\n0.9999559\n\n\nexam1\n-3.384147e-11\n2676.045\n-1.264607e-14\n1.0000000\n\n\nexam2\n2.951540e-10\n3178.418\n9.286192e-14\n1.0000000\n\n\nexam3\n2.546355e-10\n4359.366\n5.841114e-14\n1.0000000\n\n\n\n\n\n\n# 새로운 데이터에 대한 예측값 계산\nnew_data &lt;- data.frame(exam1 = c(65, 80), exam2 = c(70, 85), exam3 = c(75, 90))\npred &lt;- predict(model, newdata = new_data, type = \"response\")\n\n\n# 예측 결과 출력\nprint(pred)\n\n1 2 \n1 1 \n\n\n\n\n로지스틱 함수와 오즈비\n\\[P(Y=1|X) = \\frac{e^{\\beta_0 + \\beta_1 X}}{1 + e^{\\beta_0 + \\beta_1 X}}\\]\n\\(P(Y=1|X) = P\\)\n라고 할때,\n\\(ln(\\frac{p}{1-p}) = \\beta_0 + \\beta_1 X\\)\nodds = \\(\\frac{p}{1-p}\\)\n\n# exam1 변수의 계수 출력\ncoef(model)[\"exam1\"]\n\nexam1: -3.38414654242419e-11\n\n\n\n# 오즈비 계산\nodds_ratio &lt;- exp(coef(model)[\"exam1\"])\nodds_ratio\n\nexam1: 0.999999999966159\n\n\n\n\n위험비\n\\[HR = \\frac{\\lambda_1(t)}{\\lambda_0(t)} = \\exp(\\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_k X_k)\\]\n\\(\\lambda_1(t)\\): 치료군의 위험도\n\\(\\lambda_0(t)\\)는 대조군의 위험도\n위험비는 치료군 대 대조군의 위험도 비율\n1보다 크면 치료군의 위험이 높겠고,\n1보다 작으면 대조군의 위험이 높겠고.\n\n# 데이터 로딩\ndata(lung)\n\n# Cox 모형 적합\nlibrary(survival)\nfit &lt;- coxph(Surv(time, status) ~ age + sex + ph.ecog + ph.karno + pat.karno + meal.cal + wt.loss, data = lung)\n\nWarning message in data(lung):\n“data set ‘lung’ not found”\n\n\n\n# Hazard Ratio 계산\nexp(coef(fit))\n\nage1.0107060959455sex0.576458374699102ph.ecog2.08376570435143ph.karno1.02270907640951pat.karno0.987660215984953meal.cal1.00003329080755wt.loss0.985771582300398"
  },
  {
    "objectID": "posts/anything/2023-04-27-Clinical Trial Data and Survival Analysis.html",
    "href": "posts/anything/2023-04-27-Clinical Trial Data and Survival Analysis.html",
    "title": "Clinical Trial Data and Survival Analysis",
    "section": "",
    "text": "Clinical Trial Data and Survival Analysis\n\n\nCox 회귀모형[@배종성2006임상시험자료와]\nCox(1972)는 위험함수에 의한 비례위험모형(proportional hazard model)을 제안하였다. 이는 준모수적(semiparametric)방법으로, 생존시간의 분포에 대한 가정을 하지 않을 뿐만 아니라, 시간에 따라 변하는 공변량(time dependent variable)이 있는 경우에도 적용가능하기 때문에 생존분석에서 자주 사용되고 있다.\np개의 공변량을 가진 cox 회귀모형\n\\[h(t) = h_0(t)exp(\\beta_1 x_1 + \\dots + \\beta_p x_p)\\]\n\\(h_0(t)\\)는 모든 공변량 값들이 0일 때의 baseline haxart function(기저위험함수)\n비례위험모형이란 시간에 대해 두 개체 간 위험률(아래)이 일정, 즉 상수 값 산출\n\\(\\frac{h(t|x_1)}{h(t|x_2)} = \\frac{exp(\\beta' x_1}{exp(\\beta' x_2}\\)\n비례위험 가정 만족 시, 개체 간 생존 시간 분포 곡선은 평행, 모형에서 만족해야 함\n모든 개체에서 기저 위험인 \\(h_0(t)\\)는 공통으로 가지고 있지만 상대위험(relative risk)인 \\(exp(\\beta'x)\\)는 각 개체들의 상대적 위험도를 나타냄\n\\(exp(\\beta'x)\\)를 통해 모수 \\(\\beta_j\\)의 해석이 이뤄지고, 이 \\(\\beta_j\\)는 공변량 \\(x_j\\)의 한 단위 증가에 따른 상대위험 정도를 나타냄\n생존확률을 그림으로 나타내었을때 기저위험baseline hazard 가 다를때, 즉 곡선이 평행라지 않는다면 cox의 회귀분석의 비례위험모형 가정에 위배되어 그룹별로 층화된 모형 고려해야 함."
  },
  {
    "objectID": "posts/anything/2023-06-12-post_hoc.html",
    "href": "posts/anything/2023-06-12-post_hoc.html",
    "title": "Post Hoc Tests",
    "section": "",
    "text": "Post Hoc Tests\n\nRef: Post Hoc Tests, https://mindscale.kr/course/basic-stat-r/post-hoc/#_2\n실무 진행하면서 이해한 바대로 explanation:\n분산분석 후 세 그룹 이상의 그룹에서 차이가 존재한다면 t test를 여러번 하게 되면 제 1종 오류가 기존에 정한 값보다 커지는 문제가 생긴다. (표본의 크기가 다를 경우) 본페로니 검정 후 p값 3배(세 그룹이라면, 즉 그룹 수대로 배수) 해주기\nFWER\nFamilywise Error Rate, 여러 개의 가설 검정 진해 시 적어도 하나의 가설에서 1종 오류가 발생할 가능성\n\nImport\n\nlibrary(DescTools)\n\n대표적인 사후분석 방법\n\n본페로니 교정\n피셔의 LSD\n투키의 HSD\n셰페의 방법\n\n분산분석\n\nm = aov(weight ~ group, data = PlantGrowth)\n\n\nsummary(m)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)  \ngroup        2  3.766  1.8832   4.846 0.0159 *\nResiduals   27 10.492  0.3886                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nFisher’s Least Significant Difference\n\n피셔의 LSD ;최소한의 유의한 차이\nFWER 높음\n\n\nPostHocTest(m, method='lsd')\n\n\n  Posthoc multiple comparisons of means : Fisher LSD \n    95% family-wise confidence level\n\n$group\n            diff      lwr.ci    upr.ci   pval    \ntrt1-ctrl -0.371 -0.94301261 0.2010126 0.1944    \ntrt2-ctrl  0.494 -0.07801261 1.0660126 0.0877 .  \ntrt2-trt1  0.865  0.29298739 1.4370126 0.0045 ** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n마지막인 trt2-trt1 차이만 p-값이 0.05보다 작아 통계적으로 유의한 차이가 있다고 할 수 있다.\n\n\nBonferroni correction\n\n모든 집단을 짝지어서 t-test 진행\n짝지어 비교를 3번하면 p값을 3배해야 한다.\nFWER 중간\n\n\nPostHocTest(m, method='bonferroni')\n\n\n  Posthoc multiple comparisons of means : Bonferroni \n    95% family-wise confidence level\n\n$group\n            diff     lwr.ci    upr.ci   pval    \ntrt1-ctrl -0.371 -1.0825786 0.3405786 0.5832    \ntrt2-ctrl  0.494 -0.2175786 1.2055786 0.2630    \ntrt2-trt1  0.865  0.1534214 1.5765786 0.0134 *  \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ntrt2-trt1만 유의한 차이를 가지고 있다,\n피셔의 LSD와 다른 점은 p값이 세 배가 되었다는 것이다.\n즉 데이터에 따라 피셔의 LSD에서는 유의하지만 본페로니 교정에서는 유의하지 않을 수 있다.\n\n\n\nTuckey’s Honestly Significant Difference\n\n진정으로 유의미한 차이\nFWER 중간\n\n\nPostHocTest(m, method='hsd')\n\n\n  Posthoc multiple comparisons of means : Tukey HSD \n    95% family-wise confidence level\n\n$group\n            diff     lwr.ci    upr.ci   pval    \ntrt1-ctrl -0.371 -1.0622161 0.3202161 0.3909    \ntrt2-ctrl  0.494 -0.1972161 1.1852161 0.1980    \ntrt2-trt1  0.865  0.1737839 1.5562161 0.0120 *  \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\ntrt2-trt1차이가 유의미하다는 결과가 나왔다.\n\n\nScheffe’s method\n\n보수적인 결과라 2종 오류의 가능성이 존재한다.\nFWER 가장 낮음\n\n\nPostHocTest(m, method='scheffe')\n\n\n  Posthoc multiple comparisons of means: Scheffe Test \n    95% family-wise confidence level\n\n$group\n            diff     lwr.ci    upr.ci   pval    \ntrt1-ctrl -0.371 -1.0930531 0.3510531 0.4241    \ntrt2-ctrl  0.494 -0.2280531 1.2160531 0.2265    \ntrt2-trt1  0.865  0.1429469 1.5870531 0.0163 *  \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\ntrt2-trt1 차이가 유의하다는 결과가 나왔다."
  },
  {
    "objectID": "posts/anything/2023-05-04-questions of pytorch geometric temporal.html",
    "href": "posts/anything/2023-05-04-questions of pytorch geometric temporal.html",
    "title": "Questions of PyTorch Geometric Temporal",
    "section": "",
    "text": "PyTorch Geometric Temporal"
  },
  {
    "objectID": "posts/anything/2023-05-04-questions of pytorch geometric temporal.html#applications",
    "href": "posts/anything/2023-05-04-questions of pytorch geometric temporal.html#applications",
    "title": "Questions of PyTorch Geometric Temporal",
    "section": "Applications",
    "text": "Applications\n\nEpidemiological Forecasting\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = ChickenpoxDatasetLoader()\n\ndataset = loader.get_dataset()\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import DCRNN\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = DCRNN(node_features, 32, 1)\n        self.linear = torch.nn.Linear(32, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(200)):\n    cost = 0\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    \n    \n###########################################################\n# I added this to check the shape.\nprint(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)\n\n100%|██████████| 200/200 [02:40&lt;00:00,  1.24it/s]\n\n\ntorch.Size([20, 1]) torch.Size([20]) torch.Size([20, 20])\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n# &gt;&gt;&gt; MSE: 1.0232\n\nMSE: 1.0247\n\n\n\n\nShape Check (1)\n\na = torch.randn(20, 1)\n\n\nb = torch.randn(20)\n\n\nc = a-b\n\n\nprint(a.size(),b.size(),c.size())\n\ntorch.Size([20, 1]) torch.Size([20]) torch.Size([20, 20])\n\n\n\n\n\nDoesn’t it have to ‘y_hat’ be the same shape as snapshot.y?\n\nIf we want to compare the y_hat from the model with the values y, the same shape is appropriate to evaluate.\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(200)):\n    cost = 0\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n    cost = cost / (time+1)\n    cost.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    \n    \n###########################################################\n# I added this to check the shape.\nprint(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)\n\n100%|██████████| 200/200 [01:27&lt;00:00,  2.30it/s]\n\n\ntorch.Size([20]) torch.Size([20]) torch.Size([20])\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n# &gt;&gt;&gt; MSE: 1.0232\n\nMSE: 1.2844\n\n\n\n\n\nShape Check (2)\n\na = torch.randn(20, 1).reshape(-1)\n\n\nb = torch.randn(20)\n\n\nc = a-b\n\n\nprint(a.size(),b.size(),c.size())\n\ntorch.Size([20]) torch.Size([20]) torch.Size([20])"
  },
  {
    "objectID": "posts/anything/2023-05-04-questions of pytorch geometric temporal.html#web-traffic-prediction",
    "href": "posts/anything/2023-05-04-questions of pytorch geometric temporal.html#web-traffic-prediction",
    "title": "Questions of PyTorch Geometric Temporal",
    "section": "Web Traffic Prediction",
    "text": "Web Traffic Prediction\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=14)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=14, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    \n    \n###########################################################\n# I added this to check the shape.\nprint(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)\n\n100%|██████████| 50/50 [31:26&lt;00:00, 37.73s/it]\n\n\ntorch.Size([1068, 1]) torch.Size([1068]) torch.Size([1068, 1068])\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n# &gt;&gt;&gt; MSE: 0.7760\n\nMSE: 0.7939\n\n\n\n\nShape Check (1)\n\na = torch.randn(1068, 1)\n\n\nb = torch.randn(1068)\n\n\nc = a-b\n\n\nprint(a.size(),b.size(),c.size())\n\ntorch.Size([1068, 1]) torch.Size([1068]) torch.Size([1068, 1068])\n\n\n\n\n\nIf the code changes the shape of y_hat?\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=14, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    \n    \n###########################################################\n# I added this to check the shape.\nprint(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)\n\n100%|██████████| 50/50 [36:39&lt;00:00, 43.99s/it]\n\n\ntorch.Size([1068, 1]) torch.Size([1068]) torch.Size([1068, 1068])\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n# &gt;&gt;&gt; MSE: 0.7760\n\nMSE: 0.7807\n\n\n\n\n\nShape Check (2)\n\na = torch.randn(1068, 1).reshape(-1)\n\n\nb = torch.randn(1068)\n\n\nc = a-b\n\n\nprint(a.size(),b.size(),c.size())\n\ntorch.Size([1068]) torch.Size([1068]) torch.Size([1068])\n\n\n\n\n\nReferences\n\n@inproceedings{rozemberczki2021pytorch, author = {Benedek Rozemberczki and Paul Scherer and Yixuan He and George Panagopoulos and Alexander Riedel and Maria Astefanoaei and Oliver Kiss and Ferenc Beres and and Guzman Lopez and Nicolas Collignon and Rik Sarkar}, title = {{PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models}}, year = {2021}, booktitle={Proceedings of the 30th ACM International Conference on Information and Knowledge Management}, pages = {4564–4573}, }"
  },
  {
    "objectID": "posts/anything/2023-06-15-PK Analysis.html",
    "href": "posts/anything/2023-06-15-PK Analysis.html",
    "title": "Pharmacokinetic Analysis",
    "section": "",
    "text": "Pharmacokinetic Analysis\nRef: Winnonlin Guide 8.3, Design and Analysis of Bioavailability and Bioequivalence Studies, 2×k 교차설계법에서 생물학적 동등성 추가시험의 통계적 절차, 식품의약품안전처 의약품 동등성 시험 기준"
  },
  {
    "objectID": "posts/anything/2023-06-15-PK Analysis.html#generic-medicine",
    "href": "posts/anything/2023-06-15-PK Analysis.html#generic-medicine",
    "title": "Pharmacokinetic Analysis",
    "section": "Generic Medicine",
    "text": "Generic Medicine\n\na generic medicine works in the same way and provides the same clinical benefit as the brand-name medicine.1\n특허기간이 만료된 오리지널 의약품과 주성분, 함량 및 제형이 동일하게 복제된 제네릭 의약품은 생물학적 동등성 (이하‘생동성’이라 한다)시험을 통해 오리지널 의약품과 약효가 동등하다는 것을 입증 하면 시장에 진입할 수 있다.2\n제네릭 의약품을 승인 받기 위해 생동성 시험을 거쳐야 한다"
  },
  {
    "objectID": "posts/anything/2023-06-15-PK Analysis.html#bioequivalent",
    "href": "posts/anything/2023-06-15-PK Analysis.html#bioequivalent",
    "title": "Pharmacokinetic Analysis",
    "section": "Bioequivalent",
    "text": "Bioequivalent\n\nDrug companies must submit an abbreviated new drug application (ANDA) to FDA for approval to market a generic drug that is the same as (or bioequivalent to) the brand product3\n생동성 시험은 제재학적으로 동등한 두 제제의 동등성 입증을 위해 실시하는 샐체내 실험으로, 통계학적으로 두 제제의 생체이용률의 유사성을 비교하는 시험을 의미한다.(우화형 and 박상규 2014)"
  },
  {
    "objectID": "posts/anything/2023-06-15-PK Analysis.html#parameter",
    "href": "posts/anything/2023-06-15-PK Analysis.html#parameter",
    "title": "Pharmacokinetic Analysis",
    "section": "Parameter",
    "text": "Parameter\n\n\\(AUC_t\\)\n\nArea under the curve from the time of dosing to the time of the last measurable (positive) concentratio\n약물 투여 시점부터 마지막으로 측정 가능한 (양수인) 농도까지의 면적인 (Area Under the Curve, AUC)는 약동학에서 사용되는 일반적인 파라미터\n시간에 따른 약물 노출의 범위를 추정하는 데 사용\n해당 기간 동안 혈중에서의 누적된 약물 농도를 나타냄\n\n\\(C_{max}\\) - Maximum observed concentration, occurring at time Tmax, as defined above.\n\n\\(T_{max}\\)에서의 최대 농도\n\n\\(T_{max}\\)\n\nTime of maximum observed concentration. For non-steady-state data, the entire curve is considered. If the maximum observed concentration is not unique, then the first maximum is used.\n최대 혈중 농도가 관찰된 시간\n유일한 값이 아닌 경우 첫번재 값 사용\n\n\\(\\lambda_z\\)\n\nFirst-order rate constant associated with the terminal (log-linear) portion of the curve. Estimated by linear regression of time vs. log concentration\n곡선의 말단(로그-선형) 부분과 관련된 1차 속도상수는 시간 대 로그 농도의 선형 회귀를 통해 추정\n곡선의 로그-선형 영역에서 시간과 로그 농도 간의 선형 관계를 분석하여 얻어진 1차 속도상수\n약동학 데이터의 로그-선형 부분에서 시간 대 로그 농도의 관계를 선형 회귀하여 추정된 1차 속도상수를 의미.\n\n\\(ln(2)/\\lambda_z\\)\n\nTerminal half-life\n\n\\(Tau\\)\n\nAvailable in the Dosing Used results worksheet for steady-state data. The (assumed equal) dosing interval for steady-state data.\n반복 투여하는 연구에서 반복투여하는 간격\n예) 12시간 간격으로 하루에 두 번 투여시, tau = 12\n\n\\(AUC_{TAU}\\)\n\nThe partial area from dosing time to dosing time plus Tau. See “Partial area calculation”\nfor information on how it is computed\ntau간격 별로 혈중 농도 곡선 하 면적.\n\n\n-\\(\\text{ Swing}\\): Cmax – Cmn/Cmin\n-\\(\\text{ Fluctuation}\\)\n\n100(Cmax – Cmin)/Cavg\nwhere Cmin and Cmax were obtained between dosing time and dosing time plus Tau\n약물 농도의 최소값(\\(C_{min}\\))과 최대값(\\(C_{max}\\)) 사이의 변동을 약물 투여 간격 내에서 평균 농도(\\(C_{avg}\\))에 대한 백분율로 나타내는 약동학적 파라미터 .\n\n약동학 파라메터 산출 프로그램 윈놀린 가이드 참고4\n\npage 146 정도부터 파라메터 설명 및 계산법 확인\n\n아래는 식품의약품 안전처 규칙 내용 중 일부\n\nAUCt: 투약시간부터 최종 혈중농도 정량 시간 t까지의 혈중농도-시간곡선하면적\nAUC∞ : 투약시간부터 무한시간까지의 혈중농도-시간곡선하면적 (AUC∞ = AUCt + Ct/λZ\nCt : 최종정량농도\nλZ : 말단 소실 정수\nAUCt/AUC∞ : AUCt의 AUC대한 비\nt1/2β : 소실 반감기\nAUCτ : 정상상태의 투여간격τ중의 혈중농도-시간 곡선하면적\nCmax :최고혈중농도\nCss,max정상상태의 최고혈중농도\nCss,m: 정상상태의 최저혈중농도\n\n동등성 기준 : Tmax를 제외한 대조약과 시험약의 비교평가항목치를 로그변환하여 통계처리 하였을 때, 로그변환한 평균치 차의 90% 신뢰구간이 log 0.8에서 log 1.25 이내이어야 한다"
  },
  {
    "objectID": "posts/anything/2023-06-15-PK Analysis.html#x-2-crossover-design",
    "href": "posts/anything/2023-06-15-PK Analysis.html#x-2-crossover-design",
    "title": "Pharmacokinetic Analysis",
    "section": "2 x 2 Crossover Design",
    "text": "2 x 2 Crossover Design\n현재 식품의약품 안전처에서는 두 제제의 생동성 평가 방법으로 2 x 2 교차설계법을 이용하여 두 제제의 생체이용률의 평균을 비교하는 방법 사용\n\n\n\n\nPeriod 1\nPeriod 2\n\n\n\n\nSequence 1\nReference\nTest\n\n\nSequence 2\nTest\nReference\n\n\n\n\\[y_{jkl} = \\mu + g_j + S_{l(j)} + p_k + \\pi_{jk} + \\epsilon_{jkl}\\]\n\\[j = 1,2; k = 1,2; l=1,2, \\dots, n_{1j}\\]\n\\[S_{l(j)} \\sim iid N(0,\\sigma^2_s) , \\epsilon_{jkl} \\sim iid N(0, \\sigma^2_\\epsilon)\\]\n\n혈중 농도 곡선 예시\n\n_seq = ['1'] * 18 + ['2'] * 18\nrandom.shuffle(_seq)\n\n\nseq = _seq.copy()\n\n\nprd = ['1', '2']\n\n\n# Define the two-compartment model function\ndef two_compartment_model(t, ka, ke, Vc, Vp, dose):\n    Cp = dose / (Vc + Vp) * (ka / (ka - ke)) * (np.exp(-ke * t) - np.exp(-ka * t))\n    return Cp\n\n\n# Time range\nt = np.linspace(0, 24, 20)  # Generate 100 time points from 0 to 24 hours\n\n\n# Number of subjects\nn_subjects = 36\n\n\n# Subject-specific pharmacokinetic parameter values\nka_values = np.random.uniform(0.2, 0.8, n_subjects)   # Elimination rate constant (1/hour)\nke_values = np.random.uniform(0.05, 0.15, n_subjects)  # Absorption rate constant (1/hour)\nVc_values = np.random.uniform(8, 12, n_subjects)      # Central volume of distribution (L)\nVp_values = np.random.uniform(3, 7, n_subjects)       # Peripheral volume of distribution (L)\ndose = 100  # Dose (mg)\n\nConc1=[]\n# Calculate and plot the pharmacokinetic concentration profile for each subject\nfor i in range(n_subjects):\n    ka = ka_values[i]\n    ke = ke_values[i]\n    Vc = Vc_values[i]\n    Vp = Vp_values[i]\n    Sequence=seq[i]\n    period = prd[0]\n    Cp = two_compartment_model(t, ka, ke, Vc, Vp, dose)\n    Conc1.append(Cp)\n\n\n# Subject-specific pharmacokinetic parameter values\nka_values = np.random.uniform(0.2, 0.8, n_subjects)   # Elimination rate constant (1/hour)\nke_values = np.random.uniform(0.05, 0.15, n_subjects)  # Absorption rate constant (1/hour)\nVc_values = np.random.uniform(8, 12, n_subjects)      # Central volume of distribution (L)\nVp_values = np.random.uniform(3, 7, n_subjects)       # Peripheral volume of distribution (L)\ndose = 100  # Dose (mg)\n\nConc2=[]\n# Calculate and plot the pharmacokinetic concentration profile for each subject\nfor i in range(n_subjects):\n    ka = ka_values[i]\n    ke = ke_values[i]\n    Vc = Vc_values[i]\n    Vp = Vp_values[i]\n    Sequence=seq[i]\n    period = prd[1]\n    Cp = two_compartment_model(t, ka, ke, Vc, Vp, dose)\n    Conc2.append(Cp)\n\n\nfig, (ax1,ax2) = plt.subplots(1,2,figsize=(15,6))\nfig.suptitle('Pharmacokinetic Concentration Profile (36 Subjects)')\nfor i in range(n_subjects):\n    ax1.plot(t,Conc1[i])\n    ax2.plot(t,Conc2[i])\nax1.set_xlabel('Time (hours), Period 1')\nax1.set_ylabel('Concentration (mg/L)')\nax2.set_xlabel('Time (hours), Period2')\nax2.set_ylabel('Concentration (mg/L)')\n\nText(0, 0.5, 'Concentration (mg/L)')\n\n\n\n\n\n사다리꼴 공식으로 AUC 계산\n\nauc=[]\n# AUC 계산\nfor i in range(n_subjects):\n    auc.append(trapz(Conc1, t))\n\nauc[1]\n\narray([56.95045738, 47.86409131, 42.21622527, 59.539426  , 86.67551908,\n       47.16716698, 69.1238562 , 48.31886351, 41.10456731, 77.54870044,\n       44.17471182, 84.86979417, 51.38750987, 56.38187092, 93.31926042,\n       64.86536492, 41.39841529, 49.34549501, 55.17694992, 47.80196397,\n       77.1173659 , 62.99088402, 67.81589046, 45.75082563, 41.08144901,\n       57.4092617 , 70.38694013, 60.65264211, 59.20130041, 78.037517  ,\n       75.13235504, 73.39727457, 45.94199314, 76.49863041, 52.37590008,\n       65.83072325])\n\n\n\nauc=[]\n# AUC 계산\nfor i in range(n_subjects):\n    auc.append(trapz(Conc2, t))\n\nauc[1]\n\narray([84.4561748 , 64.38750901, 64.54764973, 78.25285497, 83.33710259,\n       42.09336221, 39.00740636, 46.58495744, 47.68689149, 61.33957607,\n       49.50640257, 51.21446227, 57.54921195, 60.33096918, 75.4969536 ,\n       70.99863328, 49.58934078, 39.85776773, 85.49622606, 85.15095208,\n       44.31980906, 54.2843326 , 45.06451141, 78.41403231, 54.24686961,\n       57.3555638 , 91.1838877 , 73.63435573, 46.36158269, 53.44649347,\n       60.8944747 , 41.69662451, 77.70187433, 76.08368653, 44.59083617,\n       67.45281013])\n\n\n\ntrapz?\n\n\nSignature: trapz(y, x=None, dx=1.0, axis=-1)\nDocstring:\nAn alias of `trapezoid`.\n`trapz` is kept for backwards compatibility. For new code, prefer\n`trapezoid` instead.\nFile:      ~/anaconda3/envs/temp_csy/lib/python3.8/site-packages/scipy/integrate/_quadrature.py\nType:      function\n\n\n\n\n\n_df = pd.DataFrame()\n\nfor i in range(n_subjects):\n    temp_df1 = pd.DataFrame({\n        'Subject':str(i),\n        'Sequence': seq[i],\n        'Period': prd[0],\n        'Concentration': Conc1[i]\n    })\n    temp_df2 = pd.DataFrame({\n        'Subject':str(i),\n        'Sequence': seq[i],\n        'Period': prd[1],\n        'Concentration': Conc2[i]\n    })\n    _df = pd.concat([_df, temp_df1, temp_df2])\n\nprint(_df)\n\n   Subject Sequence Period  Concentration\n0        0        1      1       0.000000\n1        0        1      1       2.468394\n2        0        1      1       3.712638\n3        0        1      1       4.216262\n4        0        1      1       4.284278\n..     ...      ...    ...            ...\n15      35        2      2       1.571857\n16      35        2      2       1.412285\n17      35        2      2       1.268903\n18      35        2      2       1.140074\n19      35        2      2       1.024323\n\n[1440 rows x 4 columns]\n\n\n\n_df.loc[(_df['Sequence'] == '1') & (_df['Period'] == '1'), 'Treatment'] = 'R'\n_df.loc[(_df['Sequence'] == '2') & (_df['Period'] == '2'), 'Treatment'] = 'R'\n_df.loc[(_df['Sequence'] == '1') & (_df['Period'] == '2'), 'Treatment'] = 'T'\n_df.loc[(_df['Sequence'] == '2') & (_df['Period'] == '1'), 'Treatment'] = 'T'\n\n\n_df\n\n\n\n\n\n\n\n\nSubject\nSequence\nPeriod\nConcentration\nTreatment\n\n\n\n\n0\n0\n1\n1\n0.000000\nR\n\n\n1\n0\n1\n1\n2.468394\nR\n\n\n2\n0\n1\n1\n3.712638\nR\n\n\n3\n0\n1\n1\n4.216262\nR\n\n\n4\n0\n1\n1\n4.284278\nR\n\n\n...\n...\n...\n...\n...\n...\n\n\n15\n35\n2\n2\n1.571857\nR\n\n\n16\n35\n2\n2\n1.412285\nR\n\n\n17\n35\n2\n2\n1.268903\nR\n\n\n18\n35\n2\n2\n1.140074\nR\n\n\n19\n35\n2\n2\n1.024323\nR\n\n\n\n\n1440 rows × 5 columns\n\n\n\n데이터 설명\n\nSubject: 대상자\nSequence: 순서군\nPeriod: 시기군\nConcentration: 혈중농도\nTreatment: 치료군\n\n\n# ANOVA 모델 적합\nmodel = smf.mixedlm('Concentration ~ Treatment + Period + Sequence', data=_df, groups=_df['Subject']).fit()\n\n\nprint(model.summary())\n\n           Mixed Linear Model Regression Results\n===========================================================\nModel:            MixedLM Dependent Variable: Concentration\nNo. Observations: 1440    Method:             REML         \nNo. Groups:       36      Scale:              1.7059       \nMin. group size:  40      Log-Likelihood:     -2460.9348   \nMax. group size:  40      Converged:          Yes          \nMean group size:  40.0                                     \n-----------------------------------------------------------\n                  Coef. Std.Err.   z    P&gt;|z| [0.025 0.975]\n-----------------------------------------------------------\nIntercept         2.386    0.119 19.991 0.000  2.152  2.620\nTreatment[T.T]    0.055    0.069  0.804 0.421 -0.080  0.190\nPeriod[T.2]       0.034    0.069  0.494 0.621 -0.101  0.169\nSequence[T.2]     0.005    0.154  0.033 0.974 -0.297  0.307\nGroup Var         0.171    0.040                           \n===========================================================\n\n\n\n해석\n\nTrearmet의 p값은 0.05보다 큼. 치료 효과는 유의하지 않다.\nPeriod의 p값은 0.05보다 큼, 시기효과는 유의하지 않다.\nSequence의 p값은 0.05보다 큼, 순서효과는 유의하지 않다."
  },
  {
    "objectID": "posts/anything/index.html",
    "href": "posts/anything/index.html",
    "title": "Anything",
    "section": "",
    "text": "Study of any subject"
  },
  {
    "objectID": "posts/ap/2023-03-21-ap-03wk.html",
    "href": "posts/ap/2023-03-21-ap-03wk.html",
    "title": "03wk: 측도론 intro (3)",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-yJdGySrpN1x55Vs6SRntEX\n\n\n\n셀 수 있는\n- 셀 수 있는 집합과 셀 수 없는 집합.\n\ncountable: finite, countable many\nuncountable: uncountable many\n\n- 예시1: countable set, uncountable set\n\n\\(\\{1,2,3,4,5\\}\\)는 셀 수 있는 집합이다.\n\\(\\mathbb{N}\\)은 셀 수 있는 집합이다.\n\\(\\mathbb{Z}\\)는 셀 수 있는 집합이다.\n\\(\\mathbb{Q}\\)는 셀 수 있는 집합이다.\n\\(\\mathbb{R}\\)은 셀 수 없는 집합이다.\n\n- 예시2: countable sum: 아래는 모두 countable sum을 의미한다.\n\n\\(\\sum_{i=1}^{n}a_i\\).\n\\(\\sum_{i \\in I} a_i\\), where \\(I=\\{1,2,3,\\dots,10\\}\\).\n\\(\\sum_{i=1}^{\\infty} a_i\\), \\(\\sum_{i=0}^{\\infty} a_i\\).\n\\(\\sum_{i \\in \\mathbb{N}}a_i\\).\n\\(\\sum_{x \\in \\mathbb{Q}}m(\\{x\\})\\), where \\(m\\) is Lebesgue measure\n\n- 예시3: countable union: 아래는 countalbe union을 의미한다.\n\n\\(\\cup_{i=1}^n A_i\\)\n\\(\\cup_{i=1}^{\\infty} A_i\\)\n\\(\\cup_{x \\in \\mathbb{Q}} \\{x\\}\\)\n\n- 예시4: 아래는 uncountable sum을 의미한다.\n\n\\(\\sum_{x \\in [0,1]}m(\\{x\\})\\), where \\(m\\) is Lebesgue measure\n\n- 예시5: 아래는 uncountable union을 의미한다.\n\n\\(\\cup_{x \\in [0,1]} \\{x\\}\\)\n\n\n\n보충학습: 집합정리\n\n\n\n집합\n카디널리티\n분류\n르벡메져\n\n\n\n\n\\(\\{1,2,3\\}\\)\n3\n가산집합\n0\n\n\n\\(\\mathbb{N}\\)\n\\(\\aleph_0\\)\n가산집합\n0\n\n\n\\(\\mathbb{Z}\\)\n\\(\\aleph_0\\)\n가산집합\n0\n\n\n\\(\\mathbb{Q}\\)\n\\(\\aleph_0\\)\n가산집합\n0\n\n\n\\([0,1]\\)\n\\(2^{\\aleph_0}\\)\n비가산집합\n1\n\n\n\\([0,1]\\cap \\mathbb{Q}\\)\n\\(\\aleph_0\\)\n가산집합\n0\n\n\n\\([0,1]\\cup \\mathbb{Q}\\)\n\\(2^{\\aleph_0}\\)\n비가산집합\n1\n\n\n\\([0,1]\\cap \\mathbb{Q}^c\\)\n\\(2^{\\aleph_0}\\)\n비가산집합\n1\n\n\n\\([0,\\infty)\\)\n\\(2^{\\aleph_0}\\)\n비가산집합\n\\(\\infty\\)\n\n\n비탈리집합\n\\(2^{\\aleph_0}\\)\n비가산집합\nNA\n\n\n칸토어집합\n\\(2^{\\aleph_0}\\)\n비가산집합\n0\n\n\n\n\n\n지금까지의 스토리\n- 지금까지의 이야기.\n\n\\(\\Omega\\)의 모든 부분집합에 대해서 확률을 “무모순”으로 정의하는게 엄청 쉬운일 인줄 알았는데,1\n사실은 그렇지가 않았다.2 확률을 정의하는건 매우 까다로운 일이었다.\n이러한 까다로움을 해결하기 위해서 “르벡메져”라는 새로운 도구를 사용했다. 이 도구는 몇 가지 까다로운 집합에 대하여 확률을 무모순으로 정의할 수 있었다.\n르벡메져는 구간 \\([0,2\\pi)\\)의 모든 유리수 집합의 길이와 구간 \\([0,2\\pi)\\)의 모든 무리수 집합의 길이를 다르게 정의하는 신기한 방식을 사용하는데, 이러한 방식을 납득하기 위한 최소한의 노력으로 “셀 수 있는 무한”과 “셀 수 없는 무한”의 개념을 공부했다.\n하지만 르벡메져를 통해서도 \\(\\Omega\\)의 모든 부분집합에 대하여 길이를 잴 수 없는 집합3이 존재함이 밝혀졌다.\n따라서 \\(\\Omega\\)의 모든 부분집합에 대해서 확률을 “무모순”으로 정의하는 일은 포기하였다.\n대신에 \\(\\Omega\\)의 부분집합 중, 잴 수 있는 집합들에 대해서만 확률을 “무모순”으로 정의하는 일을 시도하고자 한다.\n\n- 앞으로 \\(\\Omega\\)의 부분집합 중, 잴 수 있는 집합들의 모임을 “\\(\\Omega\\)에 대한 시그마필드” 라고 하고 기호로는 \\({\\cal F}\\)로 정의한다.\n- 그런데 “잴 수 있는 집합”이 뭐지????\n\n\n시그마필드 motivation\n(예제1) – 잴 수 있는 집합의 모임\n\\(\\Omega=\\{H,T\\}\\)라고 하자. 아래집합들은 모두 확률을 정의할 수 있는 집합들이다.\n\\[\\emptyset, \\{H\\}, \\{T\\}, \\Omega\\]\n따라서 \\({\\cal F}\\)을 아래와 같이 정의한다면 묶음 \\({\\cal F}\\)가 합리적일 것이다.\n\\[{\\cal F}=\\big\\{\\emptyset, \\{H\\}, \\{T\\}, \\Omega\\big\\}\\]\n\n이때 \\({\\cal F}\\)는 집합들의 집합인데, 이러한 집합을 collection 이라고 한다.\n\n(예제2) – 집합 \\(A\\)를 잴 수 있다면, 집합 \\(A^c\\)도 잴 수 있어~\n\\(\\Omega=\\{H,T\\}\\)라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다면 묶음 \\({\\cal F}\\)는 합리적이지 않다.\n\\[{\\cal F}=\\big\\{\\emptyset, \\{H\\}, \\Omega\\big\\}\\]\n(해설1)\n이러한 묶음이 의미하는건 “앞면이 나올 확률은 모순없이 정의할 수 있지만, 뒷면이 나오는 확률은 모순없이 정의하는게 불가능해~” 라는 뜻이다. 그런데 뒷면이 나올 확률은 “1-앞면이 나올 확률” 로 모순없이 정의할 수 있으므로 “앞면이 나올 확률이 모순없이 정의되면서” 동시에 “뒷면이 나올 확률이 모순없이 정의되지 않는” 상황은 없다.\n(해설2)\n\\(\\Omega\\)의 어떠한 부분집합 \\(A\\)에 확률이 모순없이 정의된다면 그 집합의 여집합인 \\(A^c\\)에 대하여서도 확률이 모순없이 정의되어야 한다.\n\\(\\Leftrightarrow\\) \\(\\forall A \\subset {\\Omega}: ~ A \\in {\\cal F} \\Rightarrow A^c \\in {\\cal F}\\)\n(예제3) – 전체집합이 잴 수 있는 집합이니까 공집합도 잴 수 있는 집합이야\n\\(\\Omega=\\{H,T\\}\\)라고 하자. \\({\\cal F}\\)를 아래와 같이 정의한다면 묶음 \\({\\cal F}\\)는 합리적이지 않다.\n\\[{\\cal F}=\\big\\{ \\{H\\}, \\{T\\}, \\Omega\\big\\}\\]\n(해설)\n전체집합의 확률은 \\(P(\\Omega)=1\\)로 정의할 수 있다. 그런데 전체집합의 여집합인 공집합의 확률을 정의할 수 없는건 말이 안되므로 공집합은 \\(\\cal F\\)에 포함되어야 한다.\n(예제4) – 원소의 수가 유한한 경우 \\({\\cal F}=2^\\Omega\\)은 잴 수 있는 집합의 모임이야.\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\)이라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다고 하자. 이러한 묶음은 \\({\\cal F}\\)은 합리적이다.\n\\[{\\cal F}=\\text{all subset of $\\Omega$}= 2^\\Omega = \\big\\{ \\emptyset, \\{1\\}, \\{2\\}, \\dots, \\{6\\}, \\dots, \\{1,2,3,4,5\\} \\dots \\Omega\\big\\}\\]\n(해설)\n\\(\\Omega\\)의 모든 부분집합에 대하여 확률을 모순없이 정의할 수 있다. 예를들면\n\n\\(P(\\Omega)=1\\), \\(P(\\emptyset)=0\\)\n\\(P(\\{1\\})=\\frac{1}{6}\\)\n\\(P(\\{1,2,4\\})=\\frac{3}{6}\\)\n\\(P(\\{2,3,4,5,6\\})=\\frac{5}{6}\\)\n\\(\\dots\\)\n\n이런식으로 정의할 수 있다.\n(예제5) – 동일한 \\(\\Omega\\)에 대하여 잴 수 있는 집합의 모임 \\({\\cal F}\\)는 유니크하지 않음.\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\)이라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다고 하자. 이러한 묶음 \\({\\cal F}\\)는 합리적이다.\n\\[{\\cal F}=\\big\\{\\emptyset, \\{6\\}, \\{1,2,3,4,5\\},\\Omega \\big\\}\\]\n(해설)\n어떠한 특수한 상황을 가정하자. 주사위를 던져야하는데 6이 나오면 살수 있고 6이 나오지 않으면 죽는다고 하자. 따라서 던지는 사람 입장에서는 주사위를 던져서 6이 나오는지 안나오는지만 관심있을 것이다. 이 사람의 머리속에서 순간적으로 떠오르는 확률들은 아래와 같다.4\n\n살수있다 \\(\\to\\) 1/6\n죽는다 \\(\\to\\) 5/6\n살거나 죽는다 \\(\\to\\) 1\n살지도 죽지도 않는다 \\(\\to\\) 0\n\n이러한 확률은 합리적이다. 즉 아래의 집합들만 확률을 정의한다고 해도, 확률을 잘 정의할 수 있을 것 같다.\n\\[\\emptyset, \\{6\\}, \\{1,2,3,4,5\\}, \\Omega\\]\n(예제6) – \\(\\Omega\\)를 어떠한 사건의 집합으로 보느냐에 따라서 \\({\\cal F}\\)를 달리 구성할 수 있다.\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\)이라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다고 하자. 이러한 묶음 \\({\\cal F}\\)는 합리적이다.\n\\[{\\cal F}=\\big\\{\\emptyset, \\{1,3,5\\}, \\{2,4,6\\},\\Omega \\big\\}\\]\n(해설)\n전체사건을 “주사위를 던져서 짝이 나오는 사건”, “주사위를 던져서 홀이 나오는 사건” 정도만 구분하겠다는 의미\n(예제7) – \\(A\\in {\\cal F} \\Rightarrow A^c \\in {\\cal F}\\)\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\)이라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다고 하자. 이러한 묶음 \\({\\cal F}\\)는 합리적이지 않다.\n\\[{\\cal F}=\\big\\{\\emptyset, \\{1,3,5\\}, \\Omega \\big\\}\\]\n(해설)\n“주사위를 던져서 홀수가 나올 사건”에 대한 확률을 정의할 수 있는데, 짝수가 나올 사건에 대한 확률을 정의할 수 없다는건 말이 안되는 소리임.\n(예제8) – trivial \\(\\sigma\\)-field\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\)이라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다고 하자. 이러한 묶음 \\({\\cal F}\\)는 합리적이다.\n\\[{\\cal F}=\\{\\emptyset, \\Omega \\}\\]\n(해설)\n이렇게 잡으면 모순이 일어나진 않음. (쓸모가 없겠지)\n(예제9) – 서로소인 두 집합의 합, 포함관계에 있는 집합의 차\n\\(\\Omega=\\{1,2,3,4\\}\\)이라고 하자. 어떠한 필요에 따라서 1이 나올 확률과 2가 나올 확률에만 관심이 있고 나머지는 별로 관심이 없다고 하자. 그래서 \\({\\cal F}\\)을 아래와 같이 정의했다고 하자. 이러한 묶음 \\({\\cal F}\\)는 합리적이지 않다.\n\\[{\\cal F}=\\{\\emptyset, \\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\Omega \\}\\]\n(해설1)\n\\({\\cal F}\\)은 전체집합과 공집합을 포함하고 여집합에 닫혀있으므로 언뜻 생각해보면 합리적인듯 보이지만 그렇지 않다. 왜냐하면 \\(\\{1,2\\}\\)이 빠졌기 때문이다. 1이 나올 확률 \\(P(\\{1\\})\\)와 2가 나올 확률 \\(P(\\{2\\})\\)를 각각 정의할 수 있는데, 1 또는 2가 나올 확률 \\(P(\\{1,2\\})\\)을 정의할 때 모순이 발생한다는 것은 합리적이지 못하다. 왜냐하면 \\(\\{1\\} \\cap \\{2\\} = \\emptyset\\) 이므로\n\\[P(\\{1\\} \\cup \\{2\\})=P(\\{1\\}) + P(\\{2\\})\\]\n와 같이 정의가능하기 때문이다. 따라서 집합이 아래와 같이 수정되어야 한다.\n\\[{\\cal F}=\\{\\emptyset, \\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\Omega, \\{1,2\\}, \\{3,4\\} \\}\\]\n(해설2)\n생각해보니까 \\(\\{2\\}\\)는 \\(\\{2,3,4\\}\\)의 부분집합이다. 그런데 \\(P(\\{2\\})\\)와 \\(P(\\{2,3,4\\})\\)를 각각 정의할 수 있는데\n\\[P(\\{2,3,4\\} - \\{2\\}) = P(\\{3,4\\})\\]\n를 정의할 수 없는건 말이 안된다. 따라서 \\({\\cal F}\\)를 아래와 같이 수정해야 한다.\n\\[{\\cal F}=\\{\\emptyset, \\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\Omega, \\{3,4\\}, \\{1,2\\} \\}\\]\n(해설3)\n\\(\\Omega\\)의 어떠한 두 부분집합 \\(A\\), \\(B\\)가 서로소라고 상상하자. 집합 \\(A\\), \\(B\\)에 대한 확률이 각각 무모순으로 정의된다면, 집합 \\(A\\cup B\\)에 대한 확률도 무모순으로 정의되어야 한다.\n\\(\\Leftrightarrow\\) \\(\\forall A,B \\subset \\Omega\\) such that \\(A \\cap B =\\emptyset\\): \\(A,B \\in {\\cal F} \\Rightarrow A \\cup B \\in {\\cal F}\\)\n또한 \\(\\Omega\\)의 임의의 두 부분집합이 \\(A \\subset B\\)와 같은 포함관계가 성립할때, 집합 \\(A\\), \\(B\\)에 대한 확률이 각각 무모순으로 정의된다면, 집합 \\(B-A\\)에 대한 확률로 무모순으로 정의되어야 한다.\n\\(\\Leftrightarrow\\) \\(\\forall A,B \\subset \\Omega\\) such that \\(A \\subset B\\): \\(A,B \\in {\\cal F} \\Rightarrow B-A \\in {\\cal F}\\)\n(예제10) – \\({\\cal A}=\\{\\{1\\},\\{2\\}\\}\\) 일때, \\(\\sigma({\\cal A})\\) 를 구하는 문제\n\\(\\Omega=\\{1,2,3,4\\}\\)이라고 하자. 내가 관심이 있는 확률은 \\(P(\\{1\\})\\), \\(P(\\{2\\})\\) 밖에 없다고 하자. 이러한 확률들이 무모순으로 정의되기 위한 최소한의 \\({\\cal F}\\)를 정의하라.\n(해설) – 좀 귀찮네..?\n0차수정: \\({\\cal A} = \\big\\{\\{1\\}, \\{2\\}\\big\\}\\)\n1차수정: \\(\\big\\{\\emptyset, \\{1\\}, \\{2\\}, \\Omega \\big\\}\\)\n2차수정: \\(\\big\\{\\emptyset, \\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\Omega \\big\\}\\)\n3차수정: \\(\\big\\{\\emptyset, \\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\Omega, \\{1,2\\}, \\{3,4\\} \\big\\}\\)\n\n사실 우리가 관심 있는건 \\({\\cal A} = \\{ \\{1\\}, \\{2\\} \\}\\) 뿐 이었음. 그런데 뭔가 \\(P(\\{1\\})\\)와 \\(P(\\{2\\})\\)를 합리적으로 정의하기 위해서 필연적으로 발생하는 어떠한 집합들을 모두 생각하는건 매우 피곤하고 귀찮은 일임. 그래서 “아 모르겠고, \\(\\{1\\}\\) 와 \\(\\{2\\}\\)를 포함하고 확률의 뜻에 모순되지 않게 만드는 최소한의 \\({\\cal F}\\)가 있을텐데, 거기서만 확률을 정의할래!” 라고 쉽게 생각하고 싶은 사람들이 생김. 그러한 공간을 \\(\\sigma({\\cal A})\\)라는 기호로 약속하고 smallest \\(\\sigma\\)-field containing \\({\\cal A}\\) 라는 용어로 부름.\n\n\n생각의 시간1\n우리가 잴 수 있는 집합의 모임들 \\({\\cal F}\\)라는 것은 답을 구체적으로 쓸 수는 없으나 현재까지 파악한 직관에 한정하여 아래와 같은 조건5들을 만족하는 collection이라고 “일단은” 생각할 수 있다.\n\n\\(\\Omega, \\emptyset \\in {\\cal F}\\)\n\\(\\forall A \\subset \\Omega: ~ A \\in {\\cal F} \\Rightarrow A^c \\in {\\cal F}\\)\n\\(\\forall A,B \\subset \\Omega\\) such that \\(A\\cap B =\\emptyset\\): \\(A,B \\in {\\cal F} \\Rightarrow A \\cup B \\in {\\cal F}\\)\n\\(\\forall A,B \\subset \\Omega\\) such that \\(A \\subset B\\): \\(A,B \\in {\\cal F} \\Rightarrow B-A \\in {\\cal F}\\)\n\n이것은 우리가 “확률”이라는 개념을 올바르게 정의하기 위해서 필요한 최소한의 합의6이다.\n여기에서 우리가 따져볼 것은 (1) 시그마필드의 조건으로 1~4이면 충분한지 (더 많은 조건들이 필요한건 아닌지) 그리고 (2) 우리가 있었으면 하는 조건들이 꼭 필요한 조건은 맞는지 (예를들면 한두개의 조건이 다른조건을 암시하는건 아닌지) 이다.\n(충분할까?) 조건 1,2,3,4 정도를 만족하는 집합으로 시그마필드를 정의해도 충분할까? 좀 더 많은 조건들이 필요한건 아닐까? 예를들면 아래와 같은 조건들이 필요한건 아닌가?\n\n\\(\\forall A,B \\subset \\Omega:~ A,B \\in {\\cal F} ~ \\Rightarrow A\\cap B \\in {\\cal F}\\)\n\\(\\forall A,B \\subset \\Omega:~ A,B \\in {\\cal F} ~ \\Rightarrow A\\cup B \\in {\\cal F}\\)\n\\(\\forall B_1,B_2,\\dots \\subset \\Omega\\) such that \\(B_1, B_2,\\dots\\) are disjoint: \\(B_1,B_2,\\dots \\in {\\cal F} \\Rightarrow \\cup_{i=1}^{\\infty}B_i \\in {\\cal F}\\)\n\\(\\forall A_1,A_2,\\dots \\subset \\Omega\\): \\(A_1,A_2,\\dots \\in {\\cal F} \\Rightarrow \\cup_{i=1}^{\\infty}A_i \\in {\\cal F}\\)\n\n여기에서 잠시 7의 의미를 살펴보자.\n\n3의 확장버전이라고 볼 수 있다. 3은 “각 집합을 잴 수 있다면 서로소인 집합을 유한번 더한 집합도 잴 수 있어야 한다” 라는 의미가 된다. 7은 “각 집합을 잴 수 있다면 서로소인 집합을 셀 수 있는 무한번 더한 집합도 잴 수 있어야 한다” 라는 의미가 된다.\n\n\n(예제11) – 람다시스템\n\\(\\Omega=(0,2\\pi]\\) 라고 하자. \\({\\cal A} = \\{\\{x\\}: x\\in \\mathbb{Q} \\cap \\Omega \\}\\) 이라고 할 때 아래가 성립할까?\n\\[\\mathbb{Q} \\cap \\Omega \\in \\sigma({\\cal A})\\]\n즉 각각의 유리수 한점씩을 잴 수 있을 때7 유리수 전체의 집합 역시 잴 수 있을까?\n(해설1)\n유리수는 셀 수 있는 무한이므로 집합 \\(\\mathbb{Q} \\cap \\Omega\\)의 길이나 확률 따위는 잴 수 있다.\n(해설2)\n확률의 공리중 3을 살펴보면 이미 서로소인 집합의 countable union은 잴 수 있는 대상이라고 생각하고 있다. 이건 마치 “확률은 양수”이어야 한다든가, “전체확률은 1이어야” 한다는 사실처럼 당연한 사실이다.8\n\n\n\n그림1: 위키에서 캡쳐했어요~ 3번째 공리를 살펴보세요\n\n\n\n사실 납득이 되는건 아님. 그렇지만 일단은 “수학자들이 합의해서 이런건 잴 수 있다고 했어. 그러니까 잴 수 있어” 라고 이해하고 넘어가자.\n\n\n생각의 시간2\n이제 5,6의 성질을 살펴보자.\n\n\\(\\forall A,B \\subset \\Omega:~ A,B \\in {\\cal F} ~ \\Rightarrow A\\cap B \\in {\\cal F}\\)\n\\(\\forall A,B \\subset \\Omega:~ A,B \\in {\\cal F} ~ \\Rightarrow A\\cup B \\in {\\cal F}\\)\n\n6의 경우는 \\(A\\)와 \\(B\\)가 서로소가 아니더라고 \\(A \\cup B\\)를 잴 수 있느냐? 라는 것이다. (결국 이는 교집합을 잴 수 있느냐? 라는 물음과 같아서 5와 6은 같은 질문이다.)\n\n(예제12) – 교집합을 넣을까 말까\n\\(\\Omega=\\{1,2,3,4\\}\\)라고 하자. 아래와 같은 \\({\\cal F}\\)는 합리적일까?\n\\[{\\cal F}= \\big\\{ \\emptyset, \\{1,2\\}, \\{1,3\\}, \\{1,4\\},\\{2,3\\},\\{2,4\\},\\{3,4\\}, \\Omega\\big\\}\\]\n(해설1) – 틀린해설\n이러한 집합은 원칙 1-4,7 에 위배되지 않는다.\n1. \\(\\Omega, \\emptyset \\in {\\cal F}\\)\n2. \\(\\forall A \\subset \\Omega: ~ A \\in {\\cal F} \\Rightarrow A^c \\in {\\cal F}\\)\n3. \\(\\forall A,B \\subset \\Omega\\) such that \\(A\\cap B =\\emptyset\\): \\(A,B \\in {\\cal F} \\Rightarrow A \\cup B \\in {\\cal F}\\)\n4. \\(\\forall A,B \\subset \\Omega\\) such that \\(A \\subset B\\): \\(A,B \\in {\\cal F} \\Rightarrow B-A \\in {\\cal F}\\)\n7. \\(\\forall B_1,B_2,\\dots \\subset \\Omega\\) such that \\(B_1, B_2,\\dots\\) are disjoint: \\(B_1,B_2,\\dots \\in {\\cal F} \\Rightarrow \\cup_{i=1}^{\\infty}B_i \\in {\\cal F}\\)\n그런데 이 집합은\n\\[\\{1,2\\} \\cap \\{1,3\\} = \\{1\\}\\]\n와 같은 집합이라든가,\n\\[\\{1,2\\} \\cup \\{1,3\\} = \\{1,3,4\\}\\]\n와 같은 집합의 길이를 잴 수 없다. 따라서 아래와 같이 우리가 고등학교때 부터 써왔던 공식을 쓸 수 없다. (ref, Further consequences)\n\\[P(A\\cup B) = P(A) + P(B) - P(A\\cap B)\\]\n이것은 불편하니까 \\(A,B\\)가 잴 수 있다면, \\(A,B\\)의 교집합이나 합집합따위도 잴 수 있다고 정하자.\n(해설1의 반론)\n약속하지 않으면 “불편”하니까 약속하자라는 논리는 말이 되지 않음. 그 논리대로라면 \\(\\Omega\\)의 모든 집합에 대하여 확률을 정의할 수 없다고 하면 “불편”하니까 약속하자라는 논리가 됨. 잴 수 있는 집합의 합집합이나 교집합을 잴 수 있다라는 근거는 없음.\n(해설1의 반론의 반론) – 참고용으로만..\n사실 근거가 있긴함. 즉 \\(A\\)와 \\(B\\)를 각각 잴 수 있다면 \\(A\\), \\(B\\)의 교집합도 잴 수 있음. (그렇다면 자동으로 합집합도 잴 수 있게 됨.) 이것을 지금 수준에서 엄밀하게 따지기 위해서는 “잴 수 있는 집합”의 정의를 해야하는데 지금 수준에서는 까다로움.\n(해설2) – 엄밀한 해설 X\n잴 수 있는 집합을 우리는 지금 까지 당연하게\n\n확률을 잴 수 있는 집합들\n\n로 생각했음, 그런데 원래 잴 수 있는 집합이라는 개념은 “선분의 길이” 따위를 모순없이 정의할 수 있는가? 즉 수직선 \\(\\mathbb{R}\\)의 모든 부분집합의 길이라는 개념을 정의할 수 있는가? 에서 출발하였음. 즉 원래 잴 수 있는 집합이라는 의미는\n\n수직선에서 길이를 잴 수 있는 집합들\n\n이라고 생각해야함. 그렇다면 “길이”라는 개념을 다시 추상화 해야하는데 “길이”라는 개념은 아래의 원칙에 위배되면 안될 것 같음.\n\n\n\n그림2: 위키에서 긁어온 그림. 길이는 1-4의 성질이 있어야 할 것으로 판단됨\n\n\n교집합을 잴 수 없다는 논리라면, 구간 \\([a_1,b_1]\\)의 길이는 잴 수 있고 구간 \\([a_2,b_2]\\)의 길이는 잴 수 있지만 구간 \\([a_1,b_1] \\cap [a_2,b_2]\\)의 길이는 잴 수 없다는 말인데 이는 말이되지 않음.\n\n결론 (엄밀한 해설은 아님): “잴 수 있다” 라는 개념은 확률, 길이에 모두 적용할 수 있어야 한다. 잴 수 있는 대상을 확률로 상상하면 \\(A \\in {\\cal F} \\Rightarrow A^c \\in {\\cal F}\\) 인것이 당연하듯이 잴 수 있는 대상을 길이로 상상하면 \\(A,B \\in {\\cal F} \\Rightarrow A \\cap B \\in {\\cal F}\\) 임은 당연하다.\n\n\n생각의 시간3\n따라서 아래의 성질들은 모두 시그마필드가 가져아할 규칙들로 인정할 수 있다.\n\n\\(\\Omega, \\emptyset \\in {\\cal F}\\)\n\\(\\forall A \\subset \\Omega: ~ A \\in {\\cal F} \\Rightarrow A^c \\in {\\cal F}\\)\n\\(\\forall A,B \\subset \\Omega\\) such that \\(A\\cap B =\\emptyset\\): \\(A,B \\in {\\cal F} \\Rightarrow A \\cup B \\in {\\cal F}\\)\n\\(\\forall A,B \\subset \\Omega\\) such that \\(A \\subset B\\): \\(A,B \\in {\\cal F} \\Rightarrow B-A \\in {\\cal F}\\)\n\\(\\forall A,B \\subset \\Omega:~ A,B \\in {\\cal F} ~ \\Rightarrow A\\cap B \\in {\\cal F}\\)\n\\(\\forall A,B \\subset \\Omega:~ A,B \\in {\\cal F} ~ \\Rightarrow A\\cup B \\in {\\cal F}\\)\n\\(\\forall B_1,B_2,\\dots \\subset \\Omega\\) such that \\(B_1, B_2,\\dots\\) are disjoint: \\(B_1,B_2,\\dots \\in {\\cal F} \\Rightarrow \\cup_{i=1}^{\\infty}B_i \\in {\\cal F}\\)\n\n남은건 8번의 규칙이다.\n\n\\(\\forall A_1,A_2,\\dots \\subset \\Omega\\): \\(A_1,A_2,\\dots \\in {\\cal F} \\Rightarrow \\cup_{i=1}^{\\infty}A_i \\in {\\cal F}\\)\n\n이 89번 규칙은 사실 510, 711번 잘 조합하면 자동으로 이끌어진다. 즉 \\((5), (7) \\Rightarrow (8)\\). 그 외에도 “있었으면 싶은” 규칙은 모두 1-7중 적당한 것을 섞으면 만들 수 있다. 예를들어 아래와 같은 규칙을 고려하자.\n\n\\(\\forall A,B \\subset \\Omega:~ A,B \\in {\\cal F} \\Rightarrow A-B \\in {\\cal F}\\)\n\\(\\forall A,B,C \\subset \\Omega: A,B,C \\in {\\cal F} \\Rightarrow A\\cup B \\cup C \\in {\\cal F}\\)\n\\(\\forall A_1,A_2,\\dots \\subset \\Omega\\): \\(A_1,A_2,\\dots \\in {\\cal F} \\Rightarrow \\cap_{i=1}^{\\infty}A_i \\in {\\cal F}\\)\n\n규칙9는 규칙212와 513로 임플라이 할 수 있고, 규칙10은 규칙614의 확장으로 임플라이 할 수 있고, 규칙11은 규칙 215와 716로 임플라이 할 수 있다.\n\n결론: 규칙 1-8으로 시그마필드를 표현하기에 충분하다.\n\n생각의 시간4\n규칙 1-8중 필요없는 규칙을 제거하자.\n1. 규칙217가 있다면, 규칙1에서 공집합은 빼도 될 것 같다.\n2. 규칙818이 있다면, 규칙319, 규칙620, 규칙721은 필요 없다. 즉 규칙8은 규칙3,6,7의 효과를 모두 가진다.\n3. 규칙222와 규칙623이 있다면, 규칙524는 필요없다. 따라서 규칙225와 규칙826이 있어도 규칙5는 필요없다.\n4. 규칙227와 규칙528가 있다면 규칙429는 필요없다. 그런데 규칙5는 규칙2와 규칙830이 임플라이 하므로 결국 규칙2와 규칙8이 있다면 규칙4가 필요없다.\n5. 결론: 규칙1에서 공집합을 제외한 버전, 그리고 규칙2, 규칙8만 있으면 된다.\n\n\n시그마필드의 정의\n- 시그마필드, 즉 \\(\\Omega\\)의 부분집합 중 “잴 수 있는 집합의 모임”은 Durret 교재에 의하여 아래와 같이 정의된다.\n\n\n\n그림3: Durret교재에서 긁어온 시그마필드의 정의, 드래그한 부분이 정의임\n\n\n- 교재에는 \\(\\Omega \\in {\\cal F}\\)이라는 조건이 빠져있는데, \\(\\Omega \\in {\\cal F}\\)이라는 조건을 포함하여 기억하는 것이 편리하다. (위키등에서 일반적으로 정의할때는 \\(\\Omega \\in {\\cal F}\\) 조건을 포함한다) 즉 위키와 Durret을 적당히 혼합하여 아래와 같이 정의하고 기억하는게 좋다.\n(Def) Let \\(\\Omega\\) be some set, and let \\(2^{\\Omega}\\) represent its power set. Then a subset \\({\\cal F} \\subset 2^\\Omega\\) is called a \\(\\sigma\\)-field if it satisfies the following three properties:\n\n\\(\\Omega \\in {\\cal F}\\)\n\\(A \\in {\\cal F} \\Rightarrow A^c \\in {\\cal F}\\)\n\\(A_1,A_2,A_3\\dots \\in {\\cal F}\\) \\(\\Rightarrow\\) \\(\\cup_{i=1}^{\\infty}A_i \\in {\\cal F}\\)\n\n- 좀 더 편리하게 아래와 같이 기억하면 좋다.\n\n시그마필드는 잴 수 있는 집합의 모임인데 아래와 같은 규칙을 만족해야 한다. (1) 전체집합을 포함한다. (2) 여집합에 닫혀있다. (3) 가산합집합에 닫혀있다.\n\n- 참고1: 시그마필드라는 것은 유일하게 정의되지 않는다. 즉 동일한 \\(\\Omega\\)에 대하여 정의할 수 있는 잴수있는 집합의 모임 \\({\\cal F}\\)는 유일하지 않다.\n- 참고2: 시그마필드는 \\(\\Omega\\)없이 단독으로 정의되지 않는다. 즉\n\\[{\\cal F}=\\{\\emptyset, \\{H\\}, \\{T\\}, \\{H,T\\}\\}\\]\n는 단지 그냥 시그마필드라고 주장하기 보다 \\(\\Omega=\\{H,T\\}\\)에 대한 시그마필드라고 해야 정확한 표현이다.\n- 참고3: 참고2에 따라서 \\({\\cal F}\\) 단독으로 표기하는 것 보다 \\(\\Omega\\)를 붙여서 \\((\\Omega,{\\cal F})\\)와 같이 쌍으로 표기하는게 더 합리적이다. 앞으로는 이러한 쌍을 measurable space 라고 부른다.\n\n\n\n\n\nFootnotes\n\n\n동전예제↩︎\n바늘이 하나 있는 시계예제↩︎\n비탈리집합↩︎\n공평한 주사위라고 하자..↩︎\n이 조건들은 수정 및 보완 될 예정임↩︎\n모든 사람들이 인정할 수 밖에 없는 합의↩︎\n\\(P(\\{0\\})\\), \\(P(\\{0.21\\})\\), \\(\\dots\\)를 각각 정의가능할 때↩︎\n사실 일반인에게 당연하지 않을 수도 있지만 최소한 수학자들은 당연하게 생각한다. 그래서 우리도 그냥 당연하게 생각하자.↩︎\ncountable union↩︎\n교집합↩︎\n서로소의 countable union↩︎\n여집합↩︎\n교집합↩︎\n2개 집합의 합집합↩︎\n여집합↩︎\n서로소의 countable union↩︎\n여집합↩︎\ncountable union↩︎\ndisjoint union of two sets↩︎\n2개의 합집합↩︎\ncountable union of disjoint sets↩︎\n여집합↩︎\n합집합↩︎\n교집합↩︎\n여집합↩︎\ncountable union↩︎\n여집합↩︎\n교집합↩︎\n포함관계의 차집합↩︎\ncountable union↩︎"
  },
  {
    "objectID": "posts/ap/2023-04-13-7wk-2.out.html",
    "href": "posts/ap/2023-04-13-7wk-2.out.html",
    "title": "07wk-2: 마코프체인 (3)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-zAMowm9anbqZG0fCAmFI_1"
  },
  {
    "objectID": "posts/ap/2023-04-13-7wk-2.out.html#formular",
    "href": "posts/ap/2023-04-13-7wk-2.out.html#formular",
    "title": "07wk-2: 마코프체인 (3)",
    "section": "formular",
    "text": "formular\n- 저번시간에 살펴본 날씨모형은 결국 아래와 같은 모형이었다.\n\\[\\begin{bmatrix}\nP(X_{t+1}=0) \\\\\nP(X_{t+1}=1)\n\\end{bmatrix}= \\begin{bmatrix} 0.8 & 0.1 \\\\ 0.2 & 0.9 \\end{bmatrix} \\begin{bmatrix}\nP(X_{t}=0) \\\\\nP(X_{t}=1)\n\\end{bmatrix}\\]\n양변에 트랜스포즈를 취하게 되면\n\\[\\begin{bmatrix}\nP(X_{t+1}=0) &\nP(X_{t+1}=1)\n\\end{bmatrix}= \\begin{bmatrix}\nP(X_{t}=0) &\nP(X_{t}=1)\n\\end{bmatrix}\\begin{bmatrix} 0.8 & 0.2 \\\\ 0.1 & 0.9 \\end{bmatrix} \\]\n수식화하면 아래와 같이 된다. (보통 이러한 형태로 책에 많이 쓰니까 이 형태로 외울것!)\n\\[{\\boldsymbol \\mu}_{t+1}^\\top ={\\boldsymbol \\mu}_{t}^\\top {\\bf P}\\]\n\n참고: \\(X_t\\)는 0 혹은 1의 값을 가질수 있는데, 이렇게 \\(X_t\\)가 가질 수 있는 값들을 모은 공간을 상태공간이라고 하고 기호로는 \\(V=\\{0,1\\}\\)와 같이 표현한다.\n\n\n참고: 여기에서 확률과정 \\(\\{X_t\\}\\)는 이전시점의 값 \\(X_{t-1}\\)에 의하여서만 결정된다. 이러한 확률과정을 마코프체인이라고 한다.\n\n\n참고: 이때 매트릭스 \\({\\bf P}\\)를 transition matrix 라고 한다.\n\n- \\({\\bf P}\\)의 의미 (\\(\\star\\))\n\\({\\bf P}\\)의 각 원소를 아래와 같이 두자.\n\n\\({\\bf P} = \\begin{bmatrix} p_{00} & p_{01} \\\\ p_{10} & p_{11} \\end{bmatrix}\\)\n\n\\({\\bf P}\\)의 \\((i,j)\\)의 원소는 \\(i \\to j\\)로 이동할 확률을 의미한다. 즉 \\(p_{00}\\), \\(p_{01}\\), \\(p_{10}\\), \\(p_{11}\\) 은 각각 아래를 의미한다.\n\n\\(p_{00}\\): \\(0 \\to 0\\)일 확률. 즉 \\(P(X_t = 0 | X_{t-1} = 0)\\)\n\\(p_{01}\\): \\(0 \\to 1\\)일 확률. 즉 \\(P(X_t = 1 | X_{t-1} = 0)\\)\n\\(p_{10}\\): \\(1 \\to 0\\)일 확률. 즉 \\(P(X_t = 0 | X_{t-1} = 1)\\)\n\\(p_{11}\\): \\(1 \\to 1\\)일 확률. 즉 \\(P(X_t = 1 | X_{t-1} = 1)\\)\n\n- \\({\\boldsymbol \\mu}\\)의 의미 (\\(\\star\\))\n\n\\({\\boldsymbol \\mu}_t\\)는 \\(X_t\\)의 pmf를 의미한다.\n\\({\\boldsymbol \\mu}_0\\)는 \\(X_0\\)의 pmf를 의미한다. 즉 초기분포를 의미한다.\n\\({\\boldsymbol \\mu}\\)자체가 어떠한 분포를 의미한다."
  },
  {
    "objectID": "posts/ap/2023-04-13-7wk-2.out.html#특징들",
    "href": "posts/ap/2023-04-13-7wk-2.out.html#특징들",
    "title": "07wk-2: 마코프체인 (3)",
    "section": "특징들",
    "text": "특징들\n- 특징1: \\({\\bf P}\\)는 수렴한다. 즉 \\({\\bf P}^{\\infty}\\)가 존재한다.\n\nP = np.array([[0.8, 0.2],[0.1, 0.9]])\nP\n\n\nnp.linalg.matrix_power(P,1),np.linalg.matrix_power(P,10),np.linalg.matrix_power(P,30),np.linalg.matrix_power(P,50)\n\n\nPlim = np.linalg.matrix_power(P,100)\n\n- 특징2: \\({\\bf P}^{\\infty}\\)의 each column은 모두 동일한 값을 가진다. \\(\\Rightarrow\\) \\(\\mu\\)에 어떠한 값을 넣어도 \\({\\boldsymbol \\mu}^\\top{\\bf P}^{\\infty}={\\boldsymbol \\pi}^\\top = [1/3, 2/3]\\) \\(\\Rightarrow\\) \\({\\bf P}\\)의 아무 row 나 선택하여 그것을 \\({\\boldsymbol \\pi}^\\top\\)라고 두자. \\({\\boldsymbol \\pi}\\)는 \\(X_{\\infty}\\)의 pmf가 된다.\n초기값에 민감하지 않다)\n\nμ = np.array([[0.5],[0.5]]) \nμ.T @ Plim\n\n\nπ = np.array([1/3,2/3]).reshape(2,1)\nπ\n\n\n\\(X_{\\infty}=\\begin{cases} 0 & w.p.~ 1/3 \\\\ 1 & w.p.~ 2/3 \\end{cases}\\)\n\n\n참고: 여기에서 \\({\\boldsymbol \\pi}\\)를 확률과정 \\(\\{X_t\\}\\)의 정상분포 (stationary distribution) 라고 한다.\n\n- 특징3: \\({\\boldsymbol \\pi}^\\top {\\bf P} = {\\boldsymbol \\pi}^\\top\\) 가 성립한다.\n\n근데 이건 왜 이러지?\n\n\nπ.T @ P\n\n당연히 다른 분포 \\({\\boldsymbol \\mu}\\)에 대하여서는 성립하지 않음\n\nμ = np.array([[0.5],[0.5]]) \nμ.T @ P\n\n\n참고: 여기에서 수식 \\({\\boldsymbol \\pi}^\\top {\\bf P} = {\\boldsymbol \\pi}^\\top\\) 자체가 정상분포의 정의가 된다. 즉 마코프체인 \\(\\{X_t\\}\\)의 트랜지션 매트릭스가 \\({\\bf P}\\)일때, \\({\\boldsymbol \\pi}^\\top {\\bf P} = {\\boldsymbol \\pi}^\\top\\)를 만족하는 \\({\\boldsymbol \\pi}\\)가 존재한다면 \\({\\boldsymbol \\pi}\\)를 확률과정 \\(\\{X_t\\}\\)의 정상분포라고 한다.\n\n- 특징4: 초기분포 \\({\\boldsymbol \\mu}_0\\)를 \\({\\boldsymbol \\pi}\\)로 설정하면 \\(\\{X_t\\}\\)는 모든 \\(t\\)에 대하여 동일한 분포를 가진다. (독립은 아니다)\n\nπ # 초기분포: X0의 pmf \n\n\nX0 = np.random.rand() &lt; 2/3\n# X0 = np.random.rand() &gt; 0.52941176\n\n\narr = np.array([doctor_strange(np.random.rand() &lt; 2/3) for i in range(4305)])\narr\n\n\nplt.plot(arr[0][-100:])\n\n\n\n\n\narr[:,0]*1\n\n\narr[:,-1].sum()\n\n\narr[:,0].sum()\n\n\nfig, ax = plt.subplots(3,3)\nax[0][0].hist(arr[:,0]*1,alpha=0.5);\nax[0][1].hist(arr[:,500]*1,alpha=0.5);\nax[0][2].hist(arr[:,1000]*1,alpha=0.5);\nax[1][0].hist(arr[:,1500]*1,alpha=0.5);\nax[1][1].hist(arr[:,2000]*1,alpha=0.5);\nax[1][2].hist(arr[:,2500]*1,alpha=0.5);\nax[2][0].hist(arr[:,3000]*1,alpha=0.5);\nax[2][1].hist(arr[:,3500]*1,alpha=0.5);\nax[2][2].hist(arr[:,4000]*1,alpha=0.5);\nfig.tight_layout()\n\n\n\n\n\nplt.hist(arr[0]*1)\n\n\n\n\n특징4의 변형: 초기분포가 \\({\\boldsymbol \\pi}\\)가 아니더라도 적당한 시점 \\(T_0\\) 이후에는 \\(\\{X_t\\}_{t\\geq T_0}\\)는 동일한분포를 가진다고 볼 수 있다.\n\n참고: 특징4는 후에 MCMC를 이해하는 중요한 예제가 된다."
  },
  {
    "objectID": "posts/ap/2023-04-13-7wk-2.out.html#특징3을-위한-약간의-해설",
    "href": "posts/ap/2023-04-13-7wk-2.out.html#특징3을-위한-약간의-해설",
    "title": "07wk-2: 마코프체인 (3)",
    "section": "특징3을 위한 약간의 해설",
    "text": "특징3을 위한 약간의 해설\n편의상 \\({\\bf P}^{\\star}={\\bf P}^{\\infty}\\) 라고 하자. 이미 살펴본 것 처럼\n\n\\({\\bf P}^\\star {\\bf P} = {\\bf P}^\\star\\)\n\n가 성립한다. 특징2에서 살펴본것 처럼 임의의 \\({\\boldsymbol \\mu}\\)에 대하여 \\({\\boldsymbol \\mu}^\\top {\\bf P}^{\\star} = {\\boldsymbol \\pi}^\\top\\) 가 항상 성립함을 확인할 수 있다. 이 수식을 살짝 변형하면\n\n\\({\\boldsymbol \\mu}^\\top {\\bf P}^{\\star} = {\\boldsymbol \\pi}^\\top\\)\n\\(\\Rightarrow ({\\boldsymbol \\mu}^\\top{\\bf P}^{\\star}){\\bf P} = {\\boldsymbol \\pi}^\\top\\)\n\\(\\Rightarrow {\\boldsymbol \\pi}^\\top{\\bf P} = {\\boldsymbol \\pi}^\\top\\)\n\n이다. 따라서 특징3이 유도된다."
  },
  {
    "objectID": "posts/ap/2023-06-06-ap-14wk.html",
    "href": "posts/ap/2023-06-06-ap-14wk.html",
    "title": "14wk: 이산형과 연속형의 통합",
    "section": "",
    "text": "youtube: https://www.youtube.com/playlist?list=PLQqh36zP38-wThZpnzJAP_aOtJzBl1Ij"
  },
  {
    "objectID": "posts/ap/2023-06-06-ap-14wk.html#이산확률변수",
    "href": "posts/ap/2023-06-06-ap-14wk.html#이산확률변수",
    "title": "14wk: 이산형과 연속형의 통합",
    "section": "이산확률변수",
    "text": "이산확률변수\n- 예제1 – 베르누이 (with 카운팅메져)\n아래와 같은 함수를 고려하자.\n\\[F_X(x) = \\begin{cases}\n0 & x&lt;0 \\\\\n\\frac{1}{2} & 0 \\leq  x &lt;1 \\\\\n1 & x \\geq 1\n\\end{cases}\\]\n\ndef F_X(x):\n    if x &lt; 0:\n        return 0\n    elif 0 &lt;= x &lt; 1:\n        return 1/2\n    else:\n        return 1\n\n# 그래프를 그릴 x 범위 설정\nx = np.linspace(-1, 2, 1000)\n\n# 누적분포함수 계산\ny = [F_X(val) for val in x]\n\n# 그래프 그리기\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('F_X(x)')\nplt.title('Cumulative Distribution Function')\nplt.grid(True)\n\n\n\n\n이제 \\(S=\\{0,1\\}\\), \\({\\cal S}=\\{\\emptyset, \\{0\\},\\{1\\},\\{1,2\\}\\}\\)로 구성된 measurable space \\((S,{\\cal S})\\)를 생각하자. 함수 \\(\\tilde{\\mu}_X: {\\cal S} \\to [0,1]\\)를 아래와 같이 정의하면\n\n\\(\\tilde{\\mu}_X(\\emptyset)= 0\\)\n\\(\\tilde{\\mu}_X(\\{0\\})= \\frac{1}{2}\\)\n\\(\\tilde{\\mu}_X(\\{1\\})= \\frac{1}{2}\\)\n\\(\\tilde{\\mu}_X(\\{0,1\\})= 1\\)\n\n\n\n서연 필기\n\n\n\\(\\tilde{\\mu}_X(\\emptyset)= 0\\) \\(\\rightarrow\\) \\(P(\\emptyset)\\)\n\\(\\tilde{\\mu}_X(\\{0\\})= \\frac{1}{2}\\) \\(\\rightarrow\\) \\(P(H)\\)\n\\(\\tilde{\\mu}_X(\\{1\\})= \\frac{1}{2}\\) \\(\\rightarrow\\) \\(P(T)\\)\n\\(\\tilde{\\mu}_X(\\{0,1\\})= 1\\) \\(\\rightarrow\\) \\(P(\\Omega)\\)\n\n\\(\\to\\) \\(mu_x : \\cal{R} \\to [0,1]\\)으로 착각할 수 있지만 여기서는 \\(\\cal{S} \\to [0,1]\\)로 정의하였으므로 다르다.\n\n함수 \\(\\tilde{\\mu}_X\\)는 \\((S,{\\cal S})\\)에서의 메져가 되며, 이것은 \\(F_X\\)에 대응하는 분포 \\({\\mu}_X\\)와 같은 역할을 한다. 이제 measurable space \\((S,{\\cal S})\\)에 대하여 아래와 같은 함수 \\(\\#: {\\cal S} \\to \\mathbb{R}\\)을 고려하자.\n\n\\(\\#(\\emptyset)=0\\)\n\\(\\#(\\{0\\})= 1\\)\n\\(\\#(\\{1\\})= 1\\)\n\\(\\#(\\{0,1\\})= 2\\)\n\n\n\n서연 필기\n\n단순히 말하면 \\(\\#(A)\\) = 집합 \\(A\\)의 원소 수라고 할 수 있다.\n\n이때 함수 \\(\\#\\)은 \\((S,{\\cal S})\\) 에서의 메져가 되며, 이러한 메져를 특별히 카운팅메져(counting measure) 라고 한다. 이제 아래의 함수 \\(f_X:S \\to \\mathbb{R}\\)를 고려하자.\n\n\\(f_X(0)=\\frac{1}{2}\\)\n\\(f_X(1)=\\frac{1}{2}\\)\n\n함수 \\(f_X\\)는 카운팅메져 \\(\\#\\)에 대한 \\(\\tilde{\\mu}_X\\)의 라돈니코딤 도함수임을 보여라.\n(해설)\n\n\\(\\tilde{\\mu}_X\\), \\(\\#\\)는 모두 \\((S,{\\cal S})\\) 에서의 \\(\\sigma\\)-finite 메져이다.\n\\(\\tilde{\\mu}_X &lt;&lt; \\#\\)이 성립한다. 따라서 적당한 \\({\\cal S} - {\\cal R}^+\\) measurable function이 존재하여 라돈니코딤 도함수의 조건을 만족함을 알 수 있다.\n우리가 생각하는 후보는 \\(f_X\\)인데 이것이 만약에 (1) \\({\\cal S} - {\\cal R}^+\\) 가측함수이고 (2) 라돈니코딤 도함수의 조건1을 만족한다면 \\(f_X\\)는 카운팅메져 \\(\\#\\)에 대한 \\(\\mu\\)의 거의 유일한 (w.r.t. \\(\\#\\)) 밀도함수라고 주장할 수 있다.\n\\(f_X\\)는 \\({\\cal S} \\to {\\cal R}^+\\) 가측함수이다. (simple function)\n\\(\\forall B \\in {\\cal S}: \\mu(B)=\\int_B f_X d\\#=\\sum_{x \\in B} f_X(x)\\) 를 만족한다.\n\n\n\n서연 필기\n\n\n\n\\(\\tilde{\\mu}_X\\), \\(\\#\\)는 모두 \\((S,{\\cal S})\\) 에서의 \\(\\sigma\\)-finite 메져이다.\n\n\n\n\\(\\tilde{\\mu}_x(S) = 1\\)이고, \\(\\#(S) = 2\\)이니까 \\(\\tilde{\\mu}_x, \\#(S)\\)는 finite msr가 된다. 따라서 \\(\\sigma\\)-finite msr 이다.\n\n\n\\(\\tilde{\\mu}_X &lt;&lt; \\#\\)이 성립한다. 따라서 적당한 \\({\\cal S} - {\\cal R}^+\\) measurable function이 존재하여 라돈니코딤 도함수의 조건을 만족함을 알 수 있다.\n\n\n\\(\\forall B \\in \\cal{S} : \\#(B) = 0 \\leftrightarrow \\tilde{\\mu}_x (B) = 0\\)임을 보이면 된다.\n\\(\\cal{S} = \\{ \\emptyset, \\{0\\}, \\{1\\}, \\{0,1\\} \\}\\)이 있을때 위의 조건을 만족하는 것은 \\(\\emptyset\\) 뿐이다.\n따라서 \\(\\tilde{\\mu}_x (B) = 0\\)이 된다.\n\n\n우리가 생각하는 후보는 \\(f_X\\)인데 이것이 만약에 (1) \\({\\cal S} - {\\cal R}^+\\) 가측함수이고 (2) 라돈니코딤 도함수의 조건2을 만족한다면 \\(f_X\\)는 카운팅메져 \\(\\#\\)에 대한 \\(\\mu\\)의 거의 유일한 (w.r.t. \\(\\#\\)) 밀도함수라고 주장할 수 있다.\n\n\n1,2로 확인 \\(\\to\\) 적당한 가측함수 \\(f\\)가 존재하여 \\(\\forall B \\in {\\cal S}: \\mu(B)=\\int_B f_X d\\#\\) \\(\\dots \\star\\)을 만족하는 \\(f\\)가 거의 유일하게 존재한다.\n\n\n\\({\\cal S} - {\\cal R}^+\\) 가측함수이고 - Check\n\n\nsimple function 이기 때문에 measurable function이다.\n\\(f_X(0)=\\frac{1}{2}\\)와 \\(f_X(1)=\\frac{1}{2}\\)는 모두 \\(\\frac{1}{2}\\)로 하나로만 나타나니까 simple function으로 표현 가능\n\n\n라돈니코딤 도함수의 조건3 Check\n\n\n\\(B = \\emptyset\\) : LHS = 0, RHS = \\(\\int_{\\emptyset} f_X d\\#\\) = 0\n\\(B = \\{0,1\\}\\) : LHS = \\(\\mu(B) = 1\\), RHS = \\(\\int_{\\{0,1\\}} f_X d\\# = \\int_{\\{0\\}} f_X d\\# + \\int_{\\{1\\}} f_X d\\# = \\frac{1}{2} + \\frac{1}{2} = 1\\)\n\n\\(f(0) \\# \\{0\\} = \\frac{1}{2} \\times 1 = \\frac{1}{2}\\)\n\\(f(1) \\# \\{1\\} = \\frac{1}{2} \\times 1 = \\frac{1}{2}\\)\n\n\n\n\\(f_X\\)는 \\({\\cal S} \\to {\\cal R}^+\\) 가측함수이다. (simple function)\n\n\n3에서 확인 가능\n\n\n\\(\\forall B \\in {\\cal S}: \\mu(B)=\\int_B f_X d\\#=\\sum_{x \\in B} f_X(x)\\) 를 만족한다.\n\n\n3에서 확인 가능\n\n\n- 예제1에서 제안한 \\(f_X\\)의 경우 어떠한 의미에서는 밀도함수라고 해석할 수 있다.\n\n학부수준의 이해: 이산형확률변수는 확률질량함수를 가지며, 연속형확률변수는 확률밀도함수를 가진다.\n대학원수준의 이해: 이산형확률변수의 밀도함수는 \\(\\#\\)에 대한 라돈니코딤 도함수로 해석할 수 있으며, 연속형확률변수의 밀도함수는 \\(\\lambda\\)에 대한 라돈니코딤 도함수로 해석할 수 있다.\n\n- 찝찝한점1: 예제1에서는 왜 \\(\\mu_X\\) 대신에 \\(\\tilde{\\mu}_X\\)를 사용했을까?\n사실 예제1에서의 \\(\\tilde{\\mu}_X\\)는 \\(F_X\\)에 대응하는 distribution \\(\\mu_X\\)와 유사하지만 미세한 차이가 있음\n\\(\\mu_X:{\\cal R} \\to [0,1]\\)\n\n\\(\\mu_X(\\emptyset)=0\\)\n\\(\\mu_X(\\{0\\})=\\frac{1}{2}\\)\n\\(\\mu_X(\\{1\\})=\\frac{1}{2}\\)\n\\(\\mu_X(\\{0,1\\})=1\\)\n\\(\\mu_X(B)=0\\) , \\(B \\in {\\cal R} - \\{0,1\\} - \\{0\\} - \\{1\\}\\)\n\n\\(\\tilde{\\mu}_X:{\\cal S} \\to [0,1]\\)\n\n\\(\\tilde{\\mu}_X(\\emptyset)= 0\\)\n\\(\\tilde{\\mu}_X(\\{0\\})= \\frac{1}{2}\\)\n\\(\\tilde{\\mu}_X(\\{1\\})= \\frac{1}{2}\\)\n\\(\\tilde{\\mu}_X(\\{0,1\\})= 1\\)\n\n- 찝찝한점2: 예제1에서는 왜 \\((\\mathbb{R},{\\cal R})\\)를 고려하지 않고 \\((S,{\\cal S})\\)를 고려하였을까?\n\n이건 사실 \\(\\mu_X\\)대신 \\(\\tilde{\\mu}_X\\)를 쓴 이유와 연관이 있다. \\(\\mu_X\\)는 \\({\\cal R}\\)에서 정의되고 \\(\\tilde{\\mu}_X\\)는 \\({\\cal S}\\)에서 정의되는데 예제에서는 \\(\\mu_X\\)대신 \\(\\tilde{\\mu}_X\\)를 썻기 때문에 자연스럽게 \\((\\mathbb{R}, {\\cal R})\\) 대신에 \\((S,{\\cal S})\\)를 고려하게 되는 것\n\n- 찝찝한점의 해결:\n\n라돈니코딤 도함수의 존재에 필요한 조건 중 하나는 라돈니코딤 도함수를 정의하는 두개의 메져4 \\(\\sigma\\)-finite measure이어야 한다는 것임.\n\\(\\mu_X,\\lambda\\) on \\((\\mathbb{R},{\\cal R})\\)을 고려 \\(\\Rightarrow\\) \\(\\mu_X,\\lambda\\) 은 모두 \\((\\mathbb{R},{\\cal R})\\)에서 \\(\\sigma\\)-finite 조건을 만족함.\n\\(\\tilde{\\mu}_X,\\#\\) on \\((S,{\\cal S})\\)을 고려 \\(\\Rightarrow\\) \\(\\tilde{\\mu}_X,\\#\\) 은 모두 \\((S,{\\cal S})\\)에서 \\(\\sigma\\)-finite 조건을 만족함.\n\\(\\mu_X, \\#\\) on \\((\\mathbb{R},{\\cal R})\\)을 고려 \\(\\Rightarrow\\) \\(\\mu_X\\) 는 \\((\\mathbb{R},{\\cal R})\\)에서 \\(\\sigma\\)-finite 하지만 \\(\\#\\)는 \\((\\mathbb{R},{\\cal R})\\)에서 \\(\\sigma\\)-finite 하지 않음.\n\n따라서, \\((\\mathbb{R},{\\cal R})\\)에서의 두 메져 \\(\\mu_X,\\lambda\\)를 고려하거나, \\((S,{\\cal S})\\)에서의 두 메져 \\(\\tilde{\\mu}_X,\\#\\) 를 고려해야 라돈니코딤 도함수를 따져볼 수 있다.\n모티브: 그런데 \\((S,{\\cal S})\\) 말고 그냥 \\((\\mathbb{R},{\\cal R})\\)에서 적당히 \\(\\mu_X, \\tilde{\\#}\\)를 고려할 수는 없을까?\n\n\n서연 필기\n\n의문: \\(\\tilde{\\mu}_X\\)대신 \\(\\mu_X\\)를 고려한다면?\n\\(\\mu_X,\\lambda\\) on \\((\\mathbb{R},{\\cal R})\\) 에서 \\(\\mu_X,\\lambda\\)가 \\(\\sigma\\)-finite 하다면,\n\\(\\rightarrow\\) \\(\\frac{d\\mu_x}{d\\lambda} = pdf\\)(연속형 확률변수의)의 일반화된 버전\n\\(\\tilde{\\mu}_X,\\#\\) on \\((S,{\\cal S})\\) 에서 \\(\\tilde{\\mu}_X,\\#\\)가 \\(\\sigma\\)-finite 하다면,\n\\(\\rightarrow\\) \\(\\frac{d \\tilde{\\mu}_x}{d\\#} = pmf\\) 로 쓸 수 있지만, 이렇게 쓰지 말고 아래처럼 쓰고 싶다.\n\\(\\mu_X, \\#\\)5 on \\((\\mathbb{R},{\\cal R})\\) 에서 \\(\\mu_X, \\#\\)가 \\(\\sigma\\)-finite 하다면,\n\\(\\rightarrow\\) \\(\\frac{d\\mu_x}{d \\#} = pmf\\)\n\\(\\rightarrow\\) 하지만, \\(\\#(\\mathbb{R}) = \\infty\\)이므로 finite 하지 않고 \\(\\sigma\\)-finite 하지 않다.\n\\(\\star\\) \\(\\sigma\\)-finite의 조건\n\n\\(\\lambda\\)가 \\((\\mathbb{R},\\cal{R})\\)에서 \\(\\sigma\\)-finite하는지 확인\n\\(\\lambda\\) is \\(\\sigma\\)-finite msr on \\((\\mathbb{R},\\cal{R})\\)인지 보이기.\n\\(\\leftrightarrow\\) \\(A_1,A_2, \\dots\\), st (1) \\(\\cup^\\infty_{n=1} A_n = \\cal{R}\\) & (2) $ (A_n) &lt; , n $를 만족해야 한다.\n\\(A_n = (-n,n)\\)의 열린 구간으로 보면,\n\n\n\\(\\cup^\\infty_{n=1} A_n = \\cal{R}\\)은 \\(\\cup^\\infty_{n=1} A_n = \\mathbb{R}\\)로 만족함을 보임.\n$ (A_n) &lt; , n $은 \\(\\lambda(A_n) = 2n &lt; \\infty \\forall n \\in \\mathbb{N}\\) 로 만족함을 보임.\n\n\\(\\rightarrow\\) 카운팅 메져 \\(\\#\\)으로 바꾼다면? \\(\\#(A_n) = \\infty\\)하여 \\((\\mathbb{R},\\cal{R})\\)에서 \\(\\sigma\\)-finite하지 않다.\n정리\n\\(\\lambda\\)는 \\((\\mathbb{R},\\cal{R})\\)에서 \\(\\sigma\\)-finite msr\n\\(\\#\\)는 \\((\\mathbb{R},\\cal{R})\\)에서 \\(\\sigma\\)-finite msr가 아님\n\\(\\#\\)는 \\((\\mathbb{N},2^{\\mathbb{R}})\\)에서 \\(\\sigma\\)-finite msr\n\n모티브: 그런데 \\((S,{\\cal S})\\) 말고 그냥 \\((\\mathbb{R},{\\cal R})\\)에서 적당히 \\(\\mu_X, \\tilde{\\#}\\)를 고려할 수는 없을까?\n- 예제2 – 베르누이 (with 디렉메져)\n아래와 같은 함수를 고려하자.\n\\[F_X(x) = \\begin{cases}\n0 & x&lt;0 \\\\\n\\frac{1}{2} & 0 \\leq  x &lt;1 \\\\\n1 & x \\geq 1\n\\end{cases}\\]\n\ndef cumulative_distribution(x):\n    if x &lt; 0:\n        return 0\n    elif 0 &lt;= x &lt; 1:\n        return 1/2\n    else:\n        return 1\n\nx = np.linspace(-1, 2, 1000)\ny = np.vectorize(cumulative_distribution)(x)\n\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('F_X(x)')\nplt.title('Cumulative Distribution Function')\nplt.grid(True)\n\n\n\n\n\\(F_X\\)에 대응하는 분포 \\(\\mu_X:{\\cal R} \\to [0,1]\\)를 고려하자.\n\n\\(\\mu_X(\\emptyset)=0\\)\n\\(\\mu_X(\\{0\\})=\\frac{1}{2}\\)\n\\(\\mu_X(\\{1\\})=\\frac{1}{2}\\)\n\\(\\mu_X(\\{0,1\\})=1\\)\n\\(\\mu_X(B)=0\\) , \\(B \\in {\\cal R} - \\{0,1\\} - \\{0\\} - \\{1\\}\\)\n\n그리고 아래와 같은 메져를 고려하라. \\(\\#_X: {\\cal R} \\to \\mathbb{N}\\) 을 고려하자.\n\n\\(\\#_X(\\emptyset)=0\\)\n\\(\\#_X(\\{0\\})=1\\)\n\\(\\#_X(\\{1\\})=1\\)\n\\(\\#_X(\\{0,1\\})=2\\)\n\\(\\#_X(B)=0\\), \\(B \\in {\\cal R}-\\{0,1\\}-\\{0\\}-\\{1\\}\\)\n\n\n\n서연 필기\n\n\\(X\\)가 각각 값이 나올 확률\n\n\\(X = 0\\) \\(wp = \\frac{1}{2}\\)\n\\(X = 1\\) \\(wp = \\frac{1}{2}\\)\n\n\\(X\\)의 support 인 경우는 1, 아닌 경우는 모두 0\n\n\\(\\#_X(\\emptyset)=0\\)\n\\(\\#_X(\\{0\\})=1\\)\n\\(\\#_X(\\{1\\})=1\\)\n\\(\\#_X(\\{0,1\\})=2\\)\n\\(\\#_X(B)=0\\), \\(B \\in {\\cal R}-\\{0,1\\}-\\{0\\}-\\{1\\}\\)\n\n즉, 4가지 경우는 \\(\\#\\)와 같고, 그 외의 case는 0으로 정의된다.\nex) \\(\\#(\\{0,1,2\\}) = 3\\)이지만 \\(\\#_X(\\{0,1,2\\}) = \\#_X(\\{0,1)\\} + \\#_X(\\{,2\\}) = 2+ 0 = 2\\)가 된다.\n\\(\\#_X(\\mathbb{R})\\)은 \\(\\sigma\\)-finite 하다.\n\n\\(\\#_X(\\{0,1\\}) + \\#_X(\\mathbb{R} - \\{0,1\\}) = 2+0 = 2\\)이므로 finite 하기 때문에 \\(\\sigma\\)-finite 하다.\n\n절대연속이기도 하다.\n\n\\(\\forall B \\in \\cal{R}\\)에 대해 \\(\\#_X(B) = \\mu_X(B)= 0\\)임을 보이면 되는데, 둘 다 0이라는 값이 나오기 때문에 절대연속 조건 만족한다.\n\n\n\n\n이때 함수 \\(\\#_X:{\\cal R} \\to \\mathbb{N}\\) 는 \\((\\mathbb{R},{\\cal R})\\) 에서의 \\(\\sigma\\)-finite 메져가 된다. 또한 \\(\\mu_X &lt;&lt; \\#_X\\) 가 성립한다.6 이제 아래의 함수 \\(f_X:\\mathbb{R} \\to \\mathbb{R}^+\\)를 고려하자.\n\\[f_X(x)=\\begin{cases}\n\\frac{1}{2} & x=0,1 \\\\\n0 & o.w.\n\\end{cases}\\]\n함수 \\(f_X\\)는 \\({\\cal R}-{\\cal R}^+\\) 가측함수이고 (simple function 이므로)\n\\[\\forall B \\in {\\cal R}: \\mu_X(B)= \\int_B fd\\#_X\\]\n를 만족한다. 따라서\n\\[f_X=\\frac{d\\mu_X}{d\\#_X}\\]\n이다. 즉 \\(f_X\\)는 \\(\\#_X\\)에 대한 \\(\\mu_X\\)의 라돈니코딤 도함수로 해석할 수 있다.\n\n\n서연 필기\n\n\\(f_X(x)=\\begin{cases} \\frac{1}{2} & x=0,1 \\\\ 0 & o.w. \\end{cases}\\) 두 경우만 있으므로 simple function 이고 따라서 measurable function이다.\n\\(\\forall B \\in {\\cal R}: \\mu_X(B)= \\int_B fd\\#_X\\)이 성립하는 예제\n\nex) \\(\\mu_X(\\{0\\}) = \\int_{\\{0\\}} f d \\#_X = f(0) \\#_X(\\{0\\}) = \\frac{1}{2} \\times 1 = \\frac{1}{2}\\)\n\\(B = (-\\infty, 0 ] \\cup [1,\\infty)\\)에 대하여 \\(\\mu_X(B) = \\int_B f d \\#_X\\)를 만족하는지 따지자.7\n\n\\(B = (-\\infty,0) \\cup \\{0\\} \\cup \\{1\\} \\cup (1,\\infty) = B_1 \\uplus\\{0\\} \\uplus \\{1\\} \\uplus B_2\\)\nLHS = \\(\\mu_X(\\{0\\} ).+ \\mu_X(\\{1\\})\\)\nRHS = \\(f(0) \\#(\\{0\\} + f(1)\\#(\\{1\\})\\)\n\n- 정의 (디렉메져): 가측공간 \\((\\mathbb{R}, {\\cal R})\\)에서 디렉메져 \\(\\delta_x\\)는\n\\[\\forall B \\in {\\cal R}: ~\\delta_{x}(B)=\\mathbb{1}_B(x)=\\mathbb{1}(x \\in B)\\]\n로 정의되는 메져이다.\n- 디랙메져의 표현법에 따르면 예제2의 경우 \\(\\#_X := \\delta_0 + \\delta_1\\) 로 표현할 수 있다. 여기에서 \\(\\delta_x\\)는 \\((\\mathbb{R},{\\cal R})\\)에서의 디랙메져이다.\n- 꼭 베르누이와 같은 상황이 아니라도 임의의 이산확률변수 \\(X\\)에 대한 분포 \\(\\mu_X\\)를 dominating하는 적절한 \\(\\sigma\\)-finite한 메져 \\(\\#_X\\)를 \\((\\mathbb{R}, {\\cal R})\\)에서 정의할 수 있다. 예를들면 주사위예제의 경우\n\\[\\#_X = \\delta_1+\\delta_2+\\delta_3+\\delta_4+\\delta_5+\\delta_6\\]\n와 같은 방식으로 정의할 수 있다. 즉 임의의 이산확률변수 \\(X\\)에 대하여 아래를 만족하는 \\(\\#_X\\)를 항상 잡을 수 있다.\n\n\\(\\#_X\\) is \\(\\sigma\\)-finite\n\\(\\mu_X &lt;&lt; \\#_X\\)\n\n따라서 \\(\\frac{d\\mu_X}{d\\#_X}\\)는 언제나 잘 정의되며 이는 우리가 알고 있는 pmf의 정의와 일치한다.\n\n\n서연 필기\n\n디렉메져, \\(\\cal{S}_x(B) \\to 0,1\\)\n\n\\(x\\in B\\) \\(\\rightarrow 1\\)\n\\(x\\notin B\\) \\(\\rightarrow 0\\)\n\n\\(\\delta_0(\\{0\\}) = 1\\), 0이 포함되니까 1\n\\(\\delta_0(\\{1\\}) = 0\\), 0이 포함되지 않으니까 0\n\\(\\delta_0([0,1]) = 1\\), 0이 포함되니까 1\n\\(\\delta_0((0,1)) = 0\\), 0이 포함되지 않으니까 0\n\n\n따라서 위의 \\(\\#_X\\)를 디렉메져로 정의한다면, \\(\\#_X: \\delta_0 + \\delta_1\\)\n\n\\((\\delta_0 + \\delta_1)(\\{0,1\\}) = \\delta_0 (\\{0,1\\}) + \\delta_1(\\{0,1\\}) = 1+1=2\\)\n\n\n- 결국 이산형 확률변수의 밀도함수를 설명하는 방법은 크게 3가지가 있는 셈이다.\n\n이산형확률변수는 밀도함수가 없다.\n이산형확률변수의 밀도함수는 \\(\\frac{d}{d\\#}\\tilde{\\mu}_X\\) 으로 정의할 수 있다.\n이산형확률변수의 밀도함수는 \\(\\frac{d}{d\\#_X}\\mu_X\\) 으로 정의할 수 있다.\n\n설명1,2,3은 각각의 장단점이 있다.\n설명1: 라돈니코딤 도함수에 대한 이해가 없어도 된다는 점에서 장점이 있다. (그래서 학부수준에서는 가장 일반적으로 사용하는 설명)\n설명2: 연속형은 르벡메져에 대한 라돈니코딤 도함수, 이산형은 카운팅메져에 대한 라돈니코딤 도함수로 구분하여 설명할 수 있다는 점에서는 클리어하지만 분포함수 \\(\\mu_X\\)를 활용하지 못한다는 점과 그에 따라서 이산형 확률변수의 support \\(S\\)에 맞추어 가측공간 \\((S,{\\cal S})\\)를 재설정해야한다는 불편함이 있다. 이러한 방식으로 유도되는 베르누이 분포의 pmf는 아래와 같이 정의된다.\n\n\\(f_X(x)=p_X(x)=\\begin{cases} 1-p & x=0 \\\\ p & x=1 \\end{cases}\\)\n\n설명3: 연속형은 르벡메져에 대한 라돈니코딤 도함수, 이산형은 카운팅메져에 대한 라돈니코딤 도함수로 구분하여 설명할 수는 없으며 확률변수 \\(X\\)에 따라서 \\(\\#_X\\)를 그때 그때 정의해야하는 지저분함이 있다. 하지만 분포함수 \\(\\mu_X\\)를 활용할 수 있고 가측공간 \\((\\mathbb{R},{\\cal R})\\)를 그대로 활용한다는 장점이 있다. 이러한 방식으로 유도되는 베르누이분포의 pmf는 아래와 같이 정의된다.\n\n\\(f_X(x)=p_X(x)=\\begin{cases} 1-p & x=0 \\\\ p & x=1 \\\\ 0 & o.w. \\end{cases}\\)\n\n\n여기에서 \\(p_X(x)\\)는 학부때 배우는 pmf\n\n\n\n서연 필기\n\n\n이산형확률변수는 밀도함수가 없다.\n\n\n\\(\\mu_X &lt;&lt; \\lambda\\) \\(\\mu_X\\)가 르벡메져에 대해 \\(X\\)에 대해 연속이 아니기 때문에 밀도함수가 없다.\n\n\n이산형확률변수의 밀도함수는 \\(\\frac{d}{d\\#}\\tilde{\\mu}_X\\) 으로 정의할 수 있다.\n\n\n꼭 르벡메져로 볼 필요 없음\n카운팅 msr로 보고 \\(\\tilde{\\mu}_X\\)로 보겠다.\n카운팅 msr를 수정하지 않고 그대로 쓸 수 있다는 장점\n\\(\\mu_X\\) 대신 \\(\\tilde{\\mu}\\) 써야 한다는 단점\n\\(\\frac{d \\tilde{\\mu}_X}{d \\#_X}\\)가 모두 \\((\\mathbb{S},\\cal{S}\\)에서 정의되기 때문에 support를 실수 전체로 잡을 필요가 없다.\n\n\n이산형확률변수의 밀도함수는 \\(\\frac{d}{d\\#_X}\\mu_X\\) 으로 정의할 수 있다.\n\n\n카운팅 msr로 보고 \\(\\mu_X\\)로 보겠다.\n\\(\\mu_X\\) 그대로 쓴다는 장점\n카운팅 msr를 수정해야 한다는 단점\n\\(\\frac{d \\mu_X}{d \\#_X}\\)가 모두 \\((\\mathbb{R},\\cal{R}\\)에서 정의되기 때문에 support를 실수 전체로 잡아야 한다."
  },
  {
    "objectID": "posts/ap/2023-06-06-ap-14wk.html#혼합형확률변수",
    "href": "posts/ap/2023-06-06-ap-14wk.html#혼합형확률변수",
    "title": "14wk: 이산형과 연속형의 통합",
    "section": "혼합형확률변수",
    "text": "혼합형확률변수\n- 예제1: 아래와 같은 분포함수 \\(F_X\\)를 고려하자.\n\\[F_X(x) = \\begin{cases} 0 & x&lt; 0 \\\\ \\frac{1}{2} & 0 \\leq x &lt; \\frac{1}{2} \\\\ x & \\frac{1}{2} \\leq x \\leq 1 \\\\ 1 & x&gt;1  \\end{cases}\\]\n\ndef cumulative_distribution(x):\n    result = []\n    for val in x:\n        if val &lt; 0:\n            result.append(0)\n        elif 0 &lt;= val &lt; 1/2:\n            result.append(1/2)\n        elif 1/2 &lt;= val &lt;= 1:\n            result.append(val)\n        else:\n            result.append(1)\n    return result\n\nx = np.linspace(-1, 2, 1000)\ny = cumulative_distribution(x)\n\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('F_X(x)')\nplt.title('Cumulative Distribution Function')\nplt.grid(True)\n\n\n\n\n이 분포함수는 동전을 던져 앞면이 나오면 \\(X=0\\)으로 결정하고 뒷면이 나오면 균등분포 \\([0.5,1]\\)에서 확률변수 \\(X\\)를 생성하는 실험을 상상하면 쉽게 이해할 수 있다. 아래와 같은 함수\n\\[f_X(x) = \\begin{cases} \\frac{1}{2} & x=0 \\\\ 1 & \\frac{1}{2} \\leq x \\leq 1 \\\\ 0 & o.w. \\end{cases}\\]\n가 \\(F_X\\)의 밀도함수가 될 수 있음을 설명하라.\n(해설)\n\n\\(\\nu:= \\lambda + \\delta_0\\) 이라고 정의하자.\n\\(\\nu\\)는 \\(\\sigma\\)-finite 하며 \\(\\mu_X &lt;&lt; \\nu\\) 를 만족한다.\n함수 \\(f_X(x)\\)는 가측함수이며 (simple function) \\(\\forall B \\in {\\cal R}\\)에 대하여 아래를 만족한다.\n\n\\[\\mu_X(B)=\\int_B f_X d\\nu =\\int_B f_X d(\\lambda+\\delta_0)=\\int_B f_X d\\lambda + \\int_B f_X d\\delta_0\\]\n\n\\(B = (-\\infty,x]\\)와 같은 꼴에서만 성립함을 보이고 나머지는 \\(\\pi\\)-\\(\\lambda\\) thm 쓰면 되죠?\n\n\n\n서연 필기\n\n\n\\(\\nu:= \\lambda + \\delta_0\\) 이라고 정의하자.\n\n\\(\\nu:= \\lambda + \\delta_0\\)의 의미 \\(\\rightarrow\\) \\(\\forall B \\in \\cal{R}\\): \\(\\nu(B) = \\lambda(B) + \\delta_0(B)\\)이렇게 더할 것이다는 뜻\n\n\\(\\nu\\)는 \\(\\sigma\\)-finite 하며 \\(\\mu_X &lt;&lt; \\nu\\) 를 만족한다.\n\n\n\\(\\lambda\\)가 finite하고, \\(\\delta_0\\)가 \\(\\sigma\\)-finite 하여 \\(\\nu\\)도 \\(\\sigma\\)-finite 할 것이다.\n\\(\\nu\\) is \\(\\sigma\\)-finite on \\((\\mathbb{R},\\cal{R})\\)\n\npf. \\(A_n = (-n,n)\\) open range로 잡으면, \\(\\nu(A_n) = \\lambda(A_n) + \\delta(A_n) = 2n+1\\)8\n\\(\\because \\forall n \\in \\mathbb{N}\\) \\(\\nu(A_n) = 2n + 1 &lt; \\infty\\)\n그리고 \\(\\cup^\\infty_{n=1} A_n = \\mathbb{R}\\) 따라서 \\(\\sigma\\)-finite 하다.\n\\(\\nu(B) = 0 \\leftrightarrow \\mu_X(B) = 0\\)으로 절대연속임을 보이자.\n\\((\\lambda + \\delta_0) (B) = 0\\)9\n\\(\\lambda(B) + \\delta_0(B) = 0\\)10\n따라서 \\(\\lambda(B) = 0\\) & \\(\\delta_0(B) = 0\\)\n\\(\\mu_X(B) = \\mu_X(B - \\{0\\})\\)11 \\(+ \\mu_X(\\{0\\})\\)12 \\(= 0 + 0 = 0\\)\n\n함수 \\(f_X(x)\\)는 가측함수이며 (simple function) \\(\\forall B \\in {\\cal R}\\)에 대하여 아래를 만족한다.\n\n\nsimple function 이기 때문에 가측함수\n모든 구간에서 증명이 어려워 특정 집합 \\(B = (-\\infty,x]\\)에서 증명 후 \\(\\pi-\\lambda\\)-system 사용하여 증명\n\n\\(B = (-\\infty,x]\\),\n\\(\\mu_X(B) = F_X(x)\\)가 됨.\n\n\\(x&lt;0, \\mu_X(B) = F_X(x) = 0\\)\n\n\\(\\mu_X(B) = 0\\)\n\\(\\int_B f_X d\\lambda + \\int_B f_X d\\delta_0=0\\)\n\\(\\rightarrow\\) 성립\n\n\\(x=0, F_X(X) = \\frac{1}{2}\\)\n\n\\(\\mu_X(B) =F_X(X)= \\frac{1}{2}\\)\n\\(\\int_{-\\infty}^0 f_X d\\lambda + \\int_{-\\infty}^0 f_X d\\delta_0 = 0 + \\int_{\\{0\\}} f_X d \\delta_0 = f_X(0) \\delta_0(\\{0\\}) = \\frac{1}{2} \\times 1 = \\frac{1}{2}\\)\n\\(\\rightarrow\\) 성립\n\n\\(0&lt;x&lt;\\frac{1}{2}\\) , \\(F_X(X)= \\frac{1}{2}\\)\n\n\\(\\mu_X(B) = F_X(X) = \\frac{1}{2}\\)\n\\(\\int_{-\\infty}^x f_X d\\lambda\\)13 \\(+ \\int_{-\\infty}^x f_X d\\delta_0 = 0 + \\int_{\\{0\\}}^x f_X d\\delta_0 = f_X(0) \\delta_X(\\{0\\}) = \\frac{1}{2} \\times 1 = \\frac{1}{2}\\)\n\\(\\rightarrow\\) 성립\n\n\\(\\frac{1}{2} \\le x \\le 1\\) \\(F_X(x) = x\\)\n\n\\(\\mu_X(B) = F_X(x) = x\\)\n\\(\\int_{-\\infty}^x f_X d\\lambda + \\int_{-\\infty} f_X d\\delta_0 = \\int_{-\\infty}^x f_X d\\lambda + \\frac{1}{2} = \\int_{\\frac{1}{2}}^1 1 dx + \\frac{1}{2} = x - \\frac{1}{2} + \\frac{1}{2}\\)14\n\\(\\rightarrow\\) 성립\n\n\\(x&gt;1\\) \\(F_X(x) = \\mu_X(x) = 1\\)\n\n\\(\\mu_X(B) = F_X(x) = 1\\)\n\\(\\int_{-\\infty}^x f_X d\\lambda + \\int_{-\\infty}^x f_X d\\delta_0 = \\int_{\\frac{1}{2}}^1 1 dx + \\frac{1}{2} = \\frac{1}{2}+ \\frac{1}{2}\\)\n\n\n\n\n\n\n\n위의 3에 대한 추가설명.\n\n\n\n결국 임의의 \\(B=(-\\infty,x]\\)와 같은 꼴에서 \\(\\mu_X(B) = \\int_Bf_Xd\\lambda + \\int_B f_Xd\\delta_0\\) 임을 보이면 된다.\n편의상 아래와 같이 정의하자.\n\n\\(LHS = \\mu_X(B)\\)\n\\(RHS_1 = \\int_B f_Xd\\lambda\\)\n\\(RHS_2 = \\int_B f_Xd\\delta_0\\)\n\ncase1: \\(x &lt; 0\\)\n\n\\(LHS = F_X(x)=0\\)\n\\(RHS_1 = 0\\)\n\\(RHS_2 = 0\\)\n\ncase2: \\(x = 0\\)\n\n\\(LHS = F_X(x)=\\frac{1}{2}\\)\n\\(RHS_1 = \\int_{-\\infty}^0f_X(x)dx = 0\\)\n\\(RHS_2 = \\int_{\\{0\\}}f_Xd\\delta_0 = f_X(0)\\delta_0(\\{0\\}) = \\frac{1}{2}\\)\n\ncase3: \\(0&lt;x&lt; \\frac{1}{2}\\)\n\n\\(LHS = F_X(x)=\\frac{1}{2}\\)\n\\(RHS_1 = \\int_{-\\infty}^{0}f_X(x)dx+ \\int_{0}^{x}f_X(x)dx= 0\\)\n\\(RHS_2 = \\int_{\\{0\\}}f_Xd\\delta_0 = f_X(0)\\delta_0(\\{0\\}) = \\frac{1}{2}\\)\n\ncase4: \\(\\frac{1}{2}&lt;x&lt; 1\\)\n\n\\(LHS = F_X(x)=x\\)\n\\(RHS_1 =\\int_{-\\infty}^{1/2}f_X(x)dx+ \\int_{1/2}^xf_X(x)dx = \\int_{1/2}^xf_X(x)dx=\\int_{1/2}^xdx= x-\\frac{1}{2}\\)\n\\(RHS_2 = \\int_{\\{0\\}}f_Xd\\delta_0 = f_X(0)\\delta_0(\\{0\\}) = \\frac{1}{2}\\)\n\ncase5: \\(x&gt;1\\)\n\n\\(LHS = F_X(x)=1\\)\n\\(RHS_1 =\\int_{-\\infty}^{1/2}f_X(x)dx+ \\int_{1/2}^{1}f_X(x)dx = \\int_{1/2}^1f_X(x)dx=\\int_{1/2}^1dx= 1-\\frac{1}{2}\\)\n\\(RHS_2 = \\int_{\\{0\\}}f_Xd\\delta_0 = f_X(0)\\delta_0(\\{0\\}) = \\frac{1}{2}\\)"
  },
  {
    "objectID": "posts/ap/2023-05-30-ap-13wk.html",
    "href": "posts/ap/2023-05-30-ap-13wk.html",
    "title": "13wk: 밀도함수",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/ap/2023-05-30-ap-13wk.html#정의",
    "href": "posts/ap/2023-05-30-ap-13wk.html#정의",
    "title": "13wk: 밀도함수",
    "section": "정의",
    "text": "정의\n- 아래의 집합열 \\(C_n\\)의 극한 \\({\\cal C}=\\lim_{n\\to\\infty} C_n\\)를 생각하자.\n실제수열\n\n\\(C_0=[0,1]\\)\n\\(C_1=[0,\\frac{1}{3}] \\cup [\\frac{2}{3},1]\\)\n\\(C_2=\\big([0,\\frac{1}{9}]\\cup[\\frac{2}{9},\\frac{1}{3}] \\big) \\cup \\big([\\frac{2}{3},\\frac{7}{9}]\\cup [\\frac{8}{9},1] \\big)\\)\n\\(\\dots\\)\n\n언어버전: created by iteratively deleting the open middle third from a set of line segments.\n\n\\(C_0\\): \\([0,1]\\)\n\\(C_1\\): \\(C_0\\)에서 정의된 line을 3등분한뒤 가운데를 제거\n\\(C_2\\): \\(C_1\\)에서 정의된 line segments를 각각 3등분한뒤 각각 가운데를 제거\n\\(\\dots\\)\n\n수식버전\n\n\\(C_0=[0,1]\\)\n\\(C_1=\\frac{C_{0}}{3}\\cup(\\frac{2}{3}+\\frac{C_{0}}{3})\\)\n\\(C_2=\\frac{C_{1}}{3}\\cup(\\frac{2}{3}+\\frac{C_{1}}{3})\\)\n\\(\\dots\\)\n\\(C_n=\\frac{C_{n-1}}{3}\\cup(\\frac{2}{3}+\\frac{C_{n-1}}{3})\\)\n\n단, 여기에서\n\n\\(\\frac{1}{3}[a,b]= [\\frac{a}{3},\\frac{b}{3}]\\)\n\\(\\frac{2}{3}+[a,b]= [\\frac{2}{3}+a,\\frac{2}{3}+b]\\)\n\n와 같이 정의한다.\n그림버전\n\n\n\n그림1: 칸토어 집합"
  },
  {
    "objectID": "posts/ap/2023-05-30-ap-13wk.html#성질",
    "href": "posts/ap/2023-05-30-ap-13wk.html#성질",
    "title": "13wk: 밀도함수",
    "section": "성질",
    "text": "성질\n- 3진법의 표기: 칸토어 집합의 원소는 \\([0,1]\\)사이의 원소를 삼진법으로 표현할때 모든 자리수가 0 또는 2가 되는 수만 모은 집합이다.\n\n\\([0,1]\\) 사이의 모든 실수를 3진법을 표현한다고 생각하자.\n\\(C_1\\)은 \\(0.1xxxx\\dots_{3}\\)와 같은 숫자가 빠지고, \\(C_2\\)에서는 \\(0.01xxx\\dots_{3}\\) 혹은 \\(0.21xxx\\dots_{3}\\) 에 대응하는 숫자가 빠지는 과정이 반복적으로 일어난다고 볼 수 있다.\n2의 결과를 잘 생각하면 칸토어 집합에 포함되는 수는 삼전법 소수로 표기했을 때 모든 자리수가 0 또는 2가 된다는 점을 쉽게 눈치챌 수 있다.\n\n- 카디널리티: 칸토어 집합의 카디널리티는 구간 \\([0,1]\\)의 카디널리티와 같다. 즉 \\(2^{\\aleph_0}\\) 이다.\n\n\\(y\\in [0,1]\\) 사이의 모든 실수는 임의의 2진수로 표현할 수 있다.\n예를들어 \\(y=\\frac{3}{5}=0.100110011001..._{2}\\)와 같이 표현할 수 있다.\n만약에 2의 결과에서 \\(1\\)을 모두 \\(2\\)로 바꾸어 3진법수를 만들면 \\(0.200220022002..._{3}=\\frac{7}{10}\\)와 같이 쓸 수 있는데, 이는 칸토르 집합의 원소가 된다.\n3을 2의 출력으로 바꾸는 과정을 수행하는 함수 \\(f\\)를 정의하자. 즉 이 예제의 경우 \\(f(\\frac{7}{10})=\\frac{3}{5}\\).\n\\(f\\)는 전사함수이므로 \\({\\sf card}([0,1]) \\leq {\\sf card}({\\cal C})\\).\n\n- 잴 수 있는 집합: \\({\\cal C} \\in {\\cal R}\\)\n\n\\(C_0,C_1,C_2\\dots \\in {\\cal R}\\)\n\\({\\cal C} = \\lim_{n\\to \\infty} C_n = \\cap_{n=0}^{\\infty} C_n\\) (\\(C_0,C_1,C_2,\\dots\\) 이 감소하는 집합열임을 이용)\n시그마필드 \\({\\cal R}\\)은 countable intersection에 닫혀있으므로 \\({\\cal C} \\in {\\cal R}\\)\n\n- 르벡측도값(길이): \\(\\lambda({\\cal C})=0\\)이다. 여기에서 \\(\\lambda\\)은 르벡측도이다. 즉 칸토어집합의 길이는 0이다.\n\n칸토어 집합을 만드는 과정에서 제외되는 집합의 길이는 순서대로 \\(\\frac{1}{3}, \\frac{2}{9}, \\frac{4}{27} \\dots\\) 이다.\n이것은 첫째항이 \\(\\frac{1}{3}\\)이고 공비가 \\(\\frac{2}{3}\\)인 등비수열이므로 무한등비급수의 합을 이용하면 제외되는 길이의 합은 \\(1\\)이 됨을 계산할 수 있다.\n\n- 굉장히 오래전에 만들었던 표\n\n\n\n집합\n카디널리티\n분류\n르벡메져\n\n\n\n\n\\(\\{1,2,3\\}\\)\n3\n가산집합\n0\n\n\n\\(\\mathbb{N}\\)\n\\(\\aleph_0\\)\n가산집합\n0\n\n\n\\(\\mathbb{Z}\\)\n\\(\\aleph_0\\)\n가산집합\n0\n\n\n\\(\\mathbb{Q}\\)\n\\(\\aleph_0\\)\n가산집합\n0\n\n\n\\([0,1]\\)\n\\(2^{\\aleph_0}\\)\n비가산집합\n1\n\n\n\\([0,1]\\cap \\mathbb{Q}\\)\n\\(\\aleph_0\\)\n가산집합\n0\n\n\n\\([0,1]\\cup \\mathbb{Q}\\)\n\\(2^{\\aleph_0}\\)\n비가산집합\n1\n\n\n\\([0,1]\\cap \\mathbb{Q}^c\\)\n\\(2^{\\aleph_0}\\)\n비가산집합\n1\n\n\n\\([0,\\infty)\\)\n\\(2^{\\aleph_0}\\)\n비가산집합\n\\(\\infty\\)\n\n\n비탈리집합\n\\(2^{\\aleph_0}\\)\n비가산집합\nNA\n\n\n칸토어집합\n\\(2^{\\aleph_0}\\)\n비가산집합\n0\n\n\n\n\n\n\n\n\n\n강의설명 오류 정정\n\n\n\n이부분의 설명에서 제가 “가산집합이면 대부분 르벡메져가 0이다” 라는 식으로 설명했는데요, 이는 잘못된 설명입니다. 대부분의 가산집합이 르벡메져가 0이 아니고 “모든 가산집합은 무조건 르벡메져가 0입니다.” 왜냐하면 임의의 가산집합 \\(A\\)는 아래와 같이 한점의 집합의 countable union으로\n\\[A = \\cup_{i=1}^{\\infty} \\{a_i\\}\\]\n으로 표현가능한데요, 여기에 르벡메져를 취하면\n\\[\\lambda(A) = \\lambda\\big(\\cup_{i=1}^{\\infty} \\{a_i\\}\\big)=\\sum_{i=1}^{\\infty}\\lambda( \\{a_i\\})=0\\]\n와 같이 됩니다. 두번째 등호는 메져의 정의 (\\(\\sigma\\)-additivity) 에 의하여 성립합니다. 강의오류에 발견에 도움을 준 김보람학생 감사합니다."
  },
  {
    "objectID": "posts/ap/2023-05-30-ap-13wk.html#정의-1",
    "href": "posts/ap/2023-05-30-ap-13wk.html#정의-1",
    "title": "13wk: 밀도함수",
    "section": "정의",
    "text": "정의\n- (정의) \\(X\\)를 확률공간 \\((\\Omega, {\\cal F}, P)\\)에서 정의된 확률변수라고 하고 \\(F_X\\)를 \\(X\\)의 분포함수 라고 하자. 만약에 \\(F_X\\)가 아래와 같은 방식으로 표현된다면 \\(f_X\\)를 \\(X\\)를 밀도함수 (density function) 이라고 한다.\n\\[F_X(x)=\\int_{-\\infty}^xf_X(y)dy\\]\n- 저런 표현이 존재하지 않는다면 어쩌지?\n\n\\(F_X(x)\\)가 불연속인 경우: 미분 불가능\n\\(F_X(x)\\)가 연속인 경우: 미분가능할 수도 있고, 아닐 수도 있고"
  },
  {
    "objectID": "posts/ap/2023-05-30-ap-13wk.html#다양한-밀도함수-예시",
    "href": "posts/ap/2023-05-30-ap-13wk.html#다양한-밀도함수-예시",
    "title": "13wk: 밀도함수",
    "section": "다양한 밀도함수 예시",
    "text": "다양한 밀도함수 예시\n- 교양: 함수 \\(F_X(x)\\)가 연속인 경우는 연속확률변수 \\(X\\)의 분포함수 (distribution fucntion) 혹은 CDF라고 하고 함수 \\(F_X(x)\\)가 jump만 존재하는 불연속인 경우는 이산확률변수의 분포함수 (distribution function) 혹은 CDF라고 한다.\n(예제1) – 균등분포\n아래와 같은 distribution function \\(F_X\\)을 가지는 확률변수 \\(X\\)를 고려하자.\n\\[F_X(x) = \\begin{cases} 0 & x&lt;0\\\\ x & 0\\leq x \\leq 1 \\\\ 1 & 1&lt;x\\end{cases}\\]\n이러한 함수 \\(F_X\\)의 density가 존재하는가?\n체크: 일단 \\(F_x(x)\\)는 (1) 비감소하며 (2) \\(\\lim_{x\\to -\\infty}F_X(x) = F_X(0) = 0\\), \\(\\lim_{x\\to \\infty}F_X(x) = F_X(1) = 1\\) (3) 오른쪽연속 (그냥 연속임) 이므로 분포함수의 정의를 만족한다. 따라서 \\(F_X(x)\\)에 대응하는 확률변수 \\(X\\)가 있다.\n(해설)\n\n대충 생각하면 (진짜 말 그대로 대충) 아래와 같이 생각할 수 있다.\n\n\\[f_X(x) = \\frac{d}{dx}F_x(x)\\]\n\n즉 \\(f_X(x)\\)는 \\(F_x(x)\\)의 도함수 같은 것으로 생각할 수 있다.\n문제는 \\(F_X(x)\\)는 연속이지만 \\(x=0\\)과 \\(x=1\\)에서 미분가능하지는 않다는 점이다.\n그래서 \\(F_X(x)\\)는 미분가능하지 않다.\n하지만 미분가능의 개념을 “함수”에 적용하는 것이 아니라 “하나의 포인트”에 적용한다면 어떨까?\n\\(F_X(x)\\)는 \\(x=0\\)과 \\(x=1\\)을 제외한 모든 점에서 미분가능하며 그 도함수는 대략적으로 아래와 같이 표현할 수 있다.\n\n\\[f_X(x) = \\begin{cases} 0 & x&lt;0 \\\\ ?? & x=0 \\\\ 1 & 0&lt;x&lt;1 \\\\ ?? & x=1 \\\\ 0 & 1&lt;x \\end{cases}\\]\n\n어차피 유한개의 점을 제외하여도 적분값에 영향이 없으므로 ??의 값은 아무값이나 넣어도 상관없다. 편의상 아래와 같은 \\(f_X(x)\\)를 고려하자.\n\n\\[f_X(x) = \\begin{cases}  1 & 0\\leq x \\leq 1 \\\\ 0 & o.w. \\end{cases}\\]\n\n위와 같은 \\(f_X(x)\\)에 대하여 아래식이 성립한다고 볼 수 있다. \\[F_X(x) = \\int_{-\\infty}^x f_X(y)dy\\]\n\n\n\\(F_X(x)\\)는 미분불가능하지만 또 어떠한 의미에서는 가능하다고 볼 수 도 있다.\n\n\n\n\n\n\n\n(a) 균등분포의 cdf\n\n\n\n\n\n\n\n(b) 균등분포의 pdf\n\n\n\n\n\n\n그림2: 위키에서 긁어온 균등분포의 pdf, cdf 그림. 실제로는 \\(x=0,1\\)에서 \\(F_X'(x)\\)의 값이 존재하지 않으나 편의상 정의함.\n\n\n\n(예제1의 정답에 대한 의문)\n만약에 누군가가 아래와 같은 \\(f_X(x)\\)들이 pdf라고 주장한다면?\n\n\\(f_X(x) = \\begin{cases} 1 & 0&lt; x &lt;1 \\\\ 0 & o.w. \\end{cases}\\)\n\\(f_X(x) = \\begin{cases} 1 & 0\\leq x &lt; 1 \\\\ 0 & o.w. \\end{cases}\\)\n\\(f_X(x) = \\begin{cases} 1 & 0&lt; x \\leq 1 \\\\ 0 & o.w. \\end{cases}\\)\n\n별로 상관없을듯 하다. 어차피 \\(\\lambda(\\{0\\})=\\lambda(\\{1\\})=0\\) 이므로 넓이에 영향이 없다. 위의 함수는 \\(x=0,1\\)을 제외한 모든곳에서는 함수값이 일치하므로 거의 같다고 보아도 무방하다. 즉 아래의 함수들은 거의 모든 곳에서 같다.\n\n\\(f_X(x) = \\begin{cases} 1 & 0&lt; x &lt;1 \\\\ 0 & o.w. \\end{cases}\\)\n\\(f_X(x) = \\begin{cases} 1 & 0\\leq x &lt; 1 \\\\ 0 & o.w. \\end{cases}\\)\n\\(f_X(x) = \\begin{cases} 1 & 0&lt; x \\leq 1 \\\\ 0 & o.w. \\end{cases}\\)\n\\(f_X(x) = \\begin{cases} 1 & 0\\leq x \\leq 1 \\\\ 0 & o.w. \\end{cases}\\)\n\n여기에서 두 함수 \\(f\\), \\(g\\)가 거의 모든 곳에서 같다라는 표현은\n\\[\\lambda\\big(\\{x: f(x) \\neq g(x)\\}\\big)=0\\]\n을 의미한다. 즉 함수값이 다른 집합의 르벡측도값이 0이라는 의미이다.\n(예제2) – 혼합된 균등분포\n아래와 같은 distribution function \\(F_X\\)을 가지는 확률변수 \\(X\\)를 고려하자.\n\\[F_X(x) = \\begin{cases} 0 & x&lt;0\\\\ \\frac{3}{2}x & 0\\leq x &lt; \\frac{1}{2} \\\\ \\frac{1}{2}+\\frac{1}{2}x & \\frac{1}{2}\\leq x&lt;1 \\\\ 1 & 1\\leq x\\end{cases}\\]\n이러한 함수 \\(F_X\\)의 density가 존재하는가?\n체크: 일단 \\(F_x(x)\\)는 (1) 비감소하며 (2) \\(\\lim_{x\\to -\\infty}F_X(x) = F_X(0) = 0\\), \\(\\lim_{x\\to \\infty}F_X(x) = F_X(1) = 1\\) (3) 오른쪽연속 (그냥 연속임) 이므로 분포함수의 정의를 만족한다. 따라서 \\(F_X(x)\\)에 대응하는 확률변수 \\(X\\)가 있다.\n(해설)\n함수 \\(F_X(x)\\)는 \\(x=0,\\frac{1}{2},1\\) 에서 미분불가능하지만 어차피 미분불가능한 점이 countable 하므로 여기에서는 무시하고 \\(f_X(x)\\) 값을 편의상 정의하여도 무방하다. 따라서 아래와 같은 함수 \\(f_X(x)\\)가 pdf가 될 수 있다.\n\\[f_X(x) = \\begin{cases}  \\frac{3}{2} & 0 \\leq x &lt;\\frac{1}{2} \\\\ \\frac{1}{2} & \\frac{1}{2}&lt; x &lt; 1 \\end{cases}\\]\n그 외에도 \\(x=0,\\frac{1}{2}, 1\\)에서의 함수값을 어떻게 정의하느냐에 따라서 여러개의 정답이 있을 수 있지만, 그러한 함수들은 \\(f_X(x)\\)와 거의 모든 곳에서 같은 함수이다.\n\n여기서도 \\(F_X(x)\\)는 미분불가능하지만 또 어떠한 의미에서는 가능하다고 볼 수 도 있다.\n\n- 주장: \\(F_X(x)\\)가 모든 곳에서 연속 이고 거의 모든 곳에서 미분가능하다고 가능하면 아래를 만족하는 (도함수 비스무리한) \\(f_X(x)\\)가 존재한다.\n\\[F_X(x) = \\int_{-\\infty}^{x} f_X(x) dx\\]\n이때 \\(F_X(x)\\)가 미분가능하지 않은 집합에 대하여서는 적분을 정의함에 있어서 제외하고 정의해도 무방하다.\n\n엄청 그럴듯해보이지만 칸토어함수의 존재로 인하여 이 주장은 틀렸다."
  },
  {
    "objectID": "posts/ap/2023-05-30-ap-13wk.html#칸토어함수-칸토어분포",
    "href": "posts/ap/2023-05-30-ap-13wk.html#칸토어함수-칸토어분포",
    "title": "13wk: 밀도함수",
    "section": "칸토어함수, 칸토어분포",
    "text": "칸토어함수, 칸토어분포\n- 아래와 같은 과정으로 얻어지는 함수 \\(F_0, F_1, F_2, \\dots\\)를 고려하자.\n\n\n\n그림3: 위키에서 긁어온 칸토어함수의 생성예제\n\n\n그림에서는 \\(f_0, f_1, f_2\\) 와 같이 표현하였지만 우리는 편의상 \\(F_0, F_1, F_2\\)와 같이 표현하도록 하겠다.\n- 이제 이러한 함수의 극한을 \\(F\\)라고 하자. 즉\n\\[F(x) = \\lim_{n\\to \\infty} F_n(x)\\]\n이다. 이것을 기호로 간단하기 \\(F_n \\to F\\) 와 같이 표현하기도 한다. 여기에서 \\(F_n \\to F\\)의 의미는 \\(F_n\\)의 임의의 고정된 점 \\(x^\\star\\)에 대하여 \\(F_n(x^\\star) \\to F(x^\\star)\\)라는 의미이다.\n- 함수 \\(F_n\\)의 정의역을 칸토르 집합 \\({\\cal C}\\)와 연계하여 이해하면 아래와 같은 사실을 관찰할 수 있다.\n\n\\(F_0\\)은 \\(C_0\\)에서는 양의 기울기를 가지고 \\([0,1]-C_0\\) 에서는 기울기가 0이다.\n\\(F_1\\)은 \\(C_1\\)에서는 양의 기울기를 가지고 \\([0,1]-C_1\\) 에서는 기울기가 0이다.\n\\(F_2\\)은 \\(C_2\\)에서는 양의 기울기를 가지고 \\([0,1]-C_2\\) 에서는 기울기가 0이다.\n\n따라서 아래의 사실을 유추할 수 있다.\n\n\\(F\\)는 \\({\\cal C}\\)에서는 양의 기울기를 가지고 \\([0,1]-{\\cal C}\\) 에서는 기울기가 0이다.\n\n- 함수 \\(F\\)를 칸토어 함수라고 부른다. 칸토어함수는 아래와 같은 특징이 있다.\n\n칸토어 함수는 모든 곳에서 연속이다.\n칸토어 집합의 외부 \\([0,1]-{\\cal C}\\)에서는 상수함수이다. 즉 칸토어집합의 외부에서는 기울기가 0이다. \\(m({\\cal C})=0\\) 이므로 이 함수는 거의 모든 곳에서 기울기가 0이다.\n\\(F\\)는 비감소함수이다.\n\\(F(0)=0\\) 이고 \\(F(1)=1\\)이다.\n\n- 1,3,4에 의하여 \\(F\\)는 분포함수의 정의를 만족한다. 1에 의하여 \\(F\\)는 연속형확률변수의 분포함수가 된다. 칸토어 집합의 외부에서 (그러니까 [0,1]의 거의 모든 점에서) 도함수는 \\(0\\) 이므로\n\\[\\frac{d}{dx}F(x)=f(x)=0,\\quad \\sf{a.e.}\\]\n이다. 하지만 \\(f(x)\\)는 pdf의 정의를 만족하지 않는다.\n- 요약\n\n칸토어함수 \\(F\\)는 분포함수의 정의를 만족한다. 따라서 \\(F\\)에 대응하는 확률변수 \\(X\\)가 반드시 있다.\n심지어 칸토어함수는 연속함수이므로, \\(F\\)에 대응하는 확률변수 \\(X\\)는 연속형 확률변수가 된다.\n\\(F\\)는 거의 모든 점에서 도함수가 존재하지만 그 도함수의 적분이 아니다.\n그래서 \\(X\\)의 pdf는 존재하지 않는다.\n\n\n칸토어함수는 미적분학의 기본정리 성립하지 않는 반례를 찾기 위해 고안되었다. 즉 어떠한 함수 \\(F\\)가 거의 모든 곳에서 미분가능하며, 그 도함수를 \\(f\\)가 르벡적분 가능 할지라도 \\(\\int_{-\\infty}^{x} f(y) dy= F(x)\\) 가 성립하지 않을 수 있다."
  },
  {
    "objectID": "posts/ap/2023-05-30-ap-13wk.html#절대연속",
    "href": "posts/ap/2023-05-30-ap-13wk.html#절대연속",
    "title": "13wk: 밀도함수",
    "section": "절대연속",
    "text": "절대연속\n- 모티브\n\n\\(F_X\\)의 “도함수 비슷한 함수”를 일반화 할 수 없을까? \\(\\Rightarrow\\) 라돈니코딤 도함수\n\\(F_X\\)의 1과 같이 도함수 비슷한 함수가 언제 존재하는지 조건을 알 수 있을까? \\(\\Rightarrow\\) 절대연속\n\n\n\n\n함수\n도함수\n라돈니코딤 도함수\n\n\n\n\n연속\nX\nX1\n\n\n절대연속\nX\nO\n\n\n미분가능\nO\nO\n\n\n\n\n암기: 절대연속은 연속보다 강하고, 미분가능보다 약한 조건이다.\n\n- 정의: 함수 \\(F_X(x)\\)가 분포함수의 정의를 만족한다고 가정하자.2 \\(F_X(x)\\)에 대응하는 분포 \\(\\mu_X:{\\cal R} \\to [0,1]\\)를 생각하자. \\(F_X(x)\\)가 절대연속이라는 뜻은 아래가 성립한다는 의미이다.\n\\[\\forall B \\in {\\cal R}: \\lambda(B) =0 \\Rightarrow \\mu_X(B)=0\\]\n이럴 경우 아래와 같이 표현한다.\n\nA measure \\(\\mu_X\\) is abosolutely continous with respect to Lebesgue measure \\(\\lambda\\)\n\\(\\mu_X &lt;&lt; \\lambda\\)\n\n\n\n서연 필기\n\n\\(\\mu_X((-\\infty, x]) = F_X(x)\\)\n\\((a,b] = (-\\infty,b] - (-\\infty,a] = F_X(b) - F_x(a)\\)\n\\(\\mu_X([a,b]) = F_X(b) - F_X(a)\\)\n\\(\\lambda(B)\\) = 구간 \\(B\\)의 길이\n\\(\\mu(B)\\) = 구간 \\(B\\)에 \\(F_X\\)의 차이\n\\(\\therefore \\lambda(B) =0 \\Rightarrow \\mu_X(B)=0\\)의 의미는 구간 \\(B\\) 길이가 작아질수록 \\(F_X\\)의 차이 차이도 작아야 한다는 의미\n\\(\\to\\) 위의 정의로 \\(F_X\\)가 절대 연속이다고 말할 수 있다.\n\n- 정의: 좀 더 일반적으로는 아래와 같이 정의할 수 있다. (Durrett 2019, p 470)\n가측공간 \\((\\mathbb{R},{\\cal R})\\)를 고려하고 \\(\\mu\\), \\(\\lambda\\)를 \\((\\mathbb{R},{\\cal R})\\)에서의 메져라고 하자. \\(\\mu\\)가 absolutely continuous w.r.t. \\(\\lambda\\) 라는 의미는\n\\[\\forall B \\in {\\cal R}:~ \\lambda(B) =0 \\Rightarrow \\mu(B)=0\\]\n라는 의미이며 기호로는 \\(\\mu &lt;&lt; \\lambda\\) 와 같이 나타낸다.\n\n여기에서 공간 \\((\\mathbb{R},{\\cal R})\\) 은 이해를 돕기위해서 제한한 것이며, 대부분 교재에서는 좀 더 일반적인 가측공간에서 절대연속을 정의한다.\n\n\n\n서연 필기\n\n\\(\\to\\) 위의 정의로 \\(\\mu\\)는 \\(\\lambda\\)에 대하여 \\((\\mathbb{R},{\\cal R})\\)에서 절대연속이다고 말할 수 있다.\n또는 일반적인 measurable space \\((\\mathbb{S},{\\cal S})\\)에서도 절대연속이라고 할 수 있다.\n\n- 절대연속의 예제를 살펴보기전에 필요한 예비학습\n이런게 있었거든요.. // 7주차 강의노트\n함수 \\(\\mu\\)가 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\)에서 정의된 메져라고 하자.\n\n\\(A_i \\uparrow A\\) \\(\\Rightarrow\\) \\(\\mu(\\lim_{n\\to \\infty}A_n) = \\lim_{n \\to \\infty}\\mu(A_n)\\)\n\\(A_i \\downarrow A\\) with \\(\\mu(A_1)&lt;\\infty\\) \\(\\Rightarrow\\) \\(\\mu(\\lim_{n\\to \\infty}A_n) = \\lim_{n \\to \\infty}\\mu(A_n)\\)\n감소하거나 증가하는 집합열에서는 \\(\\lim\\)을 넣거나 뺼 수 있다. (정확하지 않은 state, 그냥 기억을 위한 문장)\n\n\n\n서연 필기\n\n\n\\(A_i \\uparrow A\\) \\(\\Rightarrow\\) \\(\\mu(\\lim_{n\\to \\infty}A_n) = \\lim_{n \\to \\infty}\\mu(A_n)\\) 에 대한 설명\n\n\\(A_i \\uparrow A\\) = \\(A_1 \\subset A_2 \\subset A_3 \\subset \\dots , A_i \\in \\cal{F}\\) & \\(\\cup^\\infty_{i=1}A_i = A\\)\n이때, \\(A\\)가 증가하는 집합열이라면\n\\(A_i \\uparrow A\\) = \\(A_1 \\subset A_2 \\subset A_3 \\subset \\dots , A_i \\in \\cal{F}\\) & \\(lim_{n \\to \\infty}A_n = A\\)\n라 쓸 수 있다.\n\\(\\mu(\\lim_{n\\to \\infty}A_n) = \\lim_{n \\to \\infty}\\mu(A_n)\\)\n\\(\\to\\) \\(A_n\\)이 증가하는 집합열이므로 \\(lim_{n \\to \\infty}A_n = \\cup^\\infty_{i=1}A_i\\)이라고 쓸 수 있다.\n\\(\\mu(\\lim_{n\\to \\infty}A_n) = \\lim_{n \\to \\infty}\\mu(A_n) = \\mu(\\uplus_{n=1}^{\\infty} B_n)\\)\n\\(\\to\\) \\(A_1,A_2, \\dots \\in \\cal{F}\\)이고 \\(\\cal{F}\\)는 차집합에 반쯤 닫혀 있어서 disjoint화 가능하다.\n\\(\\mu(\\lim_{n\\to \\infty}A_n) = \\lim_{n \\to \\infty}\\mu(A_n) = \\mu(\\uplus_{n=1}^{\\infty} B_n) = \\sum^\\infty_{n=1} \\mu(B_n)\\)\n\\(\\to\\) msr의 정의인 \\(\\sigma-add\\)에 의해 가능하다.\n\\(\\mu(\\lim_{n\\to \\infty}A_n) = \\lim_{n \\to \\infty}\\mu(A_n) = \\mu(\\uplus_{n=1}^{\\infty} B_n) = \\sum^\\infty_{n=1} \\mu(B_n) = lim_{b \\to \\infty} \\sum^n_{k=1} \\mu(B_k) = lim_{n \\to \\infty} \\mu(\\uplus^n_{k=1} B_k)\\)\n\\(\\to\\) msr \\(\\sigma-add\\)에 의해 가능하다.\n\\(\\mu(\\lim_{n\\to \\infty}A_n) = \\lim_{n \\to \\infty}\\mu(A_n) = \\mu(\\uplus_{n=1}^{\\infty} B_n) = \\sum^\\infty_{n=1} \\mu(B_n) = lim_{b \\to \\infty} \\sum^n_{k=1} \\mu(B_k) = lim_{n \\to \\infty} \\mu(\\uplus^n_{k=1} B_k) = lim_{n \\to \\infty} \\mu (\\uplus^{n}_{k=1} A_k)\\)\n\\(\\to\\) \\(A_1,A_2, \\dots \\in \\cal{F}\\)이고 \\(\\cal{F}\\)는 차집합에 반쯤 닫혀 있어서 disjoint화 가능하다.\n\\(\\mu(\\lim_{n\\to \\infty}A_n) = \\lim_{n \\to \\infty}\\mu(A_n) = \\mu(\\uplus_{n=1}^{\\infty} B_n) = \\sum^\\infty_{n=1} \\mu(B_n) = lim_{b \\to \\infty} \\sum^n_{k=1} \\mu(B_k) = lim_{n \\to \\infty} \\mu(\\uplus^n_{k=1} B_k) = lim_{n \\to \\infty} \\mu (\\uplus^{n}_{k=1} A_k) = lim_{n \\to \\infty} \\mu (A_n)\\)\n\\(\\to\\) \\(A_1,A_2, \\dots\\)가 증가하는 집합열이기 때문에 가능하다.\n\n\\(A_i \\downarrow A\\) with \\(\\mu(A_1)&lt;\\infty\\) \\(\\Rightarrow\\) \\(\\mu(\\lim_{n\\to \\infty}A_n) = \\lim_{n \\to \\infty}\\mu(A_n)\\)에 대한 설명\n\n\\(A_i \\downarrow A\\) = \\(A_1 \\supset A_2 \\supset \\dots, A_i \\in \\cal{F}\\) & \\(\\cap^\\infty_{n=1} A_n = A\\)\n이때, \\(A\\)가 감소하는 집합열이라면\n\\(A_i \\downarrow A\\) = \\(A_1 \\supset A_2 \\supset \\dots, A_i \\in \\cal{F}\\) & \\(lim_{n \\to \\infty} A_n = A\\)\n\\(A_1 \\supset A_2 \\supset \\dots, A_i \\in \\cal{F}\\) & \\(\\cap^\\infty_{n=1} A_n = A\\)\n증가하는 집합열에 대해 증명했으니 같은 방법으로 보이기 위해 증가하는 집합열로 바꿔준다.\n\\(A_1 - A_1 \\supset A_1 - A_2 \\supset A_1 - A_3 \\dots A_1 - A_i \\in \\cal{F}\\) & \\(\\cap^\\infty_{n=1} (A_1 - A_n) = A_1 - A\\)\n\\(LHS\\) \\(\\mu(lim_{n \\to \\infty} (A_1 - A_n)) = lim_{n \\to \\infty} \\mu((A_1 - A_n)\\) \\(RHS\\)\n\\(LHS\\) \\(\\mu(A_1 - lim_{n \\to \\infty} A_n) = \\mu(A_1 - lim_{n \\to \\infty} A_n)\\)\n\\(\\to\\) \\(lim_{n \\to \\infty} A_n = A\\) 이 성립하기 때문이고, 이게 성립하는 이유는 감소하는 집합열이기 때문에 \\(\\cap^\\infty_{n=1} A_n = A\\)라 쓸 수 있어서이다.\n\\(LHS\\) \\(\\mu(A_1 - lim_{n \\to \\infty} A_n) = \\mu(A_1 - lim_{n \\to \\infty} A_n) = \\mu(A_1) - \\mu(lim_{n \\to \\infty} A_n)\\)\n\\(\\to\\) \\(A_1 \\supset A\\) 이라서, 포함관계에 있는 차집합은 msr에서 뺀 것과 같다.\n\\(RHS\\) \\(lim_{n \\to \\infty} \\mu((A_1 - A_n) = lim_{n \\to \\infty} \\{ \\mu(A_1) - \\mu(A_n)\\}\\)\n\\(\\to\\) \\(A_1 \\supset A\\) 이라서, 포함관계에 있는 차집합은 msr에서 뺀 것과 같다.\n\\(RHS\\) \\(lim_{n \\to \\infty} \\mu((A_1 - A_n) = lim_{n \\to \\infty} \\{ \\mu(A_1) - \\mu(A_n)\\} = \\mu(A_1 ) - lim_{n \\to \\infty} \\mu(A_n)\\)\n\\(\\therefore\\) \\(LHS\\) \\(\\mu(A_1) - \\mu(lim_{n \\to \\infty} A_n = \\mu(A_1 ) - lim_{n \\to \\infty} \\mu(A_n)\\) \\(RHS\\)\n\\(\\mu(lim_{n \\to \\infty} A_n) = lim_{n \\to \\infty} \\mu(A_n)\\)\n단, \\(\\mu(A_1)\\)가 \\(\\infty\\)보다 작아야 가능하다. 따라서 \\(\\mu(A_1)\\)가 \\(\\infty\\)보다 작다.\n\n\\(A_i \\downarrow A\\) with \\(\\mu(A_1)&lt;\\infty\\) \\(\\Rightarrow\\) \\(\\mu(\\lim_{n\\to \\infty}A_n) = \\lim_{n \\to \\infty}\\mu(A_n)\\)여기서 \\(\\mu(A_1)&lt;\\infty\\) 조건을 만족하지 않아서 안 되는 예제\n\n\\((\\mathbb{N} , 2^\\mathbb{N})\\) 잴 수 있는 공간\n이 공간에서 counting msr \\(\\# : 2^\\mathbb{N} \\to [0, \\infty]\\)로 정의하자.\n\\(A_n = \\{ n,n+1,n+2 ,\\dots\\}\\)\n\\(A_1 = \\mathbb{N}\\)\n\\(A_2 = \\mathbb{N} - \\{1\\} = \\{2,3,4,\\dots\\}\\)\n\\(A_3 = \\mathbb{N} - \\{1,2\\} = \\{3,4,5,\\dots\\}\\)\n여기서\n\\(lim_{n \\to \\infty} A_n = \\oslash\\)\n\\(\\forall_n \\in \\mathbb{N} : A_n \\ne \\oslash\\)\n\\(\\to\\) \\(\\mathbb{N}\\) 여기에는 \\(\\infty\\)가 포함되어 있지 않다.\n\n\n\n\n\n\n\n\n\n\n\n\\(n\\)\n\\(n=1\\)\n\\(n=2\\)\n\\(n=3\\)\n\\(\\dots\\)\n\\(\\infty\\)\n\n\n\n\n\\(A_n\\)\n\\(\\{1,2,\\dots\\}\\)\n\\(\\{2,3,4,\\dots\\}\\)\n\\(\\{3,4,5,\\dots\\}\\)\n\\(\\to\\) 감소\n\\(\\oslash\\)\n\n\n\\(\\#(A_n)\\)\n\\(\\infty\\)\n\\(\\infty\\)\n\\(\\infty\\)\n\\(\\dots\\)\n\\(\\infty\\)\n\n\n\n\\(A_n \\downarrow \\oslash\\)이다. \\(\\Rightarrow\\) \\(\\#(lim_{n \\to \\infty} A_n) = lim_{n \\to \\infty} \\# (A_n)\\)\n\\(\\#(lim_{n \\to \\infty} A_n)\\) \\(\\Rightarrow\\) \\(\\#(\\oslash) = 0\\)\n\\(lim_{n \\to \\infty} \\# (A_n)\\) \\(\\Rightarrow\\) \\(\\infty\\)\n이유는 \\(\\#(A_1) &lt; \\infty\\) 조건이 없기 때문이다.\n따라서 \\(\\#(A_1) &lt; \\infty\\)이 필요하다.\n\n- 예제1: – 베르누이\n아래와 같은 함수를 고려하자.\n\\[F_X(x) = \\begin{cases}\n0 & x&lt;0 \\\\\n\\frac{1}{2} & 0\\leq x&lt; 1 \\\\\n1 & x \\geq 1 \\\\\n\\end{cases}\\]\n\ndef F_X(x):\n    if x &lt; 0:\n        return 0\n    elif 0 &lt;= x &lt; 1:\n        return 1/2\n    else:\n        return 1\n\nx = np.linspace(-1, 2, 1000)\ny = [F_X(i) for i in x]\n\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('F_X(x)')\nplt.title('Cumulative Distribution Function')\nplt.ylim(-0.1, 1.1)\nplt.grid(True)\n\n\n\n\n이 함수는 르벡메져에 대하여 absolutely continuous 하지 않다.\n(해설1)\n연속이 아니므로 절대연속이 아니다.\n(해설2)\n임의의 \\(\\{x\\}\\)에 대하여 \\(\\mu_X(\\{x\\})\\)를 계산하기 위해서는 아래와 같이 하면 된다.\n\n\\(\\mu_{X}(\\{x\\})=\\mu_{X}\\big(\\lim_{n\\to\\infty}(x-\\frac{1}{n},x]\\big)=\\lim_{n\\to\\infty}\\mu_{X}\\big((x-\\frac{1}{n},x]\\big)\\)\n\\((x-\\frac{1}{n}, x]= (-\\infty, x] - (-\\infty,x-\\frac{1}{n}]\\)\n\\(\\mu_{X}\\big((x-\\frac{1}{n},x]\\big)=F_X(x)-F_X(x-\\frac{1}{n})\\)\n\\(\\mu_{X}(\\{x\\})=F_X(x)-\\lim_{n\\to\\infty}F_X(x-\\frac{1}{n})\\)\n\n이를 이용하면\n\n\\(\\lambda(\\{0\\})=0 \\not \\Rightarrow \\mu_X(\\{0\\})=F_X(0)-\\lim_{n\\to\\infty}F_X(-\\frac{1}{n})=\\frac{1}{2}-0\\)\n\\(\\lambda(\\{1\\})=0 \\not \\Rightarrow \\mu_X(\\{1\\})=F_X(1)-\\lim_{n\\to\\infty}F_X(1-\\frac{1}{n})=1-\\frac{1}{2}\\)\n\\(\\lambda(\\{0,1\\})=0 \\not \\Rightarrow \\mu_X(\\{0,1\\}) =\\mu_X(\\{0\\})+\\mu_X(\\{1\\})=1\\)\n\n\n위에서 언급한 경우 이외에서는 연속임. \\(\\lambda(\\{0.77\\})=0 \\Rightarrow \\mu_X(\\{0.77\\})=F_X(0.77)-\\lim_{n\\to\\infty}F_X(0.77-\\frac{1}{n})=\\frac{1}{2}-\\frac{1}{2}\\)\n\n\n\n서연 필기\n\nQuestion: \\(F_X\\)는 절대 연속인지? 연속이 아니라서 절대연속이 아니다?\n\\(\\forall B \\in \\cal{R} : \\lambda(B) = 0\\) \\(\\rightarrow\\) \\(\\mu_X(B) = 0\\) \\(\\dots \\star\\)\n추측: \\(B = \\{0\\} , B = \\{1\\}\\)일 경우는 \\(\\star\\)가 성립하지 않을 것이다.\n\\(B = \\{0\\}\\)로 생각 \\(\\rightarrow\\) \\(\\lambda(B) = 0, \\mu_X(B) \\ne 0\\) 일 것 같다. (둘 다 0 이면 \\(\\star\\)가 성립한다는 말이 되니까)\n\\(\\mu_X(B)\\)만 계산하면 되겠다, \\(\\mu_X(\\{0\\})\\)만 계산하면 되겠다.\n\\(\\{0\\} = lim_{n \\to \\infty} (0 - \\frac{1}{n},0]\\) \\(\\rightarrow\\) 감소하는 집합열 \\(= \\cap^{\\infty}_{n=1}(-\\frac{1}{n},0]\\)\n또, \\(\\{0\\} \\in \\cap^\\infty_{n=1}(-\\frac{1}{n},0]\\)\n\\(x&lt;0\\) \\(\\rightarrow\\) \\(\\{ x\\} \\notin \\cap^\\infty_{n=1}(-\\frac{1}{n},0]\\)\n\\(\\to\\) 아무리 \\(0\\)에 가까운 \\(x\\)라도 그것보다 더 \\(0\\)에 가까운 \\(-\\frac{1}{n}\\)이 존재하므로, 그러한 \\(-\\infty\\)에 대해서는 \\(x \\notin (-\\frac{1}{n},0]\\)\n\\(\\therefore \\mu_X(\\{0\\}) = \\mu_X (lim_{n \\to \\infty} ( -\\frac{1}{n},0]) = lim_{n \\to \\infty} \\mu_X ((-\\frac{1}{n},0])\\)\n\\(\\bullet\\) \\(\\mu_X((a,b]) = F_X(b) - F_X(a)\\)\n\\(\\bullet\\) \\((a,b] = (-\\infty,b] - (-\\infty,a]\\) \\(\\rightarrow\\) \\(\\mu_X((a,b])= \\mu((-\\infty,b] - (-\\infty,a]) = \\mu((-\\infty,b]) - \\mu((-\\infty,a]) = F_X(b) - F_x(a)\\)\n\\(\\therefore \\mu_X ((-\\frac{1}{n},0]) = F_X(0) - F_X(-\\frac{1}{n})\\)\n\\(\\mu_X(\\{0\\}) = \\mu_X (lim_{n \\to \\infty} ( -\\frac{1}{n},0]) = lim_{n \\to \\infty} \\mu_X ((-\\frac{1}{n},0]) = lim_{n \\to \\infty} \\{ F_X(0) - F_X(-\\frac{1}{n}\\} = \\frac{1}{2} - lim_{n \\to \\infty} F_X(-\\frac{1}{n}) = \\frac{1}{2} -0 = \\frac{1}{2}\\)\n\\(\\therefore \\lambda(B) = 0, \\mu_X(B) = \\frac{1}{2}\\)이다. 그래서 절대연속 조건인 \\(\\lambda(B) = 0\\) \\(\\rightarrow\\) \\(\\mu_X(B) = 0\\)가 성립하지 않는다.\n\n- 예제2: – 균등분포\n아래와 같은 함수를 고려하자.\n\\[F_X(x) = \\begin{cases}\n0 & x&lt;0 \\\\\nx & 0\\leq  x \\leq  1 \\\\\n1 & x&gt; 1 \\\\\n\\end{cases}\\]\n\ndef F_X(x):\n    if x &lt; 0:\n        return 0\n    elif 0 &lt;= x &lt;= 1:\n        return x\n    else:\n        return 1\n\nx = np.linspace(-1, 2, 1000)\ny = [F_X(i) for i in x]\n\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('F_X(x)')\nplt.title('Cumulative Distribution Function')\nplt.ylim(-0.1, 1.1)\nplt.grid(True)\n\n\n\n\n이 함수는 르벡메져에 대하여 absolutely continuous 하다.\n(해설)\n\\(\\forall B\\in {\\cal R}: \\mu_X(B) \\leq \\lambda(B)\\) 이므로 자명함\n\n\n서연 필기\n\n\\(B\\)가 ~ 0 까지의 구간과 1 ~ 의 구간에서는 \\(\\mu_X(B) = 0\\)\n\\(B\\)가 0~1의 구간에서 선택된다면 \\(\\mu_X(B) = \\lambda(B)\\), \\(\\mu_X([a,b]) = F_X(b) - F_X(a) = b-a\\)\n결국 \\(\\mu_X(B) \\le \\lambda(B)\\)의 결과로 나올 것이다.\n따라서 \\(\\lambda(B)\\)이 0이면 \\(\\mu_X(B)\\)도 0이 될 것이기 때문에 절대연속의 조건이 성립한다.\n\n- 예제3 – 혼합된 균등분포\n아래와 같은 distribution function \\(F_X\\)을 가지는 확률변수 \\(X\\)를 고려하자.\n\\[F_X(x) = \\begin{cases} 0 & x&lt;0\\\\ \\frac{3}{2}x & 0\\leq x &lt; \\frac{1}{2} \\\\ \\frac{1}{2}+\\frac{1}{2}x & \\frac{1}{2}\\leq x&lt;1 \\\\ 1 & 1\\leq x\\end{cases}\\]\n\ndef F_X(x):\n    if x &lt; 0:\n        return 0\n    elif 0 &lt;= x &lt; 0.5:\n        return (3/2) * x\n    elif 0.5 &lt;= x &lt; 1:\n        return 0.5 + (1/2) * x\n    else:\n        return 1\n\nx = np.linspace(-1, 2, 1000)\ny = [F_X(i) for i in x]\n\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('F_X(x)')\nplt.title('Cumulative Distribution Function')\nplt.ylim(-0.1, 1.1)\nplt.grid(True)\n\n\n\n\n이러한 함수 \\(F_X\\)는 르벡메져에 대하여 absolutely continuous 한가?\n(해설)\n\\(\\forall B \\in {\\cal R}: \\mu_X(B) \\leq \\frac{3}{2}\\lambda(B)\\) 이므로 자명함.\n\n예제2,3으로 관찰하고 착각할 수 있는 것: 그냥 연속이면 다 절대연속 아니야?\n\n\n\n서연 필기\n\n\\(F_X(x) = \\begin{cases} 0 & x&lt;0\\\\ \\frac{3}{2}x & 0\\leq x &lt; \\frac{1}{2} & \\mu_X(B) = \\frac{3}{2}\\lambda(B)\\\\ \\frac{1}{2}+\\frac{1}{2}x & \\frac{1}{2}\\leq x&lt;1& \\mu_X(B) = \\frac{1}{2}\\lambda(B)\\\\ 1 & 1\\leq x&\\mu_X(B) = 0\\end{cases}\\)\n\\(\\mu_X(B) \\leq \\frac{3}{2}\\lambda(B)\\) 결국은 다 이렇게 되겠네.\n따라서 절대연속이다.\n\n- 예제3 – 칸토어함수\n칸토어함수 \\(F_X\\)는 르벡메져에 대하여 absolutely continuous 하지 않다.\n(해설)\n칸토어함수 \\(F_X\\)가 absolutely continuous 하다고 하자. 그러면 \\(\\mu_X((a,b]) = \\mu_X([a,b])\\) 가 성립한다.\n\n\n서연 필기\n\n\\(\\mu_X([a,b]) = \\mu_X(\\{a\\}) + \\mu_X((a,b]) = 0+ \\mu_X(\\{a\\}) = 0\\)\n\\(\\lambda(\\{a\\}) = 0\\) \\(\\rightarrow\\) \\(\\mu_x(\\{a\\}) = 0\\), 왜냐하면 \\(\\mu_X &lt;&lt; \\lambda\\)(절대연속이니까)\n\n\\(n=0\\):\n\n\\(C_0=[0,1]\\)\n\\(\\mu_X(C_0)=\\mu_X((0,1])=F_X(1)-F_X(0)=1\\)\n\n\\(n=1\\):\n\n\\(C_1=[0,\\frac{1}{3}] \\cup [\\frac{2}{3},1]\\)\n\\(\\mu_X(C_1)=\\mu_X((0,\\frac{1}{3}])+\\mu_X((\\frac{2}{3},1])=F_X(\\frac{1}{3})-F_X(0)+F_X(1)-F_X(\\frac{2}{3})=1\\)\n\n정리하면 아래와 같다.\n\n\n\n\n\n\n\n\n\\(n\\)\n\\(C_n\\)\n\\(\\mu_X(C_n)\\)\n\n\n\n\n\\(0\\)\n\\([0,1]\\)\n\\(1\\)\n\n\n\\(1\\)\n\\([0,\\frac{1}{3}] \\cup [\\frac{2}{3},1]\\)\n\\(1\\)\n\n\n\\(2\\)\n\\([0,\\frac{1}{9}]\\cup[\\frac{2}{9},\\frac{1}{3}] \\cup[\\frac{2}{3},\\frac{7}{9}]\\cup [\\frac{8}{9},1]\\)\n\\(1\\)\n\n\n\\(\\dots\\)\n\\(\\dots\\)\n\\(1\\)\n\n\n\n그런데 \\(\\lambda({\\cal C})=0\\) 이지만 \\(\\mu_X(\\lim_{n\\to \\infty}C_n)=\\mu_X({\\cal C})=1\\) 이므로 \\(\\mu&lt;&lt;\\lambda\\)에 모순이다."
  },
  {
    "objectID": "posts/ap/2023-05-30-ap-13wk.html#라돈니코딤-정리",
    "href": "posts/ap/2023-05-30-ap-13wk.html#라돈니코딤-정리",
    "title": "13wk: 밀도함수",
    "section": "라돈니코딤 정리",
    "text": "라돈니코딤 정리\n- 이론: 분포함수 \\(F_X:\\mathbb{R} \\to [0,1]\\)가 (르벡메져에 대하여) 절대연속이라면 아래를 만족하는 함수 \\(f_X:\\mathbb{R} \\to \\mathbb{R}^+\\)가 존재한다.\n\\[F_X = \\int_{(-\\infty,x]}f_Xd\\lambda\\]\n여기에서 함수 \\(f_X\\)를 \\(F_X\\)의 밀도함수 (density function) 이라고 한다. 일반적으로 밀도함수 \\(f_X\\)는 유일하지 않지만, 르벡측도로 재었을때 0인 집합을 제외한 부분에서는 유일하게 결정된다. (요약: 분포함수 \\(F_X\\)가 절대연속이면 밀도함수 \\(f_X\\)가 존재하고, 거의 유일함)\n\n위에서 “르벡측도로 재었을때 0인 집합을 제외한 부분에서는 유일하게 결정된다”라는 부분은 “르벡메져 \\(\\lambda\\)에 대하여 거의 유일하다” 라고 이해해도 무방. 엄밀하게 쓰면 “분포함수 \\(F_X\\)가 있다면 밀도함수의 정의하는 만족하는 함수가 반드시 하나는 존재한다. 만약에 두 함수 \\(f\\)와 \\(g\\)가 모두 밀도함수의 정의를 만족한다면 ‘\\(f=g\\) a.e. with respect to \\(\\lambda\\)’ 가 성립한다.” 와 같은 식으로 쓸 수 있음.\n\n\n위에서 \\(f\\)의 공역이 \\(\\mathbb{R}^+\\)인 이유는 \\(F_X\\)가 증가함수라서..\n\n- Thm (라돈니코딤 정리)(Durrett 2019, Thm A.4.8.): 가측공간 \\((S,{\\cal S})\\)를 고려하자. 그리고 \\(\\mu\\)와 \\(\\lambda\\)가 \\((S,{\\cal S})\\)에서의 \\(\\sigma\\)-finite measure 라고 하자. 만약에 \\(\\mu &lt;&lt; \\lambda\\) 이라면 아래를 만족하는 가측함수 \\(f:(S,{\\cal S}) \\to (\\mathbb{R}^+,{\\cal R}^+)\\)가 거의 유일하게 (w.r.t. \\(\\lambda\\)) 존재한다.\n\\[\\forall B \\in {\\cal S}:~ \\mu(B) = \\int_B f d\\lambda.\\]\n여기에서 \\(f\\)를 Radon-Nikodym derivative of \\(\\mu\\) w.r.t. \\(\\lambda\\) 라고 하며, 이러한 의미에서 \\(f=\\frac{d\\mu}{d\\lambda}\\)와 같이 표현하기도 한다.\n\n\n\n\n\n\n강의 오류 정정\n\n\n\n\\(f: (S,{\\cal S}) \\to (S, {\\cal S})\\)를 \\(f:(S,{\\cal S}) \\to (\\mathbb{R}^+, {\\cal R}^+)\\)로 정정합니다.\n\n\n\n\n서연 필기\n\n정의역이 실수 전체를 가질 수 있다. \\(\\mathbb{R}\\)\n증가함수라서 항상 양의 값을 가질 것이다. \\(\\mathbb{R}^+\\)\n\\(\\to\\) 따라서 pdf도 항상 양의 값을 가질 것이다.\n\\(\\star\\) \\(\\mu_X\\)를 다룰때는 이라 finite 했는데 finite 이면 \\(\\sigma\\)-finite이라서 위에서는 언급 안 했다. 지금은 필요해서 언급\n이렇게 쓰기도 한다. \\(\\int_B f d\\lambda = \\int_B \\frac{du}{d\\lambda} d\\lambda = \\int_B du = \\mu(B)\\)\n\n- 예제1 – 균등분포\n아래와 같은 함수를 고려하자.\n\\[F_X(x) = \\begin{cases}\n0 & x&lt;0 \\\\\nx & 0\\leq  x \\leq  1 \\\\\n1 & x&gt; 1 \\\\\n\\end{cases}\\]\n또한 아래와 같은 함수 \\(f_X: \\mathbb{R} \\to \\mathbb{R}\\) 를 고려하자.\n\\[f_X(x) = \\begin{cases} 1 & 0 \\leq x \\leq 1 \\\\ 0 & o.w. \\end{cases}\\]\n\\(f_X(x)\\)가 \\(F_X(x)\\)의 라돈니코딤 도함수임을 설명하라.\n\ndef cumulative_distribution_function(x):\n    if x &lt; 0:\n        return 0\n    elif x &lt;= 1:\n        return x\n    else:\n        return 1\n\nx = np.linspace(-1, 2, 1000)\ny = np.array([cumulative_distribution_function(i) for i in x])\n\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('F_X(x)')\nplt.title('Cumulative Distribution Function')\nplt.grid(True)\n\n\n\n\n(해설)\n\n\\(\\mu_X\\)와 \\(\\lambda\\)는 모두 \\((\\mathbb{R},{\\cal R})\\)에서 \\(\\sigma\\)-finite 하다.\n\\(\\mu_X &lt;&lt; \\lambda\\)이다. 따라서 적당한 \\({\\cal R} \\to {\\cal R}^+\\) measurable function이 존재하여 라돈니코딤 도함수의 조건을 만족함을 알 수 있다.\n우리가 생각하는 후보는 \\(f_X\\)인데 이것이 만약에 (1) \\({\\cal R} \\to {\\cal R}^+\\) 가측함수이고 (2) 라돈니코딤 도함수의 조건을 만족한다면 \\(f_X\\)는 \\(F_X\\)의 거의 유일한 (w.r.t. \\(\\lambda\\)) 밀도함수라고 주장할 수 있다.\n\\(f_X\\)는 simple function이므로 \\({\\cal R} \\to {\\cal R}^+\\) 가측함수이다.\n임의의 \\(x\\)에 대하여 \\(F_X(x)=\\mu_X((-\\infty,x])=\\int_{(-\\infty,x]}f_Xd\\lambda\\) 이 성립한다.\n5와 \\(\\pi\\)-\\(\\lambda\\) thm을 이용하면 모든 \\(B \\in {\\cal R}\\)에 대하여 \\(\\mu_X(B) = \\int_B f_X d\\lambda\\) 가 성립한다. (풀이참고)\n따라서 \\(f_X\\)는 \\(F_X\\)의 밀도함수이다.\n\n\n\n서연 필기\n\n\n\\(\\mu_x\\)은 finite msr이고, \\(\\lambda\\)는 \\(\\sigma\\) finite msr라 \\((\\mathbb{R},\\cal{R})\\)에서 \\(\\sigma\\)-finite하다.\n\n\\(\\sigma\\)-finite은 \\(\\lambda(\\mathbb{R}) = \\infty\\)인 것은 상관없다.\n하지만 \\(A_1,A_2, \\dots \\in \\mathbb{R}\\)에서 (1) \\(\\lambda(A_n) &lt; \\infty, \\forall n \\in \\mathbb{N}\\)이고. (2) \\(\\cup^\\infty_{n=1}A_n = \\mathbb{R}\\)을 만족하면 \\(\\sigma\\)-finite msr라고 하기로 했다.(이렇게 쪼갤 수 있고 각각이 finite하고 이를 합쳐서 전체집합을 만들 수 있을때)\n\n\\(\\mu_X &lt;&lt; \\lambda\\)이다. 따라서 적당한 \\({\\cal R} \\to {\\cal R}^+\\) measurable function이 존재하여 라돈니코딤 도함수의 조건을 만족함을 알 수 있다.\n\n\\(F_X\\)가 절대 연속, 왜냐하면 \\(\\forall B \\in \\cal{R}: \\mu_X(B) \\le \\lambda(B)\\). 따라서 \\(\\mu_X(B) = 0\\), \\(\\lambda(B) = 0\\)\n(1)\\(\\mu_X,\\lambda\\)가 \\(\\sigma\\)-finite하고, (2)\\(\\mu_X&lt;&lt;\\lambda\\)을 모두 만족하면, \\(\\forall B\\in \\cal{R}, \\mu_X(B) = \\inf f_X d \\lambda\\)가 유일하게 존재한다는 것은 아나, 정확한 식은 알지 못한다.\n하지만 여기서는 예제로서 정해놨다. \\(f_X(x) = \\begin{cases} 1 & 0 \\leq x \\leq 1 \\\\ 0 & o.w. \\end{cases}\\)\n\n우리가 생각하는 후보는 \\(f_X\\)인데 이것이 만약에 (1) \\({\\cal R} \\to {\\cal R}^+\\) 가측함수이고 (2) 라돈니코딤 도함수의 조건을 만족한다면 \\(f_X\\)는 \\(F_X\\)의 거의 유일한 (w.r.t. \\(\\lambda\\)) 밀도함수라고 주장할 수 있다.\n\n이 \\(f_X(x) = \\begin{cases} 1 & 0 \\leq x \\leq 1 \\\\ 0 & o.w. \\end{cases}\\)가 \\(\\forall B \\in \\cal{R}\\): \\(\\int_B f d \\lambda \\mu_X(B) \\dots \\star\\)를 만족한다면 이 \\(f_X\\)는 \\(F_X\\)의 라돈니코딘 도함수라고 주장할 수 있다.\n4번에 의해 “(1) \\({\\cal R} \\to {\\cal R}^+\\) 가측함수이고”는 해결\n우리가 알고 싶은 것 \\(\\forall B \\in \\cal{R}\\): \\(\\int_B f d \\lambda \\mu_X(B)\\)\n만약 \\(B = (-\\infty,x]\\)이면 \\(\\mu(B) = F_X(x) = \\int_{(-\\infty,x]} f d \\lambda = \\int^x_{-\\infty} f(y) dy\\)로 쓸 수 있다.\n아니라면? \\(\\mu(B) = F_X(x) = \\int_B f d \\lambda\\)라고 주장하기 어려워진다.\n\n\\(f_X\\)는 simple function이므로 \\({\\cal R} \\to {\\cal R}^+\\) 가측함수이다.\n임의의 \\(x\\)에 대하여 \\(F_X(x)=\\mu_X((-\\infty,x])=\\int_{(-\\infty,x]}f_Xd\\lambda\\) 이 성립한다.\n\n\\(\\cal{A} = \\{(-\\infty,x] : x \\in \\mathbb{R}\\}\\)이라고 하자.\n\\(\\forall A \\in \\cal{A} : \\int_A f_X d \\lambda = \\mu_X (A)\\)임은 보였음.\n목표: \\(\\forall A \\in \\cal{R} : \\int_A f_X d \\lambda = \\mu_X(A)\\)임을 보이자.\nThm: If \\(\\cal{AA}\\) is \\(\\pi\\)-system, then \\(l(\\cal{A}) = \\sigma(\\cal{A})\\)\nwts : \\(\\cal{D} = \\{ A: \\int_A f_X d\\lambda = \\mu_X(A)\\} = \\cal{R}\\)3 = \\(\\sigma(\\cal{A})\\)4\n따라서 \\(\\cal{D} \\supset \\cal{R}\\) & \\(\\cal{D} \\subset \\cal{R}\\)임을 보이면 된다.\n이 때, \\(\\cal{D} \\subset \\cal{R}\\)임은 당연하므로, \\(\\cal{D} \\supset \\cal{R}\\)임을 보이면 된다. 그런데, \\(\\cal{D}\\)가 (1) \\(\\lambda\\)-system이고, (2)\\(\\cal{A}\\)를 포함한다면 (Note \\(\\cal{A}\\)is \\(\\pi\\)-sysyem)\n\\(\\sigma(\\cal{A}) = l(\\cal{A} )\\) \\(\\rightarrow\\) \\(\\pi\\)-\\(\\lambda\\) thm 때문에 가능하다.\n\\(\\sigma(\\cal{A}) = l(\\cal{A} ) = \\cal{R}\\) \\(\\sigma(\\cal{A})\\)는 \\(\\cal{R}\\)와 정의상 같아서 이렇게 식을 쓸 수 있다.\n\\(\\cal{R}\\)5 \\(\\subset\\) \\(\\cal{D}\\) 6 \\(\\dots \\star\\)\n\\(\\star\\)가 성립하므로 \\(\\cal{R} \\supset \\cal{D}\\)이 해결된다.\n\nCheck 1. \\(\\cal{A}\\)는 \\(\\pi\\)-system이고, \\(\\cal{A} \\in \\cal{D}\\)이다.\n\n\\(\\cal{D} = \\{ A: \\int_A f d \\lambda = \\mu_X(A), A \\in \\cal{R}\\}\\)\n\\(A \\in \\cal{A}\\) \\(\\rightarrow\\) \\(\\int_A f d \\lambda = \\mu_X(A)\\) 성립. \\(\\rightarrow\\) A $\n\nCheck 2. \\(\\cal{D}\\)가 \\(\\lambda\\)-system임을 보이면 증명이 끝\n\n\n\\(\\mathbb{R} \\in \\cal{D}\\)\n\\(\\forall A,B \\in \\cal{D}\\) such that \\(A \\subset B : B-A \\in \\cal{D}\\)\n\\(\\forall A_1 A_2 \\dots \\in \\cal{D} : \\uplus^{\\infty}_{n=1} A_n \\in \\cal{D}\\)\n\n참고: \\(\\cal{D} = \\{ A : \\int_A f_X d \\lambda = \\mu_X(A) , A \\in \\cal{R}\\}\\)\n\n증명 \\(\\int_{\\cal{R}} f_X d \\lambda = 1 = \\mu_X (\\mathbb{R})\\)\nFix \\(A \\in B\\) \\(A \\in \\cal{A} , B \\in \\cal{D}\\)\n\n\\(\\rightarrow\\) \\(B-A \\in \\cal{D}\\) \\(\\leftrightarrow\\) \\(\\int_{B-A} f_X d \\lambda = \\mu_X (B-A)\\) 와 같음.\n\\(\\rightarrow\\) LHS = \\(\\int_B f_X d \\lambda - \\int_A f_X d \\lambda\\) (\\(B \\supset A\\)이기 때문에)\n\\(\\rightarrow\\) = \\(\\mu_X(B) - \\mu_X(A)\\) (\\(A,B \\in \\cal{D}\\))이기 때문에\n\\(\\rightarrow\\) = \\(\\mu_X(B-A)\\) ((\\(B \\supset A\\)이기 때문에) = RHS\n하지만 \\(A,B\\)를 고정하지 않고 임의의 \\(A\\subset B\\) & \\(A,B \\in \\cal{D}\\) 를 선택해도 위의 논리가 성립하므로 Check 2 확인 완료.\n\nFix \\(A_1, A_2 \\dots \\in \\cal{D}\\) & $ A_1, A_2, $ are disjoiny일 때, \\(\\uplus^{\\infty}_{i=1} A_i \\in \\cal{D}\\)임을 보이자.\n\n\\(\\rightarrow\\) \\(\\int_{\\uplus^{\\infty}_{i=1} A_i} f_X d \\lambda = \\mu_X(\\uplus^{\\infty}_{i=1} A_i)\\) 임을 보이면 된다.\n\\(\\rightarrow\\) LHS = \\(\\sum^{\\infty}_{i=1} \\int_{A_i} f_X d \\lambda = \\sum^{\\infty}_{i=1} \\mu_X (A_i)\\) (\\(A_1,A_2,\\dots \\in \\cal{D}\\)라서 가능)\n\\(\\rightarrow\\) = \\(\\mu_X(\\uplus^{\\infty}_{i=1} A_i)\\) = RHS\n위의 논의가 \\(A_1,A_2,\\dots \\in \\cal{D}\\) & \\(A_1,A_2 \\dots\\) are disjoint 한 임의의 \\(A_1,A_2, \\dots\\)에 대하여 성립하므로 (3)이 확인되었다.\n\\(\\therefore \\cal{D}\\)는 \\(\\lambda\\)-system\n\n5와 \\(\\pi\\)-\\(\\lambda\\) thm을 이용하면 모든 \\(B \\in {\\cal R}\\)에 대하여 \\(\\mu_X(B) = \\int_B f_X d\\lambda\\) 가 성립한다.\n따라서 \\(f_X\\)는 \\(F_X\\)의 밀도함수이다.\n\n\n- 예제2 – 베르누이 분포\n아래와 같은 함수를 고려하자.\n\\[F_X(x) = \\begin{cases}\n0 & x&lt;0 \\\\\n\\frac{1}{2} & 0 \\leq  x &lt;1 \\\\\n1 & x \\geq 1\n\\end{cases}\\]\n\ndef F_X(x):\n    if x &lt; 0:\n        return 0\n    elif 0 &lt;= x &lt; 1:\n        return 0.5\n    else:\n        return 1\n\nx = np.linspace(-2, 2, 1000)\ny = np.vectorize(F_X)(x)\n\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('F_X(x)')\nplt.title('Cumulative Distribution Function')\nplt.grid(True)\n\n\n\n\n이 함수에 대응하는 \\(\\mu_X\\)를 아래와 같이 정의하자.\n\n\\(\\mu_X(\\emptyset)=0\\)\n\\(\\mu_X(\\{0\\})=\\frac{1}{2}\\)\n\\(\\mu_X(\\{1\\})=\\frac{1}{2}\\)\n\\(\\mu_X(\\{0,1\\})=1\\)\n\\(\\mu_X(B)=0\\) , \\(B \\in {\\cal R} - \\{0,1\\} - \\{0\\} - \\{1\\}\\)\n\n\\(\\mu_X\\)는 \\(\\lambda\\)에 대한 라돈니코딤 도함수를 가지지 않음을 보여라.\n(해설) – 절대연속이 안되는걸?"
  },
  {
    "objectID": "posts/ap/2023-05-16-ap-11wk.html",
    "href": "posts/ap/2023-05-16-ap-11wk.html",
    "title": "11wk: 적분 (1)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-wE3YLAgBkDd80KhdCztqy4"
  },
  {
    "objectID": "posts/ap/2023-05-16-ap-11wk.html#기호에-대한-암묵적-약속",
    "href": "posts/ap/2023-05-16-ap-11wk.html#기호에-대한-암묵적-약속",
    "title": "11wk: 적분 (1)",
    "section": "기호에 대한 암묵적 약속",
    "text": "기호에 대한 암묵적 약속\n- 르벡메져: 르벡메져는 지금까지 \\(m\\)으로 표현 \\(\\Rightarrow\\) 앞으로는 \\(\\lambda\\)로 표현.\n- 메져: \\(\\mu,\\nu\\) 등으로 표현.\n- 분포, 분포함수, 밀도함수: 확률공간 \\((\\Omega, {\\cal F}, P)\\)에서 정의된 확률변수 \\(X\\)에 대응하는 분포는 \\(\\mu_X\\), 그에 대응하는 분포함수는 \\(F_X\\), 그에 대응하는 밀도함수는 \\(f_X\\)라고 표현.\n- 일반적인 교재의 표기법\n\n르벡메져: \\(\\mu\\), \\(\\lambda\\), \\(m\\)\n메져: \\(\\mu\\), \\(\\nu\\), \\(m\\)\n분포: \\(\\mu\\)\n분포함수: \\(F\\), \\(F_X\\)\n밀도함수: \\(f\\), \\(f_X\\)\n\n- 잴 수 있는 함수의 표현 (아래는 모두 같은말)\n\n두 개의 가측공간 \\((\\Omega, {\\cal F})\\), \\((S, {\\cal S})\\)을 고려하자. 함수 \\(f:\\Omega \\to S\\)는 \\(\\forall B \\in {\\cal S}:~\\{\\omega: f(\\omega) \\in B\\} \\in {\\cal F}\\) 을 만족한다.\n두 개의 가측공간 \\((\\Omega, {\\cal F})\\), \\((S, {\\cal S})\\)을 고려하자. \\(f:\\Omega \\to S\\)는 잴 수 있는 함수이다.\n\\(f:(\\Omega,{\\cal F}) \\to (S, {\\cal S})\\)\n\\(f\\)는 \\({\\cal F}-{\\cal S}\\) measurable 하다.\n\\(f \\in {\\cal F}\\), 이 표기법은 \\((S,{\\cal S})=(\\mathbb{R}, {\\cal R})\\)일 경우에 한정하여 사용할 수 있음.\n\\(f\\)는 \\(S\\)-valued measurable map"
  },
  {
    "objectID": "posts/ap/2023-05-16-ap-11wk.html#확장된-실수공간",
    "href": "posts/ap/2023-05-16-ap-11wk.html#확장된-실수공간",
    "title": "11wk: 적분 (1)",
    "section": "확장된 실수공간",
    "text": "확장된 실수공간\n- 교재에 따라서 확장된 실수공간 \\(\\bar{\\mathbb{R}}\\)를 고려하기도 한다. (Durrett 2019, p 14)\n\\[\\bar{\\mathbb{R}} = \\mathbb{R} \\cup \\{-\\infty\\} \\cup \\{\\infty\\}\\]\n- 또한 확장된 실수공간에 대응하는 보렐셋을 정의하기도 한다.\n\\[{\\cal B}(\\bar{\\mathbb{R}})=\\bar{\\cal R}\\]\n- \\(\\infty\\), \\(-\\infty\\)는 실수가 아니다. 따라서 \\(x\\in \\mathbb{R}\\) 인 경우는 \\(x\\)를 real-valued 라고 표현하지만 \\(x \\in \\bar{\\mathbb{R}}\\) 인 경우는 \\(x\\)를 \\(\\bar{\\mathbb{R}}\\)-valued 라고 표현한다."
  },
  {
    "objectID": "posts/ap/2023-05-16-ap-11wk.html#mathbbrd-cal-rd",
    "href": "posts/ap/2023-05-16-ap-11wk.html#mathbbrd-cal-rd",
    "title": "11wk: 적분 (1)",
    "section": "\\((\\mathbb{R}^d, {\\cal R}^d)\\)",
    "text": "\\((\\mathbb{R}^d, {\\cal R}^d)\\)\n- 정의: 두개의 집합 \\(A\\), \\(B\\)가 있을때 두집합의 곱집합 (cartesian product) \\(A\\times B\\)를 아래와 같이 정의한다.\n\\[A\\times B=\\{(a,b): a \\in A, b \\in B\\}\\]\n- 정의: 수직선상의 두 열린구간 \\((a_1,b_1)\\), \\((a_2,b_2)\\) 의 곱집합\n\\[({\\boldsymbol a},{\\boldsymbol b}) = \\bigtimes_{i=1}^{2}(a_i,b_i)= (a_1,b_1) \\times (a_2,b_2)\\]\n을 open rantangle 이라고 한다. 비슷한 논리전개로 \\(({\\boldsymbol a},{\\boldsymbol b}],[{\\boldsymbol a},{\\boldsymbol b}),[{\\boldsymbol a},{\\boldsymbol b}]\\) 역시 정의할 수 있다.\n- 이론: 아래와 같은 집합들의 모임 \\({\\cal A}\\)를 생각하자.\n\\[{\\cal A}=\\{({\\boldsymbol a}, {\\boldsymbol b}]: {\\boldsymbol a} &lt; {\\boldsymbol b},~ {\\boldsymbol a}, {\\boldsymbol b} \\in \\mathbb{R}^2\\}\\]\n여기에서 \\({\\boldsymbol a}&lt; {\\boldsymbol b}\\)는 “\\(a_1&lt;b_1\\) and \\(a_2 &lt; b_2\\)” 를 의미한다.\n\n시그마필드 \\(\\sigma({\\cal A})\\)는 잘 정의된다. (귀찮아서 만든 이론1)\n\\(\\sigma({\\cal A})\\)은 \\({\\cal R}\\)의 2차원버전이라 해석할 수 있다.\n이러한 의미에서 \\({\\cal R}^2=\\sigma({\\cal A})\\)라는 기호를 쓰기도 한다.\n\\((\\mathbb{R}^2, {\\cal R}^2)\\) 는 잴 수 있는 공간이다.\n함수 \\(\\tilde{\\lambda}: {\\cal A} \\to [0,\\infty]\\)를 아래와 같이 정의하자. 카라테오도리의 확장정리에 의하여 \\(\\tilde{\\lambda}\\)는 \\((\\mathbb{R}^2,{\\cal R}^2)\\) 에서의 메져가 된다. \\[\\tilde{\\lambda}(({\\boldsymbol a},{\\boldsymbol b}])=\\prod_{i=1}^{2}(b_i-a_i)\\]\n08주차에 정리된 모든 \\({\\cal A}_i\\)에 대하여, \\(\\sigma({\\cal A}_i)={\\cal R}^2\\) 을 만족한다.\n\n- 체크: \\((\\mathbb{R}^2, {\\cal R}^2)\\) 와 동일한 논리전개가 \\((\\mathbb{R}^d, {\\cal R}^d)\\) 에서도 성립한다."
  },
  {
    "objectID": "posts/ap/2023-05-16-ap-11wk.html#sup-inf",
    "href": "posts/ap/2023-05-16-ap-11wk.html#sup-inf",
    "title": "11wk: 적분 (1)",
    "section": "sup, inf",
    "text": "sup, inf\n- 집합 \\(A=\\{1,2,3\\}\\)에 대하여 아래의 표현을 살펴보자.\n\n\\(\\max A =3\\)\n\\(\\min A =1\\)\n\n- 집합 \\(A=[0,2]\\)에 대하여 아래의 표현을 살펴보자.\n\n\\(\\max A =2\\)\n\\(\\min A =0\\)\n\n- 집합 \\(A=(0,2)\\)라면?\n\n\\(\\max A =???\\)1\n\\(\\min A =???\\)2\n\\(\\sup A = 2\\)\n\\(\\inf A = 0\\)\n\n- 가짜정의: 어떠한 집합 \\(A\\)가 있다고 할떄 \\(\\sup A\\)와 \\(\\inf A\\)는 각각 \\(\\max A\\)와 \\(\\min A\\)의 개념을 좀 더 업그레이드 한것이다. \\(\\max A\\)는 \\(A\\)의 원소중 최대값을 의미하는데 이러한 \\(\\max\\)의 정의는 구간 \\([0,2)\\)의 최대값은 \\(2\\)라고 주장할 수 없어 쓰기에 불편할 때가 있다. \\(\\min\\) 역시 마찬가지의 불편함이 있다. 이를 보완하기 위해 등장한 개념이 \\(\\sup\\)과 \\(\\inf\\)이다.\n- 트릭: 증가하는 수열 \\(a_n\\)의 경우 \\(\\sup\\{a_n\\}\\)은 수열 \\(\\{a_n\\}\\)의 극한을 의미하기도 한다. 반대로 감소하는 수열 \\(\\{a_n\\}\\)의 경우 \\(\\inf \\{a_n\\}\\)이 \\(\\{a_n\\}\\)의 극한을 의미하기도 한다.\n잘못된 사용\n1. 집합들의 집합에서 \\(\\inf,\\sup\\)의 잘못된 사용: 부등호 \\(&lt;\\)를 \\(\\subset\\)으로 해석\n\n예시1: \\(\\inf\\big\\{(-\\frac{1}{n},0]: n \\in \\mathbb{N}\\big\\}=\\{0\\}\\) // 틀린표현\n예시2: \\(\\sup\\big\\{[0,1-\\frac{1}{n}]: n \\in \\mathbb{N}\\big\\}=[0,1)\\) // 틀린표현\n\n2 함수들의 집합에서 \\(\\inf,\\sup\\)의 잘못된 사용: 부등호 \\(f&lt;g\\) 를 “\\(\\forall x: f(x)&lt;g(x)\\)” 로 해석\n\n예시1: \\(f(x)=x\\) 일때, \\(\\sup\\big\\{f_n: f_n(x)=x-\\frac{1}{n}, n \\in \\mathbb{n} \\big\\}=f\\) // 틀린표현"
  },
  {
    "objectID": "posts/ap/2023-05-16-ap-11wk.html#잴-수-있는-함수들",
    "href": "posts/ap/2023-05-16-ap-11wk.html#잴-수-있는-함수들",
    "title": "11wk: 적분 (1)",
    "section": "잴 수 있는 함수들",
    "text": "잴 수 있는 함수들\n- 이론: 두 개의 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\), \\((\\mathbb{R}, {\\cal R})\\)을 고려하자. \\({\\cal F}\\)-measurable 한 집합 \\(A\\)에 대하여3 함수 \\(f:\\Omega \\to \\mathbb{R}\\)을 아래와 같이 정의한다고 하자.\n\\[f(\\omega) = \\begin{cases} 1 & \\omega \\in A \\\\ 0 & \\omega \\not \\in A \\end{cases}\\]\n함수 \\(f\\)는 \\({\\cal F}-{\\cal R}\\) measurable function 이다.\n(해설)\n\n\\(B \\in {\\cal R}\\)를 고정하자.\n만약에 \\(\\{1,0\\} \\not \\subset B\\) 이라면 \\(\\{\\omega: f(\\omega) \\in B\\}=\\emptyset \\in {\\cal F}\\) 이다.\n만약에 \\(\\{1\\} \\subset B, \\{0\\} \\not \\subset B\\) 이라면 \\(B=\\{1\\} \\cup (B-\\{1\\})\\) 와 같이 분해한다.\n\\(f\\)는 함수이므로 \\(f^{-1}(B)=f^{-1}(\\{1\\}) \\cup f^{-1}(B-\\{1\\})\\)를 만족한다.\n\\(f^{-1}(\\{1\\})=A\\)이고 \\(f^{-1}(B-\\{1\\})=\\emptyset\\) 이므로 \\(f^{-1}(B)=A \\in {\\cal F}\\) 를 만족한다.\n3-5의 논의가 \\(\\{0\\} \\subset B, \\{1\\} \\not \\subset B\\) 에 대해서도 성립한다.\n\\(\\{0,1\\} \\subset B\\) 인 경우에는 \\(f^{-1}(B) =\\Omega\\)가 되므로 \\(f^{-1}(B) \\in {\\cal F}\\) 를 만족한다.\n1-7의 논의가 임의의 \\(B\\)에 대하여 모두 성립하므로 \\(\\forall B \\in {\\cal R}:~f^{-1}(B) \\in {\\cal F}\\) 이다.\n따라서 \\(f\\)는 \\({\\cal F}-{\\cal R}\\) measurable function 이다.\n\n- 이론: 두 개의 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\), \\((\\mathbb{R}, {\\cal R})\\)을 고려하자. 함수 \\(f\\)가 \\(\\mathbb{R}\\)-valued measurable function 이라면 임의의 \\(\\alpha \\in \\mathbb{R}\\)에 대하여 함수\n\\[g(\\omega)=\\alpha f(\\omega)\\]\n역시 \\(\\mathbb{R}\\)-valued measurable function 이다.\n(해설)\n\n\\(\\alpha=0\\) 이라면, 자명하게 성립. 따라서 \\(\\alpha\\neq 0\\) 일 경우만 증명하면 된다.\n\\(B \\in {\\cal R}\\)를 고정하자.\n\\(g^{-1}(B)=f^{-1}(\\frac{1}{\\alpha}B)\\) 가 성립한다. 여기에서 \\(\\frac{1}{\\alpha}B =: \\{x: x=\\frac{y}{\\alpha}, y\\in B\\}\\).\n\\(f\\)는 \\(\\mathbb{R}\\)-valued measurable map 이므로 \\(f^{-1}(\\frac{1}{\\alpha}B) \\in {\\cal F}\\).\n임의의 \\(B\\)에 대하여 2-4의 논의가 성립하므로 \\(g\\) 역시 \\({\\cal F}-{\\cal R}\\) measurable 이다.\n\n- Thm (Durrett 2019, Thm 1.3.2): 세 개의 잴 수 있는 공간 \\((\\Omega,{\\cal F})\\), \\((S,{\\cal S})\\), \\((T,{\\cal T})\\)를 고려하자. \\(f:(\\Omega,{\\cal F}) \\to (S,{\\cal S})\\) 이고 \\(g:(S,{\\cal S}) \\to (T,{\\cal T})\\) 이면 \\(g\\circ f: (\\Omega, {\\cal F}) \\to (T,{\\cal T})\\) 이다.\n- 이론: 함수 \\(f:\\mathbb{R} \\to \\mathbb{R}\\)가 연속함수라면 \\(f:(\\mathbb{R},{\\cal R}) \\to (\\mathbb{R},{\\cal R})\\) 이다.\n(해설) – 연속함수의 정의 + (Durrett 2019, Thm 1.3.1) 를 알면 이해하기 쉬운데…\n- 이론: 두 개의 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\), \\((\\mathbb{R}, {\\cal R})\\)을 고려하자. 함수 \\(f,g\\)가 \\(\\mathbb{R}\\)-valued measurable function 이라고 하자. 아래는 모두 \\(\\mathbb{R}\\)-valued measurable function 이다.\n\n\\(h:=f+g\\)\n\\(h:=f-g\\)\n\\(h:=\\max(f,g)\\), where \\(h: \\omega \\mapsto \\max(f(\\omega),g(\\omega))\\)\n\\(h:=\\min(f,g)\\), where \\(h: \\omega \\mapsto \\min(f(\\omega),g(\\omega))\\)\n\n- 이론 (Durrett 2019, Thm 1.3.5): 두 개의 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\), \\((\\mathbb{R}, {\\cal R})\\)을 고려하자. 함수열 \\(\\{f_n: n \\in \\mathbb{N}\\}\\)의 모든 원소가 \\(\\mathbb{R}\\)-valued measurable function 이라고 하자. 그렇다면 아래는 모두 \\({\\cal F}-{\\cal R}\\) measurable 한 함수이다.\n\n\\(h:=\\inf f_n\\), where \\(h: \\omega \\mapsto \\inf\\big\\{f_1(\\omega),f_2(\\omega),\\dots \\big\\}\\)\n\\(h:=\\sup f_n\\), where \\(h: \\omega \\mapsto \\sup\\big\\{f_1(\\omega),f_2(\\omega),\\dots \\big\\}\\)"
  },
  {
    "objectID": "posts/ap/2023-05-16-ap-11wk.html#르벡적분-맛보기",
    "href": "posts/ap/2023-05-16-ap-11wk.html#르벡적분-맛보기",
    "title": "11wk: 적분 (1)",
    "section": "르벡적분 맛보기",
    "text": "르벡적분 맛보기\n- (예제1) – 사각형의 넓이\n아래와 같은 함수의 밑면적을 계산해보자.\n\\[f(x)= \\begin{cases} 1 &  0 \\leq x \\leq 1 \\\\ 0 & o.w. \\end{cases}\\]\n답은 1이다. 이것을 적분을 이용하여 구하는 과정을 서술해라.\n(서술1)\n\\[\\int_{-\\infty}^{\\infty} f(x)dx = \\int_0^1 f(x) dx = \\int_{0}^{1}dx = 1\\]\n(서술2)\n그런데 이 예제의 경우 구간 \\([0,1]\\)에서 함수 \\(f(x)\\)의 값이 모두 \\(f(x)=1\\)로 같고 그 외의 구간에서는 모두 \\(f(x)=0\\)이므로 아래와 같이 수식을 쓰는 것도 가능하다.\n\\[\\lambda([0,1]) \\times 1= 1\\]\n- (예제2) – 사각형의 넓이 (2)\n이제 아래와 같은 함수의 밑면적을 고려하자.\n\\[g(x)= \\begin{cases} 1 &  0 &lt; x &lt; 1 \\\\ 0 & o.w. \\end{cases}\\]\n이것을 적분을 이용하여 구하는 과정을 서술하고 기호를 살펴보자.\n(틀린서술)\n\\[\\int_{-\\infty}^{\\infty} g(x)dx=\\int_0^1 g(x)dx = \\int_0^1dx=1\\]\n– 틀린이유? \\(\\int_0^1\\)은 폐구간 \\([0,1]\\)를 의미함. 이러한 구간에서는 \\(g(x)\\)의 값이 일괄적으로 1이라고 주장할 수 없다.\n(서술1)\n구간 \\([0,1]\\)에서 \\(g(x)\\)의 밑면적은 구간 \\([0,1]\\)에서 \\(f(x)\\)의 밑면적과 같으므로 1이다.\n(서술2)\n이 예제의 경우 구간 \\((0,1)\\)에서 함수 \\(g(x)\\)의 값이 모두 \\(g(x)=1\\)로 같고 그 외의 구간에서는 모두 \\(g(x)=0\\)이므로 아래와 같이 수식을 쓸 수 있다.\n\\[\\lambda((0,1)) \\times 1= 1\\]\n- (예제3) – 사각형의 넓이 (3)\n이제 아래와 같은 함수 \\(f(x)\\)에 대한 밑면적을 계산하고 싶다고 생각해보자.\n\\[f(x)= \\begin{cases}\n1 & 0&lt;x&lt;1/2 \\\\\n2 & 1/2 \\leq x &lt; 1 \\\\\n\\frac{1}{3} & 1&lt;x&lt;3 \\\\\n0 & o.w\n\\end{cases}\\]\n예제1,2에서 소개한 서술1,2에 근거하여 \\(f\\)의 밑면적을 구하는 방법을 논의하라.\n(서술1)\n\\(f\\)의 밑면적 \\(S\\)를 적분으로 나타내면\n\\[S=\\int_{0}^{\\frac{1}{2}}dx + \\int_{\\frac{1}{2}}^{1} 2dx + \\int_{1}^{3} \\frac{1}{3}dx\\]\n사실 \\(\\int_{a}^{b}f(x)dx\\) 와 같은 형태는 일반적으로 함수가 \\(f\\)가 폐구간 \\([a,b]\\) 에서 정의된다고 가정하고 사용하므로 위의 기호는 정확하지 않다.\n\n\\(x=\\frac{1}{2},1,3\\)에 해당하는 영역은 중복혜서 계산된다.\n\\(x=\\frac{1}{2}\\)에 해당하는 영역은 함수값을 1로 보기도 하고 2로 보기도 한다.\n\\(x=1\\)에 해당하는 영역은 함수값을 2로 보기도 하고 3으로 보기도 한다.\n\\(x=0\\)에 해당하는 영역은 실제로는 함수값이 0이지만 계산상으로는 1로 생각한다.\n\\(x=1\\)에 해당하는 영역은 실제로는 함수값이 0이지만 계산상으로는 2 혹은 \\(\\frac{1}{3}\\)로 생각한다.\n\\(x=3\\)에 해당하는 영역은 실제로는 함수값이 0이지만 계산상으로는 \\(\\frac{1}{3}\\)로 생각한다.\n\n하지만 이러한 사소한점을 무시해도 계산결과는 여전히 \\(S\\)이다.\n(서술2)\n함수 \\(f\\)의 면적 \\(S\\)는 아래와 같이 나타낼 수 있다.\n\\[S = 1\\times \\lambda(A_1) + 2 \\times \\lambda(A_2) + \\frac{1}{3} \\lambda(A_3)\\]\n단, 여기에서 \\(A_1=(0,\\frac{1}{2}), A_2=[\\frac{1}{2},1), A_3=(1,3)\\) 이다.\n(소감)\n르벡메져를 이용하여 넓이를 정의하니까 애매한 점 없이 매우 깔끔하다. 단지 \\(A_1,A_2,A_3\\)이 르벡측도로 잴 수 있는 집합이어야 하므로 \\(A_1,A_2,A_3 \\in {\\cal R}\\) 정도만 체크해주면 될 것 같다.\n- (예제4) – 리만적분 vs 르벡적분\n이제 아래와 같은 함수 \\(f\\)의 밑면적을 계산하는 방식을 고려하여 보자.\n\\[f(x) = \\begin{cases} 1 & x \\in [0,1] \\cap \\mathbb{Q}  \\\\ 2 & x \\in [0,1] \\cap \\mathbb{Q}^c \\\\ 0 & o.w. \\end{cases}\\]\n(서술1) – 리만적분\n적분이 불가능하다. 그 이유를 엄밀하지 않게 서술하면 아래와 같다.\n\n우리가 알고 있는 “적분”이라는 것은 본래 \\(x\\)축을 잘게 쪼개서 아주 작은 구간을 만든뒤에 그 구간에서 \\(f(x)\\)의 값들이 비슷함을 이용하여 \\(f(x)\\)의 밑면적을 사각형넓이들의 합으로 근사시키는 방식이다.\n이것은 아주 작은 구간에서는 \\(f(x)\\)의 값이 다른값을 가져봤자 그 차이는 미미하고 그래서 거의 상수처럼 생각할 수 있다는 직관을 이용하는 것이다.\n일반적인 함수는 구간의 크기를 작게 만들수록 \\(f(x)\\)의 값은 점점 상수화되고 그 결과 사각형들의 합으로 근사된 넓이는 함수 \\(f\\)의 밑면적으로 수렴한다.\n그런데 이 예제의 경우 아무리 작은 구간을 잡아도 그 사이에는 수많은 유리수와 수많은 무리수가 있으므로 함수값 \\(f(x)\\)은 안정화 되지 않으며 1과 2사이를 “널뛴다.”\n따라서 적분값은 안정화되지 않는다.\n\n\n구간에서의 \\(f(x)\\)의 대표값을 양 끝점중 하나로 설정한다고 하자. 만약 구간의 양끝점을 유리수로만 설정하면 넓이는 1로 계산되고, 무리수로만 설정하면넓이는 2로 계산될 것이다.\n\n(서술2) – 르벡적분\n함수 \\(f\\)의 면적 \\(S\\)는 아래와 같이 나타낼 수 있다.\n\\[S = 1\\times \\lambda(A_1) + 2 \\times \\lambda(A_2)\\]\n단, 여기에서 \\(A_1=[0,1] \\cap \\mathbb{Q}, A_2=[0,1] \\cap \\mathbb{Q}^c\\) 이다. 집합 \\(A_1,A_2\\) 는 모두 \\({\\cal R}\\)-measurable 하므로 \\(\\lambda(A_1), \\lambda(A_2)\\)의 값이 각각 0과 1로 잘 정의된다. 따라서 \\(S=2\\)로 계산할 수 있다."
  },
  {
    "objectID": "posts/ap/2023-05-16-ap-11wk.html#그림을-통한-이해",
    "href": "posts/ap/2023-05-16-ap-11wk.html#그림을-통한-이해",
    "title": "11wk: 적분 (1)",
    "section": "그림을 통한 이해",
    "text": "그림을 통한 이해\n- 느낌: 리만적분은 정의역을 잘게 쪼개는 느낌이지만, 르벡적분은 치역을 잘게 쪼개는 느낌이다. (리만적분을 밑넓이를 세로나누어 계산하고, 르벡적분은 가로로 나누어 계산한다.)\n\n\n\n위키에서 긁은 그림: 왼쪽이 리만적분, 오른쪽이 르벡적분\n\n\n\n\n\n위키에서 긁은 그림: 위쪽이 리만적분, 아래가 르벡적분"
  },
  {
    "objectID": "posts/ap/2023-05-16-ap-11wk.html#dx-대신-dlambda를",
    "href": "posts/ap/2023-05-16-ap-11wk.html#dx-대신-dlambda를",
    "title": "11wk: 적분 (1)",
    "section": "\\(dx\\) 대신 \\(d\\lambda\\)를",
    "text": "\\(dx\\) 대신 \\(d\\lambda\\)를\n- 리만적분(\\(dx\\))과 르벡적분(\\(d\\lambda\\))를 연결하여 보자.\n- 참고: 아래와 같은 함수 \\(f(x)\\)를 고려하자.\n\\[f(x) = \\begin{cases} \\alpha & x \\in [0,1]  \\\\  o.w \\end{cases}\\]\n그리고 \\(\\lambda\\)를 르벡메져라고 하자. 아래는 모두 같은 표현이다.\n\n\\(\\int_{-\\infty}^{\\infty} f(x) dx\\)\n\\(\\int_0^1f(x)dx\\)\n\\(\\int_0^1 \\alpha dx\\)\n\\(\\alpha \\int_0^1 dx\\)\n\\(\\alpha\\lambda(A)\\)\n\\(\\alpha\\int_{A}d\\lambda\\)\n\\(\\int_{A}\\alpha d\\lambda\\)\n\\(\\int_{A}f d\\lambda\\)\n\\(\\int f d\\lambda\\)"
  },
  {
    "objectID": "posts/ap/2023-05-16-ap-11wk.html#dlambda-대신-dmu를",
    "href": "posts/ap/2023-05-16-ap-11wk.html#dlambda-대신-dmu를",
    "title": "11wk: 적분 (1)",
    "section": "\\(d\\lambda\\) 대신 \\(d\\mu\\)를",
    "text": "\\(d\\lambda\\) 대신 \\(d\\mu\\)를\n- 위의 표현들에서 \\(d\\lambda\\)와 같은 표현은 르벡메져가 아닌 일반적인 메져에서도 표현가능하다. 만약 가측공간 \\((\\mathbb{R},{\\cal R})\\)에 아래와 같은 메져 \\(\\nu\\)가 존재한다고 하자.\n\\[\\nu = 2\\lambda\\]\n여기에서 \\(\\lambda\\)는 르벡메져이다. 그렇다면, 임의의 \\(A \\in {\\cal R}\\)에 대하여 아래가 성립한다.\n\\[\\int_A d\\nu = 2\\int_A d\\lambda \\]"
  },
  {
    "objectID": "posts/ap/2023-05-16-ap-11wk.html#모든-곳에서-거의-모든-곳에서",
    "href": "posts/ap/2023-05-16-ap-11wk.html#모든-곳에서-거의-모든-곳에서",
    "title": "11wk: 적분 (1)",
    "section": "모든 곳에서, 거의 모든 곳에서",
    "text": "모든 곳에서, 거의 모든 곳에서\n- 르벡측도 0인 곳을 제외하고는 어떠한 명제가 성립할때 거의 모든 곳에서 라는 수식어를 붙인다. 영어로는 almost everywhere 라고 하며 기호로는 a.e. 라고 표현한다.\n- 예시1: 아래와 같은 함수 \\(f\\)를 고려하자.\n\\[f(x) = \\begin{cases} 1 & x\\in \\mathbb{Q} \\\\ 0 & x\\in \\mathbb{R}-\\mathbb{Q} \\end{cases}\\]\n이 함수는 거의 모든 곳에서 0이다.\n\n기호로는 \\(f \\overset{a.e.}{=} 0\\) 혹은 \\(f \\overset{a.e.}{=} 0\\) w.r.t. \\(\\lambda\\) 와 같이 표현한다.\n\n- 예시2: 아래와 같은 함수 \\(f,g\\)를 고려하자.\n\\[f(x) = \\begin{cases} 1 & x\\in \\mathbb{Q} \\\\ 0 & x\\in \\mathbb{R}-\\mathbb{Q} \\end{cases}\\]\n\\[g(x) = \\begin{cases} 2 & x\\in \\mathbb{Q} \\\\ 0 & x \\in \\mathbb{R}-\\mathbb{Q} \\end{cases}\\]\n함수 \\(f\\)와 \\(g\\)는 거의 모든 곳에서 같다.\n\n기호로는 \\(f\\overset{a.e.}{=} g\\) 혹은 \\(f\\overset{a.e.}{=} g\\) w.r.t. \\(\\lambda\\) 와 같이 표현한다.\n\n- 예시3: 아래와 같은 함수 \\(f,g\\)를 고려하자.\n\\[f(x) = \\begin{cases} 0 & x\\in \\mathbb{Q} \\\\ 1 & x\\in \\mathbb{R}-\\mathbb{Q} \\end{cases}\\]\n함수 \\(f\\)는 거의 모든 곳에서 양수이다.\n\n기호로는 \\(f\\overset{a.e.}{&gt;} 0\\) 혹은 \\(f\\overset{a.e.}{&gt;} g\\) w.r.t. \\(\\lambda\\) 와 같이 표현한다.\n\n- 예시4: 아래와 같은 함수 \\(f,g\\)를 고려하자.\n\\[f(x) = \\begin{cases} 0 & x\\in \\mathbb{Q} \\\\ 1 & x\\in \\mathbb{R}-\\mathbb{Q} \\end{cases}\\]\n\\[g(x) = \\begin{cases} 0 & x\\in \\mathbb{Q} \\\\ 2 & x \\in \\mathbb{R}-\\mathbb{Q} \\end{cases}\\]\n함수 \\(f\\)는 거의 모든 곳에서 \\(g\\)보다 작다.\n\n기호로는 \\(f\\overset{a.e.}{&lt;} g\\) 혹은 \\(f\\overset{a.e.}{&lt;} g\\) w.r.t. \\(\\lambda\\) 와 같이 표현한다.\n\n- 예시4: 만약에 아래와 같은 함수 \\(f,g\\)가 있다면\n\\[f(x) = \\begin{cases} 1 & x\\in \\mathbb{Q} \\\\ 0 & x\\in \\mathbb{R}-\\mathbb{Q} \\end{cases}\\]\n\\[g(x) = \\begin{cases} 1 & x\\in \\mathbb{Q} \\\\ 0 & x \\in \\mathbb{R}-\\mathbb{Q} \\end{cases}\\]\n함수 \\(f\\)와 \\(g\\)는 모든 곳에서 같다라고 할 수 있겠다. (보통 그냥 같다라고 하죠..)"
  },
  {
    "objectID": "posts/ap/2023-04-13-7wk-1.html",
    "href": "posts/ap/2023-04-13-7wk-1.html",
    "title": "07wk-1: 마코프체인 (2)",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-wi47mCKi03xoqvwIzkxG0H\n\n\n\nimport\n\nimport numpy as np\n\n\n\n확률과정\n- 동전을 무한히 던지는 시행을 생각하자. 동전을 10번 던져서 결과를 관찰했다고 하자. 동전을 30번째 던져서 앞면이 나올지 뒷면이 나올지 알고 싶다면?\n- 현재 삼성전자 주가는 66000이다. 20일뒤의 삼성전자 주가가 얼마일지 알고 싶다면?\n- 원래 미래를 예측하기 위해서 해야하는 과정\n\n\n\n그림1: 1400만개의 미래를 탐색중인 Doctor Strange\n\n\n- 하지만 현실적으로는 이게 너무 힘들지 않을까?\n\n\n날씨예측\n- 아래와 같이 세상의 법칙이 있다고 하자.\n\n어제 맑음 \\(\\to\\) 오늘도 맑음: 40% // 오늘은 비: 60%\n어제 비 \\(\\to\\) 오늘은 맑음: 70% // 오늘도 비 30%\n\n- 모든 \\(t\\)에 대하여 확률변수 \\(X_t\\)를 아래와 같이 정의하자.\n\n\\(X_t=\\begin{cases} 0 & \\text{맑음} \\\\ 1 & \\text{비} \\end{cases}\\)\n\n- 오늘 (2023년4월13일) 비가 왔다고 치자. 10000일 뒤에도 비가 올 확률은 얼마일까?\n\n\n풀이1\n- \\(X_t=0\\) 이라면? (\\(t\\)시점에 비가 오지 않았다면?)\n\nnp.random.rand() &lt; 0.6 \n\nFalse\n\n\n- \\(X_t=1\\) 이라면? (\\(t\\)시점에 비가 왔다면?)\n\nnp.random.rand(0) &lt; 0.3\n\narray([], dtype=bool)\n\n\n- 두 코드를 합쳐보자.\n\ndef rain(before):\n    if before == True: # 비가 왔음 \n        after = np.random.rand() &lt; 0.3\n    else: # 비가 안왔음 \n        after = np.random.rand() &lt; 0.6 \n    return after \n\n- 테스트\n\n# 비가 왔음, Xt = 1 \nsum([rain(1) for i in range(100)])\n\n30\n\n\n\n# 비가 안왔음, Xt = 0 \nsum([rain(0) for i in range(100)])\n\n60\n\n\n- 하나의 \\(\\omega\\)에 대응하는 길이가 10000인 확률과정을 관찰\n\ndef doctor_strange(today):\n    lst = [today]\n    for i in range(10000): \n        lst.append(rain(lst[i]))\n    return lst \n\n\ntoday = True # 오늘 비가 왔다는 뜻 \narr = doctor_strange(today)\n\n\nlen(arr)\n\n10001\n\n\n- 4305개의 \\(\\omega\\)에 대응하는 길이가 10000인 확률과정을 관찰\n\ntoday = True # 오늘 비가 왔다는 뜻 \narr = np.array([doctor_strange(today) for ω in range(4305)])\n\n\narr[:,-1].mean()\n\n0.4662020905923345\n\n\n- 10000일 뒤에도 비가 올 확률은 약 46% 정도 인듯\n\n\n풀이2\n- 세상의 법칙을 다시 정리해보자.\n\n\\(X_{t-1}=0 \\Rightarrow X_t \\sim Ber(0.6)\\)\n\\(X_{t-1}=1 \\Rightarrow X_t \\sim Ber(0.3)\\)\n\n- 정리하면\n\n\\(P(X_t=0)= P(X_{t-1}=0) \\times 0.4 + P(X_{t-1}=1) \\times 0.7\\)\n\\(P(X_t=1)= P(X_{t-1}=0) \\times 0.6 + P(X_{t-1}=1) \\times 0.3\\)\n\n- 매트릭스형태로 표현하면\n\n\\(\\begin{bmatrix} P(X_t=0) \\\\ P(X_t=1) \\end{bmatrix}= \\begin{bmatrix} 0.4 & 0.7 \\\\ 0.6 & 0.3 \\end{bmatrix} \\begin{bmatrix} P(X_{t-1}=0) \\\\ P(X_{t-1}=1) \\end{bmatrix}\\)\n\\({\\boldsymbol \\mu}_t = {\\bf P} {\\boldsymbol \\mu}_{t-1}\\)\n\n- 이렇게 놓고 보니까\n\n\\({\\boldsymbol \\mu}_1 ={\\bf P}{\\boldsymbol \\mu}_0\\)\n\\({\\boldsymbol \\mu}_2 ={\\bf P}{\\boldsymbol \\mu}_1={\\bf P}^2{\\boldsymbol \\mu}_0\\)\n\\(\\dots\\)\n\\({\\boldsymbol \\mu}_{10000} ={\\bf P}^{10000}{\\boldsymbol \\mu}_0\\)\n\n- 이제 계산을 해보자.\n\nμ0 = np.array([[0],[1]])\nμ0\n\narray([[0],\n       [1]])\n\n\n\nP = np.array([[0.4,0.7],[0.6,0.3]])\nP\n\narray([[0.4, 0.7],\n       [0.6, 0.3]])\n\n\n\nP@P # P의 제곱\n\narray([[0.58, 0.49],\n       [0.42, 0.51]])\n\n\n\nP@P@P@P # P의 4제곱\n\narray([[0.5422, 0.5341],\n       [0.4578, 0.4659]])\n\n\n\nP@P@P@P @ P@P@P@P # P의 8제곱 \n\narray([[0.53849182, 0.53842621],\n       [0.46150818, 0.46157379]])\n\n\n\nP@P@P@P@P@P@P@P @ P@P@P@P@P@P@P@P # P의 16제곱 \n\narray([[0.53846154, 0.53846154],\n       [0.46153846, 0.46153846]])\n\n\n\\({\\bf P}\\)가 수렴하는거 같지 않어?\n\nP@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P @ P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P \n\narray([[0.53846154, 0.53846154],\n       [0.46153846, 0.46153846]])\n\n\n대충 \\({\\bf P}^{10000} \\approx {\\bf P}^{32}\\)\n\nPlim = P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P @ P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P \nPlim \n\narray([[0.53846154, 0.53846154],\n       [0.46153846, 0.46153846]])\n\n\n\nPlim @ μ0\n\narray([[0.53846154],\n       [0.46153846]])\n\n\n- 이 풀이에 따르면 10000일 뒤에 비가 올 확률은 46% 정도이다.\n\n\n풀이3\n- 세상의 법칙을 다시 정리해보자.\n\n\\(X_{t-1}=0 \\Rightarrow X_t \\sim Ber(0.6)\\)\n\\(X_{t-1}=1 \\Rightarrow X_t \\sim Ber(0.3)\\)\n\n- 추측: 10000일 뒤에 비가 올 확률이 \\(p\\)라고 치자. 그렇다면 9999일 뒤에 비가 올 확률도 \\(p\\) 아닐까?\n이걸 가정하고 계산해보자\n1. 9999일 뒤에 비가 안 올 확률 \\(1-p\\)\n\n9999일 뒤에 비가 안오고, 10000일 뒤에는 비가 올 확률: \\(0.6(1-p)\\)\n9999일 뒤에 비가 안오고, 10000일 뒤에는 비가 안 올 확률: \\(0.4(1-p)\\)\n\n2. 9999일 뒤에 비가 올 확률 \\(p\\)\n\n9999일 뒤에 비가 오고, 10000일 뒤에도 비가 올 확률: \\(0.3p\\)\n9999일 뒤에 비가 오고, 10000일 뒤에는 비가 안 올 확률: \\(0.7p\\)\n\n따라서 \\(0.6(1-p) + 0.3p = p\\)\n풀어보면 \\(0.6/1.3 =p\\)\n\n0.6/1.3\n\n0.4615384615384615\n\n\n\n\n풀이4\n\nnp.mean(doctor_strange(True)[1:])\n\n0.462"
  },
  {
    "objectID": "posts/ap/2023-06-08-15wk-1.html",
    "href": "posts/ap/2023-06-08-15wk-1.html",
    "title": "15wk-1: MCMC (3)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport copy"
  },
  {
    "objectID": "posts/ap/2023-06-08-15wk-1.html#단계1-아무값이나-넣어서-boldsymbol-theta_0를-초기화한다.",
    "href": "posts/ap/2023-06-08-15wk-1.html#단계1-아무값이나-넣어서-boldsymbol-theta_0를-초기화한다.",
    "title": "15wk-1: MCMC (3)",
    "section": "단계1: 아무값이나 넣어서 \\({\\boldsymbol \\theta}_0\\)를 초기화한다.",
    "text": "단계1: 아무값이나 넣어서 \\({\\boldsymbol \\theta}_0\\)를 초기화한다.\n- \\({\\boldsymbol \\theta}_0=(\\theta_0[0],\\dots,\\theta_0[5])\\)를 아무값이나 셋팅\n\nθ = {\n    'doc1':[2,1],\n    'doc2':[1,2],\n    'doc3':[2,1]\n}\n\n\n\\({\\boldsymbol \\theta}_0 = [2,1,1,2,2,1]\\) 이라고 생각하자.\n\n- 임의의 초기값이 셋팅된 상황은 아래와 같다.\n\n\nTable 3: 초기상태요약\n\n\n\n\n(a) \\(D\\): 코퍼스(=관찰한자료)\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n손흥민\n골\n확률\n\n\n골\n확률\n데이터과학\n\n\n\n\n\n\n(b) \\({\\boldsymbol \\theta}_t\\): 임의의 초기값으로 설정된 토픽\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n2 (=\\(\\theta_0[0]\\))\n1 (=\\(\\theta_0[2]\\))\n2 (=\\(\\theta_0[4]\\))\n\n\n1 (=\\(\\theta_0[1]\\))\n2 (=\\(\\theta_0[3]\\))\n1 (=\\(\\theta_0[5]\\))\n\n\n\n\n\n\n\n\n(c) 토픽별로 등장하는 단어\n\n\n\n\n\n\ntopic\nwords\n\n\n\n\n1\n골, 골, 데이터과학\n\n\n2\n손흥민, 확률, 확률"
  },
  {
    "objectID": "posts/ap/2023-06-08-15wk-1.html#단계2-boldsymbol-theta_00-boldsymbol-theta_01-cdots-boldsymbol-theta_05-을-순서대로-샘플링",
    "href": "posts/ap/2023-06-08-15wk-1.html#단계2-boldsymbol-theta_00-boldsymbol-theta_01-cdots-boldsymbol-theta_05-을-순서대로-샘플링",
    "title": "15wk-1: MCMC (3)",
    "section": "단계2: \\({\\boldsymbol \\theta}_0[0], {\\boldsymbol \\theta}_0[1] \\cdots, {\\boldsymbol \\theta}_0[5]\\) 을 순서대로 샘플링",
    "text": "단계2: \\({\\boldsymbol \\theta}_0[0], {\\boldsymbol \\theta}_0[1] \\cdots, {\\boldsymbol \\theta}_0[5]\\) 을 순서대로 샘플링\n- 예비개념: MCMC에서 베타분포를 뽑았던 예제로 돌아가보자\n\n임의의 초기값 \\(x\\) 생성\n새로운 값으로 \\(y\\)를 고려 (추천받을 수도 있고 그냥 고려할수도 있음)\n\\(x\\)가 그럴듯한지, \\(y\\)가 그럴듯한지 판단하고 \\(x'\\)의 값은 어떠한확률로 \\(x,y\\) 중에서 선택\n\n- 전략: 그동안 pmf 혹은 pdf의 정보가 필요했던 것은 “그럴듯한 정도” 를 판단할 기준을 얻기 위해서였다. 그런데 만약, “그럴듯한 정도”를 판단하는 기준을 pmf, pdf 로 정하지 않는다면? pmf 혹은 pdf 가 필요하지 않다.\n\nstage0: \\({\\boldsymbol \\theta}_0[0]\\)을 sampling\n- 현재상태\n\n빨간색/볼드: 지금 focus하는 것\n\n\n\nTable 4: \\(t=0\\), \\(d={\\tt doc1}\\), \\(w={\\tt 손흥민}\\)\n\n\n\n\n(a) \\(D\\): 코퍼스(=관찰한자료)\n\n\n\n\n\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n손흥민\n골\n확률\n\n\n골\n확률\n데이터과학\n\n\n\n\n\n\n(b) \\({\\boldsymbol \\theta}_t\\): 추정된 토픽\n\n\n\n\n\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n 2 (=\\(\\theta_0[0]\\))\n1 (=\\(\\theta_0[2]\\))\n2 (=\\(\\theta_0[4]\\))\n\n\n1 (=\\(\\theta_0[1]\\))\n2 (=\\(\\theta_0[3]\\))\n1 (=\\(\\theta_0[5]\\))\n\n\n\n\n\n\n\n\n(c) 토픽별로 등장하는 단어\n\n\n\n\n\n\ntopic\nwords\n\n\n\n\n1\n골, 골, 데이터과학\n\n\n2\n손흥민, 확률, 확률\n\n\n\n\n\n\n(d) \\(\\theta_0[0]\\)의 고민 = 나는 토픽1인가 토픽2인가?\n\n\n\n\n\n\n\n\n관찰\n결론\n\n\n\n\n문서눈치\n문서안에서 나말고 다른 단어는 토픽1으로 분류되어있음\n나도 토픽1인듯\n\n\n토픽눈치\n토픽1에도, 토픽2에도 나랑 같은 단어는 없음\n난 토픽1도 2도 아닌듯\n\n\n\n\n\n\n- \\(\\theta_0[0]\\)이 토픽1에서 뽑혓다고 보는게 타당한지 토픽1에서 뽑혔다고 보는게 타당하지 아래와 같이 따져보자.\n\n토픽1의 타당성: (doc1에 토픽1이 포함된 비율) \\(\\times\\) (토픽1에서 손흥민이라는 단어가 포함된 비율) = 1 \\(\\times\\) 0\n토픽2의 타당성: (doc1에 토픽2가 포함된 비율) \\(\\times\\) (토픽2에서 손흥민이라는 단어가 포함된 비율) = 0 \\(\\times\\) 0\n\n\n둘 다 \\(0\\) 이라서 비긴거야?? 그런데 그래도 토픽1가 그나마 타당한거아냐?\n\n- 수정된 타당성\n\n토픽1의 타당성: (doc1에 토픽1이 포함된 비율) \\(\\times\\) (토픽1에서 손흥민이라는 단어가 포함된 비율) = 1 \\(\\times\\) 0.001\n토픽2의 타당성: (doc1에 토픽2가 포함된 비율) \\(\\times\\) (토픽2에서 손흥민이라는 단어가 포함된 비율) = 0.001 \\(\\times\\) 0.001\n\n\n\\(\\theta_0[0]\\)의 생각: 나는 토픽1인듯해\n\n- 업데이트\n\nθ['doc1'][0]\n\n2\n\n\n\nθ['doc1'][0] = 1\n\n\n\nstage1: \\({\\boldsymbol \\theta}_0[1]\\)을 sampling\n- 현재상태\n\n빨간색/볼드: 지금 focus하는 것\n파란색/볼드: 과거 / 업데이트O\n\n\n\nTable 5: \\(t=0\\), \\(d={\\tt doc1}\\), \\(w={\\tt 골}\\)\n\n\n\n\n(a) \\(D\\): 코퍼스(=관찰한자료)\n\n\n\n\n\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n손흥민\n골\n확률\n\n\n골\n확률\n데이터과학\n\n\n\n\n\n\n(b) \\({\\boldsymbol \\theta}_t\\): 추정된 토픽\n\n\n\n\n\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n 1 (=\\(\\theta_1[0]\\))1\n1 (=\\(\\theta_0[2]\\))\n2 (=\\(\\theta_0[4]\\))\n\n\n 1 (=\\(\\theta_0[1]\\))\n2 (=\\(\\theta_0[3]\\))\n1 (=\\(\\theta_0[5]\\))\n\n\n\n\n\n\n\n\n(c) 토픽별로 등장하는 단어\n\n\n\n\n\n\ntopic\nwords\n\n\n\n\n1\n골, 골, 데이터과학, 손흥민2\n\n\n2\n확률, 확률\n\n\n\n\n\n\n(d) \\(\\theta_0[1]\\)의 고민 = 나는 토픽1인가 토픽2인가?\n\n\n\n\n\n\n\n\n관찰\n결론\n\n\n\n\n문서눈치\n문서안에서 나말고 다른 단어는 토픽1으로 분류되어있음\n나도 토픽1인듯\n\n\n토픽눈치\n토픽1에는 나랑 같은 단어가 있는데 토픽2에는 없음\n나도 토픽1인듯\n\n\n\n\n\n\n- 수정된 타당성\n\n토픽1의 타당성: (doc1에 토픽1이 포함된 비율) \\(\\times\\) (토픽1에서 골이라는 단어가 포함된 비율) = 1 \\(\\times\\) 1/3\n토픽2의 타당성: (doc1에 토픽2가 포함된 비율) \\(\\times\\) (토픽2에서 골이라는 단어가 포함된 비율) = 0.001 \\(\\times\\) 0.001\n\n\n\\(\\theta_0[1]\\)의 생각: 나는 토픽1인듯해\n\n- 업데이트: 안함.. 난 토픽1이 맞는것 같음\n\n\nstage2: \\({\\boldsymbol \\theta}_0[2]\\)을 sampling\n- 현재상태\n\n빨간색/볼드: 지금 focus하는 것\n파란색/볼드: 과거 / 업데이트O\n파란색/볼드X: 과거 / 업데이트X\n\n\n\nTable 6: \\(t=0\\), \\(d={\\tt doc2}\\), \\(w={\\tt 골}\\)\n\n\n\n\n(a) \\(D\\): 코퍼스(=관찰한자료)\n\n\n\n\n\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n손흥민\n골\n확률\n\n\n골\n확률\n데이터과학\n\n\n\n\n\n\n(b) \\({\\boldsymbol \\theta}_t\\): 추정된 토픽\n\n\n\n\n\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n 1 (=\\(\\theta_1[0]\\))3\n 1 (=\\(\\theta_0[2]\\)) \n2 (=\\(\\theta_0[4]\\))\n\n\n 1 (=\\(\\theta_1[1]\\))\n2 (=\\(\\theta_0[3]\\))\n1 (=\\(\\theta_0[5]\\))\n\n\n\n\n\n\n\n\n(c) 토픽별로 등장하는 단어\n\n\n\n\n\n\ntopic\nwords\n\n\n\n\n1\n골, 골, 데이터과학, 손흥민4\n\n\n2\n확률, 확률\n\n\n\n\n\n\n(d) \\(\\theta_0[2]\\)의 고민 = 나는 토픽1인가 토픽2인가?\n\n\n\n\n\n\n\n\n관찰\n결론\n\n\n\n\n문서눈치\n문서안에서 나말고 다른 단어는 토픽2로 분류되어있음\n나도 토픽2인듯\n\n\n토픽눈치\n토픽1에는 나랑 같은 단어가 있는데 토픽2에는 없음\n나도 토픽1인듯\n\n\n\n\n\n\n- 수정된 타당성\n\n토픽1의 타당성: (doc2에 토픽1이 포함된 비율) \\(\\times\\) (토픽1에서 골이라는 단어가 포함된 비율) = 0.001 \\(\\times\\) 1/3\n토픽2의 타당성: (doc2에 토픽2가 포함된 비율) \\(\\times\\) (토픽2에서 골이라는 단어가 포함된 비율) = 1 \\(\\times\\) 0.001\n\n\n\\(\\theta_0[2]\\)의 생각: 나는 토픽2인듯함 (그런데 아닐 수도 있음)\n\n- 업데이트\n\nθ['doc2'][0]\n\n1\n\n\n\nθ['doc2'][0] = 2\n\n\n\nstage3: \\({\\boldsymbol \\theta}_0[3]\\)을 sampling\n- 현재상태\n\n빨간색/볼드: 지금 focus하는 것\n파란색/볼드: 과거 / 업데이트O\n파란색/볼드X: 과거 / 업데이트X\n\n\n\nTable 7: \\(t=0\\), \\(d={\\tt doc2}\\), \\(w={\\tt 확률}\\)\n\n\n\n\n(a) \\(D\\): 코퍼스(=관찰한자료)\n\n\n\n\n\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n손흥민\n골\n확률\n\n\n골\n확률\n데이터과학\n\n\n\n\n\n\n(b) \\({\\boldsymbol \\theta}_t\\): 추정된 토픽\n\n\n\n\n\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n 1 (=\\(\\theta_1[0]\\))5\n 2 (=\\(\\theta_1[2]\\)) 6\n2 (=\\(\\theta_0[4]\\))\n\n\n 1 (=\\(\\theta_1[1]\\))\n 2 (=\\(\\theta_0[3]\\))\n1 (=\\(\\theta_0[5]\\))\n\n\n\n\n\n\n\n\n(c) 토픽별로 등장하는 단어\n\n\n\n\n\n\ntopic\nwords\n\n\n\n\n1\n골, 데이터과학, 손흥민7\n\n\n2\n확률, 확률, 골8\n\n\n\n\n\n\n(d) \\(\\theta_0[3]\\)의 고민 = 나는 토픽1인가 토픽2인가?\n\n\n\n\n\n\n\n\n관찰\n결론\n\n\n\n\n문서눈치\n문서안에서 나말고 다른 단어는 토픽2로 분류되어있음\n나도 토픽2인듯\n\n\n토픽눈치\n토픽1에는 나랑 같은 단어가 없는데 토픽2에는 있음\n나도 토픽2인듯\n\n\n\n\n\n\n- 수정된 타당성\n\n토픽1의 타당성: (doc2에 토픽1이 포함된 비율) \\(\\times\\) (토픽1에서 확률이라는 단어가 포함된 비율) = 0.001 \\(\\times\\) 0.001\n토픽2의 타당성: (doc2에 토픽2가 포함된 비율) \\(\\times\\) (토픽2에서 확률이라는 단어가 포함된 비율) = 1 \\(\\times\\) 1/2\n\n\n\\(\\theta_0[3]\\)의 생각: 나는 토픽2인듯함\n\n- 업데이트: 안함. 난 토픽2가 확실한듯\n\n\nstage4: \\({\\boldsymbol \\theta}_0[4]\\)을 sampling\n- 현재상태\n\n빨간색/볼드: 지금 focus하는 것\n파란색/볼드: 과거 / 업데이트O\n파란색/볼드X: 과거 / 업데이트X\n\n\n\nTable 8: \\(t=0\\), \\(d={\\tt doc3}\\), \\(w={\\tt 확률}\\)\n\n\n\n\n(a) \\(D\\): 코퍼스(=관찰한자료)\n\n\n\n\n\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n손흥민\n골\n확률\n\n\n골\n확률\n데이터과학\n\n\n\n\n\n\n(b) \\({\\boldsymbol \\theta}_t\\): 추정된 토픽\n\n\n\n\n\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n 1 (=\\(\\theta_1[0]\\))9\n 2 (=\\(\\theta_1[2]\\)) 10\n2 (=\\(\\theta_0[4]\\))\n\n\n 1 (=\\(\\theta_1[1]\\))\n 2 (=\\(\\theta_1[3]\\))\n1 (=\\(\\theta_0[5]\\))\n\n\n\n\n\n\n\n\n(c) 토픽별로 등장하는 단어\n\n\n\n\n\n\ntopic\nwords\n\n\n\n\n1\n골, 데이터과학, 손흥민11\n\n\n2\n확률, 확률, 골12\n\n\n\n\n\n\n(d) \\(\\theta_0[4]\\)의 고민 = 나는 토픽1인가 토픽2인가?\n\n\n\n\n\n\n\n\n관찰\n결론\n\n\n\n\n문서눈치\n문서안에서 나말고 다른 단어는 토픽1로 분류되어있음\n나도 토픽1인듯\n\n\n토픽눈치\n토픽1에는 나랑 같은 단어가 없는데 토픽2에는 있음\n나도 토픽2인듯\n\n\n\n\n\n\n- 수정된 타당성\n\n토픽1의 타당성: (doc3에 토픽1이 포함된 비율) \\(\\times\\) (토픽1에서 확률이라는 단어가 포함된 비율) = 1 \\(\\times\\) 0.001\n토픽2의 타당성: (doc3에 토픽2가 포함된 비율) \\(\\times\\) (토픽2에서 확률이라는 단어가 포함된 비율) = 0.001 \\(\\times\\) 1/2\n\n\n\\(\\theta_0[4]\\)의 생각: 나는 토픽1인듯함 (그런데 아닐수도 있음)\n\n- 업데이트: 안함. 난 토픽1인것 같긴한데, 확실하지 않아서 그냥 토픽2에 머무르겠음.\n\n\nstage5: \\({\\boldsymbol \\theta}_0[5]\\)을 sampling\n- 현재상태\n\n빨간색/볼드: 지금 focus하는 것\n파란색/볼드: 과거 / 업데이트O\n파란색/볼드X: 과거 / 업데이트X\n\n\n\nTable 9: \\(t=0\\), \\(d={\\tt doc3}\\), \\(w={\\tt 데이터과학}\\)\n\n\n\n\n(a) \\(D\\): 코퍼스(=관찰한자료)\n\n\n\n\n\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n손흥민\n골\n확률\n\n\n골\n확률\n데이터과학\n\n\n\n\n\n\n(b) \\({\\boldsymbol \\theta}_t\\): 추정된 토픽\n\n\n\n\n\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n 1 (=\\(\\theta_1[0]\\))13\n 2 (=\\(\\theta_1[2]\\)) 14\n2 (=\\(\\theta_1[4]\\))15\n\n\n 1 (=\\(\\theta_1[1]\\))\n 2 (=\\(\\theta_1[3]\\))\n1 (=\\(\\theta_0[5]\\))\n\n\n\n\n\n\n\n\n(c) 토픽별로 등장하는 단어\n\n\n\n\n\n\ntopic\nwords\n\n\n\n\n1\n골, 데이터과학, 손흥민16\n\n\n2\n확률, 확률17, 골18\n\n\n\n\n\n\n(d) \\(\\theta_0[5]\\)의 고민 = 나는 토픽1인가 토픽2인가?\n\n\n\n\n\n\n\n\n관찰\n결론\n\n\n\n\n문서눈치\n문서안에서 나말고 다른 단어는 토픽2로 분류되어있음\n나도 토픽2인듯\n\n\n토픽눈치\n토픽1에도, 토픽2에도 나랑 같은 단어는 없음\n나는 토픽1도 토픽2도 아닌듯\n\n\n\n\n\n\n- 수정된 타당성\n\n토픽1의 타당성: (doc3에 토픽1이 포함된 비율) \\(\\times\\) (토픽1에서 데이터과학이라는 단어가 포함된 비율) = 0.001 \\(\\times\\) 0.001\n토픽2의 타당성: (doc3에 토픽2가 포함된 비율) \\(\\times\\) (토픽2에서 데이터과학이라는 단어가 포함된 비율) = 1 \\(\\times\\) 0.001\n\n\n\\(\\theta_0[5]\\)의 생각: 나는 토픽1인듯함 (그런데 아닐수도 있음)\n\n- 업데이트: 난 토픽2가 확실한듯\n\nθ['doc3'][1]\n\n1\n\n\n\nθ['doc3'][1] = 2"
  },
  {
    "objectID": "posts/ap/2023-06-08-15wk-1.html#단계3-t1234dots-에-대하여-단계2를-반복",
    "href": "posts/ap/2023-06-08-15wk-1.html#단계3-t1234dots-에-대하여-단계2를-반복",
    "title": "15wk-1: MCMC (3)",
    "section": "단계3: \\(t=1,2,3,4,\\dots\\) 에 대하여 단계2를 반복",
    "text": "단계3: \\(t=1,2,3,4,\\dots\\) 에 대하여 단계2를 반복\n\nθ\n\n{'doc1': [1, 1], 'doc2': [2, 2], 'doc3': [2, 2]}\n\n\n- 초기상태와 지금을 비교하면 아래와 같다.\n\n\nTable 10: 수정된 상태\n\n\n\n\n(a) \\({\\boldsymbol \\pi}\\)\n\n\n\n\n\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n\\(\\begin{bmatrix}0.9\\\\0.1\\end{bmatrix}\\)\n\\(\\begin{bmatrix}0.8\\\\0.2\\end{bmatrix}\\)\n\\(\\begin{bmatrix}0.3\\\\0.7\\end{bmatrix}\\)\n\n\n\\(\\begin{bmatrix}0.8\\\\0.2\\end{bmatrix}\\)\n\\(\\begin{bmatrix}0.3\\\\0.7\\end{bmatrix}\\)\n\\(\\begin{bmatrix}0.05\\\\0.95\\end{bmatrix}\\)\n\n\n\n\n\n\n(b) \\({\\boldsymbol \\theta}_0\\)\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n2\n1\n2\n\n\n1\n2\n1\n\n\n\n\n\n\n(c) \\({\\boldsymbol \\theta}_1\\)\n\n\ndoc1\ndoc2\ndoc3\n\n\n\n\n1\n219\n220\n\n\n1\n2\n2\n\n\n\n\n\n\n- \\(t=1,2,3,4\\dots\\)로 진행하다보면 서로 눈치를 보면서 아래와 같은 원리로 이동한다.\n\n문서눈치: 내가 토픽k 라면, 내가 속한 문서에는 토픽k로 분류된 단어가 많을거야.\n토픽눈치: 내가 토픽k 라면, 토픽k에는 나랑 같은 단어가 많을거야."
  },
  {
    "objectID": "posts/ap/2023-06-08-15wk-1.html#구현에-필요한-예비학습",
    "href": "posts/ap/2023-06-08-15wk-1.html#구현에-필요한-예비학습",
    "title": "15wk-1: MCMC (3)",
    "section": "구현에 필요한 예비학습",
    "text": "구현에 필요한 예비학습\n\nenumerate\n\nfor i in 'abc':\n    print(i)\n\na\nb\nc\n\n\n\nfor i in enumerate('abc'):\n    print(i)\n\n(0, 'a')\n(1, 'b')\n(2, 'c')\n\n\n\nfor i,s in enumerate('abc'):\n    print(i,s)\n\n0 a\n1 b\n2 c\n\n\n\nfor i,s in enumerate('abc'):\n    print(s*(i+1))\n\na\nbb\nccc\n\n\n\n\nnp.random.choice\n\nnp.random.choice([10,100,1000],size=50)\n\narray([1000, 1000,   10,  100,  100, 1000,  100,  100,   10, 1000,   10,\n       1000,  100,   10, 1000,  100,   10,  100,  100, 1000, 1000,   10,\n       1000, 1000,   10, 1000, 1000,  100, 1000, 1000, 1000, 1000, 1000,\n        100,   10, 1000,   10, 1000,   10,   10, 1000,  100,   10, 1000,\n        100,  100, 1000,   10,  100,  100])\n\n\n\nnp.random.choice([10,100,1000],size=50,p=[0.8,0.1,0.1])\n\narray([  10,   10,   10,   10,   10,   10,   10,   10,  100,   10, 1000,\n         10,   10,  100,   10,   10,   10,   10,   10,   10,   10,   10,\n         10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,\n         10,   10,   10,   10,   10,   10, 1000,   10,   10,   10,   10,\n         10,   10,   10,   10,   10,   10])\n\n\n\n\n딕셔너리의 해체\n- 아래와 같은 딕셔너리를 고려하자.\n\nD = {'doc1':['손흥민','골'],\n     'doc2':['골','확률'],\n     'doc3':['확률','데이터과학']}\nθ = {'doc1':[2,1],\n     'doc2':[1,2],\n     'doc3':[2,1]}\n\n- 이러한 딕셔너리에를 해체하고 싶다면?\n\n[wrd for doc in D for wrd in D[doc]]\n\n['손흥민', '골', '골', '확률', '확률', '데이터과학']\n\n\n\n[tpc for doc in θ for tpc in θ[doc]]\n\n[2, 1, 1, 2, 2, 1]\n\n\n\n\n리스트의 count 메소드\n\nlst = list('asdfsdasdfasdfasdfasdfas')\nlst.count('a')\n\n6\n\n\n\n[wrd for doc in D for wrd in D[doc]]\n\n['손흥민', '골', '골', '확률', '확률', '데이터과학']\n\n\n\n[wrd for doc in D for wrd in D[doc]].count('골')\n\n2\n\n\n\n\n조건부 컴프리헨션\n\nlst = [-1,0,1,2]\n[l for l in lst if l&lt;=0]\n\n[-1, 0]\n\n\n\n\n딕셔너리의 원소삭제\n\ndct = {'doc1':['손흥민']*5, 'doc2':['골']*5}\ndct\n\n{'doc1': ['손흥민', '손흥민', '손흥민', '손흥민', '손흥민'],\n 'doc2': ['골', '골', '골', '골', '골']}\n\n\n\ndel dct['doc1'][0]\n\n\ndct\n\n{'doc1': ['손흥민', '손흥민', '손흥민', '손흥민'], 'doc2': ['골', '골', '골', '골', '골']}\n\n\n\n\n깊은복사\n- 특정원소가 삭제된 dct와 삭제되지 않은 dct를 동시에 가지고 있으려면?\n\ndct = {'doc1':['손흥민']*5, 'doc2':['골']*5}\ndct2 = dct \n\n\ndel dct['doc1'][0]\n\n\ndct\n\n{'doc1': ['손흥민', '손흥민', '손흥민', '손흥민'], 'doc2': ['골', '골', '골', '골', '골']}\n\n\n\ndct2 # 잉 왜 같이 삭제되는거야?\n\n{'doc1': ['손흥민', '손흥민', '손흥민', '손흥민'], 'doc2': ['골', '골', '골', '골', '골']}\n\n\n- 해결책\n\nimport copy\n\n\ndct = {'doc1':['손흥민']*5, 'doc2':['골']*5}\ndct2 = copy.deepcopy(dct)\n\n\ndel dct['doc1'][0]\n\n\ndct\n\n{'doc1': ['손흥민', '손흥민', '손흥민', '손흥민'], 'doc2': ['골', '골', '골', '골', '골']}\n\n\n\ndct2 # 이제야 제대로 돌아가네\n\n{'doc1': ['손흥민', '손흥민', '손흥민', '손흥민', '손흥민'],\n 'doc2': ['골', '골', '골', '골', '골']}\n\n\n\n\n연습문제\n아래와 같은 자료가 있다고 하자.\n\nD = {'doc1':['손흥민','골'],\n     'doc2':['골','확률'],\n     'doc3':['확률','데이터과학']}\nθ = {'doc1':[2,1],\n     'doc2':[1,2],\n     'doc3':[2,1]}\n\n(1) \\(D\\)에는 총 몇개의 단어가 있는가?\n\nlen(set([wrd for doc in D for wrd in D[doc]]))\n\n4\n\n\n(2) 문서2에 토픽1은 몇개나 있는가?\n\nθ['doc2']\n\n[1, 2]\n\n\n\nθ['doc2'].count(1)\n\n1\n\n\n(3) 토픽1에 들어있는 단어들의 목록을 구하라.\n\nwrdlst = [wrd for doc in D for wrd in D[doc]]\nwrdlst\n\n['손흥민', '골', '골', '확률', '확률', '데이터과학']\n\n\n\ntpclst = [tpc for doc in θ for tpc in θ[doc]]\ntpclst \n\n[2, 1, 1, 2, 2, 1]\n\n\n\n[wrd for i,wrd in enumerate(wrdlst) if tpclst[i]==1 ]\n\n['골', '골', '데이터과학']\n\n\n(4) 토픽1에서 ’골’이라는 단어는 몇번 등장하는가?\n\n[wrd for i,wrd in enumerate(wrdlst) if tpclst[i]==1 ].count('골')\n\n2"
  },
  {
    "objectID": "posts/ap/2023-06-08-15wk-1.html#데이터-d와-theta의-설정",
    "href": "posts/ap/2023-06-08-15wk-1.html#데이터-d와-theta의-설정",
    "title": "15wk-1: MCMC (3)",
    "section": "데이터: \\(D\\)와 \\(\\theta\\)의 설정",
    "text": "데이터: \\(D\\)와 \\(\\theta\\)의 설정\n\nD = {'doc1': ['심판', '헤딩', '선수', '골', '리그', '골', '선수', '공격', '헤딩', '슈팅', '공', '패스', '공격수', '페널티킥', '공'], 'doc2': ['수비', '골', '챔피언스리그', '헤딩', '경기장', '골키퍼', '챔피언스리그', '헤딩', '경기장', '수비수', '수비수', '패스', '드리블', '선수', '월드컵'], 'doc3': ['헤딩', '리그', '드리블', '골키퍼', '공격수', '공격수', '월드컵', '선수', '공', '헤딩', '중앙미드필더', '공격', '선수', '수비수', '드리블'], 'doc4': ['클럽', '선수', '챔피언스리그', '슈팅', '리그', '수비', '리그', '중앙미드필더', '공격', '공', '중앙미드필더', '골', '패스', '중앙미드필더', '클럽'], 'doc5': ['선수', '경기장', '수비', '골키퍼', '월드컵', '리그', '드리블', '공격수', '슈팅', '선수', '선수', '월드컵', '드리블', '월드컵', '골키퍼'], 'doc6': ['수비수', '심판', '공', '공격', '표준편차', '표본', '상관관계', '모집단', '딥러닝', '클러스터링', '인공지능', '챔피언스리그', '공', '심판', '챔피언스리그'], 'doc7': ['페널티킥', '중앙미드필더', '챔피언스리그', '선수', '표본', '평균', '분류', '로지스틱 회귀', '머신러닝', '클러스터링', '평균', '수비수', '중앙미드필더', '페널티킥', '심판'], 'doc8': ['공격', '경기장', '패스', '수비수', '신뢰구간', '데이터과학', '확률', '통계', '분류', '인공지능', '머신러닝', '수비수', '수비수', '페널티킥', '수비수'], 'doc9': ['페널티킥', '패스', '골키퍼', '공', '신뢰구간', '딥러닝', '평균', '인공지능', '딥러닝', '분산', '딥러닝', '월드컵', '월드컵', '슈팅', '골키퍼'], 'doc10': ['리그', '슈팅', '드리블', '선수', '평균', '데이터분석', '데이터과학', '신뢰구간', '평균', '분류', '딥러닝', '심판', '슈팅', '패스', '선수'], 'doc11': ['평균', '데이터분석', '클러스터링', '데이터과학', '신경망', '데이터분석', '상관관계', '인공지능', '상관관계', '확률', '회귀분석', '로지스틱 회귀', '평균', '표준편차', '딥러닝'], 'doc12': ['신뢰구간', '딥러닝', '확률', '평균', '데이터분석', '상관관계', '회귀분석', '통계', '신경망', '상관관계', '회귀분석', '확률', '로지스틱 회귀', '상관관계', '데이터과학'], 'doc13': ['확률', '로지스틱 회귀', '통계', '딥러닝', '모집단', '머신러닝', '인공지능', '표준편차', '상관관계', '확률', '확률', '클러스터링', '신경망', '분류', '데이터분석'], 'doc14': ['데이터분석', '데이터과학', '분류', '통계적 가설검정', '머신러닝', '로지스틱 회귀', '회귀분석', '분류', '표본', '모집단', '통계적 가설검정', '상관관계', '표본', '클러스터링', '표본'], 'doc15': ['딥러닝', '인공지능', '표본', '표준편차', '신경망', '분류', '모집단', '데이터분석', '통계', '통계적 가설검정', '통계적 가설검정', '머신러닝', '머신러닝', '상관관계', '딥러닝']}\npd.DataFrame(D)\n\n\n\n\n\n\n\n\ndoc1\ndoc2\ndoc3\ndoc4\ndoc5\ndoc6\ndoc7\ndoc8\ndoc9\ndoc10\ndoc11\ndoc12\ndoc13\ndoc14\ndoc15\n\n\n\n\n0\n심판\n수비\n헤딩\n클럽\n선수\n수비수\n페널티킥\n공격\n페널티킥\n리그\n평균\n신뢰구간\n확률\n데이터분석\n딥러닝\n\n\n1\n헤딩\n골\n리그\n선수\n경기장\n심판\n중앙미드필더\n경기장\n패스\n슈팅\n데이터분석\n딥러닝\n로지스틱 회귀\n데이터과학\n인공지능\n\n\n2\n선수\n챔피언스리그\n드리블\n챔피언스리그\n수비\n공\n챔피언스리그\n패스\n골키퍼\n드리블\n클러스터링\n확률\n통계\n분류\n표본\n\n\n3\n골\n헤딩\n골키퍼\n슈팅\n골키퍼\n공격\n선수\n수비수\n공\n선수\n데이터과학\n평균\n딥러닝\n통계적 가설검정\n표준편차\n\n\n4\n리그\n경기장\n공격수\n리그\n월드컵\n표준편차\n표본\n신뢰구간\n신뢰구간\n평균\n신경망\n데이터분석\n모집단\n머신러닝\n신경망\n\n\n5\n골\n골키퍼\n공격수\n수비\n리그\n표본\n평균\n데이터과학\n딥러닝\n데이터분석\n데이터분석\n상관관계\n머신러닝\n로지스틱 회귀\n분류\n\n\n6\n선수\n챔피언스리그\n월드컵\n리그\n드리블\n상관관계\n분류\n확률\n평균\n데이터과학\n상관관계\n회귀분석\n인공지능\n회귀분석\n모집단\n\n\n7\n공격\n헤딩\n선수\n중앙미드필더\n공격수\n모집단\n로지스틱 회귀\n통계\n인공지능\n신뢰구간\n인공지능\n통계\n표준편차\n분류\n데이터분석\n\n\n8\n헤딩\n경기장\n공\n공격\n슈팅\n딥러닝\n머신러닝\n분류\n딥러닝\n평균\n상관관계\n신경망\n상관관계\n표본\n통계\n\n\n9\n슈팅\n수비수\n헤딩\n공\n선수\n클러스터링\n클러스터링\n인공지능\n분산\n분류\n확률\n상관관계\n확률\n모집단\n통계적 가설검정\n\n\n10\n공\n수비수\n중앙미드필더\n중앙미드필더\n선수\n인공지능\n평균\n머신러닝\n딥러닝\n딥러닝\n회귀분석\n회귀분석\n확률\n통계적 가설검정\n통계적 가설검정\n\n\n11\n패스\n패스\n공격\n골\n월드컵\n챔피언스리그\n수비수\n수비수\n월드컵\n심판\n로지스틱 회귀\n확률\n클러스터링\n상관관계\n머신러닝\n\n\n12\n공격수\n드리블\n선수\n패스\n드리블\n공\n중앙미드필더\n수비수\n월드컵\n슈팅\n평균\n로지스틱 회귀\n신경망\n표본\n머신러닝\n\n\n13\n페널티킥\n선수\n수비수\n중앙미드필더\n월드컵\n심판\n페널티킥\n페널티킥\n슈팅\n패스\n표준편차\n상관관계\n분류\n클러스터링\n상관관계\n\n\n14\n공\n월드컵\n드리블\n클럽\n골키퍼\n챔피언스리그\n심판\n수비수\n골키퍼\n선수\n딥러닝\n데이터과학\n데이터분석\n표본\n딥러닝\n\n\n\n\n\n\n\n- 간단한 데이터 조사\n\n데이터는 총 15개의 문서로 이루어져 있으며 처음5개의 문서는 축구관련, 이후 5개는 축구와 통계 관련, 이후 5개는 통계관련이다.\n축구와 통계가 섞인 doc6~doc11은 축구관련4단어, 통계관련7단어, 축구관련4단어의 조합으로 이루어져 있다.\n\n- 초기값\n\nθ = {doc:np.random.choice([0,1],size=15).tolist() for doc in D}\nθ\n\n{'doc1': [0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n 'doc2': [1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0],\n 'doc3': [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0],\n 'doc4': [1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1],\n 'doc5': [1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0],\n 'doc6': [1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1],\n 'doc7': [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0],\n 'doc8': [0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1],\n 'doc9': [1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1],\n 'doc10': [1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0],\n 'doc11': [1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n 'doc12': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1],\n 'doc13': [0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n 'doc14': [1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n 'doc15': [1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]}\n\n\n- D와 \\(\\theta\\)를 묶어서 하나의 dict를 만들자.\n\ndata = {'D':D, 'θ':θ}"
  },
  {
    "objectID": "posts/ap/2023-06-08-15wk-1.html#하이퍼파라메터",
    "href": "posts/ap/2023-06-08-15wk-1.html#하이퍼파라메터",
    "title": "15wk-1: MCMC (3)",
    "section": "하이퍼파라메터",
    "text": "하이퍼파라메터\n\nK = 2 # 토픽의수 &lt;-- 유저가 설정함"
  },
  {
    "objectID": "posts/ap/2023-06-08-15wk-1.html#필요한-함수",
    "href": "posts/ap/2023-06-08-15wk-1.html#필요한-함수",
    "title": "15wk-1: MCMC (3)",
    "section": "필요한 함수",
    "text": "필요한 함수\n- \\(p_1\\): \\(d\\)-th document에 포함된 토픽 \\(k\\)의 비율을 리턴하는 함수, 즉 아래를 계산한다.\n\\[p_1=:\\frac{\\#({\\tt topic == k, document == d})+0.1}{\\#({\\tt document == d})+0.1\\times K}\\]\n여기에서 \\(K\\)는 토픽의 수.\n\ndef p1(topic,doc,data):\n    θ = data['θ']\n    a = θ[doc].count(topic) +0.1\n    b = len(θ[doc]) + 0.1 *K  \n    return a/b\n\n- \\(p_2\\): \\(k\\)-th topic에 포함된 단어 \\(w\\)의 비율을 리턴하는 함수, 즉 아래를 계산한다.\n\\[p_2=:\\frac{\\#({\\tt word ==w, topic == k})+0.1}{\\#({\\tt topic == k})+0.1\\times W}\\]\n여기에서 \\(W\\)는 전체단어의 수. (이 예제의 경우 40개의 단어로 이루어짐)\n\ndef p2(word,topic,data):\n    D=data['D']\n    θ=data['θ']\n    tpclst = [tpc for doc in θ for tpc in θ[doc]]\n    wrdlst = [wrd for doc in D for wrd in D[doc]]\n    a = [wrd for i,wrd in enumerate(wrdlst) if tpclst[i]==topic].count(word) + 0.1 \n    b = tpclst.count(topic) + 0.1 * len(set(wrdlst))\n    return a/b"
  },
  {
    "objectID": "posts/ap/2023-06-08-15wk-1.html#알고리즘",
    "href": "posts/ap/2023-06-08-15wk-1.html#알고리즘",
    "title": "15wk-1: MCMC (3)",
    "section": "알고리즘",
    "text": "알고리즘\n\n1. 초기값: \\({\\boldsymbol \\theta}_0\\)\n\nθ = {doc:np.random.choice([0,1],size=15).tolist() for doc in D}\nplt.matshow(list(θ.values()))\n\n&lt;matplotlib.image.AxesImage at 0x7fbe31030610&gt;\n\n\n\n\n\n\n\n2. 반복: \\({\\boldsymbol \\theta}_0 \\to {\\boldsymbol \\theta}_1 \\to {\\boldsymbol \\theta}_2 \\to \\dots\\)\n\nfor t in range(5):\n    for doc in D:\n        for i, wrd in enumerate(D[doc]):\n            # 임시의 data를 만들고 현재 포커싱되어있는 자료를 삭제함 \n            data = {'D':copy.deepcopy(D), 'θ': copy.deepcopy(θ)} \n            del data['D'][doc][i]\n            del data['θ'][doc][i]\n            \n            # 토픽의 타당성조사, msr는 타당성을 나타내는 측도, prob는 msr의 총합을 1로 맞춤\n            msr0 = p1(topic=0, doc=doc, data=data) * p2(word=wrd, topic=0, data=data) # 토픽0의 타당성\n            msr1 = p1(topic=1, doc=doc, data=data) * p2(word=wrd, topic=1, data=data) # 토픽1의 타당성\n            prob = [msr0/(msr0 + msr1), msr1/(msr0 + msr1)] \n            \n            # update θ|\n            θ[doc][i] = np.random.choice([0,1], p=prob)"
  },
  {
    "objectID": "posts/ap/2023-06-08-15wk-1.html#시각화",
    "href": "posts/ap/2023-06-08-15wk-1.html#시각화",
    "title": "15wk-1: MCMC (3)",
    "section": "시각화",
    "text": "시각화\n\nplt.matshow(list(θ.values()))\n\n&lt;matplotlib.image.AxesImage at 0x7fbe30f627f0&gt;"
  },
  {
    "objectID": "posts/ap/2023-05-11-11wk-1.html",
    "href": "posts/ap/2023-05-11-11wk-1.html",
    "title": "11wk-1: 마코프체인 (8)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-wPUBATQ2c1npACK21EgDsx"
  },
  {
    "objectID": "posts/ap/2023-05-11-11wk-1.html#약한조건-약한정리-강한조건-강한정리",
    "href": "posts/ap/2023-05-11-11wk-1.html#약한조건-약한정리-강한조건-강한정리",
    "title": "11wk-1: 마코프체인 (8)",
    "section": "약한조건, 약한정리, 강한조건, 강한정리",
    "text": "약한조건, 약한정리, 강한조건, 강한정리\n- 정리: 어떠한 조건을 만족하면, 어떠한 결론이 나온다.\n\n결론: 우리가 원하는 것.\n조건: 우리가 원하는 것을 얻기 위한 고난과정.\n\n- 결론이 동일하다면 조건이 약할 수록 유리하다.\n\n정리1: 수업에 온라인으로 참석하거나 오프라인으로 참석한다면 모두 출석으로 인정한다.\n정리2: 수업에 오프라인으로 참석할때만 출석으로 인정한다.\n\n\n정리2의 조건이 만족되면 정리1의 조건은 자동으로 만족된다. 따라서 정리2의 조건이 더 강한 조건이다. 조건이 강할수록 불리하므로 정리2가 더 불리하다.\n\n- 조건이 동일하다면 결론이 강한 쪽이 유리하다.\n\n정리1: 중간고사와 기말고사를 모두 응시한다면, B학점 이상이다.\n정리2: 중간고사와 기말고사를 모두 응시한다면, A학점 이상이다.\n\n\n정리2의 결론이 만족되면 정리1의 결론은 자동으로 만족되므로 정리2의 결론이 더 강하다. 결론은 강할수록 유리하므로 정리2가 더 유리하다."
  },
  {
    "objectID": "posts/ap/2023-05-11-11wk-1.html#헷갈리는-표현-infty의-포함",
    "href": "posts/ap/2023-05-11-11wk-1.html#헷갈리는-표현-infty의-포함",
    "title": "11wk-1: 마코프체인 (8)",
    "section": "헷갈리는 표현: \\(\\infty\\)의 포함",
    "text": "헷갈리는 표현: \\(\\infty\\)의 포함\n- 자연수집합 \\(\\mathbb{N}\\)은 \\(\\{\\infty\\}\\)를 포함하지 않는다. 마찬가지로 실수집합 \\(\\mathbb{R}\\) 역시 \\(\\{-\\infty\\}, \\{\\infty\\}\\)를 포함하지 않는다. 만약에 이를 포함하고 싶을 경우는 아래와 같이 표현한다.\n\n\\(\\mathbb{R} \\cup \\{-\\infty\\} \\cup \\{\\infty\\} = \\bar{\\mathbb{R}}\\)\n\\(\\mathbb{N} \\cup \\{-\\infty\\}\\)\n\n여기에서 \\(\\bar{\\mathbb{R}}\\)은 확장된 실수라고 부르는데 교재에따라 사용하기도 하고 사용하지 않기도 한다.\n- 만약에 \\(\\mathbb{N}\\)이 \\(\\{\\infty\\}\\)를 포함한다면\n\n\\(\\forall n \\in \\mathbb{N}:~ 0&lt;\\frac{1}{n} \\leq 1\\)\n\n와 같은 표현은 불가능할 것이다.\n- 구간에 대한 표현들: 구간에 대한 몇가지 표현을 정리하면 아래와 같다.\n\n\\((-\\infty, b] = \\{x: x\\leq b, ~x,b \\in \\mathbb{R}\\}\\)\n\\((-\\infty, b) = \\{x: x &lt; b,~ x,b \\in \\mathbb{R}\\}\\)"
  },
  {
    "objectID": "posts/ap/2023-05-11-11wk-1.html#이론의-정리",
    "href": "posts/ap/2023-05-11-11wk-1.html#이론의-정리",
    "title": "11wk-1: 마코프체인 (8)",
    "section": "이론의 정리",
    "text": "이론의 정리\n- \\(\\{X_t\\}\\)는 HMC 라고 하자.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaseNO\n대표예제\nFINITE\nIRR(연결)\nAP(비주기)\n\\({\\bf P}\\)의 수렴\n극한분포유일존재\n정상분포존재\n정상분포유일\n에르고딕정리를 만족\n에르고딕\n\n\n\n\n1\n\nO\nX\nX\nX\nX\nO\nX\nX\nX\n\n\n2\n단위행렬\nO\nX\nO\nO\nX\nO\nX\nX\nX\n\n\n3\n순환이동\nO\nO\nX\nX\nX\nO\nO\nO\nX\n\n\n4\n나이스\nO\nO\nO\nO\nO\nO\nO\nO\nO\n\n\n\n- CaseNO==1 의 예제"
  },
  {
    "objectID": "posts/ap/2023-05-11-11wk-1.html#emprical-분포-정상분포-극한분포",
    "href": "posts/ap/2023-05-11-11wk-1.html#emprical-분포-정상분포-극한분포",
    "title": "11wk-1: 마코프체인 (8)",
    "section": "Emprical 분포, 정상분포, 극한분포",
    "text": "Emprical 분포, 정상분포, 극한분포\n- Emprical distribution, 정상분포, 극한분포\n\n\\(\\bar{\\boldsymbol \\pi}^\\top\\): 하나의 \\(\\omega\\)에 대한 확률변수열 \\(\\{X_t\\}\\)의 emprical distribution (time average로 분포를 추정)\n\\({\\boldsymbol \\pi}^\\top\\): 모든 \\(\\omega\\)를 고려하였을 경우 확률변수열 \\(\\{X_t\\}\\)의 정상분포.\n\\({\\bf p}_{\\star}^\\top\\): \\(\\omega\\)와 무관하게 \\({\\bf P}\\)의 극한으로 얻어지는 \\(\\{X_t\\}\\)의 극한분포. // 마코프체인에 특화\n\n- 표로 정리하면 아래와 같다.\n\n\n\n\n\n\n\n\n\n\nEmpirical 분포\n정상분포\n극한분포\n\n\n\n\n용어가 통용되는 범위\n모든 확률과정\n모든 확률과정\n마코프체인\n\n\n기호\n\\(\\bar{\\boldsymbol \\pi} = \\frac{1}{T}\\begin{bmatrix}{\\tt sum}(X_t==0) \\\\ {\\tt sum}(X_t==1)\\end{bmatrix}\\)\n\\({\\boldsymbol \\pi}=\\begin{bmatrix}\\mathbb{E}(I(X=0))\\\\ \\mathbb{E}(I(X=1)) \\end{bmatrix}\\)\n\\({\\bf p}_{\\star}= \\lim_{t\\to \\infty}\\begin{bmatrix}p_{?0}^{(t)} \\\\ p_{?1}^{(t)} \\end{bmatrix}\\)\n\n\n\\(\\omega\\)의 고려\n하나의 \\(\\omega\\)만 고려해 계산\n모든 \\(\\omega\\) 고려해 계산\n\\(\\omega\\)를 고려하지 않고 계산\n\n\n통계느낌(분포느낌?)\nO\nO\nX\n\n\n이론적인값?\nX\nO\nO\n\n\n데이터와 관련\nO\nX\nX\n\n\n극한과 관련\nO\nX\nO\n\n\nLLN과 관련\nO\nO\nX\n\n\n느낌\n데이터로 계산한 평균값\n이론적인 기대값\n이론적인 수렴값\n\n\n\n\\(P^{(t)}_{?0}\\) t번만에 0에 갈 확률\n마코프 체인이 finite한 공간에 있고 연결)irreducible)하다는 것을 가정하면 에르고딕 이론을 이용해서 정상분포가 존재한다."
  },
  {
    "objectID": "posts/ap/2023-05-11-11wk-1.html#이론들의-의미를-다시-고찰",
    "href": "posts/ap/2023-05-11-11wk-1.html#이론들의-의미를-다시-고찰",
    "title": "11wk-1: 마코프체인 (8)",
    "section": "이론들의 의미를 다시 고찰",
    "text": "이론들의 의미를 다시 고찰\n- 에르고딕정리: 임피리컬분포와 정상분포에 관련한 정리 (LLN보다 더 약한 조건을 가짐)\n\n의미1: 에르고딕 정리를 만족하지 못하는 경우 하나의 확률변수열을 이용한 추론이 불가능\n\n\n## 예시\nP =np.array([[1,1,0,0],\n             [1,1,0,0],\n             [0,0,1,1],\n             [0,0,1,1]])/2\nP\n\narray([[0.5, 0.5, 0. , 0. ],\n       [0.5, 0.5, 0. , 0. ],\n       [0. , 0. , 0.5, 0.5],\n       [0. , 0. , 0.5, 0.5]])\n\n\n\n의미2: 에르고딕 정리를 만족하는 경우 \\(X_1,X_2,\\dots\\)이 동일한 분포를 가지지 않지만 무시하고 \\(\\pi\\)를 추정할 수있다.\n\n- 극한분포와 관련된 이론: 극한분포의 느낌은 초기값에 대한 삭제임\n\n극한분포는 어차피 \\(\\omega\\)를 신경안씀\n\\({\\boldsymbol \\mu}_0\\)는 아무상관이 없음\n결국 극한분포가 존재한다면 시간의존성이 삭제된다는 의미임"
  },
  {
    "objectID": "posts/ap/2023-05-11-11wk-1.html#스토리정리",
    "href": "posts/ap/2023-05-11-11wk-1.html#스토리정리",
    "title": "11wk-1: 마코프체인 (8)",
    "section": "스토리정리",
    "text": "스토리정리\n- FINITE HMC는 일단 정상분포라는게 존재함. 그런데 유일하지 않을 수 있음.\n- FINITE HMC는 크게보면 IRR인 케이스와 IRR 아닌 케이스로 나누어짐\n\n그런데 IRR이 아닌 케이스는 IRR인 케이스들의 조합으로 나누어 생각할 수 있음\n그래서 어차피 신경쓸 필요 없음.\n따라서 모든 마코프체인은 IRR이라고 가정해버려도 무방\n\n- 만약에 HMC가 (1) FINITE (2) IRR 이면 유일한 정상분포가 존재.\n\n심지어 이 조건에서는 에르고딕정리를 이용해서 임피리컬 분포로 정상분포를 estimate 할 수 있음.\n\n- 그러면 HMC가 (1) FINITE (2) IRR 이면 다 끝?\n\n언뜻 생각하면 그런거 같음.\n그런데 에르고딕 정리를 만족한다고 해서 초기분포에 대한 기억이 사라지는건 아님\n몇 가지 응용예제에서는 초기분포에 대한 의존성을 삭제시키는 것이 매우 중요함.\n이걸 위해서는 AP조건이 추가되어야 함.\n\n- HMC가 (1) FINITE (2) IRR (3) AP 라면 아주 좋음."
  },
  {
    "objectID": "posts/ap/2023-04-10-6wk-2-mid.html",
    "href": "posts/ap/2023-04-10-6wk-2-mid.html",
    "title": "06wk-2: 중간고사",
    "section": "",
    "text": "1. Cardinality\n(1) \\(\\mathbb{Q}\\)의 cardinality가 \\(\\aleph_0\\)임을 증명하라.\n(풀이) 생략\n(2) \\(\\mathbb{R}\\)의 cardinality가 \\(\\aleph_0\\)이 아님을 보여라.\n(풀이) 생략\n\n\n2. \\(\\sigma\\)-field\n(1) \\(\\Omega=\\{1,2,3,4,5,6\\}\\)일 때, 다음 중 시그마필드의 정의를 만족하는 집합을 모두 골라라.\n\n\\({\\cal F}=\\{\\emptyset, \\Omega\\}\\)\n\\({\\cal F}=\\{\\emptyset, \\{1\\},\\{2,3,4,5,6\\},\\Omega\\}\\)\n\\({\\cal F}=\\{\\emptyset, \\{1,2,3\\}, \\{4,5,6\\}, \\Omega\\}\\)\n\\({\\cal F}=2^\\Omega\\)\n\n(풀이) 1,2,3,4 모두 시그마필드\n(2) \\(\\Omega=\\{1,2,3,4,5,6\\}\\) 일 때,\n\\[{\\cal A}=\\{\\{1,2,3\\},\\{4,5,6\\}\\}\\]\n이라고 하자. \\(\\sigma({\\cal A})\\)를 구하여라.\n(풀이) \\(\\sigma({\\cal A}) = \\{\\emptyset, \\Omega, \\{1,2,3\\},\\{4,5,6\\}\\}\\)\n(3) \\(\\Omega=\\mathbb{N}\\) 일 때,\n\n\\({\\cal A}=\\{\\{n\\}: n \\in \\mathbb{N}\\}\\)\n\\({\\cal F} = \\sigma({\\cal A})\\)\n\n이라고 하자. 아래의 물음에 답하여라.\n\n\\(\\{2\\} \\in {\\cal F}\\) 인가?\n\\(\\mathbb{N} \\in {\\cal F}\\) 인가?\n\\(\\emptyset \\in {\\cal F}\\) 인가?\n\\(\\{2n: n\\in \\mathbb{N}\\} \\in {\\cal F}\\) 인가?\n\\(\\mathbb{Z} \\in {\\cal F}\\) 인가?\n\n(풀이) 1,2,3,4 (O) // 5 (X)\n시그마필드는 공집합과 전체집합을 포함하므로 \\(\\mathbb{N}, \\emptyset\\)은 \\({\\cal F}\\)의 원소이어야 한다. 시그마필드의 원소는 \\(\\mathbb{N}\\)의 부분집합이어야 하므로 \\(\\mathbb{Z}\\)는 \\({\\cal F}\\)의 원소가 될 수 없다. \\({\\cal F}\\)는 \\(\\{2\\},\\{4\\},\\{6\\},\\dots\\) 등을 원소로 포함하고 가산합집합에 닫혀있으므로 \\(\\{2n: n \\in \\mathbb{N}\\}\\) 은 \\({\\cal F}\\)의 원소이다.\n(4) \\(\\Omega=\\mathbb{R}\\) 일 때,\n\n\\({\\cal A}=\\{(a,b): -\\infty &lt;a&lt; b&lt; \\infty\\}\\)\n\\({\\cal F}=\\sigma({\\cal A})\\)\n\n이라고 하자. 아래의 물음에 답하여라.\n\n\\(\\{0\\} \\in {\\cal F}\\) 인가?\n\\(\\mathbb{R} \\in {\\cal F}\\) 인가?\n\\(\\mathbb{Q} \\in {\\cal F}\\) 인가?\n\\(\\mathbb{R} - \\mathbb{Q} \\in {\\cal F}\\) 인가?\n\\((1,3] \\in {\\cal F}\\) 인가?\n\\([1,3] \\in {\\cal F}\\) 인가?\n\\([1,3) \\in {\\cal F}\\) 인가?\n\\([1,3) \\cup (3,5] \\in {\\cal F}\\) 인가?\n\nnote: 시그마필드가 교집합, 차집합등에 닫혀있다는 성질은 증명없이 이용해도 무방함.\n(풀이) 1,2,3,4,5,6,7,8 모두 O.\n1. \\((-1,1) - \\big((-1,0)\\cup (0,1)\\big) \\in {\\cal F}\\)\n\n모든 열린구간은 \\({\\cal F}\\)의 원소이고, 열린구간의 합집합 역시 \\({\\cal F}\\)의 원소이므로 \\((-1,0) \\cup (0,1)\\) 역시 \\({\\cal F}\\)의 원소이다.\n\\(A=(-1,1)\\), \\(B=(-1,0)\\cup (0,1)\\) 이라고 하면, \\(A-B = \\{0\\}\\) 이고 시그마필드는 차집합에 닫혀있으므로 \\(A\\in {\\cal F}, B \\in {\\cal F}\\) 는 \\(A-B=\\{0\\} \\in {\\cal F}\\)를 imply한다.\n\n2. \\(\\Omega \\in {\\cal F}\\)\n\n시그마필드는 전체집합을 포함하므로 \\(\\mathbb{R}\\)은 \\({\\cal F}\\)의 원소이다.\n\n3. \\(\\forall x \\in \\mathbb{Q}, \\{x\\} \\in \\mathbb{Q} ~\\Rightarrow ~\\cup_{x \\in \\mathbb{Q}} \\{x\\} \\in {\\cal F}\\)\n\n1에 의하여 하나의 원소만 포함하는 모든 집합은 \\({\\cal F}\\)의 원소이다. 즉 모든 \\(x\\in \\mathbb{R}\\)에 대하여 \\(\\{x\\} \\in {\\cal F}\\) 이 성립한다.\n유리수전체의 집합은 \\(\\mathbb{Q}=\\cup_{x \\in \\mathbb{Q}} \\{x\\}\\) 와 같이 한점만 포함하는 집합들의 countable union으로 표현가능하고, 시그마필드는 countable union에 닫혀있으므로 \\(\\mathbb{Q} \\in {\\cal F}\\) 이다.\n\n4. \\(\\mathbb{Q} \\in {\\cal F} ~\\Rightarrow~ \\mathbb{Q}^c \\in {\\cal F}\\)\n\n무리수전체의 집합은 \\(\\mathbb{Q}^c = \\cup_{x \\in \\mathbb{Q}^c}\\{x\\}\\) 와 같이 한점만 포함하는 집합들의 uncountable union으로 표현되므로 3과 같은 방식으로는 증명할 수 없음.\n하지만 \\(\\mathbb{Q} \\in \\mathbb{R}\\)임을 3에서 보였고, 시그마필드는 여집합에 닫혀있으므로 \\(\\mathbb{Q}^c \\in \\mathbb{R}\\) 임을 보일 수 있다.\n\n5-8.\n\n모든 열린구간은 \\({\\cal F}\\)의 원소이며, 한점만 포함된 모든 집합 \\(\\{x\\}, x\\in\\mathbb{R}\\) 은 1과 유사한 논리로 \\({\\cal F}\\)의 원소임을 보일 수 있으므로 5-8은 모두 성립함.\n\n\n\n3. 확률과 확률변수\n(1) 아래와 같은 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\)를 고려하자.\n\n\\(\\Omega=\\{a,b,c,d\\}\\)\n\\({\\cal F}=2^\\Omega\\)\n\n아래와 같은 확률변수 \\(X: \\Omega \\to \\{1,2,3,4\\}\\) 를 고려하자. 다음 중 올바른 표현은?\n\n\\(X(a)\\)\n\\(X(\\{a\\})\\)\n\\(P(a)\\)\n\\(P(\\{a\\})\\)\n\\(P(X=1)\\)\n\\(X = \\begin{cases} 1 & w.p.~\\frac{1}{2} \\\\ 2 & w.p. ~\\frac{1}{6} \\\\ 3 & w.p. ~\\frac{1}{6} \\\\ 4 & w.p. ~\\frac{1}{6} \\end{cases}\\)\n\n(풀이) 1,4,5,6\n(2) 두개의 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\)와 \\((S,{\\cal S})\\)를 고려하자. 단,\n\n\\(\\Omega=\\mathbb{R}\\),\n\\({\\cal F} =\\sigma({\\cal A})\\) where \\({\\cal A} = \\{\\mathbb{Q}\\}\\),\n\\(S = \\{0,1\\}\\),\n\\({\\cal S} = 2^{S}\\).\n\n아래와 같은 함수 \\(X:\\Omega \\to S\\)을 고려하라.\n\\[X(\\omega) = \\begin{cases}\n0 & \\omega \\in \\mathbb{Q}\\\\\n1 & \\omega \\in \\mathbb{R} - \\mathbb{Q}\n\\end{cases}\\]\n\\(X\\)는 \\((\\Omega,{\\cal F})\\)에서의 확률변수인가? (즉 \\(X\\)는 \\((\\Omega,{\\cal F})\\to(S,{\\cal S})\\)인 가측함수인가?)\n(풀이) 확률변수임.\nNote: \\(\\sigma({\\cal A})=\\{\\emptyset, \\mathbb{Q}, \\mathbb{Q}^c, \\mathbb{R} \\}, 2^S = \\{\\emptyset, \\{0\\}, \\{1\\}, \\{0,1\\}\\}\\)\n확률변수임을 체크하기 위해서는 \\(2^S\\)의 모든 원소 \\(B\\)에 대하여 \\(X^{-1}(B):= \\{\\omega : X(\\omega) \\in B\\} \\in {\\cal F}\\) 임을 확인하면 된다.\n\n\\(B=\\emptyset\\) 일 경우: \\(\\{\\omega: X(\\omega) \\in \\emptyset\\}=\\emptyset \\in \\sigma({\\cal A})\\)\n\\(B=\\{0\\}\\) 일 경우: \\(\\{\\omega: X(\\omega) \\in \\{0\\}\\}=\\mathbb{Q} \\in \\sigma({\\cal A})\\)\n\\(B=\\{1\\}\\) 일 경우: \\(\\{\\omega: X(\\omega) \\in \\{1\\}\\}=\\mathbb{Q}^c \\in \\sigma({\\cal A})\\)\n\\(B=\\{0,1\\}\\) 일 경우: \\(\\{\\omega: X(\\omega) \\in \\{0,1\\}\\}=\\mathbb{R} \\in \\sigma({\\cal A})\\)\n\n(3) 두개의 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\)와 \\((S,{\\cal S})\\)를 고려하자. 단,\n\n\\(\\Omega=\\mathbb{R}\\),\n\\({\\cal F} =\\sigma({\\cal A})\\) where \\({\\cal A} = \\{\\mathbb{Q}\\}\\),\n\\(S = \\{0,1\\}\\),\n\\({\\cal S} = 2^S\\).\n\n아래와 같은 함수 \\(X:\\Omega \\to S\\)을 고려하라.\n\\[X(\\omega) = \\begin{cases}\n0 & \\omega =0\\\\\n1 & \\omega \\neq 0\n\\end{cases}\\]\n\\(X\\)는 \\((\\Omega,{\\cal F})\\)에서의 확률변수인가? (즉 \\(X\\)는 \\((\\Omega,{\\cal F})\\to(S,{\\cal S})\\)인 가측함수인가?)\n(풀이) 확률변수가 아님. \\(B=\\{0\\}\\) 일 경우, \\(\\{\\omega: X(\\omega) \\in B\\}=\\{0\\} \\notin \\sigma({\\cal A})\\) 이므로 확률변수의 정의에 만족하지 않음."
  },
  {
    "objectID": "posts/ap/2023-05-09-10wk-2.html",
    "href": "posts/ap/2023-05-09-10wk-2.html",
    "title": "10wk-2: 마코프체인 (7)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-yMXZ2TSGxoh-rIjn8vp6cV"
  },
  {
    "objectID": "posts/ap/2023-05-09-10wk-2.html#예제1-단위행렬",
    "href": "posts/ap/2023-05-09-10wk-2.html#예제1-단위행렬",
    "title": "10wk-2: 마코프체인 (7)",
    "section": "예제1: 단위행렬",
    "text": "예제1: 단위행렬\nHMC \\(\\{X_t\\}\\)의 전이행렬이 아래와 같다고 하자.\n\nP = np.array([[1,0],\n              [0,1]])\nP\n\narray([[1, 0],\n       [0, 1]])\n\n\n\\(\\{X_t\\}\\)는 유일한 정상분포를 가지는가? 가진다면 시간평균을 이용하여 정상분포를 근사하라.\n(풀이)\n이 경우는 IRR 조건이 만족되지 않으므로 유일한 정상분포가 존재하지 않음. 그래서 에르고딕정리를 이용할 수 없다.\nirreducible 하고 finite 하면 유일한 정상분포가 존재한다."
  },
  {
    "objectID": "posts/ap/2023-05-09-10wk-2.html#예제2-순환이동",
    "href": "posts/ap/2023-05-09-10wk-2.html#예제2-순환이동",
    "title": "10wk-2: 마코프체인 (7)",
    "section": "예제2: 순환이동",
    "text": "예제2: 순환이동\nHMC \\(\\{X_t\\}\\)의 전이행렬이 아래와 같다고 하자.\n\nP = np.array([[0,1],\n              [1,0]])\nP\n\narray([[0, 1],\n       [1, 0]])\n\n\nirr은 만족하는데 ap는 만족하지 않아서 \\(P*\\)를 쓰는 것은 불가능하다.\n\\(\\{X_t\\}\\)는 유일한 정상분포를 가지는가? 가진다면 시간평균을 이용하여 정상분포를 구하여라.\n(풀이)\n\\(\\{X_t\\}\\)는 finite and irreducible HMC 이므로 유일한 정상분포를 가진다. 시뮬레이션을 한다면\n\n\\(0,1,0,1,0,1,0, \\dots\\)\n\\(1,0,1,0,1,0,1, \\dots\\)\n\n중 하나의 열(array)이 관찰 될 것이고 두 경우 모두\n\n\\(\\big(\\frac{1}{T}\\sum_{t=0}^{T-1}I(X_t=0),\\frac{1}{T}\\sum_{t=0}^{T-1}I(X_t=1)\\big)=(\\hat{\\pi}_0,\\hat{\\pi}_1)\\approx (1/2,1/2)\\)\n\n와 같이 구할 수 있음"
  },
  {
    "objectID": "posts/ap/2023-05-09-10wk-2.html#예제3-비가-온다-안온다",
    "href": "posts/ap/2023-05-09-10wk-2.html#예제3-비가-온다-안온다",
    "title": "10wk-2: 마코프체인 (7)",
    "section": "예제3: 비가 온다, 안온다",
    "text": "예제3: 비가 온다, 안온다\nHMC \\(\\{X_t\\}\\)의 전이행렬이 아래와 같다고 하자.\n\nP = np.array([[0.4,0.6],\n              [0.7,0.3]])\nP\n\narray([[0.4, 0.6],\n       [0.7, 0.3]])\n\n\n\\(\\{X_t\\}\\)는 유일한 정상분포를 가지는가? 가진다면 시간평균을 이용하여 정상분포를 구하여라.\n(풀이) 이 강의노트의 풀이4\n\ndef rain(before):\n    if before == True: # 비가 왔음 \n        after = np.random.rand() &lt; 0.3\n    else: # 비가 안왔음 \n        after = np.random.rand() &lt; 0.6 \n    return after \n\n\ndef doctor_strange(today):\n    lst = [today]\n    for i in range(10000): \n        lst.append(rain(lst[i]))\n    return lst \n\n\nnp.mean(doctor_strange(True)[1:])\n\n0.4616\n\n\n위는 \\(\\pi_0\\)의 값, P는 어떤 값(행렬)으로 곧 수렴하게 될 것임."
  },
  {
    "objectID": "posts/ap/2023-03-14-ap-02wk.html",
    "href": "posts/ap/2023-03-14-ap-02wk.html",
    "title": "02wk: 측도론 intro (2)",
    "section": "",
    "text": "강의영상\n\nhttps://youtube.com/playlist?list=PLQqh36zP38-zlQzcT1FJ8lBWRGkqBIsEu\n\n\n\n강의노트 다운로드\n\n!wget https://raw.githubusercontent.com/guebin/AP2023/main/posts/I.%20Measure%20Theory/2023-03-14-2wk.ipynb\n\n--2023-03-14 18:55:02--  https://raw.githubusercontent.com/guebin/AP2023/main/posts/I.%20Measure%20Theory/2023-03-14-2wk.ipynb\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 144568 (141K) [text/plain]\nSaving to: ‘2023-03-14-2wk.ipynb.1’\n\n2023-03-14-2wk.ipyn 100%[===================&gt;] 141.18K  --.-KB/s    in 0.01s   \n\n2023-03-14 18:55:02 (12.4 MB/s) - ‘2023-03-14-2wk.ipynb.1’ saved [144568/144568]\n\n--2023-03-14 18:55:02--  http://2wk.ipynb/\nResolving 2wk.ipynb (2wk.ipynb)... failed: Name or service not known.\nwget: unable to resolve host address ‘2wk.ipynb’\nFINISHED --2023-03-14 18:55:02--\nTotal wall clock time: 0.05s\nDownloaded: 1 files, 141K in 0.01s (12.4 MB/s)\n\n\n\n\n예비개념1: 귀류법\n- 귀류법: 니 논리 대로면… &lt;- 인터넷 댓글에 많음..\n님 논리대로면..\n- XXX가 문제 없으면 서울 전체가 문제가 없고 (애초에 서울은 문제도 아니라는데 왜 이소리는 하고 계신지 모르겠지만)\n- 수도권 모 대학이 문제가 없으면 전체가 문제가 없겠네요?\n- 지방도 1개 대학이 문제가 없으니 전체가 문제 없겠네요?\n와우! 모든 문제가 해결되었습니다! 출산율 감소로 인한 한국대학의 위기가 해결되었.. 아니 애초에 위기가 없었군요!.\n어휴.. ㅠㅠ\nref: 하이브레인넷\n\n\n예비개념2: 일반화\n- 연필의 정의: 필기도구의 하나. 흑연과 점토의 혼합물을 구워 만든 가느다란 심을 속에 넣고, 겉은 나무로 둘러싸서 만든다. 1565년에 영국에서 처음으로 만들었다.\n- 질문: 아래는 연필인가?\n\n\n\ncardinality\n\nref: https://en.wikipedia.org/wiki/Cardinality\n\n- \\(A=\\{2,4,6\\}\\) \\(\\Rightarrow\\) \\(|A|=3\\), \\(A\\) has a cardinality of 3.\n- \\(A=\\{1,2,3,4,\\dots\\}=\\mathbb{N}\\) \\(\\Rightarrow\\) \\(|A|=?\\)\n\nCardinal number: 유한집합에서의 “갯수”라는 개념을 좀 더 일반화 하여 무한집합으로 적용하고 싶다.\n유한집합: 우리가 친숙한 size 와 그 뜻이 같음\n무한집합: 무한집합의 경우는 그 동작원리가 조금 더 복잡함\n\n- 질문: \\(|\\mathbb{Q}| &lt; |\\mathbb{Q}^c|\\) ??\nBijection, injection and surjection (예비학습)\n\nref: https://en.wikipedia.org/wiki/Bijection,_injection_and_surjection\n\n\n- 용어 정리\n\nsurjective = onto = 전사 = 위로의 함수\ninjective = one-to-one = 단사 = 일대일 함수\nbijective = one-to-one and onto, one-to-one correspondence = 전단사 = 일대일 대응\n\n- 따지는 방법:\n\n단사: 함수 \\(f\\)는 \\(X\\)에서 \\(Y\\)로 향하는 단사함수이다. \\(\\Leftrightarrow\\) \\(\\forall x_1,x_2 \\in X\\): \\(x_1\\neq x_2 \\Rightarrow f(x_1)\\neq f(x_2)\\)\n전사: 함수 \\(f\\)는 \\(X\\)에서 \\(Y\\)로 향하는 전사함수이다. \\(\\Leftrightarrow\\) \\(\\forall y \\in Y ~\\exists x \\in X\\) such that \\(f(x)=y\\).\n\n- 성질1: 어떤함수가 전사함수 & 단사함수 \\(\\Rightarrow\\) 전단사함수\n- 성질2:\n\n집합 \\(X\\)에서 집합 \\(Y\\)로 가는 단사함수 \\(f\\)가 존재한다. \\(\\Rightarrow\\) \\(|X| \\leq |Y|\\)\n집합 \\(X\\)에서 집합 \\(Y\\)로 가는 전사함수 \\(f\\)가 존재한다. \\(\\Rightarrow\\) \\(|X| \\geq |Y|\\)\n\n(예비학습 끝)\n- 성질1~2로 유추하면 아래와 같은 사실을 주장 할 수 있지 않을까?\n\n집합 \\(X\\)에서 집합 \\(Y\\)로 향하는 전단사함수가 존재한다 \\(\\Rightarrow\\) \\(|X|=|Y|\\)\n\n- 그렇다면 우리가 주장하고 싶은 것은 아래와 같이 된다.\n\n유리수집합의 무리수집합의 cardinality는 다르다.\n유리수집합과 무리수집합사이의 전단사함수는 존재할 수 없다.\n\n\n\n유리수집합의 카디널리티\n- 우리가 궁극적으로 궁금한 것\n\n유리수집합과 무리수집합의 카디널리티는 다를까?\n\n- 그냥 궁금한 것\n\n자연수의 집합, 비음인 정수의 집합, 음의 정수의 집합, 정수의 집합, 짝수의 집합, 홀수의 집합의 카디널리티는 어떠할까?\n\n- (예제1)\n집합 \\(X=\\{1,2,3\\}\\), \\(Y=\\{2,4,6\\}\\)을 생각하자. 적당한 함수 \\(f\\)를 아래와 같이 정의하자.\n\n\\(f(1)=2\\)\n\\(f(2)=4\\)\n\\(f(3)=6\\)\n\n아래의 질문에 대답해보자.\n\n(단사) 함수 \\(f\\)는 정의역의 모든 값에 대해 함수값이 모두 다른가? // \\(\\forall x_1,x_2 \\in X\\), \\(x_1\\neq x_2\\) \\(\\Rightarrow\\) \\(f(x_1)\\neq f(x_2)\\)?\n(전사) 함수 \\(f\\)는 공역=치역인가? // \\(\\forall y \\in Y~ \\exists x \\in X\\) such that \\(f(x)=y\\).\n\n1의 질문과 2의 질문이 모두 맞으므로 함수 \\(f\\)는 전단사 함수이다. 집합 \\(X\\)에서 집합 \\(Y\\)로 가는 전단사 함수가 존재하므로 집합 \\(X\\)와 집합 \\(Y\\)의 카디널리티는 동일하다.\n- (예제2)\n집합 \\(X=\\{1,2,3,\\dots \\}\\), \\(Y=\\{2,4,6,\\dots \\}\\)을 생각하자. 적당한 함수 \\(f\\)를 아래와 같이 정의하자.\n\n\\(f(1)=2\\)\n\\(f(2)=4\\)\n\\(f(3)=6\\)\n\\(\\dots\\)\n\n아래의 질문에 대답해보자.\n\n(단사) 함수 \\(f\\)는 정의역의 모든 값에 대해 함수값이 모두 다른가? // \\(\\forall x_1,x_2 \\in X\\), \\(x_1\\neq x_2\\) \\(\\Rightarrow\\) \\(f(x_1)\\neq f(x_2)\\)?\n(전사) 함수 \\(f\\)는 공역=치역인가? // \\(\\forall y \\in Y~ \\exists x \\in X\\) such that \\(f(x)=y\\).\n\n1의 질문과 2의 질문이 모두 맞으므로 함수 \\(f\\)는 전단사함수이다. 집합 \\(X\\)에서 집합 \\(Y\\)로 가는 전단사 함수가 존재하므로 집합 \\(X\\)와 집합 \\(Y\\)의 카디널리티는 동일하다.\n- \\(\\aleph_0\\) (알레프 널, 혹은 알레프 제로라고 읽음)\n\n자연수집합 \\(\\mathbb{N}\\)의 카디널리티는 \\(\\aleph_0\\)이다. 즉 \\(|\\mathbb{N}|=\\aleph_0\\).\n짝수인 자연수 집합의 카디널리티는 \\(\\aleph_0\\)이고, 홀수인 자연수 집합의 카디널리티는 \\(\\aleph_0\\)이다.\n정수집합 \\(\\mathbb{Z}\\)의 카디널리티는 \\(\\aleph_0\\)이다. 즉 \\(|\\mathbb{Z}|=\\aleph_0\\).\n\n- 느낌: \\(\\aleph_0\\)를 2배,3배,4배 하여도 \\(\\aleph_0\\)이다.\n\n즉 무한집합의 경우, 본인과 카디널넘버가 같은 진 부분집합이 존재할 수 있다. (유한집합에서는 불가능하겠지)\n무한집합의 정의: 집합 \\(A\\)가 무한집합이다. \\(\\Leftrightarrow\\) \\(A\\)와 동일한 카디널리티를 가지는 \\(A\\)의 진 부분집합이 존재한다.\n\n- (예제3)\n원소의 수가 \\(n\\)인 임의의 유한집합 \\(A\\)에 대하여 \\(|A|=n\\) 이다.\n- (예제4)\n유리수집합의 카디널리티는 얼마인가? (https://en.wikipedia.org/wiki/Rational_number)\n집합 \\(X\\)를 자연수의 집합이라고 하자. 집합 \\(Y\\)를 아래그림에 있는 숫자들의 집합이라고 하자.1\n\n예를들어 집합 \\(X\\)와 집합 \\(Y\\)를 앞의 몇개만 써보면\n\n\\(X=\\{1,2,3,4,5,6,\\dots\\}\\)\n\\(Y=\\{1,\\frac{2}{1},\\frac{1}{2},\\frac{3}{1},\\frac{2}{2},\\frac{1}{3},\\dots \\}\\)\n\n함수 \\(f\\)를 아래와 같이 정의하자.\n\n\\(f(1)=1\\)\n\\(f(2)=2/1\\)\n\\(f(3)=1/2\\)\n\\(f(4)=3/1\\)\n\\(f(5)=2/2\\)\n\\(f(6)=1/3\\)\n\\(\\dots\\)\n\n함수 \\(f\\)는 \\(X\\)에서 \\(Y\\)로 향하는 전단사함수이다. \\(\\Rightarrow\\) \\(|X|=\\aleph_0=|Y|\\)\n(관찰) 임의의 양의 유리수의 집합 \\(\\mathbb{Q}^+\\)는 모두 \\(Y\\)에 포함되어 있다. \\(\\Rightarrow\\) \\(X \\subset \\mathbb{Q}^+ \\subset Y\\) \\(\\Rightarrow\\) \\(|\\mathbb{Q}^+|=\\aleph_0\\)\n(생각) 그럼 음의 유리수의 집합 \\(\\mathbb{Q}^-\\)의 카디널넘버 역시 \\(\\aleph_0\\)이다. 즉 \\(|\\mathbb{Q}^-|=\\aleph_0\\).\n(결론) 그럼 유리수의 카디널넘버는 \\(\\aleph_0\\)이다.2 좀 더 자극적으로 말하면 “자연수의 갯수와 유리수의 갯수는 같다” 라고 말할 수 있다.\n- 조금 무식하게 쓰면 아래와 같이 쓸 수 있다.\n\n\\(\\aleph_0 + 1 = \\aleph_0\\)\n\\(\\aleph_0 \\times 2 = \\aleph_0\\)\n\\(\\aleph_0 \\times \\aleph_0 = \\aleph_0^2 = \\aleph_0\\)\n\n\n\n실수집합의 카디널리티\n- 아래의 관계가 성립했다.\n\n\\(|\\mathbb{N}| = \\aleph_0\\)\n\\(|\\mathbb{N}\\cup \\{0\\}| = \\aleph_0\\)\n\\(|\\mathbb{Z}| = \\aleph_0\\)\n\\(|\\mathbb{Q}| = \\aleph_0\\)\n\n- 그렇다면 아래는 어떠할까?\n\\[|\\mathbb{R}|=??\\]\n(주장) 실수에 포함된 카디널넘버는 유리수의 카디널넘버 보다 크다.\n\n\\(\\mathbb{Q}\\)에서 \\(\\mathbb{R}\\)로 가는 단사함수는 존재하지만 전사함수는 존재할 수 없음을 보이면 된다.\n\\(\\mathbb{N}\\)에서 \\(\\mathbb{R}\\)로 가는 단사함수는 존재하지만 전사함수는 존재할 수 없음을 보여도 상관없다.3\n\n(단사)\n자연수에서 실수로 가는 단사함수는 존재한다. (자연수는 실수의 부분집합이니까)\n(전사)\n소망: \\(\\mathbb{N}\\)에서 \\(\\mathbb{R}\\)로 향하는 전사는 존재할 수 없음을 보이고 싶음.\n소망2: 그런데 \\(\\mathbb{N}\\)에서 \\([0,1]\\)로 향하는 전사가 존재할 수 없음을 보여도 충분함.\n전략: \\(\\mathbb{N}\\)에서 \\([0,1]\\)로 가는 전사가 존재한다고 가정하고 모순을 이끌어 내자.\n1. 아래와 같은 주장을 하는 가상의 인물을 세움:\n\n\\(\\mathbb{N}\\)에서 \\([0,1]\\)로 향하는 전사함수가 존재한다.\n\n2. 그 가상의 인물이 하는 주장을 잘 생각해보면 아래와 같음\n\\(f\\)는 정의역이 자연수이고 공역이 실수인 함수이므로 아래와 같은 형태일 것임.\n\n\\(f(1)=0.2344253456\\cdots\\)\n\\(f(2)=0.3459837981\\cdots\\)\n\\(f(3)=0.5452349871\\cdots\\)\n\\(\\dots\\)\n\n그 가상의 인물의 주장대로라면\n\\[[0,1]=\\{f(1),f(2),f(3),\\dots\\}\\]\n이라는 의미임.4\n3. 전사함수의 정의에 의하여 아래가 성립해야 함\n\n\\(\\forall y\\in [0,1] ~\\exists x \\in \\mathbb{N}\\) such that \\(f(x)=y\\)\n\n아래의 원리에 따라서 \\(y=0.x_1x_2x_3\\cdots\\)를 뽑는다면?\n\n\\(y\\)의 첫번째 소수점의 값 \\(x_1\\)은 \\(f(1)\\)의 첫번째 소수점과 다르게 한다. \\(\\Rightarrow\\) \\(y\\neq f(1)\\) \\(\\Rightarrow\\) \\(y \\notin \\{f(1)\\}\\)\n\\(y\\)의 두번째 소수점의 값 \\(x_2\\)은 \\(f(2)\\)의 두번째 소수점과 다르게 한다. \\(\\Rightarrow\\) \\(y\\neq f(1)\\) and \\(y\\neq f(2)\\) \\(\\Rightarrow\\) \\(y \\notin \\{f(1), f(2)\\}\\)\n\n이러한 \\(y\\)는 분명히 실수이지만 \\(y \\notin \\{f(1),f(2),f(3),\\dots,\\}\\) 이다.5\n\n\n무리수집합의 카디널리티\n(주장) 무리수집합의 카디널리티는 \\(\\aleph_0\\)가 아니다.\n(쉐도복싱) 무리수집합의 카디널리티가 \\(\\aleph_0\\) 이라고 하자.\n\n\\(\\mathbb{R} = \\mathbb{Q} \\cup \\mathbb{Q}^c\\)\n\\(|\\mathbb{Q}|=\\aleph_0\\) 이므로 \\(\\mathbb{Q}\\)와 \\(\\mathbb{N}\\)사이에는 전단사함수가 존재함.\n\\(|\\mathbb{Q}^c|=\\aleph_0\\) 이므로 \\(\\mathbb{Q}^c\\)와 \\(\\mathbb{N}^{-}=\\{-1,-2,\\dots\\}\\)사이에는 전단사함수가 존재함.\n따라서 \\(\\mathbb{Q} \\cup \\mathbb{Q}^c\\) 와 \\(\\mathbb{N} \\cup \\mathbb{N}^-\\) 사이에는 전단사함수가 존재함. (모순)\n\n\n\n\n\n\nFootnotes\n\n\n그래서 일단 집합 \\(Y\\)는 양의 유리수의 집합을 포함한다↩︎\n\\(\\mathbb{Q} = \\mathbb{Q}^+ \\cup \\{0\\} \\cup \\mathbb{Q}^-\\)↩︎\n\\(|\\mathbb{Q}|=|\\mathbb{N}|=\\aleph_0\\)↩︎\n다시 말하면 \\([0,1]\\) 사이의 모든 실수는 “셀수있다”라는 의미임↩︎\n모순이네?↩︎"
  },
  {
    "objectID": "posts/ap/2023-03-16-3wk-1.html",
    "href": "posts/ap/2023-03-16-3wk-1.html",
    "title": "03wk-1: 측도론 intro (3)",
    "section": "",
    "text": "https://youtube.com/playlist?list=PLQqh36zP38-y_-OXU_IFt6uH3oo61swW4"
  },
  {
    "objectID": "posts/ap/2023-03-16-3wk-1.html#전사-단사-전단사",
    "href": "posts/ap/2023-03-16-3wk-1.html#전사-단사-전단사",
    "title": "03wk-1: 측도론 intro (3)",
    "section": "전사, 단사, 전단사",
    "text": "전사, 단사, 전단사\n함수 \\(f: X \\to Y\\) 를 상상하자.\n- 단사함수(일대일함수,인젝티브한 함수): \\(\\forall x_1,x_2 \\in X: ~ x_1 \\neq x_2 \\Rightarrow f(x_1)\\neq f(x_2)\\)\n\n암기 (고등학교): 입력이 다르면 출력이 달라\n느낌: 화살표가 팍 퍼지는 느낌\n그래프를 이용한 판단 (고등학교): 수평선을 그어서 교점이 2개 이상이면 단사함수가 아님\n\n- 전사함수(위로의함수,서젝티브한 함수): \\(\\forall y \\in Y~ \\exists x \\in X\\) such that \\(f(x)=y\\)\n\n암기 (고등학교): 치역 = 공역\n암기 (대학교): inverse image가 정의역에 있어야함 (\\(\\star\\))\n느낌: 화살표가 모이는 느낌\n그래프를 이용한 판단 (고등학교): 모양으로 판단하기 애매함..1\n\n- 전단사함수(일대일대응함수,바이젝티브한 함수)"
  },
  {
    "objectID": "posts/ap/2023-03-16-3wk-1.html#예제-finite-cases",
    "href": "posts/ap/2023-03-16-3wk-1.html#예제-finite-cases",
    "title": "03wk-1: 측도론 intro (3)",
    "section": "예제 (finite cases)",
    "text": "예제 (finite cases)\n\n예시1\n\n\n\n그림1: 단사함수 O, 전사함수 X\n\n\n- 단사함수임을 따져보자!\n\\(\\forall x_1,x_2 \\in X: x_1\\neq x_2 \\Rightarrow f(x_1)\\neq f(x_2)\\)\n\n\n\n\\(x_1\\)\n\\(x_2\\)\n\\(f(x_1)\\)\n\\(f(x_2)\\)\n\n\n\n\n1\n2\nD\nB\n\n\n1\n3\nD\nA\n\n\n2\n1\nB\nD\n\n\n2\n3\nB\nA\n\n\n3\n1\nA\nD\n\n\n3\n2\nA\nB\n\n\n\n- 전사함수임을 따져보자!\n\\(\\forall y \\in Y ~ \\exists x \\in X\\) such that \\(f(x)=y\\)\n\n\n\n\\(y\\)\n\\(x\\) such that \\(f(x)=y\\)\n\n\n\n\nD\n1\n\n\nB\n2\n\n\nC\n?\n\n\nA\n3\n\n\n\n\n\n예시2\n\n\n\n그림2: 단사함수 X, 전사함수 O\n\n\n- 단사함수임을 따져보자!\n\\(\\forall x_1,x_2 \\in X: x_1\\neq x_2 \\Rightarrow f(x_1)\\neq f(x_2)\\)\n\n\n\n\\(x_1\\)\n\\(x_2\\)\n\\(f(x_1)\\)\n\\(f(x_2)\\)\n\n\n\n\n1\n2\nD\nB\n\n\n1\n3\nD\nC\n\n\n1\n4\nD\nC\n\n\n2\n1\nB\nD\n\n\n2\n3\nB\nC\n\n\n2\n4\nB\nC\n\n\n3\n1\nC\nD\n\n\n3\n2\nC\nB\n\n\n3\n4\nC\nC\n\n\n4\n1\nC\nD\n\n\n4\n2\nC\nB\n\n\n4\n3\nC\nC\n\n\n\n- 전사함수임을 따져보자!\n\\(\\forall y \\in Y ~ \\exists x \\in X\\) such that \\(f(x)=y\\)\n\n\n\n\\(y\\)\n\\(x\\) such that \\(f(x)=y\\)\n\n\n\n\nD\n1\n\n\nB\n2\n\n\nC\n3,4\n\n\n\n\n\n예시3\n\n\n\n그림3: 단사함수 X, 전사함수 X\n\n\n- 단사함수임을 따져보자!\n\\(\\forall x_1,x_2 \\in X: x_1\\neq x_2 \\Rightarrow f(x_1)\\neq f(x_2)\\)\n\n\n\n\\(x_1\\)\n\\(x_2\\)\n\\(f(x_1)\\)\n\\(f(x_2)\\)\n\n\n\n\n1\n2\nd\nd\n\n\n1\n3\nd\nc\n\n\n2\n1\nd\nd\n\n\n2\n3\nd\nc\n\n\n3\n1\nc\nd\n\n\n3\n2\nc\nd\n\n\n\n- 전사함수임을 따져보자!\n\\(\\forall y \\in Y ~ \\exists x \\in X\\) such that \\(f(x)=y\\)\n\n\n\n\\(y\\)\n\\(x\\) such that \\(f(x)=y\\)\n\n\n\n\na\n?\n\n\nd\n1,2\n\n\nb\n?\n\n\nc\n3"
  },
  {
    "objectID": "posts/ap/2023-03-16-3wk-1.html#예제-infinite-cases",
    "href": "posts/ap/2023-03-16-3wk-1.html#예제-infinite-cases",
    "title": "03wk-1: 측도론 intro (3)",
    "section": "예제 (infinite cases)",
    "text": "예제 (infinite cases)\n\n예시1\n- 아래를 판단해보자.\n\n\\(f:\\mathbb{R} \\to \\mathbb{R}\\) defined by \\(f(x)=2x+1\\). // 답2\n\\(f:\\mathbb{R} \\to \\mathbb{R}\\) defined by \\(f(x)=x^2\\). // 답3\n\\(f:\\mathbb{R} \\to \\mathbb{R}_{\\geq 0}\\) defined by \\(f(x)=x^2\\). // 답4\n\\(f:\\mathbb{Z} \\to \\{0,1\\}\\) defined by \\(f(x)= x ~\\text{mod}~ 2\\). // 답5\n\\(f:\\mathbb{N} \\to \\mathbb{N} \\cup \\{0\\}\\) defined by \\(f(x)= x-1\\). // 답6\n\\(f:\\mathbb{N} \\to \\mathbb{N}^-\\) defined by \\(f(k)= -k\\). // 답7\n\n여기에서 \\(\\mathbb{N}^-\\{-1,-2,\\dots,\\}\\) 으로 정의\n\n\n\n\n예시2\n- 집합 \\(X\\)가 집합 \\(Y\\)의 부분집합이라면 항상 \\(X\\)에서 \\(Y\\)로 향하는 단사함수가 존재함을 보여라.\n\n따라서 \\(X \\subset Y\\) \\(\\Rightarrow\\) \\(|X|\\leq |Y|\\)"
  },
  {
    "objectID": "posts/ap/2023-03-30-5wk-1.html",
    "href": "posts/ap/2023-03-30-5wk-1.html",
    "title": "05wk-1: 마코프체인 (1)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-xlV_TS7zhmYyyYNKv8np4W"
  },
  {
    "objectID": "posts/ap/2023-03-30-5wk-1.html#확률변수의-평균",
    "href": "posts/ap/2023-03-30-5wk-1.html#확률변수의-평균",
    "title": "05wk-1: 마코프체인 (1)",
    "section": "확률변수의 평균",
    "text": "확률변수의 평균\n- 예제1: 동전을 던지는 예제\n\n\n\n\\(\\omega\\)\n\\(x=X(\\omega)\\)\n\\(P(X=x)\\)\n\n\n\n\n\\(\\omega_1\\)\n\\(0\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\omega_2\\)\n\\(1\\)\n\\(\\frac{1}{2}\\)\n\n\n\n\\[\\therefore E(X)=\\sum_{x=0}^{1}x P(X=x) = \\big(0\\times \\frac{1}{2} + 1 \\times \\frac{1}{2} \\big)=\\frac{1}{2}(0+1)\\]\n- 예제2: 주사위를 던지는 예제\n\n\n\n\\(\\omega\\)\n\\(x=X(\\omega)\\)\n\\(P(X=x)\\)\n\n\n\n\n\\(\\omega_1\\)\n\\(1\\)\n\\(\\frac{1}{6}\\)\n\n\n\\(\\omega_2\\)\n\\(2\\)\n\\(\\frac{1}{6}\\)\n\n\n\\(\\omega_3\\)\n\\(3\\)\n\\(\\frac{1}{6}\\)\n\n\n\\(\\omega_4\\)\n\\(4\\)\n\\(\\frac{1}{6}\\)\n\n\n\\(\\omega_5\\)\n\\(5\\)\n\\(\\frac{1}{6}\\)\n\n\n\\(\\omega_6\\)\n\\(6\\)\n\\(\\frac{1}{6}\\)\n\n\n\n\\[\\therefore E(X)=\\sum_{x=1}^{6}xP(X=x)=\\frac{1}{6}(1+2+3+4+5+6)=3\\]"
  },
  {
    "objectID": "posts/ap/2023-03-30-5wk-1.html#확률벡터의-평균",
    "href": "posts/ap/2023-03-30-5wk-1.html#확률벡터의-평균",
    "title": "05wk-1: 마코프체인 (1)",
    "section": "확률벡터의 평균",
    "text": "확률벡터의 평균\n- 예제1: 동전을 2회 던지는 예제\n\n\n\n\n\n\n\n\n\\(\\omega\\)\n\\({\\boldsymbol x}={\\boldsymbol X}(\\omega)\\)\n\\(P({\\boldsymbol X}={\\boldsymbol x})\\)\n\n\n\n\n\\(\\omega_1\\)\n\\(\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\\)\n\\(\\frac{1}{4}\\)\n\n\n\\(\\omega_2\\)\n\\(\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\)\n\\(\\frac{1}{4}\\)\n\n\n\\(\\omega_3\\)\n\\(\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\)\n\\(\\frac{1}{4}\\)\n\n\n\\(\\omega_4\\)\n\\(\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\)\n\\(\\frac{1}{4}\\)\n\n\n\n\\[\\therefore E({\\boldsymbol X})=\\frac{1}{4}\\left(\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}+\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}+\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}+\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\right)=\\begin{bmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\end{bmatrix} = \\begin{bmatrix} E(X_1)\\\\ E(X_2) \\end{bmatrix}\\]\n\n\\(E(X_1)=E(X_2)\\)인 이유?? iid 이니까~\n\nindependent\n- 예제2: 동전을 10회 던지는 예제\n\n\n\n\n\n\n\n\n\\(\\omega\\)\n\\({\\boldsymbol x}={\\boldsymbol X}(\\omega)\\)\n\\(P({\\boldsymbol X}={\\boldsymbol x})\\)\n\n\n\n\n\\(\\omega_1\\)\n\\([0,0,\\dots,0]^\\top\\)\n\\(\\frac{1}{2^{10}}\\)\n\n\n\\(\\omega_2\\)\n\\([0,0,\\dots,1]^\\top\\)\n\\(\\frac{1}{2^{10}}\\)\n\n\n\\(\\dots\\)\n\\(\\dots\\)\n\\(\\dots\\)\n\n\n\\(\\omega_{1024}\\)\n\\([1,1,\\dots,1]^\\top\\)\n\\(\\frac{1}{2^{10}}\\)\n\n\n\n\\[\\therefore E({\\boldsymbol X})=\\begin{bmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\\\ \\dots \\\\ \\frac{1}{2} \\end{bmatrix} = \\begin{bmatrix} E(X_1)\\\\ E(X_2) \\\\ \\dots \\\\ E(X_{10}) \\end{bmatrix}\\]"
  },
  {
    "objectID": "posts/ap/2023-03-30-5wk-1.html#motivating-example",
    "href": "posts/ap/2023-03-30-5wk-1.html#motivating-example",
    "title": "05wk-1: 마코프체인 (1)",
    "section": "motivating example",
    "text": "motivating example\n- 예제1: 동전을 1000번 던지는 예제를 상상하자. 앞면이 나올 확률은 \\(p\\)이며 이 \\(p\\)는 0.5인지 모른다고 가정하자.\n\nimport numpy as np \n\n\nunknown_probability = np.random.rand()\n\n\nx = np.random.binomial(n=1,p=unknown_probability,size=1000) # X(ω) for some ω\nx\n\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n       1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n       1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n       1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n       1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n       1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 1, 0, 1, 1, 1, 0, 1, 1])\n\n\n\n이것은 적당한 \\(\\omega\\)에 맵핑되어있는 하나의 realization 이다.\n\n- 질문: unknown_probability는 얼마일까??\n\nnp.mean(x), unknown_probability\n\n(0.796, 0.7863482228867129)\n\n\n- 비판: 문제 이상하게 푼다?\n각각이 독립적인 분포를 가지고 있기 때문에 가능\n\n\n\n\n\n\n\n\n\\(\\omega\\)\n\\({\\boldsymbol x}={\\boldsymbol X}(\\omega)\\)\n\\(P({\\boldsymbol X}={\\boldsymbol x})\\)\n\n\n\n\n\\(\\omega_1\\)\n\\([0,0,\\dots,0]^\\top\\)\n\\(\\frac{1}{2^{1000}}\\)\n\n\n\\(\\omega_2\\)\n\\([0,0,\\dots,1]^\\top\\)\n\\(\\frac{1}{2^{1000}}\\)\n\n\n\\(\\dots\\)\n\\(\\dots\\)\n\\(\\dots\\)\n\n\n\\(\\omega_{2^{1000}}\\)\n\\([1,1,\\dots,1]^\\top\\)\n\\(\\frac{1}{2^{1000}}\\)\n\n\n\n\\[\\therefore E({\\boldsymbol X})= \\begin{bmatrix} E(X_1)\\\\ E(X_2) \\\\ \\dots \\\\ E(X_{1000}) \\end{bmatrix}\\]\n\n\\(E(X_{1000})=\\frac{1}{2^{1000}}\\big(\\text{대충 0 혹은 1이 있는 숫자들을 더한것}\\big)=p\\)\n\n\nx[-1] # 이게 하나의 X_{1000} 에 대한 하나의 실현치일 뿐임. \n\n1\n\n\n따라서 개념상으로는 아래와 같이 시뮬레이션하여 구하는게 옳음\n\nsample1 = np.random.binomial(n=1,p=unknown_probability,size=1000) \nsample2 = np.random.binomial(n=1,p=unknown_probability,size=1000) \nsample3 = np.random.binomial(n=1,p=unknown_probability,size=1000) \nsample4 = np.random.binomial(n=1,p=unknown_probability,size=1000) \nsample5 = np.random.binomial(n=1,p=unknown_probability,size=1000) \nsample6 = np.random.binomial(n=1,p=unknown_probability,size=1000) \nsample7 = np.random.binomial(n=1,p=unknown_probability,size=1000) \n\n\n(sample1[-1]+sample2[-1]+sample3[-1]+sample4[-1]+sample5[-1]+sample6[-1]+sample7[-1])/7\n\n0.8571428571428571\n\n\n\nunknown_probability\n\n0.7863482228867129\n\n\n좀 더 많이…\n\nsamples = np.stack([np.random.binomial(n=1,p=unknown_probability,size=1000) for i in range(43052)])\nsamples\n\narray([[1, 1, 1, ..., 1, 0, 1],\n       [1, 0, 1, ..., 0, 1, 1],\n       [1, 0, 0, ..., 1, 1, 1],\n       ...,\n       [1, 1, 1, ..., 1, 1, 0],\n       [0, 1, 0, ..., 1, 1, 1],\n       [1, 0, 1, ..., 1, 1, 1]])\n\n\n\nsamples.shape\n\n(43052, 1000)\n\n\n\nnp.mean(samples[:,-1]) # E(X_{1000})을 근사한것\n\n0.7862120226702592"
  },
  {
    "objectID": "posts/ap/2023-03-30-5wk-1.html#용어정리의-시간",
    "href": "posts/ap/2023-03-30-5wk-1.html#용어정리의-시간",
    "title": "05wk-1: 마코프체인 (1)",
    "section": "용어정리의 시간",
    "text": "용어정리의 시간\n- 확률변수열을 표현할 때 \\(i\\)대신 \\(t\\)로 바꾼다면?\n\n\\(X_1,X_2,X_3,\\dots, X_i, \\dots, X_n\\) \\(\\Rightarrow\\) \\(X_1,X_2,X_3\\dots,X_t,\\dots X_T\\)\n\\(E(X_i)\\) \\(\\Rightarrow\\) \\(E(X_t)\\)\n\\(\\frac{1}{n}\\sum_{i=1}^{n}X_i\\) \\(\\Rightarrow\\) \\(\\frac{1}{T}\\sum_{t=1}^{T}X_t\\)\n\n- 용어: \\(E(X_t)\\)를 앙상블평균 (ensemble average) 이라고 하고, \\(\\frac{1}{T}\\sum_{t=1}^{T}X_t\\)를 시간평균 (time average) 이라고 한다."
  },
  {
    "objectID": "posts/ap/2023-03-30-5wk-1.html#생각의-시간-1",
    "href": "posts/ap/2023-03-30-5wk-1.html#생각의-시간-1",
    "title": "05wk-1: 마코프체인 (1)",
    "section": "생각의 시간 (1)",
    "text": "생각의 시간 (1)\n- 원래 \\(E(X_{1000})\\)은 \\(\\frac{1}{T}\\sum_{t=1}^{T}X_t\\)와 같은 방식으로 근사계산할 수 없긴해. (말도 안되는 소리임..)\n- 예제1: 아래와 같은 확률변수열를 고려하자.\n\n\\(X_1 \\sim Ber(0.5)\\).\n\\(X_t= X_{t-1}\\) for \\(t=2,3,4,\\dots, 1000\\).\n\n\\(E(X_{1000})\\)을 구하여라. \\(E(X_{1000})\\)을 \\(\\frac{1}{T}\\sum_{t=1}^T X_t\\)와 같은 방식으로 근사할 수 있는가?\n(풀이)\n\\(E(X_{1000})=0.5\\)임. 하지만 \\(\\frac{1}{T}\\sum_{t=1}^{T}X_t\\)로 \\(E(X_{1000})\\)을 근사할 수 없음.\n시뮬1 – calculating time average of one-sample \\((x_1,\\dots,x_{1000})\\)\n\nx1 = np.random.binomial(n=1,p=0.5,size=1).item()\nx1\n\n0\n\n\n\none_sample = np.array([x1]*1000)\none_sample\n\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n\n\n\nnp.mean(one_sample)\n\n0.0\n\n\n시뮬2 – approximating ensemble average with 43052 samples\n43052개의 \\(\\omega\\)에서 마지막 가져와서 43052개를 복원추출함\n\nsamples = np.array([[np.random.binomial(n=1,p=0.5,size=1).item()] * 1000 for i in range(43052)])\nsamples \n\narray([[1, 1, 1, ..., 1, 1, 1],\n       [0, 0, 0, ..., 0, 0, 0],\n       [1, 1, 1, ..., 1, 1, 1],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [1, 1, 1, ..., 1, 1, 1]])\n\n\n\nnp.mean(samples[:,-1])\n\n0.5003251881445694\n\n\n- 하지만 사실 iid가정이 있다면 앙상블평균을 시간평균으로 추정해도 문제 없어.\n- 예제2: 서로 독립인 1000개의 확률변수를 \\(N(0,1)\\)에서 뽑는다고 하자.\n\n\\(X_t=\\epsilon_t \\overset{i.i.d.}{\\sim} N(0,1)\\)\n\n이때는 \\(E(X_{1000})\\)을 \\(\\frac{1}{T}\\sum_{t=1}^T X_t\\)와 같은 방식으로 근사할 수 있다.\n시뮬1 – calculating time average of one-sample \\((x_1,\\dots,x_{1000})\\)\n\none_sample = np.random.binomial(1,0.5,1000)\nnp.mean(one_sample)\n\n0.536\n\n\n시뮬2 – approximating ensemble average with 43052 samples\n\nnp.stack([np.random.binomial(1,0.5,1000) for i in range(43052)])[:,-1].mean()\n\n0.4999535445507758\n\n\n- 결론: 원래 time-average와 ensemble-average는 “전혀” 다른 개념이다. 그런데, 확률변수열이 iid일 경우는 time-average로 ensemble-average를 근사계산 할 수 있다.\n- 아래의 그림은 time-average와 ensemble-average의 차이를 파악하기 용이한 예제이다.\n\n\n\n그림1: Davidson (1994) 에서 발췌한 그림.\n\n\n하지만 위는 독립이어야만 가능하지 않을까? 해서 아래 시험 해봤는데 가능함을 확인함"
  },
  {
    "objectID": "posts/ap/2023-03-30-5wk-1.html#ar1",
    "href": "posts/ap/2023-03-30-5wk-1.html#ar1",
    "title": "05wk-1: 마코프체인 (1)",
    "section": "AR(1)",
    "text": "AR(1)\n- 예제3: \\(\\epsilon_t \\overset{i.i.d.}{\\sim} N(0,1)\\) 일 때, 아래와 같은 확률변수 열을 고려하자.\n\n\\(X_1=\\epsilon_1\\)\n\\(X_t=\\frac{7}{8}X_{t-1} + \\epsilon_t\\) for \\(t=2,3,\\dots,T\\)\n\n\neps = np.random.randn(1000)\nx = np.zeros(1000)\nx[0] = eps[0]\nfor t in range(1,1000):\n    x[t] = (7/8)*x[t-1] +eps[t]\n\n\nimport matplotlib.pyplot as plt \n\n\nplt.plot(x,'--o',alpha=0.5)\n\n\n\n\n이때 \\(E(X_{T})\\)을 \\(\\frac{1}{T}\\sum_{t=1}^T X_t\\)와 같은 방식으로 근사할 수 있을까?\n(풀이)\n우선 독립인지 아닌지 체크해보자.\ncheck: \\(X_t\\)와 \\(X_{t-1}\\)은 독립??\n\nplt.plot(x[:-1],x[1:],'o',alpha=0.2)\n\n\n\n\n\ncorr이 있음.. \\(\\Rightarrow\\) 독립아님 \\(\\Rightarrow\\) ensemble-average를 time-average로 근사할 수 없다??\n\n\n참고로 독립이라면~\n\nplt.plot(eps,'--o',alpha=0.5)\n\n\n\n\n\nplt.plot(eps[1:],eps[:-1],'o',alpha=0.2)\n\n\n\n\n\n시뮬1 – calculating time average of one-sample \\((x_1,\\dots,x_{T})\\)\n\ndef gen(T=1000):\n    eps = np.random.randn(T)\n    x = np.zeros(T)\n    x[0] = eps[0]\n    for t in range(1,T):\n        x[t] = (7/8)*x[t-1] +eps[t]\n    return x\n\n\none_sample = gen()\nnp.mean(one_sample)\n\n-0.04427929741501683\n\n\n시뮬2 – approximating ensemble average with 43052 samples\n\nsamples = np.stack([gen() for ω in range(43052)])\n\n\nnp.mean(samples[:,-1])\n\n-0.001607068412044872\n\n\n근사 되는 것 같은데..?"
  },
  {
    "objectID": "posts/ap/2023-03-30-5wk-1.html#생각의-시간-2",
    "href": "posts/ap/2023-03-30-5wk-1.html#생각의-시간-2",
    "title": "05wk-1: 마코프체인 (1)",
    "section": "생각의 시간 (2)",
    "text": "생각의 시간 (2)\n- 확률변수는 값이 랜덤으로 바뀌는 변수느낌이 아니라 \\(X: \\Omega \\to \\mathbb{R}\\) 인 잴 수 있는 함수임.\n- 확률벡터는 값이 랜덤으로 바뀌는 벡터느낌이 아니라 \\(X: \\Omega \\to \\mathbb{R}^d\\) 인 잴 수 있는 함수임.\n- 동전을 반복하여 던져서 관측한 아래와 같은 확률변수열(=확률벡터)\n\\[0,1,0,0,1,1,\\dots,1\\]\n은 어떠한 \\(\\omega \\in \\Omega\\)에 대응하는 하나의 realization \\({\\boldsymbol X}(\\omega)={\\boldsymbol x}\\) 임. (즉 one-sample임)\n- 그런데 확률변수열을 독립으로 얻었다면 이러한 one-sample을 쪼개서 마치 여러개의 샘플을 얻은것처럼 생각할 수 있으며 이때\n\\[E(X_T)\\approx \\frac{1}{T}\\sum_{t=1}^{T}X_t\\]\n와 같은 방식으로 근사할 수 있음.\n- 사실상 \\(E(X_1)=E(X_2)=\\dots=E(X_T) \\approx \\frac{1}{T}\\sum_{t=1}^{T}X_t\\) 이므로 (\\(\\because\\) iid) 결국 아직 관측되지 않은 미래시점 \\(T+1\\)의 값에 대해서도\n\\[E(X_{T+1}) \\approx \\frac{1}{T}\\sum_{t=1}^T X_t\\]\n라고 주장할 수 있음.\n- 이렇게 one-sample을 여러개의 조각으로 쪼개는 기법은 iid에서만 성립할 것 같음. 만약에 iid가정이 없다면 (시뮬2)와 같은 방식으로 여러샘플을 통하여 ensemble-average를 근사시켜야 함. 정리하면 아래와 같음.\n\none-sample만 관측가능, iid 조건 만족 \\(\\Rightarrow\\) 분석가능\n여러개의 sample 관측가능 , iid 조건 만족 \\(\\Rightarrow\\) 분석가능\none-sample만 관측가능, iid 조건 만족하지 않음 \\(\\Rightarrow\\) 분석불가능??\n여러개의 sample 관측가능 , iid 조건 만족하지 않음 \\(\\Rightarrow\\) 분석가능\n\n- 문제: 그런데 실제로 우리가 다루고 싶은 자료의 형태는 3의 경우가 많다.\n- 소망: 그래서 iid가 아니지만 마치 iid인것 처럼 one-sample을 가지고 분석하고 싶다.\n\n앞으로 해야 할 것: 독립인듯 독립아닌 독립같은 확률과정은 없을까?\n\n\n독립인듯 독립아닌 독립같은 확률과정\n\nfig, ax = plt.subplots(3,3,figsize=(10,10))\nax[0][0].plot(x[:-1],x[1:],'o',alpha=0.1)\nax[0][1].plot(x[:-2],x[2:],'o',alpha=0.1)\nax[0][2].plot(x[:-3],x[3:],'o',alpha=0.1)\nax[1][0].plot(x[:-4],x[4:],'o',alpha=0.1)\nax[1][1].plot(x[:-5],x[5:],'o',alpha=0.1)\nax[1][2].plot(x[:-6],x[6:],'o',alpha=0.1)\nax[2][0].plot(x[:-7],x[7:],'o',alpha=0.1)\nax[2][1].plot(x[:-8],x[8:],'o',alpha=0.1)\nax[2][2].plot(x[:-9],x[9:],'o',alpha=0.1)"
  },
  {
    "objectID": "posts/ap/2023-03-07-1wk-2.html",
    "href": "posts/ap/2023-03-07-1wk-2.html",
    "title": "01wk-2: 강의소개",
    "section": "",
    "text": "수업구성\n1. 측도론(실변수함수론)\n\n확률과정을 이해함에 있어서 필요함.\n그런데 학부수준에서는 꼭 필요한 내용은 아님.\n대학원 진학 등 깊이 공부 할 학생들은 필요함.\n\n2. 확률과정론\n\n원래는 금융통계을 위한 백업과목\n여러가지 확률과정 중 우리는 마코프체인에만 집중\n\n3. 마코프체인의 응용 (유동적으로 변경가능)\n\n“마코프체인”이라는 용어가 나오는 응용분야를 리뷰.\nMCMC, 베이지안모형, 토픽모형(LDA), 강화학습, 구글페이지랭크 –&gt; 몇 개만 다를 수 있지 않을까?\n\n\n\n이 수업을 들어야 하는 이유\npass\n\n\n이 수업을 듣지 말아야 하는 이유\n1. F학점 줄 수 있음.\n\n진짜 줌.\n\n2. 쓸모가 없다.\n\n그동안 제가 강의했던 과목들: R입문, 파이썬입문, 통계전산, 데이터시각화, 딥러닝(파이토치/텐서플로우),\n측도론: 재미는 있음. 그런데 대학원가서 고급이론을 공부할 것이 아니면 쓸모가 없다. (통계학과에서 배우는 가장 이론적인 과목)\n확률과정론: 확률과정론 \\(\\to\\) 금융공학으로 가는 교과과정은 학부수준에 다루기 어려움. 마코프체인은 응용이 많이 되는 편이지만 이론을 꼭 알아야 하는건 아니야.\n마코프체인의 응용: 꽤 재미있는 토픽들이 많음. 그런데 이 과목에서 깊게 다루기 불가능.\n\n3. 회귀분석2와 시간이 겹침\n\n이영미교수님 수업!\n회귀분석2는 엄청 중요한 수업이에요.\n지금이라도 늦지 않음"
  },
  {
    "objectID": "posts/ap/2023-05-23-ap-12wk.html",
    "href": "posts/ap/2023-05-23-ap-12wk.html",
    "title": "12wk: 적분 (2)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-xwz12M1ec2nmB2kDOpzoXj"
  },
  {
    "objectID": "posts/ap/2023-05-23-ap-12wk.html#simple-function",
    "href": "posts/ap/2023-05-23-ap-12wk.html#simple-function",
    "title": "12wk: 적분 (2)",
    "section": "simple function",
    "text": "simple function\n- 정의: \\((\\Omega,{\\cal F})\\)가 잴 수 있는 공간이라고 하자. 함수 \\(f:\\Omega \\to \\mathbb{R}\\)가 아래와 같이 표현된다면 \\(f\\)를 simple function 이라고 한다.\n\\[f(\\omega)=\\sum_{i=1}^{n} \\alpha_i \\mathbb{1}_{A_i}(\\omega)\\]\n여기에서 \\(A_1,A_2,\\dots, A_n \\in {\\cal F}\\) 은 서로소인 집합열, \\(\\mathbb{1}_{A_1} = \\begin{cases} 1 & \\omega \\in A_1 \\\\ 0 & \\omega \\not \\in A_1 \\end{cases}\\), 그리고 \\(\\alpha_1,\\alpha_2,\\dots, \\alpha_n \\in \\mathbb{R}\\) 이다. 보통은 위를 간단하게 아래와 같이 사용한다.\n\\[f = \\sum_{i=1}^{n} \\alpha_i \\mathbb{1}_{A_i}\\]\n- 이론: \\(f\\)는 \\({\\cal F}-{\\cal R}\\) measurable map 이다.\n- Note: 가측공간 \\((\\Omega, {\\cal F})\\)에서 정의된 가측함수 \\(f\\)가 finite한 치역을 가진다면 \\(f\\)는 simple function 이다.\n- 정의: \\((\\Omega,{\\cal F})\\)가 잴 수 있는 공간이라고 하자. 함수 \\(\\mu:{\\cal F} \\to [0,\\infty]\\)을 \\((\\Omega, {\\cal F})\\)에서 정의된 \\(\\sigma\\)-finite measure 라고 하자. 또한 함수 \\(f\\)를 \\({\\cal F}-{\\cal R}\\) measurable fucntion 이라고 하자. 만약 \\(f\\)가 아래와 같이 표현된다면\n\\[f=\\sum_{i=1}^{n}\\alpha_i \\mathbb{1}_{A_i}\\]\n즉, \\(f\\)가 simple function 이라면 “\\(f\\)의 \\(\\mu\\)에 대한 적분 (intergral of \\(f\\) w.r.t. \\(\\mu\\))”을 아래와 같이 정의한다.\n\\[\\int f d\\mu = \\sum_{i=1}^{n}\\alpha_i \\mu(A_i)\\]\n- 참고: 동일한 simple function \\(f\\)에 대한 표현 \\(\\sum_{i=1}^{n}\\alpha_i \\mu(A_i)\\) 는 유일하지 않다. (왜냐하면 \\(\\alpha_i\\)가 서로 다른값이라는 가정을 한 것은 아니므로) 아래를 관찰하면 그 이유를 쉽게 알 수 있다.\n\\[\\alpha\\mathbb{1}_{(0,2]}=\\alpha\\mathbb{1}_{(0,1]}+\\alpha\\mathbb{1}_{(1,2]}\\]\n하지만 앞으로의 논리전개에서 이러한 점은 별로 문제되지 않는다. 찝찝하다면 아래의 이론을 확인하고 넘어가도 무방.\n- 이론: \\((\\Omega,{\\cal F})\\)가 잴 수 있는 공간이라고 하자. 함수 \\(\\mu:{\\cal F} \\to [0,\\infty]\\)을 \\((\\Omega, {\\cal F})\\)에서 정의된 \\(\\sigma\\)-finite measure 라고 하자. 또한 함수 \\(f\\)를 \\({\\cal F}-{\\cal R}\\) measurable fucntion 이라고 하자. 만약 \\(f\\)를 아래와 같은 두가지 방법으로 표현 가능하다면\n\\[f=\\sum_{i=1}^{m}\\alpha_i \\mathbb{1}_{A_i}=\\sum_{j=1}^{n}\\beta_j \\mathbb{1}_{B_j}\\]\n아래가 성립한다.\n\\[\\sum_{i=1}^{m}\\alpha_i\\mu(A_i)=\\sum_{j=1}^{n}\\beta_j \\mu(B_j)\\]\n즉 \\(f\\)가 서로 다른 형태의 simple function으로 표현될 수 있으나 \\(\\int f d\\mu\\)가 지칭하는 값은 같다.\n- 하여튼 \\(f\\)가 simple function일 경우는 \\(\\int f d\\mu\\) 가 의미하는 것이 아주 명확하다는 의미.\n- (예제1) – 사각형의 넓이\n두개의 잴 수 있는 공간 \\((\\mathbb{R}, {\\cal R})\\)와 \\((\\mathbb{R}, {\\cal R})\\)을 고려하자. \\(\\lambda:{\\cal R} \\to [0,\\infty]\\)를 르벡메져라고 하자. 함수 \\(f:\\mathbb{R} \\to \\mathbb{R}\\)를 아래와 같이 표현하자.\n\\[f(x) = \\begin{cases} 1 & 0\\leq x \\leq 1 \\\\ 0 & o.w. \\end{cases}\\]\n\\(\\int f d\\lambda\\) 는 잘 정의되는가? 만약 그렇다면 \\(\\int f d\\lambda\\)의 값은 어떻게 계산할 수 있는가?\nnote: 현재는 \\((\\Omega, {\\cal F})=(\\mathbb{R}, {\\cal R})\\)인 상황이다.\n(해설)\n\n\\(\\lambda\\)는 \\((\\mathbb{R}, {\\cal R})\\)에서의 시그마유한측도이다.\n\\(A=[0,1]\\) 일때 함수 \\(f\\)는 \\(f(x) = 1\\times \\mathbb{1}_A(x)\\) 이므로 \\(f\\)는 simple function 이고 따라서 \\({\\cal R}-{\\cal R}\\) 가측함수이다.\n1-2에 의하여 우선 \\(f\\)와 \\(\\lambda\\)는 \\(\\int f d\\lambda\\)라는 기호를 논의할 자격이 있다.\n\\(f\\)가 simple function 일 경우는 \\(\\int f d\\lambda\\) 의 값이 잘 정의되며 그 값은 \\(\\lambda(A)=1\\)이다.\n\n- (예제2) –\n두개의 잴 수 있는 공간 \\((\\mathbb{R}, {\\cal R})\\)와 \\((\\mathbb{R}, {\\cal R})\\)을 고려하자. \\(\\lambda:{\\cal R} \\to [0,\\infty]\\)를 르벡메져라고 하자. 함수 \\(f:\\mathbb{R} \\to \\mathbb{R}\\)를 아래와 같이 표현하자.\n\\[f(x) = \\begin{cases} 1 & x \\in [0,1] \\cap \\mathbb{Q}  \\\\ 2 & x \\in [0,1] \\cap \\mathbb{Q}^c \\\\ 0 & o.w. \\end{cases}\\]\n\\(\\int f d\\lambda\\) 는 잘 정의되는가? 만약 그렇다면 \\(\\int f d\\lambda\\)의 값은 어떻게 계산할 수 있는가?\n(해설)\n\n\\(\\lambda\\)는 \\((\\mathbb{R}, {\\cal R})\\)에서의 시그마유한측도이다.\n\\(A_1=[0,1]\\cap \\mathbb{Q}\\), \\(A_2=[0,1]\\cap \\mathbb{Q}^c\\) 일때 함수 \\(f\\)는 \\(f(x) = 1\\times \\mathbb{1}_{A_1}(x)+ 2\\times \\mathbb{1}_{A_2}(x)\\) 이므로 \\(f\\)는 simple function 이고 따라서 \\({\\cal R}-{\\cal R}\\) 가측함수이다.\n1-2에 의하여 우선 \\(f\\)와 \\(\\lambda\\)는 \\(\\int f d\\lambda\\)라는 기호를 논의할 자격이 있다.\n\\(f\\)가 simple function 일 경우는 \\(\\int f d\\lambda\\) 의 값이 잘 정의되며 그 값은 \\(\\lambda(A_1)+2\\lambda(A_2)=2\\)이다.\n\n- 앞으로의 논리전개: \\(f\\)를 simple function을 이용하여 근사할 수 있을 경우 르벡적분값 \\(\\int f d\\mu\\)가 모순없이 잘 정의됨."
  },
  {
    "objectID": "posts/ap/2023-05-23-ap-12wk.html#non-negative-function",
    "href": "posts/ap/2023-05-23-ap-12wk.html#non-negative-function",
    "title": "12wk: 적분 (2)",
    "section": "non-negative function",
    "text": "non-negative function\n- 정의: \\((\\Omega,{\\cal F})\\)가 잴 수 있는 공간이라고 하자. 함수 \\(\\mu:{\\cal F} \\to [0,\\infty]\\)을 \\((\\Omega, {\\cal F})\\)에서 정의된 \\(\\sigma\\)-finite measure 라고 하자. 또한 함수 \\(f:(\\Omega,{\\cal F})\\to(\\mathbb{R},{\\cal R})\\) non-negative (w.r.t. \\(\\mu\\)) function 이라고 하고 \\(\\varphi:(\\Omega,{\\cal F})\\to(\\mathbb{R},{\\cal R})\\) simple function이라고 하자. 그러면 “\\(f\\)의 \\(\\mu\\)에 대한 적분 (intergral of \\(f\\) w.r.t. \\(\\mu\\))”을 아래와 같이 정의할 수 있다.\n\\[\\int f d\\mu := \\sup\\Big\\{\\int \\varphi d\\mu: 0\\leq \\varphi \\leq f, ~\\text{a.e. with respect to } \\mu \\Big\\}\\]\n- 정의상 \\(\\int f d\\mu\\)는 무한대의 값을 가질 수 있다. 이 경우에도 \\(\\int f d\\mu\\)의 값은 모순 없이 잘 정의된다.\n- (예제1)\n두개의 잴 수 있는 공간 \\((\\mathbb{R}, {\\cal R})\\)와 \\((\\mathbb{R}, {\\cal R})\\)을 고려하자. \\(\\lambda:{\\cal R} \\to [0,\\infty]\\)를 르벡메져라고 하자. 함수 \\(f:\\mathbb{R} \\to \\mathbb{R}\\)를 아래와 같이 표현하자.\n\\[f(x) = \\begin{cases} x & x \\in [0,1] \\\\ 0 & o.w. \\end{cases}\\]\n\\(\\int f d\\lambda\\) 는 잘 정의되는가? 만약 그렇다면 \\(\\int f d\\lambda\\)의 값은 어떻게 계산할 수 있는가?\n(해설)\n\n\\(\\lambda\\)는 \\((\\mathbb{R}, {\\cal R})\\)에서의 시그마유한측도이다.\n\\(f(x)\\)는 가측함수이다.\n따라서 \\(\\int f d\\mu\\)라는 기호를 논의할 자격은 있다.\n1에서 0으로 등간격으로 감소하고 길이가 \\(n\\)인 적당한 수열 \\(a_1,\\dots,a_n\\)에 대하여 서로소인 집합열 \\(A_n = \\{x: f(x)&gt;a_n\\}-A_{n-1}\\) 를 설정하자. 단 \\(A_0=\\emptyset\\).\n함수 \\(\\varphi_n(x)=\\sum_{k=1}^{n} a_k \\times \\mathbb{1}_{A_k}(x)\\)를 고려하자.\n이때 \\(0\\leq \\varphi_n(x) \\leq f\\) a.e. w.r.t. \\(\\lambda\\).\n모든 \\(n \\in \\mathbb{N}\\) 에 대하여 \\(\\int \\varphi_nd \\lambda\\)의 값은 잘 정의된다. (simple function 이므로)\n따라서 집합 \\(\\big\\{\\int \\varphi_n(x)d\\lambda\\big\\}\\) 역시 잘 정의되며 \\(\\sup\\big\\{\\int \\varphi_n(x)d\\lambda\\big\\}=\\frac{1}{2}\\) 역시 잘 정의된다.\n\n- 임의의 양의함수에 대하여서도 아래와 같은 방식으로 근사할 수 있다.\n\n\n\n위키에서 긁은 그림: 구불구불한 \\(f\\)를 simple function의 합으로 근사할 수 있다."
  },
  {
    "objectID": "posts/ap/2023-05-23-ap-12wk.html#measurable-function",
    "href": "posts/ap/2023-05-23-ap-12wk.html#measurable-function",
    "title": "12wk: 적분 (2)",
    "section": "measurable function",
    "text": "measurable function\n- 지금까지의 스토리: \\(\\sigma\\)-finite measurable space \\((\\Omega, {\\cal F}, \\mu)\\) 를 고려하자. 아래의 경우 \\(\\int f d\\mu\\) 의 값이 모순없이 잘 정의되었다.\n\n\\(f:(\\Omega, {\\cal F}) \\to (\\mathbb{R}, {\\cal R})\\)인 simple function\n\\(f:(\\Omega, {\\cal F}) \\to (\\mathbb{R}, {\\cal R})\\)인 non-negative (w.r.t. \\(\\mu\\)) function\n\n이제 일반적인 \\(f:(\\Omega,{\\cal F}) \\to (\\mathbb{R}, {\\cal R})\\) 에 대하여 \\(\\int f d\\mu\\) 의 값이 모순없이 잘 정의되는 조건을 살펴보겠다.\n- 임의의 함수 \\(f:\\Omega \\to \\mathbb{R}\\)에 대하여 아래와 같은 함수를 관찰하자.\n\n\\(f^+ = \\max(0,f)\\)\n\\(f^- = \\max(0,-f)\\)\n\n함수 \\(f^+\\) 와 \\(f^-\\)는 아래의 성질이 성립한다.\n\n\\(f^+, f^-\\) 는 모두 양수이다.\n\\(|f| = f^+ + f^-\\)\n\\(f = f^+ - f^-\\)\n\n- 이론 만약에 \\(f:(\\Omega, {\\cal F}) \\to (\\mathbb{R},{\\cal R})\\) 이면\n\n\\(f^+: (\\Omega, {\\cal F}) \\to (\\mathbb{R},{\\cal R})\\)\n\\(f^: (\\Omega, {\\cal F}) \\to (\\mathbb{R},{\\cal R})\\)\n\n이다.\n- 정의: \\(\\sigma\\)-finite measurable space \\((\\Omega, {\\cal F}, \\mu)\\) 를 고려하자. 일반적인 가측함수 \\(f:(\\Omega, {\\cal F}) \\to (\\mathbb{R},{\\cal R})\\)의 \\(\\mu\\)에 대한 적분 (intergral of \\(f\\) w.r.t. \\(\\mu\\)) 은 아래와 같이 생각할 수 있다.\n\\[\\int f d\\mu := \\int f^+ d\\mu - \\int f^- d\\mu\\]\n이 값은 잘 정의될 수도 있고, 그렇지 않을 수도 있다. 구체적으로 아래와 같다.\n\n\\(\\int f^+ d\\mu &lt; \\infty\\) and \\(\\int f^- d\\mu &lt; \\infty\\) \\(\\Rightarrow\\) \\(\\int f d\\mu = \\int f^+ d\\mu - \\int f^- d\\mu\\) 로 정의\n\\(\\int f^+ d\\mu = \\infty\\) and \\(\\int f^- d\\mu &lt; \\infty\\) \\(\\Rightarrow\\) \\(\\int f d\\mu = \\infty\\) 로 정의\n\\(\\int f^+ d\\mu &lt; \\infty\\) and \\(\\int f^- d\\mu = \\infty\\) \\(\\Rightarrow\\) \\(\\int f d\\mu = -\\infty\\) 로 정의\n\\(\\int f^+ d\\mu = \\infty\\) and \\(\\int f^- d\\mu = \\infty\\) \\(\\Rightarrow\\) \\(\\int f d\\mu\\) 는 정의할 수 없음.\n\n이중에서 1,2,3에 해당하는 경우는 “\\(\\int f d\\mu\\)가 존재한다 (exist)” 고 표현하며, 4의 경우는 “\\(\\int f d\\mu\\) 가 존재하지 않는다”고 표현한다. 이때 1의 경우를 특별하게 “\\(f\\) is integrable w.r.t. \\(\\mu\\)” 라고 표현한다.\n\n헷갈려: 언뜻 생각하면 “\\(f\\)가 \\(\\mu\\)에 대하여 적분가능하지 않다”라는 의미가 “\\(\\int f d\\mu\\) 의 값을 모순없이 잘 정의할 수 없다” 라는 의미로 이해할 수 있는데 그렇지 않다.\n\n- 위의 정의에서 \\(\\int f^+ d\\mu\\) 혹은 \\(\\int f^- d\\mu\\) 라는 표현이 잘 정의되는 이유는 \\(f^+, f^-\\)이 모두 \\((\\Omega, {\\cal F}) \\to \\mathbb{R}, {\\cal R})\\)인 non-negative (w.r.t. \\(\\mu\\)) function 이기 때문이다."
  },
  {
    "objectID": "posts/ap/2023-05-23-ap-12wk.html#notations-starstarstarstarstar",
    "href": "posts/ap/2023-05-23-ap-12wk.html#notations-starstarstarstarstar",
    "title": "12wk: 적분 (2)",
    "section": "NOTATIONS (\\(\\star\\star\\star\\star\\star\\))",
    "text": "NOTATIONS (\\(\\star\\star\\star\\star\\star\\))\n- \\((\\Omega, {\\cal F}, \\mu)\\) 가 \\((\\mathbb{R}, {\\cal R}, \\lambda)\\) 이면\n\n\\(\\int f(x)dx = \\int f d\\lambda\\)\n\\(\\int_a^b f(x)dx = \\int_E fd\\lambda\\)\n\n와 같이 사용한다. 단, 여기에서 \\(E=[a,b]\\). (Durrett 2019, p 23)\n- \\(\\int_E fd\\lambda\\)는 종종\n\n\\(\\int_E f(x)\\lambda(dx)=\\int_E f(x)d\\lambda(x)\\)\n\\(\\int_E f(y)\\lambda(dy)=\\int_E f(y)d\\lambda(y)\\)\n\n와 같이 표현하기도 한다. 이러한 표현은 때때로 유용하다. 예를들어\n\n\\(\\int_{(0,1)}x^y \\lambda(dx)=\\int_{(0,1)}x^y d\\lambda(x)\\) 는 함수 \\(x \\mapsto x^y\\) 에 대한 적분을\n\\(\\int_{(0,1)}x^y \\lambda(dy)=\\int_{(0,1)}x^y d\\lambda(y)\\) 는 함수 \\(y \\mapsto x^y\\) 에 대한 적분을\n\n의미한다. (Makarov and Podkorytov 2013, p 125), (Durrett 2019, p 32, p 38)\n- \\((\\Omega, {\\cal F}, \\mu)\\) 가 \\((\\mathbb{R}, {\\cal R}, \\mu_X)\\) 이고 \\(F_X = \\mu_X((-\\infty,x])\\) 라면\n\n\\(\\int g d\\mu_X= \\int g dF_X= \\int g(x) dF_X(x)\\)\n\n와 같이 사용할 수 있다. 만약에 \\(F_X(x)\\)가 density function \\(f_X(x)\\)를 가진다면\n\n\\(\\int g(x) dF_X(x) = \\int g(x)f_X(x)dx\\)\n\n와 같이 사용할 수 있다. 표현 \\(\\int g(x) dF_X(x)\\) 와 \\(\\int g(x)f_X(x)dx\\) 는 모두 \\(\\mathbb{E}[g(X)]\\) 를 의미하지만 \\(\\int g(x) dF_X(x)\\)는 확률변수 \\(X\\)의 density가 존재하지 않을 때에도 표현가능하다는 장점이 있다. (Durrett 2019, p 23)\n- \\((\\Omega,{\\cal F},\\mu)\\) 에서\n\n\\(\\Omega\\): a countable set\n\\({\\cal F}\\): \\(2^\\Omega\\)\n\\(\\#\\): counting measure\n\n라고 하자. 그러면\n\n\\(\\int f d\\# = \\sum_{i \\in \\Omega} f(i)\\)\n\n이 성립한다. (Durrett 2019, p 23)\n- 예시1: \\((\\mathbb{N}, 2^{\\mathbb{N}}, \\#)\\) 를 고려하자. 여기에서 \\(\\#\\)는 counting measure 이다. 그렇다면\n\\[\\sum_{i=1}^{\\infty} 1/2^n = \\int 1/2^n d\\#\\]\n와 같이 표현할 수 있다. 이는 이전에 수행하였던 르벡적분이\n\n치역을 쪼갠다.\n쪼개진 치역에 대한 정의역의 길이를 측정한다.\n1과 2를 곱한뒤 모두 더한다\n\n의 과정을 수행한다는 사실을 떠올리면 쉽게 이해할 수 있다.\n- 가장 중요한 응용: \\((\\Omega, {\\cal F}, \\mu)\\)가 확률공간일 경우!"
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html",
    "href": "posts/ap/2023-04-11-ap-06wk.html",
    "title": "06wk: 측도론 (2)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-y2r-mEbWKnTAC_8CN5HcGo"
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html#약한조건-약한정리-강한조건-강한정리",
    "href": "posts/ap/2023-04-11-ap-06wk.html#약한조건-약한정리-강한조건-강한정리",
    "title": "06wk: 측도론 (2)",
    "section": "약한조건, 약한정리, 강한조건, 강한정리",
    "text": "약한조건, 약한정리, 강한조건, 강한정리\n- 정리: 어떠한 조건을 만족하면, 어떠한 결론이 나온다.\n\n결론: 우리가 원하는 것.\n조건: 우리가 원하는 것을 얻기 위한 고난과정.\n\n- 결론이 동일하다면 조건이 약할 수록 유리하다.\n\n정리1: 수업에 온라인으로 참석하거나 오프라인으로 참석한다면 모두 출석으로 인정한다.\n정리2: 수업에 오프라인으로 참석할때만 출석으로 인정한다.\n\n\n정리2의 조건이 만족되면 정리1의 조건은 자동으로 만족된다. 따라서 정리2의 조건이 더 강한 조건이다. 조건이 강할수록 불리하므로 정리2가 더 불리하다.\n\n- 조건이 동일하다면 결론이 강한 쪽이 유리하다.\n\n정리1: 중간고사와 기말고사를 모두 응시한다면, B학점 이상이다.\n정리2: 중간고사와 기말고사를 모두 응시한다면, A학점 이상이다.\n\n\n정리2의 결론이 만족되면 정리1의 결론은 자동으로 만족되므로 정리2의 결론이 더 강하다. 결론은 강할수록 유리하므로 정리2가 더 유리하다."
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html#쓸모없는-측도",
    "href": "posts/ap/2023-04-11-ap-06wk.html#쓸모없는-측도",
    "title": "06wk: 측도론 (2)",
    "section": "쓸모없는 측도",
    "text": "쓸모없는 측도\n- 세상엔 측도의 정의를 만족하지만 쓸모 없는 측도가 있다.\n\n예시1: \\({\\cal F}\\)의 모든 원소의 메져값은 0이다.\n예시2: \\({\\cal F}\\)의 모든 원소의 메져값은 무한대이다.\n\n- 예시2와 같은 측도를 고려하고 싶지 않음 \\(\\Rightarrow\\) 유한측도, 시그마유한측도의 개발"
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html#쓸모없는-가측공간",
    "href": "posts/ap/2023-04-11-ap-06wk.html#쓸모없는-가측공간",
    "title": "06wk: 측도론 (2)",
    "section": "쓸모없는 가측공간",
    "text": "쓸모없는 가측공간\n- 세상엔 쓸모없는 잴 수 없는 공간이 있다. (유의미한 측도를 주는게 불가능한 잴 수 있는 공간)\n\n예시1: \\({\\cal F}= \\{\\emptyset, \\Omega\\}\\)\n예시2: \\(\\Omega =\\mathbb{R}\\) 일때 \\({\\cal F}=2^{\\mathbb{R}}\\) (르벡메져로 측정불가능함, 모든 원소의 메져를 0으로 잡으면 무모순으로 길이를 정의할 수는 있겠으나 무슨의미?)\n\n- 예시2와 같은 \\({\\cal F}\\)는 고려하고 싶지 않음 \\(\\Rightarrow\\) \\(\\sigma({\\cal A})\\), 카라테오도리 확장정리의 고안."
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html#유한측도-시그마유한측도",
    "href": "posts/ap/2023-04-11-ap-06wk.html#유한측도-시그마유한측도",
    "title": "06wk: 측도론 (2)",
    "section": "유한측도, 시그마유한측도",
    "text": "유한측도, 시그마유한측도\n- \\(m\\)이 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\)에서의 측도라고 하자.\n\n\\(\\forall A \\in {\\cal F}\\), \\(m(A) &lt; \\infty\\) 이면 \\(m\\)을 유한측도라고 한다.1\n\\(\\exists A_1,A_2,\\dots \\in {\\cal F}\\) such that (1) \\(\\cup_{i=1}^{\\infty}A_i = \\Omega\\) (2) \\(\\forall i \\in \\mathbb{N}:~ m(A_i)&lt;\\infty\\) 이면 \\(m\\)을 시그마유한측도라고 한다.\n\n- NOTE: 모든 확률측도는 유한측도이다. 모든 유한측도는 시그마유한측도이다.2\n\n확률측도라는 것은 매우 강한 조건임\n시그마유한측도라는 것은 확률측도보다 훨씬 약한 조건임\n\n- 직관: 제 생각일 뿐이어요..\n\n세상엔 측도의 정의는 만족하지만 쓸모없는 측도가 있다. (모든 원소를 쟀더니 0이더라, 모든 원소를 쟀더니 무한대더라)\n그래서 모든 원소값에 무한대를 주는 측도는 인정하고 싶은 마음이 별로 없음. (하지만 측도의 정의는 만족)\n그래서 그냥 유한측도만 생각하기로 했는데…\n\n- 유한측도는 아니지만 시그마유한측도의 정의를 만족하는 경우 (엄청 중요해 보이는 예제들이 시그마유한측도잖아?)\n\n르벡메져\n카운팅메져: \\(m\\) is counting msr on \\((\\Omega, {\\cal F})\\) iff \\(m(A) = \\begin{cases} |A| & {\\tt if}~ A~{\\tt is~finite} \\\\ \\infty & {\\tt if}~A~{\\tt is~infinite}\\end{cases}\\)\n\n- 시그마유한측도의 느낌: 전체집합을 카운터블 유니온으로 커버하는 메져유한인 집합열이 1개만 있으면 된다.\n(기억해둘만한 예시)\n\\((\\mathbb{Z}, 2^{\\mathbb{Z}})\\) 를 잴 수 있는 공간이라고 하자. \\(m\\)을 공간 \\((\\mathbb{Z}, 2^{\\mathbb{Z}})\\)에서의 카운팅메져라고 하자.\n집합열1\n\n\\(A_1=\\mathbb{N}\\)\n\\(A_2=\\mathbb{N} \\cup \\{0\\}\\)\n\\(A_3=\\mathbb{N} \\cup \\{-1,0\\}\\)\n\\(\\dots\\)\n\n집합열2\n\n\\(B_1=\\{0\\}\\)\n\\(B_2=\\{0,1\\}\\)\n\\(B_3=\\{-1,0,1\\}\\)\n\\(\\dots\\)\n\n집합열1와 집합열2는\n\n(1) \\(\\cup_{i=1}^{\\infty}A_i=\\mathbb{Z}\\), (2) \\(\\forall i \\in \\mathbb{N}:~ m(A_i)=\\infty\\)\n(1) \\(\\cup_{i=1}^{\\infty}B_i=\\mathbb{Z}\\), (2) \\(\\forall i \\in \\mathbb{N}:~ m(B_i)&lt;\\infty\\)\n\n를 만족한다. 즉 집합열1은 전체집합을 카운터블 유니온으로 커버하지만 메져유한은 아니고, 집합열2는 전제집합을 카운터블 유니온으로 커버하고 메져유한이다. 집합열2의 존재로 인하여 \\(m\\)은 \\((\\mathbb{Z}, 2^{\\mathbb{Z}})\\)에서의 시그마유한측도가 된다."
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html#확률공간",
    "href": "posts/ap/2023-04-11-ap-06wk.html#확률공간",
    "title": "06wk: 측도론 (2)",
    "section": "확률공간",
    "text": "확률공간\n- \\(P:{\\cal F} \\to [0,1]\\) 가 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\) 에서의 확률측도라면, \\((\\Omega, {\\cal F}, P)\\) 를 확률공간이라 선언할 수 있다.\n- \\((\\Omega, {\\cal F})\\)가 잴수 있는 공간이라는 선언은 \\({\\cal F}\\)가 \\(\\Omega\\)에 대한 시그마필드라는 것이 내포되어 있다.\n- \\((\\Omega, {\\cal F}, P)\\)가 확률공간이라는 선언에는\n\n\\({\\cal F}\\)는 \\(\\Omega\\)에 대한 시그마필드이며,\n\\(P\\)는 \\((\\Omega, {\\cal F})\\)에서의 확률측도임이 내포되어 있다.\n\n- 교재의 언급 (p1) – 초록색부분\n\n\n\n그림1: 교재에 언급된 확률공간, 잴 수 있는 공간의 정의"
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html#시그마유한측도공간",
    "href": "posts/ap/2023-04-11-ap-06wk.html#시그마유한측도공간",
    "title": "06wk: 측도론 (2)",
    "section": "시그마유한측도공간",
    "text": "시그마유한측도공간\n- \\(m:{\\cal F} \\to [0,\\infty]\\)이 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\)에서의 시그마유한측도라면, \\((\\Omega, {\\cal F}, m)\\)을 시그마유한측도공간이라 부른다.\n- \\((\\Omega, {\\cal F}, m)\\)이 시그마유한측도공간이라는 선언에는\n\n\\({\\cal F}\\)는 \\(\\Omega\\)에 대한 시그마필드이며,\n\\(m\\)는 \\((\\Omega, {\\cal F})\\)에서의 시그마유한측도임이 내포되어 있다."
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html#state",
    "href": "posts/ap/2023-04-11-ap-06wk.html#state",
    "title": "06wk: 측도론 (2)",
    "section": "state",
    "text": "state\n- Thm (귀찮아서 만든 이론1): 모든 \\({\\cal A} \\subset 2^{\\Omega}\\) 에 대하여 smallest \\(\\sigma\\)-field containing \\({\\cal A}\\), 즉 \\(\\sigma({\\cal A})\\)는 존재한다.\n\n그리고 당연히 smallest 조건에 의에서 유일성이 보장됨"
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html#증명을-위한-준비학습",
    "href": "posts/ap/2023-04-11-ap-06wk.html#증명을-위한-준비학습",
    "title": "06wk: 측도론 (2)",
    "section": "증명을 위한 준비학습",
    "text": "증명을 위한 준비학습\n- 이론: (\\(\\star\\)) 임의의 인덱스 집합 \\(I\\neq\\emptyset\\)를 고려하자. 여기에서 \\(I\\)는 uncountable set일 수도 있다. 아래의 사실에 증명하라.\n\n\\({\\cal F}_i\\)가 모두 시그마필드라면, \\(\\cap_{i \\in I}{\\cal F_i}\\) 역시 시그마필드이다.\n\n(증명)\n편의상 \\({\\cal F}= \\cap_{i \\in I} {\\cal F}_i\\) 라고 하자. \\({\\cal F}\\)가 시그마필드임을 보이기 위해서는\n\n\\(A \\in {\\cal F} \\Rightarrow A^c \\in {\\cal F}\\)\n\\(A_1,A_2 \\dots \\in {\\cal F} \\Rightarrow \\cup_{i}A_i \\in {\\cal F}\\)\n\n만 보이면 된다. (이럴때는 전체집합 조건하나를 빼는게 유리하다)\n1번체크\n\\(A \\in {\\cal F} \\Rightarrow \\forall i: A \\in {\\cal F}_i \\Rightarrow \\forall i: A^c \\in {\\cal F}_i \\Rightarrow A^c \\in {\\cal F}\\)\n2번체크\n\\(A_1,A_2,\\dots \\in {\\cal F} \\Rightarrow \\forall i: A_1,A_2,\\dots \\in {\\cal F}_i \\Rightarrow \\forall i: \\cup_jA_j \\in {\\cal F}_i \\Rightarrow \\cup_jA_j \\in {\\cal F}\\)"
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html#증명",
    "href": "posts/ap/2023-04-11-ap-06wk.html#증명",
    "title": "06wk: 측도론 (2)",
    "section": "증명",
    "text": "증명\n- Thm (귀찮아서 만든 이론1): 모든 \\({\\cal A} \\subset 2^{\\Omega}\\) 에 대하여 smallest \\(\\sigma\\)-field containing \\({\\cal A}\\), 즉 \\(\\sigma({\\cal A})\\)는 존재한다.\n\n그리고 당연히 smallest 조건에 의해 유일성이 보장됨\n\n(증명)\n\\({\\cal A}\\)를 포함하는 모든 시그마필드를 구하고 그걸 교집합하여 결과를 \\({\\cal F}\\)라고 하자. 아래의 사실은 자명하게 성립한다.\n\n시그마필드의 교집합은 시그마필드이므로 \\({\\cal F}\\)는 시그마필드이다.\n교집합을 하면 할수록 집합은 작아지므로 \\({\\cal F}\\)는 위에서 구한 시그마필드중에서 가장 작다.\n\\({\\cal F}\\)는 \\({\\cal A}\\)를 포함한다.\n\n따라서 \\({\\cal F}\\)는 (\\({\\cal A}\\)를 포함하는 모든 시그마필드를 교집합하여 얻은 집합) \\({\\cal A}\\)를 포함하는 가장 작은 시그마필드가 된다.\n- 아래는 교재의 언급 (p3)\n\n\n\n그림2: Durret교재에서 언급된 “귀찮아서 만든 이론1”"
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html#state-1",
    "href": "posts/ap/2023-04-11-ap-06wk.html#state-1",
    "title": "06wk: 측도론 (2)",
    "section": "state",
    "text": "state\n- Thm: 딘킨의 \\(\\pi-\\lambda\\) 정리 ver1. (\\(\\star\\))\n\\({\\cal P}\\)가 파이시스템이면 \\(l({\\cal P})=\\sigma({\\cal P})\\)이다."
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html#증명을-위한-준비학습-1",
    "href": "posts/ap/2023-04-11-ap-06wk.html#증명을-위한-준비학습-1",
    "title": "06wk: 측도론 (2)",
    "section": "증명을 위한 준비학습",
    "text": "증명을 위한 준비학습\n- 이론: 임의의 인덱스 집합 \\(I\\neq\\emptyset\\)를 고려하자. 여기에서 \\(I\\)는 uncountable set일 수도 있다. 아래의 사실이 성립한다.\n\n\\({\\cal F}_i\\)가 모두 시그마필드라면, \\(\\cap_{i \\in I}{\\cal F_i}\\) 역시 시그마필드이다.\n\\({\\cal A}_i\\)가 모두 시그마링, \\(\\cap_{i \\in I}{\\cal A_i}\\) 역시 시그마링이다.\n\\({\\cal A}_i\\)가 모두 알지브라라면, \\(\\cap_{i \\in I}{\\cal A_i}\\) 역시 알지브라이다.\n\\({\\cal A}_i\\)가 모두 링이라면, \\(\\cap_{i \\in I}{\\cal A_i}\\) 역시 링이다.\n\\({\\cal A}_i\\)가 모두 람다시스템이라면, \\(\\cap_{i \\in I}{\\cal A_i}\\) 역시 람다시스템이다.\n\n\n세미알지브라, 세미링, 파이시스템은 성립안함.\n\n- 예제1: 아래를 고려하자.\n\n\\(\\Omega = \\{1,2,3,4\\}\\)\n\\({\\cal A}_1 = \\{\\emptyset, \\{1\\}, \\{2,3\\}, \\{4\\}, \\Omega\\}\\)\n\\({\\cal A}_2 = \\{\\emptyset, \\{1\\}, \\{2\\}, \\{3,4\\}, \\Omega\\}\\)\n\n\\({\\cal A}_1, {\\cal A}_2\\)는 모두 세미알지브라이다. 하지만 \\({\\cal A}_1 \\cap {\\cal A}_2 = \\{\\emptyset, \\Omega, \\{1\\}\\}\\)은 세미알지브라가 아니다.\n\n이 예제에서 세미알지브라를 세미링으로 바꾸고 읽어도 성립함.\n\n- 예제2: 아래를 고려하자.\n\n\\(\\Omega=\\{H,T\\}\\)\n\\({\\cal A}_1 = \\{\\{H\\}\\}\\)\n\\({\\cal A}_2 = \\{\\{T\\}\\}\\)\n\n\\({\\cal A}_1, {\\cal A}_2\\)는 모두 파이시스템이다. 하지만 \\({\\cal A}_1 \\cap {\\cal A}_2 = \\emptyset\\)은 파이시스템이 아니다.\n- 이론: 임의의 \\({\\cal A}\\)에 대하여 아래는 존재한다.\n\n\\({\\cal A}\\)를 포함하는 가장 작은 시그마필드, \\(\\sigma({\\cal A})\\)\n\\({\\cal A}\\)를 포함하는 가장 작은 시그마링\n\\({\\cal A}\\)를 포함하는 가장 작은 알지브라\n\\({\\cal A}\\)를 포함하는 가장 작은 링\n\\({\\cal A}\\)를 포함하는 가장 작은 람다시스템, \\(l({\\cal A})\\)\n\n- 참고: “\\({\\cal A}\\)를 포함하는 가장 작은 세미링”, 혹은 “\\({\\cal A}\\)를 포함하는 가장 작은 세미알지브라”와 같은 것은 존재하지 않음.\n- 예제3: 아래를 고려하자.\n\n\\(\\Omega = \\{1,2,3,4\\}\\)\n\\({\\cal A} = \\{\\emptyset, \\Omega, \\{1\\}\\}\\)\n\n이때 \\({\\cal A}\\)를 포함하는 가장 작은 세미알지브라가\n\\[{\\cal A}_1 = \\{\\emptyset, \\Omega, \\{1\\}, \\{2,3,4\\}\\}\\]\n라고 주장할 수는 없음. 왜냐하면\n\\[{\\cal A}_2 = \\{\\emptyset, \\Omega, \\{1\\}, \\{2\\},\\{3\\},\\{4\\}\\}\\]\n역시 \\({\\cal A}\\)를 포함하는 세미알지브라이지만 \\({\\cal A}_1 \\not \\subset {\\cal A}_2\\)이므로.\n- 이론: \\({\\cal P}\\)가 파이시스템이라고 하자. 아래가 성립한다.\n\n\\({\\cal P}\\)를 포함하는 가장 작은 시그마필드는 그 자체로 파이시스템이다. (즉 \\(\\sigma({\\cal P})\\)는 파이시스템이다)\n\\({\\cal P}\\)를 포함하는 가장 작은 시그마링은 그 자체로 파이시스템이다.\n\\({\\cal P}\\)를 포함하는 가장 작은 알지브라는 그 자체로 파이시스템이다.\n\\({\\cal P}\\)를 포함하는 가장 작은 링은 그 자체로 파이시스템이다.\n\\({\\cal P}\\)를 포함하는 가장 작은 람다시스템은 그 자체로 파이시스템이다?? (즉 \\(l({\\cal P})\\)는 파이시스템이다?)\n\n- 1-4는 자명한데, 5는 자명하지 않다. 하지만 성립한다. (5의 증명은 복잡함. 그냥 암기하자.)\n- 이론: \\({\\cal A}\\)가 람다시스템이다. \\(\\Rightarrow\\) (\\({\\cal A}\\)는 시그마필드이다. \\(\\Leftrightarrow\\) \\({\\cal A}\\)는 파이시스템이다.)\n(증명) 아래의 표를 살펴보면 간단하게 증명가능하다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(A \\cap B\\)\n\\(\\emptyset\\)\n\\(A-B\\)\n\\(\\cup_iA_i=\\uplus_i B_i\\)\n\\(\\Omega\\)\n\\(A^c\\)\n\\(A\\cup B\\)\n\\(\\cup_{i=1}^{\\infty}A_i\\)\n\\(\\uplus_{i=1}^{\\infty}B_i\\)\n\\(\\cap_{i=1}^{\\infty}A_i\\)\n\n\n\n\n\\(\\pi\\)-system\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\n\n\\(\\lambda\\)-system\n\\(X\\)\n\\(O\\)\n\\(\\Delta'\\)\n\\(X\\)\n\\(O\\)\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(O\\)\n\\(X\\)\n\n\n\\(\\sigma\\)-field\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)"
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html#증명-1",
    "href": "posts/ap/2023-04-11-ap-06wk.html#증명-1",
    "title": "06wk: 측도론 (2)",
    "section": "증명",
    "text": "증명\n(증명)\n\\(l(\\cal P) \\subset \\sigma({\\cal P})\\) 임을 보이고, \\(l(\\cal P) \\supset \\sigma({\\cal P})\\) 임을 보이면된다.\n“\\(\\subset\\)”: 당연하다.3\n“\\(\\supset\\)”: \\(l({\\cal P})\\)가 시그마필드임을 보이면 자동으로 \\(l({\\cal P}) \\supset \\sigma({\\cal P})\\)임이 보여진다.\n\\(l({\\cal P})\\)이 시그마필드임은 아래를 조합하면 간단히 증명된다.\n\n파이시스템 \\({\\cal P}\\)를 포함하는 가장 작은 람다시스템 \\(l({\\cal P})\\)은 그 자체로 파이시스템이다.\n\\({\\cal A}\\)가 람다시스템이다. \\(\\Rightarrow\\) (\\({\\cal A}\\)는 시그마필드이다. \\(\\Leftrightarrow\\) \\({\\cal A}\\)는 파이시스템이다.)\n\n- 생각의 시간\n\n시그마필드(=잴 수 있는 집합의 모임)을 만들기 위해서는, 그 모임(=collection)이 파이시스템이면서 동시에 람다시스템임을 보이면 된다.\n딘킨의 정리는 적당한 파이시스템을 만들고 그것을 통하여 잴 수 있는 집합의 모임을 확률의 공리에 맞게만 설정한다면, 그것이 시그마필드가 된다는 것을 보이는 것이다.\n\n- 제 생각\n\n메져가 “선분의 길이”를 일반화 하는 개념이라 생각한다면 파이시스템에서 시작하여 시그마필드로 확장하는 것이 자연스럽다.\n메져가 “확률”을 일반화하는 개념이라 생각한다면 람다시스템에서 시작하는게 자연스럽다.4\n딘킨의 \\(\\pi-\\lambda\\) 정리는 두 흐름을 합치는 정리이다."
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html#딘킨의-pi-lambda-정리-ver2.",
    "href": "posts/ap/2023-04-11-ap-06wk.html#딘킨의-pi-lambda-정리-ver2.",
    "title": "06wk: 측도론 (2)",
    "section": "딘킨의 \\(\\pi-\\lambda\\) 정리 ver2.",
    "text": "딘킨의 \\(\\pi-\\lambda\\) 정리 ver2.\n- 이론: 딘킨의 \\(\\pi-\\lambda\\) 정리 ver2.\n\\({\\cal P}\\)가 파이시스템이고 \\({\\cal L}\\)이 \\({\\cal P}\\)를 포함하는 람다시스템이라면 \\(\\sigma({\\cal P}) \\subset {\\cal L}\\)이다.\n(설명)\nDurret에 나온 딘킨의 \\(\\pi-\\lambda\\) thm 이다. 굉장히 불친절한 편인데, ver2가 증명되면 ver1은 자명하게5 임플라이 되므로 ver2를 대신 state한 것이다.\n\nver2가 ver1를 임플라이 하는 이유: ver1의 \\(l({\\cal P}) \\subset \\sigma({\\cal P})\\)은 당연하고 \\(l({\\cal P}) \\supset \\sigma({\\cal P})\\)만 보이면 되는데, 이미 \\(\\sigma({\\cal P}) \\subset {\\cal L}\\)임을 보였으므로 \\(l({\\cal P})\\)의 정의에 의하여 \\({\\cal L} \\supset l({\\cal P}) \\supset \\sigma({\\cal P})\\)이 성립한다.\n\n- 교재의 언급 (p 456)\n\n\n\n그림2: 교재에 언급된 딘킨의 정리, 부록에 있음"
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html#state-2",
    "href": "posts/ap/2023-04-11-ap-06wk.html#state-2",
    "title": "06wk: 측도론 (2)",
    "section": "state",
    "text": "state\n- 귀찮아서 만든 이론2: 운이 좋다면, \\({\\cal A}\\) 에서 확률의 공리를 만족하는 적당한 함수 \\(\\tilde{P}:{\\cal A} \\to [0,1]\\)를 \\((\\Omega, \\sigma({\\cal A}))\\) 에서의 확률측도 \\(P\\)로 업그레이드 할 수 있으며 업그레이드 결과는 유일하다.\n- 귀찮아서 만든 이론2는 (1) 업그레이드가 가능하냐 (2) 그 업그레이드가 유일하냐 를 따져야하는데 이중 유일성만을 따져보자.\n- Thm: \\((\\Omega, \\sigma({\\cal A}), P)\\)를 확률공간이라고 하자. 여기에서 \\({\\cal A}\\)는 파이시스템이라고 가정하자. 그렇다면 확률측도 \\(P:\\sigma({\\cal A}) \\to [0,1]\\)의 값은 \\(P: {\\cal A} \\to [0,1]\\)의 값에 의하여 유일하게 결정된다.\n\n\\({\\cal A}\\)가 파이시스템이라면, \\({\\cal A}\\)에서는 agree하지만 \\(\\sigma({\\cal A})\\)에서는 agree하지 않는 확률측도 \\(P:\\sigma({\\cal A}) \\to [0,1]\\)는 존재할 수 없다는 의미이다."
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html#활용예제-star",
    "href": "posts/ap/2023-04-11-ap-06wk.html#활용예제-star",
    "title": "06wk: 측도론 (2)",
    "section": "활용예제 (\\(\\star\\))",
    "text": "활용예제 (\\(\\star\\))\n- 아래의 이론을 이해하기 위한 예제들을 살펴보자.\n\n이론: \\((\\Omega, \\sigma({\\cal A}), P)\\)를 확률공간이라고 하자. 여기에서 \\({\\cal A}\\)는 파이시스템이라고 가정하자. 그렇다면 확률측도 \\(P:\\sigma({\\cal A}) \\to [0,1]\\)의 값은 \\(P: {\\cal A} \\to [0,1]\\)의 값에 의하여 유일하게 결정된다.\n\n(예제1) – 4주차에서 했던 예제에요\n- \\(\\Omega=\\{1,2,3,4\\}\\)이라고 하고 \\({\\cal A} = \\{\\emptyset, \\{1\\},\\{2\\},\\{3,4\\},\\Omega\\}\\) 라고 하자.\n- \\({\\cal A}\\)는 파이시스템이다.\n- 아래표의 왼쪽의 \\(P\\)와 같은 확률 측도를 고려하자.\n\n\n\n\n\\(P\\)\n\\(P'\\)\n\n\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{1\\}\\)\n\\(\\frac{1}{4}\\)\n\\(\\frac{1}{4}\\)\n\n\n\\(\\{2\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{3,4\\}\\)\n\\(\\frac{1}{4}\\)\n\\(\\frac{1}{4}\\)\n\n\n\\(\\Omega\\)\n\\(1\\)\n\\(1\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\{1,2\\}\\)\n\\(\\frac{3}{4}\\)\n\\(\\frac{3}{4}\\) 이 아닐 수 있어?\n\n\n\\(\\{1,3,4\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\) 이 아닐 수 있어?\n\n\n\\(\\{2,3,4\\}\\)\n\\(\\frac{3}{4}\\)\n\\(\\frac{3}{4}\\) 이 아닐 수 있어?\n\n\n\n\\({\\cal A}\\)에서는 \\(P\\)와 그 값이 같지만 \\(\\sigma({\\cal A})-{\\cal A}\\)에서는 다른값을 가질 수도 있는 \\((\\Omega, \\sigma({\\cal A}))\\) 에서의 확률측도 \\(P'\\)는 존재하지 않는다.\n즉 \\({\\cal A}\\)가 파이시스템이라면, \\((\\Omega,\\sigma({\\cal A}))\\)에의 모든 확률측도 \\(P\\)는 \\({\\cal A}\\)에서의 값만 define하면 나머지 \\(\\sigma({\\cal A})-{\\cal A}\\)에서의 값은 유니크하게 결정된다.\n- 이 이론에 대한 짧은 생각\n\n생각1: 일단 \\((\\Omega,\\sigma({\\cal A})\\)에서의 확률측도 \\(P\\)의 존재성은 가정하고 들어간다. 즉 “존재한다면 유일하다”는 의미이지, “유일하게 존재한다”의 의미는 아니다.\n생각2: 따라서 이 정리는 “\\({\\cal A}\\)가 파이시스템일 경우, 함수 \\(\\tilde{P}:{\\cal A} \\to [0,1]\\)가 \\((\\Omega,\\sigma({\\cal A}))\\)에서의 확률측도 \\(P\\)로 업그레이드가 가능하다면 그 결과는 유일하다” 정도로 해석할 수 있다.\n\n(예제2) – 이것도 4주차에서 했던 예제입니다.\n- \\(\\Omega=\\{1,2,3,4\\}\\) 이라고 하고 \\({\\cal A} = \\{\\emptyset, \\{1,2\\},\\{2,3\\}, \\Omega\\}\\) 라고 하자.\n- 여기에서 \\({\\cal A}\\)는 파이시스템이 아니다. 따라서 \\({\\cal A}\\)에서의 값은 agree하지만 \\((\\Omega, \\sigma({\\cal A}))\\)에서 agree하지 않는 서로 다른 확률측도가 존재할 수 있다.\n\n\n\n\n\\(P_1\\)\n\\(P_2\\)\n\n\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{1,2\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{2,3\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\Omega\\)\n\\(1\\)\n\\(1\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\{1\\}\\)\n\\(0\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{2\\}\\)\n\\(\\frac{1}{2}\\)\n\\(0\\)\n\n\n\\(\\{3\\}\\)\n\\(0\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{4\\}\\)\n\\(\\frac{1}{2}\\)\n\\(0\\)\n\n\n\\(\\{1,3\\}\\)\n\\(0\\)\n\\(1\\)\n\n\n\\(\\{1,4\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{2,4\\}\\)\n\\(1\\)\n\\(0\\)\n\n\n\\(\\{3,4\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{2,3,4\\}\\)\n\\(1\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{1,3,4\\}\\)\n\\(\\frac{1}{2}\\)\n\\(1\\)\n\n\n\\(\\{1,2,4\\}\\)\n\\(1\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{1,2,3\\}\\)\n\\(\\frac{1}{2}\\)\n\\(1\\)\n\n\n\n- 만약에 이 예제에서 \\({\\cal A}\\)를 아래와 같이 수정한다면\n\\[{\\cal A}=\\{\\emptyset, \\{1,2\\}, \\{2,3\\}, \\{2\\}\\}\\]\n이번에는 \\({\\cal A}\\)는 파이시스템이 된다. 따라서 이 경우 \\((\\Omega, \\sigma({\\cal A}))\\)에서의 모든 확률측도 \\(P\\)는 \\({\\cal A}\\)의 값에 의하여 유일하게 결정된다.\n(예제3)\n- \\(\\Omega=\\{H,T\\}\\) 이라고 하고 \\({\\cal A} = \\{\\{H\\}\\}\\) 라고 하자.\n- 여기에서 \\({\\cal A}\\)은 파이시스템이므로 가측공간 \\((\\Omega,\\sigma({\\cal A}))\\)에서 정의가능한 모든 확률측도 \\(P\\)는 \\({\\cal A}\\)에서의 값으로만 정의해도 무방하다.6\n(예제4) – 통계학과라서 행복해\n- \\(\\Omega=\\{a,b\\}\\) 이라고 하고 \\({\\cal A} = \\{\\{a\\}\\}\\) 라고 하자.\n- 여기에서 \\({\\cal A}\\)은 파이시스템이다.\n- 가측공간 \\((\\Omega,\\sigma({\\cal A}))\\)에서 정의가능한 모든 확률측도 \\(P\\)는 \\({\\cal A}\\)에서의 값으로 유일하게 결정된다.\n- 그렇지만 가측공간 \\((\\Omega,\\sigma({\\cal A})\\)에서 정의가능한 “측도” \\(m\\)은 \\({\\cal A}\\)에서의 값으로 유일하게 결정되지 않는다.7\n\n\n\n\n\\(m_1\\)\n\\(m_2\\)\n\n\n\n\n\\(\\{a\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{b\\}\\)\n\\(\\frac{1}{2}\\)\n\\(1\\)\n\n\n\\(\\Omega\\)\n\\(1\\)\n\\(\\frac{3}{2}\\)"
  },
  {
    "objectID": "posts/ap/2023-04-11-ap-06wk.html#증명-2",
    "href": "posts/ap/2023-04-11-ap-06wk.html#증명-2",
    "title": "06wk: 측도론 (2)",
    "section": "증명",
    "text": "증명\n- 아래의 이론에 대한 증명\n\nThm: \\((\\Omega, \\sigma({\\cal A}), P)\\)를 확률공간이라고 하자. 여기에서 \\({\\cal A}\\)는 파이시스템이라고 가정하자. 그렇다면 확률측도 \\(P:\\sigma({\\cal A}) \\to [0,1]\\)의 값은 \\(P: {\\cal A} \\to [0,1]\\)의 값에 의하여 유일하게 결정된다.\n\n증명 (확률측도라는 가정을 추가하여 교재의 버전을 살짝 쉽게 만듬)\nLET\n\n\\((\\Omega, \\sigma({\\cal A}))\\) 는 잴 수 있는 공간임.\n\\(P_1,P_2\\)는 \\((\\Omega, \\sigma({\\cal A}))\\)에서의 확률측도임.\n\\(P_1,P_2\\)는 “\\(\\forall A \\in {\\cal A}: P_1(A)=P_2(A)\\)”를 만족함.\n\n전략: 잴 수 있는 공간 \\((\\Omega, \\sigma({\\cal A}))\\) 에서의 두 측도 \\(P_1\\), \\(P_2\\)가 \\({\\cal A}\\)에서는 일치하지만 \\(\\sigma({\\cal A})-{\\cal A}\\)에서는 일치하지 않는 경우를 찾으려 해보고, 그것이 불가능함을 보이자.\nLET: \\(\\tilde{\\cal D}=\\{B \\in \\sigma({\\cal A}): P_1(B) \\neq P_2(B)\\}\\)\nISTST: \\(\\tilde{\\cal D} =\\emptyset\\)\nISTST: \\({\\cal D} = \\{B \\in \\sigma({\\cal A}): P_1(B) = P_2(B) \\} = \\sigma({\\cal A})\\)\nISTST: (1) \\({\\cal D} \\subset \\sigma({\\cal A})\\) (2) \\({\\cal D} \\supset \\sigma({\\cal A})\\)\nISTST: \\({\\cal D} \\supset \\sigma({\\cal A})\\)\nNOTE: IF (1) \\({\\cal D}\\) is containing \\({\\cal A}\\) (2) \\({\\cal D}\\) is \\(\\lambda\\)-system, THEN we can say \\({\\cal D} \\supset \\sigma({\\cal A})=l({\\cal A})\\)\nISTST: (1) \\({\\cal A} \\subset {\\cal D}\\) (2) \\({\\cal D}\\) is \\(\\lambda\\)-system.\nISTST: 1. \\(\\Omega \\in {\\cal D}\\) 2. \\(A,B \\in {\\cal D}, A\\subset B\\) \\(\\Rightarrow\\) \\(B-A \\in {\\cal D}\\) 3. \\(\\forall B_1,B_2,\\dots, \\in {\\cal D}\\), \\(\\uplus_{i=1}^{\\infty} B_i \\in {\\cal D}\\)\nCHECK 1: \\(P_1(\\Omega) = P_2(\\Omega)\\)\nCHECK 2: \\(P_1(B-A) = P_1(B)-P_1(A) = P_2(B) - P_2(A) = P_2(B-A)\\)\nCHECK 3: \\(P_1(\\uplus_{i=1}^{\\infty} B_i)=P_1(B_1)+P_1(B_2)\\dots = P_2(B_1)+P_2(B_2) +\\dots = P_2(\\uplus_{i=1}^\\infty B_i)\\)\n- 보충노트\n\nsupp_6wk.pdf"
  },
  {
    "objectID": "posts/ap/2023-04-05-ap-05wk.html",
    "href": "posts/ap/2023-04-05-ap-05wk.html",
    "title": "05wk: 측도론 (1)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-xOLs7lnyb8ZjM3KB-N2u7I"
  },
  {
    "objectID": "posts/ap/2023-04-05-ap-05wk.html#수학과의-기호",
    "href": "posts/ap/2023-04-05-ap-05wk.html#수학과의-기호",
    "title": "05wk: 측도론 (1)",
    "section": "수학과의 기호",
    "text": "수학과의 기호\n- 아래는 기호는 몇 가지 영어단어의 축약형이다.\n\nfor all: \\(\\forall\\)\nexists: \\(\\exists\\)\nsuch that, satisfying: \\({\\sf s.t.}\\), \\({\\sf st}\\)\nif-then, implies, therefore: \\(\\Rightarrow\\)\nif and only if: \\(\\Leftrightarrow\\)\nbecause: \\(\\because\\)\ntherefore: \\(\\therefore\\)\nquod erat: \\(\\square\\), \\(\\blacksquare\\)\n\n- 예시1: 모든 실수 \\(x\\)에 대하여, \\(x^2\\)은 양수이다.\n언어\n\nfor any \\(x\\) in \\(\\mathbb{R}\\), \\(x^2 \\geq 0\\).\nfor arbitrary \\(x \\in \\mathbb{R}\\), \\(x^2 \\geq 0\\).\nfor any choice of \\(x \\in \\mathbb{R}\\), \\(x^2 \\geq 0\\).\nfor all \\(x \\in \\mathbb{R}\\), \\(x^2 \\geq 0\\).\nif \\(x \\in \\mathbb{R}\\), then \\(x^2 \\geq 0\\).\n\n기호\n\n\\(\\forall x \\in \\mathbb{R}\\): \\(x^2\\geq 0\\).\n\\(\\forall x \\in \\mathbb{R}\\), \\(x^2\\geq 0\\).\n\\(x^2 \\geq 0\\), for all \\(x \\in \\mathbb{R}\\).\n\\(x^2 \\geq 0\\), \\(\\forall x \\in \\mathbb{R}\\).\n\\(x \\in \\mathbb{R} \\Rightarrow x^2 \\geq 0\\).\n\n\n거의 쓰는 사람 마음임, 그런데 뉘앙스가 조금씩 다름.\n\n- 예시2: \\(\\Omega\\)의 임의의 부분집합 \\(A\\),\\(B\\)에 대하여, \\(A=B\\) 일 필요충분조건은 \\(A\\subset B\\) 이고 \\(B \\subset A\\) 이어야 한다.\n언어\n\nfor all \\(A,B \\subset \\Omega\\), \\(A=B\\) if and only if (1) \\(A \\subset B\\) and (2) \\(B \\subset A\\).\n\n기호\n\n\\(A = B \\Leftrightarrow A \\subset B \\text{ and } B \\subset A, \\forall A,B \\in \\Omega\\).\n\\(A = B \\Leftrightarrow \\big(A \\subset B \\text{ and } B \\subset A\\big), \\forall A,B \\in \\Omega\\).\n\\(\\forall A,B \\subset \\Omega\\): \\(A = B \\Leftrightarrow \\big(A \\subset B \\text{ and } B \\subset A\\big)\\)\n\n\n의미가 때로는 모호할때가 있지만 눈치껏 알아먹어야 한다.\n\n- 예시3: 임의의 양수 \\(\\epsilon&gt;0\\)에 대하여 \\(|x| \\leq \\epsilon\\)이라면 \\(x=0\\)일 수 밖에 없다.\n언어\n\nIf \\(|x|&lt; \\epsilon\\) for all \\(\\epsilon&gt;0\\), then \\(x=0\\).\nIf \\(|x|&lt; \\epsilon\\), \\(\\forall \\epsilon&gt;0\\), then \\(x=0\\).\nFor all \\(\\epsilon&gt;0\\), \\(|x|&lt; \\epsilon\\) implies \\(x=0\\). – 틀린표현\n\n기호\n\n\\(|x| &lt; \\epsilon,~ \\forall \\epsilon&gt;0 \\Rightarrow x=0\\)\n\\(\\forall \\epsilon&gt;0: |x| &lt; \\epsilon \\Rightarrow x=0\\) – 애매하다?\n\\(\\big(\\forall \\epsilon&gt;0:|x| &lt; \\epsilon\\big) \\Rightarrow x=0\\)\n\\(\\big(\\forall \\epsilon&gt;0\\big)\\big(|x| &lt; \\epsilon \\Rightarrow x=0\\big)\\) – 틀린표현"
  },
  {
    "objectID": "posts/ap/2023-04-05-ap-05wk.html#기타-약어-및-상투적인-표현",
    "href": "posts/ap/2023-04-05-ap-05wk.html#기타-약어-및-상투적인-표현",
    "title": "05wk: 측도론 (1)",
    "section": "기타 약어 및 상투적인 표현",
    "text": "기타 약어 및 상투적인 표현\n- 약어\n\n\\({\\sf WLOG}\\): Without Loss Of Generality\n\\({\\sf WTS}\\): What/Want To Show\n\\({\\sf iff}\\): if and only if\n\\({\\sf Q.E.D.}\\): 증명완료 (쓰지마..)\n\\({\\sf LHS}\\): Left Hand Side\n\\({\\sf RHS}\\): Right Hand Side\n\n- 상투적인 표현\n\nIt suffices to show that, It is sufficient to show that"
  },
  {
    "objectID": "posts/ap/2023-04-05-ap-05wk.html#before",
    "href": "posts/ap/2023-04-05-ap-05wk.html#before",
    "title": "05wk: 측도론 (1)",
    "section": "Before",
    "text": "Before\n- 아래의 기호를 약속\n\n전체집합: \\(\\Omega\\)\n관심있는 집합의 모임: \\({\\cal A} \\subset 2^{\\Omega}\\)\n\n- \\(\\Omega \\neq \\emptyset\\), \\({\\cal A} \\neq \\emptyset\\) 를 가정.\n- 약속: 집합 \\({\\cal A} \\subset 2^{\\Omega}\\)에 대하여 아래와 같은 용어를 약속하자.\n\n\\(\\cap\\)-closed (closed under intersection) or a \\(\\pi\\)-system: \\(\\forall A,B \\in {\\cal A}:~ A \\cap B \\in {\\cal A}\\)\n\\(\\sigma\\)-\\(\\cap\\)-closed (closed under countable interserction): \\(\\forall \\{A_i\\}_{i=1}^{\\infty} \\subset {\\cal A}:~ \\cap_{i=1}^{\\infty} A_i \\in {\\cal A}\\)\n\\(\\cup\\)-closed (closed under unions): \\(\\forall A,B \\in {\\cal A}:~ A\\cup B \\in {\\cal A}\\)\n\\(\\sigma\\)-\\(\\cup\\)-closed (closed under countable unois): \\(\\forall \\{A_i\\}_{i=1}^{\\infty} \\subset {\\cal A}:~ \\cup_{i=1}^{\\infty}A_i \\in {\\cal A}\\)\n＼-closed (closed under differences): \\(\\forall A,B \\in {\\cal A}:~ A-B \\in {\\cal A}\\)\n\\(^c\\)-closed (closed under complements): \\(\\forall A \\in {\\cal A}:~ A^c \\in {\\cal A}\\)\n\n- 우리만의 약속:\n\n앞으로 서로소인 집합들에 대한 합집합은 기호로 \\(\\uplus\\)라고 표현하겠다.\n따라서 앞으로 \\(B_1 \\uplus B_2\\)의 의미는 (1) \\(B_1 \\cup B_2\\) (2) \\(B_1 \\cap B_2 = \\emptyset\\) 을 의미한다고 정의하겠다. (꼭 서로소임을 명시하지 않아도)\n\\(\\sigma\\)-\\(\\uplus\\)-closed 의 의미는 \\(\\uplus_{i=1}^{\\infty}B_i \\in {\\cal A}, \\forall \\{B_i\\}_{i=1}^{\\infty} \\subset {\\cal A}:\\) 의 의미이다.\n\n- 이론: \\({\\cal A}\\subset 2^{\\Omega}\\) 가 여집합에 닫혀있다면, 아래가 성립한다.\n\n\\({\\cal A}\\)가 교집합1에 닫혀있음. \\(\\Leftrightarrow\\) \\({\\cal A}\\)가 합집합2에 닫혀있음.\n\\({\\cal A}\\)가 가산교집합3에 닫혀있음. \\(\\Leftrightarrow\\) \\({\\cal A}\\)가 가산합집합4에 닫혀있음.\n\n(증명) 생략\n- 이론: \\({\\cal A}\\subset 2^{\\Omega}\\)가 차집합에 닫혀있다면, 아래가 성립한다.\n\n\\({\\cal A}\\)는 교집합에 닫혀있다.\n\\({\\cal A}\\)가 가산합집합에 닫혀있다. \\(\\Rightarrow\\) \\({\\cal A}\\)가 가산교집합에 닫혀있다.\n\\(\\forall \\{A_i\\} \\subset {\\cal A},~ \\exists \\{B_i\\} \\subset {\\cal A}\\) such that \\(\\cup_{i=1}^{\\infty} A_i = \\uplus_{i=1}^{\\infty} B_i\\).5\n\n(증명)\n\nNote: \\(A\\cap B = A-(A-B)\\).\nNote: \\(\\cap_{i=1}^{\\infty}A_i = \\cap_{i=2}^{n}(A_1\\cap A_i)= \\cap_{i=2}^{n}(A_1 - (A_1-A_i))=A_1 - \\cup_{i=2}^{n}(A_1-A_i)\\).\nNote: \\(\\cup_{i=1}^{\\infty}A_i = A_1 \\uplus(A_2-A_1) \\uplus \\big((A_3-A_1) - A_2 \\big) \\uplus \\big(\\big((A_4-A_1)-A_2\\big)-A_3\\big)\\uplus \\cdots\\)\n\n\n차집합에 닫혀있다는 것은 매우 좋은 성질임."
  },
  {
    "objectID": "posts/ap/2023-04-05-ap-05wk.html#시그마필드-starstarstar",
    "href": "posts/ap/2023-04-05-ap-05wk.html#시그마필드-starstarstar",
    "title": "05wk: 측도론 (1)",
    "section": "시그마필드 (\\(\\star\\star\\star\\))",
    "text": "시그마필드 (\\(\\star\\star\\star\\))\n- 정의: 시그마필드 (\\(\\sigma\\)-field, \\(\\sigma\\)-algebra)\n집합 \\({\\cal F} \\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal F}\\)를 \\(\\Omega\\)에 대한 시그마필드라고 부른다.\n\n\\(\\Omega \\in {\\cal F}\\).\n\\({\\cal F}\\)는 여집합에 닫혀있다.\n\\({\\cal F}\\)는 가산합집합에 닫혀있다.\n\n- 시그마필드의 정의에서 1을 생략하기도 한다. 이럴 경우는 특별히 \\({\\cal F}\\neq\\emptyset\\)임을 강조한다. 1을 생략할 수 있는 논리는 아래와 같다.\n\n\\({\\cal F}\\)는 공집합이 아니므로 최소한 하나의 집합 \\(A\\)는 포함해야 한다. 즉 \\(A \\in {\\cal F}\\).\n2번 원리에 의하여 \\(A^c \\in {\\cal F}\\).\n시그마필드는 합집합에 닫혀있으므로 \\(A\\cup A^c \\in {\\cal F}\\)."
  },
  {
    "objectID": "posts/ap/2023-04-05-ap-05wk.html#알지브라-필드-star",
    "href": "posts/ap/2023-04-05-ap-05wk.html#알지브라-필드-star",
    "title": "05wk: 측도론 (1)",
    "section": "알지브라, 필드 (\\(\\star\\))",
    "text": "알지브라, 필드 (\\(\\star\\))\n- 정의1: 알지브라, 필드 (algebra, field)\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 대수라고 부른다.\n\n\\(\\Omega \\in {\\cal A}\\).\n\\({\\cal A}\\)는 차집합에 닫혀있다.\n\\({\\cal A}\\)는 합집합에 닫혀있다.\n\n- 알지브라 역시 1의 조건을 생략하기도 한다.\n- 전체집합을 포함 \\(\\Rightarrow\\) (차집합에 닫혀있음 \\(\\Rightarrow\\) 여집합에 닫혀있음) \\(\\Rightarrow\\) 따라서 대수는 여집합에 닫혀있다.\n- 차집합에 닫혀있음 \\(\\Rightarrow\\) 교집합에 닫혀있게 된다.\n\n혹은 (여집합에 닫혀있음 & 합집합에 닫혀있음) \\(\\Rightarrow\\) 교집합에 닫혀있음.\n\n- 정의2: 알지브라의 또 다른 정의\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 대수라고 부른다.\n\n\\(\\Omega \\in {\\cal A}\\).\n\\({\\cal A}\\)는 교집합에 닫혀있다.\n\\({\\cal A}\\)는 여집합에 닫혀있다.\n\n- 여집합에 닫혀있음 \\(\\Rightarrow\\) (합집합에 닫혀있음 \\(\\Leftrightarrow\\) 교집합에 닫혀있음) \\(\\Rightarrow\\) 2번 조건을 합집합으로 바꿔도 무방\n- 정의3: 알지브라의 또 또 다른 정의 (교재의 정의)\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 대수라고 부른다.\n\n\\(\\Omega \\in {\\cal A}\\).\n\\({\\cal A}\\)는 여집합에 닫혀있다.\n\\({\\cal A}\\)는 합집합에 닫혀있다.\n\n- 알지브라의 예시\n\n\\(\\Omega = \\{H,T\\}\\), \\({\\cal A} = 2^\\Omega\\) 일때, \\({\\cal A}\\)는 알지브라이다. (\\(|\\Omega| &lt;\\infty\\) 이라면 “시그마필드 = 알지브라(필드)” 이다.)"
  },
  {
    "objectID": "posts/ap/2023-04-05-ap-05wk.html#링",
    "href": "posts/ap/2023-04-05-ap-05wk.html#링",
    "title": "05wk: 측도론 (1)",
    "section": "링",
    "text": "링\n- 정의: 링 (ring)\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 링이라고 부른다.\n\n\\(\\emptyset \\in {\\cal A}\\).\n\\({\\cal A}\\)는 차집합에 닫혀있다.\n\\({\\cal A}\\)는 합집합에 닫혀있다.\n\n- 여기에서 1의 조건을 생략할 수 있다. (이럴경우 특별히 \\({\\cal A}\\neq \\emptyset\\) 임을 강조한다.)\n\n\\({\\cal A}\\)는 공집합이 아니므로 최소한 하나의 원소 \\(A\\)는 가져야 한다.\n\n조건2에 의하여 \\(A-A\\) 역시 \\({\\cal A}\\)의 원소이다.\n\n- 링은 차집합에 닫혀있음 \\(\\Rightarrow\\) 링은 교집합에도 닫혀있음 \\(\\Rightarrow\\) 링은 교집합과 합집합 모두에 닫혀 있다.\n- 링과 알지브라의 차이는 전체집합이 포함되느냐 마느냐임 \\(\\Rightarrow\\) 그런데 이 차이로 인해 알지브라는 여집합에 닫혀있지만 링은 여집합에 닫혀있지 않게 된다."
  },
  {
    "objectID": "posts/ap/2023-04-05-ap-05wk.html#시그마링",
    "href": "posts/ap/2023-04-05-ap-05wk.html#시그마링",
    "title": "05wk: 측도론 (1)",
    "section": "시그마링",
    "text": "시그마링\n- 정의: 시그마링 (\\(\\sigma\\)-ring)\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 링이라고 부른다.\n\n\\(\\emptyset \\in {\\cal A}\\).\n\\({\\cal A}\\)는 차집합에 닫혀있다.\n\\({\\cal A}\\)는 가산합집합에 닫혀있다.\n\n- 여기에서 1의 조건을 생략할 수 있다."
  },
  {
    "objectID": "posts/ap/2023-04-05-ap-05wk.html#세미알지브라-starstarstar",
    "href": "posts/ap/2023-04-05-ap-05wk.html#세미알지브라-starstarstar",
    "title": "05wk: 측도론 (1)",
    "section": "세미알지브라 (\\(\\star\\star\\star\\))",
    "text": "세미알지브라 (\\(\\star\\star\\star\\))\n- 정의1: 세미알지브라 (semi-algebra) // ref : 위키북스\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 세미알지브라 라고 부른다.\n\n\\(\\Omega \\in {\\cal A}\\).\n\\({\\cal A}\\)는 교집합에 닫혀있다.\n\\(\\forall A,B \\in {\\cal A}, \\exists \\{B_i\\}_{i=1}^{n} \\subset {\\cal A}\\) such that \\[A-B = \\uplus_{i=1}^{n} B_i.\\]\n\n\n3번을 \\({\\cal A}\\)가 차집합에 반쯤 닫혀있다고 표현한다. 즉 차집합 자체가 \\({\\cal A}\\)에 들어가는건 아니지만 차집합의 disjoint한 조각들은 모두 \\({\\cal A}\\)에 들어간다.\n\n- 세미알지브라는 공집합을 포함한다. (이때 \\({\\cal A}\\neq \\emptyset\\)임을 강조함)\n\n\\({\\cal A}\\)는 공집합이 아니므로 최소한 하나의 집합 \\(A\\)는 포함해야 한다. 즉 \\(A \\in {\\cal A}\\).\n\\(A \\in {\\cal A}\\)이면 조건3에 의하여 \\(\\emptyset\\)6을 \\({\\cal A}\\)의 원소들의 countable union으로 만들 수 있어야 한다. 이 조건을 만족하기 위해서는 \\(\\emptyset \\in {\\cal A}\\)이어야만 한다.\n\n- 정의2: 세미알지브라의 또 다른 정의 // ref: 세미링의 위키에서 언급, Durret의 정의.\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 세미알지브라 라고 부른다.\n\n\\(\\Omega \\in {\\cal A}\\)\n\\({\\cal A}\\)는 교집합에 닫혀있다.\n\\(\\forall A \\in {\\cal A}, \\exists \\{B_i\\}_{i=1}^{n} \\subset {\\cal A}\\) such that \\[A^c = \\uplus_{i=1}^{n} B_i.\\]\n\n\n3번을 \\({\\cal A}\\)가 여집합에 반쯤 닫혀있다고 표현한다. 즉 여집합 자체가 \\({\\cal A}\\)에 들어가는건 아니지만 차집합의 disjoint한 조각들은 모두 \\({\\cal A}\\)에 들어간다.\n\n- 이 정의에서도 세미알지브라는 공집합을 포함한다. (이때 \\({\\cal A}\\neq \\emptyset\\)임을 강조함)\n\n\\({\\cal A}\\)는 공집합이 아니므로 최소한 하나의 집합 \\(A\\)는 포함해야 한다. 즉 \\(A \\in {\\cal A}\\).\n3에 의하여 \\(A^c=\\uplus_{i=1}^{n}B_i\\)를 만족하는 \\(B_1,\\dots, B_n\\) 역시 \\({\\cal A}\\)에 포함되어야 한다.\n2에 의하여 \\(A \\cap B_1=\\emptyset\\) 역시 \\({\\cal A}\\)에 포함되어야 한다.\n\n- Note: 정의2의 3번조건은 정의1의 3번조건보다 강한 조건이다. (정의2의 조건3 \\(\\Rightarrow\\) 정의1의 조건3)\n\n증명은 세미링/위키 에서 스스로 확인\n\n- 교재의 정의: 정의2에서 \\(\\Omega \\in {\\cal A}\\)이 생략되어 있음.\n\n왜 생략할 수 있는지 모르겠음. (교재가 틀렸을 수도 있음)\n\n- 세미알지브라의 예시: 아래의 \\({\\cal A}\\)는 모두 \\(\\Omega\\)에 대한 세미알지브라이다.\n\n예시1: \\(\\Omega=\\{a,b,c,d\\}\\), \\({\\cal A} = \\{\\emptyset, \\{a\\},\\{b,c,d\\}, \\Omega \\}\\)\n예시2: \\(\\Omega=\\{a,b,c,d\\}\\), \\({\\cal A} = \\{\\emptyset, \\{a\\},\\{b\\},\\{c,d\\}, \\Omega \\}\\)\n예시3: \\(\\Omega=\\{a,b,c,d\\}\\), \\({\\cal A} = \\{\\emptyset, \\{a\\},\\{b,c\\},\\{d\\}, \\Omega \\}\\)\n예시4: \\(\\Omega=\\{a,b,c,d\\}\\), \\({\\cal A} = \\{\\emptyset, \\{a\\},\\{b\\},\\{c\\},\\{d\\}, \\Omega \\}\\)\n예시5: \\(\\Omega=\\{a,b,c,d\\}\\), \\({\\cal A} = \\{\\emptyset, \\{a\\},\\{b\\},\\{c\\},\\{d\\}, \\{a,b\\},\\{b,c\\},\\Omega \\}\\)\n\n\n세미알지브라는 전체집합이 몇개의 파티션으로 쪼개져서 원소로 들어가는 느낌이 있음.\n\n- 세미알지브라의 예시\\((\\star)\\): 아래의 \\({\\cal A}\\)는 모두 \\(\\Omega=\\mathbb{R}\\)에 대한 세미알지브라이다.\n\n예시1: \\({\\cal A} = \\{(a,b]: -\\infty \\leq a &lt; b \\leq \\infty \\}\\cup \\{\\emptyset\\}\\)\n예시2: \\({\\cal A} = \\{[a,b): -\\infty \\leq a &lt; b \\leq \\infty \\}\\cup \\{\\emptyset\\}\\)\n\n- 세미알지브라가 아닌 예시: 아래의 \\({\\cal A}\\)는 \\(\\Omega=\\mathbb{R}\\)에 대한 세미알지브라가 아니다.\n\n예시1: \\({\\cal A} = \\{(a,b): -\\infty \\leq a &lt; b \\leq \\infty \\}\\cup \\{\\emptyset\\}\\)\n예시2: \\({\\cal A} = \\{[a,b]: -\\infty \\leq a &lt; b \\leq \\infty \\}\\cup \\{\\emptyset\\}\\)\n\n- 교재의 언급 (p3)\n\n\n\n그림1: 교재에서의 세미알지브라 설명"
  },
  {
    "objectID": "posts/ap/2023-04-05-ap-05wk.html#세미링-starstarstar",
    "href": "posts/ap/2023-04-05-ap-05wk.html#세미링-starstarstar",
    "title": "05wk: 측도론 (1)",
    "section": "세미링 \\((\\star\\star\\star)\\)",
    "text": "세미링 \\((\\star\\star\\star)\\)\n- 정의: 세미링\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 세미링이라고 부른다.\n\n\\(\\emptyset \\in {\\cal A}\\).\n\\({\\cal A}\\)는 교집합에 닫혀있다.\n\\({\\cal A}\\)는 차집합에 반쯤 닫혀있다.\n\n- 세미링에서도 공집합포함 조건을 생략할 수 있다.\n- 세미링의 예시: 아래의 \\({\\cal A}\\)는 모두 \\(\\Omega\\)에 대한 세미링이다.\n\n예시1: \\(\\Omega=\\{a,b,c,d,e,f\\}\\), \\({\\cal A} = \\{\\emptyset, \\{a\\},\\{b,c,d\\}\\}\\)\n예시2: \\(\\Omega=\\{a,b,c,d,e,f\\}\\), \\({\\cal A} = \\{\\emptyset, \\{a\\},\\{b\\},\\{c,d\\}\\}\\)\n예시3: \\(\\Omega=\\{a,b,c,d,e,f\\}\\), \\({\\cal A} = \\{\\emptyset,\\{a,b,c\\},\\{b,c,d\\}, \\{a\\},\\{b,c\\},\\{d\\}\\}\\)\n\n\n전체집합이 포함될 필요가 없는 세미알지브라 느낌임.\n\n- 세미링의 예시: 아래의 \\({\\cal A}\\)는 모두 \\(\\Omega=\\mathbb{R}\\)에 대한 세미링이다.\n\n예시1: \\({\\cal A} = \\{(a,b]: -\\infty &lt; a &lt; b &lt; \\infty \\}\\cup \\{\\emptyset\\}\\)\n예시2: \\({\\cal A} = \\{[a,b): -\\infty &lt; a &lt; b &lt; \\infty \\}\\cup \\{\\emptyset\\}\\)\n\n- 세미링이 아닌 예시: 아래의 \\({\\cal A}\\)는 \\(\\Omega=\\mathbb{R}\\)에 대한 세미링이 아니다.\n\n예시1: \\({\\cal A} = \\{(a,b): -\\infty &lt; a &lt; b &lt; \\infty \\}\\cup \\{\\emptyset\\}\\)\n예시2: \\({\\cal A} = \\{[a,b]: -\\infty &lt; a &lt; b &lt; \\infty \\}\\cup \\{\\emptyset\\}\\)"
  },
  {
    "objectID": "posts/ap/2023-04-05-ap-05wk.html#파이시스템-starstar",
    "href": "posts/ap/2023-04-05-ap-05wk.html#파이시스템-starstar",
    "title": "05wk: 측도론 (1)",
    "section": "파이시스템 (\\(\\star\\star\\))",
    "text": "파이시스템 (\\(\\star\\star\\))\n- 정의: \\(\\pi\\)-system\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 파이스시템 이라고 부른다.\n\n\\({\\cal A}\\)는 교집합에 닫혀있다.\n\n- 파이시스템임을 강조하기 위해서 \\({\\cal A}\\) 대신에 \\({\\cal P}\\) 라고 교재에서 표현하기도 한다.\n- 파이시스템의 예시: 아래는 모두 \\(\\Omega=\\mathbb{R}\\)에 대한 파이시스템이다.\n\n예시1: \\({\\cal A} = \\{(a,b]: -\\infty &lt; a &lt; b &lt; \\infty \\}\\)\n예시2: \\({\\cal A} = \\{[a,b): -\\infty &lt; a &lt; b &lt; \\infty \\}\\)\n예시3: \\({\\cal A} = \\{(a,b): -\\infty &lt; a &lt; b &lt; \\infty \\}\\)\n예시4: \\({\\cal A} = \\{[a,b]: -\\infty &lt; a &lt; b &lt; \\infty \\}\\)"
  },
  {
    "objectID": "posts/ap/2023-04-05-ap-05wk.html#람다시스템-starstar",
    "href": "posts/ap/2023-04-05-ap-05wk.html#람다시스템-starstar",
    "title": "05wk: 측도론 (1)",
    "section": "람다시스템 (\\(\\star\\star\\))",
    "text": "람다시스템 (\\(\\star\\star\\))\n- 정의1: \\(\\lambda\\)-system\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 람다시스템 이라고 부른다.\n\n\\(\\Omega \\in {\\cal A}\\)\n\\(\\forall A,B \\in {\\cal A}:~ A\\subset B \\Rightarrow B-A \\in {\\cal A}\\)\n\\(\\forall B_1,B_2,\\dots \\in {\\cal A}\\) such that \\(B_1,B_2\\dots\\) are disjoint: \\[\\uplus_{i=1}^{\\infty} B_i \\in {\\cal A}\\]\n\n\n람다시스템은 1. 전체집합이 포함되고 2. 두 집합이 포함관계에 있는 경우 차집합에 닫혀있으며 3. 서로소인 가산합집합에 닫혀있다.\n\n- 람다시스템은 여집합에 닫혀있다. 그리고 람다시스템은 공집합을 포함한다.\n- 람다시스템의 느낌: 3주차 시그마필의 motivation에서 소개한 거의 모든 예제는 사실 람다시스템이다.\n\n람다시스템의 원칙1,2,3은 사실 확률의 공리와 깊게 관련되어있음.\n내 생각: 딘킨은 확률의 공리에 착안해서 람다시스템을 만들지 않았을까?\n\n- 아래는 모두 람다시스템의 예시이다.\n\n\\(\\Omega=\\{H,T\\}\\), \\({\\cal L}=\\{\\emptyset, \\{H\\},\\{T\\},\\Omega\\}\\) – 3주차 예제1\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\({\\cal L}=2^\\Omega\\) – 3주차 예제4\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\({\\cal L}=\\{\\emptyset,\\{6\\},\\{1,2,3,4,5\\},\\Omega\\}\\) – 3주차 예제5\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\({\\cal L}=\\{\\emptyset,\\{1,2,3\\},\\{3,4,5\\},\\Omega\\}\\) – 3주차 예제6\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\({\\cal L}=\\{\\emptyset,\\Omega\\}\\) – 3주차 예제8\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\({\\cal L}=\\{\\emptyset,\\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\{3,4\\}, \\{1,2\\},\\Omega\\}\\) – 3주차 예제9,10\n\\(\\Omega=(0,2\\pi]\\), \\({\\cal L}=\\sigma({\\cal A})\\) where \\({\\cal A} = \\{\\{x\\}: x\\in \\mathbb{Q} \\cap \\Omega \\}\\) – 3주차 예제11\n\\(\\Omega=\\{1,2,3,4\\}\\), \\({\\cal L}=\\{\\emptyset, \\{1,2\\}, \\{1,3\\}, \\{1,4\\}, \\{2,3\\}, \\{2,4\\}, \\{3,4\\}, \\Omega\\}\\) – 3주차 예제12에서 교집합 안넣은 버전\n\n- 정의2: \\(\\lambda\\)-system (교재의 정의)\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 람다시스템 이라고 부른다.\n\n\\(\\Omega \\in {\\cal A}\\)\n\\(\\forall A,B \\in {\\cal A}:~ A\\subset B \\Rightarrow B-A \\in {\\cal A}\\)\n\\(\\forall A_1,A_2,\\dots \\in {\\cal A}\\) such that \\(A_1 \\subset A_2 \\subset \\dots\\): \\[\\cup_{i=1}^{\\infty} A_i \\in {\\cal A}\\]\n\n- Note: 정의1의 3번조건과 정의2의 3번조건은 서로 동치관계이다.\n- 교재에서의 파이시스템, 람다시스템 설명\n\n\n\n그림2: 교재에서의 파이시스템과 람다시스템\n\n\n\n위의 정의에서 기호 \\(A_n \\uparrow A\\)의 의미는 “\\(A_1 \\subset A_2 \\subset \\dots\\) and \\(\\cup_{i}^{\\infty}A_i=A\\)”를 뜻하는 축약표현이다."
  },
  {
    "objectID": "posts/ap/2023-04-05-ap-05wk.html#정리",
    "href": "posts/ap/2023-04-05-ap-05wk.html#정리",
    "title": "05wk: 측도론 (1)",
    "section": "정리",
    "text": "정리\n- 정리표 (hw): 물음표를 채워라\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(A \\cap B\\)\n\\(\\emptyset\\)\n\\(A-B\\)\n\\(\\cup_iA_i \\to \\uplus_i B_i\\)\n\\(\\Omega\\)\n\\(A^c\\)\n\\(A\\cup B\\)\n\\(\\cup_{i=1}^{\\infty}A_i\\)\n\\(\\uplus_{i=1}^{\\infty}B_i\\)\n\\(\\cap_{i=1}^{\\infty}A_i\\)\n\n\n\n\n\\(\\pi\\)-system\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\n\nsemi-ring\n\\(O\\)\n\\(O\\)\n\\(\\Delta\\)\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\n\nsemi-algebra\n\\(O\\)\n\\(O\\)\n\\(\\Delta\\)\n\\(O\\)\n\\(O\\)\n\\(\\Delta\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\n\nring\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\n\nalgebra\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\n\n\\(\\sigma\\)-ring\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\n\n\\(\\lambda\\)-system\n\\(X\\)\n\\(O\\)\n\\(\\Delta\\)’\n\\(X\\)\n\\(O\\)\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(O\\)\n\\(X\\)\n\n\n\\(\\sigma\\)-field\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\n\n\n- 다이어그램 (포함관계)\n\n\n\n\n\n\nG\n\n\ncluster_0\n\nRING\n\n\ncluster_1\n\nALGEBRA\n\n\ncluster_2\n\nLAMBDA\n\n\n\nσ－ring\n\nσ－ring\n\n\n\nring\n\nring\n\n\n\nσ－ring-&gt;ring\n\n\n\n\n\nsemiring\n\nsemiring\n\n\n\nring-&gt;semiring\n\n\n\n\n\nπ－system\n\nπ－system\n\n\n\nsemiring-&gt;π－system\n\n\n\n\n\nσ－algebra\n\nσ－algebra\n\n\n\nσ－algebra-&gt;σ－ring\n\n\n\n\n\nalgebra\n\nalgebra\n\n\n\nσ－algebra-&gt;algebra\n\n\n\n\n\nλ－system\n\nλ－system\n\n\n\nσ－algebra-&gt;λ－system\n\n\n\n\n\nalgebra-&gt;ring\n\n\n\n\n\nsemialgebra\n\nsemialgebra\n\n\n\nalgebra-&gt;semialgebra\n\n\n\n\n\nsemialgebra-&gt;semiring\n\n\n\n\n\n\n\n\n\n- 다이어그램 (이해용) – 그림은 더럽지만..\n\n\n\n\n\n\nG\n\n\ncluster_1\n\nALGEBRA\n\n\ncluster_2\n\nLAMBDA\n\n\ncluster_0\n\nRING\n\n\n\nsemiring\n\nsemiring\n\n\n\nring\n\nring\n\n\n\nsemiring-&gt;ring\n\n\n∪－stable\n\n\n\nsemialgebra\n\nsemialgebra\n\n\n\nsemiring-&gt;semialgebra\n\n\nΩ－contained\n\n\n\nσ－ring\n\nσ－ring\n\n\n\nring-&gt;σ－ring\n\n\nσ－∪－stable\n\n\n\nalgebra\n\nalgebra\n\n\n\nring-&gt;algebra\n\n\nΩ－contained\n\n\n\nσ－algebra\n\nσ－algebra\n\n\n\nσ－ring-&gt;σ－algebra\n\n\nΩ－contained\n\n\n\nsemialgebra-&gt;algebra\n\n\n∪－stable\n\n\n\nalgebra-&gt;σ－algebra\n\n\nσ－∪－stable\n\n\n\nλ－system\n\nλ－system\n\n\n\nλ－system-&gt;σ－algebra\n\n\n∩－stable\n\n\n\nπ－system\n\nπ－system\n\n\n\nπ－system-&gt;semiring\n\n\n＼－semistable"
  },
  {
    "objectID": "posts/ap/2023-06-20-15wk-2-fin.html",
    "href": "posts/ap/2023-06-20-15wk-2-fin.html",
    "title": "15wk-2: 기말고사",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport copy\n\n\n1. 다음을 읽고 참 거짓을 판단하여라. (30점)\n(1) 전이확률행렬 \\({\\bf P}={\\bf I}\\)를 가지는 HMC는 irreducible 하다.\n(2) HMC \\(\\{X_t\\}\\)가 유한한 상태공간을 가진다면 irreducible 조건은 positive recurrent 를 암시한다.\n(3) HMC \\(\\{X_t\\}\\)가 irreducible 하다면 항상 전이확률행렬 \\({\\bf P}\\)가 수렴한다.\n(4) HMC \\(\\{X_t\\}\\)가 irreducible 하다면 positive recurrent 조건과 유일한 정상분포를 가질 조건이 동치이다.\n(5) HMC \\(\\{X_t\\}\\)가 정상분포를 가진다면 DBC (detailed balance condition) 을 만족한다.\n\n\n2. 페이지랭크 알고리즘 (20점)\n아래는 7개의 website에 대한 web graph이다.\n\n\n\n\nflowchart LR\n  0 --&gt;|1/2| 1\n  1 --&gt;|1/2| 0\n  0 --&gt;|1/2| 2\n  1 --&gt;|1/2| 2\n  2 --&gt;|1| 3 \n  4 --&gt;|1| 3\n  3 --&gt;|1| 5 \n  6 --&gt;|1| 5\n\n\n\n\n\n구글의 페이지랭크 알고리즘을 이용하여 위의 website들의 중요도를 랭킹하라. 단, 이때 구글매트릭스를 만들기 위한 \\(\\alpha\\)는 0.85로 설정하라.\nhint: 아래의 매트릭스를 적절하게 수정하여 만들어라.\n\nP = np.array([0.0, 1/2, 1/2, 0.0, 0.0, 0.0, 0.0,\n              1/2, 0.0, 1/2, 0.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ### 이 부분은 다 0이므로 수정이 필요함!!\n              0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]).reshape(7,7)\nP\n\n\n\n3. MH-알고리즘 (20점)\n매트로폴리스 헤이스팅스 알고리즘을 사용하여 \\(X_t \\sim {\\cal B}(2,6)\\)인 따르는 확률변수열 \\(\\{X_t\\}\\)를 샘플링하라. 샘플링결과를 히스토그램으로 시각화하고, 시각화 결과를\nnp.random.beta(2,6,size=100000)\n으로 생성한 결과와 비교하라.\n\n\n4. LDA (30점)\n아래는 장하니 학생의 2023년 확률과정론 필기자료를 바탕으로 작성한 코퍼스이다.\n\nD = {'doc1': ['기대값', '기대값', '르벡메져', '잴 수 있는 집합', 'outcome', '확률과정', '잴 수 있는 집합', '잴 수 있는 집합', '잴 수 있는 집합', '시그마필드', '평균', '기대값', '기대값', '전사', '확률변수', 'event', '전단사', '시그마필드', '전단사', '르벡메져', '시그마필드', '시그마필드', '확률', '확률', '메져', '메져', '확률', '확률과정', '르벡메져', '기대값'], 'doc2': ['기대값', '확률변수', '르벡메져', '전단사', '기대값', '확률', '확률', '단사', '확률변수', '르벡메져', '확률변수', '확률', '잴 수 있는 집합', '기대값', '시그마필드', '르벡메져', '시그마필드', 'countable', 'countable', '가산집합', '확률과정', '확률', '기대값', '기대값', '카디널리티', '기대값', '잴 수 있는 함수', '확률과정', '잴 수 있는 집합', '잴 수 있는 함수'], 'doc3': ['전단사', 'event', '전사', '시그마필드', '평균', '카디널리티', 'countable', '전단사', 'event', '평균', '메져', '확률변수', '확률변수', '기대값', '기대값', 'event', '기대값', '확률과정', '카디널리티', '확률', '단사', 'outcome', 'countable', '가산집합', '가산집합', '확률변수', '기대값', '확률변수', '잴 수 있는 집합', '전사'], 'doc4': ['잴 수 있는 함수', '가산집합', '평균', '가산집합', '확률', '확률변수', '메져', 'outcome', 'countable', '잴 수 있는 함수', '기대값', 'countable', '전사', '르벡메져', 'outcome', '잴 수 있는 집합', '카디널리티', 'outcome', '시그마필드', '가산집합', '르벡메져', '잴 수 있는 함수', '카디널리티', '메져', '시그마필드', '확률과정', 'event', '가산집합', '단사', '가산집합'], 'doc5': ['확률', 'countable', '기대값', '카디널리티', '전사', 'outcome', '시그마필드', '메져', '잴 수 있는 함수', '확률변수', '전사', '단사', '기대값', '가산집합', 'event', '평균', 'event', 'outcome', '잴 수 있는 집합', 'outcome', '카디널리티', '확률', '메져', '평균', '평균', '잴 수 있는 집합', '기대값', '확률과정', '확률', '시그마필드'], 'doc6': ['단사', '평균', '기대값', '확률', 'event', '확률', '잴 수 있는 함수', 'outcome', '메져', '확률변수', '시그마필드', '잴 수 있는 집합', '카디널리티', '전사', '기대값', '시그마필드', '잴 수 있는 함수', '전사', '확률과정', '카디널리티', '전단사', '메져', '단사', '전단사', '시그마필드', 'countable', '카디널리티', '확률과정', '확률변수', '메져'], 'doc7': ['확률변수', '메져', '메져', '잴 수 있는 함수', '르벡메져', '단사', '확률변수', '평균', '카디널리티', '평균', '전사', '확률변수', '평균', '확률변수', '잴 수 있는 집합', '가산집합', '메져', '확률과정', '확률변수', '르벡메져', 'event', '카디널리티', 'countable', '기대값', '르벡메져', '잴 수 있는 집합', '시그마필드', '메져', '메져', '메져'], 'doc8': ['기대값', 'countable', '확률', '전단사', '확률', '단사', '확률변수', 'event', '확률변수', '잴 수 있는 집합', '가산집합', 'countable', '전단사', 'event', 'outcome', '전사', '확률변수', '확률', '카디널리티', '시그마필드', '가산집합', '기대값', '전단사', 'outcome', '전사', 'event', 'event', 'outcome', '평균', '가산집합'], 'doc9': ['단사', '기대값', '기대값', 'outcome', '잴 수 있는 집합', '전단사', '메져', '시그마필드', '가산집합', '전사', '단사', '르벡메져', '기대값', '기대값', '가산집합', '확률변수', '시그마필드', 'event', 'outcome', '르벡메져', '단사', '잴 수 있는 함수', '전사', 'event', '기대값', '단사', '전단사', '전단사', '평균', '시그마필드'], 'doc10': ['기대값', '시그마필드', '시그마필드', '단사', '확률변수', 'event', 'event', '확률과정', '시그마필드', '르벡메져', '카디널리티', '확률변수', '카디널리티', '전사', 'countable', '단사', '단사', '르벡메져', 'countable', '평균', '전단사', '시그마필드', '가산집합', '기대값', '전사', '잴 수 있는 집합', '시그마필드', 'outcome', '가산집합', '확률변수'], 'doc11': ['확률변수', '마코프체인', '확률과정', 'irreducible', '상태공간', 'ergodic', '극한분포', 'ergodic', 'recurrent', '확률변수', '극한분포', '전이확률', '전이확률', 'homogeneous', 'transient', '상태공간', 'theorem', 'detailed balance condition', 'theorem', '마코프체인', '마코프체인', '정상분포', '분포', 'detailed balance condition', '확률변수', 'detailed balance condition', '정상분포', 'homogeneous', '전이확률', 'theorem'], 'doc12': ['aperiodic', '정상분포', '확률과정', '극한분포', 'homogeneous', '분포', '확률과정', '마코프체인', 'homogeneous', '확률변수', '확률과정', 'irreducible', '정상분포', 'detailed balance condition', '상태공간', 'ergodic', 'transient', '확률변수', '전이확률', 'ergodic', '상태공간', 'theorem', 'detailed balance condition', '확률변수', '상태공간', '전이확률', '전이확률', '마코프체인', '극한분포', '극한분포'], 'doc13': ['irreducible', '마코프체인', '마코프체인', '상태공간', '마코프체인', '상태공간', 'irreducible', 'recurrent', 'irreducible', '마코프체인', '정상분포', 'detailed balance condition', 'irreducible', 'detailed balance condition', '정상분포', 'ergodic', 'theorem', 'aperiodic', '전이확률', '확률과정', '확률변수', '분포', 'aperiodic', 'transient', '전이확률', 'homogeneous', 'ergodic', 'theorem', '분포', '상태공간'], 'doc14': ['확률과정', '확률변수', 'theorem', 'recurrent', 'detailed balance condition', 'homogeneous', 'irreducible', 'ergodic', '마코프체인', '분포', '상태공간', 'transient', 'ergodic', '상태공간', 'homogeneous', '정상분포', '상태공간', 'theorem', '확률변수', 'transient', '분포', '마코프체인', 'detailed balance condition', '확률과정', 'aperiodic', 'ergodic', 'ergodic', 'irreducible', '분포', 'ergodic'], 'doc15': ['detailed balance condition', '전이확률', '분포', '분포', '확률과정', '확률변수', 'homogeneous', 'irreducible', 'homogeneous', '확률과정', 'theorem', '마코프체인', '정상분포', '상태공간', '확률과정', '마코프체인', 'recurrent', '확률변수', 'transient', '마코프체인', 'homogeneous', 'irreducible', 'transient', 'detailed balance condition', '마코프체인', '극한분포', 'detailed balance condition', 'ergodic', 'theorem', '전이확률'], 'doc16': ['마코프체인', '정상분포', 'detailed balance condition', '확률과정', 'homogeneous', 'aperiodic', '극한분포', 'aperiodic', 'homogeneous', 'transient', '마코프체인', '전이확률', '극한분포', 'irreducible', 'irreducible', 'recurrent', 'transient', '확률변수', '정상분포', '극한분포', '확률변수', 'recurrent', '극한분포', 'recurrent', '상태공간', '분포', 'ergodic', '마코프체인', 'theorem', 'homogeneous'], 'doc17': ['극한분포', '전이확률', '정상분포', 'irreducible', '상태공간', 'ergodic', 'ergodic', '상태공간', '극한분포', 'transient', '상태공간', 'ergodic', 'irreducible', 'transient', '확률과정', 'ergodic', 'irreducible', '마코프체인', 'aperiodic', '전이확률', '확률변수', 'aperiodic', 'detailed balance condition', '전이확률', '전이확률', 'detailed balance condition', 'ergodic', '마코프체인', 'transient', '극한분포'], 'doc18': ['정상분포', '상태공간', 'transient', '확률변수', 'detailed balance condition', 'aperiodic', 'homogeneous', '극한분포', '정상분포', 'ergodic', 'aperiodic', 'transient', 'recurrent', '확률과정', '확률변수', 'homogeneous', '상태공간', 'aperiodic', '확률변수', 'irreducible', '확률과정', 'theorem', '정상분포', 'irreducible', '전이확률', 'aperiodic', '전이확률', '확률과정', '정상분포', 'ergodic'], 'doc19': ['극한분포', 'recurrent', 'aperiodic', 'irreducible', '확률변수', 'aperiodic', 'ergodic', 'transient', '극한분포', 'homogeneous', 'theorem', 'ergodic', 'homogeneous', 'transient', '극한분포', 'transient', 'irreducible', 'homogeneous', '분포', '정상분포', '정상분포', 'aperiodic', 'ergodic', '확률과정', '확률과정', '정상분포', 'irreducible', '마코프체인', '극한분포', 'homogeneous'], 'doc20': ['확률과정', 'detailed balance condition', '확률변수', 'aperiodic', 'irreducible', '확률과정', 'recurrent', 'theorem', 'transient', '전이확률', 'recurrent', 'recurrent', 'aperiodic', '전이확률', '확률변수', 'ergodic', '확률과정', '상태공간', '마코프체인', '확률변수', 'recurrent', '분포', '마코프체인', '마코프체인', 'ergodic', 'aperiodic', '마코프체인', 'ergodic', '확률변수', 'homogeneous'], 'doc21': ['페이지랭크', 'MDP', '메트로폴리스-헤이스팅스', '페이지랭크', '메트로폴리스-헤이스팅스', '샘플링', '구글매트릭스', '마코프체인', '몬테카를로', '강화학습', 'MCMC', '계층모형', '구글매트릭스', '메트로폴리스-헤이스팅스', '샘플링', '구글', '구글매트릭스', '베이지안', '계층모형', '몬테카를로', '몬테카를로', '몬테카를로', '계층모형', '계층모형', 'MCMC', '강화학습', '베이지안', '계층모형', 'MDP', '메트로폴리스-헤이스팅스'], 'doc22': ['강화학습', '강화학습', '구글매트릭스', 'MCMC', '계층모형', 'LDA', '강화학습', 'MCMC', '메트로폴리스-헤이스팅스', 'LDA', '구글매트릭스', '계층모형', '구글', '구글', '샘플링', '구글', '구글', '메트로폴리스-헤이스팅스', 'LDA', '베이지안', '강화학습', '마코프체인', '베이지안', '메트로폴리스-헤이스팅스', '강화학습', '마코프체인', '몬테카를로', '메트로폴리스-헤이스팅스', 'MCMC', '구글'], 'doc23': ['강화학습', '마코프체인', '계층모형', 'LDA', 'MDP', '구글매트릭스', '계층모형', '베이지안', '마코프체인', '계층모형', 'MCMC', '구글매트릭스', '몬테카를로', 'MCMC', 'LDA', '마코프체인', '베이지안', '강화학습', '구글', '베이지안', '몬테카를로', 'MCMC', '몬테카를로', '마코프체인', '강화학습', '구글', '구글매트릭스', '몬테카를로', '몬테카를로', '샘플링'], 'doc24': ['베이지안', 'MDP', '구글', '메트로폴리스-헤이스팅스', 'LDA', 'MCMC', '계층모형', '몬테카를로', 'MDP', '구글매트릭스', '마코프체인', '페이지랭크', '계층모형', '구글매트릭스', '구글매트릭스', 'MCMC', '베이지안', '계층모형', '구글매트릭스', '구글', 'MCMC', '페이지랭크', '구글매트릭스', 'MCMC', 'MDP', '몬테카를로', '몬테카를로', 'MCMC', '구글', '계층모형'], 'doc25': ['구글매트릭스', 'MCMC', 'LDA', '마코프체인', '페이지랭크', '구글매트릭스', '메트로폴리스-헤이스팅스', '페이지랭크', '구글매트릭스', '강화학습', 'MDP', 'MCMC', '페이지랭크', '베이지안', '몬테카를로', '페이지랭크', '구글매트릭스', '몬테카를로', '몬테카를로', '계층모형', '베이지안', '페이지랭크', 'MDP', '샘플링', '구글매트릭스', '구글', '샘플링', 'MDP', '마코프체인', 'LDA'], 'doc26': ['메트로폴리스-헤이스팅스', '샘플링', '샘플링', 'MDP', '계층모형', 'MDP', '마코프체인', '샘플링', '강화학습', '샘플링', '강화학습', '강화학습', '베이지안', '샘플링', '마코프체인', '계층모형', '강화학습', '샘플링', '샘플링', '베이지안', '강화학습', '강화학습', '마코프체인', '메트로폴리스-헤이스팅스', 'MDP', '마코프체인', '페이지랭크', '구글매트릭스', '계층모형', '마코프체인'], 'doc27': ['LDA', '구글매트릭스', '페이지랭크', 'MDP', '구글', '페이지랭크', '몬테카를로', 'MCMC', '몬테카를로', '계층모형', '메트로폴리스-헤이스팅스', '샘플링', '페이지랭크', '계층모형', 'MCMC', '계층모형', '구글매트릭스', '구글', 'LDA', '페이지랭크', '메트로폴리스-헤이스팅스', '메트로폴리스-헤이스팅스', 'LDA', 'MCMC', '페이지랭크', '몬테카를로', 'MDP', 'MCMC', 'MCMC', '샘플링'], 'doc28': ['구글', '몬테카를로', 'LDA', '강화학습', 'MCMC', '샘플링', '계층모형', '강화학습', '몬테카를로', '베이지안', '구글', '페이지랭크', '강화학습', '샘플링', '페이지랭크', '몬테카를로', '베이지안', '구글매트릭스', '페이지랭크', '메트로폴리스-헤이스팅스', '강화학습', '강화학습', '샘플링', 'MCMC', '페이지랭크', 'LDA', '구글', '샘플링', 'MCMC', '마코프체인'], 'doc29': ['페이지랭크', '계층모형', '샘플링', '구글', 'MCMC', '구글매트릭스', 'MCMC', '구글매트릭스', '메트로폴리스-헤이스팅스', '몬테카를로', 'LDA', '구글매트릭스', '페이지랭크', '구글', '페이지랭크', '샘플링', '몬테카를로', '구글', '강화학습', 'MDP', '계층모형', '메트로폴리스-헤이스팅스', '계층모형', 'LDA', 'MDP', '구글매트릭스', 'MCMC', 'LDA', '계층모형', '메트로폴리스-헤이스팅스'], 'doc30': ['구글매트릭스', 'MCMC', '메트로폴리스-헤이스팅스', 'MCMC', '계층모형', '메트로폴리스-헤이스팅스', '강화학습', '베이지안', '계층모형', '샘플링', '베이지안', '베이지안', '베이지안', '구글', 'MDP', '계층모형', '강화학습', '마코프체인', '몬테카를로', 'MCMC', 'LDA', '페이지랭크', '몬테카를로', '구글매트릭스', 'MDP', '구글', '구글매트릭스', '몬테카를로', '몬테카를로', '강화학습']}\ndf = pd.DataFrame(D)\ndf.head()\n\n아래는 이 자료의 일부문서 (문서1, 문서15, 문서30)을 시각화한 것이다. 문서1에는 “측도론” 관련 단어들이, 문서15에는 “마코프체인” 관련 단어들이, 그리고 문서30에는 “마코체인의 응용”과 관련된 단어들이 포함되어 있다는 것을 알수 있다.\n\ndf.stack().reset_index().rename({'level_1':'doc',0:'word'},axis=1).groupby(['doc','word']).agg('count').\\\nstack().reset_index().rename({0:'count'},axis=1).query('doc in [\"doc1\",\"doc15\",\"doc30\"]').\\\nplot.bar(backend='plotly',x='word',y='count',facet_row=\"doc\",height=800)\n\n즉 이 문서에는 총 3개의 토픽에 해당하는 단어가 있으며, 각 토픽은 (1) 측도론 (2) 마코프체인 (3) 마코프체인의 응용이다. 토픽수를 3으로 설정한 뒤 Latent Dirichlet Allocation (LDA)1 를 이용하여 각 단어를 적절한 토픽으로 분류하라.\n\n\n\n\n\nFootnotes\n\n\n@blei2003latent↩︎"
  },
  {
    "objectID": "posts/ap/2023-05-09-ap-10wk.html",
    "href": "posts/ap/2023-05-09-ap-10wk.html",
    "title": "10wk: 분포, 분포함수",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-ymuuOEv4Zru7SF5duhH7dC"
  },
  {
    "objectID": "posts/ap/2023-05-09-ap-10wk.html#분포-distribution",
    "href": "posts/ap/2023-05-09-ap-10wk.html#분포-distribution",
    "title": "10wk: 분포, 분포함수",
    "section": "분포 (distribution)",
    "text": "분포 (distribution)\n- (예제1) – 동전예제\n동전을 던지는 예제로 만들어지는 아래와 같은 확률공간 \\((\\Omega,{\\cal F},P)\\) 를 생각하자.\n\n\\(\\Omega = \\{H,T\\}\\)\n\\({\\cal F} = 2^\\Omega\\)\n\\(P(\\{H\\})=P(\\{T\\})=\\frac{1}{2}\\)1\n\n확률변수 \\(X:\\Omega \\to \\mathbb{R}\\)를 아래와 같이 정의하자.\n\n\\(X(H)=1\\)\n\\(X(T)=0\\)\n\n이제 \\(B \\in {\\cal R}\\) 에 대하여 아래와 같은 표현들을 고려하자.\n\n\\(P(X \\in B)\\) // 고등학교 부터 쓰던 그 표현\n\\(P(\\{\\omega: X(\\omega) \\in B\\})\\) // 이번에 배운 표현, 표현1의 정확한 버전\n\\(P(X^{-1}(B))\\) // 표현2의 다른 버전, inverse image의 느낌이 확 살아 있음\n\\((P \\circ X^{-1})(B)\\) // 생각해보니까 이것도 가능함. \\(P\\), \\(X\\) 모두 함수였잖아?\n\n표현4를 좀 더 살펴보자. 기호를 간단하게 하기위해서 \\(\\mu_X:=P\\circ X^{-1}\\)로 정의하자.\n\n\\(P(\\emptyset) = 0 \\Leftrightarrow \\mu_X(\\emptyset) = 0\\)\n\\(P(\\{H\\}) = \\frac{1}{2} \\Leftrightarrow \\mu_X(\\{0\\}) = \\frac{1}{2}\\)\n\\(P(\\{T\\}) = \\frac{1}{2} \\Leftrightarrow \\mu_X(\\{1\\}) = \\frac{1}{2}\\)\n\\(P(\\{H,T\\}) = 1 \\Leftrightarrow \\mu_X(\\{0,1\\}) = 1\\)\n\n- (예제2) – 주머니 예제\n주머니에 하얀공과 빨간공이 하나씩 있다고 하자. 주머니에 손을 넣어 이중 하나의 공을 뽑는 시행을 한다고 하자. 이러한 상황으로 만들어지는 아래와 같은 확률공간 \\((\\Omega,{\\cal F},P)\\) 를 생각하자.\n\n\\(\\Omega = \\{R,W\\}\\)\n\\({\\cal F} = 2^\\Omega\\)\n\\(P(\\{R\\})=P(\\{W\\})=\\frac{1}{2}\\)\n\n확률변수 \\(X:\\Omega \\to \\mathbb{R}\\)를 아래와 같이 정의하자.\n\n\\(X(R)=1\\)\n\\(X(W)=0\\)\n\n이제 \\(B \\in {\\cal R}\\) 에 대하여 아래와 같은 표현들을 고려하자.\n\n\\(P(X \\in B)\\)\n\\((P \\circ X^{-1})(B)=\\mu_X(B)\\)\n\n두 표현을 비교하여 살펴보자.\n\n\\(P(\\emptyset) = 0 \\Leftrightarrow \\mu_X(\\emptyset) = 0\\)\n\\(P(\\{R\\}) = \\frac{1}{2} \\Leftrightarrow \\mu_X(\\{0\\}) = \\frac{1}{2}\\)\n\\(P(\\{W\\}) = \\frac{1}{2} \\Leftrightarrow \\mu_X(\\{1\\}) = \\frac{1}{2}\\)\n\\(P(\\{R,W\\}) = 1 \\Leftrightarrow \\mu_X(\\{0,1\\}) = 1\\)\n\n- 생각의 시간1: 예제1,2를 관찰하며 생각\n\n예제1,2의 공통속성: 제1과 예제2는 어떠한 공통점이 있다. 비록 outcome, event, \\(\\sigma\\)-field, \\(P\\), \\(X\\) 가 모두 다르지만 사실 어떻게 보면 기호의 차이만 있을 뿐 “확률과 관련된 시행이 어떠한 결과로 나타나는지”에 관련한 본질적인 면에서 같다고 볼 수 있다.2\n\\(\\mu_X\\)가 \\(P\\)보다 예제1,2의 공통속성3을 나타내기에 유리한 것 같은데?\n\n- 생각의 시간2: \\(\\mu_X\\)는 언제나 잘 정의되는가?\n\\((\\Omega,{\\cal F}, P)\\)가 확률공간이고 \\(X:\\Omega \\to \\mathbb{R}\\)이 확률변수라면, \\(\\mu_X:=P\\circ X^{-1}\\)는 언제나 잘 정의된다.\n\n시그마필드: 모든 \\(B \\in {\\cal R}\\)에 대하여 \\(X^{-1}(B)\\)가 시그마필드의 원소가 아닐 수 없다. (만약 그렇다면 \\(X\\)는 확률변수가 아닌걸?)\n메져: 모든 \\(B \\in {\\cal R}\\)에 대하여 \\(P(X^{-1}(B))\\)의 값을 모순되게 정의할 수 없다. (만약 그렇다면 \\((\\Omega, {\\cal F}, P)\\)는 확률공간이 아닌걸?)\n\n결론: \\(\\mu_X\\)는 안전해!\n- 생각의 시간3: \\(\\mu_X\\)도 확률측도의 조건을 만족한다. 구체적으로는 \\((\\mathbb{R}, {\\cal R})\\)에서의 확률측도가 된다. 아래를 체크하자.\n\n정의역: \\(\\mu_X\\)는 시그마필드를 정의역으로 가진다.\n함수값: \\(\\mu_X(\\emptyset)=0\\), \\(\\mu_X(\\mathbb{R})=1\\) 이며 \\(\\mu_X(\\cdot)\\)은 항상 양의값을 가진다.\n\\(\\sigma\\)-add: \\(\\mu_X\\)는 \\({\\cal R}\\)의 모든 서로소인 집합에 대하여 \\(\\sigma\\)-additivity 가 성립한다.\n\n따라서 \\(P\\)가 \\((\\Omega,{\\cal F})\\)에서의 확률측도이듯이 \\(\\mu_X\\)는 \\((\\mathbb{R}, {\\cal R})\\)에서의 확률측도이다.\n- (정의): \\(X\\)를 확률공간 \\((\\Omega, {\\cal F}, P)\\)에서 정의된 확률변수라고 하자. 이때 \\(\\mu_X:=P \\circ X^{-1}\\)로 정의가능한 함수 \\(\\mu_X: {\\cal R} \\to [0,1]\\) 를 \\(X\\)의 distribution 라고 부른다.\n\n여기에서 “\\(X\\)를 확률공간 \\((\\Omega, {\\cal F}, P)\\)에서의 확률변수”라는 말이 얼마나 많은 구질구질한 선언을 대신 하는지 생각해보라. 제대로 쓰려면 아마 “\\(\\Omega\\)를 어떠한 실험에 의하여 발생한 outcome들의 집합이라고 하자. 그리고 \\({\\cal F}\\)를 \\(\\Omega\\)에 대한 시그마필드라고 하자. 즉 \\({\\cal F}\\)는 … 을 만족하는 집합이다. \\((\\Omega, {\\cal F})\\)을 묶어서 가측공간이라고 하자. \\(P\\)는 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\)에 대한 확률측도라고 하자. 즉 \\(P\\)는 … 를 만족하는 함수이다. 그리고 \\(X\\)는 \\((\\Omega,{\\cal F}) \\to (\\mathbb{R}, {\\cal R})\\)인 확률변수라고 하자. 즉 \\(X\\)는 임의의 \\(B \\in {\\cal R}\\)에 대하여 … 를 만족하는 함수이다. 여기에서 \\({\\cal R}\\)은 Borel sets이다. 즉 \\({\\cal R}\\)은 … 를 만족하는 집합이다.” 와 같은 방식으로 써야할 것이다.\n\n- \\(\\mu_X\\)는 \\((\\mathbb{R}, {\\cal R})\\)에서의 확률측도이므로 \\((\\mathbb{R},{\\cal R},\\mu_X)\\)는 확률공간이 된다. 그런데 \\(\\mu_X\\)가 \\(X\\)에 의하여 정의되므로, 확률공간 \\((\\mathbb{R},{\\cal R},\\mu_X)\\) 역시 \\(X\\)에 의하여 정의되는데 이러한 이유로 확률공간 \\((\\mathbb{R}, {\\cal R}, \\mu_X)\\)를 \\(X\\)에 의하여 유도된 확률공간이라고 표현하기도 한다.\n- \\((\\mathbb{R}, {\\cal R}, \\mu_X)\\)가 \\(X\\)에 의하여 유도된 확률공간이라는 선언의 숨은 의미4: 함수 \\(X\\)가 잘 정의된다면 (\\(X\\)가 확률변수라면!) 공간 \\((\\Omega, {\\cal F}, P)\\)와 공간 \\((\\mathbb{R}, {\\cal R}, \\mu_X)\\)는 대등한 역할을 한다. 즉 \\(\\Omega\\)의 임의의 원소는 \\(\\mathbb{R}\\)의 임의의 원소로 바꾸어 생각할 수 있고, \\({\\cal F}\\)의 임의의 원소는 \\({\\cal R}\\)의 임의의 원소로 대치할 수 있으며, \\({\\cal F}\\)의 임의의 원소(event)를 측도 \\(P\\)로 재는 일은 \\({\\cal R}\\)의 임의의 원소를 측도 \\(\\mu_X\\)로 재는 일과 동치로 해석할 수 있다."
  },
  {
    "objectID": "posts/ap/2023-05-09-ap-10wk.html#분포함수-distribution-function",
    "href": "posts/ap/2023-05-09-ap-10wk.html#분포함수-distribution-function",
    "title": "10wk: 분포, 분포함수",
    "section": "분포함수 (distribution function)",
    "text": "분포함수 (distribution function)\n- 모티브: \\(\\mu_X:{\\cal R} \\to [0,1]\\) 는 정의역이 집합이라서 아쉬움. (솔직히 우리한테 친숙한 형태는 아님) 만약에\n\n집합 \\(\\to\\) 숫자\n\n와 같은 방식으로 랜덤성을 정의하지 않고\n\n숫자 \\(\\to\\) 숫자\n\n와 같은 방식으로 랜덤성을 정의할 수 있다면 어떨까?\n- 결국 랜덤성을 기술하려면 \\(P\\)를 기술해야한다. 그런데 \\(P\\)를 기술하기가 좀 까다로울 경우가 많은데 그것을 단순화 하기 위한 노력의 시작은 카라테오도리의 확장정리였다.5 그리고 이 노력의 마지막은 이제 소개하는 분포함수이다.\n- (예제1) – 동전예제 다시\n동전을 던지는 예제로 만들어지는 아래와 같은 확률공간 \\((\\Omega,{\\cal F},P)\\) 를 생각하자.\n\n\\(\\Omega = \\{H,T\\}\\)\n\\({\\cal F} = 2^\\Omega\\)\n\\(P(\\{H\\})=P(\\{T\\})=\\frac{1}{2}\\)\n\n확률변수 \\(X:\\Omega \\to \\mathbb{R}\\)를 아래와 같이 정의하자.\n\n\\(X(H)=1\\)\n\\(X(T)=0\\)\n\n이제 아래와 같은 함수를 정의하자.\n\\[F_X(x)=\\begin{cases} 0 & x&lt;0 \\\\ \\frac{1}{2} & 0\\leq x &lt; 1 \\\\ 1 & 1 \\leq x \\end{cases}\\]\n이 함수는 동전예제가 가지는 랜덤성을 완전히 설명한다. 즉 \\(F_X:\\mathbb{R} \\to [0,1]\\)를 정의하는 일은 \\(P:{\\cal F} \\to [0,1]\\)를 정의하는 일과 동치이다. 왜 그런지 논의하라.\n(해설)\n복습 – 강의노트 06주차 파이시스템에서의 확장이론\n\nThm: \\((\\Omega, \\sigma({\\cal A}), P)\\)를 확률공간이라고 하자. 여기에서 \\({\\cal A}\\)는 파이시스템이라고 가정하자. 그렇다면 확률측도 \\(P:\\sigma({\\cal A}) \\to [0,1]\\)의 값은 \\(P: {\\cal A} \\to [0,1]\\)의 값에 의하여 유일하게 결정된다.\n\n체크\n\n\\(\\mu_X\\)는 \\((\\mathbb{R}, {\\cal R})\\)에서의 확률측도이다. 따라서 \\((\\mathbb{R}, {\\cal R}, \\mu_X)\\)는 확률공간이다.\n\n진짜해설\n\\(F_X(x)=\\mu_X((-\\infty,x])\\)로 쓸 수 있다. 따라서 모든 실수 \\(x\\in \\mathbb{R}\\)에 대하여 \\(F_X(x)\\)의 값을 정의하는 일은 모든 \\({\\cal A}=\\{(-\\infty,x]: x\\in \\mathbb{R}\\}\\) 에서 \\(\\mu_X:{\\cal A} \\to [0,1]\\) 을 정의하는 일과 동치이다. 그런데 \\({\\cal A}\\)는 파이시스템이므로 \\({\\cal A}\\)에서의 \\(\\mu_X\\)값만 결정해도 \\({\\cal R}\\)의 모든 집합에서의 \\(\\mu_X\\)값이 올바르게 결정된다. 그런데 공간 \\((\\mathbb{R}, {\\cal R}, \\mu_X)\\)는 \\(X\\)에 의하여 유도된 공간이므로 \\((\\mathbb{R}, {\\cal R})\\)에서 \\(\\mu_X\\)를 정의하는 일은 \\(P\\)를 정의하는 일과 같다.\n\n\\(\\mathbb{R}\\)에서 \\(F_X(x)\\)를 정의 \\(\\Leftrightarrow\\) \\({\\cal A}\\)에서 \\(\\mu_X\\)를 정의 \\(\\Leftrightarrow\\) \\({\\cal R}\\)에서 \\(\\mu_X\\)를 정의 \\(\\Leftrightarrow\\) \\({\\cal F}\\)에서 \\(P\\)를 정의\n\n- (정의): \\(X\\)를 확률공간 \\((\\Omega, {\\cal F}, P)\\)에서 정의된 확률변수라고 하자. \\(F_X: \\mathbb{R} \\to [0,1]\\) 인 함수를 아래와 같이 정의하자.\n\\[F_X(x) = \\mu_X((-\\infty, x])\\]\n함수 \\(F\\)를 확률변수 \\(X\\)의 distribution function 이라고 한다.\n- 위의 정의에서 함수 \\(F_X(x)\\)를 \\(F_X(x) = P(X\\leq x)\\)로 표현할 수도 있다.6\n- (예제3) – 주사위를 던지는 예제\n분포함수의 위력을 살펴보기 위하여 주사위를 던지는 예제로 만들어지는 아래와 같은 확률공간 \\((\\Omega,{\\cal F},P)\\) 를 생각하자.\n\n\\(\\Omega = \\{1,2,3,4,5,6\\}\\)\n\\({\\cal F} = 2^\\Omega\\)\n\\(P(\\{1\\})=\\dots=P(\\{6\\})=\\frac{1}{6}\\)\n\n확률변수를 \\(X: \\Omega \\to \\mathbb{R}\\)을 \\(X(\\omega)=\\omega\\)와 같이 정의하자. \\(X\\)의 distribution fucntion 을 구하라.\n(풀이)\n생략\n- 약속: \\(X\\)를 확률공간 \\((\\Omega, {\\cal F}, P)\\)에서 정의된 확률변수라고 하자. 아래와 같은 표현을 약속하자.\n\n\\(X \\sim \\mu_X\\) \\(\\Leftrightarrow\\) \\(X\\)의 distribution 이 \\(\\mu_X\\)이다.\n\\(X \\sim F_X\\) \\(\\Leftrightarrow\\) \\(X\\)의 distribution function이 \\(F_X\\)이다.\n\n- 약속2: \\(X\\)를 확률공간 \\((\\Omega_X, {\\cal F}_X, P_X)\\)에서 정의된 확률변수라고 하고, \\(Y\\)를 확률공간 \\((\\Omega_Y, {\\cal F}_Y, P_Y)\\)에서 정의된 확률변수라고 하자.\n\n\\(X \\overset{d}{=} Y\\) \\(\\Leftrightarrow\\) \\(\\forall B \\in {\\cal R}: \\mu_X(B) = \\mu_Y(B)\\)\n\\(X \\overset{d}{=} Y\\) \\(\\Leftrightarrow\\) \\(\\forall k \\in {\\mathbb R}: F_X(k) = F_Y(k)\\)\n\\(X \\overset{d}{=} Y\\) \\(\\Leftrightarrow\\) \\(\\forall k \\in {\\mathbb R}: P_X(X\\leq k) = P_Y(Y\\leq k)\\)\n\n\n만약에 랜덤성을 기술하는 언어가 \\(P\\)하나 뿐이었다면 “같은 분포를 가진다”와 같은 개념을 수식화 하기 불리하다.\n\n- Thm: 임의의 분포함수 \\(F:\\mathbb{R} \\to [0,1]\\)는 (1) 비감소 (2) \\(\\lim_{x \\to -\\infty}F(x)=0\\) and \\(\\lim_{x \\to \\infty}F(x)=1\\) (3) 오른쪽연속의 성질을 가진다.\n- Thm: 임의의 함수 \\(F:\\mathbb{R} \\to \\mathbb{R}\\)가 (1) 비감소 (2) \\(\\lim_{x \\to -\\infty}F(x)=0\\) and \\(\\lim_{x \\to \\infty}F(x)=1\\) (3) 오른쪽연속의 성질을 가진다면, \\(F\\)는 어떠한 확률변수 \\(X\\)의 분포함수이다."
  },
  {
    "objectID": "posts/ap/2023-05-09-ap-10wk.html#밀도함수-density-function",
    "href": "posts/ap/2023-05-09-ap-10wk.html#밀도함수-density-function",
    "title": "10wk: 분포, 분포함수",
    "section": "밀도함수 (density function)",
    "text": "밀도함수 (density function)\n- (정의) \\(X\\)를 확률공간 \\((\\Omega, {\\cal F}, P)\\)에서 정의된 확률변수라고 하고 \\(F_X\\)를 \\(X\\)의 분포함수 라고 하자. 만약에 \\(F_X\\)가 아래와 같은 방식으로 표현된다면 \\(f_X\\)를 \\(X\\)를 밀도함수 (density function) 이라고 한다.\n\\[F_X(x)=\\int_{-\\infty}^xf_X(y)dy\\]\n- 저런 표현이 존재하지 않는다면 어쩌지?"
  },
  {
    "objectID": "posts/ap/2023-05-18-12wk-1.html",
    "href": "posts/ap/2023-05-18-12wk-1.html",
    "title": "12wk-1: 마코프체인 (10)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-w6PeAXdc4YcGTb7M_67Wog"
  },
  {
    "objectID": "posts/ap/2023-05-18-12wk-1.html#나그네",
    "href": "posts/ap/2023-05-18-12wk-1.html#나그네",
    "title": "12wk-1: 마코프체인 (10)",
    "section": "나그네",
    "text": "나그네\n- 나그네 (박목월)\n강나루 건너서\n밀밭 길을\n\n구름에 달 가듯이\n가는 나그네\n\n길은 외줄기\n南道 삼백리\n\n술 익는 마을마다\n타는 저녁놀\n\n구름에 달 가듯이\n가는 나그네\n- 나그네\n\n정착 X\n모든 장소에 일시적(transient)으로만 머뭄\n다시 돌아올 수는 있는데 금방 다시 감.\n\n- 편의상 아래와 같이 생각하자.\n\n\\(E\\): 마을의 집합\n\\(X_t=i\\): \\(t\\)시점에 나그네가 마을 \\(i\\)에 머무는 event"
  },
  {
    "objectID": "posts/ap/2023-05-18-12wk-1.html#급수의-수렴",
    "href": "posts/ap/2023-05-18-12wk-1.html#급수의-수렴",
    "title": "12wk-1: 마코프체인 (10)",
    "section": "급수의 수렴",
    "text": "급수의 수렴\n- \\(a_n \\to 0\\) 이라고 해서 \\(\\lim_{n\\to\\infty} S_n &lt;\\infty\\) 인건 아니다.\n- 예시1: \\(a_n=\\frac{1}{2^n}\\), 수렴하는 경우\n\nsum([1/2**i for i in range(1,10000)])\n\n1.0\n\n\n- 예시2: \\(a_n = \\frac{1}{n}\\), 수렴안하는 경우\n\nsum([1/i for i in range(1,10000)])\n\n9.787506036044348"
  },
  {
    "objectID": "posts/ap/2023-05-18-12wk-1.html#예제1-오른쪽으로만-갈래",
    "href": "posts/ap/2023-05-18-12wk-1.html#예제1-오른쪽으로만-갈래",
    "title": "12wk-1: 마코프체인 (10)",
    "section": "예제1: 오른쪽으로만 갈래",
    "text": "예제1: 오른쪽으로만 갈래\n확률변수열 \\(\\{X_t\\}\\)가 HMC라고 하고, 그 transition matrix \\({\\bf P}\\) (혹은 그 비슷한 것) 가 아래와 같다고 하자.\n\\[{\\bf P} = \\begin{bmatrix}\n0 & 1 & 0 & 0 & 0 & \\dots \\\\\n0 & 0 & 1 & 0 & 0 & \\dots \\\\\n0 & 0 & 0 & 1 & 0 & \\dots \\\\\n0 & 0 & 0 & 0 & 1 & \\dots \\\\\n\\dots & \\dots & \\dots & \\dots & \\dots & \\dots\n\\end{bmatrix}\\]\n- 체크: 이 예제의 마코프체인은 IRR 하지 않다.\n1-&gt;2는 가능한데 2-&gt;1은 안 되니까\n- 나이스케이스: \\(\\bar{\\boldsymbol \\pi}^\\top \\overset{T \\to \\infty}{\\longrightarrow} {\\bf p}_{\\star}^\\top = {\\boldsymbol \\pi}^\\top\\)\n- 이 예제는 나이스하지 않음 왜? IRR이 아니라서?\n\nIRR이 아니라서 나이스하지 않다는 것은 핑계임.\n오른쪽으로 갈 확률을 0.99로 수정한다면 IRR 마코프체인이 된다. 그렇지만 이게 나이스하게 바뀔 것 같지는 않음.\n\n- 나이스하지 않은 본질적인 이유\n\n상태 \\(i\\)에 일시적(transient)으로 머무는 느낌. 거의 나그네 수준임.\n\\(\\bar{\\boldsymbol \\pi}^\\top \\overset{T \\to \\infty}{\\longrightarrow} {\\bf p}_{\\star}^\\top = {\\boldsymbol \\pi}^\\top\\) 이와 같은 논리전개를 쓰려면 일단 \\(\\{X_t\\}\\)가 특정상태를 무한번 방문해야 가능\n\n- FINITE case\n\nIRR은 가정할 수 있음.\nIRR을 가정한다면, 모든 마을에 대해서 나그네가 반복적으로 돌아오는 느낌이 있음.\n\n- 깨달음.\n\nFINITE 인 경우는 IRR 이기만 하면 “반복적으로 마을방문” 이 보장되었다.\n그런데 INFINITE 한 경우는 IRR 이어도 “반복적으로 마을방문” 이 보장되지 않는다.\n\n\nIRR 조건이 엄청 대단한 조건인줄 알았는데, 사실 그런게 아니고 (수틀리면 그냥 IRR 이라고 가정해도 무방한) 실제로 대단한 조건은 숨어있는 “반복적으로 마을방문” 이라는 조건임.\n\n- 가짜정의: HMC \\(\\{X_t\\}\\)가 (1) IRR (2) PR (3) AP 조건을 만족한다면 \\(\\{X_t\\}\\)를 에르고딕 마코프체인이라고 부른다. 여기에서 PR은 positive recurrent의 약자이며 “반복적으로 마을을 방문한다”의 의미를 가지고 있다.\nPR = Positive Recurrent\nfinite한 조건에서 IRR, finite, AP면 좋은 조건, IRR, PR,AP 면 좋은 조건, 여기서 좋은 조건이란, 에르고딕 마코프체인이라는 뜻\nreccurent 반복해서 방문 가능한 = 재귀적"
  },
  {
    "objectID": "posts/ap/2023-05-18-12wk-1.html#reccurent-transient",
    "href": "posts/ap/2023-05-18-12wk-1.html#reccurent-transient",
    "title": "12wk-1: 마코프체인 (10)",
    "section": "Reccurent, Transient",
    "text": "Reccurent, Transient\n- 대안정의: \\(\\{X_t\\}\\)가 상태공간 \\(E\\)에서 정의된 HMC 라고 하자. 만약에 상태 \\(i \\in E\\) 가 아래의 식을 만족한다면\n\\[\\sum_{t=0}^{\\infty} p_{ii}^{(t)}= \\infty\\]\n\\(i\\)는 recurrent 하다고 표현하고, 그렇지 않으면 \\(i\\)는 transient 하다고 표현한다.\n나그네의 경우로 말하면 마을i로 무한히 되돌아 온다는 뜻으로 위의 식을 이해할 수 있다.\nReccurent - null-recurrent(경계점) - Positive Recurrent(경계점을 벗어난 경우) \np가 1/2인 경우는 null-recurrent case"
  },
  {
    "objectID": "posts/ap/2023-05-18-12wk-1.html#예제2-reflecting-random-walk",
    "href": "posts/ap/2023-05-18-12wk-1.html#예제2-reflecting-random-walk",
    "title": "12wk-1: 마코프체인 (10)",
    "section": "예제2: reflecting random walk",
    "text": "예제2: reflecting random walk\n확률변수열 \\(\\{X_t\\}\\)가 HMC라고 하고, 그 transition matrix \\({\\bf P}\\) (혹은 그 비슷한 것) 가 아래와 같다고 하자.\n\\[{\\bf P} = \\begin{bmatrix}\n1-p & p & 0 & 0 & 0 & \\dots \\\\\n1-p & 0 & p & 0 & 0 & \\dots \\\\\n0 & 1-p & 0 & p & 0 & \\dots \\\\\n0 & 0 & 1-p & 0 & p & \\dots \\\\\n\\dots & \\dots & \\dots & \\dots & \\dots & \\dots\n\\end{bmatrix}\\]\n- 체크: 이 마코프체인은 IRR하다.\n- case1: \\(p=0.99\\) 라고 하자.\n\np=0.99\nP1 = np.array([[i-j == 1 for i in range(1000)] for j in range(1000)])*p\nP2 = np.array([[j-i == 1 for i in range(1000)] for j in range(1000)])*(1-p)\nP = P1+P2\nP[0,0]= 1-p \nP\n\narray([[0.01, 0.99, 0.  , ..., 0.  , 0.  , 0.  ],\n       [0.01, 0.  , 0.99, ..., 0.  , 0.  , 0.  ],\n       [0.  , 0.01, 0.  , ..., 0.  , 0.  , 0.  ],\n       ...,\n       [0.  , 0.  , 0.  , ..., 0.  , 0.99, 0.  ],\n       [0.  , 0.  , 0.  , ..., 0.01, 0.  , 0.99],\n       [0.  , 0.  , 0.  , ..., 0.  , 0.01, 0.  ]])\n\n\n\n(np.matrix(P)**10).round(5)\n\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])\n\n\n\n(np.matrix(P)**100).round(5)\n\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])\n\n\n관찰결과\n\n\\(p_{00}^{(t)} \\to 0\\).\n\\(p_{00}^{(t)} \\to 0\\) 이라고 해서 \\(\\sum_{t=0}^{\\infty} p_{00}^{(t)} &lt; \\infty\\) 이라고 주장할 순 없음. \\(\\sum_{t=0}^{\\infty} p_{00}^{(t)} = \\infty\\) 역시 주장할 수 없음.\n\\(p_{00}^{(t)}\\)이 0으로 수렴하는 속도가 매우 빠르다면 \\(\\sum_{t=0}^{\\infty} p_{00}^{(t)} &lt; \\infty\\) 일 것이고 그렇지 않다면 \\(\\sum_{t=0}^{\\infty} p_{00}^{(t)} = \\infty\\) 일 것임.\n이 경우는 \\(p_{00}^{(t)}\\)이 빠르게 0으로 수렴하는듯 보이므로 왠지 \\(\\sum_{t=0}^{\\infty} p_{00}^{(t)} &lt; \\infty\\) 일 것으로 예상가능\n상태0은 transient 인 듯 하다. (확신 X)\n\n- case2: \\(p=0.1\\) 이라고 하자.\n\np=0.1\nP1 = np.array([[i-j == 1 for i in range(1000)] for j in range(1000)])*p\nP2 = np.array([[j-i == 1 for i in range(1000)] for j in range(1000)])*(1-p)\nP = P1+P2\nP[0,0]= 1-p \nP\n\narray([[0.9, 0.1, 0. , ..., 0. , 0. , 0. ],\n       [0.9, 0. , 0.1, ..., 0. , 0. , 0. ],\n       [0. , 0.9, 0. , ..., 0. , 0. , 0. ],\n       ...,\n       [0. , 0. , 0. , ..., 0. , 0.1, 0. ],\n       [0. , 0. , 0. , ..., 0.9, 0. , 0.1],\n       [0. , 0. , 0. , ..., 0. , 0.9, 0. ]])\n\n\n\n(np.matrix(P)**100).round(5)\n\narray([[0.88889, 0.09877, 0.01097, ..., 0.     , 0.     , 0.     ],\n       [0.88889, 0.09877, 0.01097, ..., 0.     , 0.     , 0.     ],\n       [0.88889, 0.09877, 0.01097, ..., 0.     , 0.     , 0.     ],\n       ...,\n       [0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ],\n       [0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ],\n       [0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ]])\n\n\n\n(np.matrix(P)**1000).round(5)\n\narray([[0.88889, 0.09877, 0.01097, ..., 0.     , 0.     , 0.     ],\n       [0.88889, 0.09877, 0.01097, ..., 0.     , 0.     , 0.     ],\n       [0.88889, 0.09877, 0.01097, ..., 0.     , 0.     , 0.     ],\n       ...,\n       [0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ],\n       [0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ],\n       [0.     , 0.     , 0.     , ..., 0.     , 0.     , 0.     ]])\n\n\n관찰결과\n\n\\(p_{00}^{(t)} \\to 0.88889\\).\n\\(\\sum_{t=0}^{\\infty} p_{00}^{(t)} = \\infty\\)\n따라서 상태0은 recurrent!\n\n상태 0 이라는 말은 행렬(0,0)임\n\\(p_{00}^{(t)} \\to 0.88889\\) 이므로 \\(\\sum_{t=0}^{\\infty} p_{00}^{(t)} = \\infty\\) 이다. 따라서 상태 0은 recurrent!\n- case3: \\(p=0.5\\) 이라고 하자.\n\np=0.5\nP1 = np.array([[i-j == 1 for i in range(1000)] for j in range(1000)])*p\nP2 = np.array([[j-i == 1 for i in range(1000)] for j in range(1000)])*(1-p)\nP = P1+P2\nP[0,0]= 1-p \nP\n\narray([[0.5, 0.5, 0. , ..., 0. , 0. , 0. ],\n       [0.5, 0. , 0.5, ..., 0. , 0. , 0. ],\n       [0. , 0.5, 0. , ..., 0. , 0. , 0. ],\n       ...,\n       [0. , 0. , 0. , ..., 0. , 0.5, 0. ],\n       [0. , 0. , 0. , ..., 0.5, 0. , 0.5],\n       [0. , 0. , 0. , ..., 0. , 0.5, 0. ]])\n\n\n\n(np.matrix(P)**1000).round(3)\n\narray([[0.025, 0.025, 0.025, ..., 0.   , 0.   , 0.   ],\n       [0.025, 0.025, 0.025, ..., 0.   , 0.   , 0.   ],\n       [0.025, 0.025, 0.025, ..., 0.   , 0.   , 0.   ],\n       ...,\n       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ]])\n\n\n\n(np.matrix(P)**100000).round(3)\n\narray([[0.003, 0.003, 0.003, ..., 0.   , 0.   , 0.   ],\n       [0.003, 0.003, 0.003, ..., 0.   , 0.   , 0.   ],\n       [0.003, 0.003, 0.003, ..., 0.   , 0.   , 0.   ],\n       ...,\n       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ]])\n\n\n\n(np.matrix(P)**10000000).round(3)\n\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])\n\n\n관찰결과\n\n\\(p_{00}^{(t)} \\to 0\\).\n그런데 엄청 천천히 0으로 수렴함.\n\\(p_{00}^{(t)}\\)이 0으로 수렴하는 속도가 매우 빠르다면 \\(\\sum_{t=0}^{\\infty} p_{00}^{(t)} &lt; \\infty\\) 일 것이고 그렇지 않다면 \\(\\sum_{t=0}^{\\infty} p_{00}^{(t)} = \\infty\\) 일 것임.\n이 경우는 왠지 \\(\\sum_{t=0}^{\\infty} p_{00}^{(t)} = \\infty\\) 일 것 같음.\n그래서 상태 0은 recurrent 인 것 같음.\n실제로 그런지 실험해볼까?\n\n확인: \\(\\sum_{t=0}^{\\infty}p_{00}^{(t)}=\\infty\\) 임을 프로그래밍을 이용하여 근사적으로 체크해보자.\n\nPstar = P.copy()\npT = list()\npT.append(Pstar[0,0])\nT = 10000\nfor t in range(T):\n    Pstar = Pstar@P\n    pT.append(Pstar[0,0])    \nnp.array(pT).cumsum()\n\narray([  0.5       ,   1.        ,   1.375     , ..., 157.58090143,\n       157.58888008, 157.59685793])\n\n\n여기에서\n\npT = \\([p_{00}^{(0)},p_{00}^{(1)},\\dots,p_{00}^{(T)}]\\)\nnp.array(pT).cumsum() = \\([\\sum_{t=0}^{0} p_{00}^{(t)},\\sum_{t=0}^{1} p_{00}^{(t)},\\dots,\\sum_{t=0}^{T} p_{00}^{(t)}]\\)\n\n이다. 마지막의 np.array(pT).cumsum()을 시각화하면 아래와 같다.\ncumulativesum = cumsum\n\nplt.plot(np.array(pT).cumsum())\n\n\n\n\n그래프를 보니 발산할 것 같음\n- 결론: 계산해보면 (이론적으로든, 시뮬레이션을 이용하든) 이 예제의 경우 아래와 같이 됨을 알 수 있다.\n\n경우1: \\(p&gt;1/2\\) \\(\\Rightarrow\\) \\(\\sum_{t=0}^{\\infty} p_{00}^{(t)}&lt;\\infty\\). // state 0 is transient\n경우2: \\(p&lt;1/2\\) \\(\\Rightarrow\\) \\(\\sum_{t=0}^{\\infty}p_{00}^{(t)}=\\infty\\) with \\(p_{00}^{(t)} \\rightarrow c\\), \\(c&gt;0\\). // state 0 is positive recurrent\n경우3: \\(p=1/2\\) \\(\\Rightarrow\\) \\(\\sum_{t=0}^{\\infty} p_{00}^{(t)}=\\infty\\) with \\(p_{00}^{(t)} \\rightarrow 0\\). // state 0 is null recurrent\n\n- \\(p=0.45, p=0.5, p=0.55\\) 일 경우 \\(\\sum_{t=0}^{\\infty}p_{00}^{(t)}\\)의 값을 시각화\n\ndef calculate_pT(p): \n    P1 = np.array([[i-j == 1 for i in range(1000)] for j in range(1000)])*p\n    P2 = np.array([[j-i == 1 for i in range(1000)] for j in range(1000)])*(1-p)\n    P = P1+P2\n    P[0,0]= 1-p \n    \n    Pstar = P.copy()\n    pT = list()\n    pT.append(Pstar[0,0])\n    for t in range(1000):\n        Pstar = Pstar@P\n        pT.append(Pstar[0,0])    \n    return np.array(pT)\n\n\ncase1 = calculate_pT(0.55)\ncase2 = calculate_pT(0.45)\ncase3 = calculate_pT(0.50)\n\n0.5면 상태가 계속 바뀌는 나그네 같은 형태\n\nfig = plt.figure(figsize=(8,6))\nplt.plot(case1.cumsum(),label=r'$p=0.55$ $\\Rightarrow$ transient', color='C0')\nplt.plot(case2.cumsum(),label=r'$p=0.45$ $\\Rightarrow$ positive recurrent', color='C1')\nplt.plot(case3.cumsum(),label=r'$p=0.50$ $\\Rightarrow$ null recurrent', color='C2')\nplt.title('reflecting random walk with $p$',size=15)\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x7fa316ab5e50&gt;\n\n\n\n\n\n\nfig = plt.figure(figsize=(8,6))\nplt.plot(case1.cumsum(),label=r'$p=0.55$ $\\Rightarrow$ transient', color='C0')\nplt.plot(case3.cumsum(),label=r'$p=0.50$ $\\Rightarrow$ null recurrent', color='C2')\nplt.title('reflecting random walk with $p$',size=15)\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x7f7e25ecbe80&gt;"
  },
  {
    "objectID": "posts/ml/2022-10-05-ml-5w.html",
    "href": "posts/ml/2022-10-05-ml-5w.html",
    "title": "DNN (5주차)",
    "section": "",
    "text": "기계학습 특강 (5주차) 10월5일 [딥러닝의 기초 - 로지스틱(2), 깊은신경망(1)]"
  },
  {
    "objectID": "posts/ml/2022-10-05-ml-5w.html#imports",
    "href": "posts/ml/2022-10-05-ml-5w.html#imports",
    "title": "DNN (5주차)",
    "section": "imports",
    "text": "imports\n\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \n\n\n시각화를 위한 준비함수들\n준비1 loss_fn을 plot하는 함수\n\ndef plot_loss(loss_fn,ax=None):\n    if ax==None:\n        fig = plt.figure()\n        ax=fig.add_subplot(1,1,1,projection='3d')\n        ax.elev=15;ax.azim=75\n    w0hat,w1hat =torch.meshgrid(torch.arange(-10,3,0.15),torch.arange(-1,10,0.15),indexing='ij')\n    w0hat = w0hat.reshape(-1)\n    w1hat = w1hat.reshape(-1)\n    def l(w0hat,w1hat):\n        yhat = torch.exp(w0hat+w1hat*x)/(1+torch.exp(w0hat+w1hat*x))\n        return loss_fn(yhat,y) \n    loss = list(map(l,w0hat,w1hat))\n    ax.scatter(w0hat,w1hat,loss,s=0.1,alpha=0.2) \n    ax.scatter(-1,5,l(-1,5),s=200,marker='*') # 실제로 -1,5에서 최소값을 가지는건 아님.. \n\n\n\\(y_i \\sim Ber(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(-1+5x_i)}{1+\\exp(-1+5x_i)}\\) 에서 생성된 데이터 한정하여 손실함수가 그려지게 되어있음.\n\n준비2: for문 대신 돌려주고 epoch마다 필요한 정보를 기록하는 함수\n\ndef learn_and_record(net, loss_fn, optimizr):\n    yhat_history = [] \n    loss_history = []\n    what_history = [] \n\n    for epoc in range(1000): \n        ## step1 \n        yhat = net(x)\n        ## step2 \n        loss = loss_fn(yhat,y)\n        ## step3\n        loss.backward() \n        ## step4 \n        optimizr.step()\n        optimizr.zero_grad() \n\n        ## record \n        if epoc % 20 ==0: \n            yhat_history.append(yhat.reshape(-1).data.tolist())\n            loss_history.append(loss.item())\n            what_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n    return yhat_history, loss_history, what_history\n\n\n20에폭마다 yhat, loss, what을 기록\n\n준비3: 애니메이션을 만들어주는 함수\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n\ndef show_lrpr2(net,loss_fn,optimizr,suptitle=''):\n    yhat_history,loss_history,what_history = learn_and_record(net,loss_fn,optimizr)\n    \n    fig = plt.figure(figsize=(7,2.5))\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n    ax1.set_xticks([]);ax1.set_yticks([])\n    ax2.set_xticks([]);ax2.set_yticks([]);ax2.set_zticks([])\n    ax2.elev = 15; ax2.azim = 75\n\n    ## ax1: 왼쪽그림 \n    ax1.plot(x,v,'--')\n    ax1.scatter(x,y,alpha=0.05)\n    line, = ax1.plot(x,yhat_history[0],'--') \n    plot_loss(loss_fn,ax2)\n    fig.suptitle(suptitle)\n    fig.tight_layout()\n\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(what_history)[epoc,0],np.array(what_history)[epoc,1],loss_history[epoc],color='grey')\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\n준비1에서 그려진 loss 함수위에, 준비2의 정보를 조합하여 애니메이션을 만들어주는 함수"
  },
  {
    "objectID": "posts/ml/2022-10-05-ml-5w.html#logistic-intro-review-alpha",
    "href": "posts/ml/2022-10-05-ml-5w.html#logistic-intro-review-alpha",
    "title": "DNN (5주차)",
    "section": "Logistic intro (review + \\(\\alpha\\))",
    "text": "Logistic intro (review + \\(\\alpha\\))\n- 모델: \\(x\\)가 커질수록 \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt;— 외우세요!!!\n\n\\(y_i \\sim Ber(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\) &lt;— 외우세요!!\n\n- toy example\n\nx=torch.linspace(-1,1,2000).reshape(2000,1)\nw0= -1 \nw1= 5 \nu = w0+x*w1 \nv = torch.exp(u)/(1+torch.exp(u)) # v=πi, 즉 확률을 의미함\ny = torch.bernoulli(v) \n\n\nnote: \\((w_0,w_1)\\)의 true는 \\((-1,5)\\)이다. -&gt; \\((\\hat{w}_0, \\hat{w}_1)\\)을 적당히 \\((-1,5)\\)근처로 추정하면 된다는 의미\n\n\nplt.scatter(x,y,alpha=0.05)\nplt.plot(x,v,'--r')\n\n\n\n\n- step1: yhat을 만들기\n(방법1)\n\nx.shape\n\ntorch.Size([2000, 1])\n\n\n뒤의 1이 input feature로서 입력\n\ntorch.manual_seed(43052)\nl1 = torch.nn.Linear(1,1)\na1 = torch.nn.Sigmoid() \nyhat = a1(l1(x))\nyhat\n\ntensor([[0.3775],\n        [0.3774],\n        [0.3773],\n        ...,\n        [0.2327],\n        [0.2327],\n        [0.2326]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nl1.weight,l1.bias\n\n(Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n(방법2)\n\\(x \\overset{l1}{\\to} u \\overset{a1}{\\to} v = \\hat{y}\\)\n\\(x \\overset{net}{\\to} \\hat{y}\\)\n\ntorch.manual_seed(43052)\nl1 = torch.nn.Linear(1,1)\na1 = torch.nn.Sigmoid() \nnet = torch.nn.Sequential(l1,a1) \nyhat = net(x)\nyhat\n\ntensor([[0.3775],\n        [0.3774],\n        [0.3773],\n        ...,\n        [0.2327],\n        [0.2327],\n        [0.2326]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n(방법3)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nyhat = net(x)\nyhat\n\ntensor([[0.3775],\n        [0.3774],\n        [0.3773],\n        ...,\n        [0.2327],\n        [0.2327],\n        [0.2326]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n중간과정보기 힘들다.\n\n\nlen(net)\n\n2\n\n\n\nnet[0]\n\nLinear(in_features=1, out_features=1, bias=True)\n\n\n\nnet[0](x)\n\ntensor([[-0.5003],\n        [-0.5007],\n        [-0.5010],\n        ...,\n        [-1.1930],\n        [-1.1934],\n        [-1.1937]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nnet[1]\n\nSigmoid()\n\n\n\nnet[1](net[0](x))\n\ntensor([[0.3775],\n        [0.3774],\n        [0.3773],\n        ...,\n        [0.2327],\n        [0.2327],\n        [0.2326]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nl1, a1 = net\n\n\nl1\n\nLinear(in_features=1, out_features=1, bias=True)\n\n\n\na1\n\nSigmoid()\n\n\n\nid(l1),id(net[0])\n\n(140123913611200, 140123913611200)\n\n\n\n- step2: loss (일단 MSE로..)\n(방법1)\n\nloss = torch.mean((y-yhat)**2)\nloss\n\ntensor(0.2823, grad_fn=&lt;MeanBackward0&gt;)\n\n\n(방법2)\n\nloss_fn = torch.nn.MSELoss()\nloss = loss_fn(yhat,y) # yhat을 먼저쓰자!\nloss\n\ntensor(0.2823, grad_fn=&lt;MseLossBackward0&gt;)\n\n\n- step3~4는 동일\n- 반복 (준비+for문)\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.01)\n\n\nfor epoc in range(3000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,v,'--b')\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/ml/2022-10-05-ml-5w.html#로지스틱bceloss",
    "href": "posts/ml/2022-10-05-ml-5w.html#로지스틱bceloss",
    "title": "DNN (5주차)",
    "section": "로지스틱–BCEloss",
    "text": "로지스틱–BCEloss\n- BCEloss로 바꾸어서 적합하여 보자.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.01)\n\n\nfor epoc in range(3000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)  #. -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat)) \n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,v,'--b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n- 왜 잘맞지? -&gt; “linear -&gt; sigmoid” 와 같은 net에 BCEloss를 이용하면 손실함수의 모양이 convex 하기 때문에 - “linear -&gt; sigmoid” 로 \\(\\hat{y}\\)을 구하고 BCEloss로 loss를 계산하면 그 모영아 convex하므로\nBCSloss에는 local error에 빠지지 않아, loss는 있아.\n\nplot_loss 함수소개 = 이 예제에 한정하여 \\(\\hat{w}_0,\\hat{w}_1,loss(\\hat{w}_0,\\hat{w}_1)\\)를 각각 \\(x,y,z\\) 축에 그려줍니다.\n\n\nplot_loss(torch.nn.MSELoss())\n\n\n\n\n\nplot_loss(torch.nn.BCELoss())\n\n\n\n\n\n시각화1: MSE, 좋은초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\n\n\nl1.bias.data,l1.weight.data\n\n(tensor([0.6245]), tensor([[-0.2593]]))\n\n\n\nl1.bias.data = torch.tensor([-3.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nl1.bias.data,l1.weight.data\n\n(tensor([-3.]), tensor([[-1.]]))\n\n\n\nshow_lrpr2(net,loss_fn,optimizr,'MSEloss, good_init // SGD')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화2: MSE, 나쁜초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-10.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'MSEloss, bad_init // SGD')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화3: BCE, 좋은초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.BCELoss() \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-3.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'BCEloss, good_init // SGD')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화4: BCE, 나쁜초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.BCELoss() \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-10.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'BCEloss, bad_init // SGD')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/ml/2022-10-05-ml-5w.html#로지스틱adam-국민옵티마이저",
    "href": "posts/ml/2022-10-05-ml-5w.html#로지스틱adam-국민옵티마이저",
    "title": "DNN (5주차)",
    "section": "로지스틱–Adam (국민옵티마이저)",
    "text": "로지스틱–Adam (국민옵티마이저)\n\n시각화1: MSE, 좋은초기값 –&gt; 이걸 아담으로!\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(net.parameters(),lr=0.05)  ## &lt;-- 여기를 수정!\n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-3.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'MSEloss, good_init // Adam')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화2: MSE, 나쁜초기값 –&gt; 이걸 아담으로!\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-10.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'MSEloss, bad_init // Adam')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화3: BCE, 좋은초기값 –&gt; 이걸 아담으로! (혼자해봐요..)\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.BCELoss() \noptimizr = torch.optim.Adam(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-3.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'BCEloss, good_init // Adam')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화4: BCE, 나쁜초기값 –&gt; 이걸 아담으로! (혼자해봐요..)\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.BCELoss() \noptimizr = torch.optim.Adam(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-10.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'BCEloss, bad_init // Adam')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n(참고) Adam이 우수한 이유? SGD보다 두 가지 측면에서 개선이 있었음. 1. 그런게 있음.. 2. 가속도의 개념을 적용!!"
  },
  {
    "objectID": "posts/ml/2022-10-05-ml-5w.html#깊은신경망로지스틱-회귀의-한계",
    "href": "posts/ml/2022-10-05-ml-5w.html#깊은신경망로지스틱-회귀의-한계",
    "title": "DNN (5주차)",
    "section": "깊은신경망–로지스틱 회귀의 한계",
    "text": "깊은신경망–로지스틱 회귀의 한계\n\n신문기사 (데이터의 모티브)\n- 스펙이 높아도 취업이 안된다고 합니다..\n중소·지방 기업 “뽑아봤자 그만두니까”\n중소기업 관계자들은 고스펙 지원자를 꺼리는 이유로 높은 퇴직률을 꼽는다. 여건이 좋은 대기업으로 이직하거나 회사를 관두는 경우가 많다는 하소연이다. 고용정보원이 지난 3일 공개한 자료에 따르면 중소기업 청년취업자 가운데 49.5%가 2년 내에 회사를 그만두는 것으로 나타났다.\n중소 IT업체 관계자는 “기업 입장에서 가장 뼈아픈 게 신입사원이 그만둬서 새로 뽑는 일”이라며 “명문대 나온 스펙 좋은 지원자를 뽑아놔도 1년을 채우지 않고 그만두는 사원이 대부분이라 우리도 눈을 낮춰 사람을 뽑는다”고 말했다.\n\n\n가짜데이터\n- 위의 기사를 모티브로 한 데이터\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex0.csv')\ndf\n\n\n\n\n\n\n\n\nx\nunderlying\ny\n\n\n\n\n0\n-1.000000\n0.000045\n0.0\n\n\n1\n-0.998999\n0.000046\n0.0\n\n\n2\n-0.997999\n0.000047\n0.0\n\n\n3\n-0.996998\n0.000047\n0.0\n\n\n4\n-0.995998\n0.000048\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n0.995998\n0.505002\n0.0\n\n\n1996\n0.996998\n0.503752\n0.0\n\n\n1997\n0.997999\n0.502501\n0.0\n\n\n1998\n0.998999\n0.501251\n1.0\n\n\n1999\n1.000000\n0.500000\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nplt.plot(df.x,df.y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\n\n\n\n\n\n\n로지스틱 회귀로 적합\n\nx= torch.tensor(df.x).float().reshape(-1,1)\ny= torch.tensor(df.y).float().reshape(-1,1)\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\n#yhat=net(x)\n\n\nloss_fn = torch.nn.BCELoss() \n\n\noptimizr = torch.optim.Adam(net.parameters()) \n\n\nloss = loss_fn(net(x),y) \n# loss = loss_fn(yhat,y) \n# loss = -torch.mean((y)*torch.log(yhat)+(1-y)*torch.log(1-yhat))\nloss\n\ntensor(0.6403, grad_fn=&lt;BinaryCrossEntropyBackward0&gt;)\n\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'--b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nfor epoc in range(6000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'--b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n- 이건 epoc=6억번으로 설정해도 못 맞출 것 같다 (증가하다가 감소하는 underlying을 설계하는 것이 불가능) \\(\\to\\) 모형의 표현력이 너무 낮다.\n\n\n해결책\n- sigmoid 넣기 전의 상태가 꺽인 그래프 이어야 한다.\n\nsig = torch.nn.Sigmoid()\n\n\nfig,ax = plt.subplots(4,2,figsize=(8,8))\nu1 = torch.tensor([-6,-4,-2,0,2,4,6])\nu2 = torch.tensor([6,4,2,0,-2,-4,-6])\nu3 = torch.tensor([-6,-2,2,6,2,-2,-6])\nu4 = torch.tensor([-6,-2,2,6,4,2,0])\nax[0,0].plot(u1,'--o',color='C0');ax[0,1].plot(sig(u1),'--o',color='C0')\nax[1,0].plot(u2,'--o',color='C1');ax[1,1].plot(sig(u2),'--o',color='C1')\nax[2,0].plot(u3,'--o',color='C2');ax[2,1].plot(sig(u3),'--o',color='C2')\nax[3,0].plot(u4,'--o',color='C3');ax[3,1].plot(sig(u4),'--o',color='C3')"
  },
  {
    "objectID": "posts/ml/2022-10-05-ml-5w.html#깊은신경망dnn을-이용한-해결",
    "href": "posts/ml/2022-10-05-ml-5w.html#깊은신경망dnn을-이용한-해결",
    "title": "DNN (5주차)",
    "section": "깊은신경망–DNN을 이용한 해결",
    "text": "깊은신경망–DNN을 이용한 해결\n- 목표: 아래와 같은 벡터 \\({\\boldsymbol u}\\)를 만들어보자.\n\\({\\boldsymbol u} = [u_1,u_2,\\dots,u_{2000}], \\quad u_i = \\begin{cases} 9x_i +4.5& x_i &lt;0 \\\\ -4.5x_i + 4.5& x_i &gt;0 \\end{cases}\\)\n\n꺽인 그래프를 만드는 방법1\n\nu = [9*xi+4.5 if xi &lt;0 else -4.5*xi+4.5 for xi in x.reshape(-1).tolist()]\nplt.plot(u,'--')\n\n\n\n\n\n\n꺽인 그래프를 만드는 방법2\n- 전략: 선형변환 \\(\\to\\) ReLU \\(\\to\\) 선형변환\n(예비학습) ReLU 함수란?\n\\(ReLU(x) = \\max(0,x)\\)\n\nrelu=torch.nn.ReLU()\nplt.plot(x,'--r')\nplt.plot(relu(x),'--b')\n\n\n\n\n\n빨간색: x, 파란색: relu(x)\n\n예비학습끝\n우리 전략 다시 확인: 선형변환1 -&gt; 렐루 -&gt; 선형변환2\n(선형변환1)\n\nplt.plot(x);plt.plot(-x)\n\n\n\n\n(렐루)\n\nplt.plot(x,alpha=0.2);plt.plot(-x,alpha=0.5)\nplt.plot(relu(x),'--',color='C0');plt.plot(relu(-x),'--',color='C1')\n\n\n\n\n(선형변환2)\n\nplt.plot(x,alpha=0.2);plt.plot(-x,alpha=0.2)\nplt.plot(relu(x),'--',color='C0',alpha=0.2);plt.plot(relu(-x),'--',color='C1',alpha=0.2)\nplt.plot(-4.5*relu(x)-9.0*relu(-x)+4.5,'--',color='C2') \n\n\n\n\n이제 초록색선에 sig를 취하기만 하면?\n\nplt.plot(sig(-4.5*relu(x)-9.0*relu(-x)+4.5),'--',color='C2')\n\n\n\n\n정리하면!\n\nfig = plt.figure(figsize=(8, 4))\nspec = fig.add_gridspec(4, 4)\nax1 = fig.add_subplot(spec[:2,0]); ax1.set_title('x'); ax1.plot(x,'--',color='C0')\nax2 = fig.add_subplot(spec[2:,0]); ax2.set_title('-x'); ax2.plot(-x,'--',color='C1')\nax3 = fig.add_subplot(spec[:2,1]); ax3.set_title('relu(x)'); ax3.plot(relu(x),'--',color='C0')\nax4 = fig.add_subplot(spec[2:,1]); ax4.set_title('relu(-x)'); ax4.plot(relu(-x),'--',color='C1')\nax5 = fig.add_subplot(spec[1:3,2]); ax5.set_title('u'); ax5.plot(-4.5*relu(x)-9*relu(-x)+4.5,'--',color='C2')\nax6 = fig.add_subplot(spec[1:3,3]); ax6.set_title('yhat'); ax6.plot(sig(-4.5*relu(x)-9*relu(-x)+4.5),'--',color='C2')\nfig.tight_layout()\n\n\n\n\n\n이런느낌으로 \\(\\hat{\\boldsymbol y}\\)을 만들면 된다.\n\n\n\ntorch.nn.Linear()를 이용한 꺽인 그래프 구현\n\ntorch.manual_seed(43052)\nl1 = torch.nn.Linear(in_features=1,out_features=2,bias=True) \na1 = torch.nn.ReLU()\nl2 = torch.nn.Linear(in_features=2,out_features=1,bias=True) \na2 = torch.nn.Sigmoid() \n\n\nnet = torch.nn.Sequential(l1,a1,l2,a2) \n\n\nl1.weight,l1.bias,l2.weight,l2.bias\n\n(Parameter containing:\n tensor([[-0.3467],\n         [-0.8470]], requires_grad=True),\n Parameter containing:\n tensor([0.3604, 0.9336], requires_grad=True),\n Parameter containing:\n tensor([[ 0.2880, -0.6282]], requires_grad=True),\n Parameter containing:\n tensor([0.2304], requires_grad=True))\n\n\n\nl1.weight.data = torch.tensor([[1.0],[-1.0]])\nl1.bias.data = torch.tensor([0.0, 0.0])\nl2.weight.data = torch.tensor([[ -4.5, -9.0]])\nl2.bias.data= torch.tensor([4.5])\nl1.weight,l1.bias,l2.weight,l2.bias\n\n(Parameter containing:\n tensor([[ 1.],\n         [-1.]], requires_grad=True),\n Parameter containing:\n tensor([0., 0.], requires_grad=True),\n Parameter containing:\n tensor([[-4.5000, -9.0000]], requires_grad=True),\n Parameter containing:\n tensor([4.5000], requires_grad=True))\n\n\n\nplt.plot(l1(x).data)\n\n\n\n\n\nplt.plot(a1(l1(x)).data)\n\n\n\n\n\nplt.plot(l2(a1(l1(x))).data,color='C2')\n\n\n\n\n\nplt.plot(a2(l2(a1(l1(x)))).data,color='C2')\n#plt.plot(net(x).data,color='C2')\n\n\n\n\n- 수식표현\n\n\\({\\bf X}=\\begin{bmatrix} x_1 \\\\ \\dots \\\\ x_n \\end{bmatrix}\\)\n\\(l_1({\\bf X})={\\bf X}{\\bf W}^{(1)}\\overset{bc}{+} {\\boldsymbol b}^{(1)}=\\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\ x_n & -x_n\\end{bmatrix}\\)\n\n\\({\\bf W}^{(1)}=\\begin{bmatrix} 1 & -1 \\end{bmatrix}\\)\n\\({\\boldsymbol b}^{(1)}=\\begin{bmatrix} 0 & 0 \\end{bmatrix}\\)\n\n\\((a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big)=\\begin{bmatrix} \\text{relu}(x_1) & \\text{relu}(-x_1) \\\\ \\text{relu}(x_2) & \\text{relu}(-x_2) \\\\ \\dots & \\dots \\\\ \\text{relu}(x_n) & \\text{relu}(-x_n)\\end{bmatrix}\\)\n\\((l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\\\ =\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\\({\\bf W}^{(2)}=\\begin{bmatrix} -4.5 \\\\ -9 \\end{bmatrix}\\)\n\\(b^{(2)}=4.5\\)\n\n\\(net({\\bf X})=(a_2 \\circ l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{sig}\\Big(\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\Big)\\\\=\\begin{bmatrix} \\text{sig}\\Big(-4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5\\Big) \\\\ \\text{sig}\\Big(-4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\Big)\\\\ \\dots \\\\ \\text{sig}\\Big(-4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\Big)\\end{bmatrix}\\)\n\n- 차원만 따지자\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\nStep1 ~ Step4\n- 준비\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2), #u1=l1(x), x:(n,1) --&gt; u1:(n,2) \n    torch.nn.ReLU(), # v1=a1(u1), u1:(n,2) --&gt; v1:(n,2) \n    torch.nn.Linear(in_features=2,out_features=1), # u2=l2(v1), v1:(n,2) --&gt; u2:(n,1) \n    torch.nn.Sigmoid() # v2=a2(u2), u2:(n,1) --&gt; v2:(n,1) \n) \n\n\nloss_fn = torch.nn.BCELoss()\n\n\noptimizr = torch.optim.Adam(net.parameters()) # lr은 디폴트값으로..\n\n- 반복\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')\nplt.title(\"before\")\n\nText(0.5, 1.0, 'before')\n\n\n\n\n\n\nfor epoc in range(3000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y) \n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--',color='C1')\nplt.title(\"after 3000 epochs\")\n\nText(0.5, 1.0, 'after 3000 epochs')\n\n\n\n\n\n\nfor epoc in range(3000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y) \n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--',color='C1')\nplt.title(\"after 6000 epochs\")\n\nText(0.5, 1.0, 'after 6000 epochs')"
  },
  {
    "objectID": "posts/ml/2022-10-05-ml-5w.html#깊은신경망dnn으로-해결가능한-다양한-예제",
    "href": "posts/ml/2022-10-05-ml-5w.html#깊은신경망dnn으로-해결가능한-다양한-예제",
    "title": "DNN (5주차)",
    "section": "깊은신경망–DNN으로 해결가능한 다양한 예제",
    "text": "깊은신경망–DNN으로 해결가능한 다양한 예제\n\n예제1\n- 언뜻 생각하면 방금 배운 기술은 sig를 취하기 전이 꺽은선인 형태만 가능할 듯 하다. \\(\\to\\) 그래서 이 역시 표현력이 부족할 듯 하다. \\(\\to\\) 그런데 생각보다 표현력이 풍부한 편이다. 즉 생각보다 쓸 만하다.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex1.csv')\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\n\n\n\n\n\n이거 시그모이드 취하기 직전은 step이 포함된 듯 \\(\\to\\) 그래서 꺽은선으로는 표현할 수 없는 구조임 \\(\\to\\) 그런데 사실 대충은 표현가능\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=16), # x:(n,1) --&gt; u1:(n,16) \n    torch.nn.ReLU(), # u1:(n,16) --&gt; v1:(n,16)\n    torch.nn.Linear(in_features=16,out_features=1), # v1:(n,16) --&gt; u2:(n,1) \n    torch.nn.Sigmoid() # u2:(n,1) --&gt; v2:(n,1) \n)\n\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,16)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,16)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.BCELoss()\n\n\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(20000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()    \n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n예제2\n- 사실 꺽은선의 조합으로 꽤 많은걸 표현할 수 있거든요? \\(\\to\\) 심지어 곡선도 대충 맞게 적합된다.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex2.csv')\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\n\n\n\n\n\nx=torch.tensor(df.x).float().reshape(-1,1)\ny=torch.tensor(df.y).float().reshape(-1,1)\n\n(풀이1)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=32), # x:(n,1) --&gt; u1:(n,32)\n    torch.nn.ReLU(), # u1:(n,32) --&gt; v1:(n,32) \n    torch.nn.Linear(in_features=32,out_features=1) # v1:(n,32) --&gt; u2:(n,1)\n)\n\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.MSELoss() \n\n\noptimizr = torch.optim.Adam(net.parameters())\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nfor epoc in range(20000): \n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,lw=4)\n\n\n\n\n(풀이2) – 풀이1보다 좀 더 잘맞음. 잘 맞는 이유? 좋은초기값 (=운)\n\ntorch.manual_seed(5)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=32), # x:(n,1) --&gt; u1:(n,32)\n    torch.nn.ReLU(), # u1:(n,32) --&gt; v1:(n,32) \n    torch.nn.Linear(in_features=32,out_features=1) # v1:(n,32) --&gt; u2:(n,1)\n)\n\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.MSELoss() \n\n\noptimizr = torch.optim.Adam(net.parameters())\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nfor epoc in range(6000): \n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,lw=4)\n\n\n\n\n\n풀이1에서 에폭을 많이 반복하면 풀이2의 적합선이 나올까? –&gt; 안나옴!! (local min에 빠졌다)\n\n\n\n예제3\n\nimport seaborn as sns\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex3.csv')\ndf\n\n\n\n\n\n\n\n\nx1\nx2\ny\n\n\n\n\n0\n-0.874139\n0.210035\n0.0\n\n\n1\n-1.143622\n-0.835728\n1.0\n\n\n2\n-0.383906\n-0.027954\n0.0\n\n\n3\n2.131652\n0.748879\n1.0\n\n\n4\n2.411805\n0.925588\n1.0\n\n\n...\n...\n...\n...\n\n\n1995\n-0.002797\n-0.040410\n0.0\n\n\n1996\n-1.003506\n1.182736\n0.0\n\n\n1997\n1.388121\n0.079317\n0.0\n\n\n1998\n0.080463\n0.816024\n1.0\n\n\n1999\n-0.416859\n0.067907\n0.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nsns.scatterplot(data=df,x='x1',y='x2',hue='y',alpha=0.5,palette={0:(0.5, 0.0, 1.0),1:(1.0,0.0,0.0)})\n\n&lt;AxesSubplot:xlabel='x1', ylabel='x2'&gt;\n\n\n\n\n\n\nx1 = torch.tensor(df.x1).float().reshape(-1,1) \nx2 = torch.tensor(df.x2).float().reshape(-1,1) \nX = torch.concat([x1,x2],axis=1) \ny = torch.tensor(df.y).float().reshape(-1,1) \n\n\nX.shape\n\ntorch.Size([2000, 2])\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=2,out_features=32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid()\n)\n\n\n\\(\\underset{(n,2)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.BCELoss() \n\n\noptimizr = torch.optim.Adam(net.parameters()) \n\n\nfor epoc in range(3000):\n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\ndf2 = df.assign(yhat=yhat.reshape(-1).detach().tolist())\ndf2\n\n\n\n\n\n\n\n\nx1\nx2\ny\nyhat\n\n\n\n\n0\n-0.874139\n0.210035\n0.0\n0.342171\n\n\n1\n-1.143622\n-0.835728\n1.0\n0.599576\n\n\n2\n-0.383906\n-0.027954\n0.0\n0.106441\n\n\n3\n2.131652\n0.748879\n1.0\n0.916042\n\n\n4\n2.411805\n0.925588\n1.0\n0.910025\n\n\n...\n...\n...\n...\n...\n\n\n1995\n-0.002797\n-0.040410\n0.0\n0.253134\n\n\n1996\n-1.003506\n1.182736\n0.0\n0.480342\n\n\n1997\n1.388121\n0.079317\n0.0\n0.397069\n\n\n1998\n0.080463\n0.816024\n1.0\n0.268198\n\n\n1999\n-0.416859\n0.067907\n0.0\n0.102882\n\n\n\n\n2000 rows × 4 columns\n\n\n\n\nsns.scatterplot(data=df2,x='x1',y='x2',hue='yhat',alpha=0.5,palette='rainbow')\n\n&lt;AxesSubplot:xlabel='x1', ylabel='x2'&gt;\n\n\n\n\n\n- 결과시각화\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nsns.scatterplot(data=df,x='x1',y='x2',hue='y',alpha=0.5,palette={0:(0.5, 0.0, 1.0),1:(1.0,0.0,0.0)},ax=ax[0])\nsns.scatterplot(data=df2,x='x1',y='x2',hue='yhat',alpha=0.5,palette='rainbow',ax=ax[1])\n\n&lt;AxesSubplot:xlabel='x1', ylabel='x2'&gt;\n\n\n\n\n\n- 교훈: underlying이 엄청 이상해보여도 생각보다 잘 맞춤"
  },
  {
    "objectID": "posts/ml/2022-09-29-ml_4w.html",
    "href": "posts/ml/2022-09-29-ml_4w.html",
    "title": "DNN (4주차)",
    "section": "",
    "text": "기계학습 특강 (4주차) 9월28일 [회귀분석(2)–step1~4, step1의 다른표현, step4의 다른표현, 로지스틱 intro]"
  },
  {
    "objectID": "posts/ml/2022-09-29-ml_4w.html#imports",
    "href": "posts/ml/2022-09-29-ml_4w.html#imports",
    "title": "DNN (4주차)",
    "section": "imports",
    "text": "imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport pandas as pd\nimport torch"
  },
  {
    "objectID": "posts/ml/2022-09-29-ml_4w.html#numpy-torch-선택학습",
    "href": "posts/ml/2022-09-29-ml_4w.html#numpy-torch-선택학습",
    "title": "DNN (4주차)",
    "section": "numpy, torch (선택학습)",
    "text": "numpy, torch (선택학습)\n\nnumpy, torch는 엄청 비슷해요\n- torch.tensor() = np.array() 처럼 생각해도 무방\n\nnp.array([1,2,3]), torch.tensor([1,2,3])\n\n(array([1, 2, 3]), tensor([1, 2, 3]))\n\n\n- 소수점의 정밀도에서 차이가 있음 (torch가 좀 더 쪼잔함)\n\nnp.array([3.123456789])\n\narray([3.12345679])\n\n\n\ntorch.tensor([3.123456789])\n\ntensor([3.1235])\n\n\n(서연필기)tensor는 gpu에 저장하기 때문에 메모리 아끼기 위해 정밀도가 낮은 경향이 있다.\n- 기본적인 numpy 문법은 np 대신에 torch를 써도 무방 // 완전 같지는 않음\n\nnp.arange(10), torch.arange(10)\n\n(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n\n\n\nnp.linspace(0,1,10), torch.linspace(0,1,10)\n\n(array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n        0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]),\n tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n         1.0000]))\n\n\n\nnp.random.randn(10)\n\narray([-0.90388568,  0.51779102,  0.73699131, -0.88030899,  1.71668715,\n       -0.70735651, -0.29752154,  1.10432159,  0.23592126,  0.91669421])\n\n\n\ntorch.randn(10)\n\ntensor([ 0.6896,  1.8534, -0.3807,  1.3676,  0.0515,  0.4350,  0.6051, -1.5075,\n         0.1474,  0.3098])\n\n\n\n\nlength \\(n\\) vector, \\(n \\times 1\\) col-vector, \\(1 \\times n\\) row-vector\n브로드캐스팅 길이가 3인 벡터와 1인벡터를 더하면 오류 뜨지 않고 더해줌\n- 길이가 3인 벡터 선언방법\n\na = torch.tensor([1,2,3])\na.shape\n\ntorch.Size([3])\n\n\n- 3x1 col-vec 선언방법\n(방법1)\n\na = torch.tensor([[1],[2],[3]])\na.shape\n\ntorch.Size([3, 1])\n\n\n(방법2)\n\na = torch.tensor([1,2,3]).reshape(3,1)\na.shape\n\ntorch.Size([3, 1])\n\n\n- 1x3 row-vec 선언방법\n(방법1)\n\na = torch.tensor([[1,2,3]])\na.shape\n\ntorch.Size([1, 3])\n\n\n(방법2)\n\na = torch.tensor([1,2,3]).reshape(1,3)\na.shape\n\ntorch.Size([1, 3])\n\n\n- 3x1 col-vec 선언방법, 1x3 row-vec 선언방법에서 [[1],[2],[3]] 혹은 [[1,2,3]] 와 같은 표현이 이해안되면 아래링크로 가셔서\nhttps://guebin.github.io/STBDA2022/2022/03/14/(2주차)-3월14일.html\n첫번째 동영상 12:15 - 22:45 에 해당하는 분량을 학습하시길 바랍니다.\n\n\ntorch의 dtype\n- 기본적으로 torch는 소수점으로 저장되면 dtype=torch.float32 가 된다. (이걸로 맞추는게 편리함)\n\ntsr = torch.tensor([1.23,2.34])\ntsr\n\ntensor([1.2300, 2.3400])\n\n\n\ntsr.dtype\n\ntorch.float32\n\n\n- 정수로 선언하더라도 dtype를 torch.float32로 바꾸는게 유리함\n(안 좋은 선언예시)\n\ntsr = torch.tensor([1,2])\ntsr \n\ntensor([1, 2])\n\n\n\ntsr.dtype\n\ntorch.int64\n\n\n(좋은 선언예시1)\n\ntsr = torch.tensor([1,2],dtype=torch.float32)\ntsr \n\ntensor([1., 2.])\n\n\n\ntsr.dtype\n\ntorch.float32\n\n\n(좋은 선언예시2)\n\ntsr = torch.tensor([1,2.0])\ntsr \n\ntensor([1., 2.])\n\n\n\ntsr.dtype\n\ntorch.float32\n\n\n(사실 int로 선언해도 나중에 float으로 바꾸면 큰 문제없음)\n\ntsr = torch.tensor([1,2]).float()\ntsr\n\ntensor([1., 2.])\n\n\n\ntsr.dtype\n\ntorch.float32\n\n\n- 왜 정수만으로 torch.tensor를 만들때에도 torch.float32로 바꾸는게 유리할까? \\(\\to\\) torch.tensor끼리의 연산에서 문제가 될 수 있음\n별 문제 없을수도 있지만\n\ntorch.tensor([1,2])-torch.tensor([1.0,2.0]) \n\ntensor([0., 0.])\n\n\n아래와 같이 에러가 날수도 있다\n(에러1)\n\ntorch.tensor([[1.0,0.0],[0.0,1.0]]) @ torch.tensor([[1],[2]]) \n\nRuntimeError: expected scalar type Float but found Long\n\n\n(에러2)\n\ntorch.tensor([[1,0],[0,1]]) @ torch.tensor([[1.0],[2.0]])\n\nRuntimeError: expected scalar type Long but found Float\n\n\n(해결1) 둘다 정수로 통일\n\ntorch.tensor([[1,0],[0,1]]) @ torch.tensor([[1],[2]])\n\ntensor([[1],\n        [2]])\n\n\n(해결2) 둘다 소수로 통일 &lt;– 더 좋은 방법임\n\ntorch.tensor([[1.0,0.0],[0.0,1.0]]) @ torch.tensor([[1.0],[2.0]])\n\ntensor([[1.],\n        [2.]])\n\n\n\n\nshape of vector\n- 행렬곱셈에 대한 shape 조심\n\nA = torch.tensor([[2.00,0.00],[0.00,3.00]]) \nb1 = torch.tensor([[-1.0,-5.0]])\nb2 = torch.tensor([[-1.0],[-5.0]])\nb3 = torch.tensor([-1.0,-5.0])\n\n\nA.shape,b1.shape,b2.shape,b3.shape\n\n(torch.Size([2, 2]), torch.Size([1, 2]), torch.Size([2, 1]), torch.Size([2]))\n\n\n- A@b1: 계산불가, b1@A: 계산가능\n\nA@b1\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (2x2 and 1x2)\n\n\n\nb1@A\n\ntensor([[ -2., -15.]])\n\n\n- A@b2: 계산가능, b2@A: 계산불가\n\nA@b2\n\ntensor([[ -2.],\n        [-15.]])\n\n\n\nb2@A\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (2x1 and 2x2)\n\n\n- A@b3: 계산가능, b3@A: 계산가능\n\n(A@b3).shape ## b3를 마치 col-vec 처럼 해석\n\ntorch.Size([2])\n\n\n\n(b3@A).shape ## b3를 마지 row-vec 처럼 해석\n\ntorch.Size([2])\n\n\n\n뒤에 놓으면 b3를 컬럼벡터로 인식\n앞에 놓으면 b3를 로우벡터로 인식\n\n- 브로드캐스팅\n\na = torch.tensor([1,2,3])\na - 1\n\ntensor([0, 1, 2])\n\n\n\nb = torch.tensor([[1],[2],[3]])\nb - 1\n\ntensor([[0],\n        [1],\n        [2]])\n\n\n계산이 되지 않아야 맞지 않나\n\na - b # a를 row-vec 로 해석\n\ntensor([[ 0,  1,  2],\n        [-1,  0,  1],\n        [-2, -1,  0]])\n\n\n잘못 계싼할 수 있으니 dimension 명시해주자"
  },
  {
    "objectID": "posts/ml/2022-09-29-ml_4w.html#review-step14",
    "href": "posts/ml/2022-09-29-ml_4w.html#review-step14",
    "title": "DNN (4주차)",
    "section": "Review: step1~4",
    "text": "Review: step1~4\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-22-regression.csv\") \ndf\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n-2.482113\n-8.542024\n\n\n1\n-2.362146\n-6.576713\n\n\n2\n-1.997295\n-5.949576\n\n\n3\n-1.623936\n-4.479364\n\n\n4\n-1.479192\n-4.251570\n\n\n...\n...\n...\n\n\n95\n2.244400\n10.325987\n\n\n96\n2.393501\n12.266493\n\n\n97\n2.605604\n13.098280\n\n\n98\n2.605658\n12.546793\n\n\n99\n2.663240\n13.834002\n\n\n\n\n100 rows × 2 columns\n\n\n\n\nplt.plot(df.x, df.y,'o')\n\n\n\n\n\ntorch.tensor(df.x)\n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632], dtype=torch.float64)\n\n\n(서연필기)\nfloat64 숫자 정밀 저장\nfloat32이면 dtype=torch.float64)꼬리표가 붙지 않음\n_trt = torch.tensor(df.x).float()\n_trt = torch.tensor(df.x,dtype=float30)\n같은 역할, 메모리 적게 쓰기 위해 타입 바꿔주자\nx= torch.tensor(df.x,dtype=torch.float32).reshape(100,1)\n컬럼형식으로 받아주기 위해 변경\n\nx= torch.tensor(df.x,dtype=torch.float32).reshape(100,1)\ny= torch.tensor(df.y,dtype=torch.float32).reshape(100,1)\n_1= torch.ones([100,1])\nX = torch.concat([_1,x],axis=1)\n\ntorch.ones([100,1])\ntorch.tensor([[1]*100,x]).T\n같은 셋\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\nrequires_grad=True \nreshape 미분 가능 옵션 주기 전에 shape 정해주자\n\nplt.plot(x,y,'o')\n#plt.plot(x,-5+10*x,'--')\nplt.plot(x,X@What.data,'--')\n\n\n\n\n\nver1: loss = sum of squares error\n\nalpha = 1/1000\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nfor epoc in range(30): \n    # step1: yhat \n    yhat = X@What \n    # step2: loss \n    loss = torch.sum((y-yhat)**2)\n    # step3: 미분 \n    loss.backward()\n    # step4: update \n    What.data = What.data - alpha * What.grad \n    What.grad = None # \n\n\nWhat\n\ntensor([[2.4290],\n        [4.0144]], requires_grad=True)\n\n\n\nplt.plot(x,y,'o') \nplt.plot(x,X@What.data,'--')\n\n\n\n\n\nnote: 왜 What = What - alpha*What.grad 는 안되는지?\n\n\nWhat\n\ntensor([[2.4290],\n        [4.0144]], requires_grad=True)\n\n\n\nWhat.data\n\ntensor([[2.4290],\n        [4.0144]])\n\n\nWhat과 What.data는 달라요, requires_grad=True 미분 가능 꼬리표가 붙지 않기 때문!\n\n\nver2: loss = mean squared error = MSE\n\nalpha = 1/10\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nfor epoc in range(30): \n    # step1: yhat \n    yhat = X@What \n    # step2: loss \n    loss = torch.mean((y-yhat)**2)\n    # step3: 미분 \n    loss.backward()\n    # step4: update \n    What.data = What.data - alpha * What.grad \n    What.grad = None # \n\n\nWhat\n\ntensor([[2.4290],\n        [4.0144]], requires_grad=True)\n\n\n(서연필기)mean 정의 - 데이터를 더 효율적으로 학습 가능, 데이터 수만큼 안 해도 돼, 계산 덜 해도 돼"
  },
  {
    "objectID": "posts/ml/2022-09-29-ml_4w.html#step1의-다른버전-net-설계만",
    "href": "posts/ml/2022-09-29-ml_4w.html#step1의-다른버전-net-설계만",
    "title": "DNN (4주차)",
    "section": "step1의 다른버전 – net 설계만",
    "text": "step1의 다른버전 – net 설계만\n\nver1: net = torch.nn.Linear(1,1,bias=True)\n\ntorch.nn.Linear?\n\n\nInit signature:\ntorch.nn.Linear(\n    in_features: int,\n    out_features: int,\n    bias: bool = True,\n    device=None,\n    dtype=None,\n) -&gt; None\nDocstring:     \nApplies a linear transformation to the incoming data: :math:`y = xA^T + b`\nThis module supports :ref:`TensorFloat32&lt;tf32_on_ampere&gt;`.\nArgs:\n    in_features: size of each input sample\n    out_features: size of each output sample\n    bias: If set to ``False``, the layer will not learn an additive bias.\n        Default: ``True``\nShape:\n    - Input: :math:`(*, H_{in})` where :math:`*` means any number of\n      dimensions including none and :math:`H_{in} = \\text{in\\_features}`.\n    - Output: :math:`(*, H_{out})` where all but the last dimension\n      are the same shape as the input and :math:`H_{out} = \\text{out\\_features}`.\nAttributes:\n    weight: the learnable weights of the module of shape\n        :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n        initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n        :math:`k = \\frac{1}{\\text{in\\_features}}`\n    bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n            If :attr:`bias` is ``True``, the values are initialized from\n            :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n            :math:`k = \\frac{1}{\\text{in\\_features}}`\nExamples::\n    &gt;&gt;&gt; m = nn.Linear(20, 30)\n    &gt;&gt;&gt; input = torch.randn(128, 20)\n    &gt;&gt;&gt; output = m(input)\n    &gt;&gt;&gt; print(output.size())\n    torch.Size([128, 30])\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/csy/lib/python3.8/site-packages/torch/nn/modules/linear.py\nType:           type\nSubclasses:     NonDynamicallyQuantizableLinear, LazyLinear, Linear, Linear\n\n\n\n\ninput 잡는 법 - x의 컬럼 부분을 input이라고 생각하자\n\nx.shape\n\ntorch.Size([100, 1])\n\n\noutput 잡는 법 - y의 컬럼 부분을 output이라고 생각하자\n\ny.shape\n\ntorch.Size([100, 1])\n\n\n\n_net =  torch.nn.Linear(in_features=1, out_features=1, bias=True) \n\n\n_net(x).shape\n\ntorch.Size([100, 1])\n\n\n\n_net.bias # w0\n\nParameter containing:\ntensor([-0.1281], requires_grad=True)\n\n\n\n_net.weight # w1\n\nParameter containing:\ntensor([[0.1433]], requires_grad=True)\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=1, out_features=1, bias=True) \n\n\nnet.bias, net.weight\n\n(Parameter containing:\n tensor([-0.8470], requires_grad=True),\n Parameter containing:\n tensor([[-0.3467]], requires_grad=True))\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\nw0hat = -0.847\nw1hat = -0.3467\nplt.plot(x,w0hat+w1hat*x,'--')\n\n\n\n\n출력결과 같음을 확인\n- net에서 \\(\\hat{w}_0, \\hat{w}_1\\) 의 값은?\n\nnet.weight # w1 \n\nParameter containing:\ntensor([[-0.3467]], requires_grad=True)\n\n\n\nnet.bias # w0 \n\nParameter containing:\ntensor([-0.8470], requires_grad=True)\n\n\n\n_yhat = -0.8470 + -0.3467*x \n\n\nplt.plot(x,y,'o')\nplt.plot(x, _yhat,'--')\nplt.plot(x,net(x).data,'-.')\n\n\n\n\n- 수식표현: \\(\\hat{y}_i = \\hat{w}_0 + \\hat{w}_1 x_i = \\hat{b} + \\hat{w}x_i = -0.8470 + -0.3467 x_i\\) for all \\(i=1,2,\\dots,100\\).\n\n\nver2: net = torch.nn.Linear(2,1,bias=False)\n- 입력이 x가 아닌 X를 넣고 싶다면? (보통 잘 안하긴 해요, 왜? bias=False로 주는게 귀찮거든요) - X는 바이어스가 고려된 상황\n\nnet(X) ## 그대로 쓰면 당연히 에러\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (100x2 and 1x1)\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=2, out_features=1, bias=False) \n\n\nnet(X).shape\n\ntorch.Size([100, 1])\n\n\n\nnet.weight\n\nParameter containing:\ntensor([[-0.2451, -0.5989]], requires_grad=True)\n\n\n위에 \\(w_0,w_1\\) 순\n\nnet.bias\n\nbias 없음을 확인\n\nplt.plot(x,y,'o') \nplt.plot(x,net(X).data, '--')\nplt.plot(x,X@torch.tensor([[-0.2451],[-0.5989]]), '-.')\n\n\n\n\n- 수식표현: \\(\\hat{\\bf y} = {\\bf X} {\\bf \\hat W} = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots & \\dots \\\\ 1 & x_{100} \\end{bmatrix} \\begin{bmatrix} -0.2451 \\\\ -0.5989 \\end{bmatrix}\\)\n\n\n잘못된사용1\n\n_x = x.reshape(-1)\n\n\n_x\n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632])\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=1,out_features=1) \n\n\nnet(_x)\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (1x100 and 1x1)\n\n\nnet(_x.reshape(100,1))\n과 같이 정의\n\n\n잘못된사용2\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=2,out_features=1) # bias=False를 깜빡..\n\n\nnet.weight\n\nParameter containing:\ntensor([[-0.2451, -0.5989]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([0.2549], requires_grad=True)\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\nplt.plot(x,X@torch.tensor([[-0.2451],[-0.5989]])+0.2549,'-.')\n\n\n\n\n\n수식표현: \\(\\hat{\\bf y} = {\\bf X} {\\bf \\hat W} + \\hat{b}= \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots & \\dots \\\\ 1 & x_{100} \\end{bmatrix} \\begin{bmatrix} -0.2451 \\\\ -0.5989 \\end{bmatrix} + 0.2549\\)"
  },
  {
    "objectID": "posts/ml/2022-09-29-ml_4w.html#step1의-다른버전-끝까지",
    "href": "posts/ml/2022-09-29-ml_4w.html#step1의-다른버전-끝까지",
    "title": "DNN (4주차)",
    "section": "step1의 다른버전 – 끝까지",
    "text": "step1의 다른버전 – 끝까지\n\nver1: net = torch.nn.Linear(1,1,bias=True)\n- 준비\n\nnet = torch.nn.Linear(1,1,bias=True)\nnet.weight.data = torch.tensor([[10.0]])\nnet.bias.data = torch.tensor([-5.0])\nnet.weight,net.bias\n\n(Parameter containing:\n tensor([[10.]], requires_grad=True),\n Parameter containing:\n tensor([-5.], requires_grad=True))\n\n\n- step1\n\nyhat = net(x) \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\nplt.plot(x,-5+10*x,'--')\n\n\n\n\n- step2\n\nloss = torch.mean((y-yhat)**2)\n\n- step3\n(미분전)\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([-5.], requires_grad=True),\n Parameter containing:\n tensor([[10.]], requires_grad=True))\n\n\n\nnet.bias.grad, net.weight.grad\n\n(None, None)\n\n\n(미분)\n\nloss.backward()\n\n(미분후)\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([-5.], requires_grad=True),\n Parameter containing:\n tensor([[10.]], requires_grad=True))\n\n\n\nnet.bias.grad,net.weight.grad\n\n(tensor([-13.4225]), tensor([[11.8893]]))\n\n\n- step4\n(업데이트전)\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([-5.], requires_grad=True),\n Parameter containing:\n tensor([[10.]], requires_grad=True))\n\n\n\nnet.bias.grad, net.weight.grad\n\n(tensor([-13.4225]), tensor([[11.8893]]))\n\n\n(업데이트)\n\nnet.bias.data = net.bias.data - 0.1*net.bias.grad \nnet.weight.data = net.weight.data - 0.1*net.weight.grad \n\n\nnet.bias.grad = None \nnet.weight.grad = None \n\n(업데이트후)\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([-3.6577], requires_grad=True),\n Parameter containing:\n tensor([[8.8111]], requires_grad=True))\n\n\n\nnet.bias.grad, net.weight.grad\n\n(None, None)\n\n\n- 반복\n\nnet = torch.nn.Linear(1,1)\nnet.weight.data = torch.tensor([[10.0]])\nnet.bias.data = torch.tensor([-5.0])\n\n\nfor epoc in range(30):\n    yhat = net(x) \n    loss = torch.mean((y-yhat)**2)\n    loss.backward()\n    net.weight.data = net.weight.data - 0.1*net.weight.grad\n    net.bias.data = net.bias.data - 0.1*net.bias.grad\n    net.weight.grad = None\n    net.bias.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\nver2: net = torch.nn.Linear(2,1,bias=False)\n- 준비\n\nnet = torch.nn.Linear(2,1,bias=False)\nnet.weight.data = torch.tensor([[-5.0, 10.0]])\n\n- step1\n\nyhat = net(X)\n\n- step2\n\nloss = torch.mean((y-yhat)**2)\n\n- step3\n(미분전)\n\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet.weight.grad\n\n(미분)\n\nloss.backward()\n\n(미분후)\n\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet.weight.grad\n\ntensor([[-13.4225,  11.8893]])\n\n\n- step4\n(업데이트전)\n\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet.weight.grad\n\ntensor([[-13.4225,  11.8893]])\n\n\n(업데이트)\n\nnet.weight.data = net.weight.data - 0.1*net.weight.grad\n\n\nnet.weight.grad = None\n\n(업데이트후)\n\nnet.weight\n\nParameter containing:\ntensor([[-3.6577,  8.8111]], requires_grad=True)\n\n\n\nnet.weight.grad\n\n- 반복\n\nnet = torch.nn.Linear(2,1,bias=False)\nnet.weight.data = torch.tensor([[-5.0, 10.0]])\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\n\n\n\n\n\nfor epoc in range(30):\n    yhat = net(X) \n    loss = torch.mean((y-yhat)**2)\n    loss.backward()\n    net.weight.data = net.weight.data - 0.1*net.weight.grad\n    net.weight.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')"
  },
  {
    "objectID": "posts/ml/2022-09-29-ml_4w.html#step4의-다른버전-옵티마이저",
    "href": "posts/ml/2022-09-29-ml_4w.html#step4의-다른버전-옵티마이저",
    "title": "DNN (4주차)",
    "section": "step4의 다른버전: 옵티마이저!",
    "text": "step4의 다른버전: 옵티마이저!\n\nver1: net = torch.nn.Linear(1,1,bias=True)\n- 준비\n\nnet = torch.nn.Linear(1,1) \nnet.weight.data = torch.tensor([[10.0]]) \nnet.bias.data = torch.tensor([[-5.0]]) \n\n\ntorch.optim.SGD?\n\n\nInit signature:\ntorch.optim.SGD(\n    params,\n    lr=&lt;required parameter&gt;,\n    momentum=0,\n    dampening=0,\n    weight_decay=0,\n    nesterov=False,\n)\nDocstring:     \nImplements stochastic gradient descent (optionally with momentum).\n.. math::\n   \\begin{aligned}\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{input}      : \\gamma \\text{ (lr)}, \\: \\theta_0 \\text{ (params)}, \\: f(\\theta)\n            \\text{ (objective)}, \\: \\lambda \\text{ (weight decay)},                          \\\\\n        &\\hspace{13mm} \\:\\mu \\text{ (momentum)}, \\:\\tau \\text{ (dampening)},\\:nesterov\\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n        &\\hspace{5mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\n        &\\hspace{5mm}\\textbf{if} \\: \\lambda \\neq 0                                           \\\\\n        &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda  \\theta_{t-1}                            \\\\\n        &\\hspace{5mm}\\textbf{if} \\: \\mu \\neq 0                                               \\\\\n        &\\hspace{10mm}\\textbf{if} \\: t &gt; 1                                                   \\\\\n        &\\hspace{15mm} \\textbf{b}_t \\leftarrow \\mu \\textbf{b}_{t-1} + (1-\\tau) g_t           \\\\\n        &\\hspace{10mm}\\textbf{else}                                                          \\\\\n        &\\hspace{15mm} \\textbf{b}_t \\leftarrow g_t                                           \\\\\n        &\\hspace{10mm}\\textbf{if} \\: nesterov                                                \\\\\n        &\\hspace{15mm} g_t \\leftarrow g_{t-1} + \\mu \\textbf{b}_t                             \\\\\n        &\\hspace{10mm}\\textbf{else}                                                   \\\\[-1.ex]\n        &\\hspace{15mm} g_t  \\leftarrow  \\textbf{b}_t                                         \\\\\n        &\\hspace{5mm}\\theta_t \\leftarrow \\theta_{t-1} - \\gamma g_t                    \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n        &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n   \\end{aligned}\nNesterov momentum is based on the formula from\n`On the importance of initialization and momentum in deep learning`__.\nArgs:\n    params (iterable): iterable of parameters to optimize or dicts defining\n        parameter groups\n    lr (float): learning rate\n    momentum (float, optional): momentum factor (default: 0)\n    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n    dampening (float, optional): dampening for momentum (default: 0)\n    nesterov (bool, optional): enables Nesterov momentum (default: False)\nExample:\n    &gt;&gt;&gt; optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n    &gt;&gt;&gt; optimizer.zero_grad()\n    &gt;&gt;&gt; loss_fn(model(input), target).backward()\n    &gt;&gt;&gt; optimizer.step()\n__ http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf\n.. note::\n    The implementation of SGD with Momentum/Nesterov subtly differs from\n    Sutskever et. al. and implementations in some other frameworks.\n    Considering the specific case of Momentum, the update can be written as\n    .. math::\n        \\begin{aligned}\n            v_{t+1} & = \\mu * v_{t} + g_{t+1}, \\\\\n            p_{t+1} & = p_{t} - \\text{lr} * v_{t+1},\n        \\end{aligned}\n    where :math:`p`, :math:`g`, :math:`v` and :math:`\\mu` denote the\n    parameters, gradient, velocity, and momentum respectively.\n    This is in contrast to Sutskever et. al. and\n    other frameworks which employ an update of the form\n    .. math::\n        \\begin{aligned}\n            v_{t+1} & = \\mu * v_{t} + \\text{lr} * g_{t+1}, \\\\\n            p_{t+1} & = p_{t} - v_{t+1}.\n        \\end{aligned}\n    The Nesterov version is analogously modified.\nFile:           ~/anaconda3/envs/csy/lib/python3.8/site-packages/torch/optim/sgd.py\nType:           type\nSubclasses:     \n\n\n\n\nStocastic Gradiant Decscent\n\nnet.parameters()\n\n&lt;generator object Module.parameters at 0x7f5f0d522740&gt;\n\n\n\noptimizr = torch.optim.SGD(net.parameters(),lr=1/10) \n\n- step1~3\n\nyhat = net(x)     \n\n\nloss = torch.mean((y-yhat)**2) \n\n\nloss.backward() \n\n- step4\n(update 전)\n\nnet.weight.data, net.bias.data ## 값은 업데이트 전\n\n(tensor([[10.]]), tensor([[-5.]]))\n\n\n\nnet.weight.grad, net.bias.grad ## 미분값은 청소전 \n\n(tensor([[11.8893]]), tensor([[-13.4225]]))\n\n\n(update)\n\noptimizr.step() \noptimizr.zero_grad() \n\n(update 후)\n\nnet.weight.data, net.bias.data ## 값은 업데이트 되었음 \n\n(tensor([[8.8111]]), tensor([[-3.6577]]))\n\n\n\nnet.weight.grad, net.bias.grad ## 미분값은 0으로 초기화하였음 \n\n(tensor([[0.]]), tensor([[0.]]))\n\n\n- 반복\n\nnet = torch.nn.Linear(1,1) \nnet.weight.data = torch.tensor([[10.0]])\nnet.bias.data = torch.tensor([-5.0])\noptimizr = torch.optim.SGD(net.parameters(),lr=1/10) \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nfor epoc in range(30): \n    yhat = net(x)\n    loss = torch.mean((y-yhat)**2) \n    loss.backward() \n    optimizr.step(); optimizr.zero_grad() \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\nver2: net = torch.nn.Linear(2,1,bias=False)\n- 바로 반복하겠습니다..\n\nnet = torch.nn.Linear(2,1,bias=False) \nnet.weight.data = torch.tensor([[-5.0, 10.0]])\noptimizr = torch.optim.SGD(net.parameters(),lr=1/10) \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\n\n\n\n\n\nfor epoc in range(30): \n    yhat = net(X)\n    loss = torch.mean((y-yhat)**2) \n    loss.backward() \n    optimizr.step(); optimizr.zero_grad() \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')"
  },
  {
    "objectID": "posts/ml/2022-09-29-ml_4w.html#appendix-net.parameters의-의미-선택학습",
    "href": "posts/ml/2022-09-29-ml_4w.html#appendix-net.parameters의-의미-선택학습",
    "title": "DNN (4주차)",
    "section": "Appendix: net.parameters()의 의미? (선택학습)",
    "text": "Appendix: net.parameters()의 의미? (선택학습)\n- iterator, generator의 개념필요 - https://guebin.github.io/IP2022/2022/06/06/(14주차)-6월6일.html, 클래스공부 8단계 참고\n- 탐구시작: 네트워크 생성\n\nnet = torch.nn.Linear(in_features=1,out_features=1)\nnet.weight\n\nParameter containing:\ntensor([[-0.4277]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([-0.0629], requires_grad=True)\n\n\n- torch.optim.SGD? 를 확인하면 params에 대한설명에 아래와 같이 되어있음\nparams (iterable): iterable of parameters to optimize or dicts defining\n        parameter groups\n- 설명을 읽어보면 params에 iterable object를 넣으라고 되어있음 (iterable object는 숨겨진 명령어로 __iter__를 가지고 있는 오브젝트를 의미)\n\nset(dir(net.parameters)) & {'__iter__'}\n\nset()\n\n\n\nset(dir(net.parameters())) & {'__iter__'}\n\n{'__iter__'}\n\n\n- 무슨의미?\n\n_generator = net.parameters()\n\n\n_generator.__next__()\n\nParameter containing:\ntensor([[-0.4277]], requires_grad=True)\n\n\n\n_generator.__next__()\n\nParameter containing:\ntensor([-0.0629], requires_grad=True)\n\n\n\n_generator.__next__()\n\nStopIteration: \n\n\n- 이건 이런느낌인데?\n\n_generator2 = iter([net.weight,net.bias])\n\n\n_generator2\n\n&lt;list_iterator at 0x7f5f0d2cdeb0&gt;\n\n\n\n_generator2.__next__()\n\nParameter containing:\ntensor([[-0.4277]], requires_grad=True)\n\n\n\n_generator2.__next__()\n\nParameter containing:\ntensor([-0.0629], requires_grad=True)\n\n\n\n_generator2.__next__()\n\nStopIteration: \n\n\n- 즉 아래는 같은코드이다.\n### 코드1\n_generator = net.parameters() \ntorch.optim.SGD(_generator,lr=1/10) \n### 코드2\n_generator = iter([net.weight,net.bias])\ntorch.optim.SGD(_generator,lr=1/10) \n### 코드3 (이렇게 써도 코드2가 실행된다고 이해할 수 있음)\n_iterator = [net.weight,net.bias]\ntorch.optim.SGD(_iterator,lr=1/10) \n결론: net.parameters()는 net오브젝트에서 학습할 파라메터를 모두 모아 리스트(iterable object)로 만드는 함수라 이해할 수 있다.\n- 응용예제1\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\noptimizr = torch.optim.SGD([What],lr=1/10) \n\n\nplt.plot(x,y,'o')\nplt.plot(x,(X@What).data,'--')\n\n\n\n\n\nfor epoc in range(30):\n    yhat = X@What \n    loss = torch.mean((y-yhat)**2)\n    loss.backward()\n    optimizr.step();optimizr.zero_grad() \n\n\nplt.plot(x,y,'o')\nplt.plot(x,(X@What).data,'--')\n\n\n\n\n- 응용예제2\n\nb = torch.tensor(-5.0,requires_grad=True)\nw = torch.tensor(10.0,requires_grad=True)\noptimizr = torch.optim.SGD([b,w],lr=1/10)\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(w*x+b).data,'--')\n\n\n\n\n\nfor epoc in range(30):\n    yhat = b+ w*x \n    loss = torch.mean((y-yhat)**2)\n    loss.backward()\n    optimizr.step(); optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(w*x+b).data,'--')"
  },
  {
    "objectID": "posts/ml/2022-09-29-ml_4w.html#logistic-regression",
    "href": "posts/ml/2022-09-29-ml_4w.html#logistic-regression",
    "title": "DNN (4주차)",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nmotive\n- 현실에서 이런 경우가 많음 - \\(x\\)가 커질수록 (혹은 작아질수록) 성공확률이 증가함.\n- (X,y)는 어떤모양?\n\n_df = pd.DataFrame({'x':range(-6,7),'y':[0,0,0,0,0,0,1,0,1,1,1,1,1]})\n_df \n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n-6\n0\n\n\n1\n-5\n0\n\n\n2\n-4\n0\n\n\n3\n-3\n0\n\n\n4\n-2\n0\n\n\n5\n-1\n0\n\n\n6\n0\n1\n\n\n7\n1\n0\n\n\n8\n2\n1\n\n\n9\n3\n1\n\n\n10\n4\n1\n\n\n11\n5\n1\n\n\n12\n6\n1\n\n\n\n\n\n\n\n\nplt.plot(_df.x,_df.y,'o')\n\n\n\n\n- (예비학습) 시그모이드라는 함수가 있음\n\nxx = torch.linspace(-6,6,100)\ndef f(x):\n    return torch.exp(x)/(1+torch.exp(x))\n\n\nplt.plot(_df.x,_df.y,'o')\nplt.plot(xx,f(xx))\nplt.plot(xx,f(2.5*xx-1.2)) # 영향을 크게 받을 때 + 운적인 요소 영향 받을 때(절편) -&gt; 모델링하는 과정\n\n\n\n\n베르누이 특정 확률로 0 또는 1 뽑기\n\n\nmodel\n- \\(x\\)가 커질수록 \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt;— 외우세요!!!\n\n\\(y_i \\sim Ber(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)\n\\(\\hat{y}_i= \\hat{pi}_\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\) &lt;— 외우세요!!\n\n\\(y_i=1\\) \\(\\hat{y_i} = 1\\)loss가 0 근처 \\(\\hat{y_i} = 0\\) loss가- 무한대\n\\(y_i = 0\\) \\(\\hat{y_i} = 0\\)loss가 0근처 \\(\\hat{y_i} = 1\\) loss가 1\n\n\ntoy example\n- 예제시작\n\ntorch.bernoulli?\n\n\nDocstring:\nbernoulli(input, *, generator=None, out=None) -&gt; Tensor\nDraws binary random numbers (0 or 1) from a Bernoulli distribution.\nThe :attr:`input` tensor should be a tensor containing probabilities\nto be used for drawing the binary random number.\nHence, all values in :attr:`input` have to be in the range:\n:math:`0 \\leq \\text{input}_i \\leq 1`.\nThe :math:`\\text{i}^{th}` element of the output tensor will draw a\nvalue :math:`1` according to the :math:`\\text{i}^{th}` probability value given\nin :attr:`input`.\n.. math::\n    \\text{out}_{i} \\sim \\mathrm{Bernoulli}(p = \\text{input}_{i})\nThe returned :attr:`out` tensor only has values 0 or 1 and is of the same\nshape as :attr:`input`.\n:attr:`out` can have integral ``dtype``, but :attr:`input` must have floating\npoint ``dtype``.\nArgs:\n    input (Tensor): the input tensor of probability values for the Bernoulli distribution\nKeyword args:\n    generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling\n    out (Tensor, optional): the output tensor.\nExample::\n    &gt;&gt;&gt; a = torch.empty(3, 3).uniform_(0, 1)  # generate a uniform random matrix with range [0, 1]\n    &gt;&gt;&gt; a\n    tensor([[ 0.1737,  0.0950,  0.3609],\n            [ 0.7148,  0.0289,  0.2676],\n            [ 0.9456,  0.8937,  0.7202]])\n    &gt;&gt;&gt; torch.bernoulli(a)\n    tensor([[ 1.,  0.,  0.],\n            [ 0.,  0.,  0.],\n            [ 1.,  1.,  1.]])\n    &gt;&gt;&gt; a = torch.ones(3, 3) # probability of drawing \"1\" is 1\n    &gt;&gt;&gt; torch.bernoulli(a)\n    tensor([[ 1.,  1.,  1.],\n            [ 1.,  1.,  1.],\n            [ 1.,  1.,  1.]])\n    &gt;&gt;&gt; a = torch.zeros(3, 3) # probability of drawing \"1\" is 0\n    &gt;&gt;&gt; torch.bernoulli(a)\n    tensor([[ 0.,  0.,  0.],\n            [ 0.,  0.,  0.],\n            [ 0.,  0.,  0.]])\nType:      builtin_function_or_method\n\n\n\n\n\ntorch.bernoulli(torch.tensor([0.5]*100)) # 0.5의 확률ㄹ 0 또는 1 뽑아\n\ntensor([0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.,\n        0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1.,\n        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n        1., 1., 0., 1., 1., 0., 1., 0., 0., 1.])\n\n\n\nx=torch.linspace(-1,1,2000).reshape(2000,1)\nw0= -1 \nw1= 5 \nu = w0+x*w1 \nv = torch.exp(u)/(1+torch.exp(u)) # v=πi, 즉 확률을 의미함\ny = torch.bernoulli(v) \n\n\nv\n\ntensor([[0.0025],\n        [0.0025],\n        [0.0025],\n        ...,\n        [0.9818],\n        [0.9819],\n        [0.9820]])\n\n\n\nu\n\ntensor([[-6.0000],\n        [-5.9950],\n        [-5.9900],\n        ...,\n        [ 3.9900],\n        [ 3.9950],\n        [ 4.0000]])\n\n\n\n#plt.scatter(x,y,alpha=0.05)\nplt.plot(x,y,'o',alpha=0.05,ms=4)\nplt.plot(x,v,'--r')\n\n\n\n\n\n우리의 목적: \\(x\\)가 들어가면 빨간선 \\(\\hat{y}\\)의 값을 만들어주는 mapping을 학습해보자.\n\n\nw0hat = 10\nw1hat = 3\nyhat = f(w0hat + w1hat*x)\nplt.plot(x,y,'o',alpha=0.05,ms=4)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat,'--r')\n\n\n\n\n\nl1 = torch.nn.Linear(1,1)\n\n\nl1.bias.data = torch.tensor([-1.0])\nl1.weight.data = torch.tensor([[1.0]])\n\n\na1 = torch.nn.Sigmoid()\n\n\nw0hat = -1\nw1hat = 3\nyhat = a1(w0hat + w1hat*x)\nplt.plot(x,y,'o',alpha=0.05,ms=4)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat,'--r')\n\n\n\n\n\nfor epoc in range(6000):\n    ## step1 \n    yhat = a1(l1(x))\n    ## step2 \n    loss = torch.mean((y-yhat)**2) ## loss 를 원래 이렇게 하는건 아니에요.. \n    ## step3 \n    loss.backward()\n    ## step4 \n    l1.bias.data = l1.bias.data - 0.1 * l1.bias.grad \n    l1.weight.data = l1.weight.data - 0.1 * l1.weight.grad \n    l1.bias.grad = None \n    l1.weight.grad = None \n\n\nplt.plot(x,y,'o',alpha=0.05,ms=4)\nplt.plot(x,v,'--r')\nplt.plot(x,a1(l1(x)).data,'--r')"
  },
  {
    "objectID": "posts/ml/2022-09-29-ml_4w.html#숙제",
    "href": "posts/ml/2022-09-29-ml_4w.html#숙제",
    "title": "DNN (4주차)",
    "section": "숙제",
    "text": "숙제"
  },
  {
    "objectID": "posts/ml/2022-11-02-ml-midterm.html",
    "href": "posts/ml/2022-11-02-ml-midterm.html",
    "title": "Midterm",
    "section": "",
    "text": "중간고사 대체과제\nimport torch \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom fastai.vision.all import *"
  },
  {
    "objectID": "posts/ml/2022-11-02-ml-midterm.html#크롤링을-통한-이미지-분석-및-cam",
    "href": "posts/ml/2022-11-02-ml-midterm.html#크롤링을-통한-이미지-분석-및-cam",
    "title": "Midterm",
    "section": "1. 크롤링을 통한 이미지 분석 및 CAM",
    "text": "1. 크롤링을 통한 이미지 분석 및 CAM\n(1) 두 가지 키워드로 크롤링을 수행하여 이미지자료를 모아라. (키워드는 각자 마음에 드는 것으로 설정할 것)\n힌트1: hynn, iu 라는 키워드로 크롤링하여 이미지자료를 모으는 코드\n\n#\n# 크롤링에 필요한 준비작업들\n#!pip install -Uqq duckduckgo_search\nfrom duckduckgo_search import ddg_images\nfrom fastdownload import download_url\nfrom fastcore.all import *\ndef search_images(term, max_images=200): return L(ddg_images(term, max_results=max_images)).itemgot('image')\n\n# \n# 폴더만드는코드 -- 사실 손으로 만들어도 무방함.. \n!mkdir images\n!mkdir images/train\n!mkdir images/test \n!mkdir images/train/iu\n!mkdir images/train/hynn\n!mkdir images/test/iu\n!mkdir images/test/hynn\ndownload_images(dest='./images/train/iu',urls=search_images('iu',max_images=200)) # iu 라는 키워드로 200개 이미지 크롤링 -&gt; ./images/train/iu 에 저장\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/train/hynn',urls=search_images('hynn',max_images=200)) # hynn 이라는 키워드로 200개 이미지 크롤링 -&gt; ./images/train/hynn 에 저장\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/train/iu',urls=search_images('iu kpop',max_images=200))  # iu kpop 이라는 키워드로 200개 이미지 크롤링 -&gt; ./images/train/iu 에 저장\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/train/hynn',urls=search_images('hynn kpop',max_images=200)) # hynn kpop 이라는 키워드로 200개 이미지 크롤링 -&gt; ./images/train/hynn 에 저장\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/test/iu',urls=search_images('iu photo',max_images=50)) # iu photo 라는 키워드로 50개 이미지 크롤링 -&gt; ./images/test/iu 에 저장\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/test/hynn',urls=search_images('hynn photo',max_images=50)) # hynn photo 라는 키워드로 50개 이미지 크롤링 -&gt; ./images/test/hynn 에 저장 \ntime.sleep(10) # 서버과부하를 위한 휴식코드 \n힌트2: 불량이미지 삭제\nbad_images = verify_images(get_image_files('./images'))\nbad_images\n\n불량이미지 목록\n\nbad_images.map(Path.unlink)\n\n불량이미지는 dls를 불러올때 방해되므로 제거\n\n\n!mkdir images/train/bezos\n!mkdir images/train/musk\n!mkdir images/test/bezos\n!mkdir images/test/musk\n\n\ndownload_images(dest='./images/train/bezos',urls=search_images('jeff bezos',max_images=200))\ntime.sleep(10)\ndownload_images(dest='./images/train/musk',urls=search_images('elon musk',max_images=200)) \ntime.sleep(10)\ndownload_images(dest='./images/train/bezos',urls=search_images('jeff bezos rich',max_images=200))  \ntime.sleep(10) \ndownload_images(dest='./images/test/musk',urls=search_images('elon musk rich',max_images=200)) \ntime.sleep(10)\n\ndownload_images(dest='./images/test/bezos',urls=search_images('jeff bezos photo',max_images=50)) # iu photo 라는 키워드로 50개 이미지 크롤링 -&gt; ./images/test/iu 에 저장\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/test/musk',urls=search_images('elon usk photo',max_images=50)) # hynn photo 라는 키워드로 50개 이미지 크롤링 -&gt; ./images/test/hynn 에 저장 \ntime.sleep(10) # 서버과부하를 위한 휴식코드 \n\n\nbad_images = verify_images(get_image_files('./images'))\nbad_images\n\n(#25) [Path('images/train/bezos/1d39746b-ad4d-49ac-ac25-0f569a94e3f2.jpg'),Path('images/train/bezos/ee365bea-bb15-4b79-9ebc-350d5a823ca8.JPG'),Path('images/train/bezos/289cbafa-0fbc-4be9-a39f-68429c876095.jpg'),Path('images/train/bezos/21495a5a-9602-42f5-8f7b-4978856bd1e8.jpg'),Path('images/train/bezos/3bd6c738-5361-4f95-9b3b-643904f5a135.jpg'),Path('images/train/bezos/2ca0722d-cb88-4f18-bc5f-c410bd16243f.jpg'),Path('images/train/bezos/e9924f91-aac6-4a11-a235-dacb7f80d576.jpg'),Path('images/train/bezos/fcc25b56-8807-4e52-bc37-6e1718994d8a.jpg'),Path('images/train/bezos/07e554ae-1261-4c81-b908-7c8d94e94702.jpg'),Path('images/train/bezos/ea6592bc-eff0-4db6-b93c-3b6e85897877.jpg')...]\n\n\n\nbad_images.map(Path.unlink)\n\n(#25) [None,None,None,None,None,None,None,None,None,None...]\n\n\n(2) ImageDataLoaders.from_folder 를 이용하여 dls를 만들어라.\n힌트1: dls를 만드는 코드\ndls = ImageDataLoaders.from_folder(path = './images', train='train',valid='test',item_tfms=Resize(512),bs=8) \ndls.show_batch()\n\ndls = ImageDataLoaders.from_folder(path = './images', train='train',valid='test',item_tfms=Resize(512),bs=8) \n\n\ndls.show_batch()\n\n\n\n\n(3) resnet34를 이용하여 학습하라.\n\nlrnr = vision_learner(dls,resnet34,metrics=accuracy) \n\n\nlrnr.fine_tune(5)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.623527\n0.999150\n0.695341\n00:07\n\n\n\n\n\n/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.350595\n1.298542\n0.695341\n00:09\n\n\n1\n0.228978\n1.561831\n0.759857\n00:08\n\n\n2\n0.185354\n1.211755\n0.806452\n00:08\n\n\n3\n0.210802\n1.586954\n0.731183\n00:08\n\n\n4\n0.210048\n0.952422\n0.820789\n00:08\n\n\n\n\n\n(4) CAM (class activation mapping)을 이용하여 (3)의 모형의 판단근거를 시각화하라.\n\nnet1= lrnr.model[0]\nnet2= lrnr.model[1]\n\n\n_X, _y = dls.one_batch() \n\n\nnet1.to(\"cpu\")\nnet2.to(\"cpu\") \n_X = _X.to(\"cpu\")\n\n\nprint(net1(_X).shape)\nprint(net2[0](net1(_X)).shape)\nprint(net2[1](net2[0](net1(_X))).shape)\nprint(net2[2](net2[1](net2[0](net1(_X)))).shape)\n\ntorch.Size([8, 512, 16, 16])\ntorch.Size([8, 1024, 1, 1])\ntorch.Size([8, 1024])\ntorch.Size([8, 1024])\n\n\n\nnet2= torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), # (64,512,16,16) -&gt; (64,512,1,1) \n    torch.nn.Flatten(), # (64,512,1,1) -&gt; (64,512) \n    torch.nn.Linear(512,2,bias=False) # (64,512) -&gt; (64,2) \n)\n\n\nnet = torch.nn.Sequential(\n    net1,\n    net2\n)\n\n\nlrnr2= Learner(dls,net,metrics=accuracy) \n\n\nlrnr2.loss_func, lrnr.loss_func\n\n(FlattenedLoss of CrossEntropyLoss(), FlattenedLoss of CrossEntropyLoss())\n\n\n\nlrnr2.fine_tune(5) \n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.473621\n7.780233\n0.831541\n00:08\n\n\n\n\n\n/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.358073\n1.187476\n0.767025\n00:08\n\n\n1\n0.378113\n3.513460\n0.236559\n00:09\n\n\n2\n0.410308\n0.585618\n0.713262\n00:08\n\n\n3\n0.339331\n0.728930\n0.713262\n00:08\n\n\n4\n0.250342\n0.674079\n0.745520\n00:08\n\n\n\n\n\n\nsftmax = torch.nn.Softmax(dim=1)\n\n\npath = './images'\n\n\nfig, ax = plt.subplots(5,5) \nk=200\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -&gt; acij', net2[2].weight, net1(x))\n        why_bezos = why[0,0,:,:] \n        why_musk = why[0,1,:,:] \n        bezosprob, muskprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if bezosprob&gt;muskprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_bezos.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"bezos(%2f)\" % bezosprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_musk.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"musk(%2f)\" % muskprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/ml/2022-11-02-ml-midterm.html#overparameterized-model",
    "href": "posts/ml/2022-11-02-ml-midterm.html#overparameterized-model",
    "title": "Midterm",
    "section": "2. Overparameterized Model",
    "text": "2. Overparameterized Model\n(풀이 있음)\n아래와 같은 자료가 있다고 가정하자.\n\nx = torch.rand([1000,1])*2-1\ny = 3.14 + 6.28*x + torch.randn([1000,1]) \n\n\nplt.plot(x,y,'o',alpha=0.1)\n\n\n\n\n(1) 아래의 모형을 가정하고 \\(\\beta_0,\\beta_1\\)을 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i,\\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n\nnet = torch.nn.Linear(in_features=1,out_features=1)\n\n\noptimizr = torch.optim.SGD(net.parameters(),lr=1/10) \n\n\nplt.plot(x,y,'.')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nfor epoc in range(100):\n    yhat = net(x) \n    loss = torch.mean((yhat-y)**2)\n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad() \n\n\nplt.plot(x,y,'.')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nnet.weight.data, net.bias.data\n\n(tensor([[6.2839]]), tensor([3.1322]))\n\n\n(2) 아래의 모형을 가정하고 \\(\\beta_0\\)를 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\beta_0 + \\epsilon_i,\\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n\nW0hat = torch.tensor([0.0], requires_grad=True)\n\n\nW0hat\n\ntensor([0.], requires_grad=True)\n\n\n\nplt.plot(x,y,'.')\nplt.plot(x,(0*x+W0hat).data,'--')\n\n\n\n\n\nfor epoc in range(100):\n    yhat = 0 * x + W0hat\n    loss = torch.mean((y-yhat)**2)\n    loss.backward()\n    W0hat.data = W0hat.data - 0.1*W0hat.grad\n    W0hat.grad = None\n\n\nplt.plot(x,y,'.')\nplt.plot(x,(0*x+W0hat).data,'--')\n\n\n\n\n\nW0hat\n\ntensor([3.1188], requires_grad=True)\n\n\n(3) 아래의 모형을 가정하고 \\(\\beta_1\\)을 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\beta_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n\nnet = torch.nn.Linear(1,1,bias = False)\n\n\nplt.plot(x,y,'.')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\noptimizr = torch.optim.SGD(net.parameters(),lr=1/10) \n\n\nfor epoc in range(100):\n    yhat = net(x) \n    loss = torch.mean((y-yhat)**2)\n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad() \n\n\nplt.plot(x,y,'.')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nnet.weight.data\n\ntensor([[6.2637]])\n\n\n(4) 아래의 모형을 가정하고 \\(\\alpha_0,\\beta_0,\\beta_1\\)을 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\alpha_0+\\beta_0+ \\beta_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n\\(\\hat{\\alpha}_0+\\hat{\\beta}_0\\)은 얼마인가? 이 값과 문제 (1)에서 추정된 \\(\\hat{\\beta_0}\\)의 값과 비교하여 보라.\n\n_1= torch.ones([1000,1])\nX = torch.concat([_1,x],axis=1)\n\n\nnet = torch.nn.Linear(in_features=2,out_features=1)\n\n\noptimizr = torch.optim.SGD(net.parameters(),lr=1/10) \n\n\nplt.plot(x,y,'.')\nplt.plot(x,net(X).data,'--')\n\n\n\n\n\nfor epoc in range(100):\n    yhat = net(X) \n    loss = torch.mean((yhat-y)**2)\n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad() \n\n\nplt.plot(x,y,'.')\nplt.plot(x,net(X).data,'--')\n\n\n\n\n\nnet.weight.data, net.bias.data\n\n(tensor([[1.5093, 6.2918]]), tensor([1.6958]))\n\n\n\n1.7377 + 1.4358\n\n3.1734999999999998\n\n\n\n6.2363\n\n6.2363\n\n\n(5) 아래의 모형을 가정하고 \\(\\alpha_0,\\alpha_1,\\beta_0,\\beta_1\\)을 파이토치를 이용하여 추정하라. – 이거 제가 힌트를 잘못줬어요.. 문제가 좀 어렵게나왔네요 ㅠㅠ\n\n\\(y_i = \\alpha_0+\\beta_0+ \\beta_1x_i + \\alpha_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n\\(\\hat{\\alpha}_0+\\hat{\\beta}_0\\), \\(\\hat{\\alpha}_1 + \\hat{\\beta}_1\\)의 값은 각각 얼마인가? 이 값들을 (1) 에서 추정된 \\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\) 값들과 비교하라.\n\n_1= torch.ones([1000,1])\nX = torch.concat([_1,x,x],axis=1)\n\n\nnet = torch.nn.Linear(in_features=3,out_features=1)\n\n\noptimizr = torch.optim.SGD(net.parameters(),lr=1/10) \n\n\nplt.plot(x,y,'.')\nplt.plot(x,net(X).data,'--')\n\n\n\n\n\nfor epoc in range(100):\n    yhat = net(X) \n    loss = torch.mean((yhat-y)**2)\n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad() \n\n\nplt.plot(x,y,'.')\nplt.plot(x,net(X).data,'--')\n\n\n\n\n\nnet.weight.data, net.bias.data\n\n(tensor([[1.2913, 3.4037, 2.8956]]), tensor([1.9138]))\n\n\n\n1.9599 + 1.2138\n\n3.1737\n\n\n\n3.2835 + 2.9585\n\n6.242\n\n\n(6) 다음은 위의 모형에 대하여 학생들이 discussion한 결과이다. 올바르게 해석한 학생을 모두 골라라.\n민정: \\((x_i,y_i)\\)의 산점도는 직선모양이고 직선의 절펴과 기울기 모두 유의미해 보이므로 \\(y_i = \\beta_0 + \\beta_1 x_i\\) 꼴을 적합하는게 좋겠다.\n슬기: 나도 그렇게 생각해. 그래서 (2)-(3)과 같이 기울기를 제외하고 적합하거나 절편을 제외하고 적합하면 underfitting의 상황에 빠질 수 있어.\n성재: (2)의 경우 사실상 \\(\\bar{y}=\\frac{1}{n}\\sum_{i=1}^{n}y_i\\)를 추정하는 것과 같아지게 되지.\n세민: (4)의 경우 \\({\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots & \\dots \\\\ 1 & x_n \\end{bmatrix}\\) 와 같이 설정하고 네트워크를 아래와 같이 설정할 경우 얻어지는 모형이야.\nnet = torch.nn.Linear(in_features=2,out_features=1,bias=True)\n구환: 모델 (4)-(5)는 표현력은 (1)과 동일하지만 추정할 파라메터는 (1)보다 많으므로 효율적인 모델이라고 볼 수 없어.\nanswer : 민정, 슬기, 세민, 구환\n이 문제의 경우 풀이를 여기에서 확인할 수 있습니다."
  },
  {
    "objectID": "posts/ml/2022-11-02-ml-midterm.html#차원축소기법과-표현학습",
    "href": "posts/ml/2022-11-02-ml-midterm.html#차원축소기법과-표현학습",
    "title": "Midterm",
    "section": "3. 차원축소기법과 표현학습",
    "text": "3. 차원축소기법과 표현학습\n다음은 아이리스데이터를 불러오는 코드이다. (아이리스 데이터에 대한 자세한 설명은 생략한다. 잘 모르는 학생은 구글검색을 해볼 것)\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/STML2022/master/_notebooks/iris.csv\")\ndf\n\n\n\n\n\n\n\n\nSepal Length\nSepal Width\nPetal Length\nPetal Width\nSpecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n...\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n146\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n147\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n148\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n149\n5.9\n3.0\n5.1\n1.8\nvirginica\n\n\n\n\n150 rows × 5 columns\n\n\n\n\nX = torch.tensor(df.drop(columns=['Species']).to_numpy(), dtype=torch.float32)\n\n(1) 아래를 만족하도록 적당한 아키텍처, 손실함수를 설계하라. (손실함수는 MSE를 이용)\n\n\\(\\underset{(150,4)}{\\bf X} \\overset{l_1}{\\to} \\underset{(150,2)}{\\bf Z} \\overset{l_2}{\\to} \\underset{(150,4)}{\\bf \\hat X}\\)\n\\({\\bf \\hat X} \\approx {\\bf X}\\)\n\n차원축소\n\nX[:5]\n\ntensor([[5.1000, 3.5000, 1.4000, 0.2000],\n        [4.9000, 3.0000, 1.4000, 0.2000],\n        [4.7000, 3.2000, 1.3000, 0.2000],\n        [4.6000, 3.1000, 1.5000, 0.2000],\n        [5.0000, 3.6000, 1.4000, 0.2000]])\n\n\n\nX.shape\n\ntorch.Size([150, 4])\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(4,2,bias=False),\n    torch.nn.Linear(2,4,bias = False)\n)\n\n\nZ = net[0](X)\n\n\nZ.type()\n\n'torch.FloatTensor'\n\n\n\nZ[:5]\n\ntensor([[-0.8808, -1.5322],\n        [-0.8771, -1.5868],\n        [-0.8091, -1.4178],\n        [-0.8198, -1.4608],\n        [-0.8528, -1.4621]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\nXhat = net[1](net[0](X))\n\n\nXhat.type()\n\n'torch.FloatTensor'\n\n\n\nXhat[:5]\n\ntensor([[-0.6900, -1.1176, -0.2331, -0.6170],\n        [-0.6969, -1.1495, -0.2264, -0.6290],\n        [-0.6355, -1.0328, -0.2131, -0.5692],\n        [-0.6478, -1.0610, -0.2137, -0.5826],\n        [-0.6646, -1.0692, -0.2276, -0.5922]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n(2) 아래코드를 이용하여 \\({\\bf X}\\), \\({\\bf Z}\\), \\({\\bf \\hat{X}}\\)를 시각화 하라.\n(시각화예시)\nfig,ax = plt.subplots(figsize=(10,10)) \nax.imshow(torch.concat([X,Z,Xhat],axis=1)[:10])\nax.set_xticks(np.arange(0,10)) \nax.set_xticklabels([r'$X_1$',r'$X_2$',r'$X_3$',r'$X_4$',r'$Z_1$',r'$Z_2$',r'$\\hat{X}_1$',r'$\\hat{X}_2$',r'$\\hat{X}_3$',r'$\\hat{X}_4$'])\nax.vlines([3.5,5.5],ymin=-0.5,ymax=9.5,lw=2,color='red',linestyle='dashed')\nax.set_title(r'First 10 obs of $\\bf [X, Z, \\hat{X}]$ // before learning',size=25);\n\nfig,ax = plt.subplots(figsize=(10,10)) \nax.imshow(torch.concat([X,Z.data,Xhat.data],axis=1)[:10])\nax.set_xticks(np.arange(0,10)) \nax.set_xticklabels([r'$X_1$',r'$X_2$',r'$X_3$',r'$X_4$',r'$Z_1$',r'$Z_2$',r'$\\hat{X}_1$',r'$\\hat{X}_2$',r'$\\hat{X}_3$',r'$\\hat{X}_4$'])\nax.vlines([3.5,5.5],ymin=-0.5,ymax=9.5,lw=2,color='red',linestyle='dashed')\nax.set_title(r'First 10 obs of $\\bf [X, Z, \\hat{X}]$ // before learning',size=25);\n\n\n\n\n(3) 네트워크를 학습시키고 \\({\\bf X}, {\\bf Z}, {\\bf \\hat{X}}\\)를 시각화하라.\n(시각화예시)\nfig,ax = plt.subplots(figsize=(10,10)) \nax.imshow(torch.concat([X,Z,Xhat],axis=1)[:10])\nax.set_xticks(np.arange(0,10)) \nax.set_xticklabels([r'$X_1$',r'$X_2$',r'$X_3$',r'$X_4$',r'$Z_1$',r'$Z_2$',r'$\\hat{X}_1$',r'$\\hat{X}_2$',r'$\\hat{X}_3$',r'$\\hat{X}_4$'])\nax.vlines([3.5,5.5],ymin=-0.5,ymax=9.5,lw=2,color='red',linestyle='dashed')\nax.set_title(r'First 10 obs of $\\bf [X, Z, \\hat{X}]$ // after learning',size=25);\n\noptimizr= torch.optim.Adam(net.parameters())\n\n\nloss_fn= torch.nn.MSELoss()\n\n\nfor epoc in range(2000): \n    ## 1 \n    Z = net[0](X) \n    Xhat = net[1](Z) \n    ## 2 \n    loss=loss_fn(Xhat,X) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\nfig,ax = plt.subplots(figsize=(10,10)) \nax.imshow(torch.concat([X,Z.data,Xhat.data],axis=1)[:10])\nax.set_xticks(np.arange(0,10)) \nax.set_xticklabels([r'$X_1$',r'$X_2$',r'$X_3$',r'$X_4$',r'$Z_1$',r'$Z_2$',r'$\\hat{X}_1$',r'$\\hat{X}_2$',r'$\\hat{X}_3$',r'$\\hat{X}_4$'])\nax.vlines([3.5,5.5],ymin=-0.5,ymax=9.5,lw=2,color='red',linestyle='dashed')\nax.set_title(r'First 10 obs of $\\bf [X, Z, \\hat{X}]$ // after learning',size=25);\n\n\n\n\n(4) (3)의 결과로 학습된 \\(Z\\)를 입력벡터로 하고 \\(Z \\to y=\\text{Species}\\) 로 향하는 적당한 네트워크를 설계한 뒤 학습하라.\nx-&gt;y가는 mapping 안 찾아도 - z-&gt;y 가는 mapping 적절히 잘 찾으면 - x-&gt;y 적용가능한 linear function 찾기 가능\n\nZ.shape\n\ntorch.Size([150, 2])\n\n\n\nnet = torch.nn.Linear(2,4)\n\n\nloss_fn= torch.nn.CrossEntropyLoss()\n\n\noptimizr= torch.optim.Adam(net.parameters())\n\n\ndef f(txt,mapping):\n    return [mapping[key] for key in txt] \n\n\nmapping = {'setosa':0,'versicolor':1,'virginica':2}\n\n\ny_base = list(df['Species'])\n\n\ny = torch.tensor(f(y_base,mapping))\n\n\ny.unique()\n\ntensor([0, 1, 2])\n\n\n\nfor epoc in range(2000): \n    ## 1 \n    yhat = net(Z.data)\n    ## 2 \n    loss=loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\nnet.weight\n\nParameter containing:\ntensor([[ 0.1512,  1.0270],\n        [ 0.1297, -1.1137],\n        [ 0.6069, -1.1514],\n        [-0.5099, -0.4560]], requires_grad=True)\n\n\n(5) (1)~(4)의 결과를 토의한 내용이다. 적절하게 토의한 사람을 모두 고르라.\n규빈: \\({\\bf Z}\\)는 \\({\\bf X}\\)보다 적은 feature를 가지고 있다. 또한 적절한 선형변환을 하면 \\({\\bf X}\\)와 비슷한 \\({\\bf \\hat X}\\)을 만들 수 있으므로 \\({\\bf X}\\)의 정보량 대부분 유지한채로 효과적으로 차원을 줄인 방법이라 볼 수 있다.\n민정: 즉 \\({\\bf X}\\)에서 \\({\\bf y}\\)로 가는 맵핑을 학습하는 과업은 \\({\\bf Z}\\)에서 \\({\\bf y}\\)로 가는 맵핑을 학습하는 과업은 거의 동등하다고 볼 수 있다.\n성재: \\({\\bf Z}\\)의 차원을 (n,4)로 설정한다면 이론상 \\({\\bf X}\\)와 동일한 \\({\\bf \\hat X}\\)을 만들어 낼 수 있다.\n슬기: \\({\\bf Z}\\)의 차원이 (n,2)일지라도 경우에 따라서 \\({\\bf X}\\)와 동일한 \\({\\bf \\hat X}\\)을 만들어 낼 수 있다.\nanswer : 규빈, 민정, 성재, 슬기"
  },
  {
    "objectID": "posts/ml/2022-10-26-ml_8w_1.html",
    "href": "posts/ml/2022-10-26-ml_8w_1.html",
    "title": "CNN (8주차) 1",
    "section": "",
    "text": "기계학습 특강 (8주차) 10월26일–(1) [이미지자료분석 - CNN 다중클래스 분류, fastai metric 사용]"
  },
  {
    "objectID": "posts/ml/2022-10-26-ml_8w_1.html#imports",
    "href": "posts/ml/2022-10-26-ml_8w_1.html#imports",
    "title": "CNN (8주차) 1",
    "section": "imports",
    "text": "imports\n\nimport torch \nimport torchvision\nimport numpy as np\nfrom fastai.vision.all import * \n\n\nimport graphviz\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"'+s + '; }');\n\n\n#hide\ngraphviz.set_jupyter_format('png')\n\n'svg'"
  },
  {
    "objectID": "posts/ml/2022-10-26-ml_8w_1.html#cnn-다중클래스-분류",
    "href": "posts/ml/2022-10-26-ml_8w_1.html#cnn-다중클래스-분류",
    "title": "CNN (8주차) 1",
    "section": "CNN 다중클래스 분류",
    "text": "CNN 다중클래스 분류\n\n결론 (그냥 외우세요)\n- 2개의 class를 구분하는 문제가 아니라 \\(k\\)개의 class를 구분해야 한다면?\n일반적인 개념\n\n손실함수: BCE loss \\(\\to\\) Cross Entropy loss\n마지막층의 선형변환: torch.nn.Linear(?,1) \\(\\to\\) torch.nn.Linear(?,k)\n마지막층의 활성화: sig \\(\\to\\) softmax\n\n파이토치 한정 - y의형태: (n,) vector + int형 // (n,k) one-hot encoded vector + float형 - 손실함수: torch.nn.BCEWithLogitsLoss, \\(\\to\\) torch.nn.CrossEntropyLoss - 마지막층의 선형변환: torch.nn.Linear(?,1) \\(\\to\\) torch.nn.Linear(?,k) - 마지막층의 활성화: None \\(\\to\\) None (손실함수에 이미 마지막층의 활성화가 포함)\n\n\n실습: 3개의 클래스를 구분\n\npath = untar_data(URLs.MNIST)\n\ntraining set\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/2').ls()])\nX = torch.concat([X0,X1,X2])/255\ny = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))#.reshape(-1,1)\n\n다중일때 int가 아닌float으로서 y를 정의해준 모습\ntest set\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/2').ls()])\nXX = torch.concat([X0,X1,X2])/255\nyy = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))#.reshape(-1,1)\n\n\ndls\n\n\nlen(X)\n\n18623\n\n\n\nds1 = torch.utils.data.TensorDataset(X,y) \nds2 = torch.utils.data.TensorDataset(XX,yy) \ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1862) # 에폭당 11번 iter\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=3147) # \ndls = DataLoaders(dl1,dl2) \n\n\nlrnr\n\n\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\n\n\nnet1(X).shape\n\ntorch.Size([18623, 2304])\n\n\n\nnet = torch.nn.Sequential(\n    net1,\n    torch.nn.Linear(2304,3) # 0,1,2 3개를 구분하는 문제이므로 out_features=3 \n)\nloss_fn = torch.nn.CrossEntropyLoss() \n\n\nlrnr = Learner(dls,net,loss_fn) \n\nadam기본인 learner\n\n학습\n\n지금은 epoch당 11번 도는 설정, 18623/1862 = 11.xx\n\nlrnr.fit(10) \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n1.532752\n1.059955\n00:00\n\n\n1\n1.190896\n0.830852\n00:00\n\n\n2\n1.008513\n0.646931\n00:00\n\n\n3\n0.865353\n0.427843\n00:00\n\n\n4\n0.728408\n0.264087\n00:00\n\n\n5\n0.602026\n0.179980\n00:00\n\n\n6\n0.497519\n0.137681\n00:00\n\n\n7\n0.415113\n0.112264\n00:00\n\n\n8\n0.349265\n0.096033\n00:00\n\n\n9\n0.296159\n0.084770\n00:00\n\n\n\n\n\n\n예측\n\n\nlrnr.model.to(\"cpu\")\n\nSequential(\n  (0): Sequential(\n    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n    (3): Flatten(start_dim=1, end_dim=-1)\n  )\n  (1): Linear(in_features=2304, out_features=3, bias=True)\n)\n\n\n\npd.DataFrame(lrnr.model(XX)).assign(y=yy) \n\n\n\n\n\n\n\n\n0\n1\n2\ny\n\n\n\n\n0\n2.838031\n-14.031689\n-1.230620\n0\n\n\n1\n-0.732540\n-6.829875\n-0.657546\n0\n\n\n2\n2.525343\n-7.813309\n-2.658828\n0\n\n\n3\n1.173236\n-5.229916\n-2.532024\n0\n\n\n4\n0.102843\n-3.444337\n-1.044323\n0\n\n\n...\n...\n...\n...\n...\n\n\n3142\n-2.697058\n-3.533814\n-0.154926\n2\n\n\n3143\n-5.334007\n-6.445426\n2.196163\n2\n\n\n3144\n-3.041989\n-5.655945\n1.335649\n2\n\n\n3145\n-4.720510\n-5.899189\n1.208340\n2\n\n\n3146\n-2.413806\n-3.101650\n0.852677\n2\n\n\n\n\n3147 rows × 4 columns\n\n\n\n\npd.DataFrame(lrnr.model(XX)).assign(y=yy).query('y==0')\n\n\n\n\n\n\n\n\n0\n1\n2\ny\n\n\n\n\n0\n2.838031\n-14.031689\n-1.230620\n0\n\n\n1\n-0.732540\n-6.829875\n-0.657546\n0\n\n\n2\n2.525343\n-7.813309\n-2.658828\n0\n\n\n3\n1.173236\n-5.229916\n-2.532024\n0\n\n\n4\n0.102843\n-3.444337\n-1.044323\n0\n\n\n...\n...\n...\n...\n...\n\n\n975\n1.330218\n-6.934738\n-0.893682\n0\n\n\n976\n3.073657\n-11.082842\n-3.012246\n0\n\n\n977\n3.607128\n-7.156256\n-5.264734\n0\n\n\n978\n1.993969\n-7.487792\n-2.306112\n0\n\n\n979\n1.534865\n-7.852367\n-1.404178\n0\n\n\n\n\n980 rows × 4 columns\n\n\n\n\n대체적으로 첫번째 칼럼의 숫자들이 다른칼럼보다 크다.\n\n\npd.DataFrame(lrnr.model(XX)).assign(y=yy).query('y==1')\n\n\n\n\n\n\n\n\n0\n1\n2\ny\n\n\n\n\n980\n-4.239265\n2.068619\n-1.274470\n1\n\n\n981\n-4.559580\n2.755761\n-1.822832\n1\n\n\n982\n-4.617976\n1.838857\n-0.515022\n1\n\n\n983\n-4.119075\n2.247138\n-0.991911\n1\n\n\n984\n-3.344346\n1.100410\n-1.496944\n1\n\n\n...\n...\n...\n...\n...\n\n\n2110\n-4.141958\n2.405002\n-1.260467\n1\n\n\n2111\n-4.405143\n2.479209\n-1.356262\n1\n\n\n2112\n-3.695343\n1.773260\n-1.218412\n1\n\n\n2113\n-3.986775\n2.423826\n-1.349702\n1\n\n\n2114\n-4.925949\n2.532830\n-1.160674\n1\n\n\n\n\n1135 rows × 4 columns\n\n\n\n\n대체적으로 두번째 칼럼의 숫자들이 다른칼럼보다 크다.\n\n\npd.DataFrame(lrnr.model(XX)).assign(y=yy).query('y==2')\n\n\n\n\n\n\n\n\n0\n1\n2\ny\n\n\n\n\n2115\n-4.723238\n-3.105680\n1.052694\n2\n\n\n2116\n-2.576618\n-7.337523\n2.118495\n2\n\n\n2117\n-3.796456\n-6.393374\n2.169248\n2\n\n\n2118\n-3.276625\n-2.622900\n0.176427\n2\n\n\n2119\n-4.627345\n-5.335648\n1.157538\n2\n\n\n...\n...\n...\n...\n...\n\n\n3142\n-2.697058\n-3.533814\n-0.154926\n2\n\n\n3143\n-5.334007\n-6.445426\n2.196163\n2\n\n\n3144\n-3.041989\n-5.655945\n1.335649\n2\n\n\n3145\n-4.720510\n-5.899189\n1.208340\n2\n\n\n3146\n-2.413806\n-3.101650\n0.852677\n2\n\n\n\n\n1032 rows × 4 columns\n\n\n\n\n대체적으로 세번째 칼럼의 숫자들이 다른칼럼보다 크다.\n\n- 예측하는방법? - 칼럼0의 숫자가 크다 -&gt; y=0일 확률이 큼 - 칼럼1의 숫자가 크다 -&gt; y=1일 확률이 큼 - 칼럼2의 숫자가 크다 -&gt; y=2일 확률이 큼\n\n\n공부: Softmax\n- 눈치: softmax를 쓰기 직전의 숫자들은 (n,k)꼴로 되어있음. 각 observation 마다 k개의 숫자가 있는데, 그중에서 유난히 큰 하나의 숫자가 있음.\n- torch.nn.Softmax() 손계산\n(예시1) – 잘못계산\n\ntorch.nn.Softmax?\n\n\nInit signature: torch.nn.Softmax(dim: Union[int, NoneType] = None) -&gt; None\nDocstring:     \nApplies the Softmax function to an n-dimensional input Tensor\nrescaling them so that the elements of the n-dimensional output Tensor\nlie in the range [0,1] and sum to 1.\nSoftmax is defined as:\n.. math::\n    \\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}\nWhen the input Tensor is a sparse tensor then the unspecifed\nvalues are treated as ``-inf``.\nShape:\n    - Input: :math:`(*)` where `*` means, any number of additional\n      dimensions\n    - Output: :math:`(*)`, same shape as the input\nReturns:\n    a Tensor of the same dimension and shape as the input with\n    values in the range [0, 1]\nArgs:\n    dim (int): A dimension along which Softmax will be computed (so every slice\n        along dim will sum to 1).\n.. note::\n    This module doesn't work directly with NLLLoss,\n    which expects the Log to be computed between the Softmax and itself.\n    Use `LogSoftmax` instead (it's faster and has better numerical properties).\nExamples::\n    &gt;&gt;&gt; m = nn.Softmax(dim=1)\n    &gt;&gt;&gt; input = torch.randn(2, 3)\n    &gt;&gt;&gt; output = m(input)\nInit docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\nFile:           ~/anaconda3/envs/csy/lib/python3.8/site-packages/torch/nn/modules/activation.py\nType:           type\nSubclasses:     \n\n\n\n\n\nsftmax = torch.nn.Softmax(dim=0) # columns\n\n\n_netout = torch.tensor([[-2.0,-2.0,0.0],\n                        [3.14,3.14,3.14],\n                        [0.0,0.0,2.0],\n                        [2.0,2.0,4.0],\n                        [0.0,0.0,0.0]])\n_netout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\nsftmax(_netout) \n\ntensor([[0.0041, 0.0041, 0.0115],\n        [0.7081, 0.7081, 0.2653],\n        [0.0306, 0.0306, 0.0848],\n        [0.2265, 0.2265, 0.6269],\n        [0.0306, 0.0306, 0.0115]])\n\n\n(예시2) – 이게 맞게 계산되는 것임\n\nsftmax = torch.nn.Softmax(dim=1) # rows\n\n\n_netout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\nsftmax(_netout)\n\ntensor([[0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333],\n        [0.1065, 0.1065, 0.7870],\n        [0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333]])\n\n\n(예시3) – 차원을 명시안하면 맞게 계산해주고 경고 줌\n\nsftmax = torch.nn.Softmax()\n\n\n_netout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\nsftmax(_netout)\n\n/tmp/ipykernel_2380807/3715462293.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  sftmax(_netout)\n\n\ntensor([[0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333],\n        [0.1065, 0.1065, 0.7870],\n        [0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333]])\n\n\n(예시4) – 진짜 손계산\n\n_netout \n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\ntorch.exp(_netout)\n\ntensor([[ 0.1353,  0.1353,  1.0000],\n        [23.1039, 23.1039, 23.1039],\n        [ 1.0000,  1.0000,  7.3891],\n        [ 7.3891,  7.3891, 54.5981],\n        [ 1.0000,  1.0000,  1.0000]])\n\n\n\n0.1353/(0.1353 + 0.1353 + 1.0000), 0.1353/(0.1353 + 0.1353 + 1.0000), 1.0000/(0.1353 + 0.1353 + 1.0000) # 첫 obs\n\n(0.10648512513773022, 0.10648512513773022, 0.7870297497245397)\n\n\n\nnp.exp(_netout[1])/np.exp(_netout[1]).sum() # 두번째 obs \n\ntensor([0.3333, 0.3333, 0.3333])\n\n\n\nnp.apply_along_axis(lambda x: np.exp(x) / np.exp(x).sum(),1,_netout)\n\narray([[0.10650698, 0.10650698, 0.78698605],\n       [0.33333334, 0.33333334, 0.33333334],\n       [0.10650699, 0.10650699, 0.78698605],\n       [0.10650698, 0.10650698, 0.78698605],\n       [0.33333334, 0.33333334, 0.33333334]], dtype=float32)\n\n\n위에서 1은 축방향을 의미\n\n\n공부: CrossEntropyLoss\n\n# torch.nn.CrossEntropyLoss() 손계산: one-hot version\n\nloss_fn = torch.nn.CrossEntropyLoss()\n\n\n_netout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\n_y_onehot = torch.tensor([[0,0,1],\n                          [0,1,0],\n                          [0,0,1],\n                          [0,0,1],\n                          [1,0,0]])*1.0\n_y_onehot\n\ntensor([[0., 0., 1.],\n        [0., 1., 0.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [1., 0., 0.]])\n\n\n위에서 꼭 1.0 곱해줌으로써 int가 아닌 float으로 만들어주기\n\nsftmax = torch.nn.Softmax(dim=1) \nsftmax(_netout), _y_onehot\n\n(tensor([[0.1065, 0.1065, 0.7870],\n         [0.3333, 0.3333, 0.3333],\n         [0.1065, 0.1065, 0.7870],\n         [0.1065, 0.1065, 0.7870],\n         [0.3333, 0.3333, 0.3333]]),\n tensor([[0., 0., 1.],\n         [0., 1., 0.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [1., 0., 0.]]))\n\n\n- 계산결과\n\nloss_fn(_netout,_y_onehot)\n\ntensor(0.5832)\n\n\n\n- torch.sum(torch.log(sftmax(_netout)) * _y_onehot)/5 \n\ntensor(0.5832)\n\n\n- 계산하는 방법도 중요한데 torch.nn.CrossEntropyLoss() 에는 softmax 활성화함수가 이미 포함되어 있다는 것을 확인하는 것이 더 중요함.\n- 따라서 torch.nn.CrossEntropyLoss() 는 사실 torch.nn.CEWithSoftmaxLoss() 정도로 바꾸는 것이 더 말이 되는 것 같다.\n\n\n# torch.nn.CrossEntropyLoss() 손계산: lenght \\(n\\) vertor version\n\n_netout \n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\n_y = torch.tensor([2,1,2,2,0])\n\n원핫인코딩 안하면 int로 만든 다음에 넣기, float은 또 계산되지 않음!\n\nloss_fn(_netout,_y)\n\ntensor(0.5832)\n\n\n\n\n\n실습: \\(k=2\\)로 두면 이진분류도 가능\n- download data\n\npath = untar_data(URLs.MNIST) \n\ntraining\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1])/255\ny = torch.tensor([0]*len(X0) + [1]*len(X1))#.reshape(-1,1)\n\n\ny_onehot = torch.nn.functional.one_hot(y).float()\n#y_onehot = torch.tensor(list(map(lambda x: [1,0] if x==0 else [0,1],y))).float()\n\nfloat만들어주기 원핫인코딩이기\ntest\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nXX = torch.concat([X0,X1])/255\nyy = torch.tensor([0]*len(X0) + [1]*len(X1))#.reshape(-1,1)\n\n\nyy_onehot = torch.nn.functional.one_hot(yy).float()\n#yy_onehot = torch.tensor(list(map(lambda x: [1,0] if x==0 else [0,1],yy))).float()\n\n\ndls\n\n\nds1 = torch.utils.data.TensorDataset(X,y_onehot) \nds2 = torch.utils.data.TensorDataset(XX,yy_onehot) \ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1862) # 에폭당 11번 iter\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=3147) # \ndls = DataLoaders(dl1,dl2) \n\n\nlrnr\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,2)\n    #torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss()\nlrnr = Learner(dls,net,loss_fn) \n\n\n학습\n\n\nlrnr.fit(10) \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n1.233556\n0.787265\n00:00\n\n\n1\n0.829398\n0.433228\n00:00\n\n\n2\n0.650216\n0.319202\n00:00\n\n\n3\n0.540207\n0.183107\n00:00\n\n\n4\n0.444210\n0.113277\n00:00\n\n\n5\n0.365939\n0.074700\n00:00\n\n\n6\n0.303410\n0.049914\n00:00\n\n\n7\n0.253710\n0.035714\n00:00\n\n\n8\n0.214157\n0.027470\n00:00\n\n\n9\n0.182333\n0.022121\n00:00\n\n\n\n\n\n\n예측 및 시각화\n\n\nlrnr.model.to(\"cpu\")\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=2, bias=True)\n)\n\n\n\nsftmax = torch.nn.Softmax(dim=1) \nsig = torch.nn.Sigmoid()\nfig,ax = plt.subplots(1,2,figsize=(8,4))\nax[0].plot(net(X).diff(axis=1).data,',',color=\"C1\") # u2-u1\nax[1].plot(y)\nax[1].plot(sftmax(net(X))[:,1].data,',')\n#ax[1].plot(sig(net(X).diff(axis=1)).data,',')\nfig.suptitle(\"Training Set\",size=15)\n\nText(0.5, 0.98, 'Training Set')\n\n\n\n\n\n\nfig,ax = plt.subplots(1,2,figsize=(8,4))\nax[0].plot(net(XX).diff(axis=1).data,',',color=\"C1\")\nax[1].plot(yy)\nax[1].plot(sftmax(net(XX))[:,1].data,',')\n#ax[1].plot(sig(net(XX).diff(axis=1)).data,',')\nfig.suptitle(\"Test Set\",size=15)\n\nText(0.5, 0.98, 'Test Set')\n\n\n\n\n\n- note: softmax(u1,u2)=[sig(u1-u2), sig(u2-u1)]=[1-sig(u2-u1),sig(u2-u1)]\n\\(\\frac{1}{e^{u_1}+e^{u_2}} \\to \\frac{e^{u_1-u_2}}{e^{u_1-u_2}+e^{u_2-u_2}} \\to \\frac{e^{u_1-u_2}}{e^{u_1-u_2}+1} \\to sig(u_2-u_1)\\)\n\n\n공부: 이진분류에서 소프트맥스 vs 시그모이드\n- 이진분류문제 = “y=0 or y=1” 을 맞추는 문제 = 성공과 실패를 맞추는 문제 = 성공확률과 실패확률을 추정하는 문제\n- softmax, sigmoid - softmax: (실패확률, 성공확률) 꼴로 결과가 나옴 // softmax는 실패확률과 성공확률을 둘다 추정한다. - sigmoid: (성공확률) 꼴로 결과가 나옴 // sigmoid는 성공확률만 추정한다.\n- 그런데 “실패확률=1-성공확률” 이므로 사실상 둘은 같은걸 추정하는 셈이다. (성공확률만 추정하면 실패확률은 저절로 추정되니까)\n- 아래는 사실상 같은 모형이다.\n\n#collapse\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"?\"\n    \"??\"\n    \"..\"\n    \"???\"\n    label = \"Layer ?\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"?\" -&gt; \"node1\"\n    \"??\" -&gt; \"node1\"\n    \"..\" -&gt; \"node1\"\n    \"???\" -&gt; \"node1\"\n    \n    \"?\" -&gt; \"node2\"\n    \"??\" -&gt; \"node2\"\n    \"..\" -&gt; \"node2\"\n    \"???\" -&gt; \"node2\"\n    \n    \"?\" -&gt; \"...\"\n    \"??\" -&gt; \"...\"\n    \"..\" -&gt; \"...\"\n    \"???\" -&gt; \"...\"\n    \n    \"?\" -&gt; \"node2304\"\n    \"??\" -&gt; \"node2304\"\n    \"..\" -&gt; \"node2304\"\n    \"???\" -&gt; \"node2304\"\n\n    label = \"Layer: ReLU\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -&gt; \"y1\"\n    \"node2\" -&gt; \"y1\"\n    \"...\" -&gt; \"y1\"\n    \"node2304\" -&gt; \"y1\"\n    \n    \"node1\" -&gt; \"y2\"\n    \"node2\" -&gt; \"y2\"\n    \"...\" -&gt; \"y2\"\n    \"node2304\" -&gt; \"y2\"    \n    label = \"Layer: Softmax\"\n}\n''')\n\n\n\n\n\n#collapse\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"?\"\n    \"??\"\n    \"..\"\n    \"???\"\n    label = \"Layer ?\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"?\" -&gt; \"node1\"\n    \"??\" -&gt; \"node1\"\n    \"..\" -&gt; \"node1\"\n    \"???\" -&gt; \"node1\"\n    \n    \"?\" -&gt; \"node2\"\n    \"??\" -&gt; \"node2\"\n    \"..\" -&gt; \"node2\"\n    \"???\" -&gt; \"node2\"\n    \n    \"?\" -&gt; \"...\"\n    \"??\" -&gt; \"...\"\n    \"..\" -&gt; \"...\"\n    \"???\" -&gt; \"...\"\n    \n    \"?\" -&gt; \"node2304\"\n    \"??\" -&gt; \"node2304\"\n    \"..\" -&gt; \"node2304\"\n    \"???\" -&gt; \"node2304\"\n\n    label = \"Layer: ReLU\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -&gt; \"y\"\n    \"node2\" -&gt; \"y\"\n    \"...\" -&gt; \"y\"\n    \"node2304\" -&gt; \"y\"\n    label = \"Layer: Sigmoid\"\n}\n''')\n\n\n\n\n- 둘은 사실상 같은 효과를 주는 모형인데 학습할 파라메터는 sigmoid의 경우가 더 적다. \\(\\to\\) sigmoid를 사용하는 모형이 비용은 싸고(학습할 파라메터가 적음) 효과는 동일하다는 말 \\(\\to\\) 이진분류 한정해서는 softmax를 쓰지말고 sigmoid를 써야함. - softmax가 갑자기 너무 안좋아보이는데 sigmoid는 k개의 클래스로 확장이 불가능한 반면 softmax는 확장이 용이하다는 장점이 있음\n\n\n소프트맥스 vs 시그모이드 정리\n- 결론 1. 소프트맥스는 시그모이드의 확장이다. 2. 클래스의 수가 2개일 경우에는 (Sigmoid, BCEloss) 조합을 사용해야 하고 클래스의 수가 2개보다 클 경우에는 (Softmax, CrossEntropyLoss) 를 사용해야 한다.\n- 그런데 사실.. 클래스의 수가 2개일 경우일때 (Softmax, CrossEntropyLoss)를 사용해도 그렇게 큰일나는것은 아니다. (흑백이미지를 칼라잉크로 출력하는 느낌)\n참고\n\n\n\n\\(y\\)\n분포가정\n마지막층의 활성화함수\n손실함수\n\n\n\n\n3.45, 4.43, … (연속형)\n정규분포\nNone (or Identity)\nMSE\n\n\n0 or 1\n이항분포 with \\(n=1\\) (=베르누이)\nSigmoid\nBCE\n\n\n[0,0,1], [0,1,0], [1,0,0]\n다항분포 with \\(n=1\\)\nSoftmax\nCross Entropy"
  },
  {
    "objectID": "posts/ml/2022-10-26-ml_8w_1.html#fastai-metric-사용",
    "href": "posts/ml/2022-10-26-ml_8w_1.html#fastai-metric-사용",
    "title": "CNN (8주차) 1",
    "section": "fastai metric 사용",
    "text": "fastai metric 사용\n\n데이터준비\n- download data\n\npath = untar_data(URLs.MNIST)\n\n- training set\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1])/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n- test set\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nXX = torch.concat([X0,X1])/255\nyy = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\nX.shape,XX.shape,y.shape,yy.shape\n\n(torch.Size([12665, 1, 28, 28]),\n torch.Size([2115, 1, 28, 28]),\n torch.Size([12665, 1]),\n torch.Size([2115, 1]))\n\n\n\n\n사용자정의 메트릭이용\n\ndls 만들기\n\n\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \ndls = DataLoaders(dl1,dl2) \n\n\nlrnr 생성\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss() \n\n\ndef acc(yhat,y) : \n    return ((yhat&gt;0.5)==y).float().mean()\n\n\ndef err(yhat,y):\n    return 1-((yhat&gt;0.5)==y).float().mean()\n\n\nlrnr = Learner(dls,net,loss_fn,metrics=[acc,err])\n\n\n학습\n\n\nlrnr.fit(10)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nacc\nerr\ntime\n\n\n\n\n0\n1.012566\n0.676096\n0.463357\n0.536643\n00:00\n\n\n1\n0.738655\n0.477148\n0.994799\n0.005201\n00:00\n\n\n2\n0.603908\n0.335415\n0.985816\n0.014184\n00:00\n\n\n3\n0.497049\n0.183633\n0.995745\n0.004255\n00:00\n\n\n4\n0.394664\n0.097668\n0.995745\n0.004255\n00:00\n\n\n5\n0.309929\n0.056333\n0.995745\n0.004255\n00:00\n\n\n6\n0.244836\n0.037147\n0.995745\n0.004255\n00:00\n\n\n7\n0.195441\n0.027278\n0.995745\n0.004255\n00:00\n\n\n8\n0.157570\n0.021531\n0.995745\n0.004255\n00:00\n\n\n9\n0.128163\n0.017795\n0.997163\n0.002837\n00:00\n\n\n\n\n\n\n예측\n\n\n생략\n\n\n\nfastai지원 메트릭이용– 잘못된사용\n\ndls 만들기\n\n\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \ndls = DataLoaders(dl1,dl2) \n\n\nlrnr 생성\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\nlrnr = Learner(dls,net,loss_fn,metrics=[accuracy,error_rate])\n\n\naccuracy??\n\n\nSignature: accuracy(inp, targ, axis=-1)\nSource:   \ndef accuracy(inp, targ, axis=-1):\n    \"Compute accuracy with `targ` when `pred` is bs * n_classes\"\n    pred,targ = flatten_check(inp.argmax(dim=axis), targ)\n    return (pred == targ).float().mean()\nFile:      ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/metrics.py\nType:      function\n\n\n\n\n\nerror_rate??\n\n\nSignature: error_rate(inp, targ, axis=-1)\nSource:   \ndef error_rate(inp, targ, axis=-1):\n    \"1 - `accuracy`\"\n    return 1 - accuracy(inp, targ, axis=axis)\nFile:      ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/metrics.py\nType:      function\n\n\n\n\n\n학습\n\n\nlrnr.fit(10)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\nerror_rate\ntime\n\n\n\n\n0\n0.971997\n0.616424\n0.463357\n0.536643\n00:00\n\n\n1\n0.671642\n0.380434\n0.463357\n0.536643\n00:00\n\n\n2\n0.525948\n0.232161\n0.463357\n0.536643\n00:00\n\n\n3\n0.414203\n0.123899\n0.463357\n0.536643\n00:00\n\n\n4\n0.322394\n0.071857\n0.463357\n0.536643\n00:00\n\n\n5\n0.252299\n0.045784\n0.463357\n0.536643\n00:00\n\n\n6\n0.199783\n0.032276\n0.463357\n0.536643\n00:00\n\n\n7\n0.160118\n0.024500\n0.463357\n0.536643\n00:00\n\n\n8\n0.129659\n0.019576\n0.463357\n0.536643\n00:00\n\n\n9\n0.105914\n0.016207\n0.463357\n0.536643\n00:00\n\n\n\n\n\n\n이상하다..?\n\n\n예측\n\n\nlrnr.model.to(\"cpu\")\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n  (5): Sigmoid()\n)\n\n\n\nplt.plot(yy)\nplt.plot(lrnr.model(XX).data,'.')\n\n\n\n\n\n맞추는건 잘 맞추는데?\n\n\n\nfastai지원 메트릭이용– 올바른 사용(1)\n- 가정 - X의 형태는 (n,채널,픽셀,픽셀)로 가정한다. - y의 형태는 (n,) 벡터이다. 즉 \\(n\\times 1\\) 이 아니라 그냥 길이가 \\(n\\)인 벡터로 가정한다. - y의 각 원소는 0,1,2,3,… 와 같이 카테고리를 의미하는 숫자이어야 하며 이 숫자는 int형으로 저장되어야 한다. - loss function은 CrossEntropyLoss()를 쓴다고 가정한다. (따라서 네트워크의 최종레이어는 torch.nn.Linear(?,클래스의수) 꼴이 되어야 한다.)\n\ndls 만들기\n\n지원하는 함수로 바꿔주기\n\ny.to(torch.int64).reshape(-1),yy.to(torch.int64).reshape(-1)\n\n(tensor([0, 0, 0,  ..., 1, 1, 1]), tensor([0, 0, 0,  ..., 1, 1, 1]))\n\n\n\nds1 = torch.utils.data.TensorDataset(X,y.to(torch.int64).reshape(-1))\nds2 = torch.utils.data.TensorDataset(XX,yy.to(torch.int64).reshape(-1))\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \ndls = DataLoaders(dl1,dl2) \n\n\nlrnr 생성\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,2),\n)\nloss_fn = torch.nn.CrossEntropyLoss()\nlrnr = Learner(dls,net,loss_fn,metrics=[accuracy,error_rate])\n\n\n학습\n\n\nlrnr.fit(10)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\nerror_rate\ntime\n\n\n\n\n0\n1.038122\n0.539247\n0.463357\n0.536643\n00:00\n\n\n1\n0.621439\n0.261176\n0.977778\n0.022222\n00:00\n\n\n2\n0.451623\n0.118811\n0.989125\n0.010875\n00:00\n\n\n3\n0.333172\n0.059299\n0.995272\n0.004728\n00:00\n\n\n4\n0.250918\n0.037678\n0.996217\n0.003783\n00:00\n\n\n5\n0.193416\n0.026810\n0.996217\n0.003783\n00:00\n\n\n6\n0.152078\n0.020631\n0.996217\n0.003783\n00:00\n\n\n7\n0.121511\n0.016605\n0.996690\n0.003310\n00:00\n\n\n8\n0.098301\n0.013718\n0.997636\n0.002364\n00:00\n\n\n9\n0.080287\n0.011546\n0.998109\n0.001891\n00:00\n\n\n\n\n\n\n\nfastai지원 메트릭이용– 올바른 사용(2)\n- 가정 - X의 형태는 (n,채널,픽셀,픽셀)로 가정한다. - y의 형태는 (n,클래스의수)로 가정한다. 즉 y가 one_hot 인코딩된 형태로 가정한다. - y의 각 원소는 0 혹은 1이다. - loss function은 CrossEntropyLoss()를 쓴다고 가정한다. (따라서 네트워크의 최종레이어는 torch.nn.Linear(?,클래스의수) 꼴이 되어야 한다.)\n\ndls 만들기\n\n\ny_onehot = torch.tensor(list(map(lambda x: [1.0,0.0] if x==0 else [0.0,1.0], y)))\nyy_onehot = torch.tensor(list(map(lambda x: [1.0,0.0] if x==0 else [0.0,1.0], yy)))\n# y_onehot = torch.nn.functional.one_hot(y.reshape(-1).to(torch.int64)).to(torch.float32)\n# yy_onehot = torch.nn.functional.one_hot(yy.reshape(-1).to(torch.int64)).to(torch.float32)\n\n\nds1 = torch.utils.data.TensorDataset(X,y_onehot)\nds2 = torch.utils.data.TensorDataset(XX,yy_onehot)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \ndls = DataLoaders(dl1,dl2) \n\n\nlrnr 생성\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,2),\n    #torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=[accuracy_multi])\n\naccuracy_multi\n\n학습\n\n\nlrnr.fit(10)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy_multi\ntime\n\n\n\n\n0\n1.038750\n0.569555\n0.463357\n00:00\n\n\n1\n0.640057\n0.285553\n0.977778\n00:00\n\n\n2\n0.469265\n0.137582\n0.987943\n00:00\n\n\n3\n0.348698\n0.064898\n0.995035\n00:00\n\n\n4\n0.262547\n0.038338\n0.996217\n00:00\n\n\n5\n0.201805\n0.025988\n0.996690\n00:00\n\n\n6\n0.158089\n0.019443\n0.996927\n00:00\n\n\n7\n0.125811\n0.015470\n0.997163\n00:00\n\n\n8\n0.101381\n0.012772\n0.998109\n00:00\n\n\n9\n0.082515\n0.010802\n0.998582\n00:00"
  },
  {
    "objectID": "posts/ml/2022-12-14-study.html",
    "href": "posts/ml/2022-12-14-study.html",
    "title": "study",
    "section": "",
    "text": "study"
  },
  {
    "objectID": "posts/ml/2022-12-14-study.html#임베딩",
    "href": "posts/ml/2022-12-14-study.html#임베딩",
    "title": "study",
    "section": "임베딩",
    "text": "임베딩\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 0, 1, 0]), tensor([1, 0, 1, 0, 1]))\n\n\n\nclass mynet2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.l1 = torch.nn.Embedding(num_embeddings=2,embedding_dim=1)\n        self.a1 = torch.nn.Tanh()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=2)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        yhat = self.l2(self.a1(self.l1(x)))\n        ## 정의 끝\n        return yhat\n\n\nnet = mynet2()\n\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    yhat = net(x)\n    loss = loss_fn(yhat,y)\n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad()"
  },
  {
    "objectID": "posts/ml/2022-12-14-study.html#두-개의-은닉노드-이용",
    "href": "posts/ml/2022-12-14-study.html#두-개의-은닉노드-이용",
    "title": "study",
    "section": "두 개의 은닉노드 이용",
    "text": "두 개의 은닉노드 이용\n\ntxt = list('abcd')*100\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'a':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 0]), tensor([1, 2, 3, 0, 1]))\n\n\n\nl1=torch.nn.Embedding(num_embeddings=4,embedding_dim=2)\n\n\na1 = torch.nn.Tanh()\n\n\nl2 = torch.nn.Linear(in_features=2,out_features=4)\n\n\nnet = torch.nn.Sequential(\n    l1,a1,l2)\n\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    yhat=net(x)\n    loss = loss_fn(yhat,y)\n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nnet[:-1]\n\nSequential(\n  (0): Embedding(4, 2)\n  (1): Tanh()\n)\n\n\n결과 시각화 코드 10주"
  },
  {
    "objectID": "posts/ml/2022-12-14-study.html#순환신경망-class-사용-rnn",
    "href": "posts/ml/2022-12-14-study.html#순환신경망-class-사용-rnn",
    "title": "study",
    "section": "순환신경망 Class 사용 RNN",
    "text": "순환신경망 Class 사용 RNN\n10주\n\ntxt = list('AbAcAd')*100\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\nx = torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))\nx= torch.nn.functional.one_hot(x).float()\ny= torch.nn.functional.one_hot(y).float()\n\n\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(4,2) \n        self.h2h = torch.nn.Linear(2,2) \n        self.tanh = torch.nn.Tanh()\n    def forward(self,x,hidden):\n        hidden = self.tanh(self.i2h(x)+self.h2h(hidden))\n        return hidden\n\n\ntorch.manual_seed(43052)\nrnncell = rNNCell()\n\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n\nT = len(x) \nfor epoc in range(100): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) \n        ot = cook(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n시각화코드는 10주_순환신경망구현1-성공에"
  },
  {
    "objectID": "posts/ml/2022-12-14-study.html#순환신경망-rnn",
    "href": "posts/ml/2022-12-14-study.html#순환신경망-rnn",
    "title": "study",
    "section": "순환신경망 RNN",
    "text": "순환신경망 RNN\n\ntxt = list('AbAcAd')*100\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))).float()\n\n\ntorch.manual_seed(2) #1 \nrnn = torch.nn.RNN(4,3).to(\"cuda:0\") \ncook = torch.nn.Linear(3,4).to(\"cuda:0\")\n\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters()))\n\n\n_water = torch.zeros(1,3).to(\"cuda:0\") \nfor epoc in range(500):\n    ## 1\n    hidden,hT = rnn(x.to(\"cuda:0\"),_water) \n    output = cook(hidden) \n    ## 2 \n    loss = loss_fn(output,y.to(\"cuda:0\")) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)"
  },
  {
    "objectID": "posts/ml/2022-12-14-study.html#순환신경망-class-사용-lstm",
    "href": "posts/ml/2022-12-14-study.html#순환신경망-class-사용-lstm",
    "title": "study",
    "section": "순환신경망 Class 사용 LSTM",
    "text": "순환신경망 Class 사용 LSTM\n\ntxt = list('hi?hello!!')*100 \ntxt_x = txt[:-1]\ntxt_y = txt[1:]\nmapping = {'!':0, '?':1,'h':2,'i':3,'e':4,'l':5,'o':6} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")\n\n\nclass lSTMCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(7,16)\n        self.h2h = torch.nn.Linear(4,16) \n        self.tanh = torch.nn.Tanh()\n    def forward(self,xt,past):\n        ht,ct = past \n        ifgo = self.i2h(xt) + self.h2h(ht) \n        it = sig(ifgo[0:4])\n        ft = sig(ifgo[4:8])\n        gt = tanh(ifgo[8:12])\n        ot = sig(ifgo[12:16])\n        ct = ft*ct + it*gt\n        ht = ot*self.tanh(ct) \n        return ht,ct\n\n\nlstmcell = lSTMCell().to(\"cuda:0\")\nlinr = torch.nn.Linear(4,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstmcell.parameters())+list(linr.parameters()),lr=0.1)\n\n\n# 초기값셋팅\ntorch.manual_seed(43052) \n_lstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\")\n_linr = torch.nn.Linear(4,7).to(\"cuda:0\")\nlstmcell.i2h.weight.data = _lstmcell.weight_ih.data \nlstmcell.h2h.weight.data = _lstmcell.weight_hh.data \nlstmcell.i2h.bias.data = _lstmcell.bias_ih.data\nlstmcell.h2h.bias.data = _lstmcell.bias_hh.data\nlinr.weight.data = _linr.weight.data \nlinr.bias.data = _linr.bias.data \n\n\nfor epoc in range(10):\n    ## 1\n    hidden = []     \n    ht = torch.zeros(4).to(\"cuda:0\")\n    ct = torch.zeros(4).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht,ct = lstmcell(xt,(ht,ct))\n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\n\n\nyhat\n\ntensor([[0.0909, 0.0859, 0.0356,  ..., 0.1820, 0.2308, 0.1257],\n        [0.3443, 0.1629, 0.2108,  ..., 0.1008, 0.0506, 0.0774],\n        [0.3998, 0.0325, 0.5100,  ..., 0.0133, 0.0269, 0.0119],\n        ...,\n        [0.0655, 0.0525, 0.0455,  ..., 0.1652, 0.2569, 0.2828],\n        [0.3850, 0.0844, 0.3754,  ..., 0.0464, 0.0423, 0.0478],\n        [0.4012, 0.0217, 0.5328,  ..., 0.0084, 0.0254, 0.0065]],\n       device='cuda:0', grad_fn=&lt;SoftmaxBackward0&gt;)"
  },
  {
    "objectID": "posts/ml/2022-12-14-study.html#순환신경망-lstm",
    "href": "posts/ml/2022-12-14-study.html#순환신경망-lstm",
    "title": "study",
    "section": "순환신경망 LSTM",
    "text": "순환신경망 LSTM\n\ntxt = (['one',',','two',',','three',',','four',',','five',',']*100)[:-1]\nmapping = {',':0, 'one':1, 'two':2, 'three':3, 'four':4, 'five':5} \ntxt_x = txt[:-1]\ntxt_y = txt[1:] \nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")\n\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(6,20).to(\"cuda:0\") \nlinr = torch.nn.Linear(20,6).to(\"cuda:0\") \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\n_water = torch.zeros(1,20).to(\"cuda:0\")\nfor epoc in range(50):\n    ## 1 \n    hidden, (hT,cT) =lstm(x,(_water,_water))\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()     \n\n\nsoft(output)\n\ntensor([[9.9875e-01, 1.5434e-06, 6.5715e-04, 1.8973e-05, 9.5753e-05, 4.7651e-04],\n        [3.0184e-06, 3.7971e-05, 9.8694e-01, 3.6741e-03, 3.6129e-04, 8.9867e-03],\n        [9.9999e-01, 2.9932e-06, 5.9745e-07, 8.3266e-06, 1.0668e-07, 4.8888e-07],\n        ...,\n        [3.9604e-05, 8.6161e-06, 1.5918e-03, 1.1244e-07, 9.9808e-01, 2.7556e-04],\n        [9.9993e-01, 3.3252e-07, 9.5155e-06, 4.8129e-07, 2.7274e-05, 3.2102e-05],\n        [8.0918e-07, 8.0716e-03, 5.9763e-04, 7.7044e-05, 6.8931e-05, 9.9118e-01]],\n       device='cuda:0', grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\n조각난 시계열\n12주차\n\ntxt = list('hi!')*3 + list('hi?')*3\ntxt_x = txt[:-1] \ntxt_y = txt[1:] \nmapping = {'!':0, '?':1, 'h':2, 'i':3} \nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\") \n\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\nlinr = torch.nn.Linear(10,4).to(\"cuda:0\")\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1 \n    hidden, _ = lstm(x) \n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nhidden, _ = lstm(x)\nplt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f1462eb7510&gt;\n\n\n\n\n\n\ntxt = list('hi!')*3 + list('hi?')*3\ntxt1= txt[:9]\ntxt2= txt[9:]\ntxt1_x = txt1[:-1] \ntxt1_y = txt1[1:] \ntxt2_x = txt2[:-1] \ntxt2_y = txt2[1:] \nmapping = {'!':0, '?':1, 'h':2, 'i':3} \nx1 = torch.nn.functional.one_hot(torch.tensor(f(txt1_x,mapping))).float().to(\"cuda:0\")\ny1 = torch.nn.functional.one_hot(torch.tensor(f(txt1_y,mapping))).float().to(\"cuda:0\")\nx2 = torch.nn.functional.one_hot(torch.tensor(f(txt2_x,mapping))).float().to(\"cuda:0\")\ny2 = torch.nn.functional.one_hot(torch.tensor(f(txt2_y,mapping))).float().to(\"cuda:0\")\nxx = torch.stack([x1,x2],axis=1)\nyy = torch.stack([y1,y2],axis=1)\n\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\nlinr = torch.nn.Linear(10,4).to(\"cuda:0\")\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1 \n    hidden, _ = lstm(xx) \n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output[:,0,:],yy[:,0,:]) + loss_fn(output[:,1,:],yy[:,1,:])\n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nfig , ax = plt.subplots(1,2) \nax[0].matshow(soft(output[:,0,:]).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\nax[1].matshow(soft(output[:,1,:]).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f1462e93690&gt;"
  },
  {
    "objectID": "posts/ml/2022-09-14-ml_2w.html",
    "href": "posts/ml/2022-09-14-ml_2w.html",
    "title": "DNN (2주차)",
    "section": "",
    "text": "기계학습 특강 (2주차) 9월14일 [추천시스템, 텍스트분석, GAN]"
  },
  {
    "objectID": "posts/ml/2022-09-14-ml_2w.html#imports",
    "href": "posts/ml/2022-09-14-ml_2w.html#imports",
    "title": "DNN (2주차)",
    "section": "imports",
    "text": "imports\n\n#\nfrom fastai.collab import * ## 추천시스템\nfrom fastai.text.all import * ## 텍스트분석 \nfrom fastai.vision.all import *  ## GAN (이미지분석) \nfrom fastai.vision.gan import * ## GAN (이미지생성)\n\n\nimport pandas as pd"
  },
  {
    "objectID": "posts/ml/2022-09-14-ml_2w.html#이미지-자료분석-실습-지난시간-복습",
    "href": "posts/ml/2022-09-14-ml_2w.html#이미지-자료분석-실습-지난시간-복습",
    "title": "DNN (2주차)",
    "section": "이미지 자료분석 실습 (지난시간 복습)",
    "text": "이미지 자료분석 실습 (지난시간 복습)\n\n1단계: 데이터의 정리\n\npath = untar_data(URLs.PETS)/'images'\n\n\npath.ls()\n\n(#7393) [Path('/home/csy/.fastai/data/oxford-iiit-pet/images/Bombay_13.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/beagle_193.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/Ragdoll_8.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/boxer_106.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/keeshond_56.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_162.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/saint_bernard_136.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_76.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/pug_173.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_117.jpg')...]\n\n\nevery files’ list\n\nfnames = get_image_files(path)\n\n\nfnames\n\n(#7390) [Path('/home/csy/.fastai/data/oxford-iiit-pet/images/Bombay_13.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/beagle_193.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/Ragdoll_8.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/boxer_106.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/keeshond_56.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_162.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/saint_bernard_136.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_76.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/pug_173.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_117.jpg')...]\n\n\nimage files’ list\n\nImageDataLoaders.from_name_func??\n\n\nSignature:\nImageDataLoaders.from_name_func(\n    path,\n    fnames,\n    label_func,\n    valid_pct=0.2,\n    seed=None,\n    item_tfms=None,\n    batch_tfms=None,\n    bs=64,\n    val_bs=None,\n    shuffle=True,\n    device=None,\n)\nSource:   \n    @classmethod\n    def from_name_func(cls, path, fnames, label_func, **kwargs):\n        \"Create from the name attrs of `fnames` in `path`s with `label_func`\"\n        if sys.platform == 'win32' and isinstance(label_func, types.LambdaType) and label_func.__name__ == '&lt;lambda&gt;':\n            # https://medium.com/@jwnx/multiprocessing-serialization-in-python-with-pickle-9844f6fa1812\n            raise ValueError(\"label_func couldn't be lambda function on Windows\")\n        f = using_attr(label_func, 'name')\n        return cls.from_path_func(path, fnames, f, **kwargs)\nFile:      ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/vision/data.py\nType:      method\n\n\n\n\ndef f(fname):\n    if fname[0].isupper():\n        return 'cat'\n    else:\n        return 'dog'\nf(x) = x+ 1\nlambda x : x+1\n\nfnames[0]\n\nPath('/home/csy/.fastai/data/oxford-iiit-pet/images/Bombay_13.jpg')\n\n\n\nf = lambda fname: 'cat' if fname[0].isupper() else 'dog'\n\n\nf('s')\n\n'dog'\n\n\n\nf('D')\n\n'cat'\n\n\ndls = ImageDataLoaders.from_name_func(\n    path, \n    fnames,\n    lambda fname: 'cat' if fname[0].isupper() else 'dog'\n    item_tfms=Resize(224)) \n\ndls = ImageDataLoaders.from_name_func(\n    path, \n    fnames,\n    f, # f대신 (lambda fname: 'cat' if fname[0].isupper() else 'dog') 를 넣어도 가능\n    item_tfms=Resize(224)) # 사이즈가 달라서 통일\n\n\ndls.show_batch()\n\n\n\n\n\n\n2단계: lrnr 오브젝트 생성\n\ncnn_learner??\n\n\nSignature:\ncnn_learner(\n    dls,\n    arch,\n    normalize=True,\n    n_out=None,\n    pretrained=True,\n    config=None,\n    loss_func=None,\n    opt_func=&lt;function Adam at 0x7fcb70042550&gt;,\n    lr=0.001,\n    splitter=None,\n    cbs=None,\n    metrics=None,\n    path=None,\n    model_dir='models',\n    wd=None,\n    wd_bn_bias=False,\n    train_bn=True,\n    moms=(0.95, 0.85, 0.95),\n    cut=None,\n    n_in=3,\n    init=&lt;function kaiming_normal_ at 0x7fcbc439a8b0&gt;,\n    custom_head=None,\n    concat_pool=True,\n    lin_ftrs=None,\n    ps=0.5,\n    first_bn=True,\n    bn_final=False,\n    lin_first=False,\n    y_range=None,\n)\nSource:   \n@delegates(create_cnn_model)\ndef cnn_learner(dls, arch, normalize=True, n_out=None, pretrained=True, config=None,\n                # learner args\n                loss_func=None, opt_func=Adam, lr=defaults.lr, splitter=None, cbs=None, metrics=None, path=None,\n                model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95,0.85,0.95),\n                # other model args\n                **kwargs):\n    \"Build a convnet style learner from `dls` and `arch`\"\n    if config:\n        warnings.warn('config param is deprecated. Pass your args directly to cnn_learner.')\n        kwargs = {**config, **kwargs}\n    meta = model_meta.get(arch, _default_meta)\n    if normalize: _add_norm(dls, meta, pretrained)\n    if n_out is None: n_out = get_c(dls)\n    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n    model = create_cnn_model(arch, n_out, pretrained=pretrained, **kwargs)\n    splitter=ifnone(splitter, meta['split'])\n    learn = Learner(dls=dls, model=model, loss_func=loss_func, opt_func=opt_func, lr=lr, splitter=splitter, cbs=cbs,\n                   metrics=metrics, path=path, model_dir=model_dir, wd=wd, wd_bn_bias=wd_bn_bias, train_bn=train_bn,\n                   moms=moms)\n    if pretrained: learn.freeze()\n    # keep track of args for loggers\n    store_attr('arch,normalize,n_out,pretrained', self=learn, **kwargs)\n    return learn\nFile:      ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/vision/learner.py\nType:      function\n\n\n\n\n!cat ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/vision/learner.py\n이 코드로 존재하는 함수의 정의 확인 가능\n어디 소속된 함수인지 확인 하기 위해\nfastai에 소속된 cnn_leaner,따라서 fastai를 import해야 나타나지.\n\nlrnr = cnn_learner(dls,resnet34,metrics=error_rate)\n\n\nlrnr.dls.show_batch()\n\n\n\n\n\nid(lrnr.dls)\n\n140510181797744\n\n\n\nid(dls)\n\n140510181797744\n\n\n주소가 같다. 같은 역할\nlrnr에 dls가 소속되어 있다고 생각(?) - 포스트잇을 위에 덧붙인다 생각\n\n\n3단계: lrnr.학습()\n학습하는 fine_tune 이외에 여러가지 있음 - fine_tune 학습된 일부는 유지하고 바꿀 부분만 학습시키는 법: transfer learning\nfor exampel: cnn의 1d에서는 끝에만 학습\n\nlrnr.fine_tune(1)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.155603\n0.014394\n0.006766\n00:10\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.051081\n0.008424\n0.002706\n00:11\n\n\n\n\n\n\nfine_tune()은 모든 가중치를 학습하는 것이 아니라 일부만 학습하는 것임.\nfine_tune()이외이 방법으로 학습할 수도 있음.\n\n\n\n4단계: lrnr.예측()\n(방법1) lrnr.predict() 함수를 이용\n\nlrnr.predict('2022-09-07-dogs.jpeg') # 방법1-1\n#lrnr.predict(PILImage.create('2022-09-07-dogs.jpeg')) # 방법1-2\n#lrnr.predict(path.ls()[0]) # 방법1-3\n\n\n\n\n('dog', TensorBase(1), TensorBase([2.2932e-05, 9.9998e-01]))\n\n\n컴퓨터가 이해하기 쉬운 방법인 1-2번째 방법\n\nlrnr.predict(PILImage.create('2022-09-07-dogs.jpeg'))\n\n\n\n\n('dog', TensorBase(1), TensorBase([2.2932e-05, 9.9998e-01]))\n\n\n\nlrnr.predict(path.ls()[1])\n\n\n\n\n('dog', TensorBase(1), TensorBase([2.4945e-08, 1.0000e+00]))\n\n\n\ndir(lrnr.model)\ndirectory에 _call_있으면 함수처럼 사용 가능\n\n(방법2) lrnr.model(X) 를 이용: X의 shape이 (?,3,224,224)의 형태의 텐서이어야함\n\ntype(dls.one_batch())\n\ntuple\n\n\n끝에 괄호로 묶여 있으면 tuple\n\nX,y = dls.one_batch() # 방법2\nlrnr.model(X[0:1]) \n\nTensorBase([[-8.3588,  7.0462]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\nX[1].shape\n\ntorch.Size([3, 224, 224])\n\n\n\nX[:2].shape\n\ntorch.Size([2, 3, 224, 224])\n\n\n\nX.shape\n\ntorch.Size([64, 3, 224, 224])\n\n\nimage의 사이즈 224 * 224 - 3개의 채널 - 64개 - image, 입력\n\ny.shape\n\ntorch.Size([64])\n\n\n\n예측값\n\n\ny[:3]\n\nTensorCategory([1, 1, 0], device='cuda:0')\n\n\nlrnr.model(X[0])\n오류 뜬다. - torch.Size([3, 224, 224]) - shape을 - torch.Size([?, 3, 224, 224]) - 이런 식으로 만들어주자, 입력\n\nlrnr.model(X[:3])\n\nTensorBase([[ -8.3605,   7.0472],\n        [ -4.4236,   5.1110],\n        [ 14.0977, -13.0582]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\nlrnr.model(X)\n\nTensorBase([[ -8.3595,   7.0465],\n        [ -4.4246,   5.1111],\n        [ 14.0959, -13.0577],\n        [ -6.4868,   7.2289],\n        [ -3.4974,   2.0202],\n        [ -7.1135,   6.2276],\n        [ -4.2407,   2.9429],\n        [ -7.0260,   6.4789],\n        [ -6.5011,   5.1029],\n        [ -7.4927,   4.9038],\n        [ -5.7292,   5.0113],\n        [ -9.6244,   5.7399],\n        [ -6.8247,   3.4742],\n        [ 17.2742, -12.6829],\n        [ -4.0548,   2.6589],\n        [ 16.3894, -14.2360],\n        [ -3.8864,   5.6632],\n        [ -5.1192,   6.0355],\n        [ 11.3016, -13.4798],\n        [ -8.1850,   7.5925],\n        [  8.3147,  -5.9946],\n        [ -8.0415,   8.4349],\n        [ -9.6461,   8.3790],\n        [ -5.4923,   5.8070],\n        [ 12.1504,  -9.3661],\n        [ -7.7945,   6.7907],\n        [ -5.0291,   3.4955],\n        [ 13.8045, -11.3889],\n        [ -4.5400,   5.1561],\n        [ 16.5360, -13.3928],\n        [ -4.0467,   3.3478],\n        [ -5.8401,   7.2492],\n        [  6.9878,  -4.8408],\n        [ -8.0189,   6.0578],\n        [ -7.7578,   4.7063],\n        [ -5.0351,   4.5309],\n        [  6.0511,  -4.1623],\n        [ -8.4919,   8.1300],\n        [ -5.9893,   5.8341],\n        [ -7.0671,   6.2901],\n        [ 17.0369, -13.7746],\n        [ -6.7633,   5.5232],\n        [ -7.3533,   7.6700],\n        [ -8.3923,   6.6368],\n        [ 13.2212, -10.2649],\n        [ 14.7573, -11.7938],\n        [ -6.6409,   5.6934],\n        [ -6.5882,   4.9800],\n        [ -5.2839,   5.3899],\n        [ -5.7066,   4.9765],\n        [ -5.8099,   3.8355],\n        [ -8.5055,   7.2022],\n        [ -8.7006,   4.5980],\n        [ -5.4901,   4.5288],\n        [ -7.6612,   7.1533],\n        [ 15.9380, -16.2778],\n        [  7.9763,  -7.1954],\n        [ 13.4158, -10.9864],\n        [ -4.9234,   2.9219],\n        [ -4.0274,   4.1298],\n        [ 16.8217, -16.0985],\n        [ -8.6418,   7.1085],\n        [ -5.9216,   6.0076],\n        [ -5.3720,   3.9876]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\\(y\\) : 왼쪽이 크면 0, 오른쪽이 크면 1 - 둘다 음수인 건 없네? - 왼쪽이 양수면 0 오른쪽이 양수면 1로 생각 가능하겠다."
  },
  {
    "objectID": "posts/ml/2022-09-14-ml_2w.html#프로그래밍-과정",
    "href": "posts/ml/2022-09-14-ml_2w.html#프로그래밍-과정",
    "title": "DNN (2주차)",
    "section": "프로그래밍 과정",
    "text": "프로그래밍 과정\n\n프로그래밍 과정 overview\n- overview\n\ndls 오브젝트 생성\nlrnr 오브젝트 생성\nlrnr.학습()\nlrnr.예측()\n\n\n\n이미지분석, 추천시스템, 텍스트분석, GAN 분석과정 비교\n- 비교\n\n\n\n\n\n\n\n\n\n\n\n이미지분석(CNN)\n추천시스템\n텍스트분석\nGAN\n\n\n\n\n1단계\nImageDataLoaders\nCollabDataLoaders\nTextDataLoaders\nDataBlock -&gt; dls\n\n\n2단계\ncnn_learner()\ncollab_learner()\nlanguage_model_learner()\nGANLearner.wgan()\n\n\n3단계\nlrnr.fine_tune(1)\nlrnr.fit()\nlrnr.fit()\nlrnr.fit()\n\n\n4단계\nlrnr.predict(), lrnr.model(X)\nlrnr.model(X)\nlrnr.predict()"
  },
  {
    "objectID": "posts/ml/2022-09-14-ml_2w.html#추천시스템-실습",
    "href": "posts/ml/2022-09-14-ml_2w.html#추천시스템-실습",
    "title": "DNN (2주차)",
    "section": "추천시스템 실습",
    "text": "추천시스템 실습\n\n1단계\ngithub에서 해당 파일의 raw click하여 주소 가져오기\n!wget https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_view.csv\n위와 같이 wget사용하면 주소의 data 바로 다운 가능\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_view.csv')\ndf_view\n\n\n\n\n\n\n\n\n커피1\n커피2\n커피3\n커피4\n커피5\n커피6\n커피7\n커피8\n커피9\n커피10\n홍차1\n홍차2\n홍차3\n홍차4\n홍차5\n홍차6\n홍차7\n홍차8\n홍차9\n홍차10\n\n\n\n\n0\n4.149209\nNaN\nNaN\n4.078139\n4.033415\n4.071871\nNaN\nNaN\nNaN\nNaN\n1.142659\n1.109452\nNaN\n0.603118\n1.084308\nNaN\n0.906524\nNaN\nNaN\n0.903826\n\n\n1\n4.031811\nNaN\nNaN\n3.822704\nNaN\nNaN\nNaN\n4.071410\n3.996206\nNaN\nNaN\n0.839565\n1.011315\nNaN\n1.120552\n0.911340\nNaN\n0.860954\n0.871482\nNaN\n\n\n2\n4.082178\n4.196436\nNaN\n3.956876\nNaN\nNaN\nNaN\n4.450931\n3.972090\nNaN\nNaN\nNaN\nNaN\n0.983838\nNaN\n0.918576\n1.206796\n0.913116\nNaN\n0.956194\n\n\n3\nNaN\n4.000621\n3.895570\nNaN\n3.838781\n3.967183\nNaN\nNaN\nNaN\n4.105741\n1.147554\nNaN\n1.346860\nNaN\n0.614099\n1.297301\nNaN\nNaN\nNaN\n1.147545\n\n\n4\nNaN\nNaN\nNaN\nNaN\n3.888208\nNaN\n3.970330\n3.979490\nNaN\n4.010982\nNaN\n0.920995\n1.081111\n0.999345\nNaN\n1.195183\nNaN\n0.818332\n1.236331\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n95\n0.511905\n1.066144\nNaN\n1.315430\nNaN\n1.285778\nNaN\n0.678400\n1.023020\n0.886803\nNaN\n4.055996\nNaN\nNaN\n4.156489\n4.127622\nNaN\nNaN\nNaN\nNaN\n\n\n96\nNaN\n1.035022\nNaN\n1.085834\nNaN\n0.812558\nNaN\n1.074543\nNaN\n0.852806\n3.894772\nNaN\n4.071385\n3.935935\nNaN\nNaN\n3.989815\nNaN\nNaN\n4.267142\n\n\n97\nNaN\n1.115511\nNaN\n1.101395\n0.878614\nNaN\nNaN\nNaN\n1.329319\nNaN\n4.125190\nNaN\n4.354638\n3.811209\n4.144648\nNaN\nNaN\n4.116915\n3.887823\nNaN\n\n\n98\nNaN\n0.850794\nNaN\nNaN\n0.927884\n0.669895\nNaN\nNaN\n0.665429\n1.387329\nNaN\nNaN\n4.329404\n4.111706\n3.960197\nNaN\nNaN\nNaN\n3.725288\n4.122072\n\n\n99\nNaN\nNaN\n1.413968\n0.838720\nNaN\nNaN\n1.094826\n0.987888\nNaN\n1.177387\n3.957383\n4.136731\nNaN\n4.026915\nNaN\nNaN\n4.164773\n4.104276\nNaN\nNaN\n\n\n\n\n100 rows × 20 columns\n\n\n\n컴퓨터가 좋아하는 타입은 아님\n\nrow0 - row49 에 해당하는 유저는 커피를 선호\nrow50 - row99 에 해당하는 유저는 홍차를 선호\n\n위의 자료는 비효율적, tidy data로 바꿔주자, 아래와 같이 정리함으로써 저장할 data도 줄어든다.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv')\ndf\n\n\n\n\n\n\n\n\nuser\nitem\nrating\nitem_name\n\n\n\n\n0\n1\n15\n1.084308\n홍차5\n\n\n1\n1\n1\n4.149209\n커피1\n\n\n2\n1\n11\n1.142659\n홍차1\n\n\n3\n1\n5\n4.033415\n커피5\n\n\n4\n1\n4\n4.078139\n커피4\n\n\n...\n...\n...\n...\n...\n\n\n995\n100\n18\n4.104276\n홍차8\n\n\n996\n100\n17\n4.164773\n홍차7\n\n\n997\n100\n14\n4.026915\n홍차4\n\n\n998\n100\n4\n0.838720\n커피4\n\n\n999\n100\n7\n1.094826\n커피7\n\n\n\n\n1000 rows × 4 columns\n\n\n\n\n컴퓨터는 이러한 형태를 더 분석하기 좋아한다.\n\n!cat 파일명\ndata 도 확인 가능하다\n!wget https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv\n!cat Real_estate_valuation_data_set.csv\n\n\ndf.item.unique(),df.user.unique()\n# 유저는 1~100 으로 아이템은 1~20으로 번호가 매겨져 있음 \n\n(array([15,  1, 11,  5,  4, 14,  6, 20, 12, 17,  8,  9, 13, 19, 18, 16,  2,\n         3, 10,  7]),\n array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n         92,  93,  94,  95,  96,  97,  98,  99, 100]))\n\n\nitem, user 번호 확인\n\n\nCollabDataLoaders.from_df??\n\n\nSignature:\nCollabDataLoaders.from_df(\n    ratings,\n    valid_pct=0.2,\n    user_name=None,\n    item_name=None,\n    rating_name=None,\n    seed=None,\n    path='.',\n    bs=64,\n    val_bs=None,\n    shuffle=True,\n    device=None,\n)\nSource:   \n    @delegates(DataLoaders.from_dblock)\n    @classmethod\n    def from_df(cls, ratings, valid_pct=0.2, user_name=None, item_name=None, rating_name=None, seed=None, path='.', **kwargs):\n        \"Create a `DataLoaders` suitable for collaborative filtering from `ratings`.\"\n        user_name   = ifnone(user_name,   ratings.columns[0])\n        item_name   = ifnone(item_name,   ratings.columns[1])\n        rating_name = ifnone(rating_name, ratings.columns[2])\n        cat_names = [user_name,item_name]\n        splits = RandomSplitter(valid_pct=valid_pct, seed=seed)(range_of(ratings))\n        to = TabularCollab(ratings, [Categorify], cat_names, y_names=[rating_name], y_block=TransformBlock(), splits=splits)\n        return to.dataloaders(path=path, **kwargs)\nFile:      ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/collab.py\nType:      method\n\n\n\n\n\ndls=CollabDataLoaders.from_df(df)\n\nbatch 데이터들의 group\n\ndls.show_batch()\n\n\n\n\n\nuser\nitem\nrating\n\n\n\n\n0\n59\n14\n3.986921\n\n\n1\n23\n3\n4.393831\n\n\n2\n43\n15\n1.022492\n\n\n3\n15\n16\n0.857821\n\n\n4\n81\n11\n3.892794\n\n\n5\n8\n1\n4.194341\n\n\n6\n6\n18\n1.124469\n\n\n7\n41\n20\n1.019717\n\n\n8\n10\n18\n0.789071\n\n\n9\n2\n4\n3.822704\n\n\n\n\n\n학습 전\n\nX,y= dls.one_batch()\n\n\ntype(X)\n\ntorch.Tensor\n\n\n\ntype(y)\n\ntorch.Tensor\n\n\n\ntype(dls.one_batch())\n\ntuple\n\n\n\nX[0],y[0]\n\n(tensor([74,  5]), tensor([1.0687]))\n\n\n\n99번 user가 13번 아이템을 먹었을때 평점 4.3294\n64번 유저가 15번 아이템을 먹었을때 평점을 4.1146 주었음\n\n\n\n2단계\n\ncollab_learner??\n\n\nSignature:\ncollab_learner(\n    dls,\n    n_factors=50,\n    use_nn=False,\n    emb_szs=None,\n    layers=None,\n    config=None,\n    y_range=None,\n    loss_func=None,\n    opt_func=&lt;function Adam at 0x7f6f5cbebca0&gt;,\n    lr=0.001,\n    splitter=&lt;function trainable_params at 0x7f6f7682d0d0&gt;,\n    cbs=None,\n    metrics=None,\n    path=None,\n    model_dir='models',\n    wd=None,\n    wd_bn_bias=False,\n    train_bn=True,\n    moms=(0.95, 0.85, 0.95),\n)\nSource:   \n@delegates(Learner.__init__)\ndef collab_learner(dls, n_factors=50, use_nn=False, emb_szs=None, layers=None, config=None, y_range=None, loss_func=None, **kwargs):\n    \"Create a Learner for collaborative filtering on `dls`.\"\n    emb_szs = get_emb_sz(dls, ifnone(emb_szs, {}))\n    if loss_func is None: loss_func = MSELossFlat()\n    if config is None: config = tabular_config()\n    if y_range is not None: config['y_range'] = y_range\n    if layers is None: layers = [n_factors]\n    if use_nn: model = EmbeddingNN(emb_szs=emb_szs, layers=layers, **config)\n    else:      model = EmbeddingDotBias.from_classes(n_factors, dls.classes, y_range=y_range)\n    return Learner(dls, model, loss_func=loss_func, **kwargs)\nFile:      ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/collab.py\nType:      function\n\n\n\n\n\nlrnr = collab_learner(dls,y_range=(0,5)) # y_range는 평점의 범위\n\ny는 평점이니까 0~5까지의 범위를 넣어주자\n\n\n3단계\n\nlrnr.fit(30) # 총 30번 정도 해야 적합이 잘된다. \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n2.319048\n2.344653\n00:00\n\n\n1\n2.308136\n2.343053\n00:00\n\n\n2\n2.294945\n2.327852\n00:00\n\n\n3\n2.277872\n2.286632\n00:00\n\n\n4\n2.242915\n2.204543\n00:00\n\n\n5\n2.190223\n2.074773\n00:00\n\n\n6\n2.110882\n1.897575\n00:00\n\n\n7\n2.002486\n1.683303\n00:00\n\n\n8\n1.865617\n1.440904\n00:00\n\n\n9\n1.705019\n1.189762\n00:00\n\n\n10\n1.528594\n0.947479\n00:00\n\n\n11\n1.343253\n0.728591\n00:00\n\n\n12\n1.158638\n0.542451\n00:00\n\n\n13\n0.982688\n0.394331\n00:00\n\n\n14\n0.821111\n0.282930\n00:00\n\n\n15\n0.678422\n0.203212\n00:00\n\n\n16\n0.556185\n0.148874\n00:00\n\n\n17\n0.453426\n0.112210\n00:00\n\n\n18\n0.368528\n0.088727\n00:00\n\n\n19\n0.299861\n0.073288\n00:00\n\n\n20\n0.244360\n0.064172\n00:00\n\n\n21\n0.200107\n0.058580\n00:00\n\n\n22\n0.164968\n0.055078\n00:00\n\n\n23\n0.137080\n0.052871\n00:00\n\n\n24\n0.115055\n0.051715\n00:00\n\n\n25\n0.097788\n0.051180\n00:00\n\n\n26\n0.084044\n0.051137\n00:00\n\n\n27\n0.073312\n0.050811\n00:00\n\n\n28\n0.064564\n0.050948\n00:00\n\n\n29\n0.057734\n0.051064\n00:00\n\n\n\n\n\nloss가 2.3에서 0.47으로 떨어지는 모습\n\n\n4단계\n- 이미 있는 데이터를 예측\n- 하나의 배치 전체를 예측\nlrnr.model(X)\n만 넣으면 에러뜬다.\n\n!nvidia-smi\n\nTue Sep 20 23:48:21 2022       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 495.46       Driver Version: 495.46       CUDA Version: 11.5     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:65:00.0 Off |                  N/A |\n| 30%   51C    P2   130W / 420W |  12684MiB / 24268MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|    0   N/A  N/A     37424      C   ...onda3/envs/csy/bin/python     3419MiB |\n|    0   N/A  N/A    293359      C   ...onda3/envs/csy/bin/python     4789MiB |\n|    0   N/A  N/A    378609      C   ...onda3/envs/csy/bin/python     2605MiB |\n|    0   N/A  N/A    378623      C   ...onda3/envs/csy/bin/python     1869MiB |\n+-----------------------------------------------------------------------------+\n\n\nGPU 확인 가능\nGPU아님 CPU로 올리자\n\nyhat=lrnr.model(X.to(\"cuda:0\"))\nyhat\n\ntensor([1.0097, 3.9209, 4.0095, 1.0768, 1.0179, 3.9701, 1.0862, 4.0802, 4.0528,\n        1.0718, 3.9230, 0.9994, 0.9662, 0.9122, 0.9745, 4.0083, 0.9989, 4.1045,\n        4.1632, 4.0724, 3.9754, 0.9565, 4.0757, 4.0317, 4.0740, 1.0779, 3.9354,\n        0.9951, 3.9031, 1.0241, 4.0253, 4.0965, 4.0368, 4.0944, 1.0856, 4.1450,\n        4.0549, 4.0072, 0.8689, 4.0659, 3.9192, 3.9501, 4.0449, 0.9437, 1.0582,\n        0.9584, 4.0409, 4.0453, 1.0675, 0.9406, 1.0740, 0.9307, 0.9885, 3.9951,\n        3.9118, 4.1501, 0.8893, 0.8946, 3.9687, 1.0579, 4.1036, 3.9685, 1.0809,\n        1.0768], device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n\n\n\ny.reshape(-1)\n\ntensor([1.0687, 3.8248, 3.8609, 1.0261, 0.8480, 4.4577, 1.1617, 4.3921, 4.2632,\n        0.7725, 4.0136, 1.2705, 0.8435, 1.0225, 0.8010, 4.1617, 1.0468, 4.1678,\n        4.5026, 4.0560, 3.8630, 0.9917, 4.0591, 3.7022, 4.1746, 1.3469, 3.7943,\n        1.0213, 3.7841, 0.8235, 4.0407, 3.9853, 4.1260, 4.1900, 1.0309, 4.1798,\n        3.9636, 3.7450, 0.6707, 4.0318, 4.1648, 4.1057, 3.9359, 0.7864, 1.2067,\n        0.8126, 4.0661, 4.1786, 1.3155, 0.9504, 1.1084, 0.8396, 0.8503, 4.0655,\n        3.8489, 4.0402, 0.7891, 0.9279, 4.1935, 0.9436, 4.4777, 4.0123, 1.0577,\n        0.8246])\n\n\n\nlrnr.model()은 GPU메모리에 존재하고 X는 일반메모리에 존재하므로 X를 GPU메모리로 옮겨주어야 함\nX.to(“cuda:0”)을 통하여 X를 GPU메모리로 옮기는 작업을 수행할 수 있다.\n\n- 하나의 유저가 하나의 아이템을 선택했다고 가정하고 예측 (주어진 자료중에서 예측)\n\nX.shape\n\ntorch.Size([64, 2])\n\n\n\nX[0:1]\n\ntensor([[74,  5]])\n\n\n- 1번 user가 커피2 마셨을때 - 예상: 4점 근처\n\nlrnr.model(X[0:1].to(\"cuda:0\"))\n\ntensor([1.0097], device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n\n\n\nlrnr.model(tensor([[1,2]]).to(\"cuda:0\"))\n\ntensor([3.9337], device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n\n\n\n18번 유저가 5번 아이템(커피)를 먹는다면?\n\n\nlrnr.model(X[0:1].to(\"cuda:0\"))\n\ntensor([1.0097], device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n\n\n\n평점은 4.1128정도 될것\n\n- 하나의 유저가 하나의 아이템을 선택했다고 가정하고 예측 (주어지지 않은 자료중에서 예측)\n\nX[0:1]\n\ntensor([[74,  5]])\n\n\n\nXnew = torch.tensor([[1,  2]])\n\n\nlrnr.model(Xnew.to(\"cuda:0\"))\n\ntensor([3.9337], device='cuda:0', grad_fn=&lt;AddBackward0&gt;)"
  },
  {
    "objectID": "posts/ml/2022-09-14-ml_2w.html#텍스트분석-실습",
    "href": "posts/ml/2022-09-14-ml_2w.html#텍스트분석-실습",
    "title": "DNN (2주차)",
    "section": "텍스트분석 실습",
    "text": "텍스트분석 실습\ntimeseries 와 text 순서가 중요! - 가장 잘 응용할 수 있는 게 chatbot챗봇 - 나는 \\(\\to\\) 학교에 \\(\\to\\) 갔다.\ntimeseries는 뒤를 정확히 맞춰야 하지만, text는 그렇지 않..?\n\n1단계\n\ndf = pd.DataFrame({'text':['h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??']*20000})\ndf\n\n\n\n\n\n\n\n\ntext\n\n\n\n\n0\nh e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n\n\n1\nh e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n\n\n2\nh e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n\n\n3\nh e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n\n\n4\nh e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n\n\n...\n...\n\n\n19995\nh e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n\n\n19996\nh e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n\n\n19997\nh e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n\n\n19998\nh e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n\n\n19999\nh e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n\n\n\n\n20000 rows × 1 columns\n\n\n\n\nTextDataLoaders.from_df??\n\n\nSignature:\nTextDataLoaders.from_df(\n    df,\n    path='.',\n    valid_pct=0.2,\n    seed=None,\n    text_col=0,\n    label_col=1,\n    label_delim=None,\n    y_block=None,\n    text_vocab=None,\n    is_lm=False,\n    valid_col=None,\n    tok_tfm=None,\n    tok_text_col='text',\n    seq_len=72,\n    backwards=False,\n    bs=64,\n    val_bs=None,\n    shuffle=True,\n    device=None,\n)\nSource:   \n    @classmethod\n    @delegates(DataLoaders.from_dblock)\n    def from_df(cls, df, path='.', valid_pct=0.2, seed=None, text_col=0, label_col=1, label_delim=None, y_block=None,\n                text_vocab=None, is_lm=False, valid_col=None, tok_tfm=None, tok_text_col=\"text\", seq_len=72, backwards=False, **kwargs):\n        \"Create from `df` in `path` with `valid_pct`\"\n        blocks = [TextBlock.from_df(text_col, text_vocab, is_lm, seq_len, backwards, tok=tok_tfm)]\n        if y_block is None and not is_lm:\n            blocks.append(MultiCategoryBlock if is_listy(label_col) and len(label_col) &gt; 1 else CategoryBlock)\n        if y_block is not None and not is_lm: blocks += (y_block if is_listy(y_block) else [y_block])\n        splitter = RandomSplitter(valid_pct, seed=seed) if valid_col is None else ColSplitter(valid_col)\n        dblock = DataBlock(blocks=blocks,\n                           get_x=ColReader(tok_text_col),\n                           get_y=None if is_lm else ColReader(label_col, label_delim=label_delim),\n                           splitter=splitter)\n        return cls.from_dblock(dblock, df, path=path, seq_len=seq_len, **kwargs)\nFile:      ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/text/data.py\nType:      method\n\n\n\n\nis_lm = False\n다음 자료를 예측하고 싶을때\nis_lm = True\n\nclassification을 수행하고 싶을 때\n생성에 목적\nis_lm: text의 생성에 관심이 있다면 True로 설정할 것\n\n\ndls = TextDataLoaders.from_df(df,text_col='text',is_lm=True) \n\n\n\n\n\ndls.show_batch()\n\n\n\n\n\ntext\ntext_\n\n\n\n\n0\nxxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o\nh e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o .\n\n\n1\n? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l\nxxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o\n\n\n2\n? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l\n? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l\n\n\n3\no ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e\n? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l\n\n\n4\nl o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h\no ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e\n\n\n5\nl l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos\nl o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h\n\n\n6\ne l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ?\nl l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos\n\n\n7\nh e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ?\ne l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ?\n\n\n8\n! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o\nh e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ?\n\n\n\n\n\n위의 결과에서 xxbos는 하나의 내용이 끝나고 다른 내용이 시작된다는 의미\n\n\n2단계\n\nlanguage_model_learner??\n\n\nSignature:\nlanguage_model_learner(\n    dls,\n    arch,\n    config=None,\n    drop_mult=1.0,\n    backwards=False,\n    pretrained=True,\n    pretrained_fnames=None,\n    loss_func=None,\n    opt_func=&lt;function Adam at 0x7fcb70042550&gt;,\n    lr=0.001,\n    splitter=&lt;function trainable_params at 0x7fcb79d04940&gt;,\n    cbs=None,\n    metrics=None,\n    path=None,\n    model_dir='models',\n    wd=None,\n    wd_bn_bias=False,\n    train_bn=True,\n    moms=(0.95, 0.85, 0.95),\n)\nSource:   \n@delegates(Learner.__init__)\ndef language_model_learner(dls, arch, config=None, drop_mult=1., backwards=False, pretrained=True, pretrained_fnames=None, **kwargs):\n    \"Create a `Learner` with a language model from `dls` and `arch`.\"\n    vocab = _get_text_vocab(dls)\n    model = get_language_model(arch, len(vocab), config=config, drop_mult=drop_mult)\n    meta = _model_meta[arch]\n    learn = LMLearner(dls, model, loss_func=CrossEntropyLossFlat(), splitter=meta['split_lm'], **kwargs)\n    url = 'url_bwd' if backwards else 'url'\n    if pretrained or pretrained_fnames:\n        if pretrained_fnames is not None:\n            fnames = [learn.path/learn.model_dir/f'{fn}.{ext}' for fn,ext in zip(pretrained_fnames, ['pth', 'pkl'])]\n        else:\n            if url not in meta:\n                warn(\"There are no pretrained weights for that architecture yet!\")\n                return learn\n            model_path = untar_data(meta[url] , c_key='model')\n            try: fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]\n            except IndexError: print(f'The model in {model_path} is incomplete, download again'); raise\n        learn = learn.load_pretrained(*fnames)\n    return learn\nFile:      ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/text/learner.py\nType:      function\n\n\n\n\n\nlrnr = language_model_learner(dls, AWD_LSTM)\n\n\n\n3단계\n\nlrnr.fit(5)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n1.926327\n0.851078\n00:15\n\n\n1\n1.030813\n0.366239\n00:15\n\n\n2\n0.636483\n0.251018\n00:15\n\n\n3\n0.478914\n0.209533\n00:15\n\n\n4\n0.431652\n0.190482\n00:15\n\n\n\n\n\n\n\n4단계\n\nlrnr.predict('h e',n_words=30)\n\n\n\n\n'h e l l o ? h e l l o ! h e l l o ! h e l l o ! h e l l o ? ?'"
  },
  {
    "objectID": "posts/ml/2022-09-14-ml_2w.html#gan-intro",
    "href": "posts/ml/2022-09-14-ml_2w.html#gan-intro",
    "title": "DNN (2주차)",
    "section": "GAN intro",
    "text": "GAN intro\n- 저자: 이안굿펠로우 (이름이 특이함. 좋은친구..) - 천재임 - 지도교수가 요수아 벤지오\n- 논문 NIPS, 저는 이 논문 읽고 소름돋았어요.. - https://arxiv.org/abs/1406.2661 (현재시점, 38751회 인용되었음 \\(\\to\\) 48978회 인용..)\n- 최근 10년간 머신러닝 분야에서 가장 혁신적인 아이디어이다. (얀르쿤, 2014년 시점..)\n- 무슨내용? 생성모형\n\n생성모형이란? (쉬운 설명)\n\n만들수 없다면 이해하지 못한 것이다, 리처드 파인만 (천재 물리학자)\n\n- 사진속에 들어있는 동물이 개인지 고양이인지 맞출수 있는 기계와 개와 고양이를 그릴수 있는 기계중 어떤것이 더 시각적보에 대한 이해가 깊다고 볼수 있는가?\n- 진정으로 인공지능이 이미지를 이해했다면, 이미지를 만들수도 있어야 한다. \\(\\to\\) 이미지를 생성하는 모형을 만들어보자 \\(\\to\\) 성공\n\n\nGAN의 응용분야\n- 내가 찍은 사진이 피카소의 화풍으로 표현된다면? - https://www.lgsl.kr/sto/stories/60/ALMA2020070001\n- 퀸의 라이브에이드가 4k로 나온다면?\n- 1920년대 서울의 모습이 칼라로 복원된다면?\n- 딥페이크: 유명인의 가짜 포르노, 가짜뉴스, 협박(거짓기소)\n- 게임영상 (파이널판타지)\n- 거북이의 커버..\n- 너무 많아요…..\n\n\n\n생성모형이란? 통계학과 버전의 설명\n\n제한된 정보만으로 어떤 문제를 풀 때, 그 과정에서 원래의 문제보다 일반적인 문제를 풀지 말고, 가능한 원래의 문제를 직접 풀어야한다. 배프닉 (SVM 창시자)\n\n- 이미지 \\(\\boldsymbol{x}\\)가 주어졌을 경우 라벨을 \\(y\\)라고 하자.\n- 이미지를 보고 라벨을 맞추는 일은 \\(p(y| \\boldsymbol{x})\\)에 관심이 있다.\n- 이미지를 생성하는 일은 \\(p(\\boldsymbol{x},y)\\)에 관심이 있는것이다.\ny의 평균적인 확률이 나올떄 x로 y 를 예측할 수 있다고 한단\n- 데이터의 생성확률 \\(p(\\boldsymbol{x},y)\\)을 알면 클래스의 사후확률 \\(p(y|\\boldsymbol{x})\\)를 알 수 있음. (아래의 수식 참고) 하지만 역은 불가능\n\\[p(y|x) = \\frac{p(x,y)}{p(x)} = \\frac{p(x,y)}{\\sum_{y}p(x,y)} \\]\n\n즉 이미지를 생성하는일은 분류문제보다 더 어려운 일이라 해석가능\n\n분류할 수 았다는게 생성할 수 있다는 건 아니니까\n- 따라서 배프닉의 원리에 의하면 식별적 분류가 생성적 분류보다 바람직한 접근법이라 할 수 있음.\n- 하지만 다양한 현실문제에서 생성모형이 유용할때가 많다.\n\n\nGAN의 원리\n- GAN은 생성모형중 하나임\n- GAN의 원리는 경찰과 위조지폐범이 서로 선의의(?) 경쟁을 통하여 서로 발전하는 모형으로 설명할 수 있다.\n\nThe generative model can be thought of as analogous to a team of counterfeiters, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency. Competition in this game drives both teams to improve their methods until the counterfeits are indistiguishable from the genuine articles.\n\n- 서로 적대적인(adversarial) 네트워크(network)를 동시에 학습시켜 가짜이미지를 만든다(generate)\n- 무식한 상황극..\n\n위조범: 가짜돈을 만들어서 부자가 되어야지! (가짜돈을 그림)\n\n\n경찰: (위조범이 만든 돈을 보고) 이건 가짜다!\n\n\n위조범: 걸렸군.. 더 정교하게 만들어야지..\n\n\n경찰: 이건 진짠가?… –&gt; 상사에게 혼남. 그것도 구분못하냐고\n\n\n위조범: 더 정교하게 만들자..\n\n\n경찰: 더 판별능력을 업그레이드 하자!\n\n\n반복..\n\n- 굉장히 우수한 경찰조차도 진짜와 가짜를 구분하지 못할때(=진짜 이미지를 0.5의 확률로만 진짜라고 말할때 = 가짜 이미지를 0.5의 확률로만 가짜라고 말할때) 학습을 멈춘다."
  },
  {
    "objectID": "posts/ml/2022-09-14-ml_2w.html#gan-실습",
    "href": "posts/ml/2022-09-14-ml_2w.html#gan-실습",
    "title": "DNN (2주차)",
    "section": "GAN 실습",
    "text": "GAN 실습\n\n1단계\n\npath = untar_data(URLs.MNIST_SAMPLE)\n\n\nDataBlock??\n\n\nInit signature:\nDataBlock(\n    blocks=None,\n    dl_type=None,\n    getters=None,\n    n_inp=None,\n    item_tfms=None,\n    batch_tfms=None,\n    *,\n    get_items=None,\n    splitter=None,\n    get_y=None,\n    get_x=None,\n)\nSource:        \nclass DataBlock():\n    \"Generic container to quickly build `Datasets` and `DataLoaders`\"\n    get_x=get_items=splitter=get_y = None\n    blocks,dl_type = (TransformBlock,TransformBlock),TfmdDL\n    _methods = 'get_items splitter get_y get_x'.split()\n    _msg = \"If you wanted to compose several transforms in your getter don't forget to wrap them in a `Pipeline`.\"\n    def __init__(self, blocks=None, dl_type=None, getters=None, n_inp=None, item_tfms=None, batch_tfms=None, **kwargs):\n        blocks = L(self.blocks if blocks is None else blocks)\n        blocks = L(b() if callable(b) else b for b in blocks)\n        self.type_tfms = blocks.attrgot('type_tfms', L())\n        self.default_item_tfms  = _merge_tfms(*blocks.attrgot('item_tfms',  L()))\n        self.default_batch_tfms = _merge_tfms(*blocks.attrgot('batch_tfms', L()))\n        for b in blocks:\n            if getattr(b, 'dl_type', None) is not None: self.dl_type = b.dl_type\n        if dl_type is not None: self.dl_type = dl_type\n        self.dataloaders = delegates(self.dl_type.__init__)(self.dataloaders)\n        self.dls_kwargs = merge(*blocks.attrgot('dls_kwargs', {}))\n        self.n_inp = ifnone(n_inp, max(1, len(blocks)-1))\n        self.getters = ifnone(getters, [noop]*len(self.type_tfms))\n        if self.get_x:\n            if len(L(self.get_x)) != self.n_inp:\n                raise ValueError(f'get_x contains {len(L(self.get_x))} functions, but must contain {self.n_inp} (one for each input)\\n{self._msg}')\n            self.getters[:self.n_inp] = L(self.get_x)\n        if self.get_y:\n            n_targs = len(self.getters) - self.n_inp\n            if len(L(self.get_y)) != n_targs:\n                raise ValueError(f'get_y contains {len(L(self.get_y))} functions, but must contain {n_targs} (one for each target)\\n{self._msg}')\n            self.getters[self.n_inp:] = L(self.get_y)\n        if kwargs: raise TypeError(f'invalid keyword arguments: {\", \".join(kwargs.keys())}')\n        self.new(item_tfms, batch_tfms)\n    def _combine_type_tfms(self): return L([self.getters, self.type_tfms]).map_zip(\n        lambda g,tt: (g.fs if isinstance(g, Pipeline) else L(g)) + tt)\n    def new(self, item_tfms=None, batch_tfms=None):\n        self.item_tfms  = _merge_tfms(self.default_item_tfms,  item_tfms)\n        self.batch_tfms = _merge_tfms(self.default_batch_tfms, batch_tfms)\n        return self\n    @classmethod\n    def from_columns(cls, blocks=None, getters=None, get_items=None, **kwargs):\n        if getters is None: getters = L(ItemGetter(i) for i in range(2 if blocks is None else len(L(blocks))))\n        get_items = _zip if get_items is None else compose(get_items, _zip)\n        return cls(blocks=blocks, getters=getters, get_items=get_items, **kwargs)\n    def datasets(self, source, verbose=False):\n        self.source = source                     ; pv(f\"Collecting items from {source}\", verbose)\n        items = (self.get_items or noop)(source) ; pv(f\"Found {len(items)} items\", verbose)\n        splits = (self.splitter or RandomSplitter())(items)\n        pv(f\"{len(splits)} datasets of sizes {','.join([str(len(s)) for s in splits])}\", verbose)\n        return Datasets(items, tfms=self._combine_type_tfms(), splits=splits, dl_type=self.dl_type, n_inp=self.n_inp, verbose=verbose)\n    def dataloaders(self, source, path='.', verbose=False, **kwargs):\n        dsets = self.datasets(source, verbose=verbose)\n        kwargs = {**self.dls_kwargs, **kwargs, 'verbose': verbose}\n        return dsets.dataloaders(path=path, after_item=self.item_tfms, after_batch=self.batch_tfms, **kwargs)\n    _docs = dict(new=\"Create a new `DataBlock` with other `item_tfms` and `batch_tfms`\",\n                 datasets=\"Create a `Datasets` object from `source`\",\n                 dataloaders=\"Create a `DataLoaders` object from `source`\")\nFile:           ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/data/block.py\nType:           type\nSubclasses:     \n\n\n\n\n\nTransformBlock\n\nfastai.data.block.TransformBlock\n\n\n\nImageBlock\n\n&lt;function fastai.vision.data.ImageBlock(cls=&lt;class 'fastai.vision.core.PILImage'&gt;)&gt;\n\n\n\ngenerate_noise\n\n&lt;function fastai.vision.gan.generate_noise(fn, size=100)&gt;\n\n\n\ndblock = DataBlock(blocks=(TransformBlock,ImageBlock),\n          get_x = generate_noise,\n          get_items=get_image_files,\n          item_tfms=Resize(32))\ndls = dblock.dataloaders(path) \n\n\ndls.show_batch()\n\n\n\n\n\n\n2단계\n\nbasic_generator??\n\n\nSignature:\nbasic_generator(\n    out_size,\n    n_channels,\n    in_sz=100,\n    n_features=64,\n    n_extra_layers=0,\n    ks=3,\n    stride=1,\n    padding=None,\n    bias=None,\n    ndim=2,\n    norm_type=&lt;NormType.Batch: 1&gt;,\n    bn_1st=True,\n    act_cls=&lt;class 'torch.nn.modules.activation.ReLU'&gt;,\n    transpose=False,\n    init='auto',\n    xtra=None,\n    bias_std=0.01,\n    dilation: Union[int, Tuple[int, int]] = 1,\n    groups: int = 1,\n    padding_mode: str = 'zeros',\n    device=None,\n    dtype=None,\n)\nSource:   \n@delegates(ConvLayer.__init__)\ndef basic_generator(out_size, n_channels, in_sz=100, n_features=64, n_extra_layers=0, **kwargs):\n    \"A basic generator from `in_sz` to images `n_channels` x `out_size` x `out_size`.\"\n    cur_size, cur_ftrs = 4, n_features//2\n    while cur_size &lt; out_size:  cur_size *= 2; cur_ftrs *= 2\n    layers = [AddChannels(2), ConvLayer(in_sz, cur_ftrs, 4, 1, transpose=True, **kwargs)]\n    cur_size = 4\n    while cur_size &lt; out_size // 2:\n        layers.append(ConvLayer(cur_ftrs, cur_ftrs//2, 4, 2, 1, transpose=True, **kwargs))\n        cur_ftrs //= 2; cur_size *= 2\n    layers += [ConvLayer(cur_ftrs, cur_ftrs, 3, 1, 1, transpose=True, **kwargs) for _ in range(n_extra_layers)]\n    layers += [nn.ConvTranspose2d(cur_ftrs, n_channels, 4, 2, 1, bias=False), nn.Tanh()]\n    return nn.Sequential(*layers)\nFile:      ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/vision/gan.py\nType:      function\n\n\n\n\n\nbasic_critic??\n\n\nSignature:\nbasic_critic(\n    in_size,\n    n_channels,\n    n_features=64,\n    n_extra_layers=0,\n    norm_type=&lt;NormType.Batch: 1&gt;,\n    ks=3,\n    stride=1,\n    padding=None,\n    bias=None,\n    ndim=2,\n    bn_1st=True,\n    act_cls=&lt;class 'torch.nn.modules.activation.ReLU'&gt;,\n    transpose=False,\n    init='auto',\n    xtra=None,\n    bias_std=0.01,\n    dilation: Union[int, Tuple[int, int]] = 1,\n    groups: int = 1,\n    padding_mode: str = 'zeros',\n    device=None,\n    dtype=None,\n)\nSource:   \n@delegates(ConvLayer.__init__)\ndef basic_critic(in_size, n_channels, n_features=64, n_extra_layers=0, norm_type=NormType.Batch, **kwargs):\n    \"A basic critic for images `n_channels` x `in_size` x `in_size`.\"\n    layers = [ConvLayer(n_channels, n_features, 4, 2, 1, norm_type=None, **kwargs)]\n    cur_size, cur_ftrs = in_size//2, n_features\n    layers += [ConvLayer(cur_ftrs, cur_ftrs, 3, 1, norm_type=norm_type, **kwargs) for _ in range(n_extra_layers)]\n    while cur_size &gt; 4:\n        layers.append(ConvLayer(cur_ftrs, cur_ftrs*2, 4, 2, 1, norm_type=norm_type, **kwargs))\n        cur_ftrs *= 2 ; cur_size //= 2\n    init = kwargs.get('init', nn.init.kaiming_normal_)\n    layers += [init_default(nn.Conv2d(cur_ftrs, 1, 4, padding=0), init), Flatten()]\n    return nn.Sequential(*layers)\nFile:      ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/vision/gan.py\nType:      function\n\n\n\n\n\ncounterfeiter = basic_generator(32,n_channels=3,n_extra_layers=1)\npolice = basic_critic(32,n_channels=3,n_extra_layers=1)\n\n\n32는 사이즈\n채널은 컬러이면 3이지만 이건 흑백이라도 3으로 표현해봄\n\n\nGANLearner.wgan??\n\n\nSignature:\nGANLearner.wgan(\n    dls,\n    generator,\n    critic,\n    switcher=None,\n    clip=0.01,\n    switch_eval=False,\n    gen_first=False,\n    show_img=True,\n    cbs=None,\n    metrics=None,\n    loss_func=None,\n    opt_func=&lt;function Adam at 0x7fcb70042550&gt;,\n    lr=0.001,\n    splitter=&lt;function trainable_params at 0x7fcb79d04940&gt;,\n    path=None,\n    model_dir='models',\n    wd=None,\n    wd_bn_bias=False,\n    train_bn=True,\n    moms=(0.95, 0.85, 0.95),\n)\nSource:   \n    @classmethod\n    def wgan(cls, dls, generator, critic, switcher=None, clip=0.01, switch_eval=False, **kwargs):\n        \"Create a WGAN from `data`, `generator` and `critic`.\"\n        if switcher is None: switcher = FixedGANSwitcher(n_crit=5, n_gen=1)\n        return cls(dls, generator, critic, _tk_mean, _tk_diff, switcher=switcher, clip=clip, switch_eval=switch_eval, **kwargs)\nFile:      ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/vision/gan.py\nType:      method\n\n\n\n\n\nlrnr = GANLearner.wgan(dls,counterfeiter,police) \n\n\n\n3단계\n- lrnr.fit(10) 진행\n\nlrnr.fit(10)\n\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/callback/core.py:51: UserWarning: You are shadowing an attribute (generator) that exists in the learner. Use `self.learn.generator` to avoid this\n  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/callback/core.py:51: UserWarning: You are shadowing an attribute (critic) that exists in the learner. Use `self.learn.critic` to avoid this\n  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n/home/csy/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/callback/core.py:51: UserWarning: You are shadowing an attribute (gen_mode) that exists in the learner. Use `self.learn.gen_mode` to avoid this\n  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ngen_loss\ncrit_loss\ntime\n\n\n\n\n0\n-0.543594\n0.420719\n0.420719\n-0.754515\n00:04\n\n\n1\n-0.578704\n0.376830\n0.376830\n-0.759121\n00:04\n\n\n2\n-0.581667\n0.335058\n0.335058\n-0.765852\n00:04\n\n\n3\n-0.581913\n0.350422\n0.350422\n-0.766256\n00:04\n\n\n4\n-0.576919\n0.239790\n0.239790\n-0.757070\n00:04\n\n\n5\n-0.568187\n0.165856\n0.165856\n-0.738596\n00:04\n\n\n6\n-0.561763\n0.312277\n0.312277\n-0.738768\n00:04\n\n\n7\n-0.545816\n0.312626\n0.312626\n-0.735054\n00:04\n\n\n8\n-0.530404\n0.315626\n0.315626\n-0.713279\n00:04\n\n\n9\n-0.552664\n0.292665\n0.292665\n-0.719266\n00:04\n\n\n\n\n\n\nlrnr.show_results()\n\n\n\n\n\n\n\n- lrnr.fit(10) 추가로 진행 // 총20회\n\nlrnr.fit(10)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ngen_loss\ncrit_loss\ntime\n\n\n\n\n0\n-0.534434\n0.329432\n0.329432\n-0.738360\n00:04\n\n\n1\n-0.491044\n0.241687\n0.241687\n-0.282900\n00:04\n\n\n2\n-0.430823\n0.247032\n0.247032\n-0.631827\n00:04\n\n\n3\n-0.509287\n0.228638\n0.228638\n-0.702186\n00:04\n\n\n4\n-0.541639\n0.306787\n0.306787\n-0.737486\n00:04\n\n\n5\n-0.490239\n0.270219\n0.270219\n-0.686973\n00:04\n\n\n6\n-0.456657\n0.370165\n0.370165\n-0.651278\n00:04\n\n\n7\n-0.375928\n0.254674\n0.254674\n-0.463629\n00:04\n\n\n8\n-0.505262\n0.241540\n0.241540\n-0.706440\n00:04\n\n\n9\n-0.511837\n0.264010\n0.264010\n-0.717528\n00:04\n\n\n\n\n\n\nlrnr.show_results()\n\n\n\n\n\n\n\n- lrnr.fit(10) 추가로 진행 // 총30회\n\nlrnr.fit(10)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ngen_loss\ncrit_loss\ntime\n\n\n\n\n0\n-0.389076\n0.203898\n0.203898\n-0.610006\n00:04\n\n\n1\n-0.404953\n0.248211\n0.248211\n-0.564691\n00:04\n\n\n2\n-0.399689\n0.157126\n0.157126\n-0.475484\n00:04\n\n\n3\n-0.412959\n0.160083\n0.160083\n-0.628447\n00:04\n\n\n4\n-0.419133\n0.140253\n0.140253\n-0.315640\n00:04\n\n\n5\n-0.412665\n0.360084\n0.360084\n-0.504751\n00:04\n\n\n6\n-0.419645\n0.331901\n0.331901\n-0.627747\n00:04\n\n\n7\n-0.393825\n0.099620\n0.099620\n-0.479805\n00:04\n\n\n8\n-0.383802\n0.332651\n0.332651\n-0.485545\n00:04\n\n\n9\n-0.329964\n0.066743\n0.066743\n-0.331843\n00:04\n\n\n\n\n\n\nlrnr.show_results()\n\n\n\n\n\n\n\n- lrnr.fit(10) 추가로 진행 // 총 60회\n\nlrnr.fit(30)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ngen_loss\ncrit_loss\ntime\n\n\n\n\n0\n-0.280188\n0.083489\n0.083489\n-0.421842\n00:04\n\n\n1\n-0.211743\n0.066232\n0.066232\n-0.485185\n00:04\n\n\n2\n-0.548622\n0.439374\n0.439374\n-0.729976\n00:04\n\n\n3\n-0.184136\n0.166024\n0.166024\n-0.196536\n00:04\n\n\n4\n-0.180048\n0.283176\n0.283176\n-0.343643\n00:04\n\n\n5\n-0.082062\n-0.111767\n-0.111767\n-0.232821\n00:06\n\n\n6\n-0.134064\n-0.252754\n-0.252754\n-0.056792\n00:05\n\n\n7\n-0.024693\n-0.019944\n-0.019944\n-0.060462\n00:04\n\n\n8\n-0.067052\n-0.176633\n-0.176633\n-0.087246\n00:05\n\n\n9\n-0.051849\n0.077216\n0.077216\n-0.063890\n00:04\n\n\n10\n-0.062414\n0.576616\n0.576616\n0.007565\n00:04\n\n\n11\n-0.028339\n-0.177623\n-0.177623\n-0.165999\n00:04\n\n\n12\n-0.285967\n0.256777\n0.256777\n-0.486597\n00:04\n\n\n13\n-0.040034\n0.200722\n0.200722\n-0.002714\n00:05\n\n\n14\n-0.082319\n-0.218245\n-0.218245\n-0.076548\n00:04\n\n\n15\n-0.126090\n-0.120631\n-0.120631\n-0.311712\n00:04\n\n\n16\n-0.120472\n0.024194\n0.024194\n-0.165129\n00:04\n\n\n17\n-0.213207\n0.447029\n0.447029\n-0.441171\n00:04\n\n\n18\n-0.104892\n0.076353\n0.076353\n-0.305898\n00:04\n\n\n19\n-0.077636\n-0.229590\n-0.229590\n-0.206540\n00:04\n\n\n20\n-0.037347\n-0.169197\n-0.169197\n-0.070061\n00:04\n\n\n21\n-0.063813\n-0.283316\n-0.283316\n0.009801\n00:04\n\n\n22\n-0.037806\n-0.101751\n-0.101751\n-0.020896\n00:04\n\n\n23\n-0.057209\n-0.012665\n-0.012665\n-0.095574\n00:04\n\n\n24\n-0.036946\n0.090177\n0.090177\n-0.049521\n00:04\n\n\n25\n-0.050363\n-0.206716\n-0.206716\n-0.035576\n00:04\n\n\n26\n-0.047856\n0.052171\n0.052171\n-0.017636\n00:04\n\n\n27\n-0.009292\n-0.027788\n-0.027788\n-0.003629\n00:04\n\n\n28\n-0.032223\n-0.223866\n-0.223866\n-0.011261\n00:04\n\n\n29\n-0.028316\n-0.006388\n-0.006388\n-0.024545\n00:05\n\n\n\n\n\n\nlrnr.show_results()\n\n\n\n\n\n\n\n\n\n4단계 (없음)"
  },
  {
    "objectID": "posts/ml/2022-12-23-Extra-3.html",
    "href": "posts/ml/2022-12-23-Extra-3.html",
    "title": "Extra-3: 딥러닝의 기초 (5)",
    "section": "",
    "text": "벡터미분, 역전파와 기울기 소멸\n기울기 소멸: loss 를 W로 미분했더니 그 값이 거의 0ㅇ이 나오는 현상 \\(\\to\\) update가 거의 이루어지지 않음\n이유 - W -&gt; loss인 함수는 W에 어떤한 선형변환 \\(\\to\\) 비선형변환 \\(\\to\\) 선형변환 \\(\\to\\) 비선형변환 \\(\\to \\dots\\) \\(\\to\\) loss 의 과정으로 해석 가능 - 즉 loss는 W의 합성의 합섭ㅇ의… 합성함수로 해석가능 - loss 를 W로 미분한 값은 각 변환단ㅇ계에서 정의되는 함수의 도함수를 모두 곱한 것과 같음(체인룰) - 체인 중에서도 하나라도 0이 나오면 곱한 값은 0 이다. - 체인이 길수록 하나라도 0이 나오는 경우가 많음\n왜 깊은 신경망일수록 기울기 소멸이 빈번한가? - 체인이 길기 때문에.\n왜 순환신경망일수록 기울기 소멸이 빈번할까&gt;? - 체인이 길기 때문에."
  },
  {
    "objectID": "posts/ml/2022-12-23-Extra-3.html#예시-2021-빅데이터분석-중간고사-문제-2-b",
    "href": "posts/ml/2022-12-23-Extra-3.html#예시-2021-빅데이터분석-중간고사-문제-2-b",
    "title": "Extra-3: 딥러닝의 기초 (5)",
    "section": "예시: 2021 빅데이터분석 중간고사 문제 2-(b)",
    "text": "예시: 2021 빅데이터분석 중간고사 문제 2-(b)\n- 미분계수를 계산하는 문제였음..\n\nhttps://guebin.github.io/BDA2021/2021/11/09/mid.html\n\n- 체인룰을 이용하여 미분계수를 계산하여 보자.\n\nones= torch.ones(5)\nx = torch.tensor([11.0,12.0,13.0,14.0,15.0])\nX = torch.vstack([ones,x]).T\ny = torch.tensor([17.7,18.5,21.2,23.6,24.2])\n\n\nW = torch.tensor([3.0,3.0]) \n\n\nu = X@W \nv = y-u \nloss = v.T @ v \n\n/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642814471/work/aten/src/ATen/native/TensorShape.cpp:3277.)\n  This is separate from the ipykernel package so we can avoid doing imports until\n\n\n\nloss\n\ntensor(2212.1799)\n\n\n- \\(\\frac{\\partial}{\\partial\\bf W}loss\\) 의 계산\n\\(\\frac{\\partial }{\\partial \\bf W}loss = \\left({\\bf X}^\\top \\right) \\left(-{\\bf I} \\right) \\left(2{\\bf v}\\right)\\)\n\nX.T @ -torch.eye(5) @ (2*v) \n\ntensor([ 209.6000, 2748.6001])\n\n\n- 참고로 중간고사 답은\n\nX.T @ -torch.eye(5)@ (2*v) / 5 \n\ntensor([ 41.9200, 549.7200])\n\n\n입니다.\n- 확인\n\n_W = torch.tensor([3.0,3.0],requires_grad=True) \n\n\n_loss = (y-X@_W).T @ (y-X@_W)\n\n\n_loss.backward()\n\n\n_W.grad.data\n\ntensor([ 209.6000, 2748.6001])\n\n\n- \\(\\frac{\\partial}{\\partial \\bf v} loss= 2{\\bf v}\\) 임을 확인하라.\n\nv\n\ntensor([-18.3000, -20.5000, -20.8000, -21.4000, -23.8000])\n\n\n\n_v= torch.tensor([-18.3000, -20.5000, -20.8000, -21.4000, -23.8000],requires_grad=True)\n\n\n_loss = _v.T @ _v \n\n\n_loss.backward() \n\n\n_v.grad.data, v \n\n(tensor([-36.6000, -41.0000, -41.6000, -42.8000, -47.6000]),\n tensor([-18.3000, -20.5000, -20.8000, -21.4000, -23.8000]))\n\n\n- \\(\\frac{\\partial }{\\partial {\\bf u}}{\\bf v}^\\top\\) 의 계산\n\n_u = torch.tensor([36., 39., 42., 45., 48.],requires_grad=True)\n_u\n\ntensor([36., 39., 42., 45., 48.], requires_grad=True)\n\n\n\n_v = y - _u ### 이전의 _v와 또다른 임시 _v \n\n\n(_v.T).backward()\n\nRuntimeError: grad can be implicitly created only for scalar outputs\n\n\n\n사실 토치에서는 스칼라아웃풋에 대해서만 미분을 계산할 수 있음\n\n그런데 \\(\\frac{\\partial}{\\partial {\\bf u}}{\\bf v}^\\top=\\frac{\\partial}{\\partial {\\bf u}}(v_1,v_2,v_3,v_4,v_5)=\\big(\\frac{\\partial}{\\partial {\\bf u}}v_1,\\frac{\\partial}{\\partial {\\bf u}}v_2,\\frac{\\partial}{\\partial {\\bf u}}v_3,\\frac{\\partial}{\\partial {\\bf u}}v_4,\\frac{\\partial}{\\partial {\\bf u}}v_5\\big)\\) 이므로\n조금 귀찮은 과정을 거친다면 아래와 같은 알고리즘으로 계산할 수 있다.\n\n\\(\\frac{\\partial }{\\partial {\\bf u}} {\\bf v}^\\top\\)의 결과를 저장할 매트릭스를 만든다. 적당히 A라고 만들자.\n_u 하나를 임시로 만든다. 그리고 \\(v_1\\)을 _u로 미분하고 그 결과를 A의 첫번째 칼럼에 기록한다.\n_u를 또하나 임시로 만들고 \\(v_2\\)를 _u로 미분한뒤 그 결과를 A의 두번째 칼럼에 기록한다.\n(1)-(2)와 같은 작업을 \\(v_5\\)까지 반복한다.\n\n(0)을 수행\n\nA = torch.zeros((5,5))\nA\n\ntensor([[0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.]])\n\n\n(1)을 수행\n\nu,v \n\n(tensor([36., 39., 42., 45., 48.]),\n tensor([-18.3000, -20.5000, -20.8000, -21.4000, -23.8000]))\n\n\n\n_u = torch.tensor([36., 39., 42., 45., 48.],requires_grad=True)\nv1 = (y-_u)[0]\n\n\n이때 \\(v_1=g(f({\\bf u}))\\)와 같이 표현할 수 있다. 여기에서 \\(f((u_1,\\dots,u_5)^\\top)=(y_1-u_1,\\dots,y_5-u_5)^\\top\\), 그리고 \\(g((v_1,\\dots,v_n)^\\top)=v_1\\) 라고 생각한다. 즉 \\(f\\)는 벡터 뺄셈을 수행하는 함수이고, \\(g\\)는 프로젝션 함수이다. 즉 \\(f:\\mathbb{R}^5 \\to \\mathbb{R}^5\\)인 함수이고, \\(g:\\mathbb{R}^5 \\to \\mathbb{R}\\)인 함수이다.\n\n여기서 \\(v_1\\)은 꼬리표로서 selection 작성되어 있음\n\nv1.backward()\n\n\n_u.grad.data\n\ntensor([-1., -0., -0., -0., -0.])\n\n\n\nA[:,0]= _u.grad.data\n\nA의 첫번째 칼럼에 이것을 넣어주세요\n\nA\n\ntensor([[-1.,  0.,  0.,  0.,  0.],\n        [-0.,  0.,  0.,  0.,  0.],\n        [-0.,  0.,  0.,  0.,  0.],\n        [-0.,  0.,  0.,  0.,  0.],\n        [-0.,  0.,  0.,  0.,  0.]])\n\n\n(2)를 수행\n\n_u = torch.tensor([36., 39., 42., 45., 48.],requires_grad=True)\nv2 = (y-_u)[1]\n\n\nv2.backward()\n\n\n_u.grad.data\n\ntensor([-0., -1., -0., -0., -0.])\n\n\n\nA[:,1]= _u.grad.data\nA\n\ntensor([[-1., -0.,  0.,  0.,  0.],\n        [-0., -1.,  0.,  0.,  0.],\n        [-0., -0.,  0.,  0.,  0.],\n        [-0., -0.,  0.,  0.,  0.],\n        [-0., -0.,  0.,  0.,  0.]])\n\n\n(3)을 수행 // 그냥 (1)~(2)도 새로 수행하자.\n\nfor i in range(5): \n    _u = torch.tensor([36., 39., 42., 45., 48.],requires_grad=True)\n    _v = (y-_u)[i]\n    _v.backward()\n    A[:,i]= _u.grad.data\n\n\nA\n\ntensor([[-1., -0., -0., -0., -0.],\n        [-0., -1., -0., -0., -0.],\n        [-0., -0., -1., -0., -0.],\n        [-0., -0., -0., -1., -0.],\n        [-0., -0., -0., -0., -1.]])\n\n\n\n이론적인 결과인 \\(-{\\bf I}\\)와 일치한다.\n\n- \\(\\frac{\\partial }{\\partial {\\bf W}}{\\bf u}^\\top\\)의 계산\n\\(\\frac{\\partial }{\\partial {\\bf W}}{\\bf u}^\\top = \\frac{\\partial }{\\partial {\\bf W}}(u_1,\\dots,u_5)=\\big(\\frac{\\partial }{\\partial {\\bf W}}u_1,\\dots,\\frac{\\partial }{\\partial {\\bf W}}u_5 \\big)\\)\n\nB = torch.zeros((2,5))\nB\n\ntensor([[0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.]])\n\n\n\nW\n\ntensor([3., 3.])\n\n\n\n_W = torch.tensor([3., 3.],requires_grad=True)\n_W\n\ntensor([3., 3.], requires_grad=True)\n\n\n\nfor i in range(5): \n    _W = torch.tensor([3., 3.],requires_grad=True)\n    _u = (X@_W)[i]\n    _u.backward()\n    B[:,i]= _W.grad.data\n\n\nB # X의 트랜스포즈\n\ntensor([[ 1.,  1.,  1.,  1.,  1.],\n        [11., 12., 13., 14., 15.]])\n\n\n\nX\n\ntensor([[ 1., 11.],\n        [ 1., 12.],\n        [ 1., 13.],\n        [ 1., 14.],\n        [ 1., 15.]])\n\n\n\n이론적인 결과와 일치"
  },
  {
    "objectID": "posts/ml/2022-12-23-Extra-3.html#잠깐-생각해보자..",
    "href": "posts/ml/2022-12-23-Extra-3.html#잠깐-생각해보자..",
    "title": "Extra-3: 딥러닝의 기초 (5)",
    "section": "잠깐 생각해보자..",
    "text": "잠깐 생각해보자..\n- 결국 위의 예제에 한정하여 임의의 \\({\\bf \\hat{W}}\\)에 대한 \\(\\frac{\\partial}{\\partial {\\bf \\hat W}}loss\\)는 아래와 같이 계산할 수 있다.\n\n(단계1) \\(2{\\bf v}\\)를 계산하고\n(단계2) (단계1)의 결과 앞에 \\(-{\\bf I}\\)를 곱하고\n(단계3) (단계2)의 결과 앞에 \\({\\bf X}^\\top\\)를 곱한다.\n\n- step1에서 \\({\\bf v}\\)는 어떻게 알지?\n\nX \\(\\to\\) u=X@W \\(\\to\\) v = y-u\n그런데 이것은 우리가 loss를 구하기 위해서 이미 계산해야 하는것 아니었나?\nstep1: yhat, step2: loss, step3: derivate, step4: update\n\n- (중요) step2에서 loss만 구해서 저장할 생각 하지말고 중간과정을 다 저장해라. (그중에 v와 같이 필요한것이 있을테니까) 그리고 그걸 적당한 방법을 통하여 이용하여 보자.\n\nbackprogation 알고리즘 모티브\n- 아래와 같이 함수의 변환을 아키텍처로 이해하자. (함수의입력=레이어의입력, 함수의출력=레이어의출력)\n\n\\({\\bf X} \\overset{l1}{\\to} {\\bf X}{\\bf W} \\overset{l2}{\\to} {\\bf y} -{\\bf X}{\\bf W} \\overset{l3}{\\to} ({\\bf y}-{\\bf X}{\\bf W})^\\top ({\\bf y}-{\\bf X}{\\bf W})\\)\n\n- 그런데 위의 계산과정을 아래와 같이 요약할 수도 있다. (\\({\\bf X} \\to {\\bf \\hat y} \\to loss\\)가 아니라 \\({\\bf W} \\to loss({\\bf W})\\)로 생각해보세요)\n\n\\({\\bf W} \\overset{l1}{\\to} {\\bf u} \\overset{l2}{\\to} {\\bf v} \\overset{l3}{\\to} loss\\)\n\n- 그렇다면 아래와 같은 사실을 관찰할 수 있다.\n\n(단계1) \\(2{\\bf v}\\)는 function of \\({\\bf v}\\)이고, \\({\\bf v}\\)는 l3의 입력 (혹은 l2의 출력)\n(단계2) \\(-{\\bf I}\\)는 function of \\({\\bf u}\\)이고, \\({\\bf u}\\)는 l2의 입력 (혹은 l1의 출력)\n(단계3) 마찬가지의 논리로 \\({\\bf X}^\\top\\)는 function of \\({\\bf W}\\)로 해석할 수 있다.\n\n- 요약: \\(2{\\bf v},-{\\bf I}, {\\bf X}^\\top\\)와 같은 핵심적인 값들이 사실 각 층의 입/출력 값들의 함수꼴로 표현가능하다. \\(\\to\\) 각 층의 입/출력 값들을 모두 기록하면 미분계산을 유리하게 할 수 있다.\n\n문득의문: 각 층의 입출력값 \\({\\bf v}, {\\bf u}, {\\bf W}\\)로 부터 \\(2{\\bf v}, -{\\bf I}, {\\bf X}^\\top\\) 를 만들어내는 방법을 모른다면 헛수고 아닌가?\n의문해결: 어차피 우리가 쓰는 층은 선형+(렐루, 시그모이드, …) 정도가 전부임. 따라서 변환규칙은 미리 계산할 수 있음.\n\n- 결국\n(1) 순전파를 하면서 입출력값을 모두 저장하고\n(2) 그에 대응하는 층별 미분계수값 \\(2{\\bf v}, -{\\bf I}, {\\bf X}^\\top\\) 를 구하고\n(3) 층별미분계수값을 다시 곱하면 (그러니까 \\({\\bf X}^\\top (-{\\bf I}) 2{\\bf v}\\) 를 계산) 된다.\n\n\nbackpropagation\n(1) 순전파를 계산하고 각 층별 입출력 값을 기록\n\nyhat = net(X)\nloss = loss_fn(yhat,y)\n\n(2) 역전파를 수행하여 손실함수의 미분값을 계산\n\nloss.backward()\n\n- 참고로 (1)에서 층별 입출력값은 GPU의 메모리에 기록된다.. 무려 GPU 메모리..\n- 작동원리를 GPU의 관점에서 요약 (슬기로운 GPU 활용)\ngpu특징: 큰 차원의 매트릭스 곱셈 전문가 (원리? 어마어마한 코어숫자)\n\n아키텍처 설정: 모형의 파라메터값을 GPU 메모리에 올림 // net.to(\"cuda:0\")\n순전파 계산: 중간 계산결과를 모두 GPU메모리에 저장 (순전파 계산을 위해서라면 굳이 GPU에 있을 필요는 없으나 후에 역전파를 계산하기 위한 대비) // net(X)\n오차 및 손실함수 계산: loss = loss_fn(yhat,y)\n역전파 계산: 순전파단계에서 저장된 계산결과를 활용하여 손실함수의 미분값을 계산 // loss.backward()\n다음 순전파 계산: 이전값은 삭제하고 새로운 중간계산결과를 GPU메모리에 올림\n반복."
  },
  {
    "objectID": "posts/ml/2022-12-23-Extra-3.html#some-comments",
    "href": "posts/ml/2022-12-23-Extra-3.html#some-comments",
    "title": "Extra-3: 딥러닝의 기초 (5)",
    "section": "some comments",
    "text": "some comments\n- 역전파기법은 체인룰 + \\(\\alpha\\) 이다. - 미분 계산을 하기 위함인데 여기서 파라메터 업데이트 필요하지\n- 오차역전파기법이라는 용어를 쓰는 사람도 있다.\n- 이미 훈련한 네트워크에 입력 \\(X\\)를 넣어 결과값만 확인하고 싶을 경우 순전파만 사용하면 되고, 이 상황에서는 좋은 GPU가 필요 없다. - 예) 개/고양이 확인 등"
  },
  {
    "objectID": "posts/ml/2022-12-23-Extra-3.html#고요속의-외침",
    "href": "posts/ml/2022-12-23-Extra-3.html#고요속의-외침",
    "title": "Extra-3: 딥러닝의 기초 (5)",
    "section": "고요속의 외침",
    "text": "고요속의 외침\n- https://www.youtube.com/watch?v=ouitOnaDtFY\n- 중간에 한명이라도 잘못 말한다면.."
  },
  {
    "objectID": "posts/ml/2022-12-23-Extra-3.html#정의",
    "href": "posts/ml/2022-12-23-Extra-3.html#정의",
    "title": "Extra-3: 딥러닝의 기초 (5)",
    "section": "정의",
    "text": "정의\n- In machine learning, the vanishing gradient problem is encountered when training artificial neural networks with gradient-based learning methods and backpropagation."
  },
  {
    "objectID": "posts/ml/2022-12-23-Extra-3.html#이해",
    "href": "posts/ml/2022-12-23-Extra-3.html#이해",
    "title": "Extra-3: 딥러닝의 기초 (5)",
    "section": "이해",
    "text": "이해\n- 당연한것 아닌가?\n\n그레디언트 기반의 학습 (그레디언트 기반의 옵티마이저): 손실함수의 기울기를 통하여 업데이트 하는 방식\n역전파: 손실함수의 기울기를 구하는 테크닉 (체인룰 + \\(\\alpha\\)). 구체적으로는 (1) 손실함수를 여러단계로 쪼개고 (2) 각 단계의 미분값을 각각 구하고 (3) 그것들을 모두 곱하여 기울기를 계산한다.\n0 근처의 숫자를 계속 곱하면 터지거나 0으로 간다. (사실 안정적인 기울기가 나올 것이라고 생각하는것 자체가 이상함)\n\n0 전달되면 업데이트 안 되잖아\n\nimport numpy as np \n\n\ngrads = np.random.uniform(low=-2,high=2,size=100) \ngrads\n\narray([ 1.27649548, -1.3435985 , -1.98858349,  1.98266931,  0.74704939,\n       -0.4831162 ,  1.41216797, -1.20423568,  0.66637324,  1.18085266,\n        0.23356958, -0.39851281,  0.2357107 , -0.28592461, -0.96001359,\n       -1.6276445 , -0.75687257,  0.48770524,  0.02553662,  0.18478814,\n        1.28850714,  1.41398052, -0.33970936,  0.36829707,  1.85991256,\n        0.02243541, -0.68804507,  0.63659842, -1.13905311,  0.94093391,\n        1.58809026, -0.25106013, -0.14446307,  1.31747003,  1.52190566,\n       -0.44264824, -1.95722305, -0.77865942, -0.3350363 , -0.53638126,\n       -0.77254936, -1.22118632,  0.6137345 ,  0.89975951, -1.70293244,\n        1.42661365, -0.43175558, -1.30904545, -0.53912915,  1.51725173,\n       -1.83965849,  1.00143736, -0.67129779,  0.36061957, -1.68850939,\n       -0.4272909 , -0.34715325,  1.72387253, -0.98340508, -1.60825385,\n        1.64523373, -0.79036932,  1.82578785, -0.53592773, -0.61384056,\n        0.9689625 ,  1.27971335,  0.51555469, -0.53425795,  0.38883373,\n       -0.28595978, -1.93730647, -1.94581503, -0.48984819, -1.21831701,\n       -1.25965989,  1.79542393,  1.2637913 , -0.93178556, -0.61210568,\n        1.23775906, -1.80601708,  1.40265496, -0.59602715,  1.44638486,\n       -1.71721283,  1.58345756, -1.03992841,  1.10167726,  1.13332066,\n       -0.76344022, -0.7246539 ,  0.27256115, -1.95501872, -0.65922909,\n        0.78715854, -0.29077574, -0.45110518, -1.64836114,  1.91692815])\n\n\n\ngrads.prod()\n\n-4.089052412862103e-11\n\n\n\n기울기가 소멸함\n\n\ngrads = np.random.uniform(low=-5,high=5,size=100) \ngrads.prod()\n\n-1.6059047739389678e+16\n\n\n\n기울기가 폭발함.\n\n\ngrads = np.random.uniform(low=-1,high=3.5,size=100) \ngrads.prod()\n\n13058.879478242436\n\n\n- 도깨비: 기울기가 소멸하기도 하고 터지기도 한다."
  },
  {
    "objectID": "posts/ml/2022-12-23-Extra-3.html#해결책-기울기-소멸에-대한-해결책",
    "href": "posts/ml/2022-12-23-Extra-3.html#해결책-기울기-소멸에-대한-해결책",
    "title": "Extra-3: 딥러닝의 기초 (5)",
    "section": "해결책 (기울기 소멸에 대한 해결책)",
    "text": "해결책 (기울기 소멸에 대한 해결책)\n- Multi-level hierarchy\n\n여러층을 쪼개서 학습하자 \\(\\to\\) 어떻게? 사전학습, 층벼학습\n기울기소실문제를 해결하여 딥러닝을 유행시킨 태초의(?) 방법임.\n결국 입력자료를 바꾼뒤에 학습하는 형태\n\n- Gradient clipping\n\n너무 큰 값의 기울기는 사용하지 말자. (기울기 폭발에 대한 대비책)\n\n- Faster hardware\n\nGPU를 중심으로 한 테크닉\n근본적인 문제해결책은 아니라는 힌튼의 비판\nCPU를 쓸때보다 GPU를 쓰면 약간 더 깊은 모형을 학습할 수 있다 정도?\n\n- Residual Networks, LSTM\n\n아키텍처를 변경하는 방법\n\n- Other activation functions\n\n렐루의 개발\n렐루가 음수는 아예 0, 양수는 기울기 확실하니까\n\n- 배치정규화\n\n어쩌다보니 되는것.\n배치정규화는 원래 공변량 쉬프트를 잡기 위한 방법임. 그런데 기울기 소멸에도 효과가 있음. 현재는 기울기소멸문제에 대한 해결책으로 빠짐없이 언급되고 있음. 2015년의 원래 논문에는 기울기소멸에 대한 언급은 없었음. (https://arxiv.org/pdf/1502.03167.pdf)\n심지어 배치정규화는 오버피팅을 잡는효과도 있음 (이것은 논문에 언급했음)\n\n- 기울기를 안구하면 안되나?\n\n베이지안 최적화기법: (https://arxiv.org/pdf/1807.02811.pdf) \\(\\to\\) GPU를 어떻게 쓰지? \\(\\to\\) 느리다"
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-1.html",
    "href": "posts/ml/2022-12-21-Extra-1.html",
    "title": "Extra-1: 추천시스템",
    "section": "",
    "text": "추천시스템"
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-1.html#주절주절-intro",
    "href": "posts/ml/2022-12-21-Extra-1.html#주절주절-intro",
    "title": "Extra-1: 추천시스템",
    "section": "주절주절 intro",
    "text": "주절주절 intro\n- Data\n\ndf_view = pd.read_csv('2022-12-21-rcmdsolo.csv',index_col=0)\ndf_view \n\n\n\n\n\n\n\n\n영식\n영철\n영호\n광수\n상철\n영수\n\n\n\n\n옥순\n3.9\n4.1\nNaN\n0.5\n0.3\nNaN\n\n\n영자\n4.5\nNaN\n3.7\n0.5\nNaN\n0.2\n\n\n정숙\nNaN\n4.9\n4.7\nNaN\n1.2\n1.3\n\n\n영숙\n0.6\n0.2\nNaN\n4.1\n4.3\nNaN\n\n\n순자\n0.7\n0.9\nNaN\n4.2\nNaN\n3.9\n\n\n현숙\nNaN\n0.2\n0.3\nNaN\n3.5\n3.4\n\n\n\n\n\n\n\n- 데이터를 이해할때 필요한 가정들 – 내맘대로 한 설정임.\n\n(옥순,영자,정숙)은 (영식,영철,영호)와 성격이 잘 맞고 (영숙,순자,현숙)은 (광수,상철,영수)와 성격이 잘맞음\n((옥순,영자,정숙),(영식,영철,영호))은 MBTI가 I로 시작하고 ((영숙,순자,현숙),(광수,상철,영수))는 MBTI가 E로 시작한다.\n\n- 목표: NaN 을 추론\n- 수동추론:\n\n(옥순,영호)이 만난다면? \\(\\to\\) 둘다 I성향이니까 잘 맞지 않을까? \\(\\to\\) 4.0 정도?\n(정숙,영식)조합은? \\(\\to\\) 둘다 I성향이니까 잘 맞지 않을까? + 정숙은 다 잘맞던데..? \\(\\to\\) 4.8 정도?\n(현숙,영식)조합은? \\(\\to\\) 현숙은 E성향인데 영식은 I성향이므로 잘 안맞을 것임 + 현숙은 원래 좀 눈이 높음 \\(\\to\\) 0.25 정도?\n\n- 좀 더 체계적인 추론\n사람들이 가지고 있는 성향들을 두 개의 숫자로 표현하자.\n\n옥순의 성향 = (I성향,E성향) = (1.9, 0.0)\n영식의 성향 = (I성향,E성향) = (2.0, 0.1)\n현숙의 성향 = (I성향,E성향) = (0.0, 1.5)\n\n(1) 옥순과 영식의 궁합 \\(\\approx\\) 옥순의I성향\\(\\times\\)영식의I성향 \\(+\\) 옥순의E성향\\(\\times\\)영식의E성향 // 적합\n\na1= np.array([1.9,0.0]).reshape(2,1) # a1은 옥순의 성향, col-vec으로 선언하자. \nb1= np.array([2.0,0.1]).reshape(2,1) # b1은 영식의 성향, col-vec으로 선언하자.\n(a1*b1).sum()\n\n3.8\n\n\n(2) 현숙과 영식의 궁합 \\(\\approx\\) 현숙의I성향\\(\\times\\)영식의I성향 \\(+\\) 현숙의E성향\\(\\times\\)영식의E성향 // 예측\n\na6= np.array([0.0,1.5]).reshape(2,1)\n(a6*b1).sum()\n\n0.15000000000000002\n\n\n\n그럴듯함..\n\n- 모델링\n아래가 같음을 관찰하라. (차원만 다름)\n\n(a1*b1).sum(), a1.T@b1\n\n(3.8, array([[3.8]]))\n\n\n\n(a6*b1).sum(), a6.T@b1\n\n(0.15000000000000002, array([[0.15]]))\n\n\n만약에 여자의성향, 남자의성향을 적당한 매트릭스로 정리할 수 있다면 궁합매트릭스를 만들 수 있음\n\na1= np.array([1.9,0.0]).reshape(2,1)\na2= np.array([2.0,0.1]).reshape(2,1)\na3= np.array([2.5,1.0]).reshape(2,1)\na4= np.array([0.1,1.9]).reshape(2,1)\na5= np.array([0.2,2.1]).reshape(2,1)\na6= np.array([0.0,1.5]).reshape(2,1)\nA = np.concatenate([a1,a2,a3,a4,a5,a6],axis=1)\nA\n\narray([[1.9, 2. , 2.5, 0.1, 0.2, 0. ],\n       [0. , 0.1, 1. , 1.9, 2.1, 1.5]])\n\n\n\nb1= np.array([2.0,0.1]).reshape(2,1)\nb2= np.array([1.9,0.2]).reshape(2,1)\nb3= np.array([1.8,0.3]).reshape(2,1)\nb4= np.array([0.3,2.1]).reshape(2,1)\nb5= np.array([0.2,2.0]).reshape(2,1)\nb6= np.array([0.1,1.9]).reshape(2,1)\nB = np.concatenate([b1,b2,b3,b4,b5,b6],axis=1)\nB\n\narray([[2. , 1.9, 1.8, 0.3, 0.2, 0.1],\n       [0.1, 0.2, 0.3, 2.1, 2. , 1.9]])\n\n\n\nA.T@B\n\narray([[3.8 , 3.61, 3.42, 0.57, 0.38, 0.19],\n       [4.01, 3.82, 3.63, 0.81, 0.6 , 0.39],\n       [5.1 , 4.95, 4.8 , 2.85, 2.5 , 2.15],\n       [0.39, 0.57, 0.75, 4.02, 3.82, 3.62],\n       [0.61, 0.8 , 0.99, 4.47, 4.24, 4.01],\n       [0.15, 0.3 , 0.45, 3.15, 3.  , 2.85]])\n\n\n\na1.T@b1, a2.T@b2, a3.T@b1\n\n(array([[3.8]]), array([[3.82]]), array([[5.1]]))\n\n\n결국 모형은 아래와 같다.\n\\[\\text{궁합매트릭스} = {\\bf A}^\\top {\\bf B} + \\text{오차}\\]\n- 학습전략: 아래의 매트릭스중에서 어떤값은 관측하였고 어떤값은 관측하지 못함 \\(\\to\\) 관측한 값들만 대충 비슷하게 하면 되는거 아니야?\n\nA.T@B \n\narray([[3.8 , 3.61, 3.42, 0.57, 0.38, 0.19],\n       [4.01, 3.82, 3.63, 0.81, 0.6 , 0.39],\n       [5.1 , 4.95, 4.8 , 2.85, 2.5 , 2.15],\n       [0.39, 0.57, 0.75, 4.02, 3.82, 3.62],\n       [0.61, 0.8 , 0.99, 4.47, 4.24, 4.01],\n       [0.15, 0.3 , 0.45, 3.15, 3.  , 2.85]])\n\n\n\ndf_view\n\n\n\n\n\n\n\n\n영식\n영철\n영호\n광수\n상철\n영수\n\n\n\n\n옥순\n3.9\n4.1\nNaN\n0.5\n0.3\nNaN\n\n\n영자\n4.5\nNaN\n3.7\n0.5\nNaN\n0.2\n\n\n정숙\nNaN\n4.9\n4.7\nNaN\n1.2\n1.3\n\n\n영숙\n0.6\n0.2\nNaN\n4.1\n4.3\nNaN\n\n\n순자\n0.7\n0.9\nNaN\n4.2\nNaN\n3.9\n\n\n현숙\nNaN\n0.2\n0.3\nNaN\n3.5\n3.4\n\n\n\n\n\n\n\n- 자료를 아래와 같이 정리한다면?\n\ndf = pd.DataFrame([(f,m,df_view.loc[f,m]) for f in df_view.index for m in df_view.columns if not np.isnan(df_view.loc[f,m])])\ndf.columns = ['X1','X2','y']\ndf\n\n\n\n\n\n\n\n\nX1\nX2\ny\n\n\n\n\n0\n옥순\n영식\n3.9\n\n\n1\n옥순\n영철\n4.1\n\n\n2\n옥순\n광수\n0.5\n\n\n3\n옥순\n상철\n0.3\n\n\n4\n영자\n영식\n4.5\n\n\n5\n영자\n영호\n3.7\n\n\n6\n영자\n광수\n0.5\n\n\n7\n영자\n영수\n0.2\n\n\n8\n정숙\n영철\n4.9\n\n\n9\n정숙\n영호\n4.7\n\n\n10\n정숙\n상철\n1.2\n\n\n11\n정숙\n영수\n1.3\n\n\n12\n영숙\n영식\n0.6\n\n\n13\n영숙\n영철\n0.2\n\n\n14\n영숙\n광수\n4.1\n\n\n15\n영숙\n상철\n4.3\n\n\n16\n순자\n영식\n0.7\n\n\n17\n순자\n영철\n0.9\n\n\n18\n순자\n광수\n4.2\n\n\n19\n순자\n영수\n3.9\n\n\n20\n현숙\n영철\n0.2\n\n\n21\n현숙\n영호\n0.3\n\n\n22\n현숙\n상철\n3.5\n\n\n23\n현숙\n영수\n3.4\n\n\n\n\n\n\n\n\nmapp1 = {k[1]:k[0] for k in enumerate(df.X1.unique())}\nmapp2 = {k[1]:k[0] for k in enumerate(df.X2.unique())}\nmapp1,mapp2\n\n({'옥순': 0, '영자': 1, '정숙': 2, '영숙': 3, '순자': 4, '현숙': 5},\n {'영식': 0, '영철': 1, '광수': 2, '상철': 3, '영호': 4, '영수': 5})\n\n\n\nX1 = torch.tensor(list(map(lambda name: mapp1[name], df.X1)))\nX2 = torch.tensor(list(map(lambda name: mapp2[name], df.X2)))\nX1 = torch.nn.functional.one_hot(X1).float()\nX2 = torch.nn.functional.one_hot(X2).float()\ny = torch.tensor(df.y).float()\n\n- yhat을 구하는 과정..\n\nl1 = torch.nn.Linear(in_features=6,out_features=2) \nl2 = torch.nn.Linear(in_features=6,out_features=2)\n\n\nl1(X1) # 옥순~현숙의 성향들 \n\ntensor([[ 0.5101,  0.1558],\n        [ 0.5101,  0.1558],\n        [ 0.5101,  0.1558],\n        [ 0.5101,  0.1558],\n        [ 0.1860, -0.1332],\n        [ 0.1860, -0.1332],\n        [ 0.1860, -0.1332],\n        [ 0.1860, -0.1332],\n        [ 0.5840, -0.5035],\n        [ 0.5840, -0.5035],\n        [ 0.5840, -0.5035],\n        [ 0.5840, -0.5035],\n        [ 0.0356, -0.3052],\n        [ 0.0356, -0.3052],\n        [ 0.0356, -0.3052],\n        [ 0.0356, -0.3052],\n        [ 0.5411, -0.3360],\n        [ 0.5411, -0.3360],\n        [ 0.5411, -0.3360],\n        [ 0.5411, -0.3360],\n        [ 0.0738,  0.1614],\n        [ 0.0738,  0.1614],\n        [ 0.0738,  0.1614],\n        [ 0.0738,  0.1614]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nl2(X2) # 영식~영수의 성향들 \n\ntensor([[ 0.1939,  0.0405],\n        [ 0.1073, -0.2484],\n        [-0.0011, -0.2328],\n        [-0.1622, -0.1059],\n        [ 0.1939,  0.0405],\n        [-0.1635, -0.0460],\n        [-0.0011, -0.2328],\n        [-0.1319,  0.1783],\n        [ 0.1073, -0.2484],\n        [-0.1635, -0.0460],\n        [-0.1622, -0.1059],\n        [-0.1319,  0.1783],\n        [ 0.1939,  0.0405],\n        [ 0.1073, -0.2484],\n        [-0.0011, -0.2328],\n        [-0.1622, -0.1059],\n        [ 0.1939,  0.0405],\n        [ 0.1073, -0.2484],\n        [-0.0011, -0.2328],\n        [-0.1319,  0.1783],\n        [ 0.1073, -0.2484],\n        [-0.1635, -0.0460],\n        [-0.1622, -0.1059],\n        [-0.1319,  0.1783]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n- 몇개의 관측치만 생각해보자..\n\ndf.head()\n\n\n\n\n\n\n\n\nX1\nX2\ny\n\n\n\n\n0\n옥순\n영식\n3.9\n\n\n1\n옥순\n영철\n4.1\n\n\n2\n옥순\n광수\n0.5\n\n\n3\n옥순\n상철\n0.3\n\n\n4\n영자\n영식\n4.5\n\n\n\n\n\n\n\n\n(l1(X1)[0]*l2(X2)[0]).sum() # (옥순의성향 * 영식의성향).sum()\n\ntensor(0.1052, grad_fn=&lt;SumBackward0&gt;)\n\n\n\n이 값이 실제로는 3.9 이어야 한다.\n\n\n(l1(X1)[1]*l2(X2)[1]).sum() # (옥순의성향 * 영철의성향).sum()\n\ntensor(0.0160, grad_fn=&lt;SumBackward0&gt;)\n\n\n\n이 값이 실제로는 4.1 이어야 한다.\n\n- yhat을 구하면!\n\nyhat = (l1(X1) * l2(X2)).sum(axis=1) # (l1(X1) * l2(X2)).sum(1)와 결과가 같음 \nyhat\n\ntensor([ 0.1052,  0.0160, -0.0369, -0.0992,  0.0307, -0.0243,  0.0308, -0.0483,\n         0.1877, -0.0724, -0.0414, -0.1668, -0.0054,  0.0796,  0.0710,  0.0265,\n         0.0913,  0.1415,  0.0776, -0.1313, -0.0322, -0.0195, -0.0291,  0.0190],\n       grad_fn=&lt;SumBackward1&gt;)\n\n\n\nyhat[:2],y[:2] # 이 값들이 비슷해야 하는데..\n\n(tensor([0.1052, 0.0160], grad_fn=&lt;SliceBackward0&gt;), tensor([3.9000, 4.1000]))\n\n\n- 0~5 까지의 범위로 고정되어 있으니까 아래와 같이 해도 되겠음..\n\nsig = torch.nn.Sigmoid()\n\n\nyhat = sig((l1(X1) * l2(X2)).sum(axis=1))*5 # (l1(X1) * l2(X2)).sum(1)와 결과가 같음 \nyhat\n\ntensor([2.6314, 2.5200, 2.4539, 2.3760, 2.5383, 2.4696, 2.5385, 2.4397, 2.7340,\n        2.4096, 2.4482, 2.2920, 2.4932, 2.5995, 2.5887, 2.5332, 2.6140, 2.6766,\n        2.5970, 2.3361, 2.4598, 2.4756, 2.4637, 2.5238],\n       grad_fn=&lt;MulBackward0&gt;)\n\n\n\nloss = torch.mean((y-yhat)**2)\nloss\n\ntensor(3.2296, grad_fn=&lt;MeanBackward0&gt;)"
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-1.html#torch를-이용한-학습",
    "href": "posts/ml/2022-12-21-Extra-1.html#torch를-이용한-학습",
    "title": "Extra-1: 추천시스템",
    "section": "torch를 이용한 학습",
    "text": "torch를 이용한 학습\n\ntorch.manual_seed(43052)\nl1 = torch.nn.Linear(6,2) \nl2 = torch.nn.Linear(6,2)\nsig = torch.nn.Sigmoid() \n\n\nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(list(l1.parameters())+list(l2.parameters()))\n\n\nfor epoc in range(5000):\n    ## 1 \n    feature1 = l1(X1)\n    feature2 = l2(X2) \n    matching_score = (feature1*feature2).sum(axis=1) \n    yhat = sig(matching_score)*5 # 만약에 1~3점이라면 \"1+sig(matching_score)*2\" 와 같이 하면 되었을듯 \n    ## 2 \n    loss = loss_fn(yhat,y)    \n    ## 3 \n    loss.backward()    \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat\n\ntensor([3.9382, 4.0624, 0.4665, 0.3353, 4.5038, 3.6975, 0.3562, 0.3558, 4.8614,\n        4.7208, 1.1813, 1.3158, 0.4606, 0.3573, 4.1288, 4.2734, 0.8611, 0.7347,\n        4.0493, 4.0464, 0.1810, 0.3124, 3.5031, 3.3948],\n       grad_fn=&lt;MulBackward0&gt;)\n\n\n\ny\n\ntensor([3.9000, 4.1000, 0.5000, 0.3000, 4.5000, 3.7000, 0.5000, 0.2000, 4.9000,\n        4.7000, 1.2000, 1.3000, 0.6000, 0.2000, 4.1000, 4.3000, 0.7000, 0.9000,\n        4.2000, 3.9000, 0.2000, 0.3000, 3.5000, 3.4000])\n\n\n\nl1(X1) # 두번째 칼럼이 I 성향 점수로 \"해석\"된다\n\ntensor([[-1.4663,  0.2938],\n        [-1.4663,  0.2938],\n        [-1.4663,  0.2938],\n        [-1.4663,  0.2938],\n        [-1.7086,  0.6597],\n        [-1.7086,  0.6597],\n        [-1.7086,  0.6597],\n        [-1.7086,  0.6597],\n        [-0.8705,  1.2945],\n        [-0.8705,  1.2945],\n        [-0.8705,  1.2945],\n        [-0.8705,  1.2945],\n        [ 1.1046, -0.8298],\n        [ 1.1046, -0.8298],\n        [ 1.1046, -0.8298],\n        [ 1.1046, -0.8298],\n        [ 0.9880, -0.5193],\n        [ 0.9880, -0.5193],\n        [ 0.9880, -0.5193],\n        [ 0.9880, -0.5193],\n        [ 0.6834, -1.2201],\n        [ 0.6834, -1.2201],\n        [ 0.6834, -1.2201],\n        [ 0.6834, -1.2201]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\n포인트: 여성출연자중, 정숙은 대체로 잘 맞춰주고 현숙은 그렇지 않았음.. \\(\\to\\) 그러한 가중치가 잘 드러남!!"
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-1.html#fastai를-이용한-학습",
    "href": "posts/ml/2022-12-21-Extra-1.html#fastai를-이용한-학습",
    "title": "Extra-1: 추천시스템",
    "section": "fastai를 이용한 학습",
    "text": "fastai를 이용한 학습\n(1) dls\n\ndf.head() # 앞단계 전처리의 산물\n\n\n\n\n\n\n\n\nX1\nX2\ny\n\n\n\n\n0\n옥순\n영식\n3.9\n\n\n1\n옥순\n영철\n4.1\n\n\n2\n옥순\n광수\n0.5\n\n\n3\n옥순\n상철\n0.3\n\n\n4\n영자\n영식\n4.5\n\n\n\n\n\n\n\n\ndls = CollabDataLoaders.from_df(df,bs=2,valid_pct=2/24)\n\n(2) lrnr 생성\n\nlrnr = collab_learner(dls,n_factors=2,y_range=(0,5))\n\n(3) 학습\n\nlrnr.fit(30,lr=0.05)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n3.591074\n3.904783\n00:00\n\n\n1\n3.101654\n3.466946\n00:00\n\n\n2\n2.374579\n1.997278\n00:00\n\n\n3\n1.698134\n0.770927\n00:00\n\n\n4\n1.231943\n0.426845\n00:00\n\n\n5\n0.926442\n0.370695\n00:00\n\n\n6\n0.712243\n0.409414\n00:00\n\n\n7\n0.555685\n0.388226\n00:00\n\n\n8\n0.438495\n0.432698\n00:00\n\n\n9\n0.349056\n0.497208\n00:00\n\n\n10\n0.280163\n0.439011\n00:00\n\n\n11\n0.225661\n0.401682\n00:00\n\n\n12\n0.182180\n0.352246\n00:00\n\n\n13\n0.147650\n0.385491\n00:00\n\n\n14\n0.119871\n0.335851\n00:00\n\n\n15\n0.097699\n0.352764\n00:00\n\n\n16\n0.079746\n0.317207\n00:00\n\n\n17\n0.065122\n0.334073\n00:00\n\n\n18\n0.053214\n0.318105\n00:00\n\n\n19\n0.043502\n0.307008\n00:00\n\n\n20\n0.035621\n0.297896\n00:00\n\n\n21\n0.029218\n0.296005\n00:00\n\n\n22\n0.024133\n0.273959\n00:00\n\n\n23\n0.019993\n0.212600\n00:00\n\n\n24\n0.016710\n0.216026\n00:00\n\n\n25\n0.014002\n0.240446\n00:00\n\n\n26\n0.012028\n0.239832\n00:00\n\n\n27\n0.011325\n0.132652\n00:00\n\n\n28\n0.011786\n0.154043\n00:00\n\n\n29\n0.010474\n0.395495\n00:00\n\n\n\n\n\n(4) 예측\n적합값 확인\n\nlrnr.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\nX1\nX2\ny\ny_pred\n\n\n\n\n0\n2.0\n2.0\n4.3\n3.425303\n\n\n1\n4.0\n1.0\n0.5\n0.660918\n\n\n\n\n\n(옥순의 궁합)\n\ndf_new = pd.DataFrame({'X1':['옥순']*6, 'X2':['영식','영철','영호','광수','상철','영수']})\ndf_new\n\n\n\n\n\n\n\n\nX1\nX2\n\n\n\n\n0\n옥순\n영식\n\n\n1\n옥순\n영철\n\n\n2\n옥순\n영호\n\n\n3\n옥순\n광수\n\n\n4\n옥순\n상철\n\n\n5\n옥순\n영수\n\n\n\n\n\n\n\n\nlrnr.get_preds(dl=dls.test_dl(df_new))\n\n\n\n\n\n\n\n\n(tensor([3.9011, 4.1288, 3.6021, 0.6609, 0.3678, 0.5451]), None)\n\n\n비교를 위해서\n\ndf_view\n\n\n\n\n\n\n\n\n영식\n영철\n영호\n광수\n상철\n영수\n\n\n\n\n옥순\n3.9\n4.1\nNaN\n0.5\n0.3\nNaN\n\n\n영자\n4.5\nNaN\n3.7\n0.5\nNaN\n0.2\n\n\n정숙\nNaN\n4.9\n4.7\nNaN\n1.2\n1.3\n\n\n영숙\n0.6\n0.2\nNaN\n4.1\n4.3\nNaN\n\n\n순자\n0.7\n0.9\nNaN\n4.2\nNaN\n3.9\n\n\n현숙\nNaN\n0.2\n0.3\nNaN\n3.5\n3.4\n\n\n\n\n\n\n\n(정숙의 궁합)\n\ndf_new = pd.DataFrame({'X1':['정숙']*6, 'X2':['영식','영철','영호','광수','상철','영수']})\ndf_new\n\n\n\n\n\n\n\n\nX1\nX2\n\n\n\n\n0\n정숙\n영식\n\n\n1\n정숙\n영철\n\n\n2\n정숙\n영호\n\n\n3\n정숙\n광수\n\n\n4\n정숙\n상철\n\n\n5\n정숙\n영수\n\n\n\n\n\n\n\n\nlrnr.get_preds(dl=dls.test_dl(df_new))\n\n\n\n\n\n\n\n\n(tensor([4.8320, 4.8423, 4.6991, 1.5996, 1.1552, 1.2886]), None)\n\n\n높으면 잘 맞는다,\n비교를 위해서\n\ndf_view\n\n\n\n\n\n\n\n\n영식\n영철\n영호\n광수\n상철\n영수\n\n\n\n\n옥순\n3.9\n4.1\nNaN\n0.5\n0.3\nNaN\n\n\n영자\n4.5\nNaN\n3.7\n0.5\nNaN\n0.2\n\n\n정숙\nNaN\n4.9\n4.7\nNaN\n1.2\n1.3\n\n\n영숙\n0.6\n0.2\nNaN\n4.1\n4.3\nNaN\n\n\n순자\n0.7\n0.9\nNaN\n4.2\nNaN\n3.9\n\n\n현숙\nNaN\n0.2\n0.3\nNaN\n3.5\n3.4\n\n\n\n\n\n\n\n- Appedix: fastai 구조공부..\n\nlrnr.model\n\nEmbeddingDotBias(\n  (u_weight): Embedding(7, 2)\n  (i_weight): Embedding(7, 2)\n  (u_bias): Embedding(7, 1)\n  (i_bias): Embedding(7, 1)\n)\n\n\n\nlrnr.model.forward??\n\n\nSignature: lrnr.model.forward(x)\nDocstring:\nDefines the computation performed at every call.\nShould be overridden by all subclasses.\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them.\nSource:   \n    def forward(self, x):\n        users,items = x[:,0],x[:,1]\n        dot = self.u_weight(users)* self.i_weight(items)\n        res = dot.sum(1) + self.u_bias(users).squeeze() + self.i_bias(items).squeeze()\n        if self.y_range is None: return res\n        return torch.sigmoid(res) * (self.y_range[1]-self.y_range[0]) + self.y_range[0]\nFile:      ~/anaconda3/envs/py37/lib/python3.7/site-packages/fastai/collab.py\nType:      method\n\n\n\n\n\nbias를 제외하면 우리가 짠 모형과 같음!"
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-1.html#data",
    "href": "posts/ml/2022-12-21-Extra-1.html#data",
    "title": "Extra-1: 추천시스템",
    "section": "data",
    "text": "data\n- 예전에 살펴본 예제\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/main/posts/I.%20Overview/2022-09-08-rcmd_anal.csv')\ndf\n\n\n\n\n\n\n\n\nuser\nitem\nrating\nitem_name\n\n\n\n\n0\n1\n15\n1.084308\n홍차5\n\n\n1\n1\n1\n4.149209\n커피1\n\n\n2\n1\n11\n1.142659\n홍차1\n\n\n3\n1\n5\n4.033415\n커피5\n\n\n4\n1\n4\n4.078139\n커피4\n\n\n...\n...\n...\n...\n...\n\n\n995\n100\n18\n4.104276\n홍차8\n\n\n996\n100\n17\n4.164773\n홍차7\n\n\n997\n100\n14\n4.026915\n홍차4\n\n\n998\n100\n4\n0.838720\n커피4\n\n\n999\n100\n7\n1.094826\n커피7\n\n\n\n\n1000 rows × 4 columns\n\n\n\n- 기억을 살리기 위해서..\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/main/posts/I.%20Overview/2022-09-08-rcmd_view.csv')\ndf_view\n\n\n\n\n\n\n\n\n커피1\n커피2\n커피3\n커피4\n커피5\n커피6\n커피7\n커피8\n커피9\n커피10\n홍차1\n홍차2\n홍차3\n홍차4\n홍차5\n홍차6\n홍차7\n홍차8\n홍차9\n홍차10\n\n\n\n\n0\n4.149209\nNaN\nNaN\n4.078139\n4.033415\n4.071871\nNaN\nNaN\nNaN\nNaN\n1.142659\n1.109452\nNaN\n0.603118\n1.084308\nNaN\n0.906524\nNaN\nNaN\n0.903826\n\n\n1\n4.031811\nNaN\nNaN\n3.822704\nNaN\nNaN\nNaN\n4.071410\n3.996206\nNaN\nNaN\n0.839565\n1.011315\nNaN\n1.120552\n0.911340\nNaN\n0.860954\n0.871482\nNaN\n\n\n2\n4.082178\n4.196436\nNaN\n3.956876\nNaN\nNaN\nNaN\n4.450931\n3.972090\nNaN\nNaN\nNaN\nNaN\n0.983838\nNaN\n0.918576\n1.206796\n0.913116\nNaN\n0.956194\n\n\n3\nNaN\n4.000621\n3.895570\nNaN\n3.838781\n3.967183\nNaN\nNaN\nNaN\n4.105741\n1.147554\nNaN\n1.346860\nNaN\n0.614099\n1.297301\nNaN\nNaN\nNaN\n1.147545\n\n\n4\nNaN\nNaN\nNaN\nNaN\n3.888208\nNaN\n3.970330\n3.979490\nNaN\n4.010982\nNaN\n0.920995\n1.081111\n0.999345\nNaN\n1.195183\nNaN\n0.818332\n1.236331\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n95\n0.511905\n1.066144\nNaN\n1.315430\nNaN\n1.285778\nNaN\n0.678400\n1.023020\n0.886803\nNaN\n4.055996\nNaN\nNaN\n4.156489\n4.127622\nNaN\nNaN\nNaN\nNaN\n\n\n96\nNaN\n1.035022\nNaN\n1.085834\nNaN\n0.812558\nNaN\n1.074543\nNaN\n0.852806\n3.894772\nNaN\n4.071385\n3.935935\nNaN\nNaN\n3.989815\nNaN\nNaN\n4.267142\n\n\n97\nNaN\n1.115511\nNaN\n1.101395\n0.878614\nNaN\nNaN\nNaN\n1.329319\nNaN\n4.125190\nNaN\n4.354638\n3.811209\n4.144648\nNaN\nNaN\n4.116915\n3.887823\nNaN\n\n\n98\nNaN\n0.850794\nNaN\nNaN\n0.927884\n0.669895\nNaN\nNaN\n0.665429\n1.387329\nNaN\nNaN\n4.329404\n4.111706\n3.960197\nNaN\nNaN\nNaN\n3.725288\n4.122072\n\n\n99\nNaN\nNaN\n1.413968\n0.838720\nNaN\nNaN\n1.094826\n0.987888\nNaN\n1.177387\n3.957383\n4.136731\nNaN\n4.026915\nNaN\nNaN\n4.164773\n4.104276\nNaN\nNaN\n\n\n\n\n100 rows × 20 columns"
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-1.html#모형",
    "href": "posts/ml/2022-12-21-Extra-1.html#모형",
    "title": "Extra-1: 추천시스템",
    "section": "모형",
    "text": "모형\n(편의상 바이어스를 제외하면)\n- 특징벡터:\n\n유저1의 취향 = [커피를 좋아하는 정도, 홍차를 좋아하는 정도]\n아이템1의 특징 = [커피의 특징, 홍차인 특징]\n\n- 평점\n\n유저1이 아이템1을 먹었을경우 평점: 유저1의 취향과 아이템1의 특징의 내적 = (유저1의 취향 \\(\\odot\\) 아이템1의 특징).sum()"
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-1.html#학습",
    "href": "posts/ml/2022-12-21-Extra-1.html#학습",
    "title": "Extra-1: 추천시스템",
    "section": "학습",
    "text": "학습\n(1) dls\n\ndls = CollabDataLoaders.from_df(df)\n\n\ndls.items\n\n\n\n\n\n\n\n\nuser\nitem\nrating\nitem_name\n\n\n\n\n961\n97\n4\n1.085834\n커피4\n\n\n320\n33\n4\n3.994618\n커피4\n\n\n50\n6\n20\n1.018980\n홍차10\n\n\n743\n75\n13\n3.745429\n홍차3\n\n\n369\n37\n3\n4.010463\n커피3\n\n\n...\n...\n...\n...\n...\n\n\n132\n14\n4\n3.826174\n커피4\n\n\n613\n62\n5\n1.257438\n커피5\n\n\n543\n55\n20\n4.140480\n홍차10\n\n\n351\n36\n9\n4.057546\n커피9\n\n\n432\n44\n11\n1.374712\n홍차1\n\n\n\n\n800 rows × 4 columns\n\n\n\n(2) lrnr\n\nlrnr = collab_learner(dls,n_factors=2) # 교재에는 y_range 를 설정하도록 되어있지만 설정 안해도 적합에는 크게 상관없음..\n\n(3) fit\n\nlrnr.fit(10,0.1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n5.737049\n2.797844\n00:00\n\n\n1\n3.731511\n2.010181\n00:00\n\n\n2\n2.508080\n0.507782\n00:00\n\n\n3\n1.719157\n0.202478\n00:00\n\n\n4\n1.232710\n0.094146\n00:00\n\n\n5\n0.906034\n0.071345\n00:00\n\n\n6\n0.680708\n0.064701\n00:00\n\n\n7\n0.520706\n0.060424\n00:00\n\n\n8\n0.404349\n0.059761\n00:00\n\n\n9\n0.318644\n0.064408\n00:00\n\n\n\n\n\n(4) predict\n(적합된 값 확인)\n\nlrnr.show_results() # 누를때마다 결과다름\n\n\n\n\n\n\n\n\n\n\n\n\nuser\nitem\nrating\nrating_pred\n\n\n\n\n0\n60.0\n14.0\n4.000825\n3.871396\n\n\n1\n44.0\n1.0\n3.906349\n3.825386\n\n\n2\n67.0\n20.0\n4.144467\n3.897682\n\n\n3\n22.0\n4.0\n4.192549\n3.861295\n\n\n4\n22.0\n5.0\n3.576439\n3.764175\n\n\n5\n20.0\n5.0\n4.457733\n3.844410\n\n\n6\n96.0\n2.0\n1.066144\n1.056824\n\n\n7\n28.0\n7.0\n3.968184\n4.046108\n\n\n8\n14.0\n11.0\n0.829723\n0.991227\n\n\n\n\n\n(예측값)\n\ndf_new = pd.DataFrame({'user':[1,1,1,1], 'item':[9,10,11,12]})\ndf_new\n\n\n\n\n\n\n\n\nuser\nitem\n\n\n\n\n0\n1\n9\n\n\n1\n1\n10\n\n\n2\n1\n11\n\n\n3\n1\n12\n\n\n\n\n\n\n\n\nlrnr.get_preds(dl=dls.test_dl(df_new))\n\n\n\n\n\n\n\n\n(tensor([3.9138, 3.9825, 0.9447, 0.8223]), None)"
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-2.html",
    "href": "posts/ml/2022-12-21-Extra-2.html",
    "title": "Extra-2: 생성모형(GAN)",
    "section": "",
    "text": "GAN– MNIST 3/7"
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-2.html#생성모형이란-쉬운-설명",
    "href": "posts/ml/2022-12-21-Extra-2.html#생성모형이란-쉬운-설명",
    "title": "Extra-2: 생성모형(GAN)",
    "section": "생성모형이란? (쉬운 설명)",
    "text": "생성모형이란? (쉬운 설명)\n\n만들수 없다면 이해하지 못한 것이다, 리처드 파인만 (천재 물리학자)\n\n- 사진속에 들어있는 동물이 개인지 고양이인지 맞출수 있는 기계와 개와 고양이를 그릴수 있는 기계중 어떤것이 더 시각적보에 대한 이해가 깊다고 볼수 있는가?\n- 진정으로 인공지능이 이미지를 이해했다면, 이미지를 만들수도 있어야 한다. \\(\\to\\) 이미지를 생성하는 모형을 만들어보자 \\(\\to\\) 성공"
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-2.html#gan의-응용분야",
    "href": "posts/ml/2022-12-21-Extra-2.html#gan의-응용분야",
    "title": "Extra-2: 생성모형(GAN)",
    "section": "GAN의 응용분야",
    "text": "GAN의 응용분야\n- 내가 찍은 사진이 피카소의 화풍으로 표현된다면?\n- 퀸의 라이브에이드가 4k로 나온다면?\n- 1920년대 서울의 모습이 칼라로 복원된다면?\n- 딥페이크: 유명인의 가짜 포르노, 가짜뉴스, 협박(거짓기소)\n- 게임영상 (파이널판타지)\n- 거북이의 커버..\n- 너무 많아요….."
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-2.html#생성모형이란-통계학과-버전의-설명",
    "href": "posts/ml/2022-12-21-Extra-2.html#생성모형이란-통계학과-버전의-설명",
    "title": "Extra-2: 생성모형(GAN)",
    "section": "생성모형이란? 통계학과 버전의 설명",
    "text": "생성모형이란? 통계학과 버전의 설명\n\n제한된 정보만으로 어떤 문제를 풀 때, 그 과정에서 원래의 문제보다 일반적인 문제를 풀지 말고, 가능한 원래의 문제를 직접 풀어야한다. 배프닉 (SVM 창시자)\n\n- 이미지 \\(\\boldsymbol{x}\\)가 주어졌을 경우 라벨을 \\(y\\)라고 하자.\n- 이미지를 보고 라벨을 맞추는 일은 \\(p(y| \\boldsymbol{x})\\)에 관심이 있다.\n- 이미지를 생성하는 일은 \\(p(\\boldsymbol{x},y)\\)에 관심이 있는것이다.\n- 데이터의 생성확률 \\(p(\\boldsymbol{x},y)\\)을 알면 클래스의 사후확률 \\(p(y|\\boldsymbol{x})\\)를 알 수 있음. (아래의 수식 참고) 하지만 역은 불가능\n\\[p(y|x) = \\frac{p(x,y)}{p(x)} = \\frac{p(x,y)}{\\sum_{y}p(x,y)} \\]\n\n즉 이미지를 생성하는일은 분류문제보다 더 어려운 일이라 해석가능\n\n- 따라서 배프닉의 원리에 의하면 식별적 분류가 생성적 분류보다 바람직한 접근법이라 할 수 있음.\n- 하지만 다양한 현실문제에서 생성모형이 유용할때가 많다."
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-2.html#gan의-원리",
    "href": "posts/ml/2022-12-21-Extra-2.html#gan의-원리",
    "title": "Extra-2: 생성모형(GAN)",
    "section": "GAN의 원리",
    "text": "GAN의 원리\n- GAN은 생성모형중 하나임\n- GAN의 원리는 경찰과 위조지폐범이 서로 선의의(?) 경쟁을 통하여 서로 발전하는 모형으로 설명할 수 있다.\n\nThe generative model can be thought of as analogous to a team of counterfeiters, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency. Competition in this game drives both teams to improve their methods until the counterfeits are indistiguishable from the genuine articles.\n\n- 서로 적대적인(adversarial) 네트워크(network)를 동시에 학습시켜 가짜이미지를 만든다(generate)\n- 무식한 상황극..\n\n위조범: 가짜돈을 만들어서 부자가 되어야지! (가짜돈을 그림)\n경찰: (위조범이 만든 돈을 보고) 이건 가짜다!\n위조범: 걸렸군.. 더 정교하게 만들어야지..\n경찰: 이건 진짠가?… –&gt; 상사에게 혼남. 그것도 구분못하냐고\n위조범: 더 정교하게 만들자..\n경찰: 더 판별능력을 업그레이드 하자!\n반복..\n\n- 굉장히 우수한 경찰조차도 진짜와 가짜를 구분하지 못할때(=진짜 이미지를 0.5의 확률로만 진짜라고 말할때 = 가짜 이미지를 0.5의 확률로만 가짜라고 말할때) 학습을 멈춘다."
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-2.html#import",
    "href": "posts/ml/2022-12-21-Extra-2.html#import",
    "title": "Extra-2: 생성모형(GAN)",
    "section": "import",
    "text": "import\n\nimport torch \nfrom fastai.vision.all import *\n\n/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm"
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-2.html#data",
    "href": "posts/ml/2022-12-21-Extra-2.html#data",
    "title": "Extra-2: 생성모형(GAN)",
    "section": "data",
    "text": "data\n\npath = untar_data(URLs.MNIST_SAMPLE)\n\n\nthrees = (path/'train'/'3').ls()\n\n\nX = torch.stack([tensor(Image.open(i)) for i in threes]).float()/255\n\n\nX.shape\n\ntorch.Size([6131, 28, 28])\n\n\n\nplt.imshow(X[0])\n\n&lt;matplotlib.image.AxesImage at 0x7f36568083d0&gt;\n\n\n\n\n\n- MLP를 이용해 학습하기 위해 X의 차원을 변경\n\nX=X.reshape(6131,28*28)\nX.shape\n\ntorch.Size([6131, 784])"
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-2.html#위조지폐범의-설계-noise-to-가짜이미지를-만들어-내는-네트워크를-만들자.",
    "href": "posts/ml/2022-12-21-Extra-2.html#위조지폐범의-설계-noise-to-가짜이미지를-만들어-내는-네트워크를-만들자.",
    "title": "Extra-2: 생성모형(GAN)",
    "section": "위조지폐범의 설계: noise \\(\\to\\) 가짜이미지를 만들어 내는 네트워크를 만들자.",
    "text": "위조지폐범의 설계: noise \\(\\to\\) 가짜이미지를 만들어 내는 네트워크를 만들자.\n- 네트워크의 입력? 적당한 벡터, 혹은 매트릭스에 노이즈(랜덤으로 채운 어떠한 숫자들)를 채운것\n- 네트워크의 출력? (28,28)의 텐서, 784의 벡터\n\nnet1 = torch.nn.Sequential(torch.nn.Linear(in_features=28, out_features=64),\n                           torch.nn.ReLU(),\n                           torch.nn.Linear(in_features=64, out_features=64), \n                           torch.nn.ReLU(),\n                           torch.nn.Linear(in_features=64, out_features=784),\n                           torch.nn.Sigmoid()) ## 마지막의 시그모이드는 출력이 0~1사이로 나오게 하기 위함 \ncounterfeiter = net1"
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-2.html#경찰의-설계-진짜이미지는-1-가짜이미지는-0으로-판별하는-dnn을-만들자.",
    "href": "posts/ml/2022-12-21-Extra-2.html#경찰의-설계-진짜이미지는-1-가짜이미지는-0으로-판별하는-dnn을-만들자.",
    "title": "Extra-2: 생성모형(GAN)",
    "section": "경찰의 설계: 진짜이미지는 1, 가짜이미지는 0으로 판별하는 DNN을 만들자.",
    "text": "경찰의 설계: 진짜이미지는 1, 가짜이미지는 0으로 판별하는 DNN을 만들자.\n- 네트워크의 입력? (28,28)의 텐서, 혹은 784의 벡터\n- 네트워크의 출력? yhat (y는 0 or 1)\n\nnet2 = torch.nn.Sequential(torch.nn.Linear(in_features=784,out_features=64),\n                           torch.nn.ReLU(),\n                           torch.nn.Linear(in_features=64,out_features=28),\n                           torch.nn.ReLU(),\n                           torch.nn.Linear(in_features=28,out_features=1),\n                           torch.nn.Sigmoid()\n                           )\npolice = net2"
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-2.html#스토리전개",
    "href": "posts/ml/2022-12-21-Extra-2.html#스토리전개",
    "title": "Extra-2: 생성모형(GAN)",
    "section": "스토리전개",
    "text": "스토리전개\n- 아래는 진짜이미지\n\nrealimage=X[0].reshape(28,28)\nplt.imshow(realimage)\n\n&lt;matplotlib.image.AxesImage at 0x7f365676c850&gt;\n\n\n\n\n\n- 위와 같은 진짜 이미지를 경찰이 봤음 \\(\\to\\) yhat이 나오겠죠?\n\npolicehat_from_realimage = police(realimage.reshape(-1))\npolicehat_from_realimage\n\ntensor([0.5015], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\n진짜 이미지일수록 policehat_from_realimage \\(\\approx\\) 1 이어야 함\n하지만 그렇지 못함 (배운것이 없는 무능한 경찰)\n\n- 이번에는 가짜이미지를 경찰이 봤다고 생각해보자.\n(step1) 랜덤으로 아무숫자나 28개를 생성한다.\n\nerr= torch.randn(28)\nerr\n\ntensor([ 3.0166, -1.1472, -0.0645,  1.1425, -0.5632, -1.7625,  0.4353,  0.2066,\n        -0.4214,  0.2895, -1.7030, -0.8060,  0.4684,  0.5643, -0.2158,  0.9998,\n        -1.0958, -1.5119, -1.5331,  1.0283,  0.0254,  0.6410,  0.8624,  1.0544,\n        -0.6116,  0.5087, -0.0657, -0.7712])\n\n\n(step2) 위조범은 err를 입력으로 받고 가짜이미지를 만든다.\n\ncouterfeiter_output = counterfeiter(err)\nfakeimage=couterfeiter_output.reshape(28,28)\nplt.imshow(fakeimage.detach())\n\n&lt;matplotlib.image.AxesImage at 0x7f36563d4550&gt;\n\n\n\n\n\n\n누가봐도 가짜자료임\n위조범의 실력이 형편없음\n\n(step3) 위조범이 생성한 이미지를 경찰한테 넘긴다.\n\npolicehat_from_fakeimage = police(couterfeiter_output)\n#policehat_from_fakeimage = police(fakeimage.detach().reshape(-1))\npolicehat_from_fakeimage\n\ntensor([0.5014], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n- 경찰의 실력도 형편없고 위조범의 실력도 형편없다."
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-2.html#경찰네트워크의-실력을-향상시키자.",
    "href": "posts/ml/2022-12-21-Extra-2.html#경찰네트워크의-실력을-향상시키자.",
    "title": "Extra-2: 생성모형(GAN)",
    "section": "경찰네트워크의 실력을 향상시키자.",
    "text": "경찰네트워크의 실력을 향상시키자.\n- 데이터 정리 - 원래 \\(n=6131\\)개의 이미지 자료가 있음. 이를 \\({\\bf X}\\)라고 하자. 따라서 \\({\\bf X}\\)의 차원은 (6131,784). - 위조범이 만든 가짜자료를 원래 자료와 같은 숫자인 6131개 만듬. 이 가짜자료를 \\(\\tilde{\\bf X}\\)라고 하자. 따라서 \\(\\tilde{\\bf X}\\)의 차원은 (6131,784). - 진짜자료는 1, 가짜자료는 0으로 라벨링.\n\nX.shape\n\ntorch.Size([6131, 784])\n\n\n\nerr= torch.randn(6131,28)\ncounterfeiter_output = counterfeiter(err) # counterfeiter_output를 Xtilde로 생각하면 된다. \n\n\nreal_label=torch.tensor([[1.0]]*6131) ## y=1 \nfake_label=torch.tensor([[0.0]]*6131) ## y=0\n\n- step1: yhat, 경찰의 예측\n\npolicehat_from_realimage = police(X) \npolicehat_from_fakeimage = police(counterfeiter_output) \n\n- step2: 손실함수? 경찰의 미덕은 (1) 가짜를 가짜라고 하고 (2) 진짜를 진짜라 해야한다.\n\nloss_fn = torch.nn.BCELoss() \n\n\nloss_of_police =\\\nloss_fn(policehat_from_fakeimage,fake_label)+\\\nloss_fn(policehat_from_realimage,real_label)\n\nloss_of_police\n\ntensor(1.3793, grad_fn=&lt;AddBackward0&gt;)\n\n\n- step3~4는 미분이후 업데이트\n- 옵티마이저를 설계하자.\n\noptimizer_of_police = torch.optim.Adam(police.parameters())\n\n- for 문을 돌리자.\n\nfor i in range(50): \n    ## 1 yhat \n    policehat_from_realimage = police(X) \n    \n    #policehat_from_fakeimage = police(Xitlde)\n    err= torch.randn(6131,28)\n    counterfeiter_output = counterfeiter(err) # counterfeiter_output를 Xtilde로 생각하면 된다. \n    policehat_from_fakeimage= police(counterfeiter_output)\n    \n    ## 2 loss \n    loss_of_police =\\\n    loss_fn(policehat_from_fakeimage,fake_label)+\\\n    loss_fn(policehat_from_realimage,real_label)\n    \n    ## 3 back propagation \n    loss_of_police.backward()\n    \n    ## 4 update\n    optimizer_of_police.step()\n    optimizer_of_police.zero_grad()\n\n- 훈련된 경찰의 성능을 살펴보자.\n\npolice(counterfeiter_output)\n\ntensor([[0.0022],\n        [0.0022],\n        [0.0023],\n        ...,\n        [0.0022],\n        [0.0022],\n        [0.0022]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\npolice(X)\n\ntensor([[0.9996],\n        [0.9991],\n        [0.9994],\n        ...,\n        [0.9992],\n        [0.9902],\n        [0.9917]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n- 우수한 경찰 (비록 위조범의 수준이 낮긴하지만)"
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-2.html#위조범네트워크의-성능을-향상시키자.",
    "href": "posts/ml/2022-12-21-Extra-2.html#위조범네트워크의-성능을-향상시키자.",
    "title": "Extra-2: 생성모형(GAN)",
    "section": "위조범네트워크의 성능을 향상시키자.",
    "text": "위조범네트워크의 성능을 향상시키자.\n- 자료구조: X는 임의의 에러이미지, net(X)는 fakeimage\n\nerr=torch.randn(6131,28) \ncounterfeiter_output= counterfeiter(err) \n\n- 손실함수: 잘 훈련된 경찰조차도 잘못된 판단을 내릴만큼 가짜지폐를 잘 만들면 위조범의 실력이 우수하다 볼 수 있음\n\npolicehat_from_fakeimage = police(counterfeiter_output) \nloss_of_counterfeiter = loss_fn(policehat_from_fakeimage,real_label) ## 가짜이미지를 보고 경찰이 진짜라고 믿으면 위조범의 실력이 좋은것임  \n\n- 옵티마이저\n\noptimizer_of_counterfeiter = torch.optim.Adam(counterfeiter.parameters())\n\n- 학습\n\nfor i in range(50): \n    ## 1 \n    err=torch.randn(6131,28) \n    counterfeiter_output= counterfeiter(err)  \n    policehat_from_fakeimage = police(counterfeiter_output) \n    ## 2 \n    loss_of_counterfeiter = loss_fn(policehat_from_fakeimage,real_label)\n    ## 3 \n    loss_of_counterfeiter.backward()\n    ## 4 \n    optimizer_of_counterfeiter.step()\n    optimizer_of_counterfeiter.zero_grad()\n\n- 위조범의 실력향상을 감상해보자.\n\nplt.imshow(counterfeiter_output[0].reshape(28,28).data)\n\n&lt;matplotlib.image.AxesImage at 0x7f36562f7410&gt;"
  },
  {
    "objectID": "posts/ml/2022-12-21-Extra-2.html#두-적대적-네트워크를-경쟁시키자.",
    "href": "posts/ml/2022-12-21-Extra-2.html#두-적대적-네트워크를-경쟁시키자.",
    "title": "Extra-2: 생성모형(GAN)",
    "section": "두 적대적 네트워크를 경쟁시키자.",
    "text": "두 적대적 네트워크를 경쟁시키자.\n\nfor k in range(100): \n    for i in range(50): \n        ## 1 yhat \n        policehat_from_realimage = police(X) \n    \n        #policehat_from_fakeimage = police(Xitlde)\n        err= torch.randn(6131,28)\n        counterfeiter_output = counterfeiter(err) # counterfeiter_output를 Xtilde로 생각하면 된다. \n        policehat_from_fakeimage= police(counterfeiter_output)\n    \n        ## 2 loss \n        loss_of_police =\\\n        loss_fn(policehat_from_fakeimage,fake_label)+\\\n        loss_fn(policehat_from_realimage,real_label)\n    \n        ## 3 back propagation \n        loss_of_police.backward()\n    \n        ## 4 update\n        optimizer_of_police.step()\n        optimizer_of_police.zero_grad()\n        \n    for i in range(50): \n        ## 1 \n        err=torch.randn(6131,28) \n        counterfeiter_output= counterfeiter(err)  \n        policehat_from_fakeimage = police(counterfeiter_output) \n        ## 2 \n        loss_of_counterfeiter = loss_fn(policehat_from_fakeimage,real_label)\n        ## 3 \n        loss_of_counterfeiter.backward()\n        ## 4 \n        optimizer_of_counterfeiter.step()\n        optimizer_of_counterfeiter.zero_grad()        \n\n- 위조범의 최종적 실력향상감상\n\nplt.imshow(counterfeiter_output[0].reshape(28,28).data)\n\n&lt;matplotlib.image.AxesImage at 0x7f365528e7d0&gt;"
  },
  {
    "objectID": "posts/ml/2022-09-21-ml_3w.html",
    "href": "posts/ml/2022-09-21-ml_3w.html",
    "title": "DNN (3주차)",
    "section": "",
    "text": "기계학습 특강 (3주차) 9월21일 [회귀분석, 선형모형, 손실함수, 경사하강법]"
  },
  {
    "objectID": "posts/ml/2022-09-21-ml_3w.html#imports",
    "href": "posts/ml/2022-09-21-ml_3w.html#imports",
    "title": "DNN (3주차)",
    "section": "imports",
    "text": "imports\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/ml/2022-09-21-ml_3w.html#로드맵",
    "href": "posts/ml/2022-09-21-ml_3w.html#로드맵",
    "title": "DNN (3주차)",
    "section": "로드맵",
    "text": "로드맵\n- 회귀분석 \\(\\to\\) 로지스틱 \\(\\to\\) 심층신경망(DNN) \\(\\to\\) 합성곱신경망(CNN)\n- 강의계획서"
  },
  {
    "objectID": "posts/ml/2022-09-21-ml_3w.html#ref",
    "href": "posts/ml/2022-09-21-ml_3w.html#ref",
    "title": "DNN (3주차)",
    "section": "ref",
    "text": "ref\n- 넘파이 문법이 약하다면? (reshape, concatenate, stack)\n\nreshape: 아래 링크의 넘파이공부 2단계 reshape 참고\n\nhttps://guebin.github.io/IP2022/2022/04/06/(6%EC%A3%BC%EC%B0%A8)-4%EC%9B%946%EC%9D%BC.html\n\nconcatenate, stack: 아래 링크의 넘파이공부 4단계 참고\n\nhttps://guebin.github.io/IP2022/2022/04/11/(6%EC%A3%BC%EC%B0%A8)-4%EC%9B%9411%EC%9D%BC.html"
  },
  {
    "objectID": "posts/ml/2022-09-21-ml_3w.html#회귀모형-소개",
    "href": "posts/ml/2022-09-21-ml_3w.html#회귀모형-소개",
    "title": "DNN (3주차)",
    "section": "회귀모형 소개",
    "text": "회귀모형 소개\n- model: \\(y_i= w_0+w_1 x_i +\\epsilon_i = 2.5 + 4x_i +\\epsilon_i, \\quad i=1,2,\\dots,n\\)\n- model: \\({\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\)\n\n\\({\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\)\n\\(\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix} \\quad = \\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix} + \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\)"
  },
  {
    "objectID": "posts/ml/2022-09-21-ml_3w.html#회귀모형에서-데이터-생성",
    "href": "posts/ml/2022-09-21-ml_3w.html#회귀모형에서-데이터-생성",
    "title": "DNN (3주차)",
    "section": "회귀모형에서 데이터 생성",
    "text": "회귀모형에서 데이터 생성\n\n\ntorch.manual_seed(1)\n_r = torch.randn(100).sort() # 두번쨰는 index~\n\n\ntype(_r)\n\ntorch.return_types.sort\n\n\n\n_r[0]\n\ntensor([-3.3312, -2.5832, -2.2456, -2.1021, -1.6095, -1.6091, -1.5256, -1.4782,\n        -1.4465, -1.1608, -1.1334, -1.0703, -1.0373, -1.0233, -1.0055, -0.9962,\n        -0.9823, -0.9798, -0.9276, -0.9274, -0.8743, -0.8696, -0.8313, -0.8138,\n        -0.7981, -0.7773, -0.7735, -0.7502, -0.7479, -0.7121, -0.7040, -0.6970,\n        -0.6629, -0.6540, -0.6540, -0.6446, -0.6298, -0.6200, -0.6177, -0.6092,\n        -0.5962, -0.5601, -0.5065, -0.4757, -0.4610, -0.4370, -0.2515, -0.2223,\n        -0.2106, -0.1860, -0.1853, -0.1759, -0.1578, -0.1316, -0.1110, -0.1010,\n        -0.1002, -0.0721, -0.0288, -0.0255, -0.0075,  0.0103,  0.0457,  0.0612,\n         0.0663,  0.0998,  0.1374,  0.1530,  0.1578,  0.1938,  0.1991,  0.1991,\n         0.2284,  0.2444,  0.2927,  0.3037,  0.3434,  0.3956,  0.4415,  0.4676,\n         0.5451,  0.6155,  0.6995,  0.7317,  0.7626,  0.8073,  0.8539,  0.8657,\n         0.9386,  1.1017,  1.1120,  1.1651,  1.3851,  1.5392,  1.5748,  1.6734,\n         1.6871,  1.8793,  2.0154,  2.3571])\n\n\n\n_r[1]\n\ntensor([62, 90, 26, 92,  3,  7,  0, 94, 27, 17, 95, 98, 45, 65, 67, 74, 79,  6,\n        86, 48, 99, 61, 75, 85, 30, 10, 35,  1, 63,  8, 72, 16, 22,  2, 82, 59,\n        47, 93, 29,  5, 66, 77, 80, 39, 76, 51, 11, 12, 68, 58, 73, 25, 42, 31,\n        40, 96,  4, 33, 43, 64, 69, 71, 37, 28, 50, 81, 56, 38, 34, 89, 36, 19,\n        14, 21, 41,  9, 97, 78, 53, 15, 49, 88, 18, 83, 52, 23, 91, 20, 57, 24,\n        87, 54, 84, 60, 46, 70, 13, 32, 55, 44])\n\n\n\na,_ = _r[0],_r[1]\n\n\na\n\ntensor([-3.3312, -2.5832, -2.2456, -2.1021, -1.6095, -1.6091, -1.5256, -1.4782,\n        -1.4465, -1.1608, -1.1334, -1.0703, -1.0373, -1.0233, -1.0055, -0.9962,\n        -0.9823, -0.9798, -0.9276, -0.9274, -0.8743, -0.8696, -0.8313, -0.8138,\n        -0.7981, -0.7773, -0.7735, -0.7502, -0.7479, -0.7121, -0.7040, -0.6970,\n        -0.6629, -0.6540, -0.6540, -0.6446, -0.6298, -0.6200, -0.6177, -0.6092,\n        -0.5962, -0.5601, -0.5065, -0.4757, -0.4610, -0.4370, -0.2515, -0.2223,\n        -0.2106, -0.1860, -0.1853, -0.1759, -0.1578, -0.1316, -0.1110, -0.1010,\n        -0.1002, -0.0721, -0.0288, -0.0255, -0.0075,  0.0103,  0.0457,  0.0612,\n         0.0663,  0.0998,  0.1374,  0.1530,  0.1578,  0.1938,  0.1991,  0.1991,\n         0.2284,  0.2444,  0.2927,  0.3037,  0.3434,  0.3956,  0.4415,  0.4676,\n         0.5451,  0.6155,  0.6995,  0.7317,  0.7626,  0.8073,  0.8539,  0.8657,\n         0.9386,  1.1017,  1.1120,  1.1651,  1.3851,  1.5392,  1.5748,  1.6734,\n         1.6871,  1.8793,  2.0154,  2.3571])\n\n\n\n_ones = torch.ones(100)\n\n\nX = torch.stack([_ones,a]).T\n\n\n#같아요 _X = torch.stack([_ones,a],axis=1)\n\n\nϵ = torch.randn(100)*0.5\n\n\nx=4*2.5+ϵ\n\n\nx\n\ntensor([10.1027, 10.1526, 10.2678,  9.7844, 10.0786, 10.6270, 10.6638,  9.7523,\n         9.0098, 10.8993, 10.0509, 10.1700,  9.6777,  9.8565, 11.6606,  9.7990,\n         9.8485,  9.1191, 10.3174,  9.5978,  9.4814,  9.4665,  9.8957,  9.8922,\n        11.1476, 10.3375, 10.8567,  9.1029,  9.2396, 10.4598,  9.7258,  9.8264,\n        10.2365,  9.7857, 10.2757,  9.2263, 10.3787,  9.7966,  9.9361, 10.1402,\n        10.8730, 10.9275,  9.6468, 11.2785, 10.3853,  9.4630,  9.8992,  9.7199,\n         9.6880,  9.5114, 10.4374, 10.4936, 10.1252,  9.6035, 10.2616, 10.6118,\n         9.7983,  9.5204,  9.9974,  9.9606,  9.8054,  9.9602, 10.3802,  9.4987,\n         9.5180, 10.0708,  9.9182,  9.8209,  9.9703,  8.7540, 10.1211, 10.1442,\n        10.0516, 10.5502,  9.8292, 10.4737, 10.3112,  9.7759,  9.8572, 10.1940,\n        10.2575,  9.0763,  8.5416,  9.7163,  9.9647, 10.1735,  9.6732, 10.7793,\n        10.2000, 11.2211,  9.8091, 10.2163,  8.9914, 10.2118, 10.2865,  9.1019,\n         9.8469,  9.7899, 10.1414, 10.1821])\n\n\n\nW = torch.tensor([2.5,4])\n\n\nW.shape\n\ntorch.Size([2])\n\n\n곱하지지 않았어야하지만 곱해짐..!\n\ny = X@W + ϵ\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\ntorch.manual_seed(43052)\nones= torch.ones(100)\nx,_ = torch.randn(100).sort()\nX = torch.stack([ones,x]).T # torch.stack([ones,x],axis=1)\nW = torch.tensor([2.5,4])\nϵ = torch.randn(100)*0.5\ny = X@W + ϵ\n\n\nplt.plot(x,y,'o')\nplt.plot(x,2.5+4*x,'--')\n\n\n\n\nblue를 observe한 상태에서 orange를 measure함\n학습이 된 상태: prediction을 제시할 수 있는 상태\nunderline function을 아는 상태는 w0와 w1을 아는 상태라고 할 수 있다.\n\\(x_{new}\\)가 주어졌을때 underline function과 얼마나 떨어져 있나 보면 되니까"
  },
  {
    "objectID": "posts/ml/2022-09-21-ml_3w.html#회귀모형에서-학습이란",
    "href": "posts/ml/2022-09-21-ml_3w.html#회귀모형에서-학습이란",
    "title": "DNN (3주차)",
    "section": "회귀모형에서 학습이란?",
    "text": "회귀모형에서 학습이란?\n- 파란점만 주어졌을때, 주황색 점선을 추정하는것. 좀 더 정확하게 말하면 given data로 \\(\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\)를 최대한 \\(\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}\\)와 비슷하게 찾는것.\n\ngiven data : \\(\\big\\{(x_i,y_i) \\big\\}_{i=1}^{n}\\)\nparameter: \\({\\bf W}=\\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}\\)\nestimated parameter: \\({\\bf \\hat{W}}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\)\n\n\\(\\hat{y} = x \\hat{W}\\)\n- 더 쉽게 말하면 아래의 그림을 보고 적당한 추세선을 찾는것이다.\n적당한?\n\nplt.plot(x,y,'o')\n\n\n\n\n- 시도: \\((\\hat{w}_0,\\hat{w}_1)=(-5,10)\\)을 선택하여 선을 그려보고 적당한지 판단.\n\nplt.plot(x,y,'o')\nplt.plot(x,-5+x*10,'--')\n\n\n\n\n\n\\(\\hat{y}_i=-5 +10 x_i\\) 와 같이 \\(y_i\\)의 값을 적합시키겠다는 의미\n\n- 벡터표현으로 주황색점선을 계산\n\nWhat = torch.tensor([-5.0,10.0])\n\n\nX.shape\n\ntorch.Size([100, 2])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What,'--')\n\n\n\n\ndata를 보고 architecture를 설계하는 modeling과정"
  },
  {
    "objectID": "posts/ml/2022-09-21-ml_3w.html#파라메터를-학습하는-방법-적당한-선으로-업데이트-하는-방법",
    "href": "posts/ml/2022-09-21-ml_3w.html#파라메터를-학습하는-방법-적당한-선으로-업데이트-하는-방법",
    "title": "DNN (3주차)",
    "section": "파라메터를 학습하는 방법 (적당한 선으로 업데이트 하는 방법)",
    "text": "파라메터를 학습하는 방법 (적당한 선으로 업데이트 하는 방법)\n- 이론적으로 추론 &lt;- 회귀분석시간에 배운것\n- 컴퓨터의 반복계산을 이용하여 추론 (손실함수도입 + 경사하강법) &lt;- 우리가 오늘 파이토치로 실습해볼 내용.\n- 전략: 아래와 같은 3단계 전략을 취한다.\n\nstage1: 아무 점선이나 그어본다..\nstage2: stage1에서 그은 점선보다 더 좋은 점선으로 바꾼다.\nstage3: stage1 - 2 를 반복한다.\n\n\nStage1: 첫번째 점선 – 임의의 선을 일단 그어보자\n- \\(\\hat{w}_0=-5, \\hat{w}_1 = 10\\) 으로 설정하고 (왜? 그냥) 임의의 선을 그어보자.\n\n처음에는 \\({\\bf \\hat{W}}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}=\\begin{bmatrix} -5 \\\\ 10 \\end{bmatrix}\\) 를 대입해서 주황색 점선을 적당히 그려보자는 의미\n끝에 requires_grad=True는 나중에 미분을 위한 것\n\n\nWhat = torch.tensor([-5.0,10.0])\nWhat\n\ntensor([-5., 10.])\n\n\ntensor에서 tf.variable로 출력할떄롸 같은 결과임\n\nWhat = torch.tensor([-5.0,10.0],requires_grad=True)\nWhat\n\ntensor([-5., 10.], requires_grad=True)\n\n\n꼬리표가 생겼다.\n\nWhat.detach()\n\ntensor([-5., 10.])\n\n\n\nWhat.data\n\ntensor([-5., 10.])\n\n\n꼬리표가 사라졌다.\n꼬리표 있어도 계산은 되지만, matplot에서는 오류..\n그려보자!\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\n\n\n\n\n\n\nStage2: 첫번째 수정 – 최초의 점선에 대한 ‘적당한 정도’를 판단하고 더 ’적당한’ 점선으로 업데이트 한다.\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\(loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2\\)\n\\(=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\)\n\nloss = torch.sum((y - X@What)**2)\nloss\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n- loss 함수의 특징 - \\(y_i \\approx \\hat{y}_i\\) 일수록 loss값이 작다. - \\(y_i \\approx \\hat{y}_i\\) 이 되도록 \\((\\hat{w}_0,\\hat{w}_1)\\)을 잘 찍으면 loss값이 작다. - (중요) 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n- 우리의 목표: 이 loss(=8587.6875)을 더 줄이자. - 궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다. (stage2에서 할일은 아님)\n- 문제의 치환: 생각해보니까 우리의 문제는 아래와 같이 수학적으로 단순화 되었다. - 적당해보이는 주황색 선을 찾자 \\(\\to\\) \\(loss(w_0,w_1)\\)를 최소로하는 \\((w_0,w_1)\\)의 값(정의역 set)을 찾자.\n- 수정된 목표: \\(loss(w_0,w_1)\\)를 최소로 하는 \\((w_0,w_1)\\)을 구하라. - 단순한 수학문제가 되었다. 마치 \\(loss(w)=w^2-2w+3\\) 을 최소화하는 \\(w\\)를 찾으라는 것과 같음. - 즉 “적당한 선으로 업데이트 하라 = 파라메터(\\(W\\))를 학습 하라 = 손실함수를 최소화 하라”\n- 우리의 무기: 경사하강법, 벡터미분\n\n\nStage2를 위한 경사하강법 복습\n경사하강법 아이디어 (1차원)\n(step 1) 임의의 점을 찍는다.\n(step 2) 그 점에서 순간기울기를 구한다. (접선) &lt;– 미분\n(step 3) 순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다.\n(팁) 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절한다.\n(서연필기) 접선 음수면 오른쪽으로 가고 접선 양수면 왼쪽으로 가쟈~\n경사하강법 아이디어 (2차원)\n(step 1) 임의의 점을 찍는다.\n(step 2) 그 점에서 순간기울기를 구한다. (접평면) &lt;– 편미분\n(step 3) 순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다.\n(팁) 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다.\n(서연필기) x,y 다르게 정의하는~편미분\nloss를 줄이도록 \\({\\bf W}\\)를 개선하는 방법\n- \\(수정값 \\leftarrow 원래값 - 기울어진크기(=미분계수) \\times \\alpha\\)\n\n여기에서 \\(\\alpha\\)는 전체적인 보폭의 크기를 결정한다. 즉 \\(\\alpha\\)값이 클수록 한번의 update에 움직이는 양이 크다.\n\n- \\({\\bf W} \\leftarrow {\\bf W} - \\alpha \\times \\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1)\\)\n(서연필기) 미분계수 반대로 움직이기 위해 마이너스(-) 취해주자\n(서연필기) 알파자체가 음수면 방향이 바뀌니까 양수!\n\n마이너스의 의미: 기울기의 부호를 보고 반대방향으로 움직여라.\n\\(\\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1):\\) 기울기의 절대값 크기와 비례하여 움직이는 정도를 조정하라.\n\\(\\alpha\\)의 의미: 전체적인 보폭의 속도를 조절, \\(\\alpha\\)가 크면 전체적으로 빠르게 움직인다. 다리의 길이로 비유할 수 있다.\n\n\n- 우리의 목표: loss=8587.6875 인데, 이걸 줄이는 것이 목표라고 했었음. 이것을 줄이는 방법이 경사하강법이다.\n- 경사하강법으로 loss를 줄이기 위해서는 \\(\\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1)\\)의 계산이 필요한데, 이를 위해서 벡터미분이 필요하다. (loss.backward()로 하면된다)\n\nloss\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n\nWhat.grad\n\n\nloss.backward()\n\n\nWhat.grad\n\ntensor([-1342.2523,  1188.9307])\n\n\n(서연필기) What.grad의 결과 값이 생겼다!\n\nloss\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n(서연필기) loss 계산할때 What에있는 꼬리표가 따라와서 loss에도 꼬리표가 붙었다.\n\nloss.backward()의 의미: loss를 미분해라! 뭘로? requires_grad=True를 가진 텐서로!!\n\n\nloss=torch.sum((y-yhat)**2)= torch.sum((y-X@What)**2)\n# 이었고 \nWhat=torch.tensor([-5.0,10.0],requires_grad=True)\n# 이므로 결국 What으로 미분하라는 의미. \n# 미분한 식이 나오는 것이 아니고, \n# 그 식에 (-5.0, 10.0)을 대입한 계수값이 계산됨. \n- 위에서 loss.backward()의 과정은 미분을 활용하여 \\((-5,10)\\)에서의 순간기울기를 구했다는 의미임.\n\nWhat,What.grad\n\n(tensor([-5., 10.], requires_grad=True), tensor([-1342.2523,  1188.9307]))\n\n\n- (-5,10)에서 loss의 순간기울기 값은 What.grad로 확인가능하다.\n\n이것이 의미하는건 \\((-5,10)\\)에서의 \\(loss(w_0,w_1)\\)의 순간기울기가 \\((-1342.2523, 1188.9307)\\) 이라는 의미\n\n- (확인1) loss.backward()가 미분을 잘 계산해 주는 것이 맞는가? 손계산으로 검증하여 보자.\n\n\\(loss(w_0,w_1)=({\\bf y}-\\hat{\\bf y})^\\top ({\\bf y}-\\hat{\\bf y})=({\\bf y}-{\\bf XW})^\\top ({\\bf y}-{\\bf XW})\\)\n\\(\\frac{\\partial}{\\partial {\\bf W} }loss(w_0,w_1)=-2{\\bf X}^\\top {\\bf y}+2{\\bf X}^\\top {\\bf X W}\\)\n\n\n- 2 * X.T @ y + 2 * X.T @ X @ What\n\ntensor([-1342.2522,  1188.9305], grad_fn=&lt;AddBackward0&gt;)\n\n\n- (확인2) loss.backward()가 미분을 잘 계산해 주는 것이 맞는가? 편미분을 간단히 구현하여 검증하여 보자.\n\n\\(\\frac{\\partial}{\\partial {\\bf W} } loss(w_0,w_1)=\\begin{bmatrix}\\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1} \\end{bmatrix}loss(w_0,w_1) =\\begin{bmatrix}\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\\\ \\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\end{bmatrix}\\)\n\\(\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\approx \\frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}\\)\n\\(\\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\approx \\frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}\\)\n\n스칼라일때\nh = 0.01\n(loss(w+h) - loss(w)) / h\n\n_lossfn = lambda w0,w1: torch.sum((y-w0-w1*x)**2)\n_lossfn(-5,10)\n\ntensor(8587.6875)\n\n\n\nh=0.001\n(_lossfn(-5+h,10) - _lossfn(-5,10))/h,  (_lossfn(-5,10+h) - _lossfn(-5,10))/h\n\n(tensor(-1341.7968), tensor(1190.4297))\n\n\n-5,10에서의 편미분한 순간기울기\n\n약간 오차가 있지만 얼추비슷 \\(\\to\\) 잘 계산했다는 소리임\n\n(서연필기) 꼭 정확하진 않지!\n- 수정전, 수정하는폭, 수정후의 값은 차례로 아래와 같다.\n\nalpha=0.001 \nprint('수정전: ' + str(What.data)) # What 에서 미분꼬리표를 떼고 싶다면? What.data or What.detach()\nprint('수정하는폭: ' +str(-alpha * What.grad))\nprint('수정후: ' +str(What.data-alpha * What.grad))\nprint('*참값: (2.5,4)' )\n\n수정전: tensor([-5., 10.])\n수정하는폭: tensor([ 1.3423, -1.1889])\n수정후: tensor([-3.6577,  8.8111])\n*참값: (2.5,4)\n\n\n- Wbefore, Wafter 계산\n\nWbefore = What.data\nWafter = What.data- alpha * What.grad\nWbefore, Wafter\n\n(tensor([-5., 10.]), tensor([-3.6577,  8.8111]))\n\n\ndata쓰는지 grad 쓰는지 명확히\n- Wbefore, Wafter의 시각화\n\nplt.plot(x,y,'o')\nplt.plot(x,X@Wbefore,'--')\nplt.plot(x,X@Wafter,'--')\n\n\n\n\n\n\n\nStage3: Learn (=estimate \\(\\bf\\hat{W})\\)\n- 이 과정은 Stage1,2를 반복하면 된다.\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True) #\n\n\nalpha=0.001 \nfor epoc in range(30): ## 30번 반복합니다!! \n    yhat=X@What \n    loss=torch.sum((y-yhat)**2)\n    loss.backward() \n    What.data = What.data-alpha * What.grad\n    What.grad=None\n\n(서연필기) What.grad=None 해주는 이유는 grad가 미분을 누적하기 때문에 막아주기 위해서\n\n원래 철자는 epoch이 맞아요\n\n- 반복결과는?! (최종적으로 구해지는 What의 값은?!) - 참고로 true\n\nWhat.data ## true인 (2.5,4)와 상당히 비슷함\n\ntensor([2.4290, 4.0144])\n\n\n- 반복결과를 시각화하면?\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')"
  },
  {
    "objectID": "posts/ml/2022-09-21-ml_3w.html#파라메터의-학습과정-음미-학습과정-모니터링",
    "href": "posts/ml/2022-09-21-ml_3w.html#파라메터의-학습과정-음미-학습과정-모니터링",
    "title": "DNN (3주차)",
    "section": "파라메터의 학습과정 음미 (학습과정 모니터링)",
    "text": "파라메터의 학습과정 음미 (학습과정 모니터링)\n\n학습과정의 기록\n- 기록을 해보자.\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.001 \nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.detach().tolist())\n    What.grad=None\n\n(서연필기) list 그대로 받으니까 꼬리표 삭제\n- \\(\\hat{y}\\) 관찰 (epoch=3, epoch=10, epoch=15)\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[2],'--')\n\n\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[9],'--')\n\n\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[14],'--')\n\n\n\n\n\nlen(yhat_history[0])\n\n100\n\n\n- \\(\\hat{\\bf W}\\) 관찰\n\nWhat_history\n\n[[-3.657747745513916, 8.81106948852539],\n [-2.554811716079712, 7.861191749572754],\n [-1.649186372756958, 7.101552963256836],\n [-0.9060714244842529, 6.49347448348999],\n [-0.29667866230010986, 6.006272315979004],\n [0.2027742564678192, 5.615575313568115],\n [0.6119104623794556, 5.302003383636475],\n [0.9469034671783447, 5.050129413604736],\n [1.2210699319839478, 4.847657680511475],\n [1.4453645944595337, 4.684779167175293],\n [1.6287915706634521, 4.553659439086914],\n [1.778746247291565, 4.448036193847656],\n [1.90129816532135, 4.3628973960876465],\n [2.0014259815216064, 4.294229507446289],\n [2.0832109451293945, 4.238814353942871],\n [2.149996757507324, 4.194070339202881],\n [2.204521894454956, 4.157923698425293],\n [2.249027729034424, 4.128708839416504],\n [2.285348415374756, 4.105085849761963],\n [2.31498384475708, 4.0859761238098145],\n [2.339160442352295, 4.070511341094971],\n [2.3588807582855225, 4.057991027832031],\n [2.3749637603759766, 4.0478515625],\n [2.3880786895751953, 4.039637088775635],\n [2.3987717628479004, 4.032979965209961],\n [2.40748929977417, 4.027583599090576],\n [2.414595603942871, 4.023208141326904],\n [2.4203879833221436, 4.019659042358398],\n [2.4251089096069336, 4.016779899597168],\n [2.4289560317993164, 4.014443874359131]]\n\n\n- loss 관찰\n\nplt.plot(loss_history)\n\n\n\n\n\n\n학습과정을 animation으로 시각화\n\nfrom matplotlib import animation\n\n\nplt.rcParams['figure.figsize'] = (7.5,2.5)\nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n- 왼쪽에는 \\((x_i,y_i)\\) and \\((x_i,\\hat{y}_i)\\) 을 그리고 오른쪽에는 \\(loss(w_0,w_1)\\) 을 그릴것임\n\nfig = plt.figure()\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n\n\n\n- 왼쪽그림!\n\nax1.plot(x,y,'o')\nline, = ax1.plot(x,yhat_history[0]) # 나중에 애니메이션 할때 필요해요..\n\n\nfig\n\n\n\n\n- 오른쪽 그림1: \\(loss(w_0,w_1)\\)\n\n_w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) \n_w1 = np.arange(-6, 11, 0.5)\nw1,w0 = np.meshgrid(_w1,_w0)\nlss=w0*0\nfor i in range(len(_w0)):\n    for j in range(len(_w1)):\n        lss[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2)\nax2.plot_surface(w0, w1, lss, rstride=1, cstride=1, color='b',alpha=0.35) ## 파란색곡면을 그리는 코드(끝) \nax2.azim = 40  ## 3d plot의 view 조절 \nax2.dist = 8   ## 3d plot의 view 조절 \nax2.elev = 5   ## 3d plot의 view 조절 \n\n\nfig\n\n\n\n\n- 오른쪽 그림2: \\((w_0,w_1)=(2.5,4)\\) 와 \\(loss(2.5,4)\\) 값 &lt;- loss 함수가 최소가 되는 값 (이거 진짜야? ㅋㅋ)\n\nax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color='red',marker='*') ## 최소점을 표시하는 코드 (붉은색 별) \n\n&lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7f65aca1f040&gt;\n\n\n\nfig\n\n\n\n\n- 오른쪽 그림3: \\((w_0,w_1)=(-3.66, 8.81)\\) 와 \\(loss(-3.66,8.81)\\) 값\n\nWhat_history[0]\n\n[-3.657747745513916, 8.81106948852539]\n\n\n\nax2.scatter(What_history[0][0],What_history[0][1],loss_history[0],color='grey') ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) \n\n&lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7f65ac8728b0&gt;\n\n\n\nfig\n\n\n\n\n- 애니메이션\n\ndef animate(epoc):\n    line.set_ydata(yhat_history[epoc])\n    ax2.scatter(What_history[epoc][0],What_history[epoc][1],loss_history[epoc],color='grey')\n    return line\n\nani = animation.FuncAnimation(fig, animate, frames=30)\nplt.close()\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 함수로 만들자..\n\ndef show_lrpr(data,history):\n    x,y = data \n    loss_history,yhat_history,What_history = history \n    \n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n    ## ax1: 왼쪽그림 \n    ax1.plot(x,y,'o')\n    line, = ax1.plot(x,yhat_history[0]) \n    ## ax2: 오른쪽그림 \n    _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) \n    _w1 = np.arange(-6, 11, 0.5)\n    w1,w0 = np.meshgrid(_w1,_w0)\n    lss=w0*0\n    for i in range(len(_w0)):\n        for j in range(len(_w1)):\n            lss[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2)\n    ax2.plot_surface(w0, w1, lss, rstride=1, cstride=1, color='b',alpha=0.35) ## 파란색곡면을 그리는 코드(끝) \n    ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color='red',marker='*') ## 최소점을 표시하는 코드 (붉은색 별) \n    ax2.scatter(What_history[0][0],What_history[0][1],loss_history[0],color='b') ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) \n    ax2.azim = 40  ## 3d plot의 view 조절 \n    ax2.dist = 8   ## 3d plot의 view 조절 \n    ax2.elev = 5   ## 3d plot의 view 조절 \n\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(What_history)[epoc,0],np.array(What_history)[epoc,1],loss_history[epoc],color='grey')\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n(서연필기) 알파의 정도에 따라 학습 속도가 달라져.."
  },
  {
    "objectID": "posts/ml/2022-09-21-ml_3w.html#alpha에-대하여-alpha는-학습률",
    "href": "posts/ml/2022-09-21-ml_3w.html#alpha에-대하여-alpha는-학습률",
    "title": "DNN (3주차)",
    "section": "\\(\\alpha\\)에 대하여 (\\(\\alpha\\)는 학습률)",
    "text": "\\(\\alpha\\)에 대하여 (\\(\\alpha\\)는 학습률)\n\n(1) \\(\\alpha=0.0001\\): \\(\\alpha\\) 가 너무 작다면? \\(\\to\\) 비효율적이다.\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0001 \nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n(2) \\(\\alpha=0.0083\\): \\(\\alpha\\)가 너무 크다면? \\(\\to\\) 다른의미에서 비효율적이다 + 위험하다..\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0083\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n(3) \\(\\alpha=0.0085\\)\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0085\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad.data; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n(서연필기) 최솟값보다 오히려 커지는 경향이 나와버림\n\n\n(4) \\(\\alpha=0.01\\)\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.01\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/ml/2022-09-21-ml_3w.html#숙제",
    "href": "posts/ml/2022-09-21-ml_3w.html#숙제",
    "title": "DNN (3주차)",
    "section": "숙제",
    "text": "숙제\n- 학습률(\\(\\alpha\\))를 조정하며 실습해보고 스크린샷 제출\n\n(1) \\(\\alpha=0.0015\\)\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.015\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n(2) \\(\\alpha=0.0038\\)\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0038\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html",
    "href": "posts/ml/2022-11-30-12wk.html",
    "title": "RNN (12주차)",
    "section": "",
    "text": "순환신경망 minor topics"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#data-abcabc",
    "href": "posts/ml/2022-11-30-12wk.html#data-abcabc",
    "title": "RNN (12주차)",
    "section": "data: abcabC",
    "text": "data: abcabC\n\ntxt = list('abcabC')*100\ntxt[:8]\ntxt_x = txt[:-1] \ntxt_y = txt[1:]\n\n\nmapping = {'a':0,'b':1,'c':2,'C':3} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx = x.to(\"cuda:0\")\ny = y.to(\"cuda:0\") \n\n\nx.shape\n\ntorch.Size([599, 4])"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#실험",
    "href": "posts/ml/2022-11-30-12wk.html#실험",
    "title": "RNN (12주차)",
    "section": "실험",
    "text": "실험\n- 실험1\n\nHIDDEN = 3\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment1: RNN with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()\n\n\n\n\n- 실험2\n\nHIDDEN = 4\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment2: RNN with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()\n\n\n\n\n- 실험3\n\nHIDDEN = 8\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,8))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment3: RNN with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#결론",
    "href": "posts/ml/2022-11-30-12wk.html#결론",
    "title": "RNN (12주차)",
    "section": "결론",
    "text": "결론\n- 노드수가 많으면 학습에 유리함\n(서연 필기) c/C를 맞추는 것(error)보다 확실한 규칙을 맞추는 것(underline)이 중요\\(\\to\\)오히려 맞추면 과적합으로 볼 수 있다 - 그래서 학습이 잘 되었으면 - 첫 칸 - 둘째 칸 - 셋쨰, 넷째 칸 - 이 순으로 predict 되었을 것"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#data-abcc",
    "href": "posts/ml/2022-11-30-12wk.html#data-abcc",
    "title": "RNN (12주차)",
    "section": "data: ab(c,C)",
    "text": "data: ab(c,C)\n\n# torch.manual_seed(43052)\n# txta = 'a'*50\n# txtb = 'b'*50\n# prob_upper = torch.bernoulli(torch.zeros(50)+0.5) \n# txtc = list(map(lambda x: 'c' if x==1 else 'C', prob_upper))\n# txt = ''.join([txta[i]+','+txtb[i]+','+txtc[i]+',' for i in range(50)]).split(',')[:-1]\n# txt_x = txt[:-1] \n# txt_y = txt[1:]\n# pd.DataFrame({'txt_x':txt_x,'txt_y':txt_y}).to_csv(\"2022-11-25-ab(c,C).csv\",index=False)\n\n\ndf= pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/main/posts/IV.%20RNN/2022-11-25-ab(c%2CC).csv\")\ndf\n\n\n\n\n\n\n\n\ntxt_x\ntxt_y\n\n\n\n\n0\na\nb\n\n\n1\nb\nc\n\n\n2\nc\na\n\n\n3\na\nb\n\n\n4\nb\nc\n\n\n...\n...\n...\n\n\n144\na\nb\n\n\n145\nb\nC\n\n\n146\nC\na\n\n\n147\na\nb\n\n\n148\nb\nc\n\n\n\n\n149 rows × 2 columns\n\n\n\n\nmapping = {'a':0,'b':1,'c':2,'C':3} \nx= torch.nn.functional.one_hot(torch.tensor(f(df.txt_x,mapping))).float()\ny= torch.nn.functional.one_hot(torch.tensor(f(df.txt_y,mapping))).float()\n\n\nx = x.to(\"cuda:0\")\ny = y.to(\"cuda:0\")"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#실험-1",
    "href": "posts/ml/2022-11-30-12wk.html#실험-1",
    "title": "RNN (12주차)",
    "section": "실험",
    "text": "실험\n- 실험1\n\nHIDDEN = 3\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combinded = torch.concat([yhat,y],axis=1)\n        ax[i][j].matshow(combinded.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment1: LSTM with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()\n\n\n\n\n- 실험2\n\nHIDDEN = 16\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combinded = torch.concat([yhat,y],axis=1)\n        ax[i][j].matshow(combinded.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment2: LSTM with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#결론-1",
    "href": "posts/ml/2022-11-30-12wk.html#결론-1",
    "title": "RNN (12주차)",
    "section": "결론",
    "text": "결론\n- 노드수가 너무 많으면 오버피팅 경향도 있음"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#data-human-numbers-5",
    "href": "posts/ml/2022-11-30-12wk.html#data-human-numbers-5",
    "title": "RNN (12주차)",
    "section": "data: human numbers 5",
    "text": "data: human numbers 5\n\ntxt = (['one',',','two',',','three',',','four',',','five',',']*100)[:-1]\n\n\nmapping = {',':0, 'one':1, 'two':2, 'three':3, 'four':4, 'five':5} \nmapping\n\n{',': 0, 'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5}\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:] \n\n\ntxt_x[0:5], txt_y[0:5]\n\n(['one', ',', 'two', ',', 'three'], [',', 'two', ',', 'three', ','])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#torch를-이용한-learn",
    "href": "posts/ml/2022-11-30-12wk.html#torch를-이용한-learn",
    "title": "RNN (12주차)",
    "section": "torch를 이용한 learn",
    "text": "torch를 이용한 learn\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(6,20).to(\"cuda:0\") \nlinr = torch.nn.Linear(20,6).to(\"cuda:0\") \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\n_water = torch.zeros(1,20).to(\"cuda:0\")\nfor epoc in range(50):\n    ## 1 \n    hidden, (hT,cT) =lstm(x,(_water,_water))\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()     \n\n\nplt.matshow(soft(output).data[-10:].to(\"cpu\"),cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f568441a1d0&gt;"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#fastai-이용한-learn",
    "href": "posts/ml/2022-11-30-12wk.html#fastai-이용한-learn",
    "title": "RNN (12주차)",
    "section": "fastai 이용한 learn",
    "text": "fastai 이용한 learn\n\nds1 = torch.utils.data.TensorDataset(x,y)\nds2 = torch.utils.data.TensorDataset(x,y) # dummy \ndl1 = torch.utils.data.DataLoader(ds1,batch_size=998)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=998) # dummy \ndls = DataLoaders(dl1,dl2) \n\nfastai 를 이용하여 class를 사용하기 위한 목차\n\nclass MyLSTM(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lstm = torch.nn.LSTM(6,20)\n        self.linr = torch.nn.Linear(20,6) \n    def forward(self,x):\n        _water = torch.zeros(1,20).to(\"cuda:0\")\n        hidden, (hT,cT) =self.lstm(x,(_water,_water))\n        output = self.linr(hidden)\n        return output         \n\n\nnet = MyLSTM().to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\n\n\nlrnr = Learner(dls,net,loss_fn,lr=0.1)\n\n\nlrnr.fit(50)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n1.722138\n1.502271\n00:00\n\n\n1\n1.611093\n1.973368\n00:00\n\n\n2\n1.734299\n1.481888\n00:00\n\n\n3\n1.669271\n1.377668\n00:00\n\n\n4\n1.608570\n1.368541\n00:00\n\n\n5\n1.566517\n1.267919\n00:00\n\n\n6\n1.521232\n1.106543\n00:00\n\n\n7\n1.465657\n0.959904\n00:00\n\n\n8\n1.404815\n0.856123\n00:00\n\n\n9\n1.344825\n0.802936\n00:00\n\n\n10\n1.290437\n0.794831\n00:00\n\n\n11\n1.244395\n0.771966\n00:00\n\n\n12\n1.203488\n0.735865\n00:00\n\n\n13\n1.165525\n0.690032\n00:00\n\n\n14\n1.129149\n0.621654\n00:00\n\n\n15\n1.092401\n0.555875\n00:00\n\n\n16\n1.055485\n0.493046\n00:00\n\n\n17\n1.018588\n0.423167\n00:00\n\n\n18\n0.981230\n0.349703\n00:00\n\n\n19\n0.943231\n0.279531\n00:00\n\n\n20\n0.904838\n0.216544\n00:00\n\n\n21\n0.866475\n0.166756\n00:00\n\n\n22\n0.828821\n0.125583\n00:00\n\n\n23\n0.792214\n0.094763\n00:00\n\n\n24\n0.757037\n0.072662\n00:00\n\n\n25\n0.723539\n0.055544\n00:00\n\n\n26\n0.691763\n0.042442\n00:00\n\n\n27\n0.661703\n0.032804\n00:00\n\n\n28\n0.633335\n0.025908\n00:00\n\n\n29\n0.606606\n0.020872\n00:00\n\n\n30\n0.581437\n0.017020\n00:00\n\n\n31\n0.557727\n0.014002\n00:00\n\n\n32\n0.535379\n0.011625\n00:00\n\n\n33\n0.514297\n0.009755\n00:00\n\n\n34\n0.494391\n0.008293\n00:00\n\n\n35\n0.475579\n0.007180\n00:00\n\n\n36\n0.457784\n0.006386\n00:00\n\n\n37\n0.440938\n0.005807\n00:00\n\n\n38\n0.424976\n0.005199\n00:00\n\n\n39\n0.409830\n0.004525\n00:00\n\n\n40\n0.395437\n0.003926\n00:00\n\n\n41\n0.381747\n0.003398\n00:00\n\n\n42\n0.368712\n0.002977\n00:00\n\n\n43\n0.356291\n0.002673\n00:00\n\n\n44\n0.344447\n0.002432\n00:00\n\n\n45\n0.333144\n0.002230\n00:00\n\n\n46\n0.322349\n0.002058\n00:00\n\n\n47\n0.312030\n0.001911\n00:00\n\n\n48\n0.302160\n0.001785\n00:00\n\n\n49\n0.292712\n0.001678\n00:00\n\n\n\n\n\n\nplt.matshow(soft(lrnr.model(x)[-10:]).data.to(\"cpu\"),cmap = 'bwr', vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f5687137bd0&gt;"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#data-hihello",
    "href": "posts/ml/2022-11-30-12wk.html#data-hihello",
    "title": "RNN (12주차)",
    "section": "data: hi?hello!!",
    "text": "data: hi?hello!!\n\ntxt = list('hi?hello!!')*100 \ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'!':0, '?':1,'h':2,'i':3,'e':4,'l':5,'o':6} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#세트1-_water의-생략",
    "href": "posts/ml/2022-11-30-12wk.html#세트1-_water의-생략",
    "title": "RNN (12주차)",
    "section": "세트1: _water의 생략",
    "text": "세트1: _water의 생략\n- 코드1: 정석코드\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\n\n\n_water = torch.zeros(1,4).to(\"cuda:0\")\nlstm(x, (_water,_water))\n\n(tensor([[-0.1547,  0.0673,  0.0695,  0.1563],\n         [-0.0786, -0.1430, -0.0250,  0.1189],\n         [-0.0300, -0.2256, -0.1324,  0.1439],\n         ...,\n         [-0.0723,  0.0620,  0.1913,  0.2015],\n         [-0.1155,  0.0746,  0.1747,  0.2938],\n         [-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n        grad_fn=&lt;SqueezeBackward1&gt;),\n (tensor([[-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n         grad_fn=&lt;SqueezeBackward1&gt;),\n  tensor([[-0.4451, -0.2456, -0.1900,  0.6232]], device='cuda:0',\n         grad_fn=&lt;SqueezeBackward1&gt;)))\n\n\n- 코드2: _water 는 사실 없어도 괜찮았어..\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\n\n\nlstm(x)\n\n(tensor([[-0.1547,  0.0673,  0.0695,  0.1563],\n         [-0.0786, -0.1430, -0.0250,  0.1189],\n         [-0.0300, -0.2256, -0.1324,  0.1439],\n         ...,\n         [-0.0723,  0.0620,  0.1913,  0.2015],\n         [-0.1155,  0.0746,  0.1747,  0.2938],\n         [-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n        grad_fn=&lt;SqueezeBackward1&gt;),\n (tensor([[-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n         grad_fn=&lt;SqueezeBackward1&gt;),\n  tensor([[-0.4451, -0.2456, -0.1900,  0.6232]], device='cuda:0',\n         grad_fn=&lt;SqueezeBackward1&gt;)))\n\n\n\nx.shape\n\ntorch.Size([999, 7])\n\n\n999개, 구별되는 문자 7개"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#세트2-x.shape-l-h_in-or-lnh_in",
    "href": "posts/ml/2022-11-30-12wk.html#세트2-x.shape-l-h_in-or-lnh_in",
    "title": "RNN (12주차)",
    "section": "세트2: x.shape = (\\(L\\), \\(H_{in}\\)) or (\\(L\\),\\(N\\),\\(H_{in}\\))",
    "text": "세트2: x.shape = (\\(L\\), \\(H_{in}\\)) or (\\(L\\),\\(N\\),\\(H_{in}\\))\n- 파라메터 설명\n\n\\(L\\) = sequece length = 시계열의 길이 = 간장을 몇 년 전통으로 이어갈지\n\\(N\\) = batch size = 전체데이터는 몇 개의 시계열이 있는지 = 전체 데이터를 몇개의 시계열로 쪼갤지 &lt;– 왜 이걸 해야해?\n\\(H_{in}\\) = input_size = 시점을 고정하였을 경우 입력자료의 차원 = 입력시계열이 시점별로 몇개의 변수로 나타내어 지는지? = 만약에 원핫인코딩으로 단어를 정리하면 단어수를 의미함\n\n우리가 실습했던 거 모두 N이 1이었다 그래서 안 썼음 - 1일 때만 아래와 같이 여러 버전 가능\n- 코드2: _water 는 사실 없어도 괜찮았어..\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\n\n\nlstm(x)\n\n(tensor([[-0.1547,  0.0673,  0.0695,  0.1563],\n         [-0.0786, -0.1430, -0.0250,  0.1189],\n         [-0.0300, -0.2256, -0.1324,  0.1439],\n         ...,\n         [-0.0723,  0.0620,  0.1913,  0.2015],\n         [-0.1155,  0.0746,  0.1747,  0.2938],\n         [-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n        grad_fn=&lt;SqueezeBackward1&gt;),\n (tensor([[-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n         grad_fn=&lt;SqueezeBackward1&gt;),\n  tensor([[-0.4451, -0.2456, -0.1900,  0.6232]], device='cuda:0',\n         grad_fn=&lt;SqueezeBackward1&gt;)))\n\n\n- 코드3: x의 차원은 사실 엄밀하게는 (\\(L\\),\\(N\\),\\(H_{in}\\)) 와 같다…\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\n\n\nlstm(x.reshape(999,1,7))\n\n(tensor([[[-0.1547,  0.0673,  0.0695,  0.1563]],\n \n         [[-0.0786, -0.1430, -0.0250,  0.1189]],\n \n         [[-0.0300, -0.2256, -0.1324,  0.1439]],\n \n         ...,\n \n         [[-0.0723,  0.0620,  0.1913,  0.2015]],\n \n         [[-0.1155,  0.0746,  0.1747,  0.2938]],\n \n         [[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n        grad_fn=&lt;CudnnRnnBackward0&gt;),\n (tensor([[[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n         grad_fn=&lt;CudnnRnnBackward0&gt;),\n  tensor([[[-0.4451, -0.2456, -0.1900,  0.6232]]], device='cuda:0',\n         grad_fn=&lt;CudnnRnnBackward0&gt;)))\n\n\n- 코드4: batch_first=True옵션을 사용하여 lstm을 만든경우\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4,batch_first=True).to(\"cuda:0\")\n\n\nlstm(x.reshape(1,999,7))\n\n(tensor([[[-0.1547,  0.0673,  0.0695,  0.1563],\n          [-0.0786, -0.1430, -0.0250,  0.1189],\n          [-0.0300, -0.2256, -0.1324,  0.1439],\n          ...,\n          [-0.0723,  0.0620,  0.1913,  0.2015],\n          [-0.1155,  0.0746,  0.1747,  0.2938],\n          [-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n        grad_fn=&lt;CudnnRnnBackward0&gt;),\n (tensor([[[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n         grad_fn=&lt;CudnnRnnBackward0&gt;),\n  tensor([[[-0.4451, -0.2456, -0.1900,  0.6232]]], device='cuda:0',\n         grad_fn=&lt;CudnnRnnBackward0&gt;)))"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#세트3-hidden.shape-dtimes-num_layers-h_out-or-dtimes-num_layers-n-h_out",
    "href": "posts/ml/2022-11-30-12wk.html#세트3-hidden.shape-dtimes-num_layers-h_out-or-dtimes-num_layers-n-h_out",
    "title": "RNN (12주차)",
    "section": "세트3: hidden.shape = (\\(D\\times\\) num_layers, \\(H_{out}\\)) or (\\(D\\times\\) num_layers, \\(N\\), \\(H_{out}\\))",
    "text": "세트3: hidden.shape = (\\(D\\times\\) num_layers, \\(H_{out}\\)) or (\\(D\\times\\) num_layers, \\(N\\), \\(H_{out}\\))\n- 파라메터 설명\n\n\\(D\\) = 2 if bidirectional=True otherwise 1 = 양방향이면 2, 단방향이면 1 (우리는 단방향만 배움)\nnum_layres = 중첩된 RNN일 경우 (우리는 중첩을 안시켰음)\n\\(N\\) = batch size = 전체데이터는 몇 개의 시계열이 있는지 = 전체 데이터를 몇개의 시계열로 쪼갤지 &lt;– 왜 이걸 해야해?\n\\(H_{out}\\) = 히든노드의 수\n\n- 코드5: x.shape = (\\(L\\),\\(1\\),\\(H_{in}\\)) \\(\\to\\) hidden.shape = (\\(1\\),\\(1\\),\\(H_{out}\\))\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\n\n\n_water = torch.zeros(1,1,4).to(\"cuda:0\") \nlstm(x.reshape(999,1,7),(_water,_water))\n\n(tensor([[[-0.1547,  0.0673,  0.0695,  0.1563]],\n \n         [[-0.0786, -0.1430, -0.0250,  0.1189]],\n \n         [[-0.0300, -0.2256, -0.1324,  0.1439]],\n \n         ...,\n \n         [[-0.0723,  0.0620,  0.1913,  0.2015]],\n \n         [[-0.1155,  0.0746,  0.1747,  0.2938]],\n \n         [[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n        grad_fn=&lt;CudnnRnnBackward0&gt;),\n (tensor([[[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n         grad_fn=&lt;CudnnRnnBackward0&gt;),\n  tensor([[[-0.4451, -0.2456, -0.1900,  0.6232]]], device='cuda:0',\n         grad_fn=&lt;CudnnRnnBackward0&gt;)))\n\n\n- 사실 _water.shape = (1,\\(H_{out}\\)) 에서 1은 observation의 차원을 의미하는게 아님 (그런데 대충 그렇게 생각해도 무방함)\n\n한 시점의 콩물에 대하여 양방향으로 간장을 만들면 _water.shape = (2,h)\n한 시점의 콩물에 대하여 3중첩으로 간장을 만들면 _water.shape = (3,h)\n한 시점의 콩물에 대하여 3중첩간장을 양방향으로 만들면 _water.shape = (6,h)"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#data-hihello-1",
    "href": "posts/ml/2022-11-30-12wk.html#data-hihello-1",
    "title": "RNN (12주차)",
    "section": "data: hi?hello!!",
    "text": "data: hi?hello!!\n\ntxt = list('hi?hello!!')*100 \ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'!':0, '?':1,'h':2,'i':3,'e':4,'l':5,'o':6} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#세트1-_water의-생략-1",
    "href": "posts/ml/2022-11-30-12wk.html#세트1-_water의-생략-1",
    "title": "RNN (12주차)",
    "section": "세트1: _water의 생략",
    "text": "세트1: _water의 생략\n- 코드1: 정석코드\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\") \n\n\nxt = x[[1]]\n_water = torch.zeros(1,4).to(\"cuda:0\")\nxt.shape, _water.shape\n\n(torch.Size([1, 7]), torch.Size([1, 4]))\n\n\n\nlstmcell(xt,(_water,_water))\n\n(tensor([[-0.0290, -0.1758, -0.0537,  0.0598]], device='cuda:0',\n        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;),\n tensor([[-0.0582, -0.4566, -0.1256,  0.1922]], device='cuda:0',\n        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;))\n\n\n- 코드2: _water의 생략\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\") \n\n\nxt = x[[1]]\nxt.shape\n\ntorch.Size([1, 7])\n\n\n\nlstmcell(xt)\n\n(tensor([[-0.0290, -0.1758, -0.0537,  0.0598]], device='cuda:0',\n        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;),\n tensor([[-0.0582, -0.4566, -0.1256,  0.1922]], device='cuda:0',\n        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;))"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#세트2-xt.shape-nh_in-or-h_in",
    "href": "posts/ml/2022-11-30-12wk.html#세트2-xt.shape-nh_in-or-h_in",
    "title": "RNN (12주차)",
    "section": "세트2: xt.shape = (\\(N\\),\\(H_{in}\\)) or (\\(H_{in}\\))",
    "text": "세트2: xt.shape = (\\(N\\),\\(H_{in}\\)) or (\\(H_{in}\\))\nn: timeserie 개수, 1일 경우 생략 가능\n- 코드2: _water의 생략\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\") \n\n\nxt = x[[1]]\nxt.shape\n\ntorch.Size([1, 7])\n\n\n\nlstmcell(xt)\n\n(tensor([[-0.0290, -0.1758, -0.0537,  0.0598]], device='cuda:0',\n        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;),\n tensor([[-0.0582, -0.4566, -0.1256,  0.1922]], device='cuda:0',\n        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;))\n\n\n- 코드3:\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\") \n\n\nxt = x[1]\nxt.shape\n\ntorch.Size([7])\n\n\n\nlstmcell(xt)\n\n(tensor([-0.0290, -0.1758, -0.0537,  0.0598], device='cuda:0',\n        grad_fn=&lt;SqueezeBackward1&gt;),\n tensor([-0.0582, -0.4566, -0.1256,  0.1922], device='cuda:0',\n        grad_fn=&lt;SqueezeBackward1&gt;))\n\n\n(1,n)의 형태라면 괄호 하나 빼도 가능"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#세트3-hidden.shape-nh_out-or-h_out",
    "href": "posts/ml/2022-11-30-12wk.html#세트3-hidden.shape-nh_out-or-h_out",
    "title": "RNN (12주차)",
    "section": "세트3: hidden.shape = (\\(N\\),\\(H_{out}\\)) or (\\(H_{out}\\))",
    "text": "세트3: hidden.shape = (\\(N\\),\\(H_{out}\\)) or (\\(H_{out}\\))\n- 코드4: xt.shape = (\\(H_{out}\\)) \\(\\to\\) _water.shape = \\((H_{out})\\)\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\") \n\n\nxt = x[1]\n_water = torch.zeros(4).to(\"cuda:0\")\nxt.shape,_water.shape\n\n(torch.Size([7]), torch.Size([4]))\n\n\n\nlstmcell(xt, (_water,_water))\n\n(tensor([-0.0290, -0.1758, -0.0537,  0.0598], device='cuda:0',\n        grad_fn=&lt;SqueezeBackward1&gt;),\n tensor([-0.0582, -0.4566, -0.1256,  0.1922], device='cuda:0',\n        grad_fn=&lt;SqueezeBackward1&gt;))"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#똑같은-코드들-정리",
    "href": "posts/ml/2022-11-30-12wk.html#똑같은-코드들-정리",
    "title": "RNN (12주차)",
    "section": "똑같은 코드들 정리",
    "text": "똑같은 코드들 정리\n- 원래 1은 단순히 observation의 차원이 아니다. 즉 \\({\\bf X}_{n \\times p}\\)에서 \\(n\\)에 대응하는 차원으로 생각할 수 없다.\n- 그런데 (1) 단방향 (2) 조각내지 않은 시계열 (3) 중첩하지 않은 순환망에 한정하여서는 observation 처럼 생각해도 무방하다. &lt;– 엄밀하게는 이게 위험한 생각임. 하지만 정식으로 모두 따지려면 너무 헷갈림"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#실제구현시-기억할-것",
    "href": "posts/ml/2022-11-30-12wk.html#실제구현시-기억할-것",
    "title": "RNN (12주차)",
    "section": "실제구현시 기억할 것",
    "text": "실제구현시 기억할 것\n- 현실적으로 (1)-(3)이 아닌 조건에서는 Cell 단위로 연산을 이용할 일이 없다. (느리거든요) // 그냥 이해용으로 구현\n- torch.nn.RNN 혹은 torch.nn.LSTM 으로 네트워크를 구성할시 _water의 dim을 명시할 일도 없다.\n- 오로지 고려해야 할 것은 입력시계열을 조각낼지 조각내지 않을지"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#data",
    "href": "posts/ml/2022-11-30-12wk.html#data",
    "title": "RNN (12주차)",
    "section": "data",
    "text": "data\n\ntxt = list('hi!')*3 + list('hi?')*3"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#조각내지-않은-시계열",
    "href": "posts/ml/2022-11-30-12wk.html#조각내지-않은-시계열",
    "title": "RNN (12주차)",
    "section": "조각내지 않은 시계열",
    "text": "조각내지 않은 시계열\n\ntxt_x = txt[:-1] \ntxt_y = txt[1:] \n\n\nmapping = {'!':0, '?':1, 'h':2, 'i':3} \nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")\n\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\nlinr = torch.nn.Linear(10,4).to(\"cuda:0\")\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1 \n    hidden, _ = lstm(x) \n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nhidden, _ = lstm(x)\nplt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f5686bc0b90&gt;\n\n\n\n\n\n첫번째 stack은 hi!로 학습 두번째 stack은 hi?로 학습하여 결과가 이럼"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#조각난-시계열",
    "href": "posts/ml/2022-11-30-12wk.html#조각난-시계열",
    "title": "RNN (12주차)",
    "section": "조각난 시계열",
    "text": "조각난 시계열\n\ntxt1= txt[:9]\ntxt2= txt[9:]\n\n\ntxt1,txt2\n\n(['h', 'i', '!', 'h', 'i', '!', 'h', 'i', '!'],\n ['h', 'i', '?', 'h', 'i', '?', 'h', 'i', '?'])\n\n\n\ntxt1_x = txt1[:-1] \ntxt1_y = txt1[1:] \ntxt2_x = txt2[:-1] \ntxt2_y = txt2[1:] \n\n\nmapping = {'!':0, '?':1, 'h':2, 'i':3} \nx1 = torch.nn.functional.one_hot(torch.tensor(f(txt1_x,mapping))).float().to(\"cuda:0\")\ny1 = torch.nn.functional.one_hot(torch.tensor(f(txt1_y,mapping))).float().to(\"cuda:0\")\nx2 = torch.nn.functional.one_hot(torch.tensor(f(txt2_x,mapping))).float().to(\"cuda:0\")\ny2 = torch.nn.functional.one_hot(torch.tensor(f(txt2_y,mapping))).float().to(\"cuda:0\")\n\n9에서 하나씩 빼서 x,y 만들었으니까 8\n\nx1.shape, y1.shape, x2.shape, y2.shape\n\n(torch.Size([8, 4]),\n torch.Size([8, 4]),\n torch.Size([8, 4]),\n torch.Size([8, 4]))\n\n\n\nxx = torch.stack([x1,x2],axis=1)\nyy = torch.stack([y1,y2],axis=1)\nxx.shape, yy.shape\n\n(torch.Size([8, 2, 4]), torch.Size([8, 2, 4]))\n\n\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\nlinr = torch.nn.Linear(10,4).to(\"cuda:0\")\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1 \n    hidden, _ = lstm(xx) \n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output[:,0,:],yy[:,0,:]) + loss_fn(output[:,1,:],yy[:,1,:])\n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n첫번째 stzck 과 두번째 stack의 합\n  loss = loss_fn(output[:,0,:],yy[:,0,:]) + loss_fn(output[:,1,:],yy[:,1,:])\n\nfig , ax = plt.subplots(1,2) \nax[0].matshow(soft(output[:,0,:]).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\nax[1].matshow(soft(output[:,1,:]).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f5687aed450&gt;\n\n\n\n\n\nxx로 학습한 것들인데 만약 x를 넣는다면?\n\nhidden, _ = lstm(x)\nplt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f5687accf50&gt;\n\n\n\n\n\n\nhidden, _ = lstm(x1)\nplt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f5687add750&gt;\n\n\n\n\n\n\nhidden, _ = lstm(x2)\nplt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f56820f78d0&gt;\n\n\n\n\n\n\nhidden.shape\n\ntorch.Size([17, 10])\n\n\n\nlinr(hidden).shape\n\ntorch.Size([17, 4])\n\n\n- 조각난 시계열로 학습한 경우는 hi!에서 hi?로 바뀔 수 없다. 왜냐햐면 그러한 연결정보가 끊어져 있으니까"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#재미있는-실험",
    "href": "posts/ml/2022-11-30-12wk.html#재미있는-실험",
    "title": "RNN (12주차)",
    "section": "재미있는 실험",
    "text": "재미있는 실험\n- x1만 배운다면?\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\nlinr = torch.nn.Linear(10,4).to(\"cuda:0\")\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1 \n    hidden, _ = lstm(x1) \n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y1)\n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nhidden, _ = lstm(x2)\nplt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f6b701ba890&gt;\n\n\n\n\n\n- x2만 배운다면?\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\nlinr = torch.nn.Linear(10,4).to(\"cuda:0\")\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1 \n    hidden, _ = lstm(x2) \n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y2)\n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nhidden, _ = lstm(x1)\nplt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f6b9809ef50&gt;"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#data-human-numbers-5-1",
    "href": "posts/ml/2022-11-30-12wk.html#data-human-numbers-5-1",
    "title": "RNN (12주차)",
    "section": "data: human numbers 5",
    "text": "data: human numbers 5\n\ntxt = (['one',',','two',',','three',',','four',',','five',',']*100)[:-1]\n\n\nmapping = {',':0, 'one':1, 'two':2, 'three':3, 'four':4, 'five':5} \nmapping\n\n{',': 0, 'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5}\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:] \n\n\ntxt_x[0:5], txt_y[0:5]\n\n(['one', ',', 'two', ',', 'three'], [',', 'two', ',', 'three', ','])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#fastai-이용한-learn-1",
    "href": "posts/ml/2022-11-30-12wk.html#fastai-이용한-learn-1",
    "title": "RNN (12주차)",
    "section": "fastai 이용한 learn",
    "text": "fastai 이용한 learn\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=998)\n한 뭉치에 몇 개 있는지\ntorch.nn.LSTM(batxh_size)\n몇 개로 나눠져 있는지\n\nds1 = torch.utils.data.TensorDataset(x,y)\nds2 = torch.utils.data.TensorDataset(x,y) # dummy \ndl1 = torch.utils.data.DataLoader(ds1,batch_size=998)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=998) # dummy \ndls = DataLoaders(dl1,dl2) \n\n\nclass MyLSTM(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        torch.manual_seed(43052)\n        self.lstm = torch.nn.LSTM(6,20)\n        self.linr = torch.nn.Linear(20,6) \n    def forward(self,x):\n        _water = torch.zeros(1,20).to(\"cuda:0\")\n        hidden, (hT,cT) =self.lstm(x,(_water,_water))\n        output = self.linr(hidden)\n        return output         \n\n\nnet = MyLSTM().to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\n\n\nlrnr = Learner(dls,net,loss_fn,lr=0.1)\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n1.762846\n1.502211\n00:00\n\n\n1\n1.631212\n1.620583\n00:00\n\n\n2\n1.627597\n1.443686\n00:00\n\n\n3\n1.580216\n1.368762\n00:00\n\n\n4\n1.536200\n1.307310\n00:00\n\n\n5\n1.496099\n1.216339\n00:00\n\n\n6\n1.453670\n1.113821\n00:00\n\n\n7\n1.408125\n1.019931\n00:00\n\n\n8\n1.361426\n0.941434\n00:00\n\n\n9\n1.315507\n0.884034\n00:00\n\n\n\n\n\n\nsoft(lrnr.model(x)).data.to(\"cpu\").numpy().round(3)\n\narray([[0.935, 0.009, 0.015, 0.011, 0.016, 0.014],\n       [0.133, 0.164, 0.242, 0.172, 0.141, 0.147],\n       [0.982, 0.003, 0.004, 0.003, 0.004, 0.003],\n       ...,\n       [0.122, 0.171, 0.242, 0.174, 0.146, 0.144],\n       [0.984, 0.003, 0.004, 0.002, 0.004, 0.003],\n       [0.119, 0.172, 0.244, 0.175, 0.144, 0.145]], dtype=float32)"
  },
  {
    "objectID": "posts/ml/2022-11-30-12wk.html#torch를-이용한-learn-1",
    "href": "posts/ml/2022-11-30-12wk.html#torch를-이용한-learn-1",
    "title": "RNN (12주차)",
    "section": "torch를 이용한 learn",
    "text": "torch를 이용한 learn\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(6,20).to(\"cuda:0\") \nlinr = torch.nn.Linear(20,6).to(\"cuda:0\") \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\noptim으로 adam 사용\n\nfor epoc in range(10):\n    ## 1 \n    hidden, _ = lstm(x)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()     \n\n\nhidden, _ = lstm(x)\noutput = linr(hidden) \nsoft(output).data.to(\"cpu\").numpy().round(3)\n\narray([[0.935, 0.009, 0.015, 0.011, 0.016, 0.014],\n       [0.133, 0.164, 0.242, 0.172, 0.141, 0.147],\n       [0.982, 0.003, 0.004, 0.003, 0.004, 0.003],\n       ...,\n       [0.122, 0.171, 0.242, 0.174, 0.146, 0.144],\n       [0.984, 0.003, 0.004, 0.002, 0.004, 0.003],\n       [0.119, 0.172, 0.244, 0.175, 0.145, 0.145]], dtype=float32)"
  },
  {
    "objectID": "posts/ml/2022-10-12-ml-6w.html",
    "href": "posts/ml/2022-10-12-ml-6w.html",
    "title": "DNN (6주차)",
    "section": "",
    "text": "기계학습 특강 (6주차) 10월5일 [딥러닝의 기초 - 깊은신경망(2)– 시벤코정리, 신경망의표현, CPU vs GPU, 확률적경사하강법, 오버피팅]"
  },
  {
    "objectID": "posts/ml/2022-10-12-ml-6w.html#imports",
    "href": "posts/ml/2022-10-12-ml-6w.html#imports",
    "title": "DNN (6주차)",
    "section": "imports",
    "text": "imports\n\nimport torch\nimport torchvision\nfrom fastai.data.all import *\nimport matplotlib.pyplot as plt\n\n\nimport graphviz\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"'+s + '; }');\n\n\n#hide\ngraphviz.set_jupyter_format('png')\n\n'png'"
  },
  {
    "objectID": "posts/ml/2022-10-12-ml-6w.html#시벤코정리",
    "href": "posts/ml/2022-10-12-ml-6w.html#시벤코정리",
    "title": "DNN (6주차)",
    "section": "시벤코정리",
    "text": "시벤코정리\n\n지난시간 논리전개\n- 아이디어: linear -&gt; relu -&gt; linear (-&gt; sigmoid) 조합으로 꺽은선으로 표현되는 underlying 을 표현할 수 있었다. - 아이디어의 실용성: 실제자료에서 꺾은선으로 표현되는 underlying은 몇개 없을 것 같음. 그건 맞는데 꺾이는 점을 많이 설정하면 얼추 비슷하게는 “근사” 시킬 수 있음. - 아이디어의 확장성: 이러한 논리전개는 X:(n,2)인 경우도 가능했음. (이 경우 꺾인선은 꺾인평면이 된다) - 아이디어에 해당하는 용어정리: 이 구조가 x-&gt;y 로 바로 가는 것이 아니라 x-&gt;(u1-&gt;v1)-&gt;(u2-&gt;v2)=y 의 구조인데 이러한 네트워크를 하나의 은닉층을 포함하는 네트워크라고 표현한다. (이 용어는 이따가..)\n\n\n시벤코정리\nuniversal approximation thm: (범용근사정리,보편근사정리,시벤코정리), 1989\n\n하나의 은닉층을 가지는 “linear -&gt; sigmoid -&gt; linear” 꼴의 네트워크를 이용하여 세상에 존재하는 모든 (다차원) 연속함수를 원하는 정확도로 근사시킬 수 있다. (계수를 잘 추정한다면)\n\n- 사실 엄청 이해안되는 정리임. 왜냐햐면, - 그렇게 잘 맞추면 1989년에 세상의 모든 문제를 다 풀어야 한거 아니야? - 요즘은 “linear -&gt; sigmoid -&gt; linear” 가 아니라 “linear -&gt; relu -&gt; linear” 조합으로 많이 쓰던데? - 요즘은 하나의 은닉층을 포함하는 네트워크는 잘 안쓰지 않나? 은닉층이 여러개일수록 좋다고 어디서 본 것 같은데?\n- 약간의 의구심이 있지만 아무튼 universal approximation thm에 따르면 우리는 아래와 같은 무기를 가진 꼴이 된다. - 우리의 무기: \\({\\bf X}: (n,p)\\) 꼴의 입력에서 \\({\\bf y}:(n,1)\\) 꼴의 출력으로 향하는 맵핑을 “linear -&gt; relu -&gt; linear”와 같은 네트워크를 이용해서 “근사”시킬 수 있다.\n(서연 필기) 한 층만 있어도 노드가 충분히 크면 은닉층 한 층으로 충분히 맞출 수 있다."
  },
  {
    "objectID": "posts/ml/2022-10-12-ml-6w.html#시벤코정리-proof",
    "href": "posts/ml/2022-10-12-ml-6w.html#시벤코정리-proof",
    "title": "DNN (6주차)",
    "section": "시벤코정리 proof",
    "text": "시벤코정리 proof\n\n그림으로 보는 증명과정\n- 데이터\n\nx = torch.linspace(-10,10,200).reshape(-1,1)\n\n- 아래와 같은 네트워크를 고려하자.\n\nl1 = torch.nn.Linear(in_features=1,out_features=2)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=2,out_features=1)\n\n- 직관1: \\(l_1\\),\\(l_2\\)의 가중치를 잘 결합하다보면 우연히 아래와 같이 만들 수 있다.\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+10.00,+10.00])\n\n\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\n\n\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,color='C2'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$')\n\nText(0.5, 1.0, '$(l_2 \\\\circ a_1 \\\\circ \\\\l_1)(x)$')\n\n\n\n\n\n- 직관2: 아래들도 가능할듯?\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+0.00,+20.00])\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data,'--',color='C0'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data,'--',color='C0'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C0'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\n\n\n\n\n(서연 필기) 밑에 fig 다시 정의 안 해줬잖아. 그러니까 덮어쓴 거라 생각하면 돼\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+20.00,+0.00])\nl2.weight.data = torch.tensor([[2.50,2.50]])\nl2.bias.data = torch.tensor([-2.50])\nax[0].plot(x,l1(x).data,'--',color='C1'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data,'--',color='C1'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C1'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nfig\n\n\n\n\n- 은닉층의노드수=4로 하고 적당한 가중치를 조정하면 \\((l_2\\circ a_1 \\circ l_1)(x)\\)의 결과로 주황색선 + 파란색선도 가능할 것 같다. \\(\\to\\) 실제로 가능함\n\nl1 = torch.nn.Linear(in_features=1,out_features=4)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=4,out_features=1)\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00],[-5.00],[5.00]])\nl1.bias.data = torch.tensor([0.00, 20.00, 20.00, 0])\nl2.weight.data = torch.tensor([[1.00,  1.00, 2.50,  2.50]])\nl2.bias.data = torch.tensor([-1.0-2.5])\n\n\nplt.plot(l2(a1(l1(x))).data)\n\n\n\n\n- 2개의 시그모이드를 우연히 잘 결합하면 아래와 같은 함수 \\(h\\)를 만들 수 있다.\n\nh = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\n\n\nplt.plot(x,h(x))\nplt.title(\"$h(x)$\")\n\nText(0.5, 1.0, '$h(x)$')\n\n\n\n\n\n- 위와 같은 함수 \\(h\\)를 활성화함수로 하고 \\(m\\)개의 노드를 가지는 은닉층을 생각해보자. 이러한 은닉층을 사용한다면 전체 네트워크를 아래와 같이 표현할 수 있다.\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n그리고 위의 네트워크와 동일한 효과를 주는 아래의 네트워크가 항상 존재함.\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,2m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n- \\(h(x)\\)를 활성화함수로 가지는 네트워크를 설계하여 보자.\n\nclass MyActivation(torch.nn.Module): ## 사용자정의 활성화함수를 선언하는 방법\n    def __init__(self):\n        super().__init__() \n    def forward(self, input):\n        return h(input) # activation 의 출력 \n\nforward 순전파\nbackward 역전파\n\na1=MyActivation()\n# a1 = torch.nn.Sigmoid(), a1 = torch.nn.ReLU() 대신에 a1 = MyActivation()\n\n\nplt.plot(x,a1(x)) \n\n\n\n\n히든레이어가 1개의 노드를 가지는 경우\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,1),\n            MyActivation(),\n            torch.nn.Linear(1,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')\n\n\n\n\n히든레이어가 2개의 노드를 가지는 경우\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,2),\n            MyActivation(),\n            torch.nn.Linear(2,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')\n\n\n\n\n히든레이어가 3개의 노드를 가지는 경우\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,3),\n            MyActivation(),\n            torch.nn.Linear(3,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')\n\n\n\n\n히든레이어가 1024개의 노드를 가지는 경우\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,1024),\n            MyActivation(),\n            torch.nn.Linear(1024,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')\n\n\n\n\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,2048),\n            MyActivation(),\n            torch.nn.Linear(2048,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/ml/2022-10-12-ml-6w.html#시벤코정리-활용",
    "href": "posts/ml/2022-10-12-ml-6w.html#시벤코정리-활용",
    "title": "DNN (6주차)",
    "section": "시벤코정리 활용",
    "text": "시벤코정리 활용\n- 아래와 같이 하나의 은닉층을 가지고 있더라도 많은 노드수만 보장되면 매우 충분한 표현력을 가짐\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n예제1 (sin, exp)\n\ntorch.manual_seed(43052)\nx = torch.linspace(-10,10,200).reshape(-1,1)\nunderlying = torch.sin(2*x) + torch.sin(0.5*x) + torch.exp(-0.2*x)\neps = torch.randn(200).reshape(-1,1)*0.1\ny = underlying + eps \nplt.plot(x,y,'o',alpha=0.5)\nplt.plot(x,underlying,lw=3)\n\n\n\n\n\nh = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\nclass MyActivation(torch.nn.Module): ## 사용자정의 활성화함수를 선언하는 방법\n    def __init__(self):\n        super().__init__() \n    def forward(self, input):\n        return h(input) \n\n\nnet= torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    MyActivation(),\n    torch.nn.Linear(2048,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters()) \n\nmseloss쓴 거 확인\n\nfor epoc in range(200):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.2)\nplt.plot(x,underlying,lw=3)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n예제2 (스펙높아도 취업X)\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex0.csv')\ndf\n\n\n\n\n\n\n\n\nx\nunderlying\ny\n\n\n\n\n0\n-1.000000\n0.000045\n0.0\n\n\n1\n-0.998999\n0.000046\n0.0\n\n\n2\n-0.997999\n0.000047\n0.0\n\n\n3\n-0.996998\n0.000047\n0.0\n\n\n4\n-0.995998\n0.000048\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n0.995998\n0.505002\n0.0\n\n\n1996\n0.996998\n0.503752\n0.0\n\n\n1997\n0.997999\n0.502501\n0.0\n\n\n1998\n0.998999\n0.501251\n1.0\n\n\n1999\n1.000000\n0.500000\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nx = torch.tensor(df.x).reshape(-1,1).float()\ny = torch.tensor(df.y).reshape(-1,1).float()\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(df.x,df.underlying,lw=3)\n\n\n\n\n\nh = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\nclass MyActivation(torch.nn.Module): ## 사용자정의 활성화함수를 선언하는 방법\n    def __init__(self):\n        super().__init__() \n    def forward(self, input):\n        return h(input) \n\n\ntorch.manual_seed(43052)\nnet= torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    MyActivation(),\n    torch.nn.Linear(2048,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters()) \n\nBCEloss쓴 거 확인\n\nfor epoc in range(100):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.2)\nplt.plot(df.x,df.underlying,lw=3)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n예제3 (MNIST data with DNN)\n\n# 예비학습\n(예비학습1) Path\n\npath = untar_data(URLs.MNIST) \npath\n\nPath('/home/csy/.fastai/data/mnist_png')\n\n\n\npath 도 오브젝트임\npath 도 정보+기능이 있음\n\n- path의 정보\n\npath._str # 숨겨놓았네?\n\n'/home/csy/.fastai/data/mnist_png'\n\n\n- 기능1\npath는 객체,\n\npath.ls()\n\n(#2) [Path('/home/csy/.fastai/data/mnist_png/training'),Path('/home/csy/.fastai/data/mnist_png/testing')]\n\n\npath object의 list 보여주는 역할\n- 기능2\n\npath/'training'\n\nPath('/home/csy/.fastai/data/mnist_png/training')\n\n\n\npath/'testing'\n\nPath('/home/csy/.fastai/data/mnist_png/testing')\n\n\n- 기능1과 기능2의 결합\n\n(path/'training/3').ls()\n\n(#6131) [Path('/home/csy/.fastai/data/mnist_png/training/3/35407.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/26671.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/16171.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/15346.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/34710.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/48873.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/28796.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/15651.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/6894.png'),Path('/home/csy/.fastai/data/mnist_png/training/3/37927.png')...]\n\n\n\n! ls /home/csy/.fastai/data/mnist_png\n\ntesting  training\n\n\n\n! ls /home/csy/.fastai/data/mnist_png/training\n\n0  1  2  3  4  5  6  7  8  9\n\n\n\n! ls /home/csy/.fastai/data/mnist_png/testing\n\n0  1  2  3  4  5  6  7  8  9\n\n\n\n‘/home/cgb4/.fastai/data/mnist_png/training/3/37912.png’ 이 파일을 더블클릭하면 이미지가 보인단 말임\n\n(예비학습2) plt.imshow\n\nimgtsr = torch.tensor([[1.0,2],[2.0,4.0]])\nimgtsr\n\ntensor([[1., 2.],\n        [2., 4.]])\n\n\n\nplt.imshow(imgtsr,cmap='gray')\nplt.colorbar()\n\n&lt;matplotlib.colorbar.Colorbar at 0x7fa03ee40f10&gt;\n\n\n\n\n\n\nimgtsr = torch.tensor([0.1,0.2,0.3,0.4]).reshape(2,2)\nimgtsr\n\ntensor([[0.1000, 0.2000],\n        [0.3000, 0.4000]])\n\n\n\nplt.imshow(imgtsr,cmap='gray')\nplt.colorbar()\n\n&lt;matplotlib.colorbar.Colorbar at 0x7fa03ebb70a0&gt;\n\n\n\n\n\n(예비학습3) torchvision\n- ’/home/cgb4/.fastai/data/mnist_png/training/3/37912.png’의 이미지파일을 torchvision.io.read_image 를 이용하여 텐서로 만듬\n!ls '/home/csy/.fastai/data/mnist_png/training/3'\n\nimgtsr = torchvision.io.read_image('/home/csy/.fastai/data/mnist_png/training/3/37912.png')\nimgtsr\n\ntensor([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66, 138,\n          149, 180, 138, 138,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,  22, 162, 161, 228, 252, 252,\n          253, 252, 252, 252, 252,  74,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0, 116, 253, 252, 252, 252, 189,\n          184, 110, 119, 252, 252,  32,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,  74, 161, 160,  77,  45,   4,\n            0,   0,  70, 252, 210,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,  22, 205, 252,  32,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0, 162, 253, 245,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           36, 219, 252, 139,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          222, 252, 202,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43,\n          253, 252,  89,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 240,\n          253, 157,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7, 160, 253,\n          231,  42,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 142, 252, 252,\n           42,  30,  78, 161,  36,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 184, 252, 252,\n          185, 228, 252, 252, 168,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 184, 252, 252,\n          253, 252, 252, 252, 116,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 101, 179, 252,\n          253, 252, 252, 210,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  22,\n          255, 253, 215,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  34,  89, 244,\n          253, 223,  98,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0, 116, 123, 142, 234, 252, 252,\n          184,  67,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0, 230, 253, 252, 252, 252, 168,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0, 126, 253, 252, 168,  43,   2,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]],\n       dtype=torch.uint8)\n\n\n- 이 텐서는 (1,28,28)의 shape을 가짐\n\nimgtsr.shape\n\ntorch.Size([1, 28, 28])\n\n\n- imgtsr를 plt.imshow 로 시각화\n\nplt.imshow(imgtsr.reshape(28,28),cmap='gray')\n\n&lt;matplotlib.image.AxesImage at 0x7fa03e223370&gt;\n\n\n\n\n\n\n진짜 숫자3이 있음\n\n\n\n# 데이터정리\n- 데이터정리\n\nthrees_fnames = (path/'training/3').ls()\nsevens_fnames = (path/'training/7').ls()\nlen(threes_fnames),len(sevens_fnames)\n\n(6131, 6265)\n\n\n\n6131, 1, 28, 28\n6265, 1, 28, 28\n\n\ntorch.stack([torchvision.io.read_image(str(threes_fnames[i])) for i in [0,1]]).shape\n\ntorch.Size([2, 1, 28, 28])\n\n\n\ntorch.stack([torchvision.io.read_image(str(fn)) for fn in threes_fnames]).shape\n\ntorch.Size([6131, 1, 28, 28])\n\n\n\ntorch.stack([torchvision.io.read_image(str(fn)) for fn in sevens_fnames]).shape\n\ntorch.Size([6265, 1, 28, 28])\n\n\n\nX3 = torch.stack([torchvision.io.read_image(str(threes_fnames[i])) for i in range(6131)])\nX7 = torch.stack([torchvision.io.read_image(str(sevens_fnames[i])) for i in range(6265)])\n\n\nX3.shape,X7.shape\n\n(torch.Size([6131, 1, 28, 28]), torch.Size([6265, 1, 28, 28]))\n\n\n\nlen(threes_fnames) + len(sevens_fnames)\n\n12396\n\n\n\nX=torch.concat([X3,X7])\nX.shape\n\ntorch.Size([12396, 1, 28, 28])\n\n\n\nXnp = X.reshape(-1,1*28*28).float() # Xnp = X.reshape(-1,784).float()\nXnp.shape\n\ntorch.Size([12396, 784])\n\n\n\\(\\star\\) float형으로 바꿔주기\n\ny = torch.tensor([0.0]*6131 + [1.0]*6265).reshape(-1,1) \ny.shape\n\ntorch.Size([12396, 1])\n\n\n\ny = torch.tensor([0.0]*len(threes_fnames) + [1.0]*len(sevens_fnames)).reshape(-1,1) \ny.shape\n\ntorch.Size([12396, 1])\n\n\n\nplt.plot(y,'o')\n\n\n\n\n\n“y=0”은 숫자3을 의미, “y=1”은 숫자7을 의미\n숫자3은 6131개, 숫자7은 6265개 있음\n\n\n\n# 학습\n- 네트워크의 설계\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1*28*28,out_features=30),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=30,out_features=1),\n    torch.nn.Sigmoid()\n)\n\n\n\\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,30)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,30)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.BCELoss()\n\n\noptimizr = torch.optim.Adam(net.parameters())\n\n\nplt.plot(y,'o')\nplt.plot(net(Xnp).data,'.',alpha=0.2)\n\n\n\n\n\nfor epoc in range(200):\n    ## 1\n    yhat = net(Xnp) \n    ## 2\n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y,'o')\nplt.plot(net(Xnp).data,'.',alpha=0.2)\n\n\n\n\n\n대부분 잘 적합되었음"
  },
  {
    "objectID": "posts/ml/2022-10-12-ml-6w.html#신경망의-표현-boldsymbol-x-to-hatboldsymbol-y-로-가는-과정을-그림으로-표현",
    "href": "posts/ml/2022-10-12-ml-6w.html#신경망의-표현-boldsymbol-x-to-hatboldsymbol-y-로-가는-과정을-그림으로-표현",
    "title": "DNN (6주차)",
    "section": "신경망의 표현 (\\({\\boldsymbol x} \\to \\hat{\\boldsymbol y}\\) 로 가는 과정을 그림으로 표현)",
    "text": "신경망의 표현 (\\({\\boldsymbol x} \\to \\hat{\\boldsymbol y}\\) 로 가는 과정을 그림으로 표현)\n\n예제1: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n- 모든 observation과 가중치를 명시한 버전\n(표현1)\n\n#collapse\ngv(''' \n    \"1\" -&gt; \"ŵ₀ + xₙ*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"xₙ\" -&gt; \"ŵ₀ + xₙ*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + xₙ*ŵ₁,    bias=False\" -&gt; \"ŷₙ\"[label=\"sigmoid\"]\n\n    \".\" -&gt; \"....................................\"[label=\"* ŵ₀\"]\n    \"..\" -&gt; \"....................................\"[label=\"* ŵ₁\"]\n    \"....................................\" -&gt; \"...\"[label=\" \"]\n\n    \"1 \" -&gt; \"ŵ₀ + x₂*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"x₂\" -&gt; \"ŵ₀ + x₂*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + x₂*ŵ₁,    bias=False\" -&gt; \"ŷ₂\"[label=\"sigmoid\"]\n    \n    \"1  \" -&gt; \"ŵ₀ + x₁*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"x₁\" -&gt; \"ŵ₀ + x₁*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + x₁*ŵ₁,    bias=False\" -&gt; \"ŷ₁\"[label=\"sigmoid\"]\n''')\n\n\n\n\n\n단점: 똑같은 그림의 반복이 너무 많음\n\n- observation 반복을 생략한 버전들\n(표현2) 모든 \\(i\\)에 대하여 아래의 그림을 반복한다고 하면 (표현1)과 같다.\n\n#collapse\ngv(''' \n    \"1\" -&gt; \"ŵ₀ + xᵢ*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"xᵢ\" -&gt; \"ŵ₀ + xᵢ*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + xᵢ*ŵ₁,    bias=False\" -&gt; \"ŷᵢ\"[label=\"sigmoid\"]\n\n''')\n\n\n\n\n(표현3) 그런데 (표현2)에서 아래와 같이 \\(x_i\\), \\(y_i\\) 대신에 간단히 \\(x\\), \\(y\\)로 쓰는 경우도 많음\n\n#collapse\ngv(''' \n    \"1\" -&gt; \"ŵ₀ + x*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"x\" -&gt; \"ŵ₀ + x*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + x*ŵ₁,    bias=False\" -&gt; \"ŷ\"[label=\"sigmoid\"]\n\n''')\n\n\n\n\n- 1을 생략한 버전들\n(표현4) bais=False 대신에 bias=True를 주면 1을 생략할 수 있음\n\n#collapse\ngv('''\n\"x\" -&gt; \"x*ŵ₁,    bias=True\"[label=\"*ŵ₁\"] ;\n\"x*ŵ₁,    bias=True\" -&gt; \"ŷ\"[label=\"sigmoid\"] ''')\n\n\n\n\n(표현4의 수정) \\(\\hat{w}_1\\)대신에 \\(\\hat{w}\\)를 쓰는 것이 더 자연스러움\n\n#collapse\ngv('''\n\"x\" -&gt; \"x*ŵ,    bias=True\"[label=\"*ŵ\"] ;\n\"x*ŵ,    bias=True\" -&gt; \"ŷ\"[label=\"sigmoid\"] ''')\n\n\n\n\n(표현5) 선형변환의 결과는 아래와 같이 \\(u\\)로 표현하기도 한다.\n\n#collapse\ngv('''\n\"x\" -&gt; \"u\";\n\"u\" -&gt; \"y\"[label=\"sigmoid\"] ''')\n\n\n\n\n\n다이어그램은 그리는 사람의 취향에 따라 그리는 방법이 조금씩 다릅니다. 즉 교재마다 달라요.\n\n\n\n예제2: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n참고: 코드로 표현\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Sigmoid()\n)\n- 이해를 위해서 10월4일 강의노트에서 다루었던 아래의 상황을 고려하자.\n\n(강의노트의 표현)\n\n#collapse\ngv('''\n\"x\" -&gt; \" -x\"[label=\"*(-1)\"];\n\"x\" -&gt; \" x\"[label=\"*1\"]\n\" x\" -&gt; \"rlu(x)\"[label=\"relu\"] \n\" -x\" -&gt; \"rlu(-x)\"[label=\"relu\"] \n\"rlu(x)\" -&gt; \"u\"[label=\"*(-4.5)\"] \n\"rlu(-x)\" -&gt; \"u\"[label=\"*(-9.0)\"] \n\"u\" -&gt; \"sig(u)=yhat\"[label=\"sig\"] \n'''\n)\n\n\n\n\n(좀 더 일반화된 표현) 10월4일 강의노트 상황을 일반화하면 아래와 같다.\n\n#collapse\ngv('''\n\"x\" -&gt; \"u1[:,0]\"[label=\"*(-1)\"];\n\"x\" -&gt; \"u1[:,1]\"[label=\"*1\"]\n\"u1[:,0]\" -&gt; \"v1[:,0]\"[label=\"relu\"] \n\"u1[:,1]\" -&gt; \"v1[:,1]\"[label=\"relu\"] \n\"v1[:,0]\" -&gt; \"u2\"[label=\"*(-9.0)\"] \n\"v1[:,1]\" -&gt; \"u2\"[label=\"*(-4.5)\"] \n\"u2\" -&gt; \"v2=yhat\"[label=\"sig\"] \n'''\n)\n\n\n\n\n* Layer의 개념: \\({\\bf X}\\)에서 \\(\\hat{\\boldsymbol y}\\)로 가는 과정은 “선형변환+비선형변환”이 반복되는 구조이다. “선형변환+비선형변환”을 하나의 세트로 보면 아래와 같이 표현할 수 있다.\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\left( \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\right) \\overset{l_2}{\\to} \\left(\\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}\\right), \\quad \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{net({\\bf X})}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n이것을 다이어그램으로 표현한다면 아래와 같다.\n(선형+비선형을 하나의 Layer로 묶은 표현)\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -&gt; \"u1[:,0]\"\n    \"X\" -&gt; \"u1[:,1]\"\n    \"u1[:,0]\" -&gt; \"v1[:,0]\"[label=\"relu\"]\n    \"u1[:,1]\" -&gt; \"v1[:,1]\"[label=\"relu\"]\n    label = \"Layer 1\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"v1[:,0]\" -&gt; \"u2\"\n    \"v1[:,1]\" -&gt; \"u2\"\n    \"u2\" -&gt; \"v2=yhat\"[label=\"sigmoid\"]\n    label = \"Layer 2\"\n}\n''')\n\n\n\n\nLayer를 세는 방법 - 정석: 학습가능한 파라메터가 몇층으로 있는지… - 일부 교재 설명: 입력층은 계산하지 않음, activation layer는 계산하지 않음. - 위의 예제의 경우 number of layer = 2 이다.\n\n사실 input layer, activation layer 등의 표현을 자주 사용해서 layer를 세는 방법이 처음에는 헷갈립니다..\n\nHidden Layer의 수를 세는 방법 - Layer의 수 = Hidden Layer의 수 + 출력층의 수 = Hidden Layer의 수 + 1 - 위의 예제의 경우 number of hidden layer = 1 이다.\n* node의 개념: \\(u\\to v\\)로 가는 쌍을 간단히 노드라는 개념을 이용하여 나타낼 수 있음.\n(노드의 개념이 포함된 그림)\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -&gt; \"node1\"\n    \"X\" -&gt; \"node2\"\n    label = \"Layer 1:relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -&gt; \"yhat \"\n    \"node2\" -&gt; \"yhat \"\n    label = \"Layer 2:sigmoid\"\n}\n''')\n\n\n\n\n여기에서 node의 숫자 = feature의 숫자와 같이 이해할 수 있다. 즉 아래와 같이 이해할 수 있다.\n(“number of nodes = number of features”로 이해한 그림)\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -&gt; \"feature1\"\n    \"X\" -&gt; \"feature2\"\n    label = \"Layer 1:relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"feature1\" -&gt; \"yhat \"\n    \"feature2\" -&gt; \"yhat \"\n    label = \"Layer 2:sigmoid\"\n}\n''')\n\n\n\n\n\n다이어그램의 표현방식은 교재마다 달라서 모든 예시를 달달 외울 필요는 없습니다. 다만 임의의 다이어그램을 보고 대응하는 네트워크를 pytorch로 구현하는 능력은 매우 중요합니다.\n\n\n\n예제3: \\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n(다이어그램표현)\n\n#collapse\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"x1\"\n    \"x2\"\n    \"..\"\n    \"x784\"\n    label = \"Input Layer\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"x1\" -&gt; \"node1\"\n    \"x2\" -&gt; \"node1\"\n    \"..\" -&gt; \"node1\"\n    \n    \"x784\" -&gt; \"node1\"\n    \"x1\" -&gt; \"node2\"\n    \"x2\" -&gt; \"node2\"\n    \"..\" -&gt; \"node2\"\n    \"x784\" -&gt; \"node2\"\n    \n    \"x1\" -&gt; \"...\"\n    \"x2\" -&gt; \"...\"\n    \"..\" -&gt; \"...\"\n    \"x784\" -&gt; \"...\"\n\n    \"x1\" -&gt; \"node32\"\n    \"x2\" -&gt; \"node32\"\n    \"..\" -&gt; \"node32\"\n    \"x784\" -&gt; \"node32\"\n\n\n    label = \"Hidden Layer: relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n\n    \"node1\" -&gt; \"yhat\"\n    \"node2\" -&gt; \"yhat\"\n    \"...\" -&gt; \"yhat\"\n    \"node32\" -&gt; \"yhat\"\n    \n    label = \"Outplut Layer: sigmoid\"\n}\n''')\n\n\n\n\n\nLayer0,1,2 대신에 Input Layer, Hidden Layer, Output Layer로 표현함\n\n- 위의 다이어그램에 대응하는 코드\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=28*28*1,out_features=32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid() \n)"
  },
  {
    "objectID": "posts/ml/2022-10-12-ml-6w.html#cpu-vs-gpu",
    "href": "posts/ml/2022-10-12-ml-6w.html#cpu-vs-gpu",
    "title": "DNN (6주차)",
    "section": "CPU vs GPU",
    "text": "CPU vs GPU\n- 파이토치에서 GPU를 쓰는 방법을 알아보자. (사실 지금까지 우리는 CPU만 쓰고 있었음)\n\nGPU 사용방법\n- cpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_cpu = torch.tensor([0.0,0.1,0.2]).reshape(-1,1) \ny_cpu = torch.tensor([0.0,0.2,0.4]).reshape(-1,1) \nnet_cpu = torch.nn.Linear(1,1) \n\n연산되게끔 reshape으로 shape 변경해주세요\n\nx_cpu, y_cpu\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]]),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]]))\n\n\n\nnet_cpu.weight, net_cpu.bias\n\n(Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n- gpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_gpu = x_cpu.to(\"cuda:0\")\ny_gpu = y_cpu.to(\"cuda:0\")\nnet_gpu = torch.nn.Linear(1,1).to(\"cuda:0\") \n\ncpu있는 자체는 못 넣고\nnet_gpu = net_cpu.to(\"cuda:0\")\ncpu에 있는 net을 가져와서 정의해줘야 한다.\n\n\n_a = torch.nn.Linear(1,1)\n\n\n_a.weight, _a.bias\n\n(Parameter containing:\n tensor([[0.4074]], requires_grad=True),\n Parameter containing:\n tensor([-0.8885], requires_grad=True))\n\n\n\n_a.to(\"cuda:0\") \n\nLinear(in_features=1, out_features=1, bias=True)\n\n\n\n_a.weight, _a.bias\n\n(Parameter containing:\n tensor([[0.4074]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.8885], device='cuda:0', requires_grad=True))\n\n\n\n\nx_gpu, y_gpu\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]], device='cuda:0'),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]], device='cuda:0'))\n\n\n\nnet_gpu.weight, net_gpu.bias\n\n(Parameter containing:\n tensor([[-0.3467]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.8470], device='cuda:0', requires_grad=True))\n\n\n- cpu 혹은 gpu 연산이 가능한 메모리에 저장된 값들을 확인\n\nx_cpu, y_cpu, net_cpu.weight, net_cpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]]),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]]),\n Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n\nx_gpu, y_gpu, net_gpu.weight, net_gpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]], device='cuda:0'),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]], device='cuda:0'),\n Parameter containing:\n tensor([[-0.3467]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.8470], device='cuda:0', requires_grad=True))\n\n\n- gpu는 gpu끼리 연산가능하고 cpu는 cpu끼리 연산가능함\n(예시1)\n\nnet_cpu(x_cpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시2)\n\nnet_gpu(x_gpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9163]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시3)\n\nnet_cpu(x_gpu) \n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)\n\n\n(예시4)\n\nnet_gpu(x_cpu)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)\n\n\n(예시5)\n\ntorch.mean((y_cpu-net_cpu(x_cpu))**2)\n\ntensor(1.2068, grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시6)\n\ntorch.mean((y_gpu-net_gpu(x_gpu))**2)\n\ntensor(1.2068, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시7)\n\ntorch.mean((y_gpu-net_cpu(x_cpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n\n\n(예시8)\n\ntorch.mean((y_cpu-net_gpu(x_gpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n\n\n둘다 cpu에 있던가 둘 다 gpu에 있던가\n\n\n시간측정 (예비학습)\n\nimport time \n\n\nt1 = time.time()\n\n\nt2 = time.time()\n\n\nt2-t1\n\n0.42019009590148926\n\n\n\n\nCPU (512)\n- 데이터준비\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n\n- for문 준비\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- for문 + 학습시간측정\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.5373966693878174\n\n\n\n\nGPU (512)\n- 데이터준비\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n\n- for문돌릴준비\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- for문 + 학습시간측정\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n1.4511945247650146\n\n\n\n!! CPU가 더 빠르다?\n\n\n\nCPU vs GPU (20480)\n- CPU (20480)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,20480),\n    torch.nn.ReLU(),\n    torch.nn.Linear(20480,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n3.806452512741089\n\n\n- GPU (20480)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,20480),\n    torch.nn.ReLU(),\n    torch.nn.Linear(20480,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n1.308497667312622\n\n\n- 왜 이런 차이가 나는가? 연산을 하는 주체는 코어인데 CPU는 수는 적지만 일을 잘하는 코어들을 가지고 있고 GPU는 일은 못하지만 다수의 코어를 가지고 있기 때문\n\n\nCPU vs GPU (204800)\n- CPU (204800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,204800),\n    torch.nn.ReLU(),\n    torch.nn.Linear(204800,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n65.33969926834106\n\n\n- GPU (204800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,204800),\n    torch.nn.ReLU(),\n    torch.nn.Linear(204800,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n2.077875852584839\n\n\n\n!nvidia-smi\n\nWed Oct 12 21:15:05 2022       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 495.46       Driver Version: 495.46       CUDA Version: 11.5     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:65:00.0 Off |                  N/A |\n|  0%   41C    P8    28W / 420W |  12812MiB / 24268MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|    0   N/A  N/A    482816      C   ...onda3/envs/csy/bin/python     4261MiB |\n|    0   N/A  N/A    580526      C   ...onda3/envs/csy/bin/python     3249MiB |\n|    0   N/A  N/A    605977      C   ...onda3/envs/csy/bin/python     2979MiB |\n|    0   N/A  N/A   1035719      C   ...onda3/envs/csy/bin/python     2321MiB |\n+-----------------------------------------------------------------------------+"
  },
  {
    "objectID": "posts/ml/2022-10-12-ml-6w.html#확률적경사하강법-배치-에폭",
    "href": "posts/ml/2022-10-12-ml-6w.html#확률적경사하강법-배치-에폭",
    "title": "DNN (6주차)",
    "section": "확률적경사하강법, 배치, 에폭",
    "text": "확률적경사하강법, 배치, 에폭\n\n좀 이상하지 않아요?\n- 우리가 쓰는 GPU: 다나와 PC견적 - GPU 메모리 끽해봐야 24GB\n- 우리가 분석하는 데이터: 빅데이터..?\n- 데이터의 크기가 커지는순간 X.to(\"cuda:0\"), y.to(\"cuda:0\") 쓰면 난리나겠는걸?\n\nx = torch.linspace(-10,10,100000).reshape(-1,1)\neps = torch.randn(100000).reshape(-1,1)\ny = x*2 + eps \n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,2*x)\n\n\n\n\n- 데이터를 100개중에 1개만 꼴로만 쓰면 어떨까?\n\nplt.plot(x[::100],y[::100],'o',alpha=0.05)\nplt.plot(x,2*x)\n\n\n\n\n\n대충 이거만 가지고 적합해도 충분히 정확할것 같은데\n\n\n\nX,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?\n- 데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나?\n- 아래의 알고리즘을 생각해보자. 1. 데이터를 반으로 나눈다. 2. 짝수obs의 x,y 그리고 net의 모든 파라메터를 GPU에 올린다. 3. yhat, loss, grad, update 수행 4. 짝수obs의 x,y를 GPU메모리에서 내린다. 그리고 홀수obs의 x,y를 GPU메모리에 올린다. 5. yhat, loss, grad, update 수행 6. 홀수obs의 x,y를 GPU메모리에서 내린다. 그리고 짝수obs의 x,y를 GPU메모리에 올린다. 7. 반복\n(서연 필기) 전체 다 올리면 경사하강법 부분적으로 올리면 확률적 경사하강법\n\n\n경사하강법, 확률적경사하강법, 미니배치 경사하강법\n10개의 샘플이 있다고 가정. \\(\\{(x_i,y_i)\\}_{i=1}^{10}\\)\n- ver1: 모든 샘플을 이용하여 slope 계산\n(epoch1) \\(loss=\\sum_{i=1}^{10}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\)\n(epoch2) \\(loss=\\sum_{i=1}^{10}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\)\n…\n- ver2: 하나의 샘플만을 이용하여 slope 계산\n(epoch1) - \\(loss=(y_1-\\beta_0-\\beta_1x_1)^2 \\to slope \\to update\\) - \\(loss=(y_2-\\beta_0-\\beta_1x_2)^2 \\to slope \\to update\\) - … - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\to slope \\to update\\)\n(epoch2) - \\(loss=(y_1-\\beta_0-\\beta_1x_1)^2 \\to slope \\to update\\) - \\(loss=(y_2-\\beta_0-\\beta_1x_2)^2 \\to slope \\to update\\) - … - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\to slope \\to update\\)\n…\n(서연 필기) 불안해 - for 문도 많이 돌아야 해.\n- ver3: \\(m (\\leq n)\\) 개의 샘플을 이용하여 slope 계산\n\\(m=3\\)이라고 하자.\n(epoch1) - \\(loss=\\sum_{i=1}^{3}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=\\sum_{i=4}^{6}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=\\sum_{i=7}^{9}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\to slope \\to update\\)\n(epoch2) - \\(loss=\\sum_{i=1}^{3}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=\\sum_{i=4}^{6}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=\\sum_{i=7}^{9}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\to slope \\to update\\)\n…\n(서연 필기) 미니배치하고 남은 것도 계산된다.\n\n\n용어의 정리\n옛날\n- ver1: gradient descent, batch gradient descent\n- ver2: stochastic gradient descent\n- ver3: mini-batch gradient descent, mini-batch stochastic gradient descent\n요즘\n- ver1: gradient descent\n- ver2: stochastic gradient descent with batch size = 1\n- ver3: stochastic gradient descent - https://www.deeplearningbook.org/contents/optimization.html, 알고리즘 8-1 참고.\n\n\nds, dl\n- ds\n\nx=torch.tensor(range(10)).float()#.reshape(-1,1)\ny=torch.tensor([1.0]*5+[0.0]*5)#.reshape(-1,1)\n\n\nds=torch.utils.data.TensorDataset(x,y)\nds\n\n&lt;torch.utils.data.dataset.TensorDataset at 0x7fa03d24f940&gt;\n\n\n\nds.tensors # 그냥 (x,y)의 튜플\n\n(tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.]))\n\n\n- dl\n\ndl=torch.utils.data.DataLoader(ds,batch_size=3)\n#set(dir(dl)) & {'__iter__'}\n\n\nset(dir(dl)) & {'__iter__'}\n\n{'__iter__'}\n\n\ndir에 __iter__있으면 for문 쓰기 가능\n\nfor xx,yy in dl:\n    print(xx,yy)\n\ntensor([0., 1., 2.]) tensor([1., 1., 1.])\ntensor([3., 4., 5.]) tensor([1., 1., 0.])\ntensor([6., 7., 8.]) tensor([0., 0., 0.])\ntensor([9.]) tensor([0.])\n\n\n\n\nds, dl을 이용한 MNIST 구현\n- 데이터정리\n\npath = untar_data(URLs.MNIST)\n\n\nzero_fnames = (path/'training/0').ls()\none_fnames = (path/'training/1').ls()\n\n\nX0 = torch.stack([torchvision.io.read_image(str(zf)) for zf in zero_fnames])\nX1 = torch.stack([torchvision.io.read_image(str(of)) for of in one_fnames])\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\nX.shape,y.shape\n\n(torch.Size([12665, 784]), torch.Size([12665, 1]))\n\n\n- ds \\(\\to\\) dl\n\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048) \n\n\n12665/2048\n\n6.18408203125\n\n\n\ni = 0 \nfor xx,yy in dl: # 총 7번 돌아가는 for문 \n    print(i)\n    i=i+1\n\n0\n1\n2\n3\n4\n5\n6\n\n\n- 미니배치 안쓰는 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(70): \n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss= loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\ntorch.sum((yhat&gt;0.5) == y) / len(y) \n\ntensor(0.9981)\n\n\n\ntorch.mean(((yhat&gt;0.5) == y)*1.0)\n\ntensor(0.9981)\n\n\n\nlen(y) / 2048\n\n6.18408203125\n\n\n- 미니배치 쓰는 학습 (GPU 올리고 내리는 과정은 생략)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(10):\n    for xx,yy in dl: ## 7번\n        ## 1\n        #yhat = net(xx)\n        ## 2 \n        loss = loss_fn(net(xx),yy) \n        ## 3 \n        loss.backward() \n        ## 4 \n        optimizr.step()\n        optimizr.zero_grad()\n\n(서연 필기)xx넣어서 학습 시키고 전체 X넣어서 확인\n\nlen(X)\n\n12665\n\n\n\ntorch.mean(((net(X)&gt;0.5) == y)*1.0)\n\ntensor(0.9949)"
  },
  {
    "objectID": "posts/ml/2022-10-12-ml-6w.html#오버피팅",
    "href": "posts/ml/2022-10-12-ml-6w.html#오버피팅",
    "title": "DNN (6주차)",
    "section": "오버피팅",
    "text": "오버피팅\n- 오버피팅이란? - 위키: In mathematical modeling, overfitting is “the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit to additional data or predict future observations reliably”. - 제 개념: 데이터를 “데이터 = 언더라잉 + 오차”라고 생각할때 우리가 데이터로부터 적합할 것은 언더라잉인데 오차항을 적합하고 있는 현상.\n\n오버피팅 예시\n- \\(m\\)이 매우 클때 아래의 네트워크 거의 무엇이든 맞출수 있다고 보면 된다.\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n- 그런데 종종 맞추지 말아야 할 것들도 맞춘다.\nmodel: \\(y_i = (0\\times x_i) + \\epsilon_i\\), where \\(\\epsilon_i \\sim N(0,0.01^2)\\)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(100,1)\ny=torch.randn(100).reshape(100,1)*0.01\nplt.plot(x,y)\n\n\n\n\n\ny는 그냥 정규분포에서 생성한 오차이므로 \\(X \\to y\\) 로 항햐는 규칙따위는 없음\n\n\ntorch.manual_seed(1) \nnet=torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512), \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)) \noptimizer= torch.optim.Adam(net.parameters())\nloss_fn= torch.nn.MSELoss()\n\nfor epoc in range(1000): \n    ## 1 \n    yhat=net(x) \n    ## 2 \n    loss=loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizer.step()\n    net.zero_grad() \n\n\nplt.plot(x,y)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n우리는 데이터를 랜덤에서 뽑았는데, 데이터의 추세를 따라간다 \\(\\to\\) 오버피팅 (underlying이 아니라 오차항을 따라가고 있음)\n\n\n\n오버피팅이라는 뚜렷한 증거! (train / test)\n- 데이터의 분리하여 보자.\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(100,1)\ny=torch.randn(100).reshape(100,1)*0.01\nxtr = x[:80] \nytr = y[:80]\nxtest = x[80:]\nytest = y[80:]\nplt.plot(xtr,ytr)\nplt.plot(xtest,ytest)\nplt.title('train: blue / test: orange');\n\n\n\n\n- train만 학습\n\ntorch.manual_seed(1) \nnet1=torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512), \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)) \noptimizr1= torch.optim.Adam(net1.parameters())\nloss_fn= torch.nn.MSELoss()\n\nfor epoc in range(1000): \n    ## 1 \n    # net(xtr) \n    ## 2 \n    loss=loss_fn(net1(xtr),ytr) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr1.step()\n    optimizr1.zero_grad() \n\n- training data로 학습한 net를 training data 에 적용\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(xtr,net1(xtr).data,'--') # prediction (train) \n\n\n\n\n\ntrain에서는 잘 맞추는듯이 보인다.\n\n- training data로 학습한 net를 test data 에 적용\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(xtr,net1(xtr).data,'--') # prediction (train) \nplt.plot(xtest,net1(xtest).data,'--') # prediction with unseen data (test) \n\n\n\n\n\ntrain은 그럭저럭 따라가지만 test에서는 엉망이다. \\(\\to\\) overfit"
  },
  {
    "objectID": "posts/ml/2022-10-12-ml-6w.html#숙제-해설-및-풀이는-여기참고",
    "href": "posts/ml/2022-10-12-ml-6w.html#숙제-해설-및-풀이는-여기참고",
    "title": "DNN (6주차)",
    "section": "숙제 (해설 및 풀이는 여기참고)",
    "text": "숙제 (해설 및 풀이는 여기참고)\n\n숫자0과 숫자1을 구분하는 네트워크를 아래와 같은 구조로 설계하라\n\n\\[\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,64)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,64)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n위에서 \\(a_1\\)은 relu를, \\(a_2\\)는 sigmoid를 의미한다.\n\n“y=0”은 숫자0을 의미하도록 하고 “y=1”은 숫자1을 의미하도록 설정하라.\n\n\npath = untar_data(URLs.MNIST)\n\n\nzero_fnames = (path/'training/0').ls()\n\n\none_fnames = (path/'training/1').ls()\n\n\nX0 = torch.stack([torchvision.io.read_image(str(zf)) for zf in zero_fnames])\n\n\nX1 = torch.stack([torchvision.io.read_image(str(of)) for of in one_fnames])\n\n\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28).float()\n\n\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\ntorch.manual_seed(12345)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,1),\n    torch.nn.Sigmoid()\n)\n\n\n아래의 지침에 따라 200 epoch 학습을 진행하라.\n\n\n손실함수는 BECLoss를 이용할 것. torch.nn.BCELoss() 를 이용할 것.\n옵티마이저는 아담으로 설정할 것. 학습률은 lr=0.002로 설정할 것.\n\n\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.002)\n\n\nfor epoc in range(200):\n    yhat = net(X)\n    loss = loss_fn(yhat,y)\n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y)\nplt.plot(yhat.data,'.',alpha=0.4)\n\n\n\n\n\n아래의 지침에 따라 200 epoch 학습을 진행하라. 학습이 잘 되는가?\n\n\n손실함수는 BECLoss를 이용할 것. torch.nn.BCELoss()를 사용하지 않고 수식을 직접 입력할 것.\n옵티마이저는 아담으로 설정할 것. 학습률은 lr=0.002로 설정할 것.\n\n\ntorch.manual_seed(12345)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,1),\n    torch.nn.Sigmoid()\n)\n\n\noptimizr = torch.optim.Adam(net.parameters(),lr=0.002)\n\n\nfor epoc in range(200):\n    yhat = net(X)\n    loss = -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat))\n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y)\nplt.plot(yhat.data,'.',alpha=0.4)\n\n\n\n\n\nyhat.data\n\ntensor([[nan],\n        [nan],\n        [nan],\n        ...,\n        [nan],\n        [nan],\n        [nan]])\n\n\n학습이 잘 되지 않았다.\n\n아래의 지침에 따라 200 epoch 학습을 진행하라. 학습이 잘 되는가?\n\n\n이미지의 값을 0과 1사이로 규격화 하라. (Xnp = Xnp/255 를 이용하세요!)\n손실함수는 BECLoss를 이용할 것. torch.nn.BCELoss()를 사용하지 않고 수식을 직접 입력할 것.\n옵티마이저는 아담으로 설정할 것. 학습률은 lr=0.002로 설정할 것.\n\n\nX = X/255\n\n\ntorch.manual_seed(12345)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,1),\n    torch.nn.Sigmoid()\n)\n\n\noptimizr=torch.optim.Adam(net.parameters(),lr=0.002)\n\n\nfor epoc in range(200):\n    yhat = net(X)\n    loss = -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat))\n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y)\nplt.plot(yhat.data,'.',alpha=0.4)\n\n\n\n\n\n아래와 같은 수식을 이용하여 accuracy를 계산하라.\n\n\\(\\text{accuracy}=\\frac{1}{n}\\sum_{i=1}^n I(\\tilde{y}_i=y_i)\\) - \\(\\tilde{y}_i = \\begin{cases}  1 & \\hat{y}_i &gt; 0.5 \\\\  0 & \\hat{y}_i \\leq 0.5 \\end{cases}\\) - \\(I(\\tilde{y}_i=y_i) = \\begin{cases} 1 & \\tilde{y}_i=y_i \\\\ 0 & \\tilde{y}_i \\neq y_i \\end{cases}\\)\n단, \\(n\\)은 0과 1을 의미하는 이미지의 수\n\nytilde = (yhat &gt; 0.5) * 1\n\n\nytilde\n\ntensor([[0],\n        [0],\n        [0],\n        ...,\n        [1],\n        [1],\n        [1]])\n\n\n\n(ytilde == y) * 1\n\ntensor([[1],\n        [1],\n        [1],\n        ...,\n        [1],\n        [1],\n        [1]])\n\n\n\ntorch.sum((ytilde == y) * 1)\n\ntensor(12661)\n\n\n\ntorch.sum((ytilde == y) * 1)/len(y)\n\ntensor(0.9997)\n\n\n\nprint(\"accuraccy: \",torch.sum((ytilde == y) * 1)/len(y))\n\naccuraccy:  tensor(0.9997)\n\n\n\nprint(\"accuracy: \",((yhat&gt;0.5) == y).sum() / len(y))\n\naccuracy:  tensor(0.9997)"
  },
  {
    "objectID": "posts/ml/2022-09-19-Assignment-1-Copy1.html",
    "href": "posts/ml/2022-09-19-Assignment-1-Copy1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "교수님 풀이, 안 건들임\nfrom fastai.vision.all import *\nfrom fastai.collab import * \nfrom fastai.text.all import *"
  },
  {
    "objectID": "posts/ml/2022-09-19-Assignment-1-Copy1.html#이미지자료분석",
    "href": "posts/ml/2022-09-19-Assignment-1-Copy1.html#이미지자료분석",
    "title": "Assignment 1",
    "section": "1. 이미지자료분석",
    "text": "1. 이미지자료분석\n아래를 이용하여 MNIST_SAMPLE 이미지 자료를 다운로드 받고 dls오브젝트를 만들어라.\n\npath = untar_data(URLs.MNIST_SAMPLE)\n\n\ndls = ImageDataLoaders.from_folder(path,suffle=False) \n\n\ndls.show_batch()\n\n\n\n\n(1) cnn_learner를 이용하여 lrnr 오브젝트를 생성하라. - arch 는 resnet34 로 설정할 것 - metrics 는 error_rate 로 설정할 것\n(풀이)\n\nlrnr = cnn_learner(dls, arch = resnet34, metrics=error_rate)\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/fastai/vision/learner.py:284: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n(2) fine_tune 을 이용하여 lrnr 오브젝트를 학습하라.\n(풀이)\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.282870\n0.150136\n0.049068\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.042991\n0.017522\n0.006379\n00:05\n\n\n\n\n\n(3) 아래를 이용하여 X,y를 만들어라.\nX,y = dls.one_batch()\nX,y의 shape을 조사하라. X에는 몇개의 이미지가 있는가? 이미지의 size는 얼마인가?\n(풀이)\n\nX,y = dls.one_batch()\nX.shape\n\ntorch.Size([64, 3, 28, 28])\n\n\nX에는 64개의 이미지가 있고 크기는 (28,28) 이다.\n(4) 아래의 코드를 이용하여 X의 두번째 이미지가 어떠한 숫자를 의미하는지 확인하라. (그림보고 3인지 7인지 확인하여 답을 쓸 것)\nshow_image(X[0])\n그리고 show_image가 정의된 파일의 경로를 확인하고 show_image가 python 내장함수 인지, torch에서 지원하는 함수인지 fastai에서 지원하는 함수인지 파악하라.\n(풀이)\n\nshow_image(X[1]) # 두번째 이미지 \n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n&lt;AxesSubplot:&gt;\n\n\n\n\n\n\nshow_image?\n\n\nSignature:\nshow_image(\n    im,\n    ax=None,\n    figsize=None,\n    title=None,\n    ctx=None,\n    cmap=None,\n    norm=None,\n    *,\n    aspect=None,\n    interpolation=None,\n    alpha=None,\n    vmin=None,\n    vmax=None,\n    origin=None,\n    extent=None,\n    interpolation_stage=None,\n    filternorm=True,\n    filterrad=4.0,\n    resample=None,\n    url=None,\n    data=None,\n    **kwargs,\n)\nDocstring: Show a PIL or PyTorch image on `ax`.\nFile:      ~/anaconda3/envs/py37/lib/python3.7/site-packages/fastai/torch_core.py\nType:      function\n\n\n\n\n\nfastai에서 지원하는 함수\n\n(5) lrnr 오브젝트를 이용하여 AI가 X[0]을 어떤 값으로 판단하는지 확인하라. 올바르게 판단하였는가? 올바르게 판단했다면 몇 프로의 확신으로 판단하였는가? &lt;– 문제가 의도한 것과 다르게 만들어졌어요\n(풀이)\n\nshow_image(X[0]) # 첫번째 이미지\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n&lt;AxesSubplot:&gt;\n\n\n\n\n\n\nlrnr.model(X[0].reshape(1,3,28,28))\n\nTensorBase([[ 3.4148, -5.0356]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\nimport numpy as np\na=np.exp(3.4148)\nb=np.exp(-5.0356)\nprint('3일확률',a/(a+b))\nprint('7일확률',b/(a+b))\n\n3일확률 0.9997862308347155\n7일확률 0.0002137691652844868\n\n\n\n원래문제의도: lrnr.predict(X[0].to(\"cpu\"))"
  },
  {
    "objectID": "posts/ml/2022-09-19-Assignment-1-Copy1.html#추천시스템",
    "href": "posts/ml/2022-09-19-Assignment-1-Copy1.html#추천시스템",
    "title": "Assignment 1",
    "section": "2. 추천시스템",
    "text": "2. 추천시스템\n아래를 이용하여 rcmd_anal.csv 를 다운로드 받고 dls오브젝트를 만들어라.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv')\ndf\n\n\n\n\n\n\n\n\nuser\nitem\nrating\nitem_name\n\n\n\n\n0\n1\n15\n1.084308\n홍차5\n\n\n1\n1\n1\n4.149209\n커피1\n\n\n2\n1\n11\n1.142659\n홍차1\n\n\n3\n1\n5\n4.033415\n커피5\n\n\n4\n1\n4\n4.078139\n커피4\n\n\n...\n...\n...\n...\n...\n\n\n995\n100\n18\n4.104276\n홍차8\n\n\n996\n100\n17\n4.164773\n홍차7\n\n\n997\n100\n14\n4.026915\n홍차4\n\n\n998\n100\n4\n0.838720\n커피4\n\n\n999\n100\n7\n1.094826\n커피7\n\n\n\n\n1000 rows × 4 columns\n\n\n\n(1) 73번 유저가 먹은 아이템 및 평점을 출력하는 코드를 작성하라. 이를 기반으로 73번 유저가 어떠한 취향인지 파악하라.\n(풀이)\n\ndf.query('user == 73')\n\n\n\n\n\n\n\n\nuser\nitem\nrating\nitem_name\n\n\n\n\n720\n73\n20\n3.733853\n홍차10\n\n\n721\n73\n18\n3.975004\n홍차8\n\n\n722\n73\n9\n1.119541\n커피9\n\n\n723\n73\n13\n3.840801\n홍차3\n\n\n724\n73\n2\n0.943742\n커피2\n\n\n725\n73\n4\n1.152405\n커피4\n\n\n726\n73\n1\n0.887292\n커피1\n\n\n727\n73\n7\n0.947641\n커피7\n\n\n728\n73\n6\n0.868370\n커피6\n\n\n729\n73\n17\n3.873590\n홍차7\n\n\n\n\n\n\n\n\n홍차를 선호\n\n(2) dls와 lrnr 오브젝트를 생성하고 lrnr 오브젝트를 학습하라.\n(풀이)\n\ndls = CollabDataLoaders.from_df(df)\nlrnr = collab_learner(dls,y_range=(0,5))\n\n\nlrnr.fit(50)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n2.337114\n2.258755\n00:00\n\n\n1\n2.328897\n2.254714\n00:00\n\n\n2\n2.320246\n2.237874\n00:00\n\n\n3\n2.300545\n2.191783\n00:00\n\n\n4\n2.265857\n2.104007\n00:00\n\n\n5\n2.207397\n1.966761\n00:00\n\n\n6\n2.123599\n1.783263\n00:00\n\n\n7\n2.008980\n1.562448\n00:00\n\n\n8\n1.865242\n1.317642\n00:00\n\n\n9\n1.697832\n1.068948\n00:00\n\n\n10\n1.515044\n0.833239\n00:00\n\n\n11\n1.326496\n0.625003\n00:00\n\n\n12\n1.139156\n0.453686\n00:00\n\n\n13\n0.962462\n0.320953\n00:00\n\n\n14\n0.802481\n0.223124\n00:00\n\n\n15\n0.662327\n0.155420\n00:00\n\n\n16\n0.542384\n0.110662\n00:00\n\n\n17\n0.442099\n0.082435\n00:00\n\n\n18\n0.359706\n0.064858\n00:00\n\n\n19\n0.292656\n0.054441\n00:00\n\n\n20\n0.238817\n0.048325\n00:00\n\n\n21\n0.195901\n0.045092\n00:00\n\n\n22\n0.161955\n0.043386\n00:00\n\n\n23\n0.135049\n0.042616\n00:00\n\n\n24\n0.113653\n0.042549\n00:00\n\n\n25\n0.096877\n0.042678\n00:00\n\n\n26\n0.083618\n0.043010\n00:00\n\n\n27\n0.073081\n0.043308\n00:00\n\n\n28\n0.064768\n0.043905\n00:00\n\n\n29\n0.058133\n0.044605\n00:00\n\n\n30\n0.053050\n0.044990\n00:00\n\n\n31\n0.048904\n0.045569\n00:00\n\n\n32\n0.045665\n0.045833\n00:00\n\n\n33\n0.043033\n0.045906\n00:00\n\n\n34\n0.040883\n0.046624\n00:00\n\n\n35\n0.039263\n0.046878\n00:00\n\n\n36\n0.037608\n0.047040\n00:00\n\n\n37\n0.036450\n0.047146\n00:00\n\n\n38\n0.035638\n0.047335\n00:00\n\n\n39\n0.034883\n0.047623\n00:00\n\n\n40\n0.034177\n0.048048\n00:00\n\n\n41\n0.033486\n0.047836\n00:00\n\n\n42\n0.033047\n0.048263\n00:00\n\n\n43\n0.032634\n0.048296\n00:00\n\n\n44\n0.032165\n0.048577\n00:00\n\n\n45\n0.031884\n0.048578\n00:00\n\n\n46\n0.031517\n0.048725\n00:00\n\n\n47\n0.031158\n0.048977\n00:00\n\n\n48\n0.030711\n0.048955\n00:00\n\n\n49\n0.030465\n0.049127\n00:00\n\n\n\n\n\n(3) 아래와 같은 데이터 프레임을 생성하고 df_new 에 저장하라.\n\n#collapse\nimport IPython \n_html='&lt;table border=\"1\" class=\"dataframe\"&gt;\\n  &lt;thead&gt;\\n    &lt;tr style=\"text-align: right;\"&gt;\\n      &lt;th&gt;&lt;/th&gt;\\n      &lt;th&gt;user&lt;/th&gt;\\n      &lt;th&gt;item&lt;/th&gt;\\n    &lt;/tr&gt;\\n  &lt;/thead&gt;\\n  &lt;tbody&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;0&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;1&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;1&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;2&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;2&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;3&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;3&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;4&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;4&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;5&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;5&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;6&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;6&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;7&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;7&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;8&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;8&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;9&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;9&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;10&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;10&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;11&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;11&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;12&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;12&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;13&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;13&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;14&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;14&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;15&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;15&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;16&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;16&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;17&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;17&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;18&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;18&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;19&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;19&lt;/th&gt;\\n      &lt;td&gt;73&lt;/td&gt;\\n      &lt;td&gt;20&lt;/td&gt;\\n    &lt;/tr&gt;\\n  &lt;/tbody&gt;\\n&lt;/table&gt;'\nIPython.display.HTML(_html)\n\n\n\n\n\nuser\nitem\n\n\n\n\n0\n73\n1\n\n\n1\n73\n2\n\n\n2\n73\n3\n\n\n3\n73\n4\n\n\n4\n73\n5\n\n\n5\n73\n6\n\n\n6\n73\n7\n\n\n7\n73\n8\n\n\n8\n73\n9\n\n\n9\n73\n10\n\n\n10\n73\n11\n\n\n11\n73\n12\n\n\n12\n73\n13\n\n\n13\n73\n14\n\n\n14\n73\n15\n\n\n15\n73\n16\n\n\n16\n73\n17\n\n\n17\n73\n18\n\n\n18\n73\n19\n\n\n19\n73\n20\n\n\n\n\n\n(풀이)\n\ndf_new=pd.DataFrame({'user':[73]*20,'item':range(1,21)})\ndf_new\n\n\n\n\n\n\n\n\nuser\nitem\n\n\n\n\n0\n73\n1\n\n\n1\n73\n2\n\n\n2\n73\n3\n\n\n3\n73\n4\n\n\n4\n73\n5\n\n\n5\n73\n6\n\n\n6\n73\n7\n\n\n7\n73\n8\n\n\n8\n73\n9\n\n\n9\n73\n10\n\n\n10\n73\n11\n\n\n11\n73\n12\n\n\n12\n73\n13\n\n\n13\n73\n14\n\n\n14\n73\n15\n\n\n15\n73\n16\n\n\n16\n73\n17\n\n\n17\n73\n18\n\n\n18\n73\n19\n\n\n19\n73\n20\n\n\n\n\n\n\n\n(4) 아래의 코드를 이용하여 73번 유저의 취향을 파악하라. 73번 유저가 커피3, 커피5를 먹는다면 얼마정도의 평점을 줄 것이라 예측되는가?\n_dl = dls.test_dl(df_new)\nlrnr.get_preds(dl=_dl)\n(풀이)\n\n_dl = dls.test_dl(df_new)\nlrnr.get_preds(dl=_dl)\n\n\n\n\n\n\n\n\n(tensor([0.9698, 1.0314, 1.0191, 1.0177, 1.0122, 0.9323, 1.0513, 1.0184, 1.0316,\n         0.9842, 3.8255, 3.9591, 3.8640, 3.8937, 3.9437, 3.8947, 3.8272, 3.9503,\n         3.8117, 3.8603]),\n None)\n\n\n\n커피3: 1.0191, 커피5: 1.0122"
  },
  {
    "objectID": "posts/ml/2022-09-19-Assignment-1-Copy1.html#시퀀스자료분석",
    "href": "posts/ml/2022-09-19-Assignment-1-Copy1.html#시퀀스자료분석",
    "title": "Assignment 1",
    "section": "3. 시퀀스자료분석",
    "text": "3. 시퀀스자료분석\n아래를 이용하여 자료를 다운로드 받아라.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-19-human_numbers_100.csv')\ndf\n\n\n\n\n\n\n\n\nUnnamed: 0\ntext\n\n\n\n\n0\n0\none, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n\n\n1\n1\none, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n\n\n2\n2\none, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n\n\n3\n3\none, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n\n\n4\n4\none, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n\n\n...\n...\n...\n\n\n1995\n1995\none, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n\n\n1996\n1996\none, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n\n\n1997\n1997\none, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n\n\n1998\n1998\none, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n\n\n1999\n1999\none, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n\n\n\n\n2000 rows × 2 columns\n\n\n\n(1) TextDataLoaders.from_df을 이용하여 dls오브젝트를 만들어라. - is_lm = True 로 설정할 것 - seq_len = 5 로 설정할 것\n(풀이)\n\ndls = TextDataLoaders.from_df(df,is_lm=True,seq_len=5,text_col='text')\ndls.show_batch()\n\n\n\n\n\n\n\n\n\n\n\n\ntext\ntext_\n\n\n\n\n0\nxxbos one , two ,\none , two , three\n\n\n1\nhundred xxbos one , two\nxxbos one , two ,\n\n\n2\none hundred xxbos one ,\nhundred xxbos one , two\n\n\n3\n, one hundred xxbos one\none hundred xxbos one ,\n\n\n4\nnine , one hundred xxbos\n, one hundred xxbos one\n\n\n5\nninety nine , one hundred\nnine , one hundred xxbos\n\n\n6\n, ninety nine , one\nninety nine , one hundred\n\n\n7\neight , ninety nine ,\n, ninety nine , one\n\n\n8\nninety eight , ninety nine\neight , ninety nine ,\n\n\n\n\n\n(2) lrnr 오브젝트를 만들어라. - arch = AWD_LSTM 이용 - metrics = accuracy 이용\n(풀이)\n\nlrnr = language_model_learner(dls, arch= AWD_LSTM, metrics=accuracy)\n\n(3) lrnr오브젝트에서 fine_tune(3) 메소드를 이용하여 모형을 학습하라.\n(풀이)\n\nlrnr.fine_tune(3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.534681\n0.168856\n0.977650\n00:49\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.018749\n0.003256\n0.999205\n00:54\n\n\n1\n0.001580\n0.002430\n0.999324\n00:54\n\n\n2\n0.000651\n0.002244\n0.999315\n00:54\n\n\n\n\n\n(4) ‘one , two ,’ 이후에 이어질 50개의 단어를 생성하라.\n(풀이)\n\nlrnr.predict('one, two,', n_words=50) \n\n\n\n\n\n\n\n\n'one , two , three , four , five , six , seven , eight , nine , ten , eleven , twelve , thirteen , fourteen , fifteen , sixteen , seventeen , eighteen , nineteen , twenty , twenty one , twenty two , twenty three , twenty four , twenty five'\n\n\n(5) ‘twenty , twenty one ,’ 이후에 이어질 50개의 단어를 생성하라.\n(풀이)\n\nlrnr.predict('twenty, twenty one,', n_words=50) \n\n\n\n\n\n\n\n\n'twenty , twenty one , twenty two , twenty three , twenty four , twenty five , twenty six , twenty seven , twenty eight , twenty nine , thirty , thirty one , thirty two , thirty three , thirty four , thirty five , thirty six , thirty seven , thirty eight ,'"
  },
  {
    "objectID": "posts/ml/2022-09-19-Assignment-1-Copy1.html#리눅스명령어",
    "href": "posts/ml/2022-09-19-Assignment-1-Copy1.html#리눅스명령어",
    "title": "Assignment 1",
    "section": "4. 리눅스명령어",
    "text": "4. 리눅스명령어\nCollab 에서 (혹은 리눅스기반 서버에서) 아래의 명령어를 순서대로 실행해보라.\n!ls\n!ls -a \n!ls .\n!ls .. \n!ls sample\n!mkdir asdf \n!wget https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv\n!cp 2022-09-08-rcmd_anal.csv ./asdf \n!ls ./asdf \n!rm 2022-09-08-rcmd_anal.csv \n!rm -rf asdf \n각 명령들이 무엇을 의미하는지 간단히 서술하라.\n(풀이)\n!ls - 현재디렉토리 파일+폴더 출력 - !ls . 와 같음 - !ls ./ 와 같음\n!ls -a - 현재디렉토리 파일+폴더 출력, 숨겨진 항목까지 출력\n!ls . - 현재디렉토리 파일+폴더 출력 - !ls 와 같음 - !ls ./ 와 같음\n!ls .. - 현재디렉토리보다 상위디렉토리의 파일+폴더 출력\n!ls sample - 현재디렉토리에 sample 디렉토리 출력 - !ls ./sample 과 같음\n!mkdir asdf - 현재디렉토리에 asdf 폴더 생성 - !mkdir ./asdf 와 같음\n!wget https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv - url에 있는 파일 다운로드하여 현재디렉토리에 저장\n!cp 2022-09-08-rcmd_anal.csv ./asdf - 2022-09-08-rcmd_anal.csv 파일을 ./asdf 로 복사\n!ls ./asdf - 현재디렉토리에서 asdf 디렉토리의 내용출력 - !ls asdf 와 같음\n!rm 2022-09-08-rcmd_anal.csv - 현재 디렉토리에서 2022-09-08-rcmd_anal.csv 파일삭제; - rm ./2022-09-08-rcmd_anal.csv 와 같음\n!rm -rf asdf - 현재 디렉토리에서 asdf 삭제 (asdf 폴더내에 파일이 존재하면 파일도 같이 삭제) - r은 recursively, f는 force의 약자"
  },
  {
    "objectID": "posts/ml/2022-09-19-Assignment-1-Copy1.html#appendix-ipynb---html-변환",
    "href": "posts/ml/2022-09-19-Assignment-1-Copy1.html#appendix-ipynb---html-변환",
    "title": "Assignment 1",
    "section": "Appendix: ipynb -> html 변환",
    "text": "Appendix: ipynb -&gt; html 변환\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-x3HQLeyrS7GLh70Dv_54Yg"
  },
  {
    "objectID": "posts/rl/2022-12-08-rl-HW4.html",
    "href": "posts/rl/2022-12-08-rl-HW4.html",
    "title": "Regression HW 4",
    "section": "",
    "text": "고급회귀분석 과제, CH13\n네 번째 과제입니다.\n제출 기한 12월 8일\n행렬 계산은 R로 해도 됩니다.\n그리고, 계산 후에 R 함수(예:lm)를 이용하여 결과 확인하고, 본인의 풀이가 맞는지 결과 확인해보세요.\n제출 방법\n(pdf 아닌 문서는 미제출로 간주)\n주의사항\nlibrary(ggplot2)"
  },
  {
    "objectID": "posts/rl/2022-12-08-rl-HW4.html#section",
    "href": "posts/rl/2022-12-08-rl-HW4.html#section",
    "title": "Regression HW 4",
    "section": "1.",
    "text": "1.\n\n\n\n일련번호\n\\(y\\)(총 소요시간)\n\\(x_1\\)(적성검사점수)\n\\(x_2\\)(성별)\n학력\n\n\n\n\n1\n17\n151\n남자\n대\n\n\n2\n26\n92\n남자\n고\n\n\n3\n21\n175\n남자\n대\n\n\n4\n30\n31\n남자\n고\n\n\n5\n22\n104\n남자\n고\n\n\n6\n1\n277\n남자\n대학원\n\n\n7\n12\n210\n남자\n대학원\n\n\n8\n19\n120\n남자\n대\n\n\n9\n4\n290\n남자\n대학원\n\n\n10\n16\n238\n남자\n대학원\n\n\n11\n28\n164\n여자\n대학원\n\n\n12\n15\n272\n여자\n대학원\n\n\n13\n11\n295\n여자\n대학원\n\n\n14\n38\n68\n여자\n고\n\n\n15\n31\n85\n여자\n대\n\n\n16\n21\n224\n여자\n대학원\n\n\n17\n20\n166\n여자\n대\n\n\n18\n13\n305\n여자\n대학원\n\n\n19\n30\n124\n여자\n대\n\n\n20\n14\n246\n여자\n대학원\n\n\n\n\ndf &lt;- data.frame('y'=c(17,26,21,30,22,1,12,19,4,16,28,15,11,38,31,21,20,13,30,14),\n           'x1'=c(151,92,175,31,104,277,210,120,290,238,164,272,295,68,85,224,166,305,124,246),\n          'x2'=c('남자','남자','남자','남자','남자','남자','남자','남자','남자','남자','여자','여자','여자','여자','여자','여자','여자','여자','여자','여자'),\n          'edu'=c('대','고','대','고','고','대학원','대학원','대','대학원','대학원','대학원','대학원','대학원','고','대','대학원','대','대학원','대','대학원'))\n\n\n(1)\n\\(x_1\\)을 \\(x\\)로 놓고 각 성별에 대하여 회귀모형을 적합하시오. 그런 후 두 회귀직선의 기울기가 같은지에 대한 가설검정을 하시오(5장 p12 : 두 회귀모형의 검정 참고).\nanswer\n\nggplot(df, aes(x1, y, col=x2)) + \n  geom_point() + \n  theme_bw() +\n  guides(col=guide_legend(title=\"성별\")) +\n  scale_color_manual(labels = c(\"남자\", \"여자\"), \n                     values = c(\"darkorange\", \"steelblue\"))\n\n\n\n\n남성, Model 1: \\(y_i = \\beta_{01} + \\beta_{11} x_{i1} + \\epsilon_i , \\epsilon_i \\sim i.i.d. N(0, \\sigma^2)\\)\n여성, Model 2: \\(y_i = \\beta_{02} + \\beta_{12} x_{i2} + \\epsilon_i , \\epsilon_i \\sim i.i.d. N(0, \\sigma^2)\\)\n남자\n\nplot(df$x1[df$x2==\"남자\"], df$y[df$x2==\"남자\"])\n\n\n\n\n\\(S_{yy}\\)\n\nsum((df$y[df$x2==\"남자\"] - (17+26+21+30+22+1+12+19+4+16)/10)**2)\n\n745.6\n\n\n\\(S_{xx}\\)\n\nsum((df$x1[df$x2==\"남자\"] - (151+92+175+31+104+277+210+120+290+238)/10)**2)\n\n64705.6\n\n\n\\(S_{xy}\\)\n\nsum((df$y[df$x2==\"남자\"] - (17+26+21+30+22+1+12+19+4+16)/10) * \n    (df$x1[df$x2==\"남자\"] - (151+92+175+31+104+277+210+120+290+238)/10))\n\n-6461.4\n\n\n\\(\\hat{\\beta}_1 = \\frac{S_{xy}}{S_{xx}}\\)\n\nbeta_men &lt;- round(sum((df$y[df$x2==\"남자\"] - (17+26+21+30+22+1+12+19+4+16)/10) *\n    (df$x1[df$x2==\"남자\"] - (151+92+175+31+104+277+210+120+290+238)/10)) / \n    sum((df$x1[df$x2==\"남자\"] - (151+92+175+31+104+277+210+120+290+238)/10)**2),5)\nbeta_men\n\n-0.09986\n\n\n\\(\\hat{\\beta_0}\\)\n\nround((17+26+21+30+22+1+12+19+4+16)/10 - \n    round(sum((df$y[df$x2==\"남자\"] - (17+26+21+30+22+1+12+19+4+16)/10) *\n    (df$x1[df$x2==\"남자\"] - (151+92+175+31+104+277+210+120+290+238)/10)) / \n    sum((df$x1[df$x2==\"남자\"] - (151+92+175+31+104+277+210+120+290+238)/10)**2),5)*\n    (151+92+175+31+104+277+210+120+290+238)/10,5)\n\n33.65637\n\n\n\\(\\hat{y}_{men} = 33.65637 -0.09986 x_{men}\\)\n\nR code\n\nsummary(lm(df$y[df$x2==\"남자\"]~df$x1[df$x2==\"남자\"]))\n\n\nCall:\nlm(formula = df$y[df$x2 == \"남자\"] ~ df$x1[df$x2 == \"남자\"])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.9953 -1.5008 -0.6915  1.0080  6.1102 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            33.65610    2.60379  12.926 1.21e-06 ***\ndf$x1[df$x2 == \"남자\"] -0.09986    0.01393  -7.171 9.51e-05 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 3.542 on 8 degrees of freedom\nMultiple R-squared:  0.8654,    Adjusted R-squared:  0.8485 \nF-statistic: 51.43 on 1 and 8 DF,  p-value: 9.51e-05\n\n\n\nanswer\n\\(SSE_{men}\\)\n\nSSE_men &lt;- sum((df$y[df$x2==\"남자\"] - (33.65637 - 0.09986*df$x1[df$x2==\"남자\"]))**2)\nSSE_men\n\n100.3747034298\n\n\n\\(MSE_{men} \\sim \\sigma^2_{men}\\)\n\nMSE_men &lt;- sum((df$y[df$x2==\"남자\"] - (33.65637 - 0.09986*df$x1[df$x2==\"남자\"]))**2)/(10-2)\nMSE_men\n\n12.546837928725\n\n\n\nR code\n\nanova(lm(df$y[df$x2==\"남자\"]~df$x1[df$x2==\"남자\"]))\n\n\nA anova: 2 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\ndf$x1[df$x2 == \"남자\"]\n1\n645.2253\n645.22530\n51.42533\n9.509826e-05\n\n\nResiduals\n8\n100.3747\n12.54684\nNA\nNA\n\n\n\n\n\n\nanswer\n여자\n\nplot(df$x1[df$x2==\"여자\"], df$y[df$x2==\"여자\"])\n\n\n\n\n\\(S_{yy}\\)\n\nsum((df$y[df$x2==\"여자\"] - (28+15+11+38+31+21+20+13+30+14)/10)**2)\n\n756.9\n\n\n\\(S_{xx}\\)\n\nsum((df$x1[df$x2==\"여자\"] - (164+272+295+68+85+224+166+305+124+246)/10)**2)\n\n66542.9\n\n\n\\(S_{xy}\\)\n\nsum((df$y[df$x2==\"여자\"] - (28+15+11+38+31+21+20+13+30+14)/10) * \n    (df$x1[df$x2==\"여자\"] - (164+272+295+68+85+224+166+305+124+246)/10))\n\n-6783.9\n\n\n\\(\\hat{\\beta}_1 = \\frac{S_{xy}}{S_{xx}}\\)\n\nbeta_women &lt;- round(sum((df$y[df$x2==\"여자\"] - (28+15+11+38+31+21+20+13+30+14)/10) * \n    (df$x1[df$x2==\"여자\"] - (164+272+295+68+85+224+166+305+124+246)/10))/\n      sum((df$x1[df$x2==\"여자\"] - (164+272+295+68+85+224+166+305+124+246)/10)**2),5)\nbeta_women\n\n-0.10195\n\n\n\\(\\hat{\\beta_0}\\)\n\nround((28+15+11+38+31+21+20+13+30+14)/10 - \n      round(sum((df$y[df$x2==\"여자\"] - (28+15+11+38+31+21+20+13+30+14)/10) * \n    (df$x1[df$x2==\"여자\"] - (164+272+295+68+85+224+166+305+124+246)/10))/\n      sum((df$x1[df$x2==\"여자\"] - (164+272+295+68+85+224+166+305+124+246)/10)**2),5)*\n      (164+272+295+68+85+224+166+305+124+246)/10,5)\n\n41.97006\n\n\n\\(\\hat{y}_{women} = 41.97006 -0.10195 x_{women}\\)\n\nR code\n\nsummary(lm(df$y[df$x2==\"여자\"]~df$x1[df$x2==\"여자\"]))\n\n\nCall:\nlm(formula = df$y[df$x2 == \"여자\"] ~ df$x1[df$x2 == \"여자\"])\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-5.046 -1.952  0.716  2.060  2.963 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            41.96962    2.33998  17.936 9.57e-08 ***\ndf$x1[df$x2 == \"여자\"] -0.10195    0.01108  -9.205 1.57e-05 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 2.857 on 8 degrees of freedom\nMultiple R-squared:  0.9137,    Adjusted R-squared:  0.9029 \nF-statistic: 84.73 on 1 and 8 DF,  p-value: 1.57e-05\n\n\n\nanswer\n\\(SSE_{women}\\)\n\nSSE_women &lt;- sum((df$y[df$x2==\"여자\"] - (41.97006 - 0.10195*df$x1[df$x2==\"여자\"]))**2)\nSSE_women\n\n65.2965503775\n\n\n\\(MSE_{women} \\sim \\sigma^2_{women}\\)\n\nMSE_women &lt;- sum((df$y[df$x2==\"여자\"] - (41.97006 - 0.10195*df$x1[df$x2==\"여자\"]))**2)/(10-2)\nMSE_women\n\n8.1620687971875\n\n\n\nR code\n\nanova(lm(df$y[df$x2==\"여자\"]~df$x1[df$x2==\"여자\"]))\n\n\nA anova: 2 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\ndf$x1[df$x2 == \"여자\"]\n1\n691.60345\n691.603450\n84.73384\n1.56975e-05\n\n\nResiduals\n8\n65.29655\n8.162069\nNA\nNA\n\n\n\n\n\n\nanswer\n가설\n\\(H_0: \\beta_{11} - \\beta_{12} = 0\\)\n\\(H_0: \\beta_{11} - \\beta_{12} \\neq 0\\)\n검정통계량 \\(t_0 = \\frac{\\hat{\\beta}_{11}- \\hat{\\beta}_{12}}{\\sqrt{\\hat{var}(\\hat{\\beta}_{11} - \\hat{\\beta}_{12})}}\\sim H_0, t(n_1 - n_2 - 4)\\)\n\\(var(\\hat{\\beta}_{11} - \\hat{\\beta}_{12})\\)\n\\(= var(\\hat{\\beta}_{11}) + var(\\hat{\\beta}_{12})\\)\n\\(= \\frac{\\sigma^2}{\\sum(x_{11} - \\bar{x}_{11})^2} + \\frac{\\sigma^2}{\\sum(x_{12} - \\bar{x}_{12})^2}\\)\n\\(\\hat{\\beta}_{11} - \\hat{\\beta}_{12}\\)\n\nbeta_men # CH13, p14 beta_1과 동일\nbeta_women # CH13 p1.4 beta1 + beta3 과 동일\n# beta11 - beta12 = \\beta3 = 0.0021\n\n-0.09986\n\n\n-0.10195\n\n\n\nbeta_men - beta_women\n\n0.00208999999999999\n\n\n\\(\\sigma^2 = MSE(FM) = \\frac{SSE_{FM}}{n_1 + n_2 - 1}\\)\n\\(\\star SSE_{FM} = SSE_1 + SSE_2\\)\n\nSSE_men\nSSE_women\nSSE_men + SSE_women # SSE_FM\n(SSE_men + SSE_women)/(10 +10-2)\n\n100.3747034298\n\n\n65.2965503775\n\n\n165.6712538073\n\n\n9.20395854485\n\n\n\\(\\sqrt{var(\\hat{\\beta}_{11} - \\hat{\\beta}_{12}))}\\)\n\nsqrt(MSE_men/sum((df$x1[df$x2==\"남자\"] - (151+92+175+31+104+277+210+120+290+238)/10)**2) + \n    MSE_women/sum((df$x1[df$x2==\"여자\"] - (164+272+295+68+85+224+166+305+124+246)/10)**2))\n# CG13 p,16 hat{=(s.e.)(beta_3)과 동일\n\n0.0177922812236426\n\n\n\\(t_0\\)\n\n(beta_men - beta_women)/ \n    sqrt(MSE_men/sum((df$x1[df$x2==\"남자\"] - (151+92+175+31+104+277+210+120+290+238)/10)**2) + \n    MSE_women/sum((df$x1[df$x2==\"여자\"] - (164+272+295+68+85+224+166+305+124+246)/10)**2))\n\n0.117466668479969\n\n\n\\(var(\\hat{\\beta}_{men} - \\hat{\\beta}_{women})\\)\n\nMSE_men/sum((df$x1[df$x2==\"남자\"] - (151+92+175+31+104+277+210+120+290+238)/10)**2) + \n    MSE_women/sum((df$x1[df$x2==\"여자\"] - (164+272+295+68+85+224+166+305+124+246)/10)**2)\n\n0.000316565271141184\n\n\n\nqt(0.025,16)\n\n-2.11990529922126\n\n\n기각역 : \\(|t_0| &gt; t_{\\alpha/2}(n_1 + n_2 - 4) = 2.120\\)\n결론: 기각역에 속하지 않으므로 귀무가설 기각 못함.\n\\(H_0: \\beta_{11} - \\beta_{12} = 0\\) 채택\n따라서 성별간 두 기울기가 다르다고 할 수 없다.\n\nR code\n\nggplot(df, aes(x1, y, col=x2)) + \n  geom_point() + \n  theme_bw() + \n  geom_abline(slope = coef(lm(df$y~df$x1*df$x2))[2], intercept = coef(lm(df$y~df$x1*df$x2))[1], col= 'darkorange')+\n  geom_abline(slope = coef(lm(df$y~df$x1*df$x2))[2], intercept = coef(lm(df$y~df$x1*df$x2))[1]+coef(lm(df$y~df$x1*df$x2))[3], col= 'steelblue')+\n  guides(col=guide_legend(title=\"성별\")) +\n  scale_color_manual(labels = c(\"남자\", \"여자\"), values = c(\"darkorange\", \"steelblue\"))\n\n\n\n\n\nsummary(lm(df$y~df$x1*df$x2))\n\n\nCall:\nlm(formula = df$y ~ df$x1 * df$x2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0463 -1.7591 -0.6232  1.9311  6.1102 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     33.656104   2.365392  14.229 1.68e-10 ***\ndf$x1           -0.099858   0.012650  -7.894 6.59e-07 ***\ndf$x2여자        8.313516   3.541379   2.348   0.0321 *  \ndf$x1:df$x2여자 -0.002089   0.017766  -0.118   0.9078    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 3.218 on 16 degrees of freedom\nMultiple R-squared:  0.8992,    Adjusted R-squared:  0.8803 \nF-statistic: 47.56 on 3 and 16 DF,  p-value: 3.405e-08\n\n\n\\(\\beta_3 = -0.002089\\), 유의확률 $0.9078 $ 유의수준 \\(\\alpha=0.05\\)에서 기각할 수 없다.\n기각역: \\(|t_0|?t_{\\alpha/2}(n_1 + n_2 - 4) = t_{0.025}(16) = 2.120\\)\n기각역에 속하지 않으므로 \\(H_0\\) 기각 못함 \\(H_0: \\beta_{11} - \\beta_{12} = 0\\) 채택\n따라서 성별간 두 기울기가 다르다고 할 수 없다.\n\n\n(2)\n13장 강의노트 p.8 에 따르면 \\(x_1,x_2\\)을 설명변수로 했을 때 적합 결과는 \\[\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 x_2\\] \\[= 33.8349 − 0.1009x_1 + 7.9340x_2\\] 이었다. \\(\\beta_1\\) 의 추정값 \\(\\hat{\\beta}_1\\) 이 갖는 분산을 추정하고, \\(\\beta_1\\) 의 95% 신뢰구간을 구하시오.\nanswer\n\nbetahat_2 &lt;- solve(t(matrix(c(rep(1,20),df$x1,rep(0,10),rep(1,10)),nrow=20,ncol=3))%*%\n      matrix(c(rep(1,20),df$x1,rep(0,10),rep(1,10)),nrow=20,ncol=3))%*%\n        t(matrix(c(rep(1,20),df$x1,rep(0,10),rep(1,10)),nrow=20,ncol=3))%*%\n        matrix(df$y,nrow=20,ncol=1)\nbetahat_2\n\n\nA matrix: 3 × 1 of type dbl\n\n\n33.8349119\n\n\n-0.1009177\n\n\n7.9339526\n\n\n\n\n\n\ndf$sex &lt;- ifelse(df$x2=='여자',1,0)\n\n\\(var(\\beta_1) = (x^\\top x)^{-1}_{(2,2)} \\sigma^2\\)\n\nt(matrix(c(rep(1,20),df$x1,df$sex),nrow=20,ncol=3))%*%matrix(c(rep(1,20),df$x1,df$sex),nrow=20,ncol=3)\n\n\nA matrix: 3 × 3 of type dbl\n\n\n20\n3637\n10\n\n\n3637\n796043\n1949\n\n\n10\n1949\n10\n\n\n\n\n\n\nsolve(t(matrix(c(rep(1,20),df$x1,df$sex),nrow=20,ncol=3))%*%matrix(c(rep(1,20),df$x1,df$sex),nrow=20,ncol=3))\n\n\nA matrix: 3 × 3 of type dbl\n\n\n0.31709536\n-1.286110e-03\n-0.0664325307\n\n\n-0.00128611\n7.619135e-06\n-0.0001988594\n\n\n-0.06643253\n-1.988594e-04\n0.2051902307\n\n\n\n\n\n\\((x^\\top x)^{-1}_{(2,2)}\\)\n\nsolve(t(matrix(c(rep(1,20),df$x1,df$sex),nrow=20,ncol=3))%*%matrix(c(rep(1,20),df$x1,df$sex),nrow=20,ncol=3))[2,2]\n\n7.61913469487271e-06\n\n\n\\(MSE \\sim \\sigma^2\\)\n\nsum((matrix(c(rep(1,20),df$x1,rep(0,10),rep(1,10)),nrow=20,ncol=3)%*%betahat_2 - df$y)**2)/17\n\n9.75379176770424\n\n\n\\(var(\\beta_1) = (x^\\top x)^{-1}_{(2,2)} \\sigma^2\\)\n\nhat_var_b1 &lt;- ((solve(t(matrix(c(rep(1,20),df$x1,rep(0,10),rep(1,10)),nrow=20,ncol=3)) %*% matrix(c(rep(1,20),df$x1,rep(0,10),rep(1,10)),nrow=20,ncol=3)))[2,2])*\n    sum((matrix(c(rep(1,20),df$x1,rep(0,10),rep(1,10)),nrow=20,ncol=3)%*%betahat_2 - df$y)**2)/17\nhat_var_b1\n\n7.43154532638791e-05\n\n\n\nsqrt(hat_var_b1)\n\n0.00862064111675455\n\n\n\\(\\beta_1 \\pm t_{0.975}(17) se(\\hat{\\beta}_1)\\)\n\nbetahat_2[2] - qt(0.975,17) * sqrt(hat_var_b1)\n\n-0.119105687693037\n\n\n\nbetahat_2[2] + qt(0.975,17) * sqrt(hat_var_b1)\n\n-0.0827297618549584\n\n\n\nR code\n\nsummary(lm(df$y~matrix(c(rep(1,20),df$x1,df$sex),nrow=20,ncol=3)))$coefficients\n\n\nA matrix: 3 × 4 of type dbl\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n33.8349119\n1.758659173\n19.239039\n5.635999e-13\n\n\nmatrix(c(rep(1, 20), df$x1, df$sex), nrow = 20, ncol = 3)2\n-0.1009177\n0.008620641\n-11.706522\n1.468240e-09\n\n\nmatrix(c(rep(1, 20), df$x1, df$sex), nrow = 20, ncol = 3)3\n7.9339526\n1.414702366\n5.608213\n3.134533e-05\n\n\n\n\n\n\nanova(lm(df$y~matrix(c(rep(1,20),df$x1,df$sex),nrow=20,ncol=3)))\n\n\nA anova: 2 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nmatrix(c(rep(1, 20), df$x1, df$sex), nrow = 20, ncol = 3)\n2\n1477.1355\n738.567770\n75.72109\n3.419664e-09\n\n\nResiduals\n17\n165.8145\n9.753792\nNA\nNA\n\n\n\n\n\n\nconfint(lm(df$y~matrix(c(rep(1,20),df$x1,rep(0,10),rep(1,10)),nrow=20,ncol=3)), level=0.95)\n\n\nA matrix: 4 × 2 of type dbl\n\n\n\n2.5 %\n97.5 %\n\n\n\n\n(Intercept)\n30.1244654\n37.54535846\n\n\nmatrix(c(rep(1, 20), df$x1, rep(0, 10), rep(1, 10)), nrow = 20, ncol = 3)1\nNA\nNA\n\n\nmatrix(c(rep(1, 20), df$x1, rep(0, 10), rep(1, 10)), nrow = 20, ncol = 3)2\n-0.1191057\n-0.08272976\n\n\nmatrix(c(rep(1, 20), df$x1, rep(0, 10), rep(1, 10)), nrow = 20, ncol = 3)3\n4.9491915\n10.91871371\n\n\n\n\n\n\n\n(3)\n다음의 모형을 적합하시오. \\[y_i =\\beta_0 +\\beta_1x_{1i} +\\beta_2x_{2i} +\\beta_3x_{3i} +\\beta_4x_{4i} + \\epsilon_i\\]\n\\[x_{3i}=\\begin{cases} 1: & \\text{학력이 고졸} \\\\ 0 : &\\text{기타} \\end{cases}, x_{4i}= \\begin{cases} 1 : & \\text{학력이 대졸} \\\\ 0 : & \\text{기타}\\end{cases} \\]\nanswer\n\ndf$high &lt;- ifelse(df$edu=='고',1,0)\n\n\ndf$univ &lt;- ifelse(df$edu=='대',1,0)\n\n\\(\\hat{\\beta}\\)\n\nx_hu &lt;- matrix(c(rep(c(1),20),df$x1,df$sex,df$high,df$univ),nrow=20,ncol=5)\n\n\nbetahat_hu &lt;- solve(t(x_hu)%*%x_hu)%*%t(x_hu)%*%df$y\nbetahat_hu\n\n\nA matrix: 5 × 1 of type dbl\n\n\n36.5226684\n\n\n-0.1101234\n\n\n7.8990531\n\n\n-1.3758336\n\n\n-2.4036479\n\n\n\n\n\n\\(y = 36.5226684 - 0.1101234 x_1 + 7.8990531 x_2 - 1.3758336 x_3 - 2.4036479 x_4\\)\n\nR code\n\nsummary(lm(y~x1+sex+high+univ,df))\n\n\nCall:\nlm(formula = y ~ x1 + sex + high + univ, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0185 -1.7038 -0.5386  1.6375  6.1526 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 36.52267    5.33138   6.851 5.50e-06 ***\nx1          -0.11012    0.01997  -5.516 5.93e-05 ***\nsex          7.89905    1.50447   5.250 9.79e-05 ***\nhigh        -1.37583    4.13333  -0.333    0.744    \nuniv        -2.40365    2.85796  -0.841    0.414    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 3.214 on 15 degrees of freedom\nMultiple R-squared:  0.9057,    Adjusted R-squared:  0.8806 \nF-statistic: 36.02 on 4 and 15 DF,  p-value: 1.587e-07\n\n\n\n\n\n(4)\n위의 모형에서 \\(\\beta_3\\)과 \\(\\beta_4\\)가 갖는 의미를 해석하시오.\n\\[y_i =\\beta_0 +\\beta_1x_{1i} +\\beta_2x_{2i} +\\beta_3x_{3i} +\\beta_4x_{4i} + \\epsilon_i\\]\n\\[x_{3i}=\\begin{cases} 1: & \\text{학력이 고졸} \\\\ 0 : &\\text{기타} \\end{cases}, x_{4i}= \\begin{cases} 1 : & \\text{학력이 대졸} \\\\ 0 : & \\text{기타}\\end{cases} \\]\nanswer\n\\(E(y) = \\beta_0 +\\beta_1x_{1} +\\beta_2x_{2} +\\beta_3x_{3} +\\beta_4x_{4}\\)\n학력이 고등학교 졸업\n\\(E(y|고) = (\\beta_0 +\\beta_3) +\\beta_1x_{1} +\\beta_2x_{2}\\)\n학력이 대학교 졸업\n\\(E(y|고) = (\\beta_0 +\\beta_4)+\\beta_1x_{1}+\\beta_2x_{2}\\)\n학력이 대학원 졸업\n\\(E(y|대학원) = \\beta_0 +\\beta_1x_{1}+\\beta_2x_{2}\\)\n\\(\\beta_3\\) = 학력이 고등학교 졸업일때의 평균 숙련 시간에서 학력이 대학원 졸업일때의 평균 숙련시간을 뺀 값이다.\n\\(\\beta_4\\) = 학력이 대학교 졸업일때의 평균 숙련 시간에서 학력이 대학원 졸업일때의 평균 숙련시간을 뺀 값이다.\n\n\n(5)\n위의 \\(\\beta_3\\)과 \\(\\beta_4\\)의 최소제곱추정값 \\(\\hat{\\beta}_3\\)과 $_4$가 갖는 각각의 분산을 추정하시오. \\(\\beta_3\\)과 \\(\\beta_4\\)의 95% 신뢰구간을 구하시오\nanswer\n\\(var(\\beta_3) = (x^\\top x)^{-1}_{(4,4)} \\sigma^2\\)\n\nt(x_hu)%*%x_hu\n\n\nA matrix: 5 × 5 of type dbl\n\n\n20\n3637\n10\n4\n6\n\n\n3637\n796043\n1949\n295\n821\n\n\n10\n1949\n10\n1\n3\n\n\n4\n295\n1\n4\n0\n\n\n6\n821\n3\n0\n6\n\n\n\n\n\n\nsolve(t(x_hu)%*%x_hu)\n\n\nA matrix: 5 × 5 of type dbl\n\n\n2.751920464\n-0.009968093\n-0.231607148\n-1.958871839\n-1.272149536\n\n\n-0.009968093\n0.000038595\n0.000397155\n0.007022423\n0.004488433\n\n\n-0.231607148\n0.000397155\n0.219140617\n0.147531812\n0.067692796\n\n\n-1.958871839\n0.007022423\n0.147531812\n1.654085215\n0.924204433\n\n\n-1.272149536\n0.004488433\n0.067692796\n0.924204433\n0.790802611\n\n\n\n\n\n\\((x^\\top x)^{-1}_{(4,4)}\\)\n\nsolve(t(x_hu)%*%x_hu)[4,4]\n\n1.65408521513359\n\n\n\\(MSE \\sim \\sigma^2\\)\n\nsum((x_hu%*%betahat_hu - df$y)**2)\n\n154.929453525913\n\n\n\nsum((x_hu%*%betahat_hu - df$y)**2)/15\n\n10.3286302350608\n\n\n\\(var(\\hat{\\beta}_3) = (x^\\top x)^{-1}_{(4,4)} \\sigma^2\\)\n\nhat_var_hu_b3 &lt;- (solve(t(x_hu)%*%x_hu)[4,4]%*% sum((x_hu%*%betahat_hu - df$y)**2)/15)[,]\nhat_var_hu_b3\n\n17.0844345643959\n\n\n\nsqrt(hat_var_hu_b3)\n\n4.133332138166\n\n\n\\(t_{\\alpha/2}(n-4-1)\\)\n\nqt(0.975,15)\n\n2.13144954555978\n\n\n\\(\\beta_3 \\pm t_{0.975}(15) se(\\hat{\\beta}_3)\\)\n\nbetahat_hu[4] - qt(0.975,15) * sqrt(hat_var_hu_b3)\n\n-10.1858224609978\n\n\n\nbetahat_hu[4] + qt(0.975,15) * sqrt(hat_var_hu_b3)\n\n7.43415535408522\n\n\n\\((x^\\top x)^{-1}_{(5,5)}\\)\n\nsolve(t(x_hu)%*%x_hu)[5,5]\n\n0.790802610709727\n\n\n\\(MSE \\sim \\sigma^2\\)\n\nsum((x_hu%*%betahat_hu - df$y)**2)/15\n\n10.3286302350608\n\n\n\\(var(\\beta_4) = (x^\\top x)^{-1}_{(5,5)} \\sigma^2\\)\n\nhat_var_hu_b4 &lt;- (solve(t(x_hu)%*%x_hu)[5,5]%*% sum((x_hu%*%betahat_hu - df$y)**2)/15)[,]\nhat_var_hu_b4\n\n8.16790775494154\n\n\n\nsqrt(hat_var_hu_b4)\n\n2.85795517021201\n\n\n\\(\\beta_4 \\pm t_{0.975}(15) se(\\hat{\\beta}_4)\\)\n\nbetahat_hu[5] - qt(0.975,15) * sqrt(hat_var_hu_b4)\n\n-8.49523514036072\n\n\n\nbetahat_hu[5] + qt(0.975,15) * sqrt(hat_var_hu_b4)\n\n3.68793935719647\n\n\n\nR code\n\nsummary(lm(df$y~x_hu))$coefficients\n\n\nA matrix: 5 × 4 of type dbl\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n36.5226684\n5.33137589\n6.8505146\n5.501546e-06\n\n\nx_hu2\n-0.1101234\n0.01996581\n-5.5155977\n5.929593e-05\n\n\nx_hu3\n7.8990531\n1.50446748\n5.2503980\n9.786601e-05\n\n\nx_hu4\n-1.3758336\n4.13333214\n-0.3328631\n7.438444e-01\n\n\nx_hu5\n-2.4036479\n2.85795517\n-0.8410376\n4.135338e-01\n\n\n\n\n\n\nanova(lm(df$y~x_hu))\n\n\nA anova: 2 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nx_hu\n4\n1488.0205\n372.00514\n36.01689\n1.586767e-07\n\n\nResiduals\n15\n154.9295\n10.32863\nNA\nNA\n\n\n\n\n\n\nconfint(lm(df$y~x_hu), level=0.95)\n\n\nA matrix: 6 × 2 of type dbl\n\n\n\n2.5 %\n97.5 %\n\n\n\n\n(Intercept)\n25.1591097\n47.88622717\n\n\nx_hu1\nNA\nNA\n\n\nx_hu2\n-0.1526795\n-0.06756725\n\n\nx_hu3\n4.6923566\n11.10574964\n\n\nx_hu4\n-10.1858225\n7.43415535\n\n\nx_hu5\n-8.4952351\n3.68793936\n\n\n\n\n\n\n\n(6)\n만약 적성검사점수와 성별, 적성검사점수와 학력, 성별과 학력간에 교호작용이 있다면, 다음의 반응함수를 가정할 수 있다. \\[E(y)=\\beta_0 +\\beta_1x_1 +\\beta_2x_2 +\\beta_3x_3 +\\beta_4x_4\\] \\[+ \\beta_5x_1x_2 + \\beta_6x_1x_3 + \\beta_7x_1x_4 + \\beta_8x_2x_3 + \\beta_9x_2x_4\\] 데이터로부터 위의 반응함수를 적합하고, 다섯 개의 다음 가설을 유의수준 \\(\\alpha = 0.1\\)에서 검정하시오. \\(H_0 :\\beta_i =0, H_1 :\\beta_i \\neq 0(i=5,6,7,8,9)\\)\nanswer\n\nx_6 &lt;- matrix(c(rep(c(1),20),df$x1,df$sex,df$high,df$univ,\n                df$x1*df$sex, df$x1*df$high, df$x1*df$univ, df$sex*df$high, df$sex*df$univ),nrow=20,ncol=10)\n\n\nx_6\n\n\nA matrix: 20 × 10 of type dbl\n\n\n1\n151\n0\n0\n1\n0\n0\n151\n0\n0\n\n\n1\n92\n0\n1\n0\n0\n92\n0\n0\n0\n\n\n1\n175\n0\n0\n1\n0\n0\n175\n0\n0\n\n\n1\n31\n0\n1\n0\n0\n31\n0\n0\n0\n\n\n1\n104\n0\n1\n0\n0\n104\n0\n0\n0\n\n\n1\n277\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n210\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n120\n0\n0\n1\n0\n0\n120\n0\n0\n\n\n1\n290\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n238\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n164\n1\n0\n0\n164\n0\n0\n0\n0\n\n\n1\n272\n1\n0\n0\n272\n0\n0\n0\n0\n\n\n1\n295\n1\n0\n0\n295\n0\n0\n0\n0\n\n\n1\n68\n1\n1\n0\n68\n68\n0\n1\n0\n\n\n1\n85\n1\n0\n1\n85\n0\n85\n0\n1\n\n\n1\n224\n1\n0\n0\n224\n0\n0\n0\n0\n\n\n1\n166\n1\n0\n1\n166\n0\n166\n0\n1\n\n\n1\n305\n1\n0\n0\n305\n0\n0\n0\n0\n\n\n1\n124\n1\n0\n1\n124\n0\n124\n0\n1\n\n\n1\n246\n1\n0\n0\n246\n0\n0\n0\n0\n\n\n\n\n\n\nbetahat_6 &lt;- solve(t(x_6)%*%x_6)%*%t(x_6)%*%df$y\nbetahat_6\n\n\nA matrix: 10 × 1 of type dbl\n\n\n36.63696518\n\n\n-0.11186981\n\n\n12.27994350\n\n\n-3.42748073\n\n\n-6.74634061\n\n\n-0.01528919\n\n\n0.01659028\n\n\n0.03861449\n\n\n0.02924469\n\n\n-4.10250464\n\n\n\n\n\n\\(\\hat{E}(y) = 36.63696518 - 0.11186981x_1 + 12.27994350x_2 - 3.42748073x_3 - 6.74634061x_4 - 0.01528919x_1 x_2 + 0.01659028x_1 x_3 + 0.03861449 x_1 x_4 + 0.02924469x_2 x_3 - 4.10250464x_2 x_4\\)\n\nt(x_6)%*%x_6\n\n\nA matrix: 10 × 10 of type dbl\n\n\n20\n3637\n10\n4\n6\n1949\n295\n821\n1\n3\n\n\n3637\n796043\n1949\n295\n821\n446403\n24865\n117983\n68\n375\n\n\n10\n1949\n10\n1\n3\n1949\n68\n375\n1\n3\n\n\n4\n295\n1\n4\n0\n68\n295\n0\n1\n0\n\n\n6\n821\n3\n0\n6\n375\n0\n821\n0\n3\n\n\n1949\n446403\n1949\n68\n375\n446403\n4624\n50157\n68\n375\n\n\n295\n24865\n68\n295\n0\n4624\n24865\n0\n68\n0\n\n\n821\n117983\n375\n0\n821\n50157\n0\n117983\n0\n375\n\n\n1\n68\n1\n1\n0\n68\n68\n0\n1\n0\n\n\n3\n375\n3\n0\n3\n375\n0\n375\n0\n3\n\n\n\n\n\n\nsolve(t(x_6)%*%x_6)\n\n\nA matrix: 10 × 10 of type dbl\n\n\n13.17371289\n-5.093089e-02\n-12.267241674\n-13.17371289\n-8.36632222\n4.731945e-02\n5.093089e-02\n1.859418e-02\n9.049519133\n5.587008431\n\n\n-0.05093089\n2.007129e-04\n0.047358588\n0.05093089\n0.03198551\n-1.864806e-04\n-2.007129e-04\n-7.327756e-05\n-0.034677908\n-0.021032546\n\n\n-12.26724167\n4.735859e-02\n15.889907134\n12.26724167\n6.05702973\n-6.112751e-02\n-4.735859e-02\n-5.585862e-03\n-11.733236632\n-7.260347528\n\n\n-13.17371289\n5.093089e-02\n12.267241674\n15.37525737\n8.36632222\n-4.731945e-02\n-7.562090e-02\n-1.859418e-02\n-9.572142583\n-5.587008431\n\n\n-8.36632222\n3.198551e-02\n6.057029727\n8.36632222\n10.98679372\n-2.278514e-02\n-3.198551e-02\n-4.736984e-02\n-4.507640358\n-3.906316822\n\n\n0.04731945\n-1.864806e-04\n-0.061127507\n-0.04731945\n-0.02278514\n2.414928e-04\n1.864806e-04\n2.145159e-05\n0.044705999\n0.027035225\n\n\n0.05093089\n-2.007129e-04\n-0.047358588\n-0.07562090\n-0.03198551\n1.864806e-04\n5.270126e-04\n7.327756e-05\n0.037179539\n0.021032546\n\n\n0.01859418\n-7.327756e-05\n-0.005585862\n-0.01859418\n-0.04736984\n2.145159e-05\n7.327756e-05\n2.668358e-04\n0.004127154\n0.007485293\n\n\n9.04951913\n-3.467791e-02\n-11.733236632\n-9.57214258\n-4.50764036\n4.470600e-02\n3.717954e-02\n4.127154e-03\n10.045741217\n5.421952259\n\n\n5.58700843\n-2.103255e-02\n-7.260347528\n-5.58700843\n-3.90631682\n2.703522e-02\n2.103255e-02\n7.485293e-03\n5.421952259\n4.226992806\n\n\n\n\n\n\\(MSE \\sim \\sigma^2\\)\n\nsum((x_6%*%betahat_6 - df$y)**2)\n\n128.60490936452\n\n\n\nsum((x_6%*%betahat_6 - df$y)**2)/10\n\n12.860490936452\n\n\n\\(H_0: \\beta_1 = 0 \\text{ vs } H_1: \\beta_i \\neq 0 (i=5,6,7,8,9)\\)\n\\(t_0 = \\frac{\\hat{\\beta}_i}{\\hat{s.e.}(\\hat{\\beta}_i)}\\sim H_0 , t(n-p-1)\\)\n\n\\(H_0 :\\beta_5 =0\\)\n\\(H_1 :\\beta_5 \\neq 0\\)\n\\((x^\\top x)^{-1}_{(6,6)}\\)\n\nsolve(t(x_6)%*%x_6)[6,6]\n\n0.000241492771933959\n\n\n\\(var(\\hat{\\beta}_5) = (x^\\top x)^{-1}_{(6,6)} \\sigma^2\\)\n\nhat_var_6_b5 &lt;- (solve(t(x_6)%*%x_6)[6,6]*sum((x_6%*%betahat_6 - df$y)**2)/10)\nhat_var_6_b5\n\n0.00310571560467536\n\n\n\nsqrt(hat_var_6_b5)\n\n0.0557289476365323\n\n\n\\(t_0 = \\frac{\\beta_5}{\\sqrt{\\hat{var}(\\hat{\\beta}_5)}}\\)\n\nbetahat_6[6]/sqrt(hat_var_6_b5)\n\n-0.274349074823289\n\n\n\nqt(0.95,10)\n\n1.81246112281168\n\n\n\\(|t_0|&lt;1.812\\)가 되어 귀무가설 \\(H_0 :\\beta_5 =0\\)은 기각할 수 없다.\n\n\\(H_0 :\\beta_6 =0\\)\n\\(H_1 :\\beta_6 \\neq 0\\)\n\\((x^\\top x)^{-1}_{(7,7)}\\)\n\nsolve(t(x_6)%*%x_6)[7,7]\n\n0.000527012620706128\n\n\n\\(var(\\beta_6) = (x^\\top x)^{-1}_{(7,7)} \\sigma^2\\)\n\nhat_var_6_b6 &lt;- (solve(t(x_6)%*%x_6)[7,7]*sum((x_6%*%betahat_6 - df$y)**2)/10)\nhat_var_6_b6\n\n0.006777641031987\n\n\n\\(t_0 = \\frac{\\beta_6}{\\sqrt{\\hat{var}(\\hat{\\beta}_6)}}\\)\n\nbetahat_6[7]/sqrt(hat_var_6_b6)\n\n0.20151831465707\n\n\n\nqt(0.95,10)\n\n1.81246112281168\n\n\n\\(|t_0|&lt;1.812\\)가 되어 귀무가설 \\(H_0 :\\beta_6 =0\\)은 기각할 수 없다.\n\n\\(H_0 :\\beta_7 =0\\)\n\\(H_1 :\\beta_7 \\neq 0\\)\n\\((x^\\top x)^{-1}_{(8,8)}\\)\n\nsolve(t(x_6)%*%x_6)[8,8]\n\n0.000266835833441736\n\n\n\\(var(\\beta_7) = (x^\\top x)^{-1}_{(8,8)} \\sigma^2\\)\n\nhat_var_6_b7 &lt;- (solve(t(x_6)%*%x_6)[8,8]*sum((x_6%*%betahat_6 - df$y)**2)/10)\nhat_var_6_b7\n\n0.00343163981749807\n\n\n\\(t_0 = \\frac{\\beta_7}{\\sqrt{\\hat{var}(\\hat{\\beta}_7)}}\\)\n\nbetahat_6[8]\n\n0.0386144912979298\n\n\n\nbetahat_6[8]/sqrt(hat_var_6_b7)\n\n0.659173088855045\n\n\n\nqt(0.95,10)\n\n1.81246112281168\n\n\n\\(|t_0|&lt;1.812\\)가 되어 귀무가설 \\(H_0 :\\beta_7 =0\\)은 기각할 수 없다.\n\n\\(H_0 :\\beta_8 =0\\)\n\\(H_1 :\\beta_8 \\neq 0\\)\n\\((x^\\top x)^{-1}_{(9,9)}\\)\n\nsolve(t(x_6)%*%x_6)[9,9]\n\n10.0457412166377\n\n\n\\(var(\\beta_8) = (x^\\top x)^{-1}_{(9,9)} \\sigma^2\\)\n\nhat_var_6_b8 &lt;- (solve(t(x_6)%*%x_6)[9,9]*sum((x_6%*%betahat_6 - df$y)**2)/10)\nhat_var_6_b8\n\n129.193163866512\n\n\n\\(t_0 = \\frac{\\beta_8}{\\sqrt{\\hat{var}(\\hat{\\beta}_8)}}\\)\n\nbetahat_6[9]/sqrt(hat_var_6_b8)\n\n0.00257292605071365\n\n\n\nqt(0.95,10)\n\n1.81246112281168\n\n\n\\(|t_0|&lt;1.812\\)가 되어 귀무가설 \\(H_0 :\\beta_8 =0\\)은 기각할 수 없다.\n\n\\(H_0 :\\beta_9 =0\\)\n\\(H_1 :\\beta_9 \\neq 0\\)\n\\(t_0 = \\frac{\\beta_9}{\\sqrt{\\hat{var}(\\hat{\\beta}_9)}}\\)\n\\((x^\\top x)^{-1}_{(10,10)}\\)\n\nsolve(t(x_6)%*%x_6)[10,10]\n\n4.22699280590833\n\n\n\\(var(\\beta_{10}) = (x^\\top x)^{-1}_{(10,10)} \\sigma^2\\)\n\nhat_var_6_b9 &lt;- (solve(t(x_6)%*%x_6)[10,10]*sum((x_6%*%betahat_6 - df$y)**2)/10)\nhat_var_6_b9\n\n54.3612026688321\n\n\n\nbetahat_6[10]/sqrt(hat_var_6_b9)\n\n-0.55642233331273\n\n\n\nqt(0.95,10)\n\n1.81246112281168\n\n\n\\(|t_0|&lt;1.812\\)가 되어 귀무가설 \\(H_0 :\\beta_9 =0\\)은 기각할 수 없다.\n\nR code\n\nsummary(lm(y ~ x1 + sex + high + univ + x1*sex + x1*high + x1*univ + sex*high + sex*univ,df))\n\n\nCall:\nlm(formula = y ~ x1 + sex + high + univ + x1 * sex + x1 * high + \n    x1 * univ + sex * high + sex * univ, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.6490 -1.4326 -0.1288  0.8918  5.9881 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) 36.63697   13.01616   2.815   0.0183 *\nx1          -0.11187    0.05081  -2.202   0.0523 .\nsex         12.27994   14.29517   0.859   0.4104  \nhigh        -3.42748   14.06177  -0.244   0.8124  \nuniv        -6.74634   11.88678  -0.568   0.5829  \nx1:sex      -0.01529    0.05573  -0.274   0.7894  \nx1:high      0.01659    0.08233   0.202   0.8443  \nx1:univ      0.03861    0.05858   0.659   0.5247  \nsex:high     0.02924   11.36632   0.003   0.9980  \nsex:univ    -4.10250    7.37300  -0.556   0.5902  \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 3.586 on 10 degrees of freedom\nMultiple R-squared:  0.9217,    Adjusted R-squared:  0.8513 \nF-statistic: 13.08 on 9 and 10 DF,  p-value: 0.0001985\n\n\n\nanova(lm(y ~ x1 + sex + high + univ + x1*sex + x1*high + x1*univ + sex*high + sex*univ,df))\n\n\nA anova: 10 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nx1\n1\n1170.3587315\n1170.3587315\n91.00420328\n2.444210e-06\n\n\nsex\n1\n306.7768085\n306.7768085\n23.85420666\n6.380709e-04\n\n\nhigh\n1\n3.5791086\n3.5791086\n0.27830264\n6.093205e-01\n\n\nuniv\n1\n7.3058980\n7.3058980\n0.56808857\n4.683946e-01\n\n\nx1:sex\n1\n0.6267948\n0.6267948\n0.04873802\n8.297162e-01\n\n\nx1:high\n1\n0.1408619\n0.1408619\n0.01095307\n9.187174e-01\n\n\nx1:univ\n1\n12.5166525\n12.5166525\n0.97326398\n3.471356e-01\n\n\nsex:high\n1\n9.0585522\n9.0585522\n0.70437063\n4.209294e-01\n\n\nsex:univ\n1\n3.9816828\n3.9816828\n0.30960581\n5.901555e-01\n\n\nResiduals\n10\n128.6049094\n12.8604909\nNA\nNA\n\n\n\n\n\n\n\n(7)\n위의 반응함수에 대하여 회귀분석을 통한 분산분석표를 작성하고, 회귀변동의 유의성을 \\(F\\)-검정하시오. 이때 \\(F\\) -검정의 귀무가설을 \\(\\beta_i\\) 들로 표현하시오.\nanswer\n\\(SST\\)\n\nSST &lt;- sum((df$y - (17+26+21+30+22+1+12+19+4+16+28+15+11+38+31+21+20+13+30+14)/20)**2)\nSST\n\n1642.95\n\n\n\\(SSR\\)\n\nSSR_7 &lt;- sum(((17+26+21+30+22+1+12+19+4+16+28+15+11+38+31+21+20+13+30+14)/20 - x_6%*%betahat_6)**2)\nSSR_7\n\n1514.34509063554\n\n\n\\(MSR\\)\n\nMSR_7 &lt;- SSR_7/9\nMSR_7\n\n168.260565626172\n\n\n\\(SSE\\)\n\nSSE_7 &lt;- SST - SSR_7\nSSE_7\n\n128.604909364456\n\n\n\\(MSE\\)\n\nMSE_7 &lt;- SSE_7/10\nMSE_7\n\n12.8604909364456\n\n\n\\(F_0\\)\n\nF0_7 &lt;- MSR_7 / MSE_7\nF0_7\n\n13.0835258512048\n\n\n\nqf(0.95,9,10)\n\n3.02038294702137\n\n\n\n\n\n\n제곱합\n자유도\n평균제곱합\nF_0\nF_{0.05}(9,10)\n\n\n\n\n회귀\n1514.35\n9\n168.26\n13.084\n3.0204\n\n\n잔차\n128.6\n10\n12.86\n\n\n\n\n합계\n1642.95\n19\n\n\n\n\n\n\n\\(H_0 : \\beta_1 = \\beta_2 = \\beta_3 = \\beta_4 = \\beta_5 = \\beta_6 = \\beta_7 = \\beta_8 = \\beta_9 = 0\\)\n\\(H_1 : \\text{not } H_0\\)\n\\(|F_0|&gt;3.0204\\)가 되어 귀무가설 \\(H_0 : \\beta_1 = \\beta_2 = \\beta_3 = \\beta_4 = \\beta_5 = \\beta_6 = \\beta_7 = \\beta_8 = \\beta_9 = 0\\)은 기각한다.\n따라서 유의수준 0.05에서 회귀모형이 유의함을 알 수 있다.\n\nR code\n\nround(anova(lm(y ~ x1 + sex + high + univ + x1*sex + x1*high + x1*univ + sex*high + sex*univ,df)),4)\n\n\nA anova: 10 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nx1\n1\n1170.3587\n1170.3587\n91.0042\n0.0000\n\n\nsex\n1\n306.7768\n306.7768\n23.8542\n0.0006\n\n\nhigh\n1\n3.5791\n3.5791\n0.2783\n0.6093\n\n\nuniv\n1\n7.3059\n7.3059\n0.5681\n0.4684\n\n\nx1:sex\n1\n0.6268\n0.6268\n0.0487\n0.8297\n\n\nx1:high\n1\n0.1409\n0.1409\n0.0110\n0.9187\n\n\nx1:univ\n1\n12.5167\n12.5167\n0.9733\n0.3471\n\n\nsex:high\n1\n9.0586\n9.0586\n0.7044\n0.4209\n\n\nsex:univ\n1\n3.9817\n3.9817\n0.3096\n0.5902\n\n\nResiduals\n10\n128.6049\n12.8605\nNA\nNA"
  },
  {
    "objectID": "posts/rl/2022-12-08-rl-HW4.html#section-8",
    "href": "posts/rl/2022-12-08-rl-HW4.html#section-8",
    "title": "Regression HW 4",
    "section": "2.",
    "text": "2.\n아래의 데이터에 대하여 다음 물음에 답하시오.\n\n\n\n\\(x\\)\n1\n2\n2\n3\n4\n5\n5\n6\n7\n\n\n\n\n\\(y\\)\n2.0\n3.2\n3.2\n4.1\n5.2\n7.0\n7.4\n9.7\n11.5\n\n\n\n\ndf2 &lt;- data.frame('y'=c(2.0,3.2,3.2,4.1,5.2,7.0,7.4,9.7,11.5),'x1'=c(1,2,2,3,4,5,5,6,7))\n\n\n(1)\n\\(x\\)와 \\(y\\)에 대한 산점도를 그려보고, 어떤 \\(x\\)의 값(\\(x_w\\))에서 구간을 두 개로 나누면 적절한지 논하시오.\nanswer\n\nplot(df2$x1,df2$y)\n\n\n\n\n산점도를 그려보면 \\(x = 4\\)를 기준으로 기울기가 달라지는 것으로 보인다.\n\n\n(2)\n위의 (1)에서 얻은 점을 경계로 구간별 단순선형회귀선을 추정하시오. 사용되는 모형은 \\[x_{2i} = \\begin{cases} 1 :& \\text{만약 }x_{1i} &gt; x_w \\text{ 이면 }\\\\ 0 : &\\text{만약 } x_{1i} \\le x_w \\text{ 이면 } \\end{cases}\\] 과 같다.\nanswer\n\nplot(df2$x1,df2$y)\nabline(v=4,col=\"red\",lty=2)\n\n\n\n\n\ndf2$x2 &lt;- sapply(df2$x1, function(x) max(0, x-4))\n\n\nx_sp &lt;- matrix(c(rep(1,9),df2$x1,df2$x2),nrow=9,ncol=3)\n\n\nx_sp\n\n\nA matrix: 9 × 3 of type dbl\n\n\n1\n1\n0\n\n\n1\n2\n0\n\n\n1\n2\n0\n\n\n1\n3\n0\n\n\n1\n4\n0\n\n\n1\n5\n1\n\n\n1\n5\n1\n\n\n1\n6\n2\n\n\n1\n7\n3\n\n\n\n\n\n\nbetahat_sp &lt;- solve(t(x_sp)%*%x_sp)%*%t(x_sp)%*%df2$y\nbetahat_sp\n\n\nA matrix: 3 × 1 of type dbl\n\n\n1.071429\n\n\n1.023469\n\n\n1.119388\n\n\n\n\n\n\nR code\n\nmodel_1 &lt;- lm(y ~ x1+x2, df2)\n\n\nsummary(model_1)\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = df2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.30816 -0.09388  0.03469  0.08163  0.24898 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.07143    0.19695   5.440 0.001602 ** \nx1           1.02347    0.06973  14.677 6.28e-06 ***\nx2           1.11939    0.12937   8.652 0.000131 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.1823 on 6 degrees of freedom\nMultiple R-squared:  0.9976,    Adjusted R-squared:  0.9968 \nF-statistic:  1242 on 2 and 6 DF,  p-value: 1.4e-08\n\n\n\ndf2_2 &lt;- rbind(df2[,2:3], c(4,0))\n\n\ndf2_2$y &lt;- predict(model_1, newdata = df2_2)\n\nthis is the predicted line of multiple linear regression\n\nggplot(data = df2, aes(x = x1, y = y)) + \n  geom_point(color='steelblue') +\n  geom_line(color='darkorange',data = df2_2, aes(x=x1, y=y))+\n  geom_vline(xintercept = 4, lty=2, col='red')+\n  theme_bw()\n\n\n\n\n\n\n(3)\n위의 (2)에 있는 모형에서 \\(\\beta_2\\) 의 90% 신뢰구간을 구하고, 그 의미를 해석하시오.\nanswer\n\nt(x_sp)%*%x_sp\n\n\nA matrix: 3 × 3 of type dbl\n\n\n9\n35\n7\n\n\n35\n169\n43\n\n\n7\n43\n15\n\n\n\n\n\n\nsolve(t(x_sp)%*%x_sp)\n\n\nA matrix: 3 × 3 of type dbl\n\n\n1.1666667\n-0.3809524\n0.5476190\n\n\n-0.3809524\n0.1462585\n-0.2414966\n\n\n0.5476190\n-0.2414966\n0.5034014\n\n\n\n\n\n\\((x^\\top x)^{-1}_{(3,3)}\\)\n\nsolve(t(x_sp)%*%x_sp)[3,3]\n\n0.503401360544218\n\n\n\\(MSE \\sim \\sigma^2\\)\n\nSSE_sp &lt;- sum((df2$y - x_sp%*%betahat_sp)**2)\nSSE_sp\n\n0.199489795918367\n\n\n\nMSE_sp &lt;- SSE_sp/(9-2-1)\nMSE_sp\n\n0.0332482993197279\n\n\n\\(var(\\beta_2) = (x^\\top x)^{-1}_{(3,3)} \\sigma^2\\)\n\nhat_var_b2_sp &lt;- solve(t(x_sp)%*%x_sp)[3,3] * MSE_sp\nhat_var_b2_sp\n\n0.0167372391133324\n\n\n\nsqrt(hat_var_b2_sp)\n\n0.129372482056009\n\n\n\\(\\beta_2 \\pm t_{0.95}(6) se(\\hat{\\beta}_2)\\)\n\nbetahat_sp[3] - qt(0.95,6) * sqrt(hat_var_b2_sp)\n\n0.867993699129489\n\n\n\nbetahat_sp[3] + qt(0.95,6) * sqrt(hat_var_b2_sp)\n\n1.3707818110746\n\n\n\\(\\beta_2\\)는 기울기의 차이이다.\n90% 시뢰구긴이 0을 포함하지 않고 모두 양수이므로, \\(\\beta_2 \\neq 0\\)이라고 90% 확신할 수 있다.\n즉 구간별 회귀직선의 기울기는 다르다고 할 수 있다.(유의수준 0.1)\n\nR code\n\nsummary(model_1)\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = df2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.30816 -0.09388  0.03469  0.08163  0.24898 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.07143    0.19695   5.440 0.001602 ** \nx1           1.02347    0.06973  14.677 6.28e-06 ***\nx2           1.11939    0.12937   8.652 0.000131 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.1823 on 6 degrees of freedom\nMultiple R-squared:  0.9976,    Adjusted R-squared:  0.9968 \nF-statistic:  1242 on 2 and 6 DF,  p-value: 1.4e-08\n\n\n\nanova(model_1)\n\n\nA anova: 3 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nx1\n1\n80.0869407\n80.0869407\n2408.75300\n4.798337e-09\n\n\nx2\n1\n2.4891251\n2.4891251\n74.86473\n1.313702e-04\n\n\nResiduals\n6\n0.1994898\n0.0332483\nNA\nNA\n\n\n\n\n\n\nconfint(model_1, level=0.90)\n\n\nA matrix: 3 × 2 of type dbl\n\n\n\n5 %\n95 %\n\n\n\n\n(Intercept)\n0.6887173\n1.454140\n\n\nx1\n0.8879634\n1.158975\n\n\nx2\n0.8679937\n1.370782"
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_CH03, CH04.html",
    "href": "posts/rl/2022-09-21-rl_CH03, CH04.html",
    "title": "고급회귀분석 실습 CH03, CH04",
    "section": "",
    "text": "chapter 3, chapter 4\n# setwd('C:/R-Project/DAT/Regression/')\nlibrary(ggplot2)"
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_CH03, CH04.html#data",
    "href": "posts/rl/2022-09-21-rl_CH03, CH04.html#data",
    "title": "고급회귀분석 실습 CH03, CH04",
    "section": "Data",
    "text": "Data\n\ndt &lt;- data.frame(x = c(4,8,9,8,8,12,6,10,6,9),\n                 y = c(9,20,22,15,17,30,18,25,10,20))\ndt\n\n\nA data.frame: 10 × 2\n\n\nx\ny\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n4\n9\n\n\n8\n20\n\n\n9\n22\n\n\n8\n15\n\n\n8\n17\n\n\n12\n30\n\n\n6\n18\n\n\n10\n25\n\n\n6\n10\n\n\n9\n20\n\n\n\n\n\ncorrelation check\n\ncor(dt$x, dt$y)\n\n0.921812343945765\n\n\n산점도 확인\n\nplot(y~x, \n     data = dt,\n     xlab = \"광고료\",\n     ylab = \"총판매액\",\n     pch  = 16,\n     cex  = 2,\n     col  = \"darkorange\")\n\n\n\n\n\npch 점 모양\ncex 점 크기\n양의상관관계 강하네,\n우상향이네, 단순상관선형 적용해보면 되겠다.\n\n\nggplot(dt, aes(x, y)) +\n  geom_point(col='steelblue', lwd=2) +\n  # geom_abline(intercept = co[1], slope = co[2], col='darkorange', lwd=1.2) +\n  xlab(\"광고료\")+ylab(\"총판매액\")+\n  # scale_x_continuous(breaks = seq(1,10))+\n  theme_bw() +\n  theme(axis.title = element_text(size = 14))\n\n\n\n\n\n적합\n\\(\\hat{ y} = \\widehat{(E(y|X=x))} = \\hat{\\beta_0} + \\hat{\\beta_1} * x\\)\n\\(H_0\\) : \\(\\beta_0\\) =0 vs \\(H_1\\) : \\(\\beta_0 \\ne 0\\)\n\\(H_0\\) : \\(\\beta_1 =0\\) vs \\(H_1\\) : \\(\\beta_1 \\ne 0\\)\n모형 적합을 한다 yhat을 찾는다. - 회귀분석을 한다. 평균 반응을 추정한다.\nlm linear model 사용\n\n## y = beta0 + beta1*x + epsilon\nmodel1 &lt;- lm(y ~ x, dt)\n# lm(y ~ 0 + x, dt) beta0 없이 분석하고 싶을때\nmodel1\n\n\nCall:\nlm(formula = y ~ x, data = dt)\n\nCoefficients:\n(Intercept)            x  \n     -2.270        2.609  \n\n\n설명변수 x 하나일때\n\nbeta0hat = -2.270\nbeta1hat = 2.609\n\n\nsummary(model1) \n\n\nCall:\nlm(formula = y ~ x, data = dt)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.600 -1.502  0.813  1.128  4.617 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -2.2696     3.2123  -0.707 0.499926    \nx             2.6087     0.3878   6.726 0.000149 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 2.631 on 8 degrees of freedom\nMultiple R-squared:  0.8497,    Adjusted R-squared:  0.831 \nF-statistic: 45.24 on 1 and 8 DF,  p-value: 0.0001487\n\n\n\n모형의 유의성 검정 자체(f검정)\n개별 회귀계수에 대한 유의성검정(t검정)\nbeta1은 유의하지 않다\nbeta0는 유의하다\nf통계량은 45.24(msr/mse) p값 충분히 작아서 모형은 유의하다.\ny의 총 변동 중에 85%정도를 설명하고 있다.\nroot mse(RMSE) = 2.631\n\n\n6.726**2\n\n45.239076\n\n\n단순선형에서만 해당\n0.000149도 같음\n\nnames(model1)\n\n\n'coefficients''residuals''effects''rank''fitted.values''assign''qr''df.residual''xlevels''call''terms''model'\n\n\n\nmodel1$residuals # 보고 싶은 변수 입력해봐~\n\n10.83478260869565621.430.7913043478260874-3.65-1.660.9652173913043574.6173913043478281.182608695652179-3.3826086956521810-1.20869565217391\n\n\n\nmodel1$fitted.values  ##hat y\nmodel1$coefficients\n\n18.16521739130434218.6321.2086956521739418.6518.6629.0347826086957713.3826086956522823.8173913043478913.38260869565221021.2086956521739\n\n\n(Intercept)-2.2695652173913x2.60869565217391\n\n\n\nanova(model1)  ## 회귀모형의 유의성 검정\n\n\nA anova: 2 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nx\n1\n313.04348\n313.043478\n45.24034\n0.0001486582\n\n\nResiduals\n8\n55.35652\n6.919565\nNA\nNA\n\n\n\n\n\n\n설명변수의 개수가 x 자유도\n잔차의 자유도는 n-2\n\n\na &lt;- summary(model1)\nls(a)\n\n\n'adj.r.squared''aliased''call''coefficients''cov.unscaled''df''fstatistic''r.squared''residuals''sigma''terms'\n\n\n\nsummary(model1)$coef   ## 회귀계수의 유의성 검정\n\n\nA matrix: 2 × 4 of type dbl\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n-2.269565\n3.212348\n-0.7065129\n0.4999255886\n\n\nx\n2.608696\n0.387847\n6.7260939\n0.0001486582\n\n\n\n\n\n\nconfint(model1, level = 0.95)  ##회귀계수의 신뢰구간\n## beta +- t_alpha/2 (n-2) * se(beta)\nqt(0.025, 8)\nqt(0.975, 8)\n\n\nA matrix: 2 × 2 of type dbl\n\n\n\n2.5 %\n97.5 %\n\n\n\n\n(Intercept)\n-9.677252\n5.138122\n\n\nx\n1.714319\n3.503073\n\n\n\n\n\n-2.30600413520417\n\n\n2.30600413520417\n\n\n\nqt _ tquantile\n\n\n## y = beta1*x + epsilon\nmodel2 &lt;- lm(y ~ 0 + x, dt)\nsummary(model2)\n\n\nCall:\nlm(formula = y ~ 0 + x, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.0641 -1.5882  0.2638  1.4818  3.9359 \n\nCoefficients:\n  Estimate Std. Error t value Pr(&gt;|t|)    \nx   2.3440     0.0976   24.02  1.8e-09 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 2.556 on 9 degrees of freedom\nMultiple R-squared:  0.9846,    Adjusted R-squared:  0.9829 \nF-statistic: 576.8 on 1 and 9 DF,  p-value: 1.798e-09\n\n\n\nintercept 없는 모습\nr squre가 두 번째가 높고,\np값도 훨씬 유의하게 나옴\n\n\nanova(model1)\n\n\nA anova: 2 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nx\n1\n313.04348\n313.043478\n45.24034\n0.0001486582\n\n\nResiduals\n8\n55.35652\n6.919565\nNA\nNA\n\n\n\n\n\n\nanova(model2)\n\n\nA anova: 2 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nx\n1\n3769.1895\n3769.1895\n576.8138\n1.79763e-09\n\n\nResiduals\n9\n58.8105\n6.5345\nNA\nNA\n\n\n\n\n\n\n###########\nplot(y~x, data = dt,\n     xlab = \"광고료\",\n     ylab = \"총판매액\",\n     pch  = 20,\n     cex  = 2,\n     col  = \"darkorange\")\nabline(model1, col='steelblue', lwd=2)\nabline(model2, col='green', lwd=2)\n\n\n\n\nmodel들이 기울기가 살짝씩 다르다\n\nco &lt;- coef(model1)\n\n\nggplot(dt, aes(x, y)) +\n  geom_point(col='steelblue', lwd=1) +\n  geom_abline(intercept = co[1], slope = co[2], col='darkorange', lwd=1) +\n  xlab(\"광고료\")+ylab(\"총판매액\")+\n  theme_bw()+\n  theme(axis.title = element_text(size = 16))\n\n\n\n\n\n######## LSE 구하기\n# lm을 사용하지 않고 구할때\n\ndt1 &lt;- data.frame(\n  i = 1:nrow(dt),\n  x = dt$x,\n  y = dt$y,\n  x_barx = dt$x - mean(dt$x), # x - x평균\n  y_bary = dt$y - mean(dt$y))  # y - y평균\n\n\ndt1$x_barx2 &lt;- dt1$x_barx^2 # x 편차의 제곱\ndt1$y_bary2 &lt;- dt1$y_bary^2 # y편차의 제곱\ndt1$xy &lt;-dt1$x_barx * dt1$y_bary\n\n\ndt1\n\n\nA data.frame: 10 × 8\n\n\ni\nx\ny\nx_barx\ny_bary\nx_barx2\ny_bary2\nxy\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n4\n9\n-4\n-9.6\n16\n92.16\n38.4\n\n\n2\n8\n20\n0\n1.4\n0\n1.96\n0.0\n\n\n3\n9\n22\n1\n3.4\n1\n11.56\n3.4\n\n\n4\n8\n15\n0\n-3.6\n0\n12.96\n0.0\n\n\n5\n8\n17\n0\n-1.6\n0\n2.56\n0.0\n\n\n6\n12\n30\n4\n11.4\n16\n129.96\n45.6\n\n\n7\n6\n18\n-2\n-0.6\n4\n0.36\n1.2\n\n\n8\n10\n25\n2\n6.4\n4\n40.96\n12.8\n\n\n9\n6\n10\n-2\n-8.6\n4\n73.96\n17.2\n\n\n10\n9\n20\n1\n1.4\n1\n1.96\n1.4\n\n\n\n\n\n\nround(colSums(dt1),3)\n\ni55x80y186x_barx0y_bary0x_barx246y_bary2368.4xy120\n\n\n\n### hat beta1 = S_xy / S_xx\n##hat beta0 = bar y - hat beta_1 * bar x\nbeta1 &lt;- as.numeric(colSums(dt1)[8]/colSums(dt1)[6])\nbeta0 &lt;- mean(dt$y) - beta1 *  mean(dt$x)\n\n\ncat(\"hat beta0 = \", beta0)\ncat(\"hat beta1 = \", beta1)\n\nhat beta0 =  -2.269565hat beta1 =  2.608696\n\n\n\n\n평균반응, 개별 y 추정\n구분할 수 있어야 한다\n신뢰구간 달라진다.\n\n## E(Y|x0) 평균반응\n## y = E(Y|x0) + epsilon 개별 y 추정\n# x0 = 4.5\nnew_dt &lt;- data.frame(x = 4.5)\n\n\n# hat y0 = hat beta0 + hat beta1 * 4.5\n\npredict(model1, \n        newdata = new_dt,\n        interval = c(\"confidence\"), level = 0.95)\n\n\nA matrix: 1 × 3 of type dbl\n\n\n\nfit\nlwr\nupr\n\n\n\n\n1\n9.469565\n5.79826\n13.14087\n\n\n\n\n\nnew_data=new_df 정의 안 하면 fitted value가 나온다.\nconfidence는 평균반응\n\npredict(model1, newdata = new_dt, \n        interval = c(\"prediction\"), level = 0.95)\n\n\nA matrix: 1 × 3 of type dbl\n\n\n\nfit\nlwr\nupr\n\n\n\n\n1\n9.469565\n2.379125\n16.56001\n\n\n\n\n\nprediction은 개별 y 추정\n신뢰구간이 커진다. \\(\\to\\) 표준오차가 달라지기 때문\n\ndt_pred &lt;- data.frame(\n  x = 1:12,\n  predict(model1, \n          newdata=data.frame(x=1:12), \n          interval=\"confidence\", level = 0.95))\ndt_pred\n\n\nA data.frame: 12 × 4\n\n\n\nx\nfit\nlwr\nupr\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n1\n0.3391304\n-6.2087835\n6.887044\n\n\n2\n2\n2.9478261\n-2.7509762\n8.646628\n\n\n3\n3\n5.5565217\n0.6905854\n10.422458\n\n\n4\n4\n8.1652174\n4.1058891\n12.224546\n\n\n5\n5\n10.7739130\n7.4756140\n14.072212\n\n\n6\n6\n13.3826087\n10.7597808\n16.005437\n\n\n7\n7\n15.9913043\n13.8748223\n18.107786\n\n\n8\n8\n18.6000000\n16.6817753\n20.518225\n\n\n9\n9\n21.2086957\n19.0922136\n23.325178\n\n\n10\n10\n23.8173913\n21.1945634\n26.440219\n\n\n11\n11\n26.4260870\n23.1277880\n29.724386\n\n\n12\n12\n29.0347826\n24.9754543\n33.094111\n\n\n\n\n\n\ndt_pred2 &lt;- as.data.frame(predict(model1, \n                                  newdata=data.frame(x=1:12), \n                                  interval=\"prediction\", level = 0.95))\ndt_pred2\n\n\nA data.frame: 12 × 3\n\n\n\nfit\nlwr\nupr\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n0.3391304\n-8.5867330\n9.264994\n\n\n2\n2.9478261\n-5.3751666\n11.270819\n\n\n3\n5.5565217\n-2.2199297\n13.332973\n\n\n4\n8.1652174\n0.8663128\n15.464122\n\n\n5\n10.7739130\n3.8692308\n17.678595\n\n\n6\n13.3826087\n6.7738957\n19.991322\n\n\n7\n15.9913043\n9.5667143\n22.415894\n\n\n8\n18.6000000\n12.2379683\n24.962032\n\n\n9\n21.2086957\n14.7841056\n27.633286\n\n\n10\n23.8173913\n17.2086783\n30.426104\n\n\n11\n26.4260870\n19.5214047\n33.330769\n\n\n12\n29.0347826\n21.7358781\n36.333687\n\n\n\n\n\n\nnames(dt_pred2)[2:3] &lt;- c('plwr', 'pupr')\n\nplot 같이 그리게 데이터 합치기\n\ndt_pred3 &lt;- cbind.data.frame(dt_pred, dt_pred2[,2:3])\n\n\nbarx &lt;- mean(dt$x)\nbary &lt;- mean(dt$y)\n\n\nplot(y~x, data = dt,\n     xlab = \"광고료\",\n     ylab = \"총판매액\",\n     pch  = 20,\n     cex  = 2,\n     col  = \"grey\",\n     ylim = c(min(dt_pred3$plwr), max(dt_pred3$pupr)))\nabline(model1, lwd = 5, col = \"darkorange\")\nlines(dt_pred3$x, dt_pred3$lwr, col = \"dodgerblue\", lwd = 3, lty = 2)\nlines(dt_pred3$x, dt_pred3$upr, col = \"dodgerblue\", lwd = 3, lty = 2)\nlines(dt_pred3$x, dt_pred3$plwr, col = \"dodgerblue\", lwd = 3, lty = 3)\nlines(dt_pred3$x, dt_pred3$pupr, col = \"dodgerblue\", lwd = 3, lty = 3)\n\nabline(h=bary,v=barx, lty=2, lwd=0.2, col='dark grey')\n\n\n\n\n\nggplot(dt_pred3, aes(x, fit)) +\n  geom_line(col='steelblue', lwd=2) +\n  xlab(\"\")+ylab(\"\")+\n  scale_x_continuous(breaks = seq(1,10))+\n  geom_line(aes(x, lwr), lty=2, lwd=1.5, col='darkorange') +\n  geom_line(aes(x, upr), lty=2, lwd=1.5, col='darkorange') +\n  geom_line(aes(x, plwr), lty=2, lwd=1.5, col='dodgerblue') +\n  geom_line(aes(x, pupr), lty=2, lwd=1.5, col='dodgerblue') +\n  geom_vline(xintercept = barx, lty=2, lwd=0.2, col='dark grey')+\n  geom_hline(yintercept = bary, lty=2, lwd=0.2, col='dark grey')+\n  theme_bw()\n\n\n\n\n\nbb &lt;- summary(model1)$sigma * ( 1 + 1/10 +(dt$x - 8)^2/46)\ndt$ma95y &lt;- model1$fitted + 2.306*bb\ndt$mi95y &lt;- model1$fitted - 2.306*bb\n\n\nggplot(dt, aes(x=x, y=y)) +\n  geom_point() +\n  geom_smooth(method=lm , color=\"red\", fill=\"#69b3a2\", se=TRUE) +\n  geom_line(aes(x, mi95y), col = 'darkgrey', lty=2) +\n  geom_line(aes(x, ma95y), col = 'darkgrey', lty=2) +\n  theme_bw() +\n  theme(axis.title = element_blank())\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\n\n\n\n잔차분석\n\n### epsilon : 선형성, 등분산성, 정규성, 독립성\n\n\ndt\ndt$yhat &lt;- model1$fitted\n# fitted.values(model1) # y에 대한 추정값 구하기\ndt$resid &lt;- model1$residuals\n# resid(model1)\n\n\nA data.frame: 10 × 4\n\n\nx\ny\nma95y\nmi95y\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n4\n9\n16.94766\n-0.6172208\n\n\n8\n20\n25.27254\n11.9274568\n\n\n9\n22\n28.01311\n14.4042841\n\n\n8\n15\n25.27254\n11.9274568\n\n\n8\n17\n25.27254\n11.9274568\n\n\n12\n30\n37.81722\n20.2523444\n\n\n6\n18\n20.58263\n6.1825918\n\n\n10\n25\n31.01741\n16.6173744\n\n\n6\n10\n20.58263\n6.1825918\n\n\n9\n20\n28.01311\n14.4042841\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(resid ~ x, dt, pch=16, ylab = 'Residual')\nabline(h=0, lty=2, col='grey')\nplot(resid ~ yhat, dt, pch=16, ylab = 'Residual')\nabline(h=0, lty=2, col='grey')\npar(mfrow=c(1,1))\n\n\n\n\n단순선형에서는 두 plot의 차이가 없다.\n\n선형성 만족\n등분산성 나름 만족\n정규성 아웃라이어 있는 거 같은데..\n독립성?\n\n\n# 독립성검정 : DW test\nlibrary(lmtest)\n\nLoading required package: zoo\n\n\nAttaching package: ‘zoo’\n\n\nThe following objects are masked from ‘package:base’:\n\n    as.Date, as.Date.numeric\n\n\n\n\n\n## \ndwtest(model1, alternative = \"two.sided\")  #H0 : uncorrelated vs H1 : rho != 0\n# dwtest(model1, alternative = \"greater\")  #H0 : uncorrelated vs H1 : rho &gt; 0\n# dwtest(model1, alternative = \"less\")  #H0 : uncorrelated vs H1 : rho &lt; 0\n\n\n    Durbin-Watson test\n\ndata:  model1\nDW = 1.4679, p-value = 0.3916\nalternative hypothesis: true autocorrelation is not 0\n\n\np 값 커서 기각할 수 없다.\n첫 번째꺼 주로 보기\n\n## 정규분포 (QQ plot)\nqqnorm(dt$resid, pch=16)\nqqline(dt$resid, col = 2)\n\n\n\n\n분위수분위수 그림 - 정규분포의 실제 - 어떤 분포의 이론적 분위수와 내가 가진 sample의 분위수 비교\n주로 꼬리쪽을 많이 본다. - 이 데이터의 경우 꼬리부분이 차이가 커 보임\n\nggplot(dt, aes(sample = resid)) + \n  stat_qq() + stat_qq_line() +\n  theme_bw()\n\n\n\n\n\n## 정규분포 검정 \nshapiro.test(dt$resid)  ##shapiro-wilk test\n#H0 : normal distributed vs H1 : not\n\n\n    Shapiro-Wilk normality test\n\ndata:  dt$resid\nW = 0.92426, p-value = 0.3939\n\n\np값 작게 나오면 정규분포라고 하기 어렵다.\n\n정규성은 잔차를 넣어줬는데\nbptest는 model을 넣었다.\n\n\n## 등분산성 검정 \nbptest(model1) #Breusch–Pagan test\n# H0 : 등분산 vs H1 : 이분산 \n\n\n    studentized Breusch-Pagan test\n\ndata:  model1\nBP = 1.6727, df = 1, p-value = 0.1959\n\n\n\n\n책 예제\n\n# install.packages('UsingR')\nlibrary(UsingR)\n\nLoading required package: MASS\n\nLoading required package: HistData\n\nLoading required package: Hmisc\n\nLoading required package: lattice\n\nLoading required package: survival\n\nLoading required package: Formula\n\n\nAttaching package: ‘Hmisc’\n\n\nThe following objects are masked from ‘package:base’:\n\n    format.pval, units\n\n\n\nAttaching package: ‘UsingR’\n\n\nThe following object is masked from ‘package:survival’:\n\n    cancer\n\n\n\n\n\ndata(father.son)\n\n\nnames(father.son)\n\n\n'fheight''sheight'\n\n\n\nlm.fit&lt;-lm(sheight~fheight, data=father.son)\n\n\nsummary(lm.fit)\n\n\nCall:\nlm(formula = sheight ~ fheight, data = father.son)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.8772 -1.5144 -0.0079  1.6285  8.9685 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 33.88660    1.83235   18.49   &lt;2e-16 ***\nfheight      0.51409    0.02705   19.01   &lt;2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 2.437 on 1076 degrees of freedom\nMultiple R-squared:  0.2513,    Adjusted R-squared:  0.2506 \nF-statistic: 361.2 on 1 and 1076 DF,  p-value: &lt; 2.2e-16\n\n\n아버지의 키가 아들의 키의 25%만 설명\n\nplot(sheight~fheight, \n     data=father.son, \n     pch=16, cex=0.5,\n     xlab=\"father’s height (inches)\", \n     ylab=\"son’s height (inches)\")\nabline(lm.fit)\n\n\n\n\n\n\namazon&lt;-read.csv(\"amazon.csv\")\nplot(High   ~Year  , amazon, pch=16)\n\nlm.fit&lt;-lm(High~Year, data=amazon)\nsummary(lm.fit)\n\nconfint(lm.fit)\n\npar(mfrow=c(1,2))\nscatter.smooth(x=1:length(amazon$Year), y=residuals(lm.fit), xlab=\"Year\")\nscatter.smooth(x=predict(lm.fit), y=residuals(lm.fit), xlab=expression(hat(y)))\n\nlibrary(lmtest)\ndwtest(lm.fit)\n\n\nCall:\nlm(formula = High ~ Year, data = amazon)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.3629 -0.5341  0.1479  0.4903  1.1412 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -330.21235   78.03319  -4.232 0.000725 ***\nYear           0.18088    0.03961   4.567 0.000371 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.8001 on 15 degrees of freedom\nMultiple R-squared:  0.5816,    Adjusted R-squared:  0.5537 \nF-statistic: 20.85 on 1 and 15 DF,  p-value: 0.0003708\n\n\n\nA matrix: 2 × 2 of type dbl\n\n\n\n2.5 %\n97.5 %\n\n\n\n\n(Intercept)\n-496.53615985\n-163.8885460\n\n\nYear\n0.09645429\n0.2653104\n\n\n\n\n\n\n\n\n\n    Durbin-Watson test\n\ndata:  lm.fit\nDW = 1.0487, p-value = 0.006864\nalternative hypothesis: true autocorrelation is greater than 0\n\n\n\n\n\n양의 상관관계가 있다. - 시간순 index - 최근 관측 데이터에 영향 많이 받는 편"
  },
  {
    "objectID": "posts/rl/2022-11-28-rl-CH13.html",
    "href": "posts/rl/2022-11-28-rl-CH13.html",
    "title": "고급회귀분석 실습 CH13",
    "section": "",
    "text": "chapter 13"
  },
  {
    "objectID": "posts/rl/2022-11-28-rl-CH13.html#example",
    "href": "posts/rl/2022-11-28-rl-CH13.html#example",
    "title": "고급회귀분석 실습 CH13",
    "section": "Example",
    "text": "Example\n\ndt &lt;- data.frame(\n  y = c(17,26,21,30,22,1,12,19,4,16,\n        28,15,11,38,31,21,20,13,30,14),\n  x1 = c(151,92,175,31,104,277,210,120,290,238,\n         164,272,295,68,85,224,166,305,124,246),\n  x2 = factor(rep(c(0,1), each=10))\n)\n\n할 수 있는 경우의 수 1.\nx2 = factor(rep(c('M','F'), each=10))\n\ncharacter로 넣어도 factor로 인식한다.\n조심할 점 알파벳 순으로 숫자가 부여된다.\n따라서 F는 0, M은 1로 부여되었다.\n\n참고: 강의록은 F는 1, M은 0으로 부여되어 결과가 다름\n해석의 결과가 다르진 않지만 어떻게 해석하느냐가 달라짐\n\n\n\n\n\nx2 = factor(rep(c(0,1), each=10))\n\nM은 0, F는 1-&gt; 강의록과 같음\n\n\nhead(dt)\n\n\nA data.frame: 6 × 3\n\n\n\ny\nx1\nx2\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;fct&gt;\n\n\n\n\n1\n17\n151\n0\n\n\n2\n26\n92\n0\n\n\n3\n21\n175\n0\n\n\n4\n30\n31\n0\n\n\n5\n22\n104\n0\n\n\n6\n1\n277\n0\n\n\n\n\n\n\ncontrasts(factor(dt$x2))\n\n\nA matrix: 2 × 1 of type dbl\n\n\n\n1\n\n\n\n\n0\n0\n\n\n1\n1\n\n\n\n\n\n잘 부여되었나 확인 필요 - chracter일때는 이 함수를 사용해도 의미가 없어서 factor로 바꿔서 해줘야 한다.\n\nm &lt;- lm(y~x1+x2, dt)\n\n\nsummary(m)\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0165 -1.7450 -0.6055  1.8803  6.1835 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 33.834912   1.758659  19.239 5.64e-13 ***\nx1          -0.100918   0.008621 -11.707 1.47e-09 ***\nx21          7.933953   1.414702   5.608 3.13e-05 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 3.123 on 17 degrees of freedom\nMultiple R-squared:  0.8991,    Adjusted R-squared:  0.8872 \nF-statistic: 75.72 on 2 and 17 DF,  p-value: 3.42e-09\n\n\n1.\nx2 = factor(rep(c('M','F'), each=10))\n로 입력한 경우\n\\(y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\\)\n\\(x_2 = 0\\), F\n\\(x_2 = 1\\), M\n\\(x_2\\)는 0 아니면 1 인 지수함수\n\\(E(y|M) : \\beta_0 + \\beta_1x_1 + \\beta_2 = (\\beta_0 + \\beta_2) + \\beta_1x_1\\)\n\\(E(y|F) : \\beta_0 + \\beta_1x_1\\)\n2.\nx2 = factor(rep(c(0,1), each=10))\n로 입력한 경우\n\\(y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\\)\n\\(x_2 = 0\\), M\n\\(x_2 = 1\\), F\n\\(E(y|M) : \\beta_0 + \\beta_1x_1\\)\n\\(E(y|F) : \\beta_0 + \\beta_1x_1+ \\beta_2 = (\\beta_0 + \\beta_2) + \\beta_1x_1\\)\n\nggplot(dt, aes(x1, y, col=x2)) + \n  geom_point() + \n  theme_bw() +\n  guides(col=guide_legend(title=\"성별\")) +\n  scale_color_manual(labels = c(\"남자\", \"여자\"), \n                     values = c(\"darkorange\", \"steelblue\"))\n\n\n\n\n\nm &lt;- lm(y~x1+x2, dt)\n\n\nsummary(m)\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0165 -1.7450 -0.6055  1.8803  6.1835 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 33.834912   1.758659  19.239 5.64e-13 ***\nx1          -0.100918   0.008621 -11.707 1.47e-09 ***\nx21          7.933953   1.414702   5.608 3.13e-05 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 3.123 on 17 degrees of freedom\nMultiple R-squared:  0.8991,    Adjusted R-squared:  0.8872 \nF-statistic: 75.72 on 2 and 17 DF,  p-value: 3.42e-09\n\n\n\\(\\beta_2\\)가 유의함을 확인함(3.13e-05) - 남성과 여성이 차이가 있다.\n\nggplot(dt, aes(x1, y, col=x2)) + \n  geom_point() + \n  theme_bw() + \n  geom_abline(slope = coef(m)[2], intercept = coef(m)[1], col= 'darkorange')+\n  geom_abline(slope = coef(m)[2], intercept = coef(m)[1]+coef(m)[3], col= 'steelblue')+\n  guides(col=guide_legend(title=\"성별\")) +\n  scale_color_manual(labels = c(\"남자\", \"여자\"), values = c(\"darkorange\", \"steelblue\"))\n\n\n\n\n기울기 차이 고려 안해서 기울기는 같을 것\n\n교호작용\n\nm1 &lt;- lm(y~x1*x2, dt)\n\n곱하기로 교호작용 표현\n\nsummary(m1)\n\n\nCall:\nlm(formula = y ~ x1 * x2, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0463 -1.7591 -0.6232  1.9311  6.1102 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 33.656104   2.365392  14.229 1.68e-10 ***\nx1          -0.099858   0.012650  -7.894 6.59e-07 ***\nx21          8.313516   3.541379   2.348   0.0321 *  \nx1:x21      -0.002089   0.017766  -0.118   0.9078    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 3.218 on 16 degrees of freedom\nMultiple R-squared:  0.8992,    Adjusted R-squared:  0.8803 \nF-statistic: 47.56 on 3 and 16 DF,  p-value: 3.405e-08\n\n\n\\(y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_1x_2\\) - 성별, 성적, 성별*성적\n\\(M : x_2=0 \\to E(y|M) = \\beta_0+\\beta_1x_1\\)\n\\(F : x_2=1 \\to E(y|F) = \\beta_0 + \\beta_1x_1 + \\beta_2 + \\beta_3x_1 = (\\beta_0+\\beta_2) + (\\beta_1+\\beta_3)x_1\\)\n\n식으로 봤을 때 절편, 기울기 모두 차이가 난다.\n절편 차이는 유의하다.\n기울기 차이는 거의 없다.\n교호작용은 없는 것으로 확인.\n\n\nggplot(dt, aes(x1, y, col=x2)) + \n  geom_point() + \n  theme_bw() + \n  geom_abline(slope = coef(m1)[2], intercept = coef(m1)[1], col= 'darkorange')+\n  geom_abline(slope = coef(m1)[2]+coef(m1)[4], intercept = coef(m1)[1]+coef(m1)[3], col= 'steelblue')+\n  guides(col=guide_legend(title=\"성별\")) +\n  scale_color_manual(labels = c(\"남자\", \"여자\"), values = c(\"darkorange\", \"steelblue\"))\n\n\n\n\n\n\n책 예제\n\nlibrary(ISLR)\n\n\nhead(Carseats)\n\n\nA data.frame: 6 × 11\n\n\n\nSales\nCompPrice\nIncome\nAdvertising\nPopulation\nPrice\nShelveLoc\nAge\nEducation\nUrban\nUS\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;fct&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;fct&gt;\n&lt;fct&gt;\n\n\n\n\n1\n9.50\n138\n73\n11\n276\n120\nBad\n42\n17\nYes\nYes\n\n\n2\n11.22\n111\n48\n16\n260\n83\nGood\n65\n10\nYes\nYes\n\n\n3\n10.06\n113\n35\n10\n269\n80\nMedium\n59\n12\nYes\nYes\n\n\n4\n7.40\n117\n100\n4\n466\n97\nMedium\n55\n14\nYes\nYes\n\n\n5\n4.15\n141\n64\n3\n340\n128\nBad\n38\n13\nYes\nNo\n\n\n6\n10.81\n124\n113\n13\n501\n72\nBad\n78\n16\nNo\nYes\n\n\n\n\n\n\ndim(Carseats)\n\n\n40011\n\n\n• Sales : 판매량 (단위: 1,000)\n• Price : 각 지점에서의 카시트 가격\n• ShelveLoc : 진열대의 등급 (Bad, Medium, Good)\n• Urban :도시 여부 (Yes, No)\n• US: 미국 여부 (Yes, No)\n\\(\\to\\) 세 개의 범주형 자료, 가변수 4개(3-2,2-1,2-1)\n\nfit &lt;- lm(fit&lt;-lm(Sales~Price+ShelveLoc+US, \n                  data=Carseats))\n\n\nsummary(fit)\n\n\nCall:\nlm(formula = fit &lt;- lm(Sales ~ Price + ShelveLoc + US, data = Carseats))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.1720 -1.2587 -0.0056  1.2815  4.7462 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     11.476347   0.498083  23.041  &lt; 2e-16 ***\nPrice           -0.057825   0.003938 -14.683  &lt; 2e-16 ***\nShelveLocGood    4.827167   0.277294  17.408  &lt; 2e-16 ***\nShelveLocMedium  1.893360   0.227486   8.323 1.42e-15 ***\nUSYes            1.013071   0.195034   5.194 3.30e-07 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 1.857 on 395 degrees of freedom\nMultiple R-squared:  0.5718,    Adjusted R-squared:  0.5675 \nF-statistic: 131.9 on 4 and 395 DF,  p-value: &lt; 2.2e-16\n\n\n\ncontrasts(Carseats$ShelveLoc)\n\n\nA matrix: 3 × 2 of type dbl\n\n\n\nGood\nMedium\n\n\n\n\nBad\n0\n0\n\n\nGood\n1\n0\n\n\nMedium\n0\n1\n\n\n\n\n\n알파벳 순으로 부여된 것 확인\n\\(y= \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_3 + \\beta_4x_4 + \\beta_5x_5\\)\n\nlibrary(car)\n\n\\(H_0 : \\beta_2 = \\beta_3 = 0\\)\n\\(\\beta_2 = 0, \\beta_3 = 0\\)\n\nC&lt;-rbind(c(0,0,1,0,0,0),\n         c(0,0,0,1,0,0))\n\n\nlinearHypothesis(fit, C)\n\nERROR: Error in L %*% b: non-conformable arguments\n\n\n유의미한 결과 확인\n\n\n구간별 회귀분석\n\ndt &lt;- data.frame(\n  y = c(377,249,355,475,139,452,440,257),\n  x1 = c(480,720,570,300,800,400,340,650)\n)\n\n\ndt$x2 = sapply(dt$x1, function(x) max(0, x-500))\n\n\nm &lt;- lm(y ~ x1+x2, dt)\n\n\nsummary(m)\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = dt)\n\nResiduals:\n      1       2       3       4       5       6       7       8 \n-22.765  29.765  18.068   4.068 -17.463  20.605 -15.117 -17.160 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 589.5447    60.4213   9.757 0.000192 ***\nx1           -0.3954     0.1492  -2.650 0.045432 *  \nx2           -0.3893     0.2310  -1.685 0.152774    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 24.49 on 5 degrees of freedom\nMultiple R-squared:  0.9693,    Adjusted R-squared:  0.9571 \nF-statistic: 79.06 on 2 and 5 DF,  p-value: 0.0001645\n\n\n\ndt2 &lt;- rbind(dt[,2:3], c(500,0))\n\n\ndt2$y &lt;- predict(m, newdata = dt2)\n\nthis is the predicted line of multiple linear regression\n\nggplot(data = dt, aes(x = x1, y = y)) + \n  geom_point(color='steelblue') +\n  geom_line(color='darkorange',data = dt2, aes(x=x1, y=y))+\n  geom_vline(xintercept = 500, lty=2, col='red')+\n  theme_bw()"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html",
    "href": "posts/rl/2023-02-22-rl-mid_term.html",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "",
    "text": "중간고사"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-1",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-1",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(1)",
    "text": "(1)\n\\(\\beta\\)에 대한 최소제곱추정량(\\(LSE\\)) \\(\\hat{\\beta}\\)을 구하시오\nanswer\n\\(\\hat{\\beta} = argmin_{\\beta \\in R} S = \\sum^n_{i=1} (y_i - \\beta x_i)^2 \\to \\frac{\\partial S}{\\partial \\beta}|_{\\beta = \\hat{\\beta}} = 0\\)\n\\(\\frac{\\partial S}{\\partial \\beta} = \\sum^n_{i=1} (-2x_i)(y_i - \\beta x_i) \\to \\sum^n_{i=1} x_i(y_i - \\hat{\\beta}x_i) = 0 \\to \\hat{\\beta} = \\frac{\\sum^n_{i=1} x_iy_i}{\\sum^n_{i=1} x^2_i}\\)"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-2",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-2",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(2)",
    "text": "(2)\n\\(E(\\hat{\\beta})\\)을 구하시오\nanswer\n\\(\\hat{\\beta} = \\frac{\\sum^n_{i=1} x_i y_i}{\\sum^n_{i=1} x^2_i} = \\sum^n_{i=1} \\frac{x_i}{\\sum^n_{j=1} s^2_j} y_i\\)\n\\(\\to E(\\hat{\\beta})= \\sum^n_{i=1} \\frac{x_i}{\\sum^n_{i=1} x^2_j} E(y_i) = \\sum^n_{i=1}\\frac{x_i}{\\sum^n_{j=1} x^2_j} \\beta x_i = \\beta\\frac{\\sum^n_{i=1} x^2_{i=1} x^2_i}{\\sum^n_{i=1} x^2_i} = \\beta\\)"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-3",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-3",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(3)",
    "text": "(3)\n\\(Var(\\hat{\\beta})\\)을 구하시오\nanswer\n\\(Var(\\hat{\\beta}) = \\sum^n_{i=1} \\frac{x^2_i}{(\\sum^n_{j=1} x^2_j)^2} Var(y_i) = \\sum^n_{i=1} \\frac{x^2_i}{(\\sum^n_{j=1} x^2_j)^2} \\sigma^2 = \\sigma^2 \\frac{\\sum^n_{i=1} x^2_i}{(\\sum^n_{i=1} x^2_i)^2} = \\frac{\\sigma^2}{\\sum^n_{i=1} x^2_i}\\)"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-4",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-4",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(4)",
    "text": "(4)\n\\(\\hat{\\beta}\\)의 표준오차를 구하시오.\nanswer\n\\(s.e.(\\hat{\\beta}) = \\sqrt{Var(\\hat{\\beta})} = \\frac{\\sigma}{\\sqrt{\\sum^n_{i=1}x^2_i}}\\)"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-6",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-6",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(1)",
    "text": "(1)\n최소제곱법에 의한 회귀직선을 적합시키고, 결과를 해석하시오.\nanswer\n\\(\\hat{\\beta} = \\frac{\\sum^n_{i=1} x_i y_i}{\\sum^n_{i=1} x^2_i} = \\frac{18207}{9103} = 2\\)\n\\(y = 2x\\)\n사내평가점수가 1점 올라갈 때마다 영업실적이 2백만원 증가한다."
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-7",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-7",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(2)",
    "text": "(2)\n분산분석표를 작성하고, 유의수준 \\(\\alpha=0.05\\)하에서, 회귀직선에 대한 유의성 검정을 수행하시오.\nanswer\n\\(SST = \\sum^n_{i=1} y^2_i = 36961\\)\n\\(SSR = \\sum^n_{i=1} \\hat{y}^2_i = (\\beta x)^2= \\frac{(\\sum^n_{i=1} x_i y_i)^2}{\\sum^n_{i=1} x^2_{i}} = \\frac{(18207)^2}{9103} = 36416\\)\n분산분석표\n\n\n\n요인\n제곱합(SS)\n자유도(df)\n평균제곱(MS)\n\\(F_0\\)\n\n\n\n\n회귀\n36416\n1\n36416\n669.01\n\n\n잔차\n545\n10\n54.5\n\n\n\n계\n36961\n11\n\n\n\n\n\n- 가설 : \\(H_0 : \\beta = 0 \\text{ vs. } H_1 : \\beta = 0\\)\n- 기각역 : \\(F_0 &gt; F_{0.01}(1,10) = 4.96\\)\n- 결론: \\(F_0\\) 값이 기각역에 속하므로 귀무가설을 기각할 수 있다. 즉 유의수준 \\(5\\)%에서 회귀직선이 유의하다고 할 수 있다.\n\nround(qf(0.95,1,10),2)\n\n4.96"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-8",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-8",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(3)",
    "text": "(3)\n결정계수를 구하시오\nanswer\n\\(R^2 = \\frac{SSR}{SST} = \\frac{36416}{36961} = 0.9865\\)"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-9",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-9",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(4)",
    "text": "(4)\n\\(\\beta\\)에 대한 \\(95\\)% 신뢰구간을 구하여라\nanswer\n\\(\\hat{s.e.}(\\hat{\\beta}) = \\sqrt{\\frac{MSE}{\\sum^n_{i=1} x^2_i}} = \\sqrt{\\frac{54.5}{9103}} = 0.077\\)\n\\(95\\)% 신뢰구간: \\(\\hat{\\beta} \\pm t_{0.05/2}(10) \\times \\hat{s.e.}(\\hat{\\beta}) = 2 \\pm 2.23 \\times 0.077 = (1.818, 2.172)\\)\n\nround(qt(0.975,10),2)\n\n2.23"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-11",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-11",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(1)",
    "text": "(1)\n단순선형 회귀모형을 쓰고, 오차항에 대한 가정을 적으시오\nanswer\n\\(y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i, \\epsilon_i \\sim_{i.i.d.} N(0, \\sigma^2) , i=1,2,\\dots, 10\\)"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-12",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-12",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(2)",
    "text": "(2)\n투입된 비료의 양과 감자의 수확량에 대한 회귀선을 구하시오\nanswer\n\\(S_{(xx)} = \\sum^n_{i=1} x^2_i - n(\\bar{x})^2 = 110 - 10 \\times 3^2 = 20\\)\n\\(S_{(yy)} = \\sum^n_{i=1} y^2_i - n(\\bar{y})^2 = 8712-10 \\times 29^2 = 302\\)\n\\(S_{(xy)} = \\sum^n_{i=1} x_i y_i - n(\\bar{x})(\\bar{y}) = 940-10 \\times 3 \\times 29 = 70\\)\n\\(\\to \\hat{\\beta_1} = \\frac{S_{(xy)}}{S_{(xy)}} = \\frac{70}{20} = 3.5, \\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x} = 29-3.5 \\times 3 = 18.5\\)"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-13",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-13",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(3)",
    "text": "(3)\n분산분석표를 작성하고, 유의수준 α = 0.05에서, 회귀직선에 대한 유의성 검정을 수행하시오.\nanswer\n\\(SSR = \\frac{S^2_{(xy)}}{S_{(xx)}} = \\frac{70^2}{20} = 245\\)\n\\(SSE = SST - SSR = 302 - 245 = 57\\)\n\n\n\n요인\n제곱합(SS).\n자유도(df)\n평균제곱(MS)\n\\(F_0\\)\n\n\n\n\n회귀\n245\n1\n245\n34.39\n\n\n잔차\n57\n8\n7.125\n\n\n\n계\n302\n\n\n\n\n\n\n- 가설 : \\(H_0 : \\beta_1 = 0 \\text{ vs. } H_1 : \\beta_1 = 0\\)\n- 기각역 : \\(F_0 &gt; F_{\\alpha}(1,8) = 5.32\\)\n- 결론: \\(F_0\\)값이 기각역에 속하므로 귀무가설을 기각할 수 있다. 즉 유의수준 \\(5\\)%에서 회귀직선이 유의하다고 할 수 있다.\n\nround(qf(0.95,1,8),2)\n\n5.32"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-14",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-14",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(4)",
    "text": "(4)\n오차항의 분산 \\(\\sigma^2\\)에 대한 추정치를 구하여라\nanswer\n\\(\\hat{\\sigma}^2 = MSE = 7.125\\)"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-15",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-15",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(5)",
    "text": "(5)\n표본상관계수를 구하시오.\nanswer\n\\(r = \\frac{S_{(xy)}}{\\sqrt{S_{(xx)}S_{(yy)}}} = \\frac{70}{\\sqrt{20 \\times 302}} = 0.90\\)"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-16",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-16",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(6)",
    "text": "(6)\n결정계수를 구하고, 결정계수의 의미를 설명하시오\nanswer\n\\(R^2 = \\frac{SSR}{SST} = \\frac{245}{302} = 0.81\\)\n회귀모형이 반응변수의 총변동의 \\(81\\)%를 설명하고 있다."
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-17",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-17",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(7)",
    "text": "(7)\n다음의 가설검정을 유의수준 \\(\\alpha = 0.05\\)에서 수행하시오.\n\\[H_0 : \\beta_1 = 2 \\text{ vs. } H_1 : \\beta_1 &gt;2\\]\nanswer\n- 검정통계량 : \\(T = \\frac{\\hat{\\beta}_1 - \\beta^0_1}{\\hat{s.e.} (\\hat{\\beta}_1)} = \\frac{\\hat{\\beta}_1 - 2}{\\hat{s.e.}(\\hat{\\beta}_1)} \\sim_{H_0} t(8)\\)\n- \\(\\hat{s.e.}(\\hat{\\beta}_1) = \\sqrt{\\frac{MSE}{S_{(xx)}}} = \\sqrt{\\frac{7.125}{20}} = 0.597\\)\n- 검정통계량 관측값: \\(t_0 = \\frac{3.5-2}{0.597} = 2.513\\)\n- 기각역 : \\(t_0 &gt; t_{0.05}(8) = 1.86\\)\n- 결론 : \\(t_0\\)값이 기각역에 속하므로 귀무가설을 기각할 수 있다. 즉 유의수준 \\(5\\)%에서 \\(\\beta_1\\)이 \\(2\\)보다 크다고 할 수 있다.\n\nround(qt(0.95,8),2) # 단측검정\n\n1.86"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-18",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-18",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(8)",
    "text": "(8)\n\\(3.5\\)kg의 비료를 사용했을 때 평균 감자 수확량과 하나의 개별 \\(y\\)값의 \\(90\\)% 신뢰구간을 각각 구하시오\nanswer\n- \\(\\hat{\\mu}_0 = \\hat{y}_0 = 18.5 + 3.5 x = 18.5 + 3.5 \\times 3.5 = 30.75(kg)\\)\n- \\(\\hat{s.e.}(E(\\hat{y|x = 3.5})) = \\sqrt{(\\frac{1}{n} + \\frac{(x_0 - \\bar{x})^2}{S_{(xx)}})\\hat{\\sigma}^2} = \\sqrt{(\\frac{1}{10} + \\frac{(3.5-3)^2}{20}) \\times 7.125} = 0.895\\)\n- \\(\\hat{s.e.}(\\hat{y}_0) = \\sqrt{(1 + \\frac{1}{n} + \\frac{(x_0 - \\bar{x})^2}{S_{(xx)}})\\hat{\\sigma^2}} = \\sqrt{(1 + \\frac{1}{10} + \\frac{(3.5-3)^2}{20}) \\times 7.125} = 2.815\\)\n- 평균감자수확량의 \\(90\\)% 신뢰구간\n\\[\\hat{\\mu}_0 \\pm t_{0.1/2}(8)\\hat{s.e.}(E(\\hat{y|x = 3.5})) = 30.75 \\pm 1.86 \\times 0.895 = (29.085, 32.415)\\]\n- 개별 감자수확량의 \\(90\\)% 신뢰구간\n\\[\\hat{\\mu}_0 \\pm t_{0.1/2})(8) \\hat{s.e.}(\\hat{y}_0) = 30.75 \\pm 1.86 \\times 2.815 = (25.514, 35.986)\\]\n\nround(qt(0.95,8),2)\n\n1.86"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-20",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-20",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(1)",
    "text": "(1)\n적합결여검정을 수행하기 위한 가설을 적으시오.\nanswer\n\\(H_0 : E(y|x) = \\beta_0 + \\beta_1 x \\text{ vs. } H_1 : E(y|x) \\neq \\beta_0 + \\beta_1 x\\)"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-21",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-21",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(2)",
    "text": "(2)\n가설검정을 위한 검정통계량은 무엇인가? 귀무가설이 사실이라고 가정할 때 검정통계량의 분포는 무엇인가?(증명 필요없음)\nanswer\n\\(F = \\frac{SSLF/(k-2)}{SSPE/(n-k)} \\sim_{H_0}, F(k-2,n-k)\\)\n- \\(SSPE = \\sum^k_{i=1} \\sum^{n_i}_{j=1} (y_{ij} - \\bar{y}_{i} )^2\\)\n- \\(SSLF = \\sum^k_{i=1}n_i (\\hat{y_i} - \\bar{y}_i)^2 = SSE - SSPE\\)\n- \\(\\bar{y}_i = \\sum^{n_i}_{j=1} y_{ij}/n_i\\)"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-22",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-22",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(3)",
    "text": "(3)\n(1)에 대한 가설 검정을 수행하시오\nanswer\n- \\(SSPE = (1.5^2 + \\dots + (-1)^2) = 15\\)\n- \\(SSLF = SSE - SSPE = 57-15=42\\)\n- 검정통계량의 관측값 : \\(F_0 = \\frac{42/3}{15/5} = \\frac{14}{3} = 4.67\\)\n\n$ k-2 = 5-2 = 3, n-k = 10-5 = 5$\n\n- 기각역 : \\(F_0 &gt; F_{0.05}(3,5) = 5.41\\)\n- 결론: 검정통계량의 관측값이 기각역에 속하지 않기 떄문에 귀무가설을 기각할 수 없다. 즉, 유의수준 \\(5\\)%에서 회귀모형은 적절하지 않다고 할 수 있다.\n\nround(qf(0.95,3,5),2)\n\n5.41"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-24",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-24",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(1)",
    "text": "(1)\n가중회귀최소추정량(\\(WLSE\\))을 구하기 위한 가중오차제곱합(\\(Q\\))를 정의하여라.\nanswer\n\\(Q = \\sum^n_{i=1} w_i \\{ y_i - (\\beta_0 + \\beta_1 x_i) \\}^2\\)\nQuadratic Form"
  },
  {
    "objectID": "posts/rl/2023-02-22-rl-mid_term.html#section-25",
    "href": "posts/rl/2023-02-22-rl-mid_term.html#section-25",
    "title": "Advanced Regression Analysis Mid Term",
    "section": "(2)",
    "text": "(2)\n가중오차제곱합을 가장 작게 하는 WLSE를 구하여라.\nanswer\n가중최소제곱추정량(WLSE) : \\((\\hat{\\beta}_0,\\hat{\\beta}_1) = argmin_{\\beta_0,\\beta_1 \\in R} \\sum^n_{i=1}w_i \\{ y_i - (\\beta_0 + \\beta_1 x_i)\\}^2\\)\n\\(\\hat{\\beta}_1 = \\frac{\\sum w_i (x_i - \\bar{x}_w)(y_i - \\bar{y}_w)}{\\sum w_i(x_i - \\bar{x}_w)^2}\\)\n\\(\\hat{\\beta}_0 = \\bar{y}_w - \\hat{\\beta_1} \\bar{x}_w\\)\n단, \\(\\bar{x}_w = \\frac{\\sum w_i x_i}{\\sum w_i}, \\bar{y}_w = \\frac{\\sum w_i y_i}{\\sum w_i}\\)"
  },
  {
    "objectID": "posts/rl/2022-10-23-rl-HW2.html",
    "href": "posts/rl/2022-10-23-rl-HW2.html",
    "title": "Regression HW 2",
    "section": "",
    "text": "고급회귀분석 과제, CH03,04,05\n고급회귀분석 두번째 과제입니다.\n제출 기한 : 10월 23일\n(마지막 문제는 R을 이용해서 풀이해도 됨)\n제출 방법\n(pdf 아닌 문서는 미제출로 간주)\n주의사항\n예) R에서 lm으로 beta의 추정량을 구하면 안 됨. 수업 시간에 배운 식으로 풀이를 적어야 함.\n************ R을 이용해서 푸는 문제는, R 코드도 같이 업로드."
  },
  {
    "objectID": "posts/rl/2022-10-23-rl-HW2.html#section-4",
    "href": "posts/rl/2022-10-23-rl-HW2.html#section-4",
    "title": "Regression HW 2",
    "section": "(1)",
    "text": "(1)\n선형회귀모형 (\\(y = \\beta_0 + \\beta_1 x + \\epsilon\\))이 타당한가를 유의수준 \\(\\alpha = 0.05\\)를 사용하여 적합결여검정을 행하라.\nAnswer\n\\(H_0 : E(Y|X = x) = \\beta_0 + \\beta_1 x\\)\n\\(H_1 : E(Y|X=x) \\neq \\beta_0 + \\beta_1 x\\)\n\ndf_4 = data.frame(x = c(0,0,3,3,6,6,9,9,12,12),\n                  y = c(8.5,8.4,7.9,8.1,7.8,7.6,7.3,7.0,6.8,6.7))\ndf_4\n\n\nA data.frame: 10 × 2\n\n\nx\ny\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n0\n8.5\n\n\n0\n8.4\n\n\n3\n7.9\n\n\n3\n8.1\n\n\n6\n7.8\n\n\n6\n7.6\n\n\n9\n7.3\n\n\n9\n7.0\n\n\n12\n6.8\n\n\n12\n6.7\n\n\n\n\n\n산점도\n\nplot(df_4$x,df_4$y,xlab='x(경과시간)',ylab='y(신선도)')\n\n\n\n\n우하향하는 모습이다.\n\ndf_4$x_barx = df_4$x - mean(df_4$x)\ndf_4$y_bary = df_4$y - mean(df_4$y) \n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주기 위해 \\(x_i - \\bar{x}, y_i - \\bar{y}\\)를 구했다.\n\n\ndf_4$x_barx2 &lt;- df_4$x_barx^2\ndf_4$y_bary2 &lt;- df_4$y_bary^2\ndf_4$xy &lt;-df_4$x_barx * df_4$y_bary\n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주었다.\n\n\ndf_4\n\n\nA data.frame: 10 × 7\n\n\nx\ny\nx_barx\ny_bary\nx_barx2\ny_bary2\nxy\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n0\n8.5\n-6\n0.89\n36\n0.7921\n-5.34\n\n\n0\n8.4\n-6\n0.79\n36\n0.6241\n-4.74\n\n\n3\n7.9\n-3\n0.29\n9\n0.0841\n-0.87\n\n\n3\n8.1\n-3\n0.49\n9\n0.2401\n-1.47\n\n\n6\n7.8\n0\n0.19\n0\n0.0361\n0.00\n\n\n6\n7.6\n0\n-0.01\n0\n0.0001\n0.00\n\n\n9\n7.3\n3\n-0.31\n9\n0.0961\n-0.93\n\n\n9\n7.0\n3\n-0.61\n9\n0.3721\n-1.83\n\n\n12\n6.8\n6\n-0.81\n36\n0.6561\n-4.86\n\n\n12\n6.7\n6\n-0.91\n36\n0.8281\n-5.46\n\n\n\n\n\n\nround(colSums(df_4),3)\n\nx60y76.1x_barx0y_bary0x_barx2180y_bary23.729xy-25.5\n\n\n\\(\\hat{\\beta_1} = \\frac{S_{xy}}{S_{xx}}\\)\n\\(\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x}\\)\n\nbeta1_4 &lt;- as.numeric(colSums(df_4)[7]/colSums(df_4)[5])\nbeta0_4 &lt;- mean(df_4$y) - beta1_4 *  mean(df_4$x)\n\n\ncat(\"hat beta0 = \", beta0_4)\ncat(\"\\nhat beta1 = \", beta1_4)\n\nhat beta0 =  8.46\nhat beta1 =  -0.1416667\n\n\n\\(\\hat{y} = 8.46 - 0.1417x\\)\n\nSST_4 = sum((df_4$y - mean(df_4$y))^2)\n\n\nSSR_4 = sum( ( ( beta0_4 + beta1_4 *df_4$x)-mean(df_4$y) )^2 )\nMSR_4 = SSR_4/1\n\n\nSSE_4 = sum( ( df_4$y-( beta0_4 + beta1_4 *df_4$x))^2 )\nMSE_4 = SSE_4/8\n\n\ncat(\"SST = \", SST_4,\", df = 9\")\ncat(\"\\nSSR = \", SSR_4,\", df = 1\")\ncat(\"\\nSSE = \", SSE_4, \", df = 8\")\n\nSST =  3.729 , df = 9\nSSR =  3.6125 , df = 1\nSSE =  0.1165 , df = 8\n\n\n\nF_4 = MSR_4 / MSE_4\nF_4\n\n248.068669527898\n\n\n\nqf(0.95,1,8)\n\n5.31765507157871\n\n\n\\(H_0 : \\beta_1 = 0\\)\n\\(H_1 : \\beta_1 \\neq 0\\)\nF값이 유의수준 0.05에서 기준 F보다 크기 때문에 \\(H_0\\) 기각하고, \\(\\beta_1\\) 은 유의미하다.\n\ndf_4_ex &lt;- cbind(df_4[c(1,3,5,7,9),c(1,2)],df_4[c(2,4,6,8,10),c(2)])\n\n\ncolnames(df_4_ex) &lt;- c('x','y1','y2')\n\n\ndf_4_ex$ymean &lt;- (df_4_ex$y1+df_4_ex$y2)/2\ndf_4_ex$y1_ymean2 &lt;- (df_4_ex$y1 - df_4_ex$ymean)^2\ndf_4_ex$y2_ymean2 &lt;- (df_4_ex$y2 - df_4_ex$ymean)^2\ndf_4_ex$yhat &lt;- 8.46 - 0.146667 * df_4_ex$x\ndf_4_ex\n\n\nA data.frame: 5 × 7\n\n\n\nx\ny1\ny2\nymean\ny1_ymean2\ny2_ymean2\nyhat\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n0\n8.5\n8.4\n8.45\n0.0025\n0.0025\n8.460000\n\n\n3\n3\n7.9\n8.1\n8.00\n0.0100\n0.0100\n8.019999\n\n\n5\n6\n7.8\n7.6\n7.70\n0.0100\n0.0100\n7.579998\n\n\n7\n9\n7.3\n7.0\n7.15\n0.0225\n0.0225\n7.139997\n\n\n9\n12\n6.8\n6.7\n6.75\n0.0025\n0.0025\n6.699996\n\n\n\n\n\n\\(\\hat{y} = 8.46 - 01417x\\)\n\nSSPE_4 = sum(df_4_ex$y1_ymean2) + sum(df_4_ex$y2_ymean2)\nSSPE_4\n\n0.0949999999999998\n\n\n\nSSLF_4 = SSE_4 - SSPE_4\nSSLF_4\n\n0.0214999999999996\n\n\n\nF_4_0 = SSLF_4/3 / (SSPE_4 / 5)\nF_4_0\n\n0.377192982456135\n\n\n\ncat(\"유의수준 5%에서 \",qf(0.95,3,5), \"보다 \",F_4_0,\"값이 작기 때문에 귀무가설을 기각하지 못한다. 따라서 선형회귀모형은 타당하다.\")\n\n유의수준 5%에서  5.409451 보다  0.377193 값이 작기 때문에 귀무가설을 기각하지 못한다. 따라서 선형회귀모형은 타당하다.\n\n\n\\(H_0 : E(Y|X = x) = \\beta_0 + \\beta_1 x\\) 기각못함"
  },
  {
    "objectID": "posts/rl/2022-10-23-rl-HW2.html#section-5",
    "href": "posts/rl/2022-10-23-rl-HW2.html#section-5",
    "title": "Regression HW 2",
    "section": "(2)",
    "text": "(2)\n선형회귀모형이 타당한 경우, 신선도의 점수가 시간당 얼마만큼이나 떨어지는가를 95% 신뢰계수를 가지고 구간추정하라(즉, \\(\\beta_1\\)의 구간추정).\nAnswer\n\\(\\hat{\\beta}_1\\)의 \\(100(1-\\alpha)\\)%의 신뢰구간\n\\(\\hat{\\beta}_1 \\pm t_{\\alpha/2}(n-2)\\frac{\\sqrt{MSE}}{\\sqrt{S_{xx}}}\\)\n\nqt(0.975,8)\n\n2.30600413520417\n\n\n\ncat(\"beta1 is \",beta1_4)\ncat(\"\\nMSE is \",MSE_4)\ncat(\"\\nSxx is \",sum(df_4$x_barx2))\n\nbeta1 is  -0.1416667\nMSE is  0.0145625\nSxx is  180\n\n\n\ncat(\"95% 신뢰계수는 (\",beta1_4-qt(0.975,8)*sqrt(MSE_4/sum(df_4$x_barx2)),\"-\",beta1_4+qt(0.975,8)*sqrt(MSE_4/sum(df_4$x_barx2)),\") 이다.\")\n\n95% 신뢰계수는 ( -0.1624082 - -0.1209251 ) 이다.\n\n\n신뢰계수가 0을 포함하지 않는다. 신뢰구간에서 \\(\\beta_1\\)이 유의미함을 알 수 있다.\n\n\n두 타이어회사 A, B에서 생산되는 타이어를 비교하기 위하여 고속도로에서 트럭이 달리는 상황을 모의실험(simulated experiment)하여 다음의 데이터를 얻었다. \\(x\\)는 트럭이 달리는 속도이고 \\(y\\)는 타이어가 마모되기까지의 총 주행거리이다.\n\n\n\n\n\\(x_{1j}\\)\n10\n20\n30\n40\n50\n60\n70\n\n\n\n\n\\(y_{1j}(A)\\)\n9.8\n12.5\n14.9\n16.5\n22.4\n24.1\n25.8\n\n\n\\(y_{2j}(B)\\)\n15.0\n14.5\n16.5\n19.1\n22.3\n20.8\n22.4\n\n\n\n\n산점도를 그리시오.\n\nAnswer\n\ndf_5 = data.frame(x = c(10,20,30,40,50,60,70),\n                  yA = c(9.8,12.5,14.9,16.5,22.4,24.1,25.8),\n                  yB = c(15.0,14.5,16.5,19.1,22.3,20.8,22.4))\ndf_5\n\n\nA data.frame: 7 × 3\n\n\nx\nyA\nyB\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n10\n9.8\n15.0\n\n\n20\n12.5\n14.5\n\n\n30\n14.9\n16.5\n\n\n40\n16.5\n19.1\n\n\n50\n22.4\n22.3\n\n\n60\n24.1\n20.8\n\n\n70\n25.8\n22.4\n\n\n\n\n\n\nplot(df_5$yA~df_5$x,\n     xlab = \"x\",\n     ylab = \"yA(orange),yB(blue)\",\n     pch  = 16,\n     cex  = 1,\n     col  = \"darkorange\")\npar(new=TRUE)\nplot(df_5$yB~df_5$x,\n     xlab='',\n     ylab='',\n     pch  = 16,\n     cex  = 1,\n     col  = \"blue\")\n\n\n\n\n\n각 회사별로 속도와 총주행거리 간의 회귀모형을 구한다면, 두 개의 직선이 동일하다고 볼수 있는가? 유의수준 \\(\\alpha = 0.05\\)로 가설검정하시오.\n\nAnswer\n\\(H_0: \\beta_{01} = \\beta_{02} \\text{ and } \\beta_{11} = \\beta_{12}\\)\n\\(H_1: \\beta_{01} \\ne \\beta_{02} \\text{ or } \\beta_{11} \\ne \\beta_{12}\\)\n\ndf_5_A &lt;- df_5\n\n\ndf_5_A$x_barx = df_5_A$x - mean(df_5_A$x)\ndf_5_A$yA_baryA = df_5_A$yA - mean(df_5_A$yA) \n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주기 위해 \\(x_i - \\bar{x}, y_i - \\bar{y}\\)를 구했다.\n\n\ndf_5_A$x_barx2 &lt;- df_5_A$x_barx^2\ndf_5_A$yA_baryA2 &lt;- df_5_A$yA_baryA^2\ndf_5_A$xyA &lt;-df_5_A$x_barx * df_5_A$yA_baryA\n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주었다.\n\n\ndf_5_A\n\n\nA data.frame: 7 × 8\n\n\nx\nyA\nyB\nx_barx\nyA_baryA\nx_barx2\nyA_baryA2\nxyA\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n10\n9.8\n15.0\n-30\n-8.2\n900\n67.24\n246\n\n\n20\n12.5\n14.5\n-20\n-5.5\n400\n30.25\n110\n\n\n30\n14.9\n16.5\n-10\n-3.1\n100\n9.61\n31\n\n\n40\n16.5\n19.1\n0\n-1.5\n0\n2.25\n0\n\n\n50\n22.4\n22.3\n10\n4.4\n100\n19.36\n44\n\n\n60\n24.1\n20.8\n20\n6.1\n400\n37.21\n122\n\n\n70\n25.8\n22.4\n30\n7.8\n900\n60.84\n234\n\n\n\n\n\n\nround(colSums(df_5_A),3)\n\nx280yA126yB130.6x_barx0yA_baryA0x_barx22800yA_baryA2226.76xyA787\n\n\n\\(\\hat{\\beta_1} = \\frac{S_{xy}}{S_{xx}}\\)\n\\(\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x}\\)\n\nbeta1_xyA &lt;- as.numeric(colSums(df_5_A)[8]/colSums(df_5_A)[6])\nbeta0_xyA &lt;- mean(df_5_A$yA) - beta1_xyA *  mean(df_5_A$x)\n\n\ncat(\"xyA hat beta0 = \", beta0_xyA)\ncat(\"\\nxyA hat beta1 = \", beta1_xyA)\n\nxyA hat beta0 =  6.757143\nxyA hat beta1 =  0.2810714\n\n\n\\(yA = 6.757143 + 0.2810714x\\)\n\nSST_A = sum((df_5_A$yA - mean(df_5_A$yA))^2)\n\n\nSSR_A = sum( ( ( 6.757143 + 0.2810714 *df_5_A$x)-mean(df_5_A$yA) )^2 )\n\n\nSSE_A = sum( ( df_5_A$yA-( 6.757143 + 0.2810714 *df_5_A$x))^2 )\n\n\ncat(\"yA SST = \", SST_A,\", df = 6\")\ncat(\"\\nyA SSR = \", SSR_A,\", df = 1\")\ncat(\"\\nyA SSE = \", SSE_A, \", df = 5\")\n\nyA SST =  226.76 , df = 6\nyA SSR =  221.2032 , df = 1\nyA SSE =  5.556786 , df = 5\n\n\n\ndf_5_B &lt;- df_5\n\n\ndf_5_B$x_barx = df_5_B$x - mean(df_5_B$x)\ndf_5_B$yB_baryB = df_5_B$yB - mean(df_5_B$yB) \n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주기 위해 \\(x_i - \\bar{x}, y_i - \\bar{y}\\)를 구했다.\n\n\ndf_5_B$x_barx2 &lt;- df_5_B$x_barx^2\ndf_5_B$yB_baryB2 &lt;- df_5_B$yB_baryB^2\ndf_5_B$xyB &lt;-df_5_B$x_barx * df_5_B$yB_baryB\n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주었다.\n\n\ndf_5_B\n\n\nA data.frame: 7 × 8\n\n\nx\nyA\nyB\nx_barx\nyB_baryB\nx_barx2\nyB_baryB2\nxyB\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n10\n9.8\n15.0\n-30\n-3.6571429\n900\n13.3746939\n109.71429\n\n\n20\n12.5\n14.5\n-20\n-4.1571429\n400\n17.2818367\n83.14286\n\n\n30\n14.9\n16.5\n-10\n-2.1571429\n100\n4.6532653\n21.57143\n\n\n40\n16.5\n19.1\n0\n0.4428571\n0\n0.1961224\n0.00000\n\n\n50\n22.4\n22.3\n10\n3.6428571\n100\n13.2704082\n36.42857\n\n\n60\n24.1\n20.8\n20\n2.1428571\n400\n4.5918367\n42.85714\n\n\n70\n25.8\n22.4\n30\n3.7428571\n900\n14.0089796\n112.28571\n\n\n\n\n\n\nround(colSums(df_5_B),3)\n\nx280yA126yB130.6x_barx0yB_baryB0x_barx22800yB_baryB267.377xyB406\n\n\n\\(\\hat{\\beta_1} = \\frac{S_{xy}}{S_{xx}}\\)\n\\(\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x}\\)\n\nbeta1_xyB &lt;- as.numeric(colSums(df_5_B)[8]/colSums(df_5_B)[6])\nbeta0_xyB &lt;- mean(df_5_B$yB) - beta1_xyB *  mean(df_5_B$x)\n\n\ncat(\"xyB hat beta0 = \", beta0_xyB)\ncat(\"\\nxyB hat beta1 = \", beta1_xyB)\n\nxyB hat beta0 =  12.85714\nxyB hat beta1 =  0.145\n\n\n\\(yB = 12.85714 + 0.145x\\)\n\nSST_B = sum((df_5_B$yB - mean(df_5_B$yB))^2)\n\n\nSSR_B = sum( ( ( 12.85714 + 0.145*df_5_B$x)-mean(df_5_B$yB) )^2 )\n\n\nSSE_B = sum( ( df_5_B$yB-( 12.85712 + 0.145 *df_5_B$x))^2 )\n\n\ncat(\"yB SST = \", SST_B,\", df = 6\")\ncat(\"\\nyB SSR = \", SSR_B,\", df = 1\")\ncat(\"\\nyB SSE = \", SSE_B, \", df = 5\")\n\nyB SST =  67.37714 , df = 6\nyB SSR =  58.87 , df = 1\nyB SSE =  8.507143 , df = 5\n\n\n\na &lt;- df_5[,c(1,2)]\n\n\ncolnames(a) &lt;- c('x','y')\n\n\nb &lt;- df_5[,c(1,3)]\n\n\ncolnames(b) &lt;- c('x','y')\n\n\ndf_5_AB &lt;- rbind(a,b)\ndf_5_AB\n\n\nA data.frame: 14 × 2\n\n\nx\ny\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n10\n9.8\n\n\n20\n12.5\n\n\n30\n14.9\n\n\n40\n16.5\n\n\n50\n22.4\n\n\n60\n24.1\n\n\n70\n25.8\n\n\n10\n15.0\n\n\n20\n14.5\n\n\n30\n16.5\n\n\n40\n19.1\n\n\n50\n22.3\n\n\n60\n20.8\n\n\n70\n22.4\n\n\n\n\n\n\ndf_5_AB$x_barx = df_5_AB$x - mean(df_5_AB$x)\ndf_5_AB$y_bary = df_5_AB$y - mean(df_5_AB$y) \n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주기 위해 \\(x_i - \\bar{x}, y_i - \\bar{y}\\)를 구했다.\n\n\ndf_5_AB$x_barx2 &lt;- df_5_AB$x_barx^2\ndf_5_AB$y_bary2 &lt;- df_5_AB$y_bary^2\ndf_5_AB$xy &lt;-df_5_AB$x_barx * df_5_AB$y_bary\n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주었다.\n\n\ndf_5_AB\n\n\nA data.frame: 14 × 7\n\n\nx\ny\nx_barx\ny_bary\nx_barx2\ny_bary2\nxy\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n10\n9.8\n-30\n-8.5285714\n900\n72.736531\n255.85714\n\n\n20\n12.5\n-20\n-5.8285714\n400\n33.972245\n116.57143\n\n\n30\n14.9\n-10\n-3.4285714\n100\n11.755102\n34.28571\n\n\n40\n16.5\n0\n-1.8285714\n0\n3.343673\n0.00000\n\n\n50\n22.4\n10\n4.0714286\n100\n16.576531\n40.71429\n\n\n60\n24.1\n20\n5.7714286\n400\n33.309388\n115.42857\n\n\n70\n25.8\n30\n7.4714286\n900\n55.822245\n224.14286\n\n\n10\n15.0\n-30\n-3.3285714\n900\n11.079388\n99.85714\n\n\n20\n14.5\n-20\n-3.8285714\n400\n14.657959\n76.57143\n\n\n30\n16.5\n-10\n-1.8285714\n100\n3.343673\n18.28571\n\n\n40\n19.1\n0\n0.7714286\n0\n0.595102\n0.00000\n\n\n50\n22.3\n10\n3.9714286\n100\n15.772245\n39.71429\n\n\n60\n20.8\n20\n2.4714286\n400\n6.107959\n49.42857\n\n\n70\n22.4\n30\n4.0714286\n900\n16.576531\n122.14286\n\n\n\n\n\n\nround(colSums(df_5_AB),3)\n\nx560y256.6x_barx0y_bary0x_barx25600y_bary2295.649xy1193\n\n\n\\(\\hat{\\beta_1} = \\frac{S_{xy}}{S_{xx}}\\)\n\\(\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x}\\)\n\nbeta1_xy &lt;- as.numeric(colSums(df_5_AB)[7]/colSums(df_5_AB)[5])\nbeta0_xy &lt;- mean(df_5_AB$y) - beta1_xy *  mean(df_5_AB$x)\n\n\ncat(\"xy hat beta0 = \", beta0_xy)\ncat(\"\\nxy hat beta1 = \", beta1_xy)\n\nxy hat beta0 =  9.807143\nxy hat beta1 =  0.2130357\n\n\n\\(\\text{y} = 9.807143 +0.2130357\\text{x}\\)\n\nSST_5 = sum((df_5_AB$y - mean(df_5_AB$y))^2)\n\n\nSSR_5 = sum( ( (9.807143 + 0.2130357*df_5_AB$x)-mean(df_5_AB$y) )^2 )\n\n\nSSE_5 = sum( ( df_5_AB$y-(9.807143  +0.2130357 *df_5_AB$x))^2 )\n\n\ncat(\"y = \",round(beta0_xy,4), \"+ \",round(beta1_xy,4) ,\"x\")\n\ny =  9.8071 +  0.213 x\n\n\n\ncat(\"SST = \", SST_5,\", df = 13\")\ncat(\"\\nSSR = \", SSR_5,\", df = 1\")\ncat(\"\\nSSE = \", SSE_5, \", df = 12\")\n\nSST =  295.6486 , df = 13\nSSR =  254.1516 , df = 1\nSSE =  41.49696 , df = 12\n\n\n\ncat(\"yA = \",round(beta0_xyA,4), \"+ \",round(beta1_xyA,4) ,\"x\")\n\nyA =  6.7571 +  0.2811 x\n\n\n\ncat(\"yA SST = \", SST_A,\", df = 6\")\ncat(\"\\nyA SSR = \", SSR_A,\", df = 1\")\ncat(\"\\nyA SSE = \", SSE_A, \", df = 5\")\n\nyA SST =  226.76 , df = 6\nyA SSR =  221.2032 , df = 1\nyA SSE =  5.556786 , df = 5\n\n\n\ncat(\"yB = \",round(beta0_xyB,4), \"+ \",round(beta1_xyB,4) ,\"x\")\n\nyB =  12.8571 +  0.145 x\n\n\n\ncat(\"yB SST = \", SST_B,\", df = 6\")\ncat(\"\\nyB SSR = \", SSR_B,\", df = 1\")\ncat(\"\\nyB SSE = \", SSE_B, \", df = 5\")\n\nyB SST =  67.37714 , df = 6\nyB SSR =  58.87 , df = 1\nyB SSE =  8.507143 , df = 5\n\n\n가설\n\\(H_0 : \\beta_{01} = \\beta_{02} \\text{ and } \\beta_{11} = \\beta_{12}\\)\n\\(H_1 : \\beta_{01} \\neq \\beta_{02} \\text{ or } \\beta_{11} \\neq \\beta_{12}\\)\n검정통계량\n\\(F_0 = \\frac{SSE(R) - SSE(F)}{df_R-df_F} \\times \\frac{df_F}{SSE(F)}\\)\n\nSSE_5_F = SSE_A + SSE_B\ndf_5_F = 5 -2 + 5 -2\n\n\nSSE_5_R = SSE_5\ndf_5_R = 5 -1 + 5 -1\n\n\nF_5_0 = (SSE_5_R - SSE_5_F)/(df_5_R - df_5_F) / (SSE_5_F/df_5_F)\nF_5_0\n\n5.8517864828756\n\n\n\ndf_5_R - df_5_F\n\n2\n\n\n\ndf_5_F\n\n6\n\n\n\nF_5_stan = qf(0.95,2,10)\nF_5_stan\n\n4.1028210151304\n\n\n\ncat(F_5_0, \" 는 유의수준 0.05에서 F값 \", F_5_stan , \" 보다 크다.\")\n\ncat(\"\\n따라서 귀무가설을 기각하였고, 두 회귀모형은 beta0가 다르거나\")\n\ncat(\"\\n혹은 beta1이 다르거나 혹은 beta0,beta1 모두가 다르다.\")\n\n5.851786  는 유의수준 0.05에서 F값  4.102821  보다 크다.\n따라서 귀무가설을 기각하였고, 두 회귀모형은 beta0가 다르거나\n혹은 beta1이 다르거나 혹은 beta0,beta1 모두가 다르다.\n\n\n\\(H_0 : \\beta_{01} = \\beta_{02} \\text{ and } \\beta_{11} = \\beta_{12}\\) 기각"
  },
  {
    "objectID": "posts/rl/2022-10-23-rl-HW2.html#section-6",
    "href": "posts/rl/2022-10-23-rl-HW2.html#section-6",
    "title": "Regression HW 2",
    "section": "(3)",
    "text": "(3)\n관심의 대상이 \\(x\\)가 증가함에 따라 \\(y\\) 가 얼마나 증가하는가에 있다. 두 회사의 타이어에 대하여 각각 회귀모형을 적합했을 때, 기울기가 같은지 유의수준 5%로 검정하시오.\nAnswer\n기울기 비교에 대한 가설\n\\(H_0 : \\beta_{11} = \\beta_{12} \\text{ vs. } H_1 : \\beta_{11} \\neq \\beta_{12}\\)\n검정통계량\n\\(t_0 = \\frac{ \\hat{\\beta}_{11} - \\hat{\\beta}_{12} }{ \\sqrt{ \\hat{Var}( \\hat{\\beta}_{11} - \\hat{\\beta}_{12} ) } }\\)\n\\(\\text{Degree of Freedom} = t((n_1 - 1) + (n_2 - 1))\\)\n\\(\\hat{Var}( \\hat{\\beta}_{11} - \\hat{\\beta}_{12} ) = MSE(F) [\\frac{1}{\\sum(x_{1j} - \\bar{x}_1)^2} + \\frac{1}{\\sum(x_{2j} - \\bar{x}_2)^2}]\\)\n\nround(beta1_xyA,4)\n\n0.2811\n\n\n\nround(beta1_xyB,4)\n\n0.145\n\n\n\nSSE_5_F\n\n14.063928575095\n\n\n\nMSE_5_F = SSE_5_F / df_5_F\nMSE_5_F\n\n2.34398809584917\n\n\n\nsum(df_5_A$x_barx2)\n\n2800\n\n\n\nsum(df_5_B$x_barx2)\n\n2800\n\n\n\nvar_5_diff = MSE_5_F * (1/sum(df_5_A$x_barx2) + 1/sum(df_5_B$x_barx2))\nvar_5_diff\n\n0.00167427721132084\n\n\n\nt_5_0 = (beta1_xyA - beta1_xyB)/sqrt(var_5_diff)\nt_5_0\n\n3.32547173820247\n\n\n\nqt(0.95,df_5_F)\n\n1.9431802805153\n\n\n\ncat(t_5_0,\"는 \",qt(0.95,df_5_F),\"보다 크다. 따라서 유의수준 5%에서 귀무가설을 기각하여 두 회귀모형의 기울기가 다르다고 할 수 있다.\")\n\n3.325472 는  1.94318 보다 크다. 따라서 유의수준 5%에서 귀무가설을 기각하여 두 회귀모형의 기울기가 다르다고 할 수 있다.\n\n\n\\(H_0 : \\beta_{11} = \\beta_{12}\\) 기각"
  },
  {
    "objectID": "posts/rl/2022-10-23-rl-HW2.html#section-8",
    "href": "posts/rl/2022-10-23-rl-HW2.html#section-8",
    "title": "Regression HW 2",
    "section": "(1)",
    "text": "(1)\nHigh와 Year, Low와 Year, 그리고 High와 Low에 대해 산점도를 그리시오.\nAnswer\n\ndf_6 = data.frame(Year = c(1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978),\n           High = c(25.82, 25.35, 24.29, 24.05, 24.89, 25.35, 25.23, 25.06, 27.13, 27.36, 26.65, 27.13, 27.49, 27.08, 27.51, 27.54, 26.21),\n           Low = c(18.24, 16.50, 20.26, 20.97, 19.43, 19.31, 20.85, 19.54, 20.49, 21.91, 22.51, 18.81, 19.42, 19.10, 18.80, 18.80, 17.57))\ndf_6\n\n\nA data.frame: 17 × 3\n\n\nYear\nHigh\nLow\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1962\n25.82\n18.24\n\n\n1963\n25.35\n16.50\n\n\n1964\n24.29\n20.26\n\n\n1965\n24.05\n20.97\n\n\n1966\n24.89\n19.43\n\n\n1967\n25.35\n19.31\n\n\n1968\n25.23\n20.85\n\n\n1969\n25.06\n19.54\n\n\n1970\n27.13\n20.49\n\n\n1971\n27.36\n21.91\n\n\n1972\n26.65\n22.51\n\n\n1973\n27.13\n18.81\n\n\n1974\n27.49\n19.42\n\n\n1975\n27.08\n19.10\n\n\n1976\n27.51\n18.80\n\n\n1977\n27.54\n18.80\n\n\n1978\n26.21\n17.57\n\n\n\n\n\n\nplot(df_6$High,df_6$Year,\n     xlab = \"Year\",\n     ylab = \"High\",\n     pch  = 16,\n     cex  = 1)\n\n\n\n\n양의 기울기로 선형 관계를 갖는 모습이다.\n\nplot(df_6$Low~df_6$Year,\n     xlab = \"Year\",\n     ylab = \"Low\",\n     pch  = 16,\n     cex  = 1)\n\n\n\n\n이차함수 모양의 연관이 있는 모양새이다.\n\nplot(df_6$Low~df_6$High,\n    xlab = \"Low\",\n     ylab = \"High\",\n     pch  = 16,\n     cex  = 1)\n\n\n\n\n관련이 있는지 모르겠다."
  },
  {
    "objectID": "posts/rl/2022-10-23-rl-HW2.html#section-9",
    "href": "posts/rl/2022-10-23-rl-HW2.html#section-9",
    "title": "Regression HW 2",
    "section": "(2)",
    "text": "(2)\nYear에 대한 High, Year에 대한 Low, 그리고 Low에 대한 High의 회귀모형을 구하시오. 3개 회귀모형의 결과를 요약하고, 각 모형별로 회귀계수의 의미를 설명하시오.\nAnswer\nYear에 대한 High의 회귀모형\n\ndf_6_YearHigh &lt;- df_6\n\n\ndf_6_YearHigh$Year_barYear = df_6_YearHigh$Year - mean(df_6_YearHigh$Year)\ndf_6_YearHigh$High_barHigh = df_6_YearHigh$High - mean(df_6_YearHigh$High) \n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주기 위해 \\(x_i - \\bar{x}, y_i - \\bar{y}\\)를 구했다.\n\n\ndf_6_YearHigh$Year_barYear2 &lt;- df_6_YearHigh$Year_barYear^2\ndf_6_YearHigh$High_barHigh2 &lt;- df_6_YearHigh$High_barHigh^2\ndf_6_YearHigh$YearHigh &lt;-df_6_YearHigh$Year_barYear * df_6_YearHigh$High_barHigh\n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주었다.\n\n\ndf_6_YearHigh\n\n\nA data.frame: 17 × 8\n\n\nYear\nHigh\nLow\nYear_barYear\nHigh_barHigh\nYear_barYear2\nHigh_barHigh2\nYearHigh\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1962\n25.82\n18.24\n-8\n-0.30588235\n64\n0.093564014\n2.4470588\n\n\n1963\n25.35\n16.50\n-7\n-0.77588235\n49\n0.601993426\n5.4311765\n\n\n1964\n24.29\n20.26\n-6\n-1.83588235\n36\n3.370464014\n11.0152941\n\n\n1965\n24.05\n20.97\n-5\n-2.07588235\n25\n4.309287543\n10.3794118\n\n\n1966\n24.89\n19.43\n-4\n-1.23588235\n16\n1.527405190\n4.9435294\n\n\n1967\n25.35\n19.31\n-3\n-0.77588235\n9\n0.601993426\n2.3276471\n\n\n1968\n25.23\n20.85\n-2\n-0.89588235\n4\n0.802605190\n1.7917647\n\n\n1969\n25.06\n19.54\n-1\n-1.06588235\n1\n1.136105190\n1.0658824\n\n\n1970\n27.13\n20.49\n0\n1.00411765\n0\n1.008252249\n0.0000000\n\n\n1971\n27.36\n21.91\n1\n1.23411765\n1\n1.523046367\n1.2341176\n\n\n1972\n26.65\n22.51\n2\n0.52411765\n4\n0.274699308\n1.0482353\n\n\n1973\n27.13\n18.81\n3\n1.00411765\n9\n1.008252249\n3.0123529\n\n\n1974\n27.49\n19.42\n4\n1.36411765\n16\n1.860816955\n5.4564706\n\n\n1975\n27.08\n19.10\n5\n0.95411765\n25\n0.910340484\n4.7705882\n\n\n1976\n27.51\n18.80\n6\n1.38411765\n36\n1.915781661\n8.3047059\n\n\n1977\n27.54\n18.80\n7\n1.41411765\n49\n1.999728720\n9.8988235\n\n\n1978\n26.21\n17.57\n8\n0.08411765\n64\n0.007075779\n0.6729412\n\n\n\n\n\n\nround(colSums(df_6_YearHigh),3)\n\nYear33490High444.14Low332.51Year_barYear0High_barHigh0Year_barYear2408High_barHigh222.951YearHigh73.8\n\n\n\\(\\hat{\\beta_1} = \\frac{S_{xy}}{S_{xx}}\\)\n\\(\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x}\\)\n\nbeta1_YearHigh &lt;- as.numeric(colSums(df_6_YearHigh)[8]/colSums(df_6_YearHigh)[6])\nbeta0_YearHigh &lt;- mean(df_6_YearHigh$High) - beta1_YearHigh *  mean(df_6_YearHigh$Year)\n\n\ncat(\"YearHigh hat beta0 = \", beta0_YearHigh)\ncat(\"\\nYearHigh hat beta1 = \", beta1_YearHigh)\n\nYearHigh hat beta0 =  -330.2124\nYearHigh hat beta1 =  0.1808824\n\n\n\\(\\text{High} = -330.21235 + 0.18088\\text{Year}\\)\nR결과와 비교\n\nsummary(lm(df_6$High~df_6$Year))\n\n\nCall:\nlm(formula = df_6$High ~ df_6$Year)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.3629 -0.5341  0.1479  0.4903  1.1412 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -330.21235   78.03319  -4.232 0.000725 ***\ndf_6$Year      0.18088    0.03961   4.567 0.000371 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.8001 on 15 degrees of freedom\nMultiple R-squared:  0.5816,    Adjusted R-squared:  0.5537 \nF-statistic: 20.85 on 1 and 15 DF,  p-value: 0.0003708\n\n\nR결과 해석 - beta0과 beta1이 5%보다 유의확률이 작아 유의미하다. - 모형의 설명력은 50%정도에 머문다. - 모형의 p값이 0.05보다 작아 유의미하다고 볼 수 있다.\nYear에 대한 Low의 회귀모형\n\ndf_6_YearLow &lt;- df_6\n\n\ndf_6_YearLow$Year_barYear = df_6_YearLow$Year - mean(df_6_YearLow$Year)\ndf_6_YearLow$Low_barLow = df_6_YearLow$Low - mean(df_6_YearLow$Low) \n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주기 위해 \\(x_i - \\bar{x}, y_i - \\bar{y}\\)를 구했다.\n\n\ndf_6_YearLow$Year_barYear2 &lt;- df_6_YearLow$Year_barYear^2\ndf_6_YearLow$Low_barLow2 &lt;- df_6_YearLow$Low_barLow^2\ndf_6_YearLow$YearLow &lt;-df_6_YearLow$Year_barYear * df_6_YearLow$Low_barLow\n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주었다.\n\n\ndf_6_YearLow\n\n\nA data.frame: 17 × 8\n\n\nYear\nHigh\nLow\nYear_barYear\nLow_barLow\nYear_barYear2\nLow_barLow2\nYearLow\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1962\n25.82\n18.24\n-8\n-1.31941176\n64\n1.7408474048\n10.55529412\n\n\n1963\n25.35\n16.50\n-7\n-3.05941176\n49\n9.3600003460\n21.41588235\n\n\n1964\n24.29\n20.26\n-6\n0.70058824\n36\n0.4908238754\n-4.20352941\n\n\n1965\n24.05\n20.97\n-5\n1.41058824\n25\n1.9897591696\n-7.05294118\n\n\n1966\n24.89\n19.43\n-4\n-0.12941176\n16\n0.0167474048\n0.51764706\n\n\n1967\n25.35\n19.31\n-3\n-0.24941176\n9\n0.0622062284\n0.74823529\n\n\n1968\n25.23\n20.85\n-2\n1.29058824\n4\n1.6656179931\n-2.58117647\n\n\n1969\n25.06\n19.54\n-1\n-0.01941176\n1\n0.0003768166\n0.01941176\n\n\n1970\n27.13\n20.49\n0\n0.93058824\n0\n0.8659944637\n0.00000000\n\n\n1971\n27.36\n21.91\n1\n2.35058824\n1\n5.5252650519\n2.35058824\n\n\n1972\n26.65\n22.51\n2\n2.95058824\n4\n8.7059709343\n5.90117647\n\n\n1973\n27.13\n18.81\n3\n-0.74941176\n9\n0.5616179931\n-2.24823529\n\n\n1974\n27.49\n19.42\n4\n-0.13941176\n16\n0.0194356401\n-0.55764706\n\n\n1975\n27.08\n19.10\n5\n-0.45941176\n25\n0.2110591696\n-2.29705882\n\n\n1976\n27.51\n18.80\n6\n-0.75941176\n36\n0.5767062284\n-4.55647059\n\n\n1977\n27.54\n18.80\n7\n-0.75941176\n49\n0.5767062284\n-5.31588235\n\n\n1978\n26.21\n17.57\n8\n-1.98941176\n64\n3.9577591696\n-15.91529412\n\n\n\n\n\n\nround(colSums(df_6_YearLow),3)\n\nYear33490High444.14Low332.51Year_barYear0Low_barLow0Year_barYear2408Low_barLow236.327YearLow-3.22\n\n\n\\(\\hat{\\beta_1} = \\frac{S_{xy}}{S_{xx}}\\)\n\\(\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x}\\)\n\nbeta1_YearLow &lt;- as.numeric(colSums(df_6_YearLow)[8]/colSums(df_6_YearLow)[6])\nbeta0_YearLow &lt;- mean(df_6_YearLow$Low) - beta1_YearLow *  mean(df_6_YearLow$Year)\n\n\ncat(\"YearLow hat beta0 = \", beta0_YearLow)\ncat(\"\\nYearLow hat beta1 = \", beta1_YearLow)\n\nYearLow hat beta0 =  35.10696\nYearLow hat beta1 =  -0.007892157\n\n\n\\(\\text{Low} = 35.106961 -0.007892\\text{Year}\\)\nR결과와 비교\n\nsummary(lm(df_6$Low~df_6$Year))\n\n\nCall:\nlm(formula = df_6$Low ~ df_6$Year)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1147 -0.7121 -0.1610  0.9306  2.9664 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  35.106961 151.723912   0.231     0.82\ndf_6$Year    -0.007892   0.077017  -0.102     0.92\n\nResidual standard error: 1.556 on 15 degrees of freedom\nMultiple R-squared:  0.0006996, Adjusted R-squared:  -0.06592 \nF-statistic: 0.0105 on 1 and 15 DF,  p-value: 0.9197\n\n\nR결과 해석 - beta0과 beta1이 5%보다 유의확률이 커 유의미하지 않다. - 모형의 설명력은 굉장히 낮았다. - 모형의 p값이 0.05보다 커 유의미하지 않다.\nLow에 대한 High의 회귀모형\n\ndf_6_LowHigh &lt;- df_6\n\n\ndf_6_LowHigh$Low_barLow = df_6_LowHigh$Low - mean(df_6_LowHigh$Low)\ndf_6_LowHigh$High_barHigh = df_6_LowHigh$High - mean(df_6_LowHigh$High) \n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주기 위해 \\(x_i - \\bar{x}, y_i - \\bar{y}\\)를 구했다.\n\n\ndf_6_LowHigh$Low_barLow2 &lt;- df_6_LowHigh$Low_barLow^2\ndf_6_LowHigh$High_barHigh2 &lt;- df_6_LowHigh$High_barHigh^2\ndf_6_LowHigh$LowHigh &lt;-df_6_LowHigh$Low_barLow * df_6_LowHigh$High_barHigh\n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주었다.\n\n\ndf_6_LowHigh\n\n\nA data.frame: 17 × 8\n\n\nYear\nHigh\nLow\nLow_barLow\nHigh_barHigh\nLow_barLow2\nHigh_barHigh2\nLowHigh\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1962\n25.82\n18.24\n-1.31941176\n-0.30588235\n1.7408474048\n0.093564014\n0.40358478\n\n\n1963\n25.35\n16.50\n-3.05941176\n-0.77588235\n9.3600003460\n0.601993426\n2.37374360\n\n\n1964\n24.29\n20.26\n0.70058824\n-1.83588235\n0.4908238754\n3.370464014\n-1.28619758\n\n\n1965\n24.05\n20.97\n1.41058824\n-2.07588235\n1.9897591696\n4.309287543\n-2.92821522\n\n\n1966\n24.89\n19.43\n-0.12941176\n-1.23588235\n0.0167474048\n1.527405190\n0.15993772\n\n\n1967\n25.35\n19.31\n-0.24941176\n-0.77588235\n0.0622062284\n0.601993426\n0.19351419\n\n\n1968\n25.23\n20.85\n1.29058824\n-0.89588235\n1.6656179931\n0.802605190\n-1.15621522\n\n\n1969\n25.06\n19.54\n-0.01941176\n-1.06588235\n0.0003768166\n1.136105190\n0.02069066\n\n\n1970\n27.13\n20.49\n0.93058824\n1.00411765\n0.8659944637\n1.008252249\n0.93442007\n\n\n1971\n27.36\n21.91\n2.35058824\n1.23411765\n5.5252650519\n1.523046367\n2.90090242\n\n\n1972\n26.65\n22.51\n2.95058824\n0.52411765\n8.7059709343\n0.274699308\n1.54645536\n\n\n1973\n27.13\n18.81\n-0.74941176\n1.00411765\n0.5616179931\n1.008252249\n-0.75249758\n\n\n1974\n27.49\n19.42\n-0.13941176\n1.36411765\n0.0194356401\n1.860816955\n-0.19017405\n\n\n1975\n27.08\n19.10\n-0.45941176\n0.95411765\n0.2110591696\n0.910340484\n-0.43833287\n\n\n1976\n27.51\n18.80\n-0.75941176\n1.38411765\n0.5767062284\n1.915781661\n-1.05111522\n\n\n1977\n27.54\n18.80\n-0.75941176\n1.41411765\n0.5767062284\n1.999728720\n-1.07389758\n\n\n1978\n26.21\n17.57\n-1.98941176\n0.08411765\n3.9577591696\n0.007075779\n-0.16734464\n\n\n\n\n\n\nround(colSums(df_6_LowHigh),3)\n\nYear33490High444.14Low332.51Low_barLow0High_barHigh0Low_barLow236.327High_barHigh222.951LowHigh-0.511\n\n\n\\(\\hat{\\beta_1} = \\frac{S_{xy}}{S_{xx}}\\)\n\\(\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x}\\)\n\nbeta1_LowHigh &lt;- as.numeric(colSums(df_6_LowHigh)[8]/colSums(df_6_LowHigh)[6])\nbeta0_LowHigh &lt;- mean(df_6_LowHigh$High) - beta1_LowHigh *  mean(df_6_LowHigh$Low)\n\n\ncat(\"LowHigh hat beta0 = \", beta0_LowHigh)\ncat(\"\\nLowHigh hat beta1 = \", beta1_LowHigh)\n\nLowHigh hat beta0 =  26.40088\nLowHigh hat beta1 =  -0.01405959\n\n\n\\(\\text{High} = 26.40088 -0.01406\\text{Low}\\)\nR결과와 비교\n\nsummary(lm(df_6$Low~df_6$High))\n\n\nCall:\nlm(formula = df_6$Low ~ df_6$High)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0767 -0.7279 -0.1569  0.9529  2.9623 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) 20.14079    8.49368   2.371   0.0315 *\ndf_6$High   -0.02225    0.32478  -0.069   0.9463  \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 1.556 on 15 degrees of freedom\nMultiple R-squared:  0.0003129, Adjusted R-squared:  -0.06633 \nF-statistic: 0.004695 on 1 and 15 DF,  p-value: 0.9463\n\n\nR결과 해석 - beta0은 유의미 하지만 beta1이 5%보다 유의확률이 커 유의미하지 않다. - 모형의 설명력은 굉장히 낮았다. - 모형의 p값이 0.05보다 커 유의미하지 않다.\n모형 정리\n\\(\\text{Low} = 35.106961 -0.007892\\text{Year}\\) 모형의 의미 - \\(\\beta_0 = 35.106961\\): 해당 모형에서 시간에 영향을 받지 않았을때의 아마존 강의 최저 수위가 35.106961m이다. - \\(\\beta_1 = -0.007892\\): 아마존 강의 최저수위가 0.007892m만큼 감소한 것을 의미하는데, 이것은 해마다 아마존 강의 흐르는 물이 감소하는 것을 의미하지만, 0에 가까운 값으로서 영향이 미세해 보인다.\n\\(\\text{High} = -330.21235 + 0.18088\\text{Year}\\) 모형의 의미 - \\(\\beta_0 = -330.21235\\): 해당 모형에서 시간에 영향을 받지 않았을때의 아마존 강의 최고 수위가 -330.21235m이다. - \\(\\beta_1 = 0.18088\\): 아마존 강의 최고수위가 0.18088m만큼 증가된 것을 의미하는데, 이것은 해마다 아마존 강의 흐르는 물이 0.18088m 늘어난 것을 나타낼 수 있다. 이 모형에서도 영향이 크게 끼치지 않는 것 같다.\n\\(\\text{High} = 26.40088 -0.01406\\text{Low}\\) 모형의 의미 - \\(\\beta_0 = -26.40088\\): 해당 모형에서 최저수위의 영향을 받지 않았을 때의 아마존 강의 최고수위가 026.40088m 라는 것을 의미한다. - \\(\\beta_1 = -0.014061\\): 아마존 강의 최고수위가 최저수위가 1m 증가함에 따라 -0.0014061m 만큼 감소함을 의미한다. 아마존 강의 최저수위는 최고수위에 미치는 영향이 미미해 보인다."
  },
  {
    "objectID": "posts/rl/2022-10-23-rl-HW2.html#section-10",
    "href": "posts/rl/2022-10-23-rl-HW2.html#section-10",
    "title": "Regression HW 2",
    "section": "(3)",
    "text": "(3)\n이 자료를 근거로 우리는 삼림파괴가 아마존 강 수위의 변화를 일으킨다고 할 수 있는가?\nAnswer\n\n1970년대 이후 삼림파괴가 이루어졌다. 구간을 나누어 보지 않는 이상 삼림파괴가 아마존 강 수위의 변화를 일으켰다는 판단은 섣불러 보인다.\n모형만 봐도 시간과 아마존 강의 최고수위 및 최저수위의 영향과 아마존 강의 최저수위 및 최고수위 간의 영향이 거의 없어보인다. 모두 1도 넘지 않았기도 하다.\n따라서 삼림파괴가 아마존 강 수위의 변화를 일으켰다고 2번의 근거로는 할 수 없다."
  },
  {
    "objectID": "posts/rl/2022-10-23-rl-HW2.html#section-11",
    "href": "posts/rl/2022-10-23-rl-HW2.html#section-11",
    "title": "Regression HW 2",
    "section": "(4)",
    "text": "(4)\n아마존강의 최저수위와 최고수위와의 산점도를 1960년대, 1970년대 자료별로 다르게 그리고, 각각의 회귀선을 적합하시오.\nAnswer\n1960년대 아마존강의 최저수위와 최고수위와의 산점도\n\nplot(df_6$High[df_6$Year&lt;1970]~df_6$Low[df_6$Year&lt;1970],\n     xlab = \"Low\",\n     ylab =\"High\",\n     pch  = 16,\n     cex  = 1)\n\n\n\n\n1960년대 아마존강의 최저수위와 최고수위와의 회귀선\n\ndf_6_1960 &lt;- df_6[df_6$Year&lt;1970,]\n\n\ndf_6_1960$Low_barLow = df_6_1960$Low - mean(df_6_1960$Low)\ndf_6_1960$High_barHigh = df_6_1960$High - mean(df_6_1960$High) \n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주기 위해 \\(x_i - \\bar{x}, y_i - \\bar{y}\\)를 구했다.\n\n\ndf_6_1960$Low_barLow2 &lt;- df_6_1960$Low_barLow^2\ndf_6_1960$High_barHigh2 &lt;- df_6_1960$High_barHigh^2\ndf_6_1960$LowHigh &lt;-df_6_1960$Low_barLow * df_6_1960$High_barHigh\n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주었다.\n\n\nround(colSums(df_6_1960),3)\n\nYear15724High200.04Low155.1Low_barLow0High_barHigh0Low_barLow215.09High_barHigh22.392LowHigh-3.761\n\n\n\\(\\hat{\\beta_1} = \\frac{S_{xy}}{S_{xx}}\\)\n\\(\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x}\\)\n\ndf_6_1960\n\n\nA data.frame: 8 × 8\n\n\n\nYear\nHigh\nLow\nLow_barLow\nHigh_barHigh\nLow_barLow2\nHigh_barHigh2\nLowHigh\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n1962\n25.82\n18.24\n-1.1475\n0.815\n1.31675625\n0.664225\n-0.9352125\n\n\n2\n1963\n25.35\n16.50\n-2.8875\n0.345\n8.33765625\n0.119025\n-0.9961875\n\n\n3\n1964\n24.29\n20.26\n0.8725\n-0.715\n0.76125625\n0.511225\n-0.6238375\n\n\n4\n1965\n24.05\n20.97\n1.5825\n-0.955\n2.50430625\n0.912025\n-1.5112875\n\n\n5\n1966\n24.89\n19.43\n0.0425\n-0.115\n0.00180625\n0.013225\n-0.0048875\n\n\n6\n1967\n25.35\n19.31\n-0.0775\n0.345\n0.00600625\n0.119025\n-0.0267375\n\n\n7\n1968\n25.23\n20.85\n1.4625\n0.225\n2.13890625\n0.050625\n0.3290625\n\n\n8\n1969\n25.06\n19.54\n0.1525\n0.055\n0.02325625\n0.003025\n0.0083875\n\n\n\n\n\n\nbeta1_1960 &lt;- as.numeric(colSums(df_6_1960)[8]/colSums(df_6_1960)[6])\nbeta0_1960 &lt;- mean(df_6_1960$High) - beta1_1960 *  mean(df_6_1960$Low)\n\n\ncat(\"hat beta0 1960 = \", round(beta0_1960,4))\ncat(\"\\nhat beta1 1960 = \", round(beta1_1960,4))\n\nhat beta0 1960 =  29.8367\nhat beta1 1960 =  -0.2492\n\n\n\ncat(\"회귀선은 다음과 같았다. 1960 High = \",round(beta0_1960,4),\" + \", round(beta1_1960,4),\"Low\")\n\n회귀선은 다음과 같았다. 1960 High =  29.8367  +  -0.2492 Low\n\n\nR결과 비교\n\nsummary(lm(df_6_1960$High~df_6_1960$Low))\n\n\nCall:\nlm(formula = df_6_1960$High ~ df_6_1960$Low)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5606 -0.4053 -0.0057  0.3765  0.5895 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    29.8367     2.4640  12.109 1.93e-05 ***\ndf_6_1960$Low  -0.2492     0.1268  -1.966   0.0969 .  \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.4925 on 6 degrees of freedom\nMultiple R-squared:  0.3918,    Adjusted R-squared:  0.2904 \nF-statistic: 3.864 on 1 and 6 DF,  p-value: 0.09691\n\n\n\nSST_1960 = sum((df_6_1960$High - mean(df_6_1960$High))^2)\n\n\nSSR_1960 = sum( ( (29.8367  +  -0.2492*df_6_1960$Low)-mean(df_6_1960$High) )^2 )\n\n\nSSE_1960 = sum( ( df_6_1960$High-(29.8367  +  -0.2492*df_6_1960$Low))^2 )\n\n\ncat(\"1960 SST = \", SST_1960,\", df = 7\")\ncat(\"\\n1960 SSR = \", SSR_1960,\", df = 1\")\ncat(\"\\n1960 SSE = \", SSE_1960, \", df = 6\")\n\n1960 SST =  2.3924 , df = 7\n1960 SSR =  0.9370965 , df = 1\n1960 SSE =  1.455164 , df = 6\n\n\nR결과 비교\n\nanova(lm(df_6_1960$High~df_6_1960$Low))\n\n\nA anova: 2 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\ndf_6_1960$Low\n1\n0.9372373\n0.9372373\n3.864464\n0.09690958\n\n\nResiduals\n6\n1.4551627\n0.2425271\nNA\nNA\n\n\n\n\n\n1970년대 아마존강의 최저수위와 최고수위와의 산점도\n\nplot(df_6$High[df_6$Year&gt;=1970]~df_6$Low[df_6$Year&gt;=1970],\n     xlab = \"Low\",\n     ylab =\"High\",\n     pch  = 16,\n     cex  = 1)\n\n\n\n\n1970년대 아마존강의 최저수위와 최고수위와의 회귀선\n\ndf_6_1970 &lt;- df_6[df_6$Year&gt;=1970,]\n\n\ndf_6_1970$Low_barLow = df_6_1970$Low - mean(df_6_1970$Low)\ndf_6_1970$High_barHigh = df_6_1970$High - mean(df_6_1970$High) \n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주기 위해 \\(x_i - \\bar{x}, y_i - \\bar{y}\\)를 구했다.\n\n\ndf_6_1970$Low_barLow2 &lt;- df_6_1970$Low_barLow^2\ndf_6_1970$High_barHigh2 &lt;- df_6_1970$High_barHigh^2\ndf_6_1970$LowHigh &lt;-df_6_1970$Low_barLow * df_6_1970$High_barHigh\n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주었다.\n\n\nround(colSums(df_6_1970),3)\n\nYear17766High244.1Low177.41Low_barLow0High_barHigh0Low_barLow220.79High_barHigh21.574LowHigh0.338\n\n\n\\(\\hat{\\beta_1} = \\frac{S_{xy}}{S_{xx}}\\)\n\\(\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x}\\)\n\ndf_6_1970\n\n\nA data.frame: 9 × 8\n\n\n\nYear\nHigh\nLow\nLow_barLow\nHigh_barHigh\nLow_barLow2\nHigh_barHigh2\nLowHigh\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n9\n1970\n27.13\n20.49\n0.7777778\n0.007777778\n0.60493827\n6.049383e-05\n0.006049383\n\n\n10\n1971\n27.36\n21.91\n2.1977778\n0.237777778\n4.83022716\n5.653827e-02\n0.522582716\n\n\n11\n1972\n26.65\n22.51\n2.7977778\n-0.472222222\n7.82756049\n2.229938e-01\n-1.321172840\n\n\n12\n1973\n27.13\n18.81\n-0.9022222\n0.007777778\n0.81400494\n6.049383e-05\n-0.007017284\n\n\n13\n1974\n27.49\n19.42\n-0.2922222\n0.367777778\n0.08539383\n1.352605e-01\n-0.107472840\n\n\n14\n1975\n27.08\n19.10\n-0.6122222\n-0.042222222\n0.37481605\n1.782716e-03\n0.025849383\n\n\n15\n1976\n27.51\n18.80\n-0.9122222\n0.387777778\n0.83214938\n1.503716e-01\n-0.353739506\n\n\n16\n1977\n27.54\n18.80\n-0.9122222\n0.417777778\n0.83214938\n1.745383e-01\n-0.381106173\n\n\n17\n1978\n26.21\n17.57\n-2.1422222\n-0.912222222\n4.58911605\n8.321494e-01\n1.954182716\n\n\n\n\n\n\nbeta1_1970 &lt;- as.numeric(colSums(df_6_1970)[8]/colSums(df_6_1970)[6])\nbeta0_1970 &lt;- mean(df_6_1970$High) - beta1_1970 *  mean(df_6_1970$Low)\n\n\ncat(\"hat beta0 1970 = \", round(beta0_1970,4))\ncat(\"\\nhat beta1 1970 = \", round(beta1_1970,4))\n\nhat beta0 1970 =  26.8016\nhat beta1 1970 =  0.0163\n\n\nR결과 비교\n\nsummary(lm(df_6_1970$High~df_6_1970$Low))\n\n\nCall:\nlm(formula = df_6_1970$High ~ df_6_1970$Low)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.87738 -0.03226  0.02245  0.37253  0.43262 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   26.80160    2.05235  13.059  3.6e-06 ***\ndf_6_1970$Low  0.01627    0.10381   0.157     0.88    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.4733 on 7 degrees of freedom\nMultiple R-squared:  0.003495,  Adjusted R-squared:  -0.1389 \nF-statistic: 0.02455 on 1 and 7 DF,  p-value: 0.8799\n\n\n\ncat(\"회귀선은 다음과 같았다. 1970 High = \",round(beta0_1970,4),\" + \", round(beta1_1970,4),\"Low\")\n\n회귀선은 다음과 같았다. 1970 High =  26.8016  +  0.0163 Low\n\n\n\nSST_1970 = sum((df_6_1970$High - mean(df_6_1970$High))^2)\n\n\nSSR_1970 = sum( ( (26.8016  +  0.0163 *df_6_1970$Low)-mean(df_6_1970$High) )^2 )\n\n\nSSE_1970 = sum( ( df_6_1970$High-(26.8016  +  0.0163 *df_6_1970$Low))^2 )\n\n\ncat(\"1970 SST = \", SST_1970,\", df = 8\")\ncat(\"\\n1970 SSR = \", SSR_1970,\", df = 1\")\ncat(\"\\n1970 SSE = \", SSE_1970, \", df = 7\")\n\n1970 SST =  1.573756 , df = 8\n1970 SSR =  0.005528037 , df = 1\n1970 SSE =  1.56826 , df = 7\n\n\nR결과 비교\n\nanova(lm(df_6_1970$High~df_6_1970$Low))\n\n\nA anova: 2 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\ndf_6_1970$Low\n1\n0.005500107\n0.005500107\n0.02455005\n0.8799168\n\n\nResiduals\n7\n1.568255449\n0.224036493\nNA\nNA"
  },
  {
    "objectID": "posts/rl/2022-10-23-rl-HW2.html#section-12",
    "href": "posts/rl/2022-10-23-rl-HW2.html#section-12",
    "title": "Regression HW 2",
    "section": "(5)",
    "text": "(5)\n아마존강의 최저수위와 최고수위와의 관계가 1960년대와 1970년대에 따라 차이가 있는가? 두 회귀모형의 동일성 여부를 유의수준 \\(\\alpha = 0.01\\)에서 검정하시오.\nAnswer\n가설\n\\(H_0 : \\beta_{01} = \\beta_{02} \\text{ and } \\beta_{11} = \\beta_{12}\\)\n\\(H_1 : \\beta_{01} \\neq \\beta_{02} \\text{ pr } \\beta_{11} \\neq \\beta_{12}\\)\n(2)에서 구했던 것\n\\(\\text{High} = 26.40088 -0.01406\\text{Low}\\)\n\nSST = sum((df_6$High - mean(df_6$High))^2)\n\n\nSSR = sum( ( (26.40088 - 0.01406 *df_6$Low)-mean(df_6$High) )^2 )\n\n\nSSE = sum( ( df_6$High-(26.40088 - 0.01406 *df_6$Low))^2 )\n\n\ncat(\"SST = \", SST,\", df = 16\")\ncat(\"\\nSSR = \", SSR,\", df = 1\")\ncat(\"\\nSSE = \", SSE, \", df = 15\")\n\nSST =  22.95141 , df = 16\nSSR =  0.007181232 , df = 1\nSSE =  22.94423 , df = 15\n\n\nR결과와 비교\n\nanova(lm(df_6$High~df_6$Low))\n\n\nA anova: 2 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\ndf_6$Low\n1\n0.007180811\n0.007180811\n0.00469452\n0.9462794\n\n\nResiduals\n15\n22.944230954\n1.529615397\nNA\nNA\n\n\n\n\n\n\\(\\text{1960 High} = 29.8367 + -0.2492\\text{Low}\\)\n\ncat(\"1960 SST = \", SST_1960,\", df = 7\")\ncat(\"\\n1960 SSR = \", SSR_1960,\", df = 1\")\ncat(\"\\n1960 SSE = \", SSE_1960, \", df = 6\")\n\n1960 SST =  2.3924 , df = 7\n1960 SSR =  0.9370965 , df = 1\n1960 SSE =  1.455164 , df = 6\n\n\n\\(\\text{1970 High} = 26.8016 + 0.0163\\text{Low}\\)\n\ncat(\"1970 SST = \", SST_1970,\", df = 8\")\ncat(\"\\n1970 SSR = \", SSR_1970,\", df = 1\")\ncat(\"\\n1970 SSE = \", SSE_1970, \", df = 7\")\n\n1970 SST =  1.573756 , df = 8\n1970 SSR =  0.005528037 , df = 1\n1970 SSE =  1.56826 , df = 7\n\n\n검정통계량\n\\(F_0 = \\frac{SSE(R) - SSE(F)}{df_R} - \\times \\frac{df_F}{SSE(F)}\\)\n\nSSE_F = SSE_1960 + SSE_1970\ndf_F = 6 + 7\n\n\nSSE_R = SSE\ndf_R = 15\n\n\nF_0 = (SSE_R - SSE_F)/(df_R - df_F) / (SSE_F/df_F)\nF_0\n\n42.8273639841797\n\n\n\ndf_R - df_F\n\n2\n\n\n\ndf_F\n\n13\n\n\n\nF_stan = qf(0.95,2,13)\n\n\ncat(F_0, \" 는 유의수준 0.05에서 F값 \", F_stan , \" 보다 크다.\")\n\ncat(\"\\n따라서 귀무가설을 기각하였고, 두 회귀모형은 beta0가 다르거나\")\n\ncat(\"\\n혹은 beta1이 다르거나 혹은 beta0,beta1 모두가 다르다.\")\n\n42.82736  는 유의수준 0.05에서 F값  3.805565  보다 크다.\n따라서 귀무가설을 기각하였고, 두 회귀모형은 beta0가 다르거나\n혹은 beta1이 다르거나 혹은 beta0,beta1 모두가 다르다."
  },
  {
    "objectID": "posts/rl/2022-10-23-rl-HW2.html#section-13",
    "href": "posts/rl/2022-10-23-rl-HW2.html#section-13",
    "title": "Regression HW 2",
    "section": "(6)",
    "text": "(6)\n(4)에서 구한 두 회귀모형의 기울기가 같은지 유의수준 \\(\\alpha = 0.01\\)에서 검정하시오.\nAnswer\n기울기 비교에 대한 가설\n\\(H_0 : \\beta_{11} = \\beta_{12} \\text{ vs. } H_1 : \\beta_{11} \\neq \\beta_{12}\\)\n검정통계량\n\\(t_0 = \\frac{ \\hat{\\beta}_{11} - \\hat{\\beta}_{12} }{ \\sqrt{ \\hat{Var}( \\hat{\\beta}_{11} - \\hat{\\beta}_{12} ) } }\\)\n\\(\\text{Degree of Freedom} = t((n_1 - 1) + (n_2 - 1))\\)\n\\(\\hat{Var}( \\hat{\\beta}_{11} - \\hat{\\beta}_{12} ) = MSE(F) [\\frac{1}{\\sum(x_{1j} - \\bar{x}_1)^2} + \\frac{1}{\\sum(x_{2j} - \\bar{x}_2)^2}]\\)\n\nround(beta1_1960,4)\n\n-0.2492\n\n\n\nround(beta1_1970,4)\n\n0.0163\n\n\n\nSSE_F\n\n3.02342329210101\n\n\n\nMSE_F = SSE_F / df_F\nMSE_F\n\n0.232571022469308\n\n\n\nsum(df_6_1960$Low_barLow2)\n\n15.08995\n\n\n\nsum(df_6_1970$Low_barLow2)\n\n20.7903555555556\n\n\n\nvar_diff = MSE_F * (1/sum(df_6_1960$Low_barLow2) + 1/sum(df_6_1970$Low_barLow2))\nvar_diff\n\n0.026598798385161\n\n\n\nt_0 = (beta1_1960 - beta1_1970)/sqrt(var_diff)\nt_0\n\n-1.62782282241728\n\n\n\nqt(0.995,df_F)\n\n3.01227583871658\n\n\n\ncat(t_0,\"는 \",qt(0.995,df_F),\"보다 작다.\")\n\ncat(\"\\n따라서 유의수준 1%에서 귀무가설을 기각하지 못하여 두 회귀모형의 기울기가 같다고 할 수 있다.\")\n\n-1.627823 는  3.012276 보다 작다.\n따라서 유의수준 1%에서 귀무가설을 기각하지 못하여 두 회귀모형의 기울기가 같다고 할 수 있다.\n\n\n\\(H_0 : \\beta_{11} = \\beta_{12}\\) 채택"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html",
    "href": "posts/rl/2022-11-21-rl-HW3.html",
    "title": "Regression HW 3",
    "section": "",
    "text": "고급회귀분석 과제, CH03,07\n고급회귀분석 세번째 과제입니다.\n제출 기한 : 11월 21일\n제출 방법\n(pdf 아닌 문서는 미제출로 간주)\n주의사항\n예) R에서 lm으로 beta의 추정량을 구하면 안 됨. 수업 시간에 배운 식으로 풀이를 적어야 함.\n************ R을 이용해서 푸는 문제는, R 코드도 같이 업로드."
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-1",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-1",
    "title": "Regression HW 3",
    "section": "(1)",
    "text": "(1)\n\\(X^\\top X, X^\\top y, y^\\top y\\)와 \\((X^\\top X)^{-1}\\)을 구하시오.\n\nxx &lt;- t(x) %*% x\n\n\nxx\n\n\nA matrix: 2 × 2 of type dbl\n\n\n14\n62\n\n\n62\n360\n\n\n\n\n\n\nxy &lt;- t(x) %*% y\n\n\nxy\n\n\nA matrix: 2 × 1 of type dbl\n\n\n1253\n\n\n6714\n\n\n\n\n\n\nyy &lt;- t(y) %*% y\n\n\nyy\n\n\nA matrix: 1 × 1 of type dbl\n\n\n138197\n\n\n\n\n\n\nxx_i &lt;- solve(xx)\n\n\nxx_i\n\n\nA matrix: 2 × 2 of type dbl\n\n\n0.30100334\n-0.05183946\n\n\n-0.05183946\n0.01170569"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-2",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-2",
    "title": "Regression HW 3",
    "section": "(2)",
    "text": "(2)\n\\(\\hat{\\beta} = (X^\\top X)^{-1}X^\\top y\\)를 구하고, 적합된 회귀선형을 써 보아라.\n\nbetahat &lt;- xx_i %*%  xy\n\n\nbetahat\n\n\nA matrix: 2 × 1 of type dbl\n\n\n29.10702\n\n\n13.63712\n\n\n\n\n\n\\(y = 29.1 + 13.6x\\)\n\ncoef(lm(y~x, dt))\n\n(Intercept)29.1070234113712x13.6371237458194"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-3",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-3",
    "title": "Regression HW 3",
    "section": "(3)",
    "text": "(3)\n\\(\\sigma^2\\)을 MSE 로 추정할 경우, \\(\\hat{\\beta}\\)의 분산-공분산행렬의 추정은 \\(\\hat{Var}(\\hat{\\beta}) = (X^\\top X)^{-1}\\)(MSE)이다. 먼저 분산분석하여 MSE 를 구하고 \\(\\hat{Var}(\\hat{\\beta})\\)을 구하시오\n\nn &lt;- 14\n\n\np &lt;- 1\n\n\nIn = diag(rep(1,n))\n\n\nH = x %*% xx_i %*% t(x)\n\n\\(SSE = y^\\top(I-H)y\\)\n\\(SST = y^\\top y - n(\\bar{y})^2\\)\n\nsse = t(y) %*% (In-H) %*% y\nsse\n\n\nA matrix: 1 × 1 of type dbl\n\n\n10166.25\n\n\n\n\n\n\nsst = t(y) %*% y - n * mean(y)^2\nsst\n\n\nA matrix: 1 × 1 of type dbl\n\n\n26053.5\n\n\n\n\n\n\nssr = sst- sse\nssr\n\n\nA matrix: 1 × 1 of type dbl\n\n\n15887.25\n\n\n\n\n\n\nmsr = ssr/p\nmsr\n\n\nA matrix: 1 × 1 of type dbl\n\n\n15887.25\n\n\n\n\n\n\nmse = sse/(n-p-1)\nmse\n\n\nA matrix: 1 × 1 of type dbl\n\n\n847.1876\n\n\n\n\n\n\nf0 = msr/mse\nf0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n18.75293\n\n\n\n\n\n\nqf(0.95,p,n-p-1)\n\n4.74722534672251\n\n\n분산분석표\n\n\n\n요인\n제곱합\n자유도(df)\n평균제곱(MS)\n\\(F_0\\)\n유의확률\n\n\n\n\n회귀\n15887.25\n1\n15887.25\n18.75293\n4.747225\n\n\n잔차\n10166.25\n12\n847.19\n\n\n\n\n계\n26053.5\n13\n\n\n\n\n\n\n\nhat_var_betahat &lt;- mse[,] * xx_i\n\n\nvcov(lm(y~x, dt))\n\n\nA matrix: 2 × 2 of type dbl\n\n\n\n(Intercept)\nx\n\n\n\n\n(Intercept)\n255.00629\n-43.917750\n\n\nx\n-43.91775\n9.916911"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-5",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-5",
    "title": "Regression HW 3",
    "section": "(1)",
    "text": "(1)\n선형회귀모형, \\(y_j = \\beta_0 + \\beta_1 x_{1j} + \\beta_2 x_{2j} + \\epsilon_j\\) 가 성립된다고 가정하고 데이터로부터 회귀모형을 추정하시오.\n\nx = matrix(c(rep(1,8),dt$x1, dt$x2), ncol=3)\n\n\ny = dt$y\n\n\nxx &lt;- t(x) %*% x\nxx\n\n\nA matrix: 3 × 3 of type dbl\n\n\n8\n1587\n474\n\n\n1587\n315745\n94108\n\n\n474\n94108\n28136\n\n\n\n\n\n\nxx_i &lt;- solve(xx)\nxx_i\n\n\nA matrix: 3 × 3 of type dbl\n\n\n82.8749894\n-0.134598917\n-0.945973490\n\n\n-0.1345989\n0.001242266\n-0.001887521\n\n\n-0.9459735\n-0.001887521\n0.022285408\n\n\n\n\n\n\nxy &lt;- t(x) %*% y\nxy\n\n\nA matrix: 3 × 1 of type dbl\n\n\n901.9\n\n\n179676.4\n\n\n54034.3\n\n\n\n\n\n\nyy &lt;- t(y) %*% y\nyy\n\n\nA matrix: 1 × 1 of type dbl\n\n\n110959\n\n\n\n\n\n\nb &lt;- xx_i %*% xy\nb\n\n\nA matrix: 3 × 1 of type dbl\n\n\n-554.3112232\n\n\n-0.1797396\n\n\n11.8599927\n\n\n\n\n\n\\(y = -554.31 - 0.1797 x_1 + 11.86 x_2\\)"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-6",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-6",
    "title": "Regression HW 3",
    "section": "(2)",
    "text": "(2)\n오차분산이 \\(\\sigma^2 = 3\\)이라 하면, \\(Var(\\hat{\\beta}_0), Var(\\hat{\\beta}_1), Var(\\hat{\\beta}_2)\\)와 \\(Cov(\\hat{\\beta}_1, \\hat{\\beta}_2)\\)는 무엇인가?\n\\(var(\\hat{\\beta}) = (x^\\top x)^{-1} \\sigma^2\\)\n\nxx_i * 3\n\n\nA matrix: 3 × 3 of type dbl\n\n\n248.6249683\n-0.403796751\n-2.837920471\n\n\n-0.4037968\n0.003726798\n-0.005662562\n\n\n-2.8379205\n-0.005662562\n0.066856223\n\n\n\n\n\n\\(var(\\hat{\\beta}_0) = 248.6250\\)\n\\(var(\\hat{\\beta}_1) = 0.0037\\)\n\\(var(\\hat{\\beta}_2) = 0.0669\\)\n\\(cov(\\hat{\\beta}_1, \\hat{\\beta}_2) = -0.0057\\)"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-7",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-7",
    "title": "Regression HW 3",
    "section": "(3)",
    "text": "(3)\n\\(x_1 = 200\\)°C이고 \\(x_2 = 59\\text{psi}\\)에서 평균 제품의 강도의 추정값 \\(\\hat{y}\\)는 얼마인가? 이의 분산을 \\(\\sigma^2 = 3\\)이라 가정하고 구하시오.\n\nnew_dt &lt;- data.frame(x1=200, x2=59)\nnew_dt\n\n\nA data.frame: 1 × 2\n\n\nx1\nx2\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n200\n59\n\n\n\n\n\n\npredict(m2, newdata = new_dt)\n\n1: 109.480424963516\n\n\n\nx0 &lt;- c(1,200,59)\nx0\n\n\n120059\n\n\n\nmu0 &lt;- x0 %*% b\nmu0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n109.4804\n\n\n\n\n\n\\(\\hat{\\mu}_0 = 109.4804\\)"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-8",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-8",
    "title": "Regression HW 3",
    "section": "(4)",
    "text": "(4)\n추정된 회귀계수 \\(\\hat{\\beta}_1, \\hat{\\beta}_2\\)의 의미는 무엇인가?\n\\(\\hat{\\beta}_1\\) : 공정압력이 일정하게 유지되었을 때, 공정온도가 1도씨 증가하면 강도는 0.1797만큼 감소한다.\n\\(\\hat{\\beta}_2\\) : 공정온도가 일정하게 유지되었을 때, 공정압력이 1psi 증가하면 강도는 11.8600만큼 증가한다."
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-9",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-9",
    "title": "Regression HW 3",
    "section": "(5)",
    "text": "(5)\n분산분석표를 작성하고 \\(\\alpha = 0.05\\)로 \\(F\\)-검정을 행하시오.\n\nanova(m2)\n\n\nA anova: 3 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nx1\n1\n628.467\n628.4670\n1.342371\n0.29894191\n\n\nx2\n1\n6311.728\n6311.7278\n13.481505\n0.01441752\n\n\nResiduals\n5\n2340.884\n468.1768\nNA\nNA\n\n\n\n\n\n\nI8 = diag(rep(1,8))\nI8\n\n\nA matrix: 8 × 8 of type dbl\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n1\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n1\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n1\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n1\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n\n\n\n\nH = x %*% xx_i %*% t(x)\nH\n\n\nA matrix: 8 × 8 of type dbl\n\n\n0.223303342\n0.0473478224\n0.0925307250\n0.004932881\n0.04854185\n0.354021685\n0.18034566\n0.04897604\n\n\n0.047347822\n0.7875815614\n0.0003377034\n0.178850120\n0.18539614\n0.121730006\n-0.28766297\n-0.03358038\n\n\n0.092530725\n0.0003377034\n0.1733021360\n0.174906227\n0.15025388\n0.004944942\n0.19895553\n0.20476885\n\n\n0.004932881\n0.1788501200\n0.1749062270\n0.274444297\n0.21838554\n-0.166837528\n0.08255641\n0.23276205\n\n\n0.048541845\n0.1853961381\n0.1502538806\n0.218385537\n0.18446745\n-0.053127978\n0.08195337\n0.18412975\n\n\n0.354021685\n0.1217300062\n0.0049449423\n-0.166837528\n-0.05312798\n0.711046519\n0.14493505\n-0.11671270\n\n\n0.180345664\n-0.2876629720\n0.1989555317\n0.082556415\n0.08195337\n0.144935052\n0.38255762\n0.21635932\n\n\n0.048976035\n-0.0335803794\n0.2047688541\n0.232762052\n0.18412975\n-0.116712699\n0.21635932\n0.26329707\n\n\n\n\n\n\\(SSE = y^\\top (I-H)y\\)\n\\(SST = y^\\top y - n(\\bar{y})^2\\)\n\nsse = t(y) %*% (I8-H) %*% y\nsse\n\n\nA matrix: 1 × 1 of type dbl\n\n\n2340.884\n\n\n\n\n\n\nsst = t(y) %*% y - 8 * mean(y)^2\nsst\n\n\nA matrix: 1 × 1 of type dbl\n\n\n9281.079\n\n\n\n\n\n\nssr = sst- sse\nssr\n\n\nA matrix: 1 × 1 of type dbl\n\n\n6940.195\n\n\n\n\n\n\nmsr = ssr/2\nmsr\n\n\nA matrix: 1 × 1 of type dbl\n\n\n3470.097\n\n\n\n\n\n\nmse = sse/5\nmse\n\n\nA matrix: 1 × 1 of type dbl\n\n\n468.1768\n\n\n\n\n\n\nf0 = msr/mse\nf0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n7.411938\n\n\n\n\n\n\nqf(0.95,2,5)\n\n5.78613504334997\n\n\n\n\n\n요인\n제곱합\n자유도(df)\n평균제곱(MS)\n\\(F_0\\)\n유의확률\n\n\n\n\n회귀\n6940.195\n2\n3470.097\n7.4119\n5.786135\n\n\n잔차\n2340.884\n5\n468.177\n\n\n\n\n계\n9281.079\n7\n\n\n\n\n\n\n결론 : 검정통계량의 관측값이 기각역에 속하므로 귀무가설 기각. 즉 모형이 유의수준 0.05하에서 유의하다고 할 수 있다."
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-10",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-10",
    "title": "Regression HW 3",
    "section": "(6)",
    "text": "(6)\n결정계수 \\(R^2\\)을 구하시오.\n\nsummary(m2)$r.squared\n\n0.747778895028607\n\n\n\\(R^2 = \\frac{SSR}{SST}\\)\n\nssr/sst\n# 0.7478\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.7477789"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-11",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-11",
    "title": "Regression HW 3",
    "section": "(7)",
    "text": "(7)\n수정된 결정계수 \\(R^2_{adj}\\) 을 구하시오.\n\nsummary(m2)$adj\n\n0.64689045304005\n\n\n\\(R^2_{adj} = 1-\\frac{SSE(n-p-1)}{SST/(n-1)}\\)\n\n1-(sse/5)/(sst/7)\n# 0.6469\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.6468905"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-12",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-12",
    "title": "Regression HW 3",
    "section": "(8)",
    "text": "(8)\n\\(\\sigma^2\\)의 추정값 MSE 를 구하시오.\n\\(\\sigma^2 = MSE\\)\n\nmse\n##468.17687\n\n\nA matrix: 1 × 1 of type dbl\n\n\n468.1768"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-13",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-13",
    "title": "Regression HW 3",
    "section": "(9)",
    "text": "(9)\nMSR의 기대값을 \\(\\sigma^2\\)과 \\(\\beta_0, \\beta_1, \\beta_2\\)의 함수로 표시하여라.\n\nI8 &lt;- diag(rep(1,8))\nI8\n\n\nA matrix: 8 × 8 of type dbl\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n1\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n1\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n1\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n1\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n\n\n\n\none1 &lt;- rep(1,8)\none1\n\n\n11111111\n\n\n\nJn &lt;- one1 %*% t(one1)\nJn\n\n\nA matrix: 8 × 8 of type dbl\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n\n\n\n\nt(x) %*% (I8 - Jn/8) %*% x\n\n\nA matrix: 3 × 3 of type dbl\n\n\n0\n0.000\n0.00\n\n\n0\n923.875\n78.25\n\n\n0\n78.250\n51.50"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-15",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-15",
    "title": "Regression HW 3",
    "section": "(1)",
    "text": "(1)\n데이터로부터 회귀모형, \\(\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 x_2 + \\hat{\\beta}_3 x_3\\) 을 구하여라. 그리고 어째서 이 모형이 선택되었는가에 대하여 토의하시오.\n\nx = matrix(c(rep(1,10),dt$x1, dt$x2, dt$x3), ncol=4)\n\n\ny = dt$y\n\n\nxx &lt;- t(x) %*% x\nxx\n\n\nA matrix: 4 × 4 of type dbl\n\n\n10\n191\n265\n638\n\n\n191\n3971\n5047\n12620\n\n\n265\n5047\n7049\n17038\n\n\n638\n12620\n17038\n43324\n\n\n\n\n\n\nxx_i &lt;- solve(xx)\nxx_i\n\n\nA matrix: 4 × 4 of type dbl\n\n\n42.8460778\n-0.274517258\n-1.666784957\n0.1044984818\n\n\n-0.2745173\n0.005399764\n0.009802163\n-0.0013851965\n\n\n-1.6667850\n0.009802163\n0.067921641\n-0.0050213139\n\n\n0.1044985\n-0.001385196\n-0.005021314\n0.0008624387\n\n\n\n\n\n\nxy &lt;- t(x) %*% y\nxy\n\n\nA matrix: 4 × 1 of type dbl\n\n\n34.6\n\n\n686.3\n\n\n916.0\n\n\n2249.9\n\n\n\n\n\n\nyy &lt;- t(y) %*% y\nyy\n\n\nA matrix: 1 × 1 of type dbl\n\n\n121.94\n\n\n\n\n\n\nb &lt;- xx_i %*% xy\nb\n\n\nA matrix: 4 × 1 of type dbl\n\n\n2.409213010\n\n\n0.069788005\n\n\n-0.024766597\n\n\n0.005864434\n\n\n\n\n\n\\(\\hat{y} = 2.409 + 0.0698x_1 - 0.0248x_2 + 0.0059x_3\\)"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-16",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-16",
    "title": "Regression HW 3",
    "section": "(2)",
    "text": "(2)\n\\(\\hat{\\beta}_1, \\hat{\\beta}_2\\)와 \\(\\hat{\\beta}_3\\)의 의미는 무엇인가?\n\\(\\hat{\\beta}_1\\) : 작업일수, 작업량이 변하지 않을 때, 평균온도가 1도씨 증가하면 물소비량은 69.8톤 증가한다.\n\\(\\hat{\\beta}_2\\) : 평균온도, 작업량이 변하지 않을 때, 작업일수가 1일 증가하면 물소비량은 24.8톤 감소한다.\n\\(\\hat{\\beta}_3\\) : 평균온도, 작업일수이 변하지 않을 때, 작업량이 1000톤 증가하면 물소비량은 5.9톤 증가한다."
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-17",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-17",
    "title": "Regression HW 3",
    "section": "(3)",
    "text": "(3)\n\\(Var(\\hat{\\beta}_3)\\)을 구하시오. \\(\\sigma^2\\)을 MSE 로 추정하면 \\(\\hat{Var}(\\hat{\\beta}_3)\\)은 무엇인가?\n\nsummary(m3)$coefficients\n\n\nA matrix: 4 × 4 of type dbl\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n2.409213010\n1.125953765\n2.1397087\n0.076181015\n\n\nx1\n0.069788005\n0.012640155\n5.5211353\n0.001485354\n\n\nx2\n-0.024766597\n0.044830038\n-0.5524554\n0.600595338\n\n\nx3\n0.005864434\n0.005051602\n1.1609058\n0.289775583\n\n\n\n\n\n\\(var(\\beta_3) = (x^\\top x)^{-1}_{(4,4)} \\sigma^2\\)\n\nxx_i[4,4]\n## 0.0009*sigma^2\n\n0.000862438702127396\n\n\n\nhat_var_b3 &lt;- xx_i[4,4] * mse\nhat_var_b3\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.4037738\n\n\n\n\n\n\\(var(\\hat{\\beta}_3) = 0.0000255\\)"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-18",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-18",
    "title": "Regression HW 3",
    "section": "(4)",
    "text": "(4)\n분산분석표를 작성하고, 결정계수 \\(R^2\\)을 구하시오.\n\nanova(m3)\n\n\nA anova: 4 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nx1\n1\n2.004315887\n2.004315887\n67.73858599\n0.0001737553\n\n\nx2\n1\n0.002273071\n0.002273071\n0.07682153\n0.7909535228\n\n\nx3\n1\n0.039877142\n0.039877142\n1.34770234\n0.2897755827\n\n\nResiduals\n6\n0.177533900\n0.029588983\nNA\nNA\n\n\n\n\n\n\nI10 = diag(rep(1,10))\nI10\n\n\nA matrix: 10 × 10 of type dbl\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n\n\n\n\nH = x %*% xx_i %*% t(x)\nH\n\n\nA matrix: 10 × 10 of type dbl\n\n\n0.479007503\n-0.005805719\n-0.08066882\n-0.01958705\n0.26225012\n0.09655116\n-0.23996631\n0.10866366\n0.28730870\n0.11224675\n\n\n-0.005805719\n0.186448902\n0.16479959\n0.27196857\n0.01139329\n0.10399383\n0.06627062\n0.18477003\n-0.01335934\n0.02952023\n\n\n-0.080668821\n0.164799589\n0.33179614\n0.23355629\n0.24558622\n-0.08987596\n0.23998739\n0.04338569\n-0.01509426\n-0.07347228\n\n\n-0.019587049\n0.271968566\n0.23355629\n0.48736361\n0.01178437\n0.05219047\n-0.10292798\n0.28777554\n-0.11085118\n-0.11127263\n\n\n0.262250120\n0.011393292\n0.24558622\n0.01178437\n0.58743384\n-0.22034983\n0.06947229\n-0.08527926\n0.20954991\n-0.09184095\n\n\n0.096551163\n0.103993827\n-0.08987596\n0.05219047\n-0.22034983\n0.36048096\n0.08217297\n0.20539705\n0.10911272\n0.30032662\n\n\n-0.239966310\n0.066270622\n0.23998739\n-0.10292798\n0.06947229\n0.08217297\n0.69646084\n-0.11029224\n0.06925883\n0.22956358\n\n\n0.108663660\n0.184770026\n0.04338569\n0.28777554\n-0.08527926\n0.20539705\n-0.11029224\n0.27283220\n0.01617393\n0.07657339\n\n\n0.287308704\n-0.013359337\n-0.01509426\n-0.11085118\n0.20954991\n0.10911272\n0.06925883\n0.01617393\n0.25886069\n0.18903998\n\n\n0.112246749\n0.029520231\n-0.07347228\n-0.11127263\n-0.09184095\n0.30032662\n0.22956358\n0.07657339\n0.18903998\n0.33931531\n\n\n\n\n\n\\(SSE = y^\\top (I-H)y\\)\n\\(SST = y^\\top y - n(\\bar{y})^2\\)\n\nsse = t(y) %*% (I10-H) %*% y\nsse\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.1775339\n\n\n\n\n\n\nsst = t(y) %*% y - 10 * mean(y)^2\nsst\n\n\nA matrix: 1 × 1 of type dbl\n\n\n2.224\n\n\n\n\n\n\nssr = sst- sse\nssr\n\n\nA matrix: 1 × 1 of type dbl\n\n\n2.046466\n\n\n\n\n\n\nmsr = ssr/3\nmsr\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.6821554\n\n\n\n\n\n\nmse = sse/6\nmse\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.02958898\n\n\n\n\n\n\nf0 = msr/mse\nf0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n23.05437\n\n\n\n\n\n\nqf(0.95,3,6)\n\n4.75706266308941\n\n\n\n\n\n요인\n제곱합\n자유도(df)\n평균제곱(MS)\n\\(F_0\\)\n유의확률\n\n\n\n\n회귀\n2.0465\n3\n0.6822\n23.0544\n4.7571\n\n\n잔차\n0.1775\n6\n0.0296\n\n\n\n\n계\n2.2240\n9\n\n\n\n\n\n\n\\(R^2\\)\n\nssr/sst\n#0.9202\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.9201736"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-19",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-19",
    "title": "Regression HW 3",
    "section": "(5)",
    "text": "(5)\n\\(x_1 = 20, x_2 = 27, x_3 = 60\\)에서 평균 물소비량을 추정하시오. 이 추정된 소비량의 표준편차의 추정값을 구하시오.\n\nnew_dt &lt;- data.frame(x1=20, x2=27, x3 = 60)\nnew_dt\n\n\nA data.frame: 1 × 3\n\n\nx1\nx2\nx3\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n20\n27\n60\n\n\n\n\n\n\npredict(m3, newdata = new_dt)\n\n1: 3.48814105556645\n\n\n\nx0 &lt;- c(1,20,27,60)\nx0\n\n\n1202760\n\n\n\nmu0 &lt;- x0 %*% b\nmu0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n3.488141\n\n\n\n\n\n\\(\\hat{\\mu}_0 = 3.4881\\)\n\nvar_mu0 &lt;- (t(x0) %*% xx_i %*% x0) * mse\nvar_mu0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.005065205\n\n\n\n\n\n\nsqrt(var_mu0)\n# se(hat mu0) = 0.0712\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.07117026"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-20",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-20",
    "title": "Regression HW 3",
    "section": "(6)",
    "text": "(6)\n\\(x_1 = 20, x_2 = 27, x_3 = 60\\)에서 어느 한 달의 물소비량 \\(y_s\\) 를 예측하여라. 이 예측된 물소비량의 표준편차의 추정값을 구하시오.\n\nx0 &lt;- c(1,20,27,60)\nx0\n\n\n1202760\n\n\n\nmu0 &lt;- x0 %*% b\nmu0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n3.488141\n\n\n\n\n\n\\(\\hat{y}_s = 3.4881\\)\n\nvar_ys &lt;- (1+t(x0) %*% xx_i %*% x0) * mse\nvar_ys\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.03465419\n\n\n\n\n\n\nsqrt(var_ys)\n# se(hat ys) = 0.1862\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.1861564"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-21",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-21",
    "title": "Regression HW 3",
    "section": "(7)",
    "text": "(7)\n\\(y_j = \\beta_0 + \\beta_1 x_{1j} + \\beta_2 x_{2j} + \\epsilon_j\\) 라 가정하고 회귀제곱합 SSR의 기대값을 \\(\\sigma^2\\)과 \\(\\beta_i, i = 0, 1, 2, 3\\)의 함수로 표시하여라.\n\nI10 &lt;- diag(rep(1,10))\nI10\n\n\nA matrix: 10 × 10 of type dbl\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n\n\n\n\none1 &lt;- rep(1,10)\none1\n\n\n1111111111\n\n\n\nJn &lt;- one1 %*% t(one1)\nJn\n\n\nA matrix: 10 × 10 of type dbl\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n\n\n\n\nt(x) %*% (I10 - Jn/10) %*% x\n\n\nA matrix: 4 × 4 of type dbl\n\n\n6.661338e-16\n1.160183e-14\n1.751377e-14\n4.096723e-14\n\n\n-1.065814e-14\n3.229000e+02\n-1.450000e+01\n4.342000e+02\n\n\n-1.332268e-14\n-1.450000e+01\n2.650000e+01\n1.310000e+02\n\n\n-1.421085e-14\n4.342000e+02\n1.310000e+02\n2.619600e+03"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-22",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-22",
    "title": "Regression HW 3",
    "section": "(8)",
    "text": "(8)\n\\(\\beta_3\\)의 95% 신뢰구간을 구하시오. 이 신뢰구간의 의미를 해석하시오.\n\nconfint(m3)\n\n\nA matrix: 4 × 2 of type dbl\n\n\n\n2.5 %\n97.5 %\n\n\n\n\n(Intercept)\n-0.345896601\n5.16432262\n\n\nx1\n0.038858661\n0.10071735\n\n\nx2\n-0.134461748\n0.08492855\n\n\nx3\n-0.006496391\n0.01822526\n\n\n\n\n\n\\(\\beta_3 \\pm t_{0.025}(6) se(\\hat{\\beta}_3)\\)\n\nb[4] - qt(0.975,6) * sqrt(hat_var_b3)\n\n\nA matrix: 1 × 1 of type dbl\n\n\n-1.548982\n\n\n\n\n\n\nb[4] + qt(0.975,6) * sqrt(hat_var_b3)\n\n\nA matrix: 1 × 1 of type dbl\n\n\n1.56071\n\n\n\n\n\n\n#(-0.0065, 0.0182)\n\n이 신뢰구간이 \\(\\beta_3\\)을 포함하고 있을 것이라고 95% 확신한다."
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-23",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-23",
    "title": "Regression HW 3",
    "section": "(9)",
    "text": "(9)\n\\(\\beta_1\\)의 99% 신뢰구간을 구하시오. 이 신뢰구간의 의미를 해석하시오.\n\nconfint(m3, level=0.99)\n\n\nA matrix: 4 × 2 of type dbl\n\n\n\n0.5 %\n99.5 %\n\n\n\n\n(Intercept)\n-1.76517953\n6.58360555\n\n\nx1\n0.02292554\n0.11665047\n\n\nx2\n-0.19097074\n0.14143754\n\n\nx3\n-0.01286402\n0.02459289\n\n\n\n\n\n\\(\\beta_1 \\pm t_{0.005}(6) se(\\hat{\\beta}_1)\\)\n\nhat_var_b1 = xx_i[2,2] * mse\nhat_var_b1\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.0001597735\n\n\n\n\n\n\nb[2] - qt(0.995,6) * sqrt(hat_var_b1)\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.02292554\n\n\n\n\n\n\nb[2] + qt(0.995,6) * sqrt(hat_var_b1)\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.1166505\n\n\n\n\n\n\n#(0.0229, 0.1167)\n\n이 신뢰구간이 \\(\\beta_1\\)을 포함하고 있을 것이라고 99% 확신한다."
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-24",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-24",
    "title": "Regression HW 3",
    "section": "(10)",
    "text": "(10)\n\\(x_1 = 20, x_2 = 27, x_3 = 60\\)에서 평균 물소비량, \\(E(y)\\)의 95% 신뢰구간을 구하시오.\n\npredict(m3, newdata = new_dt, interval = c(\"confidence\"))\n\n\nA matrix: 1 × 3 of type dbl\n\n\n\nfit\nlwr\nupr\n\n\n\n\n1\n3.488141\n3.313994\n3.662288\n\n\n\n\n\n\nmu0 - qt(0.975,6) * sqrt(var_mu0)\n\n\nA matrix: 1 × 1 of type dbl\n\n\n3.313994\n\n\n\n\n\n\nmu0 + qt(0.975,6) * sqrt(var_mu0)\n\n\nA matrix: 1 × 1 of type dbl\n\n\n3.662288\n\n\n\n\n\n\n#(3.3140, 3.6623)"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-25",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-25",
    "title": "Regression HW 3",
    "section": "(11)",
    "text": "(11)\n가설 \\(H_0 : \\beta_1 = 0, H_1 : \\beta_1 &gt; 0\\)을 \\(\\alpha = 0.05\\)로 검정하시오.\n\nsummary(m3)\n\n\nCall:\nlm(formula = y ~ ., data = dt)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23490 -0.07744 -0.02166  0.08840  0.23442 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  2.409213   1.125954   2.140  0.07618 . \nx1           0.069788   0.012640   5.521  0.00149 **\nx2          -0.024767   0.044830  -0.552  0.60060   \nx3           0.005864   0.005052   1.161  0.28978   \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.172 on 6 degrees of freedom\nMultiple R-squared:  0.9202,    Adjusted R-squared:  0.8803 \nF-statistic: 23.05 on 3 and 6 DF,  p-value: 0.001079\n\n\n검정통계량 : \\(t_0 = \\frac{\\hat{\\beta}_1}{se(\\hat{\\beta}_1)}\\)\n\nt0 &lt;- b[2]/sqrt(hat_var_b1)\nt0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n5.521135\n\n\n\n\n\n\\(t_0 = 5.5211\\)\n기각역 : \\(t_{0.05}(6) = 1.9432\\)\n\nqt(0.95,6)\n\n1.9431802805153\n\n\n결론 : \\(H_0\\) 기각 가능. 즉 유의수준 5%에서 \\(\\beta_2\\)는 0보다 크다고 할 수 있다.\n\\(T = \\frac{\\hat{\\beta}_i - \\beta^0_i}{\\hat{\\sigma} \\sqrt{c_{ii}}}\\)"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-26",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-26",
    "title": "Regression HW 3",
    "section": "(12)",
    "text": "(12)\n가설 \\(H_0 : \\beta_1 = \\beta_2 = \\beta_3\\)을 \\(\\alpha = 0.05\\)로 검정하시오.\n\nlibrary(car) \n\nLoading required package: carData\n\n\n\n\nlinearHypothesis(m3, matrix(c(0,1,-1,0,0,0,1,-1), byrow = T, nrow=2),c(0,0))\n\n\nA anova: 2 × 6\n\n\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n8\n1.1224764\nNA\nNA\nNA\nNA\n\n\n2\n6\n0.1775339\n2\n0.9449425\n15.96781\n0.003956509\n\n\n\n\n\n\\(H_0 : \\beta_1 = \\beta_2 = \\beta_3\\)\n\\(T= (0,1,-1,0) (0,0,1,-1)\\)\n\\(y= \\beta_0 + \\beta_1 x_1 + \\beta_1 x_2 + \\beta_1 x_3 + \\epsilon = \\beta_0 + \\beta_1(x_1+x_2+x_3)\\)\n\nz &lt;- matrix(c(rep(1,10), dt$x1+dt$x2+dt$x3), ncol=2)\nz\n\n\nA matrix: 10 × 2 of type dbl\n\n\n1\n101\n\n\n1\n122\n\n\n1\n133\n\n\n1\n142\n\n\n1\n126\n\n\n1\n87\n\n\n1\n95\n\n\n1\n116\n\n\n1\n93\n\n\n1\n79\n\n\n\n\n\n\nzz &lt;- t(z) %*% z\nzz\n\n\nA matrix: 2 × 2 of type dbl\n\n\n10\n1094\n\n\n1094\n123754\n\n\n\n\n\n\nzz_i &lt;- solve(zz)\nzz_i\n\n\nA matrix: 2 × 2 of type dbl\n\n\n3.04034002\n-0.0268769654\n\n\n-0.02687697\n0.0002456761\n\n\n\n\n\n\nzy &lt;- t(z) %*% y\nzy\n\n\nA matrix: 2 × 1 of type dbl\n\n\n34.6\n\n\n3852.2\n\n\n\n\n\n\nyy &lt;- t(y) %*% y\nyy\n\n\nA matrix: 1 × 1 of type dbl\n\n\n121.94\n\n\n\n\n\n\nz %*% zz_i %*% t(z)\n\n\nA matrix: 10 × 10 of type dbl\n\n\n0.11733491\n0.073997642\n0.051297170\n0.03272406\n0.065742925\n0.146226415\n0.12971698\n0.08637972\n0.133844340\n0.162735849\n\n\n0.07399764\n0.139003538\n0.173054245\n0.20091392\n0.151385613\n0.030660377\n0.05542453\n0.12043042\n0.049233491\n0.005896226\n\n\n0.05129717\n0.173054245\n0.236831761\n0.28901336\n0.196246069\n-0.029874214\n0.01650943\n0.13826651\n0.004913522\n-0.076257862\n\n\n0.03272406\n0.200913915\n0.289013365\n0.36109473\n0.232950079\n-0.079402516\n-0.01533019\n0.15285967\n-0.031348270\n-0.143474843\n\n\n0.06574292\n0.151385613\n0.196246069\n0.23295008\n0.167698506\n0.008647799\n0.04127358\n0.12691627\n0.033117138\n-0.023977987\n\n\n0.14622642\n0.030660377\n-0.029874214\n-0.07940252\n0.008647799\n0.223270440\n0.17924528\n0.06367925\n0.190251572\n0.267295597\n\n\n0.12971698\n0.055424528\n0.016509434\n-0.01533019\n0.041273585\n0.179245283\n0.15094340\n0.07665094\n0.158018868\n0.207547170\n\n\n0.08637972\n0.120430425\n0.138266509\n0.15285967\n0.126916274\n0.063679245\n0.07665094\n0.11070165\n0.073408019\n0.050707547\n\n\n0.13384434\n0.049233491\n0.004913522\n-0.03134827\n0.033117138\n0.190251572\n0.15801887\n0.07340802\n0.166077044\n0.222484277\n\n\n0.16273585\n0.005896226\n-0.076257862\n-0.14347484\n-0.023977987\n0.267295597\n0.20754717\n0.05070755\n0.222484277\n0.327044025\n\n\n\n\n\n\ngammahat &lt;- zz_i %*% t(z) %*% y\ngammahat\n\n\nA matrix: 2 × 1 of type dbl\n\n\n1.66031840\n\n\n0.01645047\n\n\n\n\n\n\ne &lt;- y - z %*% gammahat\ne\n\n\nA matrix: 10 × 1 of type dbl\n\n\n-0.521816038\n\n\n0.232724057\n\n\n0.051768868\n\n\n0.403714623\n\n\n-0.633077830\n\n\n0.008490566\n\n\n0.276886792\n\n\n0.031426887\n\n\n-0.190212264\n\n\n0.340094340\n\n\n\n\n\n\nsse_rm &lt;- t(e) %*% e\nsse_rm\n\n\nA matrix: 1 × 1 of type dbl\n\n\n1.122476\n\n\n\n\n\n\nf0 = ((sse_rm - sse)/(2))/(sse/6)\nf0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n15.96781\n\n\n\n\n\n\nqf(0.95,2,6)\n\n5.14325284978472\n\n\n검정통계량 : \\(\\frac{(SSE_{RM} - SSE_{FM})/r}{SSE_{FM}/(n-p-1)}\\)\n관측값 \\(f_0 = 15.968\\)\n기각역 : \\(f_0 &gt; 5.1433\\)\n결론 : 기각할 수 있다."
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-27",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-27",
    "title": "Regression HW 3",
    "section": "(13)",
    "text": "(13)\n가설 \\(H_0 : \\beta_1 = \\beta_2 + 3\\)을 \\(\\alpha = 0.05\\)로 검정하시오.\n\\(H_0 : \\beta_1 = \\beta_2 = \\beta_3\\)\n\\(T= (0,1,-1,0)\\)\n\\(y = \\beta_0 + (\\beta_2+3)x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\epsilon\\) \\(y - 3x_1 = \\beta_0 + \\beta_2(x_1 + x_2) + \\beta_3 x_3 + \\epsilon\\)\n\nyy &lt;- y-3*dt$x1\nyy\n\n\n-27.2-68.1-71.1-79.6-41.9-50.9-62.5-62.4-33-41.7\n\n\n\nz &lt;- matrix(c(rep(1,10), dt$x1+dt$x2,dt$x3), ncol=3)\nz\n\n\nA matrix: 10 × 3 of type dbl\n\n\n1\n37\n64\n\n\n1\n50\n72\n\n\n1\n53\n80\n\n\n1\n54\n88\n\n\n1\n45\n81\n\n\n1\n42\n45\n\n\n1\n49\n46\n\n\n1\n47\n69\n\n\n1\n39\n54\n\n\n1\n40\n39\n\n\n\n\n\n\nzz &lt;- t(z) %*% z\nzz\n\n\nA matrix: 3 × 3 of type dbl\n\n\n10\n456\n638\n\n\n456\n21114\n29658\n\n\n638\n29658\n43324\n\n\n\n\n\n\nzz_i &lt;- solve(zz)\nzz_i\n\n\nA matrix: 3 × 3 of type dbl\n\n\n6.76054651\n-0.160413550\n0.0102556645\n\n\n-0.16041355\n0.005038964\n-0.0010871974\n\n\n0.01025566\n-0.001087197\n0.0006163093\n\n\n\n\n\n\ngammahat &lt;- zz_i %*% t(z) %*% yy\ngammahat\n\n\nA matrix: 3 × 1 of type dbl\n\n\n77.7140851\n\n\n-3.1683286\n\n\n0.2025345\n\n\n\n\n\n\ne &lt;- yy - z %*% gammahat\ne\n\n\nA matrix: 10 × 1 of type dbl\n\n\n-0.6481331\n\n\n-1.9801368\n\n\n2.9045732\n\n\n-4.0473741\n\n\n6.5554097\n\n\n-4.6583347\n\n\n5.7174312\n\n\n-5.1775193\n\n\n1.9138690\n\n\n-0.5797851\n\n\n\n\n\n\nsse_rm &lt;- t(e) %*% e\nsse_rm\n\n\nA matrix: 1 × 1 of type dbl\n\n\n157.327\n\n\n\n\n\n\nf0 = ((sse_rm - sse)/(1))/(sse/6)\nf0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n5311.082\n\n\n\n\n\n\nqf(0.95,1,6)\n\n5.9873776072737\n\n\n검정통계량 : \\(\\frac{(SSE_RM - SSE_FM)/r)}{(SSE_FM/(n-p-1))}\\)\n관측값 \\(f_0 = 5311.082\\)\n기각역 : \\(f_0 &gt; 5.9874\\)\n결론 : 기각할 수 있다."
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-28",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-28",
    "title": "Regression HW 3",
    "section": "(14)",
    "text": "(14)\n\\(x_1 = 20, x_2 = 27, x_3 = 60\\)에서 \\(E(y)\\)에 관한 가설 \\(H_0 : E(y) = 3.5, H_1 : E(y) ̸\\neq 3.5\\)를 \\(\\alpha = 0.05\\)로 검정하시오.\nsy 풀이\n\\(T_0 = \\frac{\\hat{y} - E(y)}{\\sqrt{Var{\\hat{y}}}} = \\frac{\\hat{y} - E(Y)}{\\sqrt{x^\\top (X^\\top X)^{-1} x MSE}} \\sim t(n-1)\\)\n\nx_indi &lt;- matrix(c(1,20,27,60),nrow=1,ncol=4)\n\n\nyhat &lt;- x_indi %*% b\nround(yhat,5)\n\n\nA matrix: 1 × 1 of type dbl\n\n\n3.48814\n\n\n\n\n\n\\(Var{y} = x_i (X^\\top X)^{-1} x_i^\\top \\sigma^2\\)\n\nvar_y &lt;- ((x_indi %*%solve(t(x) %*% x) %*% t(x_indi) ) * mse)[,]\nround(var_y,5)\n\n0.00507\n\n\n\nt_0 &lt;- (yhat - 3.5)/sqrt(var_y)\nround(t_0[,],5)\n\n-0.16663\n\n\n\nround(-pt(0.025,9),5)\n\n-0.5097\n\n\n\\(F_0=-0.16663\\) &gt; \\(t_{0.025}(9)=-0.5097\\) 로 귀무가설을 기각하지 못하여 \\(E(y) = 3.5\\)라는 결론이 나온다."
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-31",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-31",
    "title": "Regression HW 3",
    "section": "(1)",
    "text": "(1)\n\\(Cov(e, y) = \\sigma^2[I_n − X(X^\\top X)^{-1}X^\\top]\\)\n\\(\\bf{e} = y - \\hat{y} = y - Hy = (I-H)y\\)\n\\(Cov(\\bf{e},y) = Cov((I-H)y,y) = (I-H)Var(y) = (I-H) \\sigma^2\\)\n\\(\\star Cov(Ax,y) = A Cov(X,Y)\\)\n\\(\\star Var(y) = \\sigma^2\\)"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-32",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-32",
    "title": "Regression HW 3",
    "section": "(2)",
    "text": "(2)\n\\(Cov(e, \\hat{y}) = \\mathbb{O}_n\\)\n\\(Cov(e(I - H)\\bf{y},Hy) = (I-H) Cov(y,y)H^\\top = (I-H)H\\sigma^2 = \\mathbb{O}_n \\sigma^2\\)\n\\(\\star Cov(Ax,By) = ACov(X,Y)B^\\top\\)\n\\(\\star H^\\top= H\\)\n\\(\\star H^2 = H\\)"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-33",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-33",
    "title": "Regression HW 3",
    "section": "(3)",
    "text": "(3)\n\\(Cov(e, \\hat{\\beta}) = \\mathbb{O}_{n\\times(k+1)}\\)\n\\(Cov((I-H)\\bf{y},(X^\\top X)^{-1} y) = (I-H) Cov(y,y) X (X^\\top X)^{-1} = (I - X(X^\\top X)^{-1} X^\\top ) X (X^\\top X)^{-1} \\sigma^2 = \\{ X(X^\\top X)^{-1} - X(X^\\top X)^{-1} \\} \\sigma^2 = \\mathbb{O}_{n \\times ([+1)}\\)"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-34",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-34",
    "title": "Regression HW 3",
    "section": "(4)",
    "text": "(4)\n\\(Cov(\\epsilon, \\hat{\\beta}) = \\sigma^2 X(X^\\top X)^{-1}\\)\n\\(\\bf{\\hat{\\beta}} = (X^\\top X)^{-1} X^\\top y = (X^\\top X)^{-1} X^\\top (X\\beta + \\epsilon) = \\beta + (X^\\top X)^{-1} X^\\top \\epsilon\\)\n\\(Cov(\\bf{\\epsilon} , \\beta + (X^\\top X)^{-1} X^\\top \\epsilon ) = Cov(\\epsilon, \\beta) + Cov(\\epsilon, \\epsilon)X(X^\\top X)^{-1} = \\sigma^2 X(X^\\top X)^{-1}\\)\n\\(\\star Cov(\\epsilon, \\beta) = 0\\)\n\\(\\star Cov(\\epsilon, \\epsilon) = I_n \\sigma^2\\)"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-35",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-35",
    "title": "Regression HW 3",
    "section": "(5)",
    "text": "(5)\n\\(\\sum^{n}_{j=1} e_j y_j = SSE\\)\n\\(\\sum^{n}_{j=1} e_j y_j = \\bf{e^\\top y} = \\{ (I - H)y\\}^\\top y = y^\\top (I-H)y\\)\n\\(\\star \\bf{e}^\\top (e_1, \\dots , e_n) = (y-\\hat{y})^\\top\\)\n\\(\\star \\bf{y}^\\top = (y_1 , \\dots , y_n)\\)\n\\(SSE = \\sum^n_{j=1} (y_i - \\hat{y}_j)^2 = (\\bf{y} - \\hat{y} ) ^\\top ( y - \\hat{y} ) = e^\\top e = \\{ (I - H)y \\}^\\top \\{ (I - H)y \\} = y^\\top (I - H) (I-H)y = y^\\top (I - H)y\\)\n\\(\\star I - H_H+H^2 = I-H, H^2 = H\\)\n\\(\\therefore \\sum^{n}_{j=1} e_j y_j = SSE\\)"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-36",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-36",
    "title": "Regression HW 3",
    "section": "(6)",
    "text": "(6)\n\\(\\sum^{n}_{j=1} e_j \\hat{y}_j = 0\\)\n\\(\\sum^{n}_{j=1} \\bf{e_j \\hat{y}_j} = e^\\top \\hat{y} = y^\\top (I-H) Hy = y^\\top_{1\\times n} \\mathbb{O}_{n\\times n} y_{n \\times 1} = 0\\)\n\\(\\star H - H^2 = H - H = \\mathbb{O}_{n \\times n}\\)"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-37",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-37",
    "title": "Regression HW 3",
    "section": "(1)",
    "text": "(1)\n\\(X^\\top X, X^\\top y y^\\top y\\)와 \\((X^\\top X)^{-1}\\) 을 구하시오.\n\nxx &lt;- t(x) %*% x\nxx\n\n\nA matrix: 3 × 3 of type dbl\n\n\n6\n13\n10\n\n\n13\n33\n23\n\n\n10\n23\n20\n\n\n\n\n\n\nxx_i &lt;- solve(xx)\nxx_i\n\n\nA matrix: 3 × 3 of type dbl\n\n\n1.5232558\n-0.34883721\n-0.36046512\n\n\n-0.3488372\n0.23255814\n-0.09302326\n\n\n-0.3604651\n-0.09302326\n0.33720930\n\n\n\n\n\n\nxx_i2 &lt;- round(xx_i,2)\nxx_i2\n\n\nA matrix: 3 × 3 of type dbl\n\n\n1.52\n-0.35\n-0.36\n\n\n-0.35\n0.23\n-0.09\n\n\n-0.36\n-0.09\n0.34\n\n\n\n\n\n\nxy &lt;- t(x) %*% y\nxy\n\n\nA matrix: 3 × 1 of type dbl\n\n\n13\n\n\n32\n\n\n15\n\n\n\n\n\n\nyy &lt;- t(y) %*% y\nyy\n\n\nA matrix: 1 × 1 of type dbl\n\n\n59"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-38",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-38",
    "title": "Regression HW 3",
    "section": "(2)",
    "text": "(2)\n\\(\\beta_0, \\beta_1, \\beta_2, \\sigma^2\\)를 추정하시오.\n\ncoef(m)\n\n(Intercept)3.23255813953489x11.51162790697674x2-2.6046511627907\n\n\n\nanova(m)$Mean[3]\n\n2.55813953488372\n\n\n\nb &lt;- xx_i %*% xy\nb\n\n\nA matrix: 3 × 1 of type dbl\n\n\n3.232558\n\n\n1.511628\n\n\n-2.604651\n\n\n\n\n\n\nb1 &lt;- round(round(xx_i,2)%*% xy,2)\nb1\n\n\nA matrix: 3 × 1 of type dbl\n\n\n3.16\n\n\n1.46\n\n\n-2.46\n\n\n\n\n\n\nhaty &lt;- x %*% b\nhaty\n\n\nA matrix: 6 × 1 of type dbl\n\n\n2.13953488\n\n\n3.65116279\n\n\n-0.46511628\n\n\n5.16279070\n\n\n2.55813953\n\n\n-0.04651163\n\n\n\n\n\n\nhaty_2 &lt;- round(x %*% b1,2)\nhaty_2\n\n\nA matrix: 6 × 1 of type dbl\n\n\n2.16\n\n\n3.62\n\n\n-0.30\n\n\n5.08\n\n\n2.62\n\n\n0.16\n\n\n\n\n\n\ne &lt;- y - haty\ne\n\n\nA matrix: 6 × 1 of type dbl\n\n\n-1.1395349\n\n\n1.3488372\n\n\n0.4651163\n\n\n-1.1627907\n\n\n1.4418605\n\n\n-0.9534884\n\n\n\n\n\n\ne_2 &lt;- y - haty_2\ne_2\n\n\nA matrix: 6 × 1 of type dbl\n\n\n-1.16\n\n\n1.38\n\n\n0.30\n\n\n-1.08\n\n\n1.38\n\n\n-1.16\n\n\n\n\n\n\nsse &lt;- t(e) %*% e\nsse\n\n\nA matrix: 1 × 1 of type dbl\n\n\n7.674419\n\n\n\n\n\n\nsse_2 &lt;- t(e_2) %*% e_2\nsse_2\n\n\nA matrix: 1 × 1 of type dbl\n\n\n7.7564\n\n\n\n\n\n\nmse &lt;- sse / 3\nmse\n\n\nA matrix: 1 × 1 of type dbl\n\n\n2.55814\n\n\n\n\n\n\nmse_2 &lt;- sse_2 / 3\nmse_2\n\n\nA matrix: 1 × 1 of type dbl\n\n\n2.585467"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-39",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-39",
    "title": "Regression HW 3",
    "section": "(3)",
    "text": "(3)\n\\(x_1 = x_2 = 2\\)에서 \\(E(y)\\)의 95% 신뢰구간을 구하시오.\n\nnew_dt &lt;- data.frame(x1=2, x2=2)\nnew_dt\n\n\nA data.frame: 1 × 2\n\n\nx1\nx2\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n2\n2\n\n\n\n\n\n\npredict(m, newdata = new_dt,interval = c(\"confidence\"), level = 0.95)\n\n\nA matrix: 1 × 3 of type dbl\n\n\n\nfit\nlwr\nupr\n\n\n\n\n1\n1.046512\n-1.345982\n3.439005\n\n\n\n\n\n\nx0 &lt;- c(1,2,2)\n\n\nmu0 &lt;- x0 %*% b\n\n\nt(x0) %*% xx_i %*% x0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.2209302\n\n\n\n\n\n\nvar_mu0 &lt;- (t(x0) %*% xx_i %*% x0) * mse\nvar_mu0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.5651704\n\n\n\n\n\n\ntse &lt;- qt(0.975,3) * sqrt(var_mu0)\ntse\n\n\nA matrix: 1 × 1 of type dbl\n\n\n2.392494\n\n\n\n\n\n\nmu0 - (tse)\n\n\nA matrix: 1 × 1 of type dbl\n\n\n-1.345982\n\n\n\n\n\n\nmu0 + (tse)\n\n\nA matrix: 1 × 1 of type dbl\n\n\n3.439005"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-40",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-40",
    "title": "Regression HW 3",
    "section": "(4)",
    "text": "(4)\n\\(\\beta_1\\)의 90% 신뢰구간을 구하시오.\n\nsummary(m)\n\n\nCall:\nlm(formula = y ~ ., data = dt)\n\nResiduals:\n      1       2       3       4       5       6 \n-1.1395  1.3488  0.4651 -1.1628  1.4419 -0.9535 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)   3.2326     1.9740   1.638   0.2000  \nx1            1.5116     0.7713   1.960   0.1449  \nx2           -2.6047     0.9288  -2.804   0.0676 .\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 1.599 on 3 degrees of freedom\nMultiple R-squared:  0.7511,    Adjusted R-squared:  0.5852 \nF-statistic: 4.527 on 2 and 3 DF,  p-value: 0.1242\n\n\n\nconfint(m, level = 0.9)\n\n\nA matrix: 3 × 2 of type dbl\n\n\n\n5 %\n95 %\n\n\n\n\n(Intercept)\n-1.4129961\n7.8781124\n\n\nx1\n-0.3035404\n3.3267962\n\n\nx2\n-4.7904032\n-0.4188991\n\n\n\n\n\n\nse_b1 &lt;- sqrt(xx_i[2,2] * mse)\nse_b1\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.7713081\n\n\n\n\n\n\ntse &lt;- qt(0.95,3) *se_b1\ntse\n\n\nA matrix: 1 × 1 of type dbl\n\n\n1.815168\n\n\n\n\n\n\nb[2] - tse\n\n\nA matrix: 1 × 1 of type dbl\n\n\n-0.3035404\n\n\n\n\n\n\nb[2] + tse\n\n\nA matrix: 1 × 1 of type dbl\n\n\n3.326796"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-41",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-41",
    "title": "Regression HW 3",
    "section": "(5)",
    "text": "(5)\n가설 \\(H_0: \\beta_1 = \\beta_2, H_1: \\beta_1 \\neq \\beta_2\\)을 유의수준 \\(\\alpha = 0.05\\)\n\nlibrary(car)\n\n\nlinearHypothesis(m, c(0,1,-1), 0)\n\n\nA anova: 2 × 6\n\n\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n4\n30.092308\nNA\nNA\nNA\nNA\n\n\n2\n3\n7.674419\n1\n22.41789\n8.763357\n0.05952979\n\n\n\n\n\n\nz &lt;- matrix(c(1,1,1,1,1,1,x[,2]+x[,3]), ncol=2)\n\n\nzz &lt;- t(z) %*% z\nzz\n\n\nA matrix: 2 × 2 of type dbl\n\n\n6\n23\n\n\n23\n99\n\n\n\n\n\n\nzz_i &lt;- solve(zz)\nzz_i\n\n\nA matrix: 2 × 2 of type dbl\n\n\n1.5230769\n-0.35384615\n\n\n-0.3538462\n0.09230769\n\n\n\n\n\n\nzy &lt;- t(z) %*% y\nzy\n\n\nA matrix: 2 × 1 of type dbl\n\n\n13\n\n\n47\n\n\n\n\n\n\nyy &lt;- t(y) %*% y\nyy\n\n\nA matrix: 1 × 1 of type dbl\n\n\n59\n\n\n\n\n\n\nz %*% zz_i %*% t(z)\n\n\nA matrix: 6 × 6 of type dbl\n\n\n0.47692308\n3.076923e-01\n3.076923e-01\n0.1384615\n-0.03076923\n-2.000000e-01\n\n\n0.30769231\n2.307692e-01\n2.307692e-01\n0.1538462\n0.07692308\n1.110223e-16\n\n\n0.30769231\n2.307692e-01\n2.307692e-01\n0.1538462\n0.07692308\n1.110223e-16\n\n\n0.13846154\n1.538462e-01\n1.538462e-01\n0.1692308\n0.18461538\n2.000000e-01\n\n\n-0.03076923\n7.692308e-02\n7.692308e-02\n0.1846154\n0.29230769\n4.000000e-01\n\n\n-0.20000000\n1.110223e-16\n1.110223e-16\n0.2000000\n0.40000000\n6.000000e-01\n\n\n\n\n\n\ngammahat &lt;- zz_i %*% t(z) %*% y\ngammahat\n\n\nA matrix: 2 × 1 of type dbl\n\n\n3.1692308\n\n\n-0.2615385\n\n\n\n\n\n\ne &lt;- y - z %*% gammahat\ne\n\n\nA matrix: 6 × 1 of type dbl\n\n\n-1.646154\n\n\n2.615385\n\n\n-2.384615\n\n\n1.876923\n\n\n2.138462\n\n\n-2.600000\n\n\n\n\n\n\nsse_rm &lt;- t(e) %*% e\nsse_rm\n\n\nA matrix: 1 × 1 of type dbl\n\n\n30.09231\n\n\n\n\n\n\nf0 = (sse_rm - sse)/(sse/3)\nf0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n8.763357\n\n\n\n\n\n\nqf(0.95,1,3)\n\n10.1279644860139\n\n\nT검정 방법\n\nq = c(0,1,-1)\n\n\nvar_qb = t(q) %*% xx_i %*% q*  mse\nvar_qb\n\n\nA matrix: 1 × 1 of type dbl\n\n\n1.933478\n\n\n\n\n\n\nse_qb = sqrt(var_qb)\nse_qb\n\n\nA matrix: 1 × 1 of type dbl\n\n\n1.390495\n\n\n\n\n\n\nt0 = (t(q) %*% b )/se_qb\nt0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n2.960297\n\n\n\n\n\n\nt0^2\n\n\nA matrix: 1 × 1 of type dbl\n\n\n8.763357"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-42",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-42",
    "title": "Regression HW 3",
    "section": "(6)",
    "text": "(6)\n가설 \\(H_0 : \\beta_1 = 0, H_1 : \\beta_1 \\neq 0\\)을 유의수준 \\(\\alpha = 0.1\\)로 검정하시오. 위 (3)의 질문의 결과와 어떠한 연관을 지을 수 있는가?\n\nt0 &lt;- b[2] / se_b1\n\n\nqt(0.95,3)\n\n2.35336343480182"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-43",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-43",
    "title": "Regression HW 3",
    "section": "(7)",
    "text": "(7)\n\\(x_1 = 2, x_2 = 3\\)에서 가설 \\(H_0 : E(y) = 4,H_1 : E(y) \\neq 4\\)를 \\(\\alpha = 0.05\\)로 검정하시오\n\nnew_dt &lt;- data.frame(x1=2, x2=2)\n\n\npredict(m, newdata = new_dt,interval = c(\"confidence\"), level = 0.95)\n\n\nA matrix: 1 × 3 of type dbl\n\n\n\nfit\nlwr\nupr\n\n\n\n\n1\n1.046512\n-1.345982\n3.439005\n\n\n\n\n\n\nx0 &lt;- c(1,2,3)\n\n\nmu0 &lt;- x0 %*% b\n\n\nt(x0) %*% xx_i %*% x0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.8139535\n\n\n\n\n\n\nvar_mu0 &lt;- (t(x0) %*% xx_i %*% x0) * mse\nvar_mu0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n2.082207\n\n\n\n\n\n\nt0 &lt;- (mu0-4)/ sqrt(var_mu0)\nt0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n-3.851834\n\n\n\n\n\n\nqt(0.975,3)\n\n3.18244630528371"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-44",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-44",
    "title": "Regression HW 3",
    "section": "(8)",
    "text": "(8)\n가설 \\(H_0 : \\beta_2 = 0, H_1: \\beta_2 &lt;0\\)을 \\(\\alpha = 0.05\\) 로 검정하시오.\n\nse_b2 &lt;- sqrt(xx_i[3,3] * mse)\nse_b2\n\n\nA matrix: 1 × 1 of type dbl\n\n\n0.9287779\n\n\n\n\n\n\nt0&lt;- b[3] / se_b2\nt0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n-2.804385"
  },
  {
    "objectID": "posts/rl/2022-11-21-rl-HW3.html#section-45",
    "href": "posts/rl/2022-11-21-rl-HW3.html#section-45",
    "title": "Regression HW 3",
    "section": "(9)",
    "text": "(9)\n가설 $H_0: _1 = 2_2, H_1 : _1 _2 $를 \\(\\alpha=0..05\\)로 검정하시오.\n\nlinearHypothesis(m, c(0,1,-2), 0)\n\n\nA anova: 2 × 6\n\n\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n4\n30.797619\nNA\nNA\nNA\nNA\n\n\n2\n3\n7.674419\n1\n23.1232\n9.039069\n0.05737101\n\n\n\n\n\n\nz &lt;- matrix(c(1,1,1,1,1,1,2*x[,2]+x[,3]), ncol=2)\n\n\nzz &lt;- t(z) %*% z\nzz\n\n\nA matrix: 2 × 2 of type dbl\n\n\n6\n36\n\n\n36\n244\n\n\n\n\n\n\nzz_i &lt;- solve(zz)\nzz_i\n\n\nA matrix: 2 × 2 of type dbl\n\n\n1.4523810\n-0.21428571\n\n\n-0.2142857\n0.03571429\n\n\n\n\n\n\nzy &lt;- t(z) %*% y\nzy\n\n\nA matrix: 2 × 1 of type dbl\n\n\n13\n\n\n79\n\n\n\n\n\n\nyy &lt;- t(y) %*% y\nyy\n\n\nA matrix: 1 × 1 of type dbl\n\n\n59\n\n\n\n\n\n\nz %*% zz_i %*% t(z)\n\n\nA matrix: 6 × 6 of type dbl\n\n\n0.48809524\n0.27380952\n0.38095238\n0.05952381\n-0.04761905\n-0.15476190\n\n\n0.27380952\n0.20238095\n0.23809524\n0.13095238\n0.09523810\n0.05952381\n\n\n0.38095238\n0.23809524\n0.30952381\n0.09523810\n0.02380952\n-0.04761905\n\n\n0.05952381\n0.13095238\n0.09523810\n0.20238095\n0.23809524\n0.27380952\n\n\n-0.04761905\n0.09523810\n0.02380952\n0.23809524\n0.30952381\n0.38095238\n\n\n-0.15476190\n0.05952381\n-0.04761905\n0.27380952\n0.38095238\n0.48809524\n\n\n\n\n\n\ngammahat &lt;- zz_i %*% t(z) %*% y\ngammahat\n\n\nA matrix: 2 × 1 of type dbl\n\n\n1.95238095\n\n\n0.03571429\n\n\n\n\n\n\ne &lt;- y - z %*% gammahat\ne\n\n\nA matrix: 6 × 1 of type dbl\n\n\n-1.059524\n\n\n2.869048\n\n\n-2.095238\n\n\n1.797619\n\n\n1.761905\n\n\n-3.273810\n\n\n\n\n\n\nsse_rm &lt;- t(e) %*% e\nsse_rm\n\n\nA matrix: 1 × 1 of type dbl\n\n\n30.79762\n\n\n\n\n\n\nf0 = (sse_rm - sse)/(sse/3)\nf0\n\n\nA matrix: 1 × 1 of type dbl\n\n\n9.039069\n\n\n\n\n\n\nqf(0.95,1,3)\n\n10.1279644860139"
  },
  {
    "objectID": "posts/rl/2023-03-02-graduation_test.html",
    "href": "posts/rl/2023-03-02-graduation_test.html",
    "title": "Advanced Regression Analysis GT",
    "section": "",
    "text": "GT"
  },
  {
    "objectID": "posts/rl/2023-03-02-graduation_test.html#section-1",
    "href": "posts/rl/2023-03-02-graduation_test.html#section-1",
    "title": "Advanced Regression Analysis GT",
    "section": "(1)",
    "text": "(1)\n\\(\\beta\\)에 대한 최소제곱추정량(\\(LSE\\)) \\(\\hat{\\beta}\\)을 구하시오\nanswer\n\\(\\hat{\\beta} = argmin_{\\beta \\in R} S = \\sum^n_{i=1} (y_i - \\beta x_i)^2 \\to \\frac{\\partial S}{\\partial \\beta}|_{\\beta = \\hat{\\beta}} = 0\\)\n\\(\\frac{\\partial S}{\\partial \\beta} = \\sum^n_{i=1} (-2x_i)(y_i - \\beta x_i) \\to \\sum^n_{i=1} x_i(y_i - \\hat{\\beta}x_i) = 0 \\to \\hat{\\beta} = \\frac{\\sum^n_{i=1} x_iy_i}{\\sum^n_{i=1} x^2_i}\\)"
  },
  {
    "objectID": "posts/rl/2023-03-02-graduation_test.html#section-2",
    "href": "posts/rl/2023-03-02-graduation_test.html#section-2",
    "title": "Advanced Regression Analysis GT",
    "section": "(2)",
    "text": "(2)\n\\(E(\\hat{\\beta})\\)을 구하시오\nanswer\n\\(\\hat{\\beta} = \\frac{\\sum^n_{i=1} x_i y_i}{\\sum^n_{i=1} x^2_i} = \\sum^n_{i=1} \\frac{x_i}{\\sum^n_{j=1} s^2_j} y_i\\)\n\\(\\to E(\\hat{\\beta})= \\sum^n_{i=1} \\frac{x_i}{\\sum^n_{i=1} x^2_j} E(y_i) = \\sum^n_{i=1}\\frac{x_i}{\\sum^n_{j=1} x^2_j} \\beta x_i = \\beta\\frac{\\sum^n_{i=1} x^2_{i=1} x^2_i}{\\sum^n_{i=1} x^2_i} = \\beta\\)"
  },
  {
    "objectID": "posts/rl/2023-03-02-graduation_test.html#section-3",
    "href": "posts/rl/2023-03-02-graduation_test.html#section-3",
    "title": "Advanced Regression Analysis GT",
    "section": "(3)",
    "text": "(3)\n\\(Var(\\hat{\\beta})\\)을 구하시오\nanswer\n\\(Var(\\hat{\\beta}) = \\sum^n_{i=1} \\frac{x^2_i}{(\\sum^n_{j=1} x^2_j)^2} Var(y_i) = \\sum^n_{i=1} \\frac{x^2_i}{(\\sum^n_{j=1} x^2_j)^2} \\sigma^2 = \\sigma^2 \\frac{\\sum^n_{i=1} x^2_i}{(\\sum^n_{i=1} x^2_i)^2} = \\frac{\\sigma^2}{\\sum^n_{i=1} x^2_i}\\)"
  },
  {
    "objectID": "posts/rl/2023-03-02-graduation_test.html#section-5",
    "href": "posts/rl/2023-03-02-graduation_test.html#section-5",
    "title": "Advanced Regression Analysis GT",
    "section": "(1)",
    "text": "(1)\n\\(\\sum^n_{j=1} Var(\\hat{y}_j) = (p+1) \\sigma^2\\)\nanswer\n\\(\\hat{\\bf{y}}= X\\hat{\\beta} = X(X^\\top X)^{-1} X^\\top y = Hy\\)\n\\(Var(X\\hat{\\beta}) = XVar(\\hat{\\beta})X^\\top\\)\n\\(Var(\\hat{\\beta}) = Var((X^\\top X)^{-1} X^\\top y) = (X^\\top X)^{-1} X^\\top Var(y)X(X^\\top X)^{-1} = (X^\\top X)^{-1} X^\\top X(X^\\top X)^{-1} \\sigma^2 = (X^\\top X )^{-1} \\sigma^2\\)\n\\(Var(\\hat{y}) = Var(X\\hat{\\beta}) = X(X^\\top X)^{-1} X^\\top \\sigma^2\\)\n\\(\\to Var(\\hat{y}) = HVar(y) H^\\top = HH\\sigma^2 = H\\sigma^2\\)\n\\(\\star H^\\top = H, H^2 = H, Var(y) = I_n \\sigma^2\\)\n\\(\\sum^{n}_{j=1} Var(\\hat{y}_j) = tr(Var(\\hat{y})) = tr(H\\sigma^2) = \\sigma^2 tr(H) = tr((X^\\top X)^{-1} X^\\top X)\\sigma^2 = tr(I_{p+1})\\sigma^2 = (p+1)\\sigma^2\\)\n\\(\\star tr(X (X^\\top X)^{-1} X^\\top)\\)"
  },
  {
    "objectID": "posts/rl/2023-03-02-graduation_test.html#section-6",
    "href": "posts/rl/2023-03-02-graduation_test.html#section-6",
    "title": "Advanced Regression Analysis GT",
    "section": "(2)",
    "text": "(2)\n\\(Cov(\\mathbf{e,y}) = \\sigma^2[I_n - X(X^\\top X)^{-1} X^\\top]\\)\nanswer\n\\(\\bf{e} = y - \\hat{y} = y - Hy = (I-H)y\\)\n\\(Cov(\\bf{e},y) = Cov((I-H)y,y) = (I-H)Var(y) = (I-H) \\sigma^2\\)\n\\(\\star Cov(Ax,y) = A Cov(X,Y)\\)\n\\(\\star Var(y) = \\sigma^2\\)"
  },
  {
    "objectID": "posts/rl/2023-03-02-graduation_test.html#section-7",
    "href": "posts/rl/2023-03-02-graduation_test.html#section-7",
    "title": "Advanced Regression Analysis GT",
    "section": "(3)",
    "text": "(3)\n\\(Cov(\\mathbf{e,\\hat{y}}) = O_n\\)\nanswer\n\\(Cov(e(I - H)\\bf{y},Hy) = (I-H) Cov(y,y)H^\\top = (I-H)H\\sigma^2 = \\mathbb{O}_n \\sigma^2\\)\n\\(\\star Cov(Ax,By) = ACov(X,Y)B^\\top\\)\n\\(\\star H^\\top= H\\)\n\\(\\star H^2 = H\\)"
  },
  {
    "objectID": "posts/rl/2023-03-02-graduation_test.html#section-8",
    "href": "posts/rl/2023-03-02-graduation_test.html#section-8",
    "title": "Advanced Regression Analysis GT",
    "section": "(4)",
    "text": "(4)\n\\(Cov(\\mathbf{e,\\hat{\\beta}}) = O_{n \\times (p+1)}\\)\nanswer\n\\(Cov((I-H)\\bf{y},(X^\\top X)^{-1} y) = (I-H) Cov(y,y) X (X^\\top X)^{-1} = (I - X(X^\\top X)^{-1} X^\\top ) X (X^\\top X)^{-1} \\sigma^2 = \\{ X(X^\\top X)^{-1} - X(X^\\top X)^{-1} \\} \\sigma^2 = \\mathbb{O}_{n \\times ([+1)}\\)"
  },
  {
    "objectID": "posts/rl/2023-03-02-graduation_test.html#section-9",
    "href": "posts/rl/2023-03-02-graduation_test.html#section-9",
    "title": "Advanced Regression Analysis GT",
    "section": "(5)",
    "text": "(5)\n\\(Cov(\\mathbf{\\epsilon, \\hat{\\beta}}) = \\sigma^2 X(X^\\top X)^{-1}\\)\nanswer\n\\(\\bf{\\hat{\\beta}} = (X^\\top X)^{-1} X^\\top y = (X^\\top X)^{-1} X^\\top (X\\beta + \\epsilon) = \\beta + (X^\\top X)^{-1} X^\\top \\epsilon\\)\n\\(Cov(\\bf{\\epsilon} , \\beta + (X^\\top X)^{-1} X^\\top \\epsilon ) = Cov(\\epsilon, \\beta) + Cov(\\epsilon, \\epsilon)X(X^\\top X)^{-1} = \\sigma^2 X(X^\\top X)^{-1}\\)\n\\(\\star Cov(\\epsilon, \\beta) = 0\\)\n\\(\\star Cov(\\epsilon, \\epsilon) = I_n \\sigma^2\\)"
  },
  {
    "objectID": "posts/rl/2023-03-02-graduation_test.html#section-10",
    "href": "posts/rl/2023-03-02-graduation_test.html#section-10",
    "title": "Advanced Regression Analysis GT",
    "section": "(6)",
    "text": "(6)\n\\(\\mathbf{e^\\top y} = SSE\\)\nanswer\n\\(\\sum^{n}_{j=1} e_j y_j = \\bf{e^\\top y} = \\{ (I - H)y\\}^\\top y = y^\\top (I-H)y\\)\n\\(\\star \\bf{e}^\\top (e_1, \\dots , e_n) = (y-\\hat{y})^\\top\\)\n\\(\\star \\bf{y}^\\top = (y_1 , \\dots , y_n)\\)\n\\(SSE = \\sum^n_{j=1} (y_i - \\hat{y}_j)^2 = (\\bf{y} - \\hat{y} ) ^\\top ( y - \\hat{y} ) = e^\\top e = \\{ (I - H)y \\}^\\top \\{ (I - H)y \\} = y^\\top (I - H) (I-H)y = y^\\top (I - H)y\\)\n\\(\\star I - H_H+H^2 = I-H, H^2 = H\\)\n\\(\\therefore \\sum^{n}_{j=1} e_j y_j = SSE\\)"
  },
  {
    "objectID": "posts/rl/2023-03-02-graduation_test.html#section-11",
    "href": "posts/rl/2023-03-02-graduation_test.html#section-11",
    "title": "Advanced Regression Analysis GT",
    "section": "(7)",
    "text": "(7)\n\\(\\mathbf{e^\\top \\hat{y}}=0\\)\nanswer\n\\(\\sum^{n}_{j=1} \\bf{e_j \\hat{y}_j} = e^\\top \\hat{y} = y^\\top (I-H) Hy = y^\\top_{1\\times n} \\mathbb{O}_{n\\times n} y_{n \\times 1} = 0\\)\n\\(\\star H - H^2 = H - H = \\mathbb{O}_{n \\times n}\\)"
  },
  {
    "objectID": "posts/rl/2023-03-02-graduation_test.html#section-12",
    "href": "posts/rl/2023-03-02-graduation_test.html#section-12",
    "title": "Advanced Regression Analysis GT",
    "section": "(8)",
    "text": "(8)\n\\(E(\\frac{SSE}{n-p-1}) = \\sigma^2\\)\nanswer\n정리 5.1\n\\(y \\sim N(\\mu,V)\\) 이면\n\\(E(y^\\top A y) = tr(AV) + \\mu^\\top A \\mu, cov(y,y^\\top A y) = 2VA\\mu\\)\n\\(\\frac{SSE}{\\sigma^2} = y^\\top \\frac{1}{\\sigma^2}(I-H)y\\)\n\\(B = \\frac{1}{\\sigma^2}(I-H)\\)\n\\(y \\sim N(X\\beta, I \\sigma^2)\\)\n\\(BV = \\frac{1}{\\sigma^2}(I-H)I\\sigma^2 = B, BV=B\\)\n\\(B, BV\\)는 멱등행렬\n\\(tr(BV) = tr(B) = tr(I-H) = tr(I) - tr(H) = n-p-1\\)\n\\(\\star\\) \\(X\\)가 \\(n \\times (p+1)\\) 행렬이고, \\(rank\\)가 \\(p+1\\), \\(\\therefore tr(H) = p+1\\)\n\\(\\mu = X B\\)\n\\(B = \\frac{1}{\\sigma^2}(I-H)\\)\n\\(B\\mu = \\frac{1}{\\sigma^2}(I-H) X \\beta = \\frac{1}{\\sigma^2}(X B - HXB) = 0\\)\n\\(\\star HX = X\\)\n\\(\\therefore \\mu^\\top B \\mu = 0\\)\n\\(E(\\frac{SSE}{\\sigma^2}) = n-p-1\\)\n\\(E(SSE) = (n-p-1)\\sigma^2\\)\n\\(\\therefore E(\\frac{SSE}{(n-p-1)}) = \\sigma^2\\)"
  },
  {
    "objectID": "posts/rl/2023-03-02-graduation_test.html#section-14",
    "href": "posts/rl/2023-03-02-graduation_test.html#section-14",
    "title": "Advanced Regression Analysis GT",
    "section": "(1)",
    "text": "(1)\n적합결여검정을 위한 가설을 제시하라."
  },
  {
    "objectID": "posts/rl/2023-03-02-graduation_test.html#section-15",
    "href": "posts/rl/2023-03-02-graduation_test.html#section-15",
    "title": "Advanced Regression Analysis GT",
    "section": "(2)",
    "text": "(2)\n적합결여검정 수행을 위한 과정과 결과 추론을 구체적으로 제시하라(계산 X)"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Attention Mechanism.html",
    "href": "posts/ml_basic/2023-05-28-Attention Mechanism.html",
    "title": "Attention Mechanism",
    "section": "",
    "text": "Attention Mechanism\nRef: 딥 러닝을 위한 자연어 처리 입문\nRNN에 기반한 seq2seq 모델의 문제점\n\\(\\to\\) 기계 번역 동안 입력 문장이 길면 품질이 떨어지는 현상 발생, 이의 대안으로 입력 시퀀스가 길어지면 출력 시퀀스의 정확도가 떨어지는 것을 보정해주기 위해 들장한 어텐션."
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Attention Mechanism.html#dot-product-attention",
    "href": "posts/ml_basic/2023-05-28-Attention Mechanism.html#dot-product-attention",
    "title": "Attention Mechanism",
    "section": "Dot-Product Attention",
    "text": "Dot-Product Attention\n\n디코더의 마지막 LSTM 셀이 출력단어를 예측하기 위해 인코더의 모든 입력 단어들의 정보를 다시 참고하고자 함\n이 때, 소프트 맥스를 이용\n\n인코더에 입력된 값들이 출력 단어를 예측할 때 얼마나 도움이 되었는지 수치화한 결과\n다시 디코더로 전달\n디코더가 출력 단어를 더 정확하게 예측하게 도와줌\n\n\n\n1. 어텐션 스코어를 구한다.\n\n인코더의 은닉 시점 time stamp = \\(1,2, \\dots, N\\)\n인코더의 은닉 상태 hidden state = \\(s_t\\)\n\n단, 인코더와 디코더의 은닉 상태는 차원이 같음\n\n\n\n\n\n\n\n\nImportant\n\n\n\n디코더의 현재시점 t에서 필요한 입력값\nseq2seq\n\n이전 시점인 t-1의 은닉 상태\n이전 시점 t-1에서 나온 출력 단어\n\nattention\n\n이전 시점인 t-1의 은닉 상태\n이전 시점 t-1에서 나온 출력 단어\n어텐션 값 \\(a_t\\)\n\n\n\nattention score 어텐션 값\n\n현재 디코더의 시점 t에서 단어를 예측하기 위해 인코더의 모든 은닉 상태 각각이 디코더의 현 시점의 은닉 상태 \\(s_t\\)와 얼마나 유사한지를 판단하는 스코어 값\n\n닷 프로덕트 어텐션은 은닉 상태 \\(s_t\\)를 전치(transpose)하고, 각 은닉 상태와 내적(dot product)를 수행하여 스칼라 결과 어텐션 스코어 score 추출\n\n닷 프러덕트 어텐션이라고 부르는 이유\n\n\\[score(s_t, h_i) = s_t^\\top h_i\\]\n\\[e^t = [s_t^\\top h_1, \\dots, s_t^\\top h_N]\\]\n\\(e^t\\)는 \\(s_t\\)와 인코더의 모든 은닉 상태의 어텐션 스코어의 모음값\n\n\n2. 소프트맥스 함수를 통해 어텐션 분포를 구한다.\n\n\\(e^t\\)에 소프트맥스 함수 적용해서 합이 1이 되는 확률 분포 도출\n\n각각 값은 어텐션 가중치 Attention weight\n분포는 어텐션 분포 Attention Distribution \\(\\alpha^t\\)\n\n\n\\[\\alpha^t = softmax(e^t)\\]\n\n\n3. 각 인코더의 어텐션 가중치와 은닉 상태를 가중합하여 어텐션 값을 구한다.\n\n어텐션의 최종 결과값을 얻기 위해 각 인코더의 은닉상태 \\(s_t\\)와 어텐션 가중치 값attention weight를 곱하고 가중합weighted sum인 어텐션 값attention value \\(a_t\\)을 구한다.\n\n\\[a_t = \\sum^N_{i=1} \\alpha_i^t h_i\\]\n\n\n\n\n\n\nTip\n\n\n\n어텐션 값 attention value \\(a_t\\)는 인코더의 문맥을 포함하고 있다고 하여 컨텐스트 벡터 context vector라고도 부른다.\n단, seq2seq에서는 인코더의 마지막 은닉 상태를 컨텍스트 벡터context vector라고 불렀음.\n\n\n\n\n4. 어텐션 값과 디코더의 t 시점의 은닉 상태를 연결한다.\n\n어텐션 값\\(a_t\\)와 디코더의 은닉 상태 \\(s_t\\)를 결합concatenate하여 하나의 벡터로 만드는 작업을 수행한다. \\(\\to\\) \\(v_t\\)\n아 \\(v_t\\)를 예측 연산의 입력으로 사용함으로써 인코더로부터 얻은 정보를 활용하여 \\(\\hat{y}\\)를 더 잘 예측할 수 있게 됨 \\(\\to\\) 어텐션 메커니즘의 핵심\n\n\n\n5. 출력층 연산의 입력이 되는 \\(\\tilde{s}_t\\)를 계산한다.\n\n어텐션 값과 디코더의 t시점의 은닉 상태를 연결하고\\(a_t s_t\\) tanh하이퍼볼릭탄젠트 함수를 통과하도록 해서 출력층 연산을 위한 새로운 벡터 \\(\\tilde{s}_t\\)를 얻는다.\n\n\n\n\n\n\n\nNote\n\n\n\nseq2seq\n\n출력층의 입력이 t시점의 은닉 상태인 \\(s_t\\)\n\nattention\n\n출력층의 입력이 \\(\\tilde{s}_t\\)\n\n\n\n\\[\\tilde{s}_t = tanh(W_c[a_t;s_t] + b_c\\]\n\\(b_c\\)는 편향\n참고: 기계학습 특강 9주차 tanh\n\nimport torch\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\ntanh = torch.nn.Tanh()\n\n\n_x = torch.linspace(-5,5,100)\nplt.plot(_x,tanh(_x))\nplt.title(\"tanh(x)\", size=15)\n\nText(0.5, 1.0, 'tanh(x)')\n\n\n\n\n\n\n\n6. \\(\\tilde{s}_t\\)를 출력층의 입력으로 사용한다.\n\\[\\hat{y}_t = Softmax(W_y \\tilde{s}_t + b_y)\\]"
  },
  {
    "objectID": "posts/ml_basic/2023-03-29-Lasso and Ridge.html",
    "href": "posts/ml_basic/2023-03-29-Lasso and Ridge.html",
    "title": "Lasso and Ridge",
    "section": "",
    "text": "Lasso and Ridge\n릿지ridge 회귀 = 능형회귀 = 티호노프 tikhonov 규제 = L2 노름\n\\(\\star\\) 숙지!\n릿지 회귀는 L2 규제를 사용하여 모델의 가중치가 커지지 않도록 제한합니다. 이 규제는 일반적으로 극단적인 가중치 값을 갖는 것을 방지하고, 모델의 일반화 성능을 향상시킵니다.\n하지만 릿지 회귀는 가중치를 완전히 0으로 만들지는 않습니다. 대신, 가중치를 작게 만들어 모델이 더 일반적인 패턴을 학습하도록 유도합니다. 이는 희소성을 가진 데이터에서 모델의 성능을 향상시키는 데 도움이 됩니다.\n반면, 라쏘 회귀는 L1 규제를 사용하여 가중치를 0으로 만들 수 있습니다. 이는 희귀 학습에서 유용합니다. 희소성을 가진 데이터에서는 많은 특성 중 일부만 중요하다는 것을 알 수 있습니다. 따라서, 라쏘 회귀는 이러한 특성을 선택하고 다른 특성을 제거하여 모델을 희소하게 만들 수 있습니다.\nRefernece: 책_The Elements of Statistical Learning, 그림과 수식으로 배우는 통통 머신러닝, 2021데이터과학 최규빈교수님 lecture 노트"
  },
  {
    "objectID": "posts/ml_basic/2023-03-29-Lasso and Ridge.html#예제",
    "href": "posts/ml_basic/2023-03-29-Lasso and Ridge.html#예제",
    "title": "Lasso and Ridge",
    "section": "예제)",
    "text": "예제)\n\\(y = \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\epsilon, \\epsilon \\sim N(0,\\sigma^2)_{idd}\\)임 모형이 있다고 할 때,\n원래 모형은 \\(y = 5 x_{i1} + 600 x_{i2}\\)이다.\n이 때, \\(x_{i3}\\)이 \\(x_{i1}\\)과 거의 \\(1\\)의 상관관계를 가지고 있다면? \\(\\to\\) 다중공선성을 가지고 있다면?\n\\(\\beta_1 + \\beta_3 = 5\\)만 된다면 원래 모형에 근사하다고 나올 터, 심지어 음수가 나올 때 조차도.\n\n다중공선성의 특징\n\n추정하는 \\(\\beta\\)가 어떤 값인지 거의 예측이 안 된다.\n\n\\(\\beta\\)들의 분산이 크다. (다양한 값 나오고 그러니..)\n\n\\(\\beta\\)는 그래도 더하면 원래 값에 근사함.\n\n\n모두 참이라고 생각되는 모형 \\(\\to\\) 합은 일단 원히던 5임\n\n조건) 다중공선성 없는 \\(x_{i2}\\)는 \\(y\\)쪽으로 옮긴 상황. 즉 신경 안 써도 됌\n\n\n\\(\\beta_1=2,\\beta_2=3\\)\n\\(\\beta_1=5,\\beta_2=0\\)\n\\(\\beta_1=10,\\beta_2=-5\\)\n\\(\\beta_1=10000,\\beta_2=-9995\\)\n\n\\(\\dots\\)\n-&gt; 음수 있는 해석 불가한 이상한 모형들 다 가능하겠다. 해석 불가능."
  },
  {
    "objectID": "posts/ml_basic/2023-04-02-Ensemble and Random Forest.html",
    "href": "posts/ml_basic/2023-04-02-Ensemble and Random Forest.html",
    "title": "Ensemble and Random Forest",
    "section": "",
    "text": "Ensemble and Random Forest\n직접 투표 hard voting\n간접 투표 soft voting\n약한학습기1 weak learner일지라도 큰 수의 법칙 law of large numbers에 의해 앙상블은 강한 학습기 strong learner가 될 수 있다.\n결정주분류 Decision-Making Classifier"
  },
  {
    "objectID": "posts/ml_basic/2023-04-02-Ensemble and Random Forest.html#에이다부스트",
    "href": "posts/ml_basic/2023-04-02-Ensemble and Random Forest.html#에이다부스트",
    "title": "Ensemble and Random Forest",
    "section": "에이다부스트",
    "text": "에이다부스트\n에이다부스트AdaBoost5\n\n과소적합했던 훈련 샘플의 가중치를 더 높여 새로운 예측기 만들기\n가중치 부여: 이전 모델에서 잘못 분류된 샘플에 더 높은 가중치를 부여하여 다음 모델에서 이 샘플이 더 중요하게 처리되도록 합니다.\n재샘플링: 이전 모델에서 잘못 분류된 샘플을 더 많이 선택하여 다음 모델에서 이 샘플이 더 많이 등장하도록 합니다.\n특성 선택: 이전 모델에서 잘못 분류된 샘플과 관련이 높은 특성을 더 많이 사용하여 다음 모델을 학습시킵니다.\n학습률을 줄여 해당 분류기가 전체 모델에 기여하는 확률을 줄임\n\n에이다부스트를 통해 학습을 수행하는 알고리즘6\n\n각 훈련 표본 \\(\\{x_i, y_i)\\}^n_{i=1}\\)에 대응하는 가중치 \\(\\{ w_i\\}^n_{i=1}\\)을 모두 같은 값으로, 강분류기 \\(f\\)는 0으로 초기화한다.\n\n\n\\(w_1,\\dots, w_n \\leftarrow 1/n, f \\leftarrow 0\\)\n\n\n\\(j=1,\\dots,b\\)에 대하여 아래의 과정을 반복한다.\n\n\n표본의 현재 가중치 \\(\\{ w_i\\}^n_{i=1}\\)에 대하여 가중 오분류율(0/1손실7에 가중치를 곱한 합)\\(R(\\psi)\\)가 최소가 되도록 약 분류기\\(\\psi_j\\)를 학습시킨다.\n\n\n\\(\\psi_j = argmin_{\\psi} R(\\psi), R(\\psi) = \\sum^n_{i=1} \\frac{w_i}{2}(1-\\psi(x_i)y_i)\\)\n\n\n약 분류기 \\(\\psi_j\\)의 가중치 \\(\\theta_j\\)를 다음 식과 같이 결정한다.\n\n\n\\(\\theta_j = \\frac{1}{2} log\\frac{1-R(\\psi_j)}{R(\\psi_j)}\\)\n\n\n강 분류기 \\(f\\)를 다음 식과 같이 업데이트 한다.\n\n\n\\(f \\leftarrow f+\\theta_j\\psi_j\\)\n\n\n표본의 가중치 \\(\\{ w_i\\}^n_{i=1}\\)을 다음 식과 같이 업데이트 한다.\n\n\n\\(w_i \\leftarrow \\frac{exp(-f(x_i)y_i)}{\\sum^n_{i'=1}exp(-f(x_{i'})y_{i'})}, \\forall i = 1,\\dots, n\\)"
  },
  {
    "objectID": "posts/ml_basic/2023-04-02-Ensemble and Random Forest.html#그레이디언트-부스팅",
    "href": "posts/ml_basic/2023-04-02-Ensemble and Random Forest.html#그레이디언트-부스팅",
    "title": "Ensemble and Random Forest",
    "section": "그레이디언트 부스팅",
    "text": "그레이디언트 부스팅\n\n그레이디언트 부스팅 gradient boosting\n\n이전 예측기가 만든 잔여 오차에 새로운 예측기 학습\n그레디언트 트리 부스팅 gradient tree boosting = 그레디언트 부스티드 회귀 트리 gradient boosted regression tree(GBRT)\n\n결정 트리를 기반 예측기로 사용\n\n확률적 그레디언트 부스팅 stochastic gradient boosting\n\n트리가 훈련할 때 사용할 훈련 샘플의 비율 지정 -&gt; 분산 낮아질 것\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n에이다부스트(AdaBoost)는 처음에는 지수 손실 최소화를 통해 분류기를 학습합니다. 그러나 이후에는 분류 오차를 최소화하기 위해 다른 손실 함수나 분류기 학습 알고리즘을 사용하기도 합니다.\n예를 들어, 로지스틱 회귀(Logistic Regression)를 사용하여 분류기를 학습하면 로지스틱 손실 함수를 최소화하는 방향으로 학습됩니다. 또한, 그레디언트 부스팅(Gradient Boosting)을 사용하여 분류기를 학습할 수도 있습니다. 이 경우, 분류 오차를 최소화하는 방향으로 학습됩니다.\n따라서, 에이다부스트는 지수 손실 최소화 학습 관점에서만 볼 수 있는 것은 아니며, 다른 손실 함수나 학습 알고리즘을 사용하여 분류기를 학습할 수 있습니다. 그러나 초기에는 지수 손실 함수를 사용하여 가중치를 부여하는 방식으로 분류기를 학습하는 것이 일반적입니다."
  },
  {
    "objectID": "posts/ml_basic/2023-03-31-Ridge Regression_note3_0331.html",
    "href": "posts/ml_basic/2023-03-31-Ridge Regression_note3_0331.html",
    "title": "Ridge Regression",
    "section": "",
    "text": "Lasso and Ridge\n\n\n능형회귀\n\n다중공선성이 \\(\\hat{\\beta}\\)에 대한 분산과 공분산을 모두 크게한다.\nref: Montgomery, D. C., Peck, E. A., & Vining, G. G. (2021). Introduction to linear regression analysis. John Wiley & Sons.\n아래와 같이 2개의 regressor가 존재하는 모형을 생각하자.\n\\(y_i=\\beta_0+\\beta_1x_{i1}+\\beta_2 x_{i2}+\\epsilon_i, \\quad \\epsilon_i ~ \\sim iid N(0,\\sigma^2)\\)\n편의상 아래를 가정하자.\n\\(s_y^2=\\sum_{i=1}^{n}(y_i-\\bar{y})^2=1\\)\n\\(s_1^2=\\sum_{i=1}^{n}(x_{i1}-\\bar{x}_1)^2=1\\)\n\\(s_2^2=\\sum_{i=1}^{n}(x_{i2}-\\bar{x}_2)^2=1\\)\n최소제곱추정법으로 \\(\\hat{\\beta}_1\\), \\(\\hat{\\beta}_2\\)를 구하면 아래와 같다.\n\\(\\hat{\\beta_1}=\\frac{r_{1y}-r_{12}r_{2y}}{1-r_{12}^2}\\).\n\\(\\hat{\\beta_2}=\\frac{r_{2y}-r_{12}r_{1y}}{1-r_{12}^2}\\).\n단,\n\\(r_{1y}=\\frac{s_{1y}}{\\sqrt{s_1^2s_y^2}}=s_{1y}\\), \\(\\quad s_{1y}=\\sum_{i=1}^{n}(y_i-\\bar{y})(x_{i1}-\\bar{x}_1)\\)\n\\(r_{2y}=\\frac{s_{2y}}{\\sqrt{s_2^2s_y^2}}=s_{2y}\\), \\(\\quad s_{2y}=\\sum_{i=1}^{n}(y_i-\\bar{y})(x_{i2}-\\bar{x}_2)\\)\n\\(r_{12}=\\frac{s_{12}}{\\sqrt{s_1^2s_2^2}}=s_{12}\\). \\(\\quad s_{12}=\\sum_{i=1}^{n}(x_{i1}-\\bar{x}_1)(x_{i2}-\\bar{x}_2)\\)\n(관찰1)\n만약에 \\(x_1\\)과 \\(x_2\\)사이에 강한 선형관계가 있다면 \\(r_{12}\\approx 1\\) or \\(r_{12}\\approx -1\\)\n\\(\\hat{\\beta}_1\\)의 분모 = \\(1-r_{12}^2 \\approx 0\\)\n\\(\\hat{\\beta}_1\\)의 분자 \\(\\approx 0\\)\n\\(\\to\\) \\(\\hat{\\beta}_1\\)와 \\(\\hat{\\beta}_2\\)의 값이 불안정할것 같다.\n(관찰2)\n\\(\\hat{\\beta}_1\\), \\(\\hat{\\beta}_2\\)의 분산과 공분산을 구해보자.\n\\(\\mbox{V}(\\hat{\\beta_1})=\\frac{1}{1-r_{12}^2}\\sigma^2\\)\n\\(\\mbox{V}(\\hat{\\beta_2})=\\frac{1}{1-r_{12}^2}\\sigma^2\\)\n\\(\\mbox{cov}\\big(\\hat{\\beta}_1,\\hat{\\beta}_2\\big)=\\frac{-r_{12}}{1-r_{12}^2}\\sigma^2\\)\n(관찰3)\n\\(\\mbox{cor}\\big(\\hat{\\beta}_1,\\hat{\\beta}_2\\big)=-r_{12}\\)\n\nimport rpy2 \n%load_ext rpy2.ipython\n\n\n%%R \nset.seed(999)\nn&lt;-20000\ntoeic&lt;-750+rnorm(n,sd=80)\ntoeic[toeic&gt;990]&lt;-990\ntoeic&lt;-round(toeic)\nteps&lt;-toeic + rnorm(n,sd=0.01)\ngpa&lt;-3.5+rnorm(n,sd=0.3)\ngpa[gpa&gt;4.5]&lt;-4.5 \ngpa&lt;-round(gpa,1)\nsal&lt;-gpa*600+toeic*5+rnorm(n,sd=300)\nsal&lt;-round(sal)\n\n\n%%R \ncor(toeic,teps)\n\n[1] 1\n\n\n(직관)\n토익이나 텝스점수나 그게 그거이다. (강한 상관관계)\n원래모형은 연봉=학점*600+토익*5+오차인데, 토익이나 텝스나 그게 그거이므로, 아래와 같은 모형들도 거의 참모형이라고 생각할 수 있다.\n\n연봉=학점*600+토익*2+텝스*3+오차\n연봉=학점*600+토익*1+텝스*4+오차\n연봉=학점*600+토익*(-5)+텝스*10+오차\n연봉=학점*600+토익*(-1000)+텝스*(1005)+오차\n연봉=학점*600+토익*(-10000)+텝스*(10005)+오차\n\n…\n결국에는 토익의 계수와 텝스의 계수를 더해서 5만되면 참모형\n\n%%R \nlm1&lt;-lm(sal~toeic+teps+gpa)\nlm1\n\n\nCall:\nlm(formula = sal ~ toeic + teps + gpa)\n\nCoefficients:\n(Intercept)        toeic         teps          gpa  \n      50.38       194.70      -189.72       590.53  \n\n\n\n토익의 계수는 194.70, 텝스의 계수는 -189.72 로 추정되었다. 두개더하면 대략 5.\n몇번 더 시도를 해보자.\n(시도2)\n\n%%R \nset.seed(1)\nn&lt;-20000\ntoeic&lt;-750+rnorm(n,sd=80)\ntoeic[toeic&gt;990]&lt;-990\ntoeic&lt;-round(toeic)\nteps&lt;-toeic + rnorm(n,sd=0.01)\ngpa&lt;-3.5+rnorm(n,sd=0.3)\ngpa[gpa&gt;4.5]&lt;-4.5 \ngpa&lt;-round(gpa,1)\nsal&lt;-gpa*600+toeic*5+rnorm(n,sd=300)\nsal&lt;-round(sal)\n\n\n%%R \nlm1&lt;-lm(sal~toeic+teps+gpa)\nlm1\n\n\nCall:\nlm(formula = sal ~ toeic + teps + gpa)\n\nCoefficients:\n(Intercept)        toeic         teps          gpa  \n     -45.82       -64.47        69.50       606.31  \n\n\n\n이번에는 토익의 계수는 -64.49, 텝스의 계수는 69.50 두개 더하면 대충 5\n(시도3)\n\n%%R \nset.seed(2)\nn&lt;-20000\ntoeic&lt;-750+rnorm(n,sd=80)\ntoeic[toeic&gt;990]&lt;-990\ntoeic&lt;-round(toeic)\nteps&lt;-toeic + rnorm(n,sd=0.01)\ngpa&lt;-3.5+rnorm(n,sd=0.3)\ngpa[gpa&gt;4.5]&lt;-4.5 \ngpa&lt;-round(gpa,1)\nsal&lt;-gpa*600+toeic*5+rnorm(n,sd=300)\nsal&lt;-round(sal)\n\n\n%%R \nlm1&lt;-lm(sal~toeic+teps+gpa)\nlm1\n\n\nCall:\nlm(formula = sal ~ toeic + teps + gpa)\n\nCoefficients:\n(Intercept)        toeic         teps          gpa  \n      19.54       217.27      -212.31       603.10  \n\n\n\n토익의 계수는 217.27, 텝스의 계수는 -212.31 두개더하면 대충 5\n(시도4)\n\n%%R \nset.seed(3)\nn&lt;-20000\ntoeic&lt;-750+rnorm(n,sd=80)\ntoeic[toeic&gt;990]&lt;-990\ntoeic&lt;-round(toeic)\nteps&lt;-toeic + rnorm(n,sd=0.01)\ngpa&lt;-3.5+rnorm(n,sd=0.3)\ngpa[gpa&gt;4.5]&lt;-4.5 \ngpa&lt;-round(gpa,1)\nsal&lt;-gpa*600+toeic*5+rnorm(n,sd=300)\nsal&lt;-round(sal)\n\n\n%%R \nlm1&lt;-lm(sal~toeic+teps+gpa)\nlm1\n\n\nCall:\nlm(formula = sal ~ toeic + teps + gpa)\n\nCoefficients:\n(Intercept)        toeic         teps          gpa  \n     -32.02      -152.82       157.85       600.85  \n\n\n\n토익의 계수는 -152.82, 텝스의 계수는 157.85 두개더하면 대충 5.\n[다중공선성의 특징]\n\n추정하는 \\(\\hat{\\beta_1}\\), \\(\\hat{\\beta_2}\\)가 어떤값일지 거의 예측안된다.\n\n\n5근처의 값이 나올때도 있고, 30근처의 값이 나오기도 하고, 100근처의 값이 나오기도 한다.\n\\(\\hat{\\beta}_1\\), \\(\\hat{\\beta}_2\\)의 분산이 크다.\n\n\n그래도 \\(\\hat{\\beta}_1+\\hat{\\beta}_2\\approx 5\\)라는 공통점은 있음.\n\n\n\n수식적으로 그럴듯해 보여도, 모두 바람직한 모형은 아니다.\n아래는 모두 참모형이라고 생각되어지는 상황이다.\n\n\\(\\hat{\\beta}_1=2\\), \\(\\hat{\\beta}_2=3\\)\n\\(\\hat{\\beta}_1=5\\), \\(\\hat{\\beta}_2=0\\)\n\\(\\hat{\\beta}_1=10\\), \\(\\hat{\\beta}_2=-5\\)\n\n모두 참모형에 가깝지만 상식적으로 (3)은 용납할 수 잆음.\n이유1: (3)번과 같은 형태를 허용하면 \\(\\hat{\\beta}_1=10000, ~ \\hat{\\beta}_2=-9995\\) 와 같은식으로도 만들수 있음.\n이유2: (해석불가능한 모델)\n\\(\\hat{\\beta}_2\\)가 의미하는 것은 텝스점수가 얼마나 연봉에 영향을 주는지이다.\n즉 텝스점수 1점을 올리면 연봉이 5만원 깍임.\n상식적으로 말이 안된다.\n\n\n해결책\n논의를 간단하게 하기 위해서 모형을 좀 더 단순화 하자.\ngpa에 대응하는 계수 600을 우리가 이미 알고있다고 가정하자. (혹은 적절하게 추정했다고 가정하자.)\n그리고 오로지 연봉을 토익과 텝스만으로 추정한다고 하자.\n단순화된 모형은\nsal-600*gpa = toeic * β1 + teps * β2\n이제 아래와 같이 계수를 추정하였을 경우\n\n\\(\\hat{\\beta}_1=2\\), \\(\\hat{\\beta}_2=3\\)\n\\(\\hat{\\beta}_1=5\\), \\(\\hat{\\beta}_2=0\\)\n\\(\\hat{\\beta}_1=10\\), \\(\\hat{\\beta}_2=-5\\)\n\n(3)과 같은 상황이 발생하지 않도록 하여보자.\n\n%%R \nset.seed(2)\nn&lt;-20000\ntoeic&lt;-750+rnorm(n,sd=80)\ntoeic[toeic&gt;990]&lt;-990\ntoeic&lt;-round(toeic)\nteps&lt;-toeic + rnorm(n,sd=0.01)\ngpa&lt;-3.5+rnorm(n,sd=0.3)\ngpa[gpa&gt;4.5]&lt;-4.5 \ngpa&lt;-round(gpa,1)\nsal&lt;-gpa*600+toeic*5+rnorm(n,sd=300)\nsal&lt;-round(sal)\n\n\n%%R\ny&lt;-sal-600*gpa\nlm(y~toeic+teps-1)\n\n\nCall:\nlm(formula = y ~ toeic + teps - 1)\n\nCoefficients:\n toeic    teps  \n 216.9  -211.9  \n\n\n\n\\(\\hat{\\beta}_1=216.9\\)\n\\(\\hat{\\beta}_2=-211.9\\)\n위의 결과는 \\(L(\\beta)\\)를 최소화하는 \\(\\beta\\)를 구한 결과임\n\n%%R \nX&lt;-cbind(toeic,teps)\nL&lt;-function(beta){\n    t(y-X%*%beta)%*%(y-X%*%beta)\n}\n\n\n%%R\nbeta&lt;-c(216.9,-211.9)\nc&lt;-L(beta)\n\n즉 \\(c=1798374986\\)이 \\(L\\)이 가질수 있는 최소값.\n\n%%R\nbeta1&lt;-c(2,3)\nL1&lt;-L(beta1)/c\nbeta2&lt;-c(5,0)\nL2&lt;-L(beta2)/c\nbeta3&lt;-c(10,-5)\nL3&lt;-L(beta3)/c\nbeta4&lt;-c(104,-100)\nL4&lt;-L(beta4)/c\nc(L1,L2,L3,L4)\n\n[1] 1.000052 1.000050 1.000048 7.321030\n\n\n\n\\(\\hat{\\beta}_1=2\\), \\(\\hat{\\beta}_2=3\\) \\(\\longrightarrow\\) \\(L(\\boldsymbol{\\beta})=1.000052\\)\n\\(\\hat{\\beta}_1=5\\), \\(\\hat{\\beta}_2=0\\) \\(\\longrightarrow\\) \\(L(\\boldsymbol{\\beta})=1.000050\\)\n\\(\\hat{\\beta}_1=10\\), \\(\\hat{\\beta}_2=-5\\) \\(\\longrightarrow\\) \\(L(\\boldsymbol{\\beta})=1.000048\\)\n\\(\\hat{\\beta}_1=104\\), \\(\\hat{\\beta}_2=-100\\) \\(\\longrightarrow\\) \\(L(\\boldsymbol{\\beta})=7.321030\\)\n\n이대로라면 위의 (1)-(4) 중에서 가장 적절한 해는 (3)이다.\n아이디어: \\(L(\\beta)\\)을 조금 바꾸자. 위의 손실함수에서 각각 \\(\\frac{1}{100000}\\big(\\beta_1^2+\\beta_2^2\\big)\\)를 더한다면?\n\n%%R\nbeta1&lt;-c(2,3)\nbeta2&lt;-c(5,0)\nbeta3&lt;-c(10,-5)\nbeta4&lt;-c(104,-100)\np1&lt;-(beta1[1]^2+beta1[2]^2)/100000\np2&lt;-(beta2[1]^2+beta2[2]^2)/100000\np3&lt;-(beta3[1]^2+beta3[2]^2)/100000\np4&lt;-(beta4[1]^2+beta4[2]^2)/100000\n\nL1&lt;-L(beta1)/c+p1\nL2&lt;-L(beta2)/c+p2\nL3&lt;-L(beta3)/c+p3\nL4&lt;-L(beta4)/c+p4\nc(L1,L2,L3,L4)\n\n[1] 1.000182 1.000300 1.001298 7.529190\n\n\n\n\\(\\hat{\\beta}_1=2\\), \\(\\hat{\\beta}_2=3\\) \\(\\longrightarrow\\) \\(L(\\boldsymbol{\\beta})=1.000182\\)\n\\(\\hat{\\beta}_1=5\\), \\(\\hat{\\beta}_2=0\\) \\(\\longrightarrow\\) \\(L(\\boldsymbol{\\beta})=1.000300\\)\n\\(\\hat{\\beta}_1=10\\), \\(\\hat{\\beta}_2=-5\\) \\(\\longrightarrow\\) \\(L(\\boldsymbol{\\beta})=1.001298\\)\n\\(\\hat{\\beta}_1=104\\), \\(\\hat{\\beta}_2=-100\\) \\(\\longrightarrow\\) \\(L(\\boldsymbol{\\beta})=7.529190\\)\n\n이렇게하면 이제 (수정된) \\(L\\)을 최소화하는 해는 (1)이다.\n\n\n해결책의 시각적 이해\n\n%%R\nβ1 = seq(-10,15,length=50)\nβ2 = seq(-10,15,length=50)\nL_ &lt;- function(β1,β2){\n    rtn&lt;-c()\n    for(k in 1:length(β2)){\n        rtn[k]&lt;-sum((y-β1[k]*toeic-β2[k]*teps)^2)/c\n    }\n    rtn\n}\nz_=outer(β1,β2,L_)\n#install.packages(\"plot3D\")\nlibrary(plot3D) \nribbon3D(z=z_,contour=TRUE,xlab=\"β1\",ylab=\"β2\",zlab=\"L(β1,β2)\",main=\"original loss function\")\n\n\n\n\n\n%%R\nβ1 = seq(-10,15,length=50)\nβ2 = seq(-10,15,length=50)\npanelty_&lt;-function(β1,β2){\n    λ&lt;-1.5 # 1/100000\n    rtn&lt;-c()\n    for(k in 1:length(β2)){\n        rtn[k]&lt;-λ*sum(β1[k]^2+β2[k]^2)\n    }\n    rtn    \n}\n\nL_ &lt;- function(β1,β2){\n    rtn&lt;-c()\n    for(k in 1:length(β2)){\n        rtn[k]&lt;-sum((y-β1[k]*toeic-β2[k]*teps)^2)/c\n    }\n    rtn\n}\nz_=outer(β1,β2,L_)\nz__=outer(β1,β2,panelty_)\n#install.packages(\"plot3D\")\nlibrary(plot3D) \nribbon3D(z=z_,contour=TRUE,xlab=\"β1\",ylab=\"β2\",main=\"그림1: L(β1,β2)\")\nribbon3D(z=z__,contour=TRUE,xlab=\"β1\",ylab=\"β2\",main=\"그림2: λ(β1^2+β2^2)\")\nribbon3D(z=z_+z__,contour=TRUE,xlab=\"β1\",ylab=\"β2\",main=\"그림3: L(β1,β2)+λ(β1^2+β2^2)\")\n\n\n\n\\(\\lambda\\)의 역할 \\((\\lambda&gt;0)\\)\n[그림1]이랑 [그림2]을 섞어서 [그림3]을 만드는데, 각각을 얼만큼의 비율로 섞을지 결정한다.\n람다가 크면 그림2를 많이 반영한다. \\(\\to\\) 람다가 너무 크면 결국 \\(\\hat{\\beta}_1\\)와 \\(\\hat{\\beta}_2\\)의 추정값이 거의 0에 가깝게 된다.\n람다가 작으면 그림1을 많이 반영한다. \\(\\to\\) 람다가 너무 작게되면, 우리는 손실함수 \\(L(\\beta_1,\\beta_2)\\)에 아무런 수정도 하지않은 셈이된다.\n\n\n\\(\\lambda(\\beta_1^2+\\beta_2^2)\\)의 역할\n원래 \\(\\beta_1+\\beta_2=5\\)를 만족하는 어떠한 해도 솔루션이 되었음. 즉 [그림1]과 같은 상황\n[그림1]과 같은 상황에서 약간의 경사를 주어서 [그림3]과 같은 상황을 만듬\n\\(\\hat{\\beta}_1\\) 와 \\(\\hat{\\beta}_2\\) 의 값을 안정적으로 만들어 준다.\n그러면서도 딱히 원래 \\(L(\\beta_1,\\beta_2)\\)의 모양을 크게 해치지 않는다.\n(!) 그럴듯함. 우리가 원하는것 같다.\n이렇게 하면 다중공선성이 발생하는 상황에서 적절한 해를 구할 수 있을 것 같다.\n(관찰)\n\\(\\lambda\\big(\\beta_1^2+\\beta_2^2\\big)\\)은 아래와 같이 표현가능함.\n\\(\\lambda [\\beta_1,\\beta_2]\\begin{bmatrix}\\beta_1 \\\\ \\beta_2 \\end{bmatrix}=\\lambda\\beta^\\top \\beta\\)\n단, \\(\\beta=\\begin{bmatrix}\\beta_1 \\\\ \\beta_2 \\end{bmatrix}\\).\n\n\n릿지에 대한 책의 설명들..\nStep 1. \\(\\hat{\\beta}^R=\\bf\\big(X^\\top X+\\lambda I \\big)^{-1}{\\bf X}^\\top y\\).\n일반적인 회귀분석과 다르게 아래와 같은 손실함수를 생각하자.\n\\(L={\\bf (y-X\\beta)^\\top}{\\bf (y-X\\beta)}+\\lambda \\beta^\\top \\beta=\\mbox{goodness of fit} + \\mbox{panalty}\\)\n\\(L\\)를 최소화하는 \\(\\hat{\\beta}\\)을 구하면 아래와 같다. 구분을 위해서 \\(\\hat{\\beta}^R\\)이라는 기호를쓰자.\n\\(\\hat{\\beta}^R=\\bf\\big(X^\\top X+\\lambda I \\big)^{-1}{\\bf X}^\\top y\\)\nStep 2 : \\(\\hat{\\beta}^R\\)이 \\(\\hat{\\beta}^{OLS}\\)보다 왜 좋은가?\n\\(\\hat{\\beta}^{OLS}={\\bf (X^\\top X)^{-1}X^\\top y}\\)\n\\(\\hat{\\beta}^{R}={\\bf (X^\\top X+\\lambda I)^{-1}X^\\top y}\\)\n\n\\(\\hat{\\beta}^{OLS}\\)는 \\(\\beta\\)에 대한 불편추정량 이지만, \\(\\hat{\\beta}^{R}\\)은 아니다.\n하지만 분산은 \\(\\hat{\\beta}^{OLS}\\)보다 \\(\\hat{\\beta}^R\\)이 더 작다.\n좋은 추정량은 bias와 분산이 모두 작아야하는데, \\(\\hat{\\beta}^{R}\\)은 바이어스는 \\(\\hat{\\beta}^{OLS}\\)보다 큰 상황이고, 분산은 \\(\\hat{\\beta}^{OLS}\\)보다 작은 상황이다.\n따라서 두 추정치중에서 뭐가 더 좋다고 말하기 애매한데, 이를 명확하게 말하기 위해서는 MSE(\\(=\\mbox{bias}^2 + \\mbox{variance}\\))를 비교해봐야한다.\nHoerl 과 Kennard는 \\(\\hat{\\beta}^{R}\\)이 \\(\\hat{\\beta}^{OLS}\\)보다 MSE가 작게되는 \\(\\lambda\\)값이 항상 존재한다고 한다고 밝혔다. (1970년)\n따라서 이러한 \\(\\lambda\\)를 잘 찾으면 항상 Ridge Regression이 Linear Regression 보다 좋다고 주장할 수 있다.\n\n(참고)\n\n일반적인 손실함수 \\(L={\\bf (y-X\\beta)^\\top (y-X\\beta)}\\)와 수정된 손실함수를 구분하기 위해서 아래와 같이 \\(\\tilde{L}\\)와 같은 기호를 쓰기도 한다.\n\n\\(\\tilde{L}={\\bf(y-X\\beta)^\\top(y-X\\beta)+\\lambda \\beta^\\top \\beta }\\)\n\n일반적인 손실함수 \\(L\\)을 최소화하는 \\(\\beta\\)와 수정된 손실함수 \\(\\tilde{L}\\)을 최소화하는 \\(\\beta\\)를 구분하기 위해서 아래와 같은 기호를 쓰기도 한다.\n\n\\(\\hat{\\beta}^{OLS}={\\bf (X^\\top X)^{-1}X^\\top y}\\)\n\\(\\hat{\\beta}^{R}={\\bf (X^\\top X+\\lambda I)^{-1}X^\\top y}\\)\n\n\\(\\lambda \\beta^\\top \\beta\\)를 패널티항(=벌점항), \\(L_2\\)-패널티, regularization term (정규화항) 이라고 부른다.\n\\(\\lambda \\beta^\\top \\beta\\)를 \\(\\lambda \\|\\beta\\|_2^2\\)로 표현하기도 한다. \\(\\| \\cdot \\|_2\\)는 벡터의 \\(L_2\\)-노름 이라고 한다.\n\n\n\\({\\bf x}=(x_1,x_2)\\) \\(\\to\\) \\(\\|{\\bf x}\\|_2^2:=x_1^2+x_2^2\\), \\(\\|{\\bf x}\\|_2:=\\sqrt{x_1^2+x_2^2}\\)\n\\(\\lambda \\beta^\\top \\beta = \\lambda(\\beta_1^2+\\beta_2^2)\\)\n\n\n(4)에서 유리하여 \\(\\lambda \\beta^\\top \\beta\\)를 \\(L_2\\)-패널티항이라고 부르기도 한다.\n참고로 \\(L_1\\)-패널티항도 있다. 그리고 \\(L_1\\)과 \\(L_2\\)패널티를 섞어서 쓰는 방법도 있다.\n\n\n\\(Loss=SSE+L_2\\mbox{-}panalty\\): Ridge\n\\(Loss=SSE+L_1\\mbox{-}panalty\\): Lasso\n\\(Loss=SSE+L_1\\mbox{-}panalty+L_2\\mbox{-}panalty\\): Elastic-net\n\n\n\\(L_2\\)-패널티항은 너무 큰 \\(\\beta_1,\\beta_2\\)를 구할때 패널티를 부여하여 되도록이면 작은 \\(\\beta_1,\\beta_2\\)을 선택하게끔 제약을 건다.\n일반적인 손실함수 \\(L\\)이지만 우리는 \\(\\tilde{L}\\)을 최소화해야 하므로 (i) 되도록이면 \\(\\beta_1,\\beta_2\\)의 값이 작을수록 좋다는 제약하에서 (ii) \\(L\\)를 최소화하는 2가지 역할을 수행해야 한다.\n\\(\\tilde{L}\\)를 최소화하는 문제를 제약된 조건하에서의 최소화문제라고 표현한다.\n(8)에서 (i)-(ii)의 역할중에서 어떤것을 더 중시할지 조율하는 역할을 \\(\\lambda\\)가 하는데, 이와 같은 이유로 \\(\\lambda\\)를 조율모수 (tuning parameter)라고 부르기도 한다.\n\\(\\lambda\\)를 하이퍼파라메터라고 부르기도 한다.\n\\(\\hat{\\beta}^{R}\\)의 값은 대체적으로 \\(\\hat{\\beta}^{OLS}\\)보다 작은값을 가진다. 이러한 이유로 \\(\\beta^{R}\\) shrinkage esitmator라고 부른다.\nbiased regression, shrinkage method, regularization method, panalty method.. 등 ridge를 표현하는 방법들은 다양하다.\n능형회귀를 수행함에 있어서 (이론적인 부분에서는 언급되지 않았으나) 변수의 표준화를 먼저 시행해야 한다."
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Transformers.html",
    "href": "posts/ml_basic/2023-05-28-Transformers.html",
    "title": "Transformers",
    "section": "",
    "text": "Attention is all you need\nref: 딥 러닝을 이용한 자연어 처리 입문, Attention is all you need\n\\(\\star\\) seq2seq 구조인 인코더-디코더를 따르면서 어텐션만으로 구현한 모델, RNN을 사용하지 않고 인코더-디코더 구조로 설계하였지만 RNN보다 우수한 성능을 보임\nhttps://github.com/huggingface/transformers\nhttps://github.com/huggingface/transformers/blob/main/README_ko.md"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Transformers.html#positional-encoding",
    "href": "posts/ml_basic/2023-05-28-Transformers.html#positional-encoding",
    "title": "Transformers",
    "section": "Positional Encoding",
    "text": "Positional Encoding\n\n\n\n\n\n\nNote\n\n\n\nRNN이 자연어 처리에서 유용했던 이유\n\n단어의 위치에 따라 단어를 순차적으로 입력받아서 처리하는 RNN의 특성으로 인해 각 단어의 위치 정보 position information을 가질 수 있어서\n\n\n\n포지셔널 인코딩\n\n트랜스포머는 단어의 위치 정보를 얻기 위해서 각 단어의 임베딩 벡터에 위치 정보들을 더하여 모델의 입력으로 사용\n\n\n\n\n\nflowchart LR\n    _--&gt;__\n    __--&gt;out\n    subgraph _\n    direction BT\n    Embedding_en--&gt;Positional\\nEncoding_en\n    Positional\\nEncoding_en--&gt;Encoders\n        subgraph Encoders\n        Encoder\n        end\n        subgraph Embedding_en\n        Text1(\"'I|am|a|student'\")\n        end\n    end\n    subgraph __\n    direction BT\n    Embedding_de--&gt;Positional\\nEncoding_de\n    Positional\\nEncoding_de--&gt;Decoders\n        subgraph Decoders\n        Decoder\n        end\n        subgraph Embedding_de\n        Text2(\"'&lt;\\br&gt;sos|je|suis|étudiant'\")\n        end\n    end\n    out(\"'je|suis|étudiant|eos'\")\n\n\n\n\n\n\n입력으로 사용되는 임베딩 벡터들이 트랜스포머의 입력으로 사용되기 전에 포지셔널 인코딩 값이 더해지는 과정\n\n\\[PE_{(pos, 2i)} = \\sin(pos/10000^{2i/d_{model}})\\]\n\\[PE_{(pos, 2i+1)} = \\cos(pos/10000^{2i/d_{model}})\\]\n\n트랜스포머가 위치 정보를 가진 값을 만들기 위해 사용하는 두 개의 함수\n\n\nimport numpy as np\nimport pandas as pd\n\n\nd_model = pd.DataFrame(np.empty((4, 4), dtype=str), index=['I', 'am', 'a', 'student'])\n\nvalues = ['pos1,i1', 'pos1,i2', 'pos1,i3', 'pos1,i4',\n          'pos2,i1', 'pos2,i2', 'pos2,i3', 'pos2,i4',\n          'pos3,i1', 'pos3,i2', 'pos3,i3', 'pos3,i4',\n          'pos4,i1', 'pos4,i2', 'pos4,i3', 'pos4,i4']\n\nfor i in range(4):\n    for j in range(4):\n        d_model.iloc[i, j] = values[i * 4 + j]\n\n\nd_model\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n\n\n\n\nI\npos1,i1\npos1,i2\npos1,i3\npos1,i4\n\n\nam\npos2,i1\npos2,i2\npos2,i3\npos2,i4\n\n\na\npos3,i1\npos3,i2\npos3,i3\npos3,i4\n\n\nstudent\npos4,i1\npos4,i2\npos4,i3\npos4,i4\n\n\n\n\n\n\n\n\npos는 입력 문장에서 임베딩 벡터의 위치\ni는 임베딩 벡터 내의 차원의 인덱스를 의미\n위 식에 따르면\n\n짝수면 sin함수 사용 \\(\\to\\) (pos,2i)\n홀수면 cos함수 사용 \\(\\to\\) (pos,2i+1)\n\n여기서 \\(d_{model}\\)은 트랜스포머의 모든 층의 출력 차원을 의미하는 하이퍼파라미터\n임베딩 벡터도 같은 차원임\n이와 깉은 포지셔널 인코딩 방법을 사용하면 순서 정보가 보존됨.\n\n각 임베딩 멕터에 포지셔널 인코딩의 값을 더하면(차원 같음!) 같은 단어라도 문장 내의 위치에 따라 트랜스포머의 입력으로 들어가는 임베딩 벡터의 값이 달라짐\n\n\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n\nclass PositionalEncoding(tf.keras.layers.Layer):\n    def __init__(self, position, d_model):\n        super(PositionalEncoding, self).__init__()\n        self.pos_encoding = self.positional_encoding(position, d_model)\n\n    def get_angles(self, position, i, d_model):\n        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n        return position * angles\n\n    def positional_encoding(self, position, d_model):\n        angle_rads = self.get_angles(\n            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n            d_model=d_model)\n\n        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n        sines = tf.math.sin(angle_rads[:, 0::2])\n\n        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n        cosines = tf.math.cos(angle_rads[:, 1::2])\n\n        angle_rads = np.zeros(angle_rads.shape)\n        angle_rads[:, 0::2] = sines\n        angle_rads[:, 1::2] = cosines\n        pos_encoding = tf.constant(angle_rads)\n        pos_encoding = pos_encoding[tf.newaxis, ...]\n\n        print(pos_encoding.shape)\n        return tf.cast(pos_encoding, tf.float32)\n\n    def call(self, inputs):\n        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n\n포지셔널 인코딩 행렬 시각화\n\n# 문장의 길이 50, 임베딩 벡터의 차원 128\nsample_pos_encoding = PositionalEncoding(50, 128)\n\nplt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\nplt.xlabel('Depth')\nplt.xlim((0, 128))\nplt.ylabel('Position')\nplt.colorbar()\nplt.show()\n\n(1, 50, 128)"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Transformers.html#self-attention",
    "href": "posts/ml_basic/2023-05-28-Transformers.html#self-attention",
    "title": "Transformers",
    "section": "1. Self Attention",
    "text": "1. Self Attention\n\n셀프 어텐션\n\nQ = 입력 문장의 모든 단어 벡터들\nK = 입력 문장의 모든 단어 벡터들\nV = 입력 문장의 모든 단어 벡터들\n\n연속된 문장들에 대하여 지칭하는 단어가 다르지만 의미는 같을 수 있는데, 셀프 어텐션은 이 유사도를 구하여서 연관 가능성을 찾아낸다."
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Transformers.html#q-k-v",
    "href": "posts/ml_basic/2023-05-28-Transformers.html#q-k-v",
    "title": "Transformers",
    "section": "2. Q, K, V",
    "text": "2. Q, K, V\n\n셀프 어텐션은 일단 문장의 각 단어 벡터로부터 Q벡터, K벡터, V벡터를 얻음.\n\nQ벡터, K벡터, V벡터는 \\(d_{model}\\) 차원을 가지는 단어 벡터들보다 더 작은 차원을 가짐\n논문을 예로 들면 \\(d_{model}\\)의 차원은 512, Q벡터, K벡터, V벡터의 차원은 각각 64\n이 64는 또 다른 하이퍼파라미터인 num_heads로 결정되는데, 트랜스포머는 \\(d_{model}\\)을 num_heads로 나눈 값을 Q벡터, K벡터, V벡터의 차원으로 결정.\n논문의 num_heads = 8이었으니까 \\(512/8 = 64\\)로 결정된 것\n이 Q벡터, K벡터, V벡터는 단어마다, 벡터마다 서로 다른 가중치 행렬을 곱하여 얻음\n각 단어마다 Q벡터, K벡터, V벡터 각각의 가중치, Q벡터, K벡터, V벡터 각각이 존재하는 것"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Transformers.html#scaled-dot-product-attention",
    "href": "posts/ml_basic/2023-05-28-Transformers.html#scaled-dot-product-attention",
    "title": "Transformers",
    "section": "3. Scaled dot-product Attention",
    "text": "3. Scaled dot-product Attention\n각 단어 별로 Q벡터, K벡터, V벡터를 구한 후 각 Q벡터는 모든 K벡터에 대해서 어텐션 스코어를 구하고, 어텐션 분포를 구한 뒤 이를 사용하여 모든 V벡터를 가중합하여 어텐션 값 또는 컨텍스트 벡터를 구함-&gt; 모든 Q벡터에 대해 반복\n\n내적한 후 특정값을 나눔으로써 값을 조정하는 과정 추가한 스케일드 갓-프로덕트 어텐션\n\n\\[score(q,k) = \\frac{q k}{\\sqrt{n}}\\]\n\\(\\sqrt{n}\\)이 결정되는 과정\n\n논문을 예로 들면 \\(d_{model}\\)의 차원이 512, num_heads가 8, Q,K,V의 차원 \\(d_k\\)가 64(512/8) 이었음, 여기서 64에 root 취한 8으로 결정되는 것"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Transformers.html#행렬-연산으로-일괄-처리",
    "href": "posts/ml_basic/2023-05-28-Transformers.html#행렬-연산으로-일괄-처리",
    "title": "Transformers",
    "section": "4. 행렬 연산으로 일괄 처리",
    "text": "4. 행렬 연산으로 일괄 처리\nQ 벡터마다 3을 연산하는 것을 피하기 위함\n\n문장 행렬에 가중치 행렬을 곱하여 Q행렬, K행렬, V행렬을 구한다(단지 벡터를 행렬화한 것 뿐).\n각 단어의 Q벡터와 전치한 K벡터의 내적이 각 행렬의 원소가 되는 행렬을 결과로 추출.\n2번의 결과에 \\(\\sqrt{d_k}\\)를 나누어 softmax취한 후 V행렬을 곱하여 각 행과 열이 어텐션 스코어 값을 가지는 행렬을 구함.\n\n\\[Attention(Q,K,V) = softmax(\\frac{QK^\\top}{\\sqrt{d_k}})V\\]\n입력 문장의 길이가 seq_len이라면, 문장 행렬의 크기는 (seq_len,\\(d_{model}\\))\n차원 정리\n\n\\(Q\\) = (seq_len, \\(d_k)\\)\n\n\\(W^Q = (d_{model},d_k)\\)\n\n\\(K^\\top\\) = (\\(d_k\\), seq_len)\n\n\\(W^K = (d_{model},d_k)\\)\n\n\\(V\\) = (seq_len, \\(d_v)\\)\n\n\\(W^V = (d_{model},d_v)\\)\n\n논문에서는 \\(d_k,d_v\\)의 차원이 \\(d_{model}\\)/num_heads로 같게 설정함\nattention score matrix = (seq_len, \\(d_v\\))"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Transformers.html#scaled-dot-product-attention-구현",
    "href": "posts/ml_basic/2023-05-28-Transformers.html#scaled-dot-product-attention-구현",
    "title": "Transformers",
    "section": "5. Scaled dot-product attention 구현",
    "text": "5. Scaled dot-product attention 구현\n\ndef scaled_dot_product_attention(query, key, value, mask):\n    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n    # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n    # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n\n    # Q와 K의 곱. 어텐션 스코어 행렬.\n    matmul_qk = tf.matmul(query, key, transpose_b=True)\n\n    # 스케일링\n    # dk의 루트값으로 나눠준다.\n    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n    logits = matmul_qk / tf.math.sqrt(depth)\n\n    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n    if mask is not None:\n        logits += (mask * -1e9)\n\n    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n    attention_weights = tf.nn.softmax(logits, axis=-1)\n\n    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n    output = tf.matmul(attention_weights, value)\n\n    return output, attention_weights\n\nscaled_dot_product_attention 실행\n\n# 임의의 Query, Key, Value인 Q, K, V 행렬 생성\nnp.set_printoptions(suppress=True)\ntemp_k = tf.constant([[10,0,0],\n                      [0,10,0],\n                      [0,0,10],\n                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n\ntemp_v = tf.constant([[   1,0],\n                      [  10,0],\n                      [ 100,5],\n                      [1000,6]], dtype=tf.float32)  # (4, 2)\ntemp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n\nquery에 해당하는 [0,10,0]은 key에 해당하는 두 번째 값과 일치해야 함.\n\n# 함수 실행\ntemp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\nprint(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\nprint(temp_out) # 어텐션 값\n\ntf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\ntf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n\n\n두 번째 값과 일치했어서 두 번째가 1인 값을 반환, 결과적으로 [10,0]의 어텐션 값 반환\n\ntemp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\ntemp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\nprint(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\nprint(temp_out) # 어텐션 값\n\ntf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\ntf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n\n\n세 번째 값과 네 번째 값이 같이 일치하다면? 합이 1이되게 나눠서 0.5,0.5씩 나눠짐\n\n[100,5] * 0.5 + [1000,6] * 0.5 = [550,5.5]\n\n\n[100*0.5 + 1000*0.5,5*0.5 + 6*0.5]\n\n[550.0, 5.5]\n\n\n\ntemp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\ntemp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\nprint(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\nprint(temp_out) # 어텐션 값\n\ntf.Tensor(\n[[0.  0.  0.5 0.5]\n [0.  1.  0.  0. ]\n [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\ntf.Tensor(\n[[550.    5.5]\n [ 10.    0. ]\n [  5.5   0. ]], shape=(3, 2), dtype=float32)"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Transformers.html#multi-head-attention",
    "href": "posts/ml_basic/2023-05-28-Transformers.html#multi-head-attention",
    "title": "Transformers",
    "section": "6. Multi-head Attention",
    "text": "6. Multi-head Attention\n왜 스케일링하여 어텐션 스코어를 구했을까?\n\n논문에서는 한 번의 어텐션보다 여러번의 어텐션을 병렬로 사용하는 것이 더 효과적이라고 판단\n그래서 \\(d_{model}\\)의 차원을 num_heads로 나누어 \\(d_{model}\\)/num_heads의 차원을 가지는 Q,K,V에 대해서 num_heads 개의 병렬 어텐션 수행\nnum_heads만큼 병렬이 이뤄지는데, 이 때 나오는 각각의 어텐션 값 행렬을 어텐션 헤드라고 함.\n\n이 때 가중치 행렬의 값\\(W^Q,W^K,W^V\\)은 num_heads의 어텐션 해드마다 전부 다름\n\n\n병렬로 수행한 효과?\n\n어텐션을 병렬로 수행하여 다른 시각으로 정보를 수집할 수 있음"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Transformers.html#multi-head-attention-구현",
    "href": "posts/ml_basic/2023-05-28-Transformers.html#multi-head-attention-구현",
    "title": "Transformers",
    "section": "7. Multi-head Attention 구현",
    "text": "7. Multi-head Attention 구현\n가중치 행렬\n\nQ, K, V 행렬을 만들기 위한 가중치 행렬 \\(W^Q,W^K,W^V\\)\n어텐션 헤드들을 연결concatenation 후에 곱해주는 행렬 \\(W^O\\)\n\n가중치 행렬을 곱하는 것은 Dense layer 지나게 하여 구현\n\n\\(W^Q,W^K,W^V\\)에 해당하는 \\(d_{model}\\)의 크기의 밀집층(Dense layer)을 지나게 한다.\n지정된 헤드수 num_heads 만큼 나눈다(split).\nscaled dot-product attention\n나눠졌던 헤드들을 연결concatenatetion한다.\n\\(W^O\\)에 해당하는 밀집층을 지나게 한다.\n\n\nclass MultiHeadAttention(tf.keras.layers.Layer):\n\n    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n        super(MultiHeadAttention, self).__init__(name=name)\n        self.num_heads = num_heads\n        self.d_model = d_model\n\n        assert d_model % self.num_heads == 0\n\n        # d_model을 num_heads로 나눈 값.\n        # 논문 기준 : 64\n        self.depth = d_model // self.num_heads\n\n        # WQ, WK, WV에 해당하는 밀집층 정의\n        self.query_dense = tf.keras.layers.Dense(units=d_model)\n        self.key_dense = tf.keras.layers.Dense(units=d_model)\n        self.value_dense = tf.keras.layers.Dense(units=d_model)\n\n        # WO에 해당하는 밀집층 정의\n        self.dense = tf.keras.layers.Dense(units=d_model)\n\n    # num_heads 개수만큼 q, k, v를 split하는 함수\n    def split_heads(self, inputs, batch_size):\n        inputs = tf.reshape(\n            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n\n    def call(self, inputs):\n        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n            'value'], inputs['mask']\n        batch_size = tf.shape(query)[0]\n\n        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n        # q : (batch_size, query의 문장 길이, d_model)\n        # k : (batch_size, key의 문장 길이, d_model)\n        # v : (batch_size, value의 문장 길이, d_model)\n        # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n        query = self.query_dense(query)\n        key = self.key_dense(key)\n        value = self.value_dense(value)\n\n        # 2. 헤드 나누기\n        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n        query = self.split_heads(query, batch_size)\n        key = self.split_heads(key, batch_size)\n        value = self.split_heads(value, batch_size)\n\n        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n        # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n\n        # 4. 헤드 연결(concatenate)하기\n        # (batch_size, query의 문장 길이, d_model)\n        concat_attention = tf.reshape(scaled_attention,\n                                      (batch_size, -1, self.d_model))\n\n        # 5. WO에 해당하는 밀집층 지나기\n        # (batch_size, query의 문장 길이, d_model)\n        outputs = self.dense(concat_attention)\n\n        return outputs"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Transformers.html#padding-mask",
    "href": "posts/ml_basic/2023-05-28-Transformers.html#padding-mask",
    "title": "Transformers",
    "section": "8. Padding Mask",
    "text": "8. Padding Mask\n어텐션에서 제외하기 위해 값을 가리는 역할\n\n방법: 어텐션 스코어 행렬의 마스킹 위치에 매우 작은 음수값을 넣어주기\n\n소프트맥스 함수를 지나면 값이 0이 되어 유사도 구할때 반영되지 않름.\n\n\n\ndef create_padding_mask(x):\n    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n    # (batch_size, 1, 1, key의 문장 길이)\n    return mask[:, tf.newaxis, tf.newaxis, :]\n\n\nprint(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))\n\ntf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Transformers.html#잔차-연결",
    "href": "posts/ml_basic/2023-05-28-Transformers.html#잔차-연결",
    "title": "Transformers",
    "section": "1. 잔차 연결",
    "text": "1. 잔차 연결\n\\[H(x) = x + F(x)\\]\n\n\\(F(x)\\)는 트랜스포머에서 서브층에 해당\n즉, 장차 연결은 서브층의 입력과 출력을 더하는 것\n서브층의 입력과 출력은 동일한 차원을 갖고 있어서 가능\n그래서 재귀하는 것처럼 다이어그램 그려보면 화살표가 출력층에서 나와 입력층으로 들어가는 모습\n잔차 연결은 컴퓨터 비전 분야에서 주로 사용되는 모델의 학습을 돕는 기법\n\n식으로 표현 -&gt; \\(x + Sublayer(x)\\)\n서브층이 멀티 헤드 어텐션이었다면 $H(x) - x + Multi - head Attention(x)\n참고 : 잔차연결 관련 논문"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Transformers.html#층-정규화",
    "href": "posts/ml_basic/2023-05-28-Transformers.html#층-정규화",
    "title": "Transformers",
    "section": "2. 층 정규화",
    "text": "2. 층 정규화\n잔차연결과 층 정규화 모두 수행한 함수\n\\[LN = LayerNorm(x+Sublayer(x))\\]\n텐서의 마지막 차원에 대하여 평균과 분산을 구하고, 이를 가지고 어떤 수식을 통해 값을 정규화하여 학습을 도움\n\n텐서의 마지막 차원 = 트랜스포머에서는 \\(d_{model}\\) 차원을 의미\n\n\n평균과 분산을 통한 벡터 \\(x_i\\) 정규화\n\n스칼라인 평균과 분산 도출\n\\(\\epsilon\\)은 분모가 0이 되는 것을 방지\n\n\n\\[\\hat{x}_{i,k} = \\frac{x_{i,k} - \\mu_i}{\\sqrt{\\sigma^2_i + \\epsilon}}\\]\n\n감마와 베타 도입\n\n\nLayerNormalization(케라스에 내장되어 있음)\n\n\\[ln_i = \\gamma \\hat{x}_i + \\beta = LayerNorm(x_i)\\]\n참고: 층 정규화 관련 논문"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Transformers.html#nd-decoder-sublayer-encoder-decoder-attention",
    "href": "posts/ml_basic/2023-05-28-Transformers.html#nd-decoder-sublayer-encoder-decoder-attention",
    "title": "Transformers",
    "section": "2nd Decoder sublayer : Encoder-Decoder Attention",
    "text": "2nd Decoder sublayer : Encoder-Decoder Attention\n디코더 두번째 서브층은 멀티 헤드 어텐션을 수행한다는 점에서 이전의 어텐션들(인코더와 디코더의 첫번째 서브층)과는 공통점이 있으나 이건 셀프 어텐션이 아님!\n\n셀프 어텐션은 Query, Key, Value가 출처가 같은 경우를 말하는데, 인코더-디코더 어텐션은 Query가 디코더인 행렬인 반면, Key, Value가 인코더 행렬이기 때문\n인코더의 첫번째 서브층 = Query = Key = Value\n디코더의 첫번째 서브층 = Query = Key = Value\n디코더의 두번째 서브층 = Query = 디코더 행렬(의 첫번째 서브층 결과), Key = Value = 인코더 행렬(의 마지막 층에서 얻은 값)"
  },
  {
    "objectID": "posts/ml_basic/2023-03-28-Linear Regression, Logistic Regression.html",
    "href": "posts/ml_basic/2023-03-28-Linear Regression, Logistic Regression.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "Logistic Regression\n\n로지스틱 함수는 샘플이 어느 카테고리에 속할 확률을 추정하여 분류하는 회귀 알고리즘이다.\nRefernece: 핸즈 온 머신러닝\n\n로지스틱 회귀"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Transformer Chatbot Tutorial.html",
    "href": "posts/ml_basic/2023-05-28-Transformer Chatbot Tutorial.html",
    "title": "Transformer Chatbot Tutorial",
    "section": "",
    "text": "Transformer Chatbot Tutorial\n\nRef: 딥 러닝을 이용한 자연어 처리 입문\n\nImport\n\n# 최종 버전\nclass PositionalEncoding(tf.keras.layers.Layer):\n    def __init__(self, position, d_model):\n        super(PositionalEncoding, self).__init__()\n        self.pos_encoding = self.positional_encoding(position, d_model)\n\n    def get_angles(self, position, i, d_model):\n        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n        return position * angles\n\n    def positional_encoding(self, position, d_model):\n        angle_rads = self.get_angles(\n            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n            d_model=d_model)\n\n        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n        sines = tf.math.sin(angle_rads[:, 0::2])\n\n        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n        cosines = tf.math.cos(angle_rads[:, 1::2])\n\n        angle_rads = np.zeros(angle_rads.shape)\n        angle_rads[:, 0::2] = sines\n        angle_rads[:, 1::2] = cosines\n        pos_encoding = tf.constant(angle_rads)\n        pos_encoding = pos_encoding[tf.newaxis, ...]\n\n        print(pos_encoding.shape)\n        return tf.cast(pos_encoding, tf.float32)\n\n    def call(self, inputs):\n        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n\n\nsample_pos_encoding = PositionalEncoding(50, 128)\n\nplt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\nplt.xlabel('Depth')\nplt.xlim((0, 128))\nplt.ylabel('Position')\nplt.colorbar()\nplt.show()\n\n(1, 50, 128)\n\n\n\n\n\n\ndef scaled_dot_product_attention(query, key, value, mask):\n    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n    # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n    # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n\n    # Q와 K의 곱. 어텐션 스코어 행렬.\n    matmul_qk = tf.matmul(query, key, transpose_b=True)\n\n    # 스케일링\n    # dk의 루트값으로 나눠준다.\n    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n    logits = matmul_qk / tf.math.sqrt(depth)\n\n    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n    if mask is not None:\n        logits += (mask * -1e9)\n\n    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n    attention_weights = tf.nn.softmax(logits, axis=-1)\n\n    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n    output = tf.matmul(attention_weights, value)\n\n    return output, attention_weights\n\n\nclass MultiHeadAttention(tf.keras.layers.Layer):\n\n  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n    super(MultiHeadAttention, self).__init__(name=name)\n    self.num_heads = num_heads\n    self.d_model = d_model\n\n    assert d_model % self.num_heads == 0\n\n    # d_model을 num_heads로 나눈 값.\n    # 논문 기준 : 64\n    self.depth = d_model // self.num_heads\n\n    # WQ, WK, WV에 해당하는 밀집층 정의\n    self.query_dense = tf.keras.layers.Dense(units=d_model)\n    self.key_dense = tf.keras.layers.Dense(units=d_model)\n    self.value_dense = tf.keras.layers.Dense(units=d_model)\n\n    # WO에 해당하는 밀집층 정의\n    self.dense = tf.keras.layers.Dense(units=d_model)\n\n  # num_heads 개수만큼 q, k, v를 split하는 함수\n  def split_heads(self, inputs, batch_size):\n    inputs = tf.reshape(\n        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n\n  def call(self, inputs):\n    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n        'value'], inputs['mask']\n    batch_size = tf.shape(query)[0]\n\n    # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n    # q : (batch_size, query의 문장 길이, d_model)\n    # k : (batch_size, key의 문장 길이, d_model)\n    # v : (batch_size, value의 문장 길이, d_model)\n    # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n    query = self.query_dense(query)\n    key = self.key_dense(key)\n    value = self.value_dense(value)\n\n    # 2. 헤드 나누기\n    # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n    # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n    # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n    query = self.split_heads(query, batch_size)\n    key = self.split_heads(key, batch_size)\n    value = self.split_heads(value, batch_size)\n\n    # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n    # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n\n    # 4. 헤드 연결(concatenate)하기\n    # (batch_size, query의 문장 길이, d_model)\n    concat_attention = tf.reshape(scaled_attention,\n                                  (batch_size, -1, self.d_model))\n\n    # 5. WO에 해당하는 밀집층 지나기\n    # (batch_size, query의 문장 길이, d_model)\n    outputs = self.dense(concat_attention)\n\n    return outputs\n\n\ndef create_padding_mask(x):\n    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n    # (batch_size, 1, 1, key의 문장 길이)\n    return mask[:, tf.newaxis, tf.newaxis, :]\n\n\ndef encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n\n    # 인코더는 패딩 마스크 사용\n    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n\n    # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n    attention = MultiHeadAttention(\n      d_model, num_heads, name=\"attention\")({\n          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n          'mask': padding_mask # 패딩 마스크 사용\n      })\n\n    # 드롭아웃 + 잔차 연결과 층 정규화\n    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n    attention = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(inputs + attention)\n\n    # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n\n    # 드롭아웃 + 잔차 연결과 층 정규화\n    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n    outputs = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(attention + outputs)\n\n    return tf.keras.Model(\n      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n\n\ndef encoder(vocab_size, num_layers, dff,\n            d_model, num_heads, dropout,\n            name=\"encoder\"):\n    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n\n    # 인코더는 패딩 마스크 사용\n    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n\n    # 포지셔널 인코딩 + 드롭아웃\n    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n\n    # 인코더를 num_layers개 쌓기\n    for i in range(num_layers):\n        outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n            dropout=dropout, name=\"encoder_layer_{}\".format(i),\n        )([outputs, padding_mask])\n\n    return tf.keras.Model(\n      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n\n\n# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\ndef create_look_ahead_mask(x):\n    seq_len = tf.shape(x)[1]\n    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n    padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n    return tf.maximum(look_ahead_mask, padding_mask)\n\n\ndef decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n\n    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n    look_ahead_mask = tf.keras.Input(\n      shape=(1, None, None), name=\"look_ahead_mask\")\n    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n\n    # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n    attention1 = MultiHeadAttention(\n      d_model, num_heads, name=\"attention_1\")(inputs={\n          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n          'mask': look_ahead_mask # 룩어헤드 마스크\n      })\n\n    # 잔차 연결과 층 정규화\n    attention1 = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(attention1 + inputs)\n\n    # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n    attention2 = MultiHeadAttention(\n      d_model, num_heads, name=\"attention_2\")(inputs={\n          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n          'mask': padding_mask # 패딩 마스크\n      })\n\n    # 드롭아웃 + 잔차 연결과 층 정규화\n    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n    attention2 = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(attention2 + attention1)\n\n    # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n\n    # 드롭아웃 + 잔차 연결과 층 정규화\n    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n    outputs = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(outputs + attention2)\n\n    return tf.keras.Model(\n      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n      outputs=outputs,\n      name=name)\n\n\ndef decoder(vocab_size, num_layers, dff,\n            d_model, num_heads, dropout,\n            name='decoder'):\n    inputs = tf.keras.Input(shape=(None,), name='inputs')\n    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n\n    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n    look_ahead_mask = tf.keras.Input(\n      shape=(1, None, None), name='look_ahead_mask')\n    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n\n    # 포지셔널 인코딩 + 드롭아웃\n    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n\n    # 디코더를 num_layers개 쌓기\n    for i in range(num_layers):\n        outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n            dropout=dropout, name='decoder_layer_{}'.format(i),\n        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n\n    return tf.keras.Model(\n      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n      outputs=outputs,\n      name=name)\n\n\ndef transformer(vocab_size, num_layers, dff,\n                d_model, num_heads, dropout,\n                name=\"transformer\"):\n\n    # 인코더의 입력\n    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n\n    # 디코더의 입력\n    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n\n    # 인코더의 패딩 마스크\n    enc_padding_mask = tf.keras.layers.Lambda(\n      create_padding_mask, output_shape=(1, 1, None),\n      name='enc_padding_mask')(inputs)\n\n    # 디코더의 룩어헤드 마스크(첫번째 서브층)\n    look_ahead_mask = tf.keras.layers.Lambda(\n      create_look_ahead_mask, output_shape=(1, None, None),\n      name='look_ahead_mask')(dec_inputs)\n\n    # 디코더의 패딩 마스크(두번째 서브층)\n    dec_padding_mask = tf.keras.layers.Lambda(\n      create_padding_mask, output_shape=(1, 1, None),\n      name='dec_padding_mask')(inputs)\n\n    # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n    enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n      d_model=d_model, num_heads=num_heads, dropout=dropout,\n    )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n\n    # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n    dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n      d_model=d_model, num_heads=num_heads, dropout=dropout,\n    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n\n    # 다음 단어 예측을 위한 출력층\n    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n\n    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n\n\nsmall_transformer = transformer(\n    vocab_size = 9000,\n    num_layers = 4,\n    dff = 512,\n    d_model = 128,\n    num_heads = 4,\n    dropout = 0.3,\n    name=\"small_transformer\")\n\ntf.keras.utils.plot_model(\n    small_transformer, to_file='small_transformer.png', show_shapes=True)\n\n(1, 9000, 128)\n(1, 9000, 128)\nYou must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n\n\n\ndef loss_function(y_true, y_pred):\n    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n      from_logits=True, reduction='none')(y_true, y_pred)\n\n    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n    loss = tf.multiply(loss, mask)\n\n    return tf.reduce_mean(loss)\n\n\nclass CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n\n    def __init__(self, d_model, warmup_steps=4000):\n        super(CustomSchedule, self).__init__()\n        self.d_model = d_model\n        self.d_model = tf.cast(self.d_model, tf.float32)\n        self.warmup_steps = warmup_steps\n\n    def __call__(self, step):\n        arg1 = tf.math.rsqrt(step)\n        arg2 = step * (self.warmup_steps**-1.5)\n\n        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n\n\nsample_learning_rate = CustomSchedule(d_model=128)\n\nplt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\nplt.ylabel(\"Learning Rate\")\nplt.xlabel(\"Train Step\")\n\nText(0.5, 0, 'Train Step')\n\n\n\n\n\n\n\nData load\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\nimport urllib.request\nimport time\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\n\n\nurllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\ntrain_data = pd.read_csv('ChatBotData.csv')\ntrain_data.head()\n\n\n\n\n\n\n\n\nQ\nA\nlabel\n\n\n\n\n0\n12시 땡!\n하루가 또 가네요.\n0\n\n\n1\n1지망 학교 떨어졌어\n위로해 드립니다.\n0\n\n\n2\n3박4일 놀러가고 싶다\n여행은 언제나 좋죠.\n0\n\n\n3\n3박4일 정도 놀러가고 싶다\n여행은 언제나 좋죠.\n0\n\n\n4\nPPL 심하네\n눈살이 찌푸려지죠.\n0\n\n\n\n\n\n\n\n\nprint('챗봇 샘플의 개수 :', len(train_data))\n\n챗봇 샘플의 개수 : 11823\n\n\nNULL 값 확인\n\nprint(train_data.isnull().sum())\n\nQ        0\nA        0\nlabel    0\ndtype: int64\n\n\n?, ., !과 같은 구두점이 있는데 공백을 추가하여 다른 문자들과 구별\n\nquestions = []\nfor sentence in train_data['Q']:\n    # 구두점에 대해서 띄어쓰기\n    # ex) 12시 땡! -&gt; 12시 땡 !\n    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n    sentence = sentence.strip()\n    questions.append(sentence)\n\n\nanswers = []\nfor sentence in train_data['A']:\n    # 구두점에 대해서 띄어쓰기\n    # ex) 12시 땡! -&gt; 12시 땡 !\n    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n    sentence = sentence.strip()\n    answers.append(sentence)\n\n\nprint(questions[:5])\nprint(answers[:5])\n\n['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n\n\n\n\nMake Words Group\n\n# 서브워드텍스트인코더를 사용하여 질문, 답변 데이터로부터 단어 집합(Vocabulary) 생성\ntokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n    questions + answers, target_vocab_size=2**13)\n\n\n# 시작 토큰과 종료 토큰에 대한 정수 부여.\nSTART_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n\n# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\nVOCAB_SIZE = tokenizer.vocab_size + 2\n\n\nprint('시작 토큰 번호 :',START_TOKEN)\nprint('종료 토큰 번호 :',END_TOKEN)\nprint('단어 집합의 크기 :',VOCAB_SIZE)\n\n시작 토큰 번호 : [8178]\n종료 토큰 번호 : [8179]\n단어 집합의 크기 : 8180\n\n\n\n\n정수 인코딩과 패딩\n\n# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\nprint('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))\n\n임의의 질문 샘플을 정수 인코딩 : [5766, 611, 3509, 141, 685, 3747, 849]\n\n\n\n# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n# 임의의 입력 문장을 sample_string에 저장\nsample_string = questions[20]\n\n# encode() : 텍스트 시퀀스 --&gt; 정수 시퀀스\ntokenized_string = tokenizer.encode(sample_string)\nprint ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n\n# decode() : 정수 시퀀스 --&gt; 텍스트 시퀀스\noriginal_string = tokenizer.decode(tokenized_string)\nprint ('기존 문장: {}'.format(original_string))\n\n정수 인코딩 후의 문장 [5766, 611, 3509, 141, 685, 3747, 849]\n기존 문장: 가스비 비싼데 감기 걸리겠어\n\n\n\n# 각 정수는 각 단어와 어떻게 mapping되는지 병렬로 출력\n# 서브워드텍스트인코더는 의미있는 단위의 서브워드로 토크나이징한다. 띄어쓰기 단위 X 형태소 분석 단위 X\nfor ts in tokenized_string:\n    print ('{} ----&gt; {}'.format(ts, tokenizer.decode([ts])))\n\n5766 ----&gt; 가스\n611 ----&gt; 비 \n3509 ----&gt; 비싼\n141 ----&gt; 데 \n685 ----&gt; 감기 \n3747 ----&gt; 걸리\n849 ----&gt; 겠어\n\n\n\n# 최대 길이를 40으로 정의\nMAX_LENGTH = 40\n\n# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\ndef tokenize_and_filter(inputs, outputs):\n    tokenized_inputs, tokenized_outputs = [], []\n\n    for (sentence1, sentence2) in zip(inputs, outputs):\n        # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n\n        tokenized_inputs.append(sentence1)\n        tokenized_outputs.append(sentence2)\n\n        # 패딩\n        tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n            tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n        tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n            tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n        \n        return tokenized_inputs, tokenized_outputs\n\n\nquestions, answers = tokenize_and_filter(questions, answers)\n\n질문과 답변의 길이 변환\n\nprint('질문 데이터의 크기(shape) :', questions.shape)\nprint('답변 데이터의 크기(shape) :', answers.shape)\n\n질문 데이터의 크기(shape) : (1, 40)\n답변 데이터의 크기(shape) : (1, 40)\n\n\n\n# 0번 샘플을 임의로 출력\nprint(questions[0])\nprint(answers[0])\n\n[8178 7915 4207 3060   41 8179    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0]\n[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0]\n\n\n길이 40을 맞추기 위해 0이 패딩된 것 확인\n\n\nInput Encoders and Decoders and make Label\n\n# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\nBATCH_SIZE = 64\nBUFFER_SIZE = 20000\n\n# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\ndataset = tf.data.Dataset.from_tensor_slices((\n    {\n        'inputs': questions,\n        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n    },\n    {\n        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n    },\n))\n\ndataset = dataset.cache()\ndataset = dataset.shuffle(BUFFER_SIZE)\ndataset = dataset.batch(BATCH_SIZE)\ndataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n\n\n# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\nprint(answers[0]) # 기존 샘플\nprint(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\nprint(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다.\n\n[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0]\n[[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0]]\n[[3844   74 7894    1 8179    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0]]\n\n\n\n\nMake Transformer\n\n\\(d_{model}\\) = 256\nnum_layers = 2\nnum_heads = 8\n\\(d_{ff}\\) = 512\n\n\ntf.keras.backend.clear_session()\n\n# 하이퍼파라미터\nD_MODEL = 256\nNUM_LAYERS = 2\nNUM_HEADS = 8\nDFF = 512\nDROPOUT = 0.1\n\nmodel = transformer(\n    vocab_size=VOCAB_SIZE,\n    num_layers=NUM_LAYERS,\n    dff=DFF,\n    d_model=D_MODEL,\n    num_heads=NUM_HEADS,\n    dropout=DROPOUT)\n\n(1, 8180, 256)\n(1, 8180, 256)\n\n\n\nlearning_rate = CustomSchedule(D_MODEL)\n\noptimizer = tf.keras.optimizers.Adam(\n    learning_rate=0.001, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n\ndef accuracy(y_true, y_pred):\n    # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n\nmodel.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n\n\nEPOCHS = 50\nmodel.fit(dataset, epochs=EPOCHS,verbose=False)\n\n&lt;keras.callbacks.History at 0x7f2207d9cf10&gt;\n\n\n\n\nChatbot Evaluation\n\ndef preprocess_sentence(sentence):\n    # 단어와 구두점 사이에 공백 추가.\n    # ex) 12시 땡! -&gt; 12시 땡 !\n    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n    sentence = sentence.strip()\n    return sentence\n\n\ndef evaluate(sentence):\n    # 입력 문장에 대한 전처리\n    sentence = preprocess_sentence(sentence)\n\n    # 입력 문장에 시작 토큰과 종료 토큰을 추가\n    sentence = tf.expand_dims(\n      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n\n    output = tf.expand_dims(START_TOKEN, 0)\n\n    # 디코더의 예측 시작\n    for i in range(MAX_LENGTH):\n        predictions = model(inputs=[sentence, output], training=False)\n\n        # 현재 시점의 예측 단어를 받아온다.\n        predictions = predictions[:, -1:, :]\n        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n\n        # 만약 현재 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n        if tf.equal(predicted_id, END_TOKEN[0]):\n            break\n\n        # 현재 시점의 예측 단어를 output(출력)에 연결한다.\n        # output은 for문의 다음 루프에서 디코더의 입력이 된다.\n        output = tf.concat([output, predicted_id], axis=-1)\n\n    # 단어 예측이 모두 끝났다면 output을 리턴.\n    return tf.squeeze(output, axis=0)\n\n\ndef predict(sentence):\n    prediction = evaluate(sentence)\n\n    # prediction == 디코더가 리턴한 챗봇의 대답에 해당하는 정수 시퀀스\n    # tokenizer.decode()를 통해 정수 시퀀스를 문자열로 디코딩.\n    predicted_sentence = tokenizer.decode(\n      [i for i in prediction if i &lt; tokenizer.vocab_size])\n\n    print('Input: {}'.format(sentence))\n    print('Output: {}'.format(predicted_sentence))\n\n    return predicted_sentence\n\n\noutput = predict(\"영화 볼래?\")\n\nInput: 영화 볼래?\nOutput: 하루가 또 가네요 .\n\n\n\noutput = predict(\"고민이 있어\")\n\nInput: 고민이 있어\nOutput: 하루가 또 가네요 .\n\n\n\noutput = predict(\"카페갈래?\")\n\nInput: 카페갈래?\nOutput: 하루가 또 가네요 .\n\n\n\noutput = predict(\"게임하고싶당\")\n\nInput: 게임하고싶당\nOutput: 하루가 또 가네요 .\n\n\n\noutput = predict(\"게임하자\")\n\nInput: 게임하자\nOutput: 하루가 또 가네요 .\n\n\n터진다.."
  },
  {
    "objectID": "posts/ml_basic/index.html",
    "href": "posts/ml_basic/index.html",
    "title": "Machine Learning basic",
    "section": "",
    "text": "Let’s study Machine Learning from begining."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": ";)",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n \n\n\n07wk-2: 마코프체인 (3)\n\n\n \n\n\n\n\n \n\n\n09wk-1: 중간고사_sy\n\n\n \n\n\n\n\n \n\n\nA2: 강화학습 (2) – 4x4 grid\n\n\n \n\n\n\n\n \n\n\nA1: 강화학습 (1) – bandit\n\n\n \n\n\n\n\n \n\n\nA3: 강화학습 (3) – LunarLander\n\n\n \n\n\n\n\nAug 26, 2023\n\n\n[Coding Test]Python Programming HW review\n\n\nSEOYEON CHOI\n\n\n\n\nJul 30, 2023\n\n\nSpecial Topics in Applied Statistics\n\n\nSEOYEON CHOI\n\n\n\n\nJul 30, 2023\n\n\nMulticollinearity\n\n\nSEOYEON CHOI\n\n\n\n\nJun 20, 2023\n\n\n15wk-2: 기말고사\n\n\n최규빈 \n\n\n\n\nJun 15, 2023\n\n\nLaplace Distribution\n\n\nSEOYEON CHOI\n\n\n\n\nJun 13, 2023\n\n\n15wk: 기말고사\n\n\nGUEBIN CHOI\n\n\n\n\nJun 12, 2023\n\n\nPost Hoc Tests\n\n\nSEOYEON CHOI\n\n\n\n\nJun 12, 2023\n\n\nSteady State\n\n\nSEOYEON CHOI\n\n\n\n\nJun 9, 2023\n\n\nPharmacokinetic Analysis\n\n\nSEOYEON CHOI\n\n\n\n\nJun 6, 2023\n\n\n14wk: 이산형과 연속형의 통합\n\n\nGUEBIN CHOI\n\n\n\n\nJun 1, 2023\n\n\n14wk-1,2: MCMC (2)\n\n\n최규빈 \n\n\n\n\nJun 1, 2023\n\n\n15wk-1: MCMC (3)\n\n\n최규빈 \n\n\n\n\nJun 1, 2023\n\n\nSurvival Analysis Tutorial with R\n\n\nSEOYEON CHOI\n\n\n\n\nMay 30, 2023\n\n\n13wk: 밀도함수\n\n\nGUEBIN CHOI\n\n\n\n\nMay 30, 2023\n\n\n13wk-2: MCMC (1)\n\n\n최규빈 \n\n\n\n\nMay 28, 2023\n\n\nTransformer Chatbot Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nMay 28, 2023\n\n\nTransformers\n\n\nSEOYEON CHOI\n\n\n\n\nMay 28, 2023\n\n\nSequence-to-Sequence, seq2seq\n\n\nSEOYEON CHOI\n\n\n\n\nMay 28, 2023\n\n\nAttention Mechanism\n\n\nSEOYEON CHOI\n\n\n\n\nMay 25, 2023\n\n\n13wk-1: 마코프체인 (12)\n\n\n최규빈 \n\n\n\n\nMay 23, 2023\n\n\n12wk-2: 마코프체인 (11)\n\n\n최규빈 \n\n\n\n\nMay 23, 2023\n\n\n12wk: 적분 (2)\n\n\nGUEBIN CHOI\n\n\n\n\nMay 20, 2023\n\n\nManifold learning Embedding\n\n\nSEOYEON CHOI\n\n\n\n\nMay 18, 2023\n\n\n12wk-1: 마코프체인 (10)\n\n\n최규빈 \n\n\n\n\nMay 16, 2023\n\n\n11wk-2: 마코프체인 (9)\n\n\n최규빈 \n\n\n\n\nMay 16, 2023\n\n\n11wk: 적분 (1)\n\n\nGUEBIN CHOI\n\n\n\n\nMay 11, 2023\n\n\n11wk-1: 마코프체인 (8)\n\n\n최규빈 \n\n\n\n\nMay 9, 2023\n\n\nExpectation Maximization(EM algorithm)\n\n\nSEOYEON CHOI\n\n\n\n\nMay 9, 2023\n\n\n10wk: 분포, 분포함수\n\n\nGUEBIN CHOI\n\n\n\n\nMay 9, 2023\n\n\n10wk-2: 마코프체인 (7)\n\n\n최규빈 \n\n\n\n\nMay 4, 2023\n\n\nQuestions of PyTorch Geometric Temporal\n\n\nSEOYEON CHOI\n\n\n\n\nMay 2, 2023\n\n\n09wk: 확률변수\n\n\nGUEBIN CHOI\n\n\n\n\nApr 27, 2023\n\n\n09wk-1: 마코프체인 (6)\n\n\n최규빈 \n\n\n\n\nApr 27, 2023\n\n\nClinical Trial Data and Survival Analysis\n\n\nSEOYEON CHOI\n\n\n\n\nApr 25, 2023\n\n\n08wk-2: 마코프체인 (5)\n\n\n최규빈 \n\n\n\n\nApr 25, 2023\n\n\n08wk: 측도론 (4)\n\n\nGUEBIN CHOI\n\n\n\n\nApr 20, 2023\n\n\n08wk-1: 마코프체인 (4)\n\n\n최규빈 \n\n\n\n\nApr 20, 2023\n\n\nHazard ratio, Odds ratio\n\n\nSEOYEON CHOI\n\n\n\n\nApr 18, 2023\n\n\n7wk: 측도론 (3)\n\n\nGUEBIN CHOI\n\n\n\n\nApr 17, 2023\n\n\nAnything\n\n\nSEOYEON CHOI\n\n\n\n\nApr 17, 2023\n\n\nSurvival Analysis\n\n\nSEOYEON CHOI\n\n\n\n\nApr 13, 2023\n\n\n07wk-1: 마코프체인 (2)\n\n\n최규빈 \n\n\n\n\nApr 11, 2023\n\n\n06wk: 측도론 (2)\n\n\nGUEBIN CHOI\n\n\n\n\nApr 10, 2023\n\n\n06wk-2: 중간고사\n\n\n최규빈 \n\n\n\n\nApr 9, 2023\n\n\nClustering\n\n\nSEOYEON CHOI\n\n\n\n\nApr 9, 2023\n\n\nLogistic Regression\n\n\nSEOYEON CHOI\n\n\n\n\nApr 4, 2023\n\n\n05wk: 측도론 (1)\n\n\nGUEBIN CHOI\n\n\n\n\nApr 2, 2023\n\n\nEnsemble and Random Forest\n\n\nSEOYEON CHOI\n\n\n\n\nMar 30, 2023\n\n\n05wk-1: 마코프체인 (1)\n\n\n최규빈 \n\n\n\n\nMar 29, 2023\n\n\nLasso and Ridge\n\n\nSEOYEON CHOI\n\n\n\n\nMar 29, 2023\n\n\n05wk-2: HW1\n\n\n최규빈 \n\n\n\n\nMar 28, 2023\n\n\nPrincipal Component Analysis\n\n\nSEOYEON CHOI\n\n\n\n\nMar 28, 2023\n\n\n04wk: 측도론 intro (4)\n\n\nGUEBIN CHOI\n\n\n\n\nMar 28, 2023\n\n\n04wk-2: 측도론 intro (6)\n\n\n최규빈 \n\n\n\n\nMar 25, 2023\n\n\nSupport Vector Machine\n\n\nSEOYEON CHOI\n\n\n\n\nMar 23, 2023\n\n\nMachine Learning basic\n\n\nSEOYEON CHOI\n\n\n\n\nMar 23, 2023\n\n\n04wk-1: 측도론 intro (5)\n\n\n최규빈 \n\n\n\n\nMar 23, 2023\n\n\nTree\n\n\nSEOYEON CHOI\n\n\n\n\nMar 21, 2023\n\n\n03wk-2: 측도론 intro (4)\n\n\n최규빈 \n\n\n\n\nMar 21, 2023\n\n\n03wk: 측도론 intro (3)\n\n\nGUEBIN CHOI\n\n\n\n\nMar 19, 2023\n\n\nQueue\n\n\nSEOYEON CHOI\n\n\n\n\nMar 16, 2023\n\n\n03wk-1: 측도론 intro (3)\n\n\n최규빈 \n\n\n\n\nMar 14, 2023\n\n\n02wk: 측도론 intro (2)\n\n\nGUEBIN CHOI\n\n\n\n\nMar 14, 2023\n\n\n02wk-2: 측도론 intro (2)\n\n\n최규빈 \n\n\n\n\nMar 9, 2023\n\n\n02wk-1: 측도론 intro (1)\n\n\n최규빈 \n\n\n\n\nMar 7, 2023\n\n\nAdvanced Probability Theory\n\n\nSEOYEON CHOI\n\n\n\n\nMar 7, 2023\n\n\n1주차: 측도론\n\n\nSEOYEON CHOI\n\n\n\n\nMar 6, 2023\n\n\n01wk-2: 강의소개\n\n\n최규빈 \n\n\n\n\nMar 5, 2023\n\n\nStack\n\n\nSEOYEON CHOI\n\n\n\n\nMar 3, 2023\n\n\nAdvanced Regression Analysis GT\n\n\nSEOYEON CHOI\n\n\n\n\nMar 3, 2023\n\n\nTheoritical Statistics GT\n\n\nSEOYEON CHOI\n\n\n\n\nMar 3, 2023\n\n\nTheoritical Statistics Final term 6 Explanation\n\n\nGUEBIN CHOI\n\n\n\n\nFeb 23, 2023\n\n\nAdvanced Regression Analysis Final Term\n\n\nSEOYEON CHOI\n\n\n\n\nFeb 22, 2023\n\n\nAdvanced Regression Analysis Mid Term\n\n\nSEOYEON CHOI\n\n\n\n\nFeb 12, 2023\n\n\nArrayList & LinkedList\n\n\nSEOYEON CHOI\n\n\n\n\nJan 30, 2023\n\n\n코딩 테스트 공부(Done)\n\n\nSEOYEON CHOI\n\n\n\n\nJan 26, 2023\n\n\nTheoritical Statistics Final term\n\n\nSEOYEON CHOI\n\n\n\n\nJan 23, 2023\n\n\n두 큐 합 같게 만들기(Done)\n\n\nSEOYEON CHOI\n\n\n\n\nJan 21, 2023\n\n\n성격 유형 검사하기(Done)\n\n\nSEOYEON CHOI\n\n\n\n\nJan 20, 2023\n\n\nTheoritical Statistics HW9\n\n\nSEOYEON CHOI\n\n\n\n\nJan 18, 2023\n\n\nTheoritical Statistics HW8\n\n\nSEOYEON CHOI\n\n\n\n\nJan 18, 2023\n\n\nTheoritical Statistics HW7\n\n\nSEOYEON CHOI\n\n\n\n\nJan 15, 2023\n\n\nAlgorithm\n\n\nSEOYEON CHOI\n\n\n\n\nJan 15, 2023\n\n\n내장함수\n\n\nSEOYEON CHOI\n\n\n\n\nJan 15, 2023\n\n\nTheoritical Statistics Mid term\n\n\nSEOYEON CHOI\n\n\n\n\nJan 14, 2023\n\n\nTheoritical Statistics HW6\n\n\nSEOYEON CHOI\n\n\n\n\nJan 12, 2023\n\n\nTheoritical Statistics HW5\n\n\nSEOYEON CHOI\n\n\n\n\nJan 11, 2023\n\n\nTheoritical Statistics HW4\n\n\nSEOYEON CHOI\n\n\n\n\nJan 8, 2023\n\n\nTheoritical Statistics HW3\n\n\nSEOYEON CHOI\n\n\n\n\nJan 6, 2023\n\n\nTheoritical Statistics HW2\n\n\nSEOYEON CHOI\n\n\n\n\nJan 5, 2023\n\n\nTheoritical Statistics HW1\n\n\nSEOYEON CHOI\n\n\n\n\nJan 1, 2023\n\n\nChapter 03 Greedy\n\n\nSEOYEON CHOI\n\n\n\n\nDec 31, 2022\n\n\n확률변수와 확률분포\n\n\nSEOYEON CHOI\n\n\n\n\nDec 28, 2022\n\n\nCoding Test\n\n\nSEOYEON CHOI\n\n\n\n\nDec 27, 2022\n\n\nTheoritical Statistics\n\n\nSEOYEON CHOI\n\n\n\n\nDec 21, 2022\n\n\nExtra-2: 생성모형(GAN)\n\n\nSEOYEON CHOI\n\n\n\n\nDec 21, 2022\n\n\nExtra-1: 추천시스템\n\n\nSEOYEON CHOI\n\n\n\n\nDec 21, 2022\n\n\nExtra-3: 딥러닝의 기초 (5)\n\n\nSEOYEON CHOI\n\n\n\n\nDec 13, 2022\n\n\nFinalterm\n\n\nSEOYEON CHOI\n\n\n\n\nDec 11, 2022\n\n\n고급회귀분석 CH10\n\n\nSEOYEON CHOI\n\n\n\n\nDec 8, 2022\n\n\nRegression HW 4\n\n\nSEOYEON CHOI\n\n\n\n\nDec 8, 2022\n\n\nRNN (13주차)\n\n\nSEOYEON CHOI\n\n\n\n\nDec 8, 2022\n\n\nstudy\n\n\nSEOYEON CHOI\n\n\n\n\nDec 7, 2022\n\n\nA1: 깊은복사와 얕은복사 (12주차)\n\n\nSEOYEON CHOI\n\n\n\n\nDec 5, 2022\n\n\n고급회귀분석 실습 CH11\n\n\nSEOYEON CHOI\n\n\n\n\nNov 30, 2022\n\n\nRNN (12주차)\n\n\nSEOYEON CHOI\n\n\n\n\nNov 29, 2022\n\n\nDeep Learning final example\n\n\nSEOYEON CHOI\n\n\n\n\nNov 28, 2022\n\n\n고급회귀분석 실습 CH13\n\n\nSEOYEON CHOI\n\n\n\n\nNov 21, 2022\n\n\nRegression HW 3\n\n\nSEOYEON CHOI\n\n\n\n\nNov 21, 2022\n\n\n고급회귀분석 실습 CH10\n\n\nSEOYEON CHOI\n\n\n\n\nNov 21, 2022\n\n\nRNN (11주차)\n\n\nSEOYEON CHOI\n\n\n\n\nNov 14, 2022\n\n\n고급회귀분석 실습 CH06, CH07\n\n\nSEOYEON CHOI\n\n\n\n\nNov 9, 2022\n\n\nRNN (10주차)\n\n\nSEOYEON CHOI\n\n\n\n\nNov 2, 2022\n\n\nMidterm\n\n\nSEOYEON CHOI\n\n\n\n\nNov 2, 2022\n\n\nRNN (9주차)\n\n\nSEOYEON CHOI\n\n\n\n\nOct 26, 2022\n\n\nCNN (8주차) 2\n\n\nSEOYEON CHOI\n\n\n\n\nOct 26, 2022\n\n\nCNN (8주차) 1\n\n\nSEOYEON CHOI\n\n\n\n\nOct 23, 2022\n\n\nRegression HW 2\n\n\nSEOYEON CHOI\n\n\n\n\nOct 19, 2022\n\n\nCNN (7주차)\n\n\nSEOYEON CHOI\n\n\n\n\nOct 12, 2022\n\n\nDNN (6주차)\n\n\nSEOYEON CHOI\n\n\n\n\nOct 5, 2022\n\n\nHomework\n\n\nSEOYEON CHOI\n\n\n\n\nOct 5, 2022\n\n\nDNN (5주차)\n\n\nSEOYEON CHOI\n\n\n\n\nSep 29, 2022\n\n\nDNN (4주차)\n\n\nSEOYEON CHOI\n\n\n\n\nSep 21, 2022\n\n\nRegression HW 1\n\n\nSEOYEON CHOI\n\n\n\n\nSep 21, 2022\n\n\n고급회귀분석 실습 CH03, CH04\n\n\nSEOYEON CHOI\n\n\n\n\nSep 21, 2022\n\n\nDNN (3주차)\n\n\nSEOYEON CHOI\n\n\n\n\nSep 19, 2022\n\n\nAssignment 1\n\n\nSEOYEON CHOI\n\n\n\n\nSep 14, 2022\n\n\nDNN (2주차)\n\n\nSEOYEON CHOI\n\n\n\n\nSep 7, 2022\n\n\nIntro\n\n\nSEOYEON CHOI\n\n\n\n\nSep 7, 2022\n\n\nDNN (1주차)\n\n\nSEOYEON CHOI\n\n\n\n\nSep 1, 2022\n\n\nAdvanced Regression Analysis\n\n\nSEOYEON CHOI\n\n\n\n\nSep 1, 2022\n\n\nSpecial Topics in Machine Learning\n\n\nSEOYEON CHOI\n\n\n\n\nMar 31, 2021\n\n\nRidge Regression\n\n\nGUEBINCHOI \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/ml_basic/2023-05-20-Manifold learning Embedding.html",
    "href": "posts/ml_basic/2023-05-20-Manifold learning Embedding.html",
    "title": "Manifold learning Embedding",
    "section": "",
    "text": "Expectation Maximization\n참고: LocallyLinearEmbedding, t-SNE, 머신러닝 도감, sklean\nimport matplotlib.pyplot as plt\nimport numpy as np"
  },
  {
    "objectID": "posts/ml_basic/2023-05-20-Manifold learning Embedding.html#algorithm",
    "href": "posts/ml_basic/2023-05-20-Manifold learning Embedding.html#algorithm",
    "title": "Manifold learning Embedding",
    "section": "Algorithm",
    "text": "Algorithm\n\n데이터 포인트 \\(x_i\\) 근처에 있는 점(\\(k\\)개)을 찾는다.\n근처에 있는 \\(K\\)개 점의 선형 결합으로 \\(x_i\\)를 재구성하는 가중치 \\(W_{ij}\\)를 계산한다.\n가중치 \\(W_{ij}\\)로 낮은 차원(\\(d\\)차원)의 \\(y_i\\)를 계산한다.\n\n\nimport sklearn.datasets # 이제 sklearn에서 samples_generator없음\nfrom sklearn.manifold import LocallyLinearEmbedding\n\n\ndata, color = sklearn.datasets.make_swiss_roll(n_samples=1500)\n\n\ndata.shape\n\n(1500, 3)\n\n\n\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111, projection=\"3d\")\nfig.add_axes(ax)\nax.scatter(\n    data[:, 0], data[:, 1], data[:, 2], c=color, s=50, alpha=0.8\n)\nax.set_title(\"Swiss Roll in Ambient Space\")\nax.view_init(azim=-66, elev=12)\n_ = ax.text2D(0.8, 0.05, s=\"n_samples=1500\", transform=ax.transAxes)\n\n\n\n\n\nn_neighbors = 12 # 근처에 있는 점 개수\n\n\nn_components = 2 # 차원 축소 후 차원 수\n\n\n# 국소 선형 임베딩 모델 설정\nmodel = LocallyLinearEmbedding(n_neighbors = n_neighbors,\n                               n_components = n_components)\n\n\nmodel.fit(data) # 학습\n\nLocallyLinearEmbedding(n_neighbors=12)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LocallyLinearEmbeddingLocallyLinearEmbedding(n_neighbors=12)\n\n\n\nprint(model.transform(data)) # 차원 축소한 데이터 출력\n\n[[ 0.010313   -0.02643186]\n [-0.01607846 -0.01272895]\n [ 0.00912732  0.02124591]\n ...\n [ 0.03685466 -0.08256278]\n [ 0.00095445  0.00296153]\n [-0.00527724 -0.00157992]]\n\n\n\nlle = model.transform(data)\n\n\nmodel_5 = LocallyLinearEmbedding(n_neighbors = 5,\n                               n_components = n_components)\n\n\nmodel_5.fit(data) # 학습\n\nLocallyLinearEmbedding()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LocallyLinearEmbeddingLocallyLinearEmbedding()\n\n\n\nlle_5 = model_5.transform(data)\n\n\nmodel_50 = LocallyLinearEmbedding(n_neighbors = 50,\n                               n_components = n_components)\n\n\nmodel_50.fit(data) # 학습\n\nLocallyLinearEmbedding(n_neighbors=50)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LocallyLinearEmbeddingLocallyLinearEmbedding(n_neighbors=50)\n\n\n\nlle_50 = model_50.transform(data)\n\n\nfig, ax = plt.subplots(figsize=(15, 12), nrows=3)\nax[0].scatter(lle[:, 0], lle[:, 1], c=color, label = 'neighbors=12')\nax[0].legend(fontsize=15)\nax[0].set_title(\"LLE Embedding of Swiss Roll\")\nax[1].scatter(lle_5[:, 0], lle_5[:, 1], c=color, label = 'neighbors=5')\nax[1].legend(fontsize=15)\nax[2].scatter(lle_50[:, 0], lle_50[:, 1], c=color, label = 'neighbors=50')\nax[2].legend(fontsize=15)\n\n&lt;matplotlib.legend.Legend at 0x7f8953936e20&gt;\n\n\n\n\n\n\n근처에 있는 점이 5개라면 숨어 있는 낮은 차원의 데이터 구조를 꺼낼 수 없으므로 차우너 축소 후 점들이 좁은 범위에 모여 있다. 따라서 넓은 범위의 데이터 정보를 알 수 없다.\n근처에 있는 점이 50개라면 색깔이 다른 점이 근처에 있다. 근처에 있는 점 개수가 너무 많아서 일부 범위의 데이터 구조를 파악할 수 없다."
  },
  {
    "objectID": "posts/ml_basic/2023-05-20-Manifold learning Embedding.html#algorithm-1",
    "href": "posts/ml_basic/2023-05-20-Manifold learning Embedding.html#algorithm-1",
    "title": "Manifold learning Embedding",
    "section": "Algorithm",
    "text": "Algorithm\n\n모든 \\(i,j\\) 쌍에 관한 \\(x_i, x_j\\)의 유사도를 가우스 분포를 이용한 유사도로 나타낸다.\n\\(x_i\\)와 같은 개수의 점 \\(y_i\\)를 낮은 차원 공간에 무작위로 배치하고, 모든 \\(i,j\\)쌍에 관한 \\(y_i,y_j\\)의 유사도를 t분포를 이용해 나타낸다.\n1과 2에서 정의한 유사도 분포가 가능하면 같도록 데이터 포인트 \\(y_i\\)를 갱신한다.\n수렴 조건까지 과정 3을 반복한다.\n\n\nt분포는 헤비테일분포1이므로 높은 차원 공간에서는 중심에서 먼 부분의 비중이 높다.\n따라서 일부분의 정보를 유지하기 어려워 4차원 이상의 공간은 차원 축소가 제대로 되지 않을 수 있다.\n\n\nimport sklearn.datasets\nfrom sklearn.manifold import TSNE\n\n\n# 필기체 숫자 이미지 데이터세트 불러오기\ndata = sklearn.datasets.load_digits()\n\n\ndata.keys()\n\ndict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n\n\n\ndata['data']\n\narray([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n       ...,\n       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n       [ 0.,  0., 10., ..., 12.,  1.,  0.]])\n\n\n\nnp.array(data['data']).shape\n\n(1797, 64)\n\n\n\n# 2차원으로 차원 축소\nn_components = 2\n\n\n# t-분포 확률적 임베딩 모델 생성\nmodel = TSNE(n_components = n_components)\n\n\n# 특징으로 학습한 2차원 공간 값 출력\nprint(model.fit_transform(data.data))\n\nAttributeError: 'NoneType' object has no attribute 'split'\n\n\n[[ -2.8487089  53.309692 ]\n [ 10.247521  -12.026601 ]\n [-14.381865  -19.028639 ]\n ...\n [ -6.171889  -11.055643 ]\n [-21.39586    15.081427 ]\n [-14.349473   -7.253504 ]]\n\n\n\ntsne = model.fit_transform(data.data)\n\nAttributeError: 'NoneType' object has no attribute 'split'\n\n\n\nfig, ax = plt.subplots(figsize=(15, 12), nrows=1)\nax.scatter(tsne[:, 0], tsne[:, 1],c=data.target,label = 'n_components=2')\nax.legend(fontsize=15)\nax.set_title(\"t-SNE Embedding of the UCI ML hand-written digits\")\n\nText(0.5, 1.0, 't-SNE Embedding of the UCI ML hand-written digits')"
  },
  {
    "objectID": "posts/ml_basic/2023-04-09-Clustering.html",
    "href": "posts/ml_basic/2023-04-09-Clustering.html",
    "title": "Clustering",
    "section": "",
    "text": "Clustering\nReference: Pattern\n경성 군집화 hard clustering = 한 셈플이 하나의 군집에 속하도록 강제하는 방식\n연성 군집화 soft clustering = 샘플마다 군집에 속하는 정도를 다르게 할 수 있음"
  },
  {
    "objectID": "posts/ml_basic/2023-04-09-Clustering.html#최적화-문제로-해석",
    "href": "posts/ml_basic/2023-04-09-Clustering.html#최적화-문제로-해석",
    "title": "Clustering",
    "section": "최적화 문제로 해석",
    "text": "최적화 문제로 해석\nk평균은 직관에 기초한 휴리스틱한 알고리즘으로 보이는데, 이면에는 이론적인 토대를 갖추고 있다.\nk평균의 목적함수\n\\(J(Z,A) = \\sum^n_{i=1} \\sum^k_{j=1} a_{ji} dist(x_i, z_j)\\)\nZ는 군집 중심으로 A는 샘플의 배정 정보를 나타내는 k*n 행렬이다. i번째 샘플이 j번째 군집에 배정되었다면 \\(a_{ji}\\)는 1이고, 그렇지 않으면 0이다.\nk-평균은 최적화 문제를 푸는 알고리즘으로 볼 수 있다.\n\n루프를 반복하면서 목적함수의 값이 작아지는 방향으로 해를 갱신한다.\n어떤 초기 군집 중심을 가지고 출발하더라도 수렴한다는 것은 증명되었으나\n초기 군집 중심이 달라지면 최종 결과가 달라지는 문제가 있다."
  },
  {
    "objectID": "posts/ml_basic/2023-04-09-Clustering.html#em-기초",
    "href": "posts/ml_basic/2023-04-09-Clustering.html#em-기초",
    "title": "Clustering",
    "section": "EM 기초",
    "text": "EM 기초\nZ는 입출력단계에서 보이지 않는 은닉변수 latent variable\nEM 알고리즘 Expectation Maximazation algorithm\nE단계\n\n은닉변수를 추정하는 단계\n\nM단계\n\n매개변수를 추정하는 단계"
  },
  {
    "objectID": "posts/ml_basic/2023-04-09-Clustering.html#친밀도-전파-알고리즘",
    "href": "posts/ml_basic/2023-04-09-Clustering.html#친밀도-전파-알고리즘",
    "title": "Clustering",
    "section": "친밀도 전파 알고리즘",
    "text": "친밀도 전파 알고리즘\n소셜네트워크 자료에서 사용?"
  },
  {
    "objectID": "posts/ml_basic/2023-04-09-Clustering.html#커널-클러스터링",
    "href": "posts/ml_basic/2023-04-09-Clustering.html#커널-클러스터링",
    "title": "Clustering",
    "section": "커널 클러스터링",
    "text": "커널 클러스터링\n유클리드 거리로 표현되는 거리를 내적으로 표현해서 커널로 보내어 비선형으로 분리한 클러스터링 결과 얻기\n초기값의 영향을 많이 받아 결과가 바뀌기도"
  },
  {
    "objectID": "posts/ml_basic/2023-04-09-Clustering.html#스펙트럴-클러스터링",
    "href": "posts/ml_basic/2023-04-09-Clustering.html#스펙트럴-클러스터링",
    "title": "Clustering",
    "section": "스펙트럴 클러스터링",
    "text": "스펙트럴 클러스터링\n차원축소를 통래 초기값에 대한 의존성을 줄이려는 시도"
  },
  {
    "objectID": "posts/ml_basic/2023-04-09-Clustering.html#파라미터의-자동-결정",
    "href": "posts/ml_basic/2023-04-09-Clustering.html#파라미터의-자동-결정",
    "title": "Clustering",
    "section": "파라미터의 자동 결정",
    "text": "파라미터의 자동 결정\n직접 초기값 입력하면 거기에 의존하여 결과가 바뀌기도 하니 객관적으로 결정되게끔 파라미터 선택되게 하는 기법\n제곱 손실 상호정보량mutual information 사용 상호정보량보다 이상값에 민감하게 반응하지 않는디."
  },
  {
    "objectID": "posts/ml_basic/2023-06-15-Laplace.html",
    "href": "posts/ml_basic/2023-06-15-Laplace.html",
    "title": "Laplace Distribution",
    "section": "",
    "text": "Definition\nCDF(Cumulative Distribution Function) 누적 분포 함수\n가우시안 분포\n\\[F(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\int_{-\\infty}^x e^{\\frac{1}{2} (\\frac{x-\\mu}{\\sigma})^2}, -\\infty &lt; x&lt; \\infty\\]\n라플라스 분포Laplace distribution\n\\[F(x) = \\begin{cases} \\frac{1}{2}e^{\\frac{x-\\mu}{b}} & if x \\le \\mu \\\\\n                        1-\\frac{1}{2}e^{-\\frac{x-\\mu}{b}} & if x \\ge \\mu \\end{cases}\\]\nPDF(Probability Distribution Function) 확률 밀도 함수\n가우시안 분포\n\\[f(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{\\frac{1}{2} (\\frac{x-\\mu}{\\sigma})^2}, -\\infty &lt; x&lt; \\infty\\]\n라플라스 분포Laplace distribution\n\\[f(x) = \\frac{1}{2b}e^{-\\frac{|x-\\mu|}{b}}, -\\infty &lt; x&lt; \\infty\\]\n\n\nCDF\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm, laplace\n\n# 가우시안 분포\nmu = 0  # 평균\nsigma = 1  # 표준편차\n\nx = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)  # x 값 범위 설정\ngaussian_cdf = norm.cdf(x, loc=mu, scale=sigma)  # 가우시안 분포 CDF\n\nplt.plot(x, gaussian_cdf)\nplt.title('Gaussian Distribution CDF')\nplt.xlabel('x')\nplt.ylabel('Cumulative Probability')\nplt.show()\n\n# 라플라스 분포\nloc = 0  # 평균\nscale = 1  # 스케일 매개변수\n\nlaplace_cdf = laplace.cdf(x, loc=loc, scale=scale)  # 라플라스 분포 CDF\n\nplt.plot(x, laplace_cdf)\nplt.title('Laplace Distribution CDF')\nplt.xlabel('x')\nplt.ylabel('Cumulative Probability')\nplt.show()\n\n\n\n\n\n\n\n\n\nPDF\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 가우시안 분포\nmu = 0  # 평균\nsigma = 1  # 표준편차\n\nx = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)  # x 값 범위 설정\ngaussian = np.exp(-(x - mu)**2 / (2 * sigma**2)) / (sigma * np.sqrt(2 * np.pi))  # 가우시안 분포 함수\n\nplt.plot(x, gaussian)\nplt.title('Gaussian Distribution')\nplt.xlabel('x')\nplt.ylabel('Probability Density')\nplt.show()\n\n# 라플라스 분포\nloc = 0  # 평균\nscale = 1  # 스케일 매개변수\n\nlaplace = np.exp(-np.abs(x - loc) / scale) / (2 * scale)  # 라플라스 분포 함수\n\nplt.plot(x, laplace)\nplt.title('Laplace Distribution')\nplt.xlabel('x')\nplt.ylabel('Probability Density')\nplt.show()\n\n\n\n\n\n\n\n\n\nsigma/scale이 다를때\n\n# 가우시안 분포\nmu = 0  # 평균\nsigma = 1  # 표준편차\n\nx = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)  # x 값 범위 설정\ngaussian = np.exp(-(x - mu)**2 / (2 * sigma**2)) / (sigma * np.sqrt(2 * np.pi))  # 가우시안 분포 함수\n\nplt.plot(x, gaussian,label='sigma=1')\nplt.title('Gaussian Distribution')\nplt.xlabel('x')\nplt.ylabel('Probability Density')\n\nsigma = 2  # 표준편차\n\nx = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)  # x 값 범위 설정\ngaussian = np.exp(-(x - mu)**2 / (2 * sigma**2)) / (sigma * np.sqrt(2 * np.pi))  # 가우시안 분포 함수\n\nplt.plot(x, gaussian,label='sigma=2')\n\nsigma = 3  # 표준편차\n\nx = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)  # x 값 범위 설정\ngaussian = np.exp(-(x - mu)**2 / (2 * sigma**2)) / (sigma * np.sqrt(2 * np.pi))  # 가우시안 분포 함수\n\nplt.plot(x, gaussian,label='sigma=3')\nplt.legend(loc='upper left',facecolor='white', frameon=True)\n\n&lt;matplotlib.legend.Legend at 0x7fe5c3008eb0&gt;\n\n\n\n\n\n\n# 라플라스 분포\nloc = 0  # 평균\nscale = 1  # 스케일 매개변수\n\nlaplace = np.exp(-np.abs(x - loc) / scale) / (2 * scale)  # 라플라스 분포 함수\n\nplt.plot(x, laplace,label='scale=1')\nplt.title('Laplace Distribution')\nplt.xlabel('x')\nplt.ylabel('Probability Density')\n\nscale = 2  # 스케일 매개변수\n\nlaplace = np.exp(-np.abs(x - loc) / scale) / (2 * scale)  # 라플라스 분포 함수\n\nplt.plot(x, laplace,label='scale=2')\n\nscale = 3  # 스케일 매개변수\n\nlaplace = np.exp(-np.abs(x - loc) / scale) / (2 * scale)  # 라플라스 분포 함수\n\nplt.plot(x, laplace,label='scale=3')\nplt.legend(loc='upper left',facecolor='white', frameon=True)\n\n&lt;matplotlib.legend.Legend at 0x7fe5c33daca0&gt;"
  },
  {
    "objectID": "posts/ml_basic/2023-05-09-EM_algorithm.html",
    "href": "posts/ml_basic/2023-05-09-EM_algorithm.html",
    "title": "Expectation Maximization(EM algorithm)",
    "section": "",
    "text": "Expectation Maximization\nimport random"
  },
  {
    "objectID": "posts/ml_basic/2023-05-09-EM_algorithm.html#어떤-동전인지-알-때-expactation",
    "href": "posts/ml_basic/2023-05-09-EM_algorithm.html#어떤-동전인지-알-때-expactation",
    "title": "Expectation Maximization(EM algorithm)",
    "section": "어떤 동전인지 알 때 Expactation",
    "text": "어떤 동전인지 알 때 Expactation\n어떤 동전에서 어떤 면이 나올 기댓값을 직접 구할 수 있다.\n\n1: 앞 면\n2: 뒷 면\n\nA 동전\n\nN = 80\noutcomes = []\nfor i in range(N):\n    outcome = random.choice([1, 2])\n    outcomes.append(outcome)\nnum_of_ones = outcomes.count(1)\nprobability_of_one = num_of_ones / N\nprint(\"Number of ones:\", num_of_ones)\nprint(\"Probability of one:\", probability_of_one)\n\nNumber of ones: 37\nProbability of one: 0.4625\n\n\nB 동전\n\nN = 80\noutcomes = []\nfor i in range(N):\n    outcome = random.choice([1, 2])\n    outcomes.append(outcome)\nnum_of_ones = outcomes.count(1)\nprobability_of_one = num_of_ones / N\nprint(\"Number of ones:\", num_of_ones)\nprint(\"Probability of one:\", probability_of_one)\n\nNumber of ones: 45\nProbability of one: 0.5625"
  },
  {
    "objectID": "posts/ml_basic/2023-05-09-EM_algorithm.html#어떤-동전인지-모를-때-expactation",
    "href": "posts/ml_basic/2023-05-09-EM_algorithm.html#어떤-동전인지-모를-때-expactation",
    "title": "Expectation Maximization(EM algorithm)",
    "section": "어떤 동전인지 모를 때 Expactation",
    "text": "어떤 동전인지 모를 때 Expactation\n값이 어떤 동전에서 나오는지 모르는 경우\n\n10번 시도한 1 sequence: 앞/뒤/앞/뒤/뒤/앞/뒤/앞/앞/뒤\n사용되는 동전의 수 = hidden variable/latent variable\n\n임의의 초기값(랜덤 부여 가능)\n\n\\(\\theta_A = 0.4\\)\n\\(\\theta_B = 0.3\\)\n\n\nE step\n1 sequence에서 Hidden variable의 responsibility를 구한다.\nA 동전\n\n(0.4)**5*(0.6)**5\n\n0.0007962624\n\n\nB 동전\n\n(0.3)**5*(0.7)**5\n\n0.00040841009999999976\n\n\n1 sequence에서 A 동전을 사용했을 비율(responsibility)\n\nround(((0.4)**5*(0.6)**5)/((0.4)**5*(0.6)**5 + (0.3)**5*(0.7)**5),2)\n\n0.66\n\n\n1 sequence에서 B 동전을 사용했을 비율(responsibility)\n\nround(((0.3)**5*(0.7)**5)/((0.4)**5*(0.6)**5 + (0.3)**5*(0.7)**5),2)\n\n0.34\n\n\n\n\nM step\n1 sequence에서 A 동전 앞면\n\nround((0.66)*5,2)\n\n3.3\n\n\n1 sequence에서 A 동전 뒷면\n\nround((0.44)*5,2)\n\n2.2\n\n\n1 sequence에서 B 동전 앞면\n\nround((0.34)*5,2)\n\n1.7\n\n\n1 sequence에서 B 동전 뒷면\n\nround((0.66)*5,2)\n\n3.3\n\n\n\\(\\dots\\)\n이런 식으로 모든 sequence의 동전의 앞 뒷명면의 reponsibility를 사용하여 probability를 계산한다.\n\n\nUpdate\n\\(\\hat{\\theta}^{(1)}_A \\sim \\frac{14}{14+16} \\sim 0.47\\)\n\\(\\hat{\\theta}^{(1)}_B \\sim \\frac{14}{14+16} \\sim 0.38\\)\n\n\n…E/M step and Update Repeat\nLocal maximum으로 답 찾을 수 있음."
  },
  {
    "objectID": "posts/ml_basic/2023-03-28-Principal Component Analysis.html",
    "href": "posts/ml_basic/2023-03-28-Principal Component Analysis.html",
    "title": "Principal Component Analysis",
    "section": "",
    "text": "Principal Component Analysis\nRefernece: 핸즈 온 머신러닝, 최규빈교수님 통계전산강의노트 사이킷런 홈페이지"
  },
  {
    "objectID": "posts/ml_basic/2023-03-28-Principal Component Analysis.html#분산-보존",
    "href": "posts/ml_basic/2023-03-28-Principal Component Analysis.html#분산-보존",
    "title": "Principal Component Analysis",
    "section": "1. 분산 보존",
    "text": "1. 분산 보존\n분산이 최대로 보존되는 차원 축소가 정보를 가장 적게 손실되어 합리적으로 보임"
  },
  {
    "objectID": "posts/ml_basic/2023-03-28-Principal Component Analysis.html#주성분",
    "href": "posts/ml_basic/2023-03-28-Principal Component Analysis.html#주성분",
    "title": "Principal Component Analysis",
    "section": "2. 주성분",
    "text": "2. 주성분\n분산이 큰 순서대로 차원의 수만큼 찾음\ni번째 축 = 주성분 PC principal component\n특이값 분해 SVD singular value decomposition= training set에서 주성분 찾는 방법\n교수님 lecture note with julia\n\n이론 : \\(X_{n \\times m} = U_{n \\times n} D_{n \\times m} (V_{m \\times m})^\\top\\)\n\nver 1 = \\(U, V\\)가 모두 직교 행렬\nver 2 = \\(U\\) 또는 \\(V\\)가 직교 행렬\n\n왜?\n\n데이터 매트릭스 \\(X\\)가 존재할때 정보는 유지하면서 비용을 줄이는 \\(Z\\)4를 찾고 싶다.\n\\(Z\\) 구하는 법\n\n\\(Z = \\tilde{U} \\tilde{D}\\) \\(\\to\\) \\(\\tilde{U} \\tilde{D} = X\\tilde{V}\\) \\(\\to\\) \\(Z = X\\tilde{V}\\)\n\\(X^\\top X = \\psi \\lambda \\psi^\\top\\)을 구해서 \\(Z = X\\tilde{\\psi}\\) \\(\\to\\) \\(\\hat{X} = Z\\tilde{\\psi}^\\top\\)\n\n\n\n\\(\\star\\) PCA는 데이터셋의 평균이 0이라고 가정"
  },
  {
    "objectID": "posts/ml_basic/2023-03-28-Principal Component Analysis.html#d차원으로-투영하기",
    "href": "posts/ml_basic/2023-03-28-Principal Component Analysis.html#d차원으로-투영하기",
    "title": "Principal Component Analysis",
    "section": "3. d차원으로 투영하기",
    "text": "3. d차원으로 투영하기\n\\(X_{d-proj,n \\times d} = X_{n \\times M} W_{d,n \\times d}\\)"
  },
  {
    "objectID": "posts/ml_basic/2023-03-28-Principal Component Analysis.html#설명된-분산의-비율",
    "href": "posts/ml_basic/2023-03-28-Principal Component Analysis.html#설명된-분산의-비율",
    "title": "Principal Component Analysis",
    "section": "4. 설명된 분산의 비율",
    "text": "4. 설명된 분산의 비율\n설명된 분산의 비율 explained variance ratio\n\n공분산 행렬의 고유값\n투영한 분산의 비율\n주성분 선택된 순으로 작아짐"
  },
  {
    "objectID": "posts/ml_basic/2023-03-28-Principal Component Analysis.html#적절한-차원-수-선택하기",
    "href": "posts/ml_basic/2023-03-28-Principal Component Analysis.html#적절한-차원-수-선택하기",
    "title": "Principal Component Analysis",
    "section": "5. 적절한 차원 수 선택하기",
    "text": "5. 적절한 차원 수 선택하기\n차원 수를 임의로 정하는 것보다는 충분한 분산5이 될 떄까지 선택"
  },
  {
    "objectID": "posts/ml_basic/2023-03-28-Principal Component Analysis.html#압축을-위한-pca",
    "href": "posts/ml_basic/2023-03-28-Principal Component Analysis.html#압축을-위한-pca",
    "title": "Principal Component Analysis",
    "section": "6. 압축을 위한 PCA",
    "text": "6. 압축을 위한 PCA\n참고\n중요한 특징만을 살리기 위해 PCA를 시도하여 차원 축소하였다.\n이후 원본 데이터로 돌아가려 할 때 특징은 살아있지만 완벽히 데이터셋이 일치하지 않는데,\n여기서 이 오류를 재구성 오차 = 재건 오류 reconstruction error 라고 한다.\n\\(X_{n \\times M} = X_{d-proj,n \\times d} (W_{d,n \\times d})^\\top\\)"
  },
  {
    "objectID": "posts/ml_basic/2023-03-28-Principal Component Analysis.html#커널-pca",
    "href": "posts/ml_basic/2023-03-28-Principal Component Analysis.html#커널-pca",
    "title": "Principal Component Analysis",
    "section": "7. 커널 PCA",
    "text": "7. 커널 PCA\n차원 축소를 통해 비선형 투영 수행\n\\(\\zeta = \\Psi \\alpha\\)\n\n이 때, \\(||\\alpha_j|| = 1\\)로 정규화한다.\n그러기 위해 \\(\\alpha_j\\)를 \\(||\\zeta_j||\\)로 나누어 정규화\n\n\\(||\\zeta_j|| = \\sqrt{\\lambda}_j\\)\n\\(\\alpha_j \\to \\frac{1}{\\sqrt{\\lambda}_j} \\alpha_j, j=1, \\dots, m\\)\n\n\n특징 벡터로 내적하여 나오는 커널\\(K\\) 행렬로 중심화\n\n\\(K = HKH\\)\n\\(H = I_n - 1_{n \\times 1} /n\\)\n\n\\(\\alpha\\) 정규화 한 후 중심화하면\n\\((z_1, \\dots, z_n) = (\\frac{1}{\\sqrt{\\lambda_1}} \\alpha_1,\\dots , \\frac{1}{\\sqrt{\\lambda_m}}\\alpha_m)^\\top HKH\\)\n\n여기서 m개가 주성분!\n\n\n\n\nimage\n\n\n\\(\\star\\) 고유벡터\n\n선형 \\(C = \\psi \\psi^\\top\\)\n비선형 \\(K = \\psi^\\top \\psi\\)\n\n\\(\\psi\\)의 길이에 따라 고유값 문제의 표현을 다르게 하여 계산 시간 줄이기\n차원 수가 표본 수보다 큰 경우에는 커널 행렬을 사용하는 것이 효율적"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Sequence-to-Sequence, seq2seq.html",
    "href": "posts/ml_basic/2023-05-28-Sequence-to-Sequence, seq2seq.html",
    "title": "Sequence-to-Sequence, seq2seq",
    "section": "",
    "text": "Sequence-to-Sequence, seq2seq\nRef: 딥러닝을 이용한 자연어 처리 입문, keras"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Sequence-to-Sequence, seq2seq.html#teacher-forcing-교사-강요",
    "href": "posts/ml_basic/2023-05-28-Sequence-to-Sequence, seq2seq.html#teacher-forcing-교사-강요",
    "title": "Sequence-to-Sequence, seq2seq",
    "section": "Teacher Forcing 교사 강요",
    "text": "Teacher Forcing 교사 강요\n\ntrain에서는 이전 시점의 디코더 셀의 출력을 현재 시점의 디코더 셀의 입력으로 넣어주지 않음.\n이전 시점의 실제값을 현재 시점의 디코더 셀의 입력값으로 하는 방법 사용\n\n이전 시점의 디코더 셀의 예측이 틀렸는데 이를 현재 시점의 디코더 셀의 입력으로 사용하면 현재 시점의 디코더 셀의 예측에도 잘못될 가능성이 높음\n이는 연쇄 작용으로 디코더 전체의 예측을 어렵게 함\n이런 상황이 반복되면 훈련 시간이 느려질 수 있음\n\n\n교사 강요\n\nRNN의 모든 시점에 대해서 이전 시점의 예측값 대신 실제값을 입력으로 주는 방법"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Sequence-to-Sequence, seq2seq.html#seq2seq-기계-번역기-훈련",
    "href": "posts/ml_basic/2023-05-28-Sequence-to-Sequence, seq2seq.html#seq2seq-기계-번역기-훈련",
    "title": "Sequence-to-Sequence, seq2seq",
    "section": "seq2seq 기계 번역기 훈련",
    "text": "seq2seq 기계 번역기 훈련\n\nfrom tensorflow.keras.layers import Input, LSTM, Embedding, Dense\nfrom tensorflow.keras.models import Model\nimport numpy as np\n\nencoder_states 가 바로 컨텍스트 벡터\n\nencoder_inputs = Input(shape=(None, src_vocab_size))\nencoder_lstm = LSTM(units=256, return_state=True)\n\n# encoder_outputs은 여기서는 불필요\nencoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n\n# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 은닉 상태와 셀 상태.\nencoder_states = [state_h, state_c]\n\nreturn_state=True\n인코더의 내부 상태를 디코더로 넘겨주기 위해, False면 리턴하지 않음\n\ndecoder_inputs = Input(shape=(None, tar_vocab_size))\ndecoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n\n# 디코더에게 인코더의 은닉 상태, 셀 상태를 전달.\ndecoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n\ndecoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\ndecoder_outputs = decoder_softmax_layer(decoder_outputs)\n\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\nmodel.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n\n디코더는 은닉상태, 셀 상태를 사용하지 않기 때문에 _로 받아줌\n\nmodel.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=40, validation_split=0.2)\n\nEpoch 1/40\n750/750 [==============================] - 100s 131ms/step - loss: 0.8574 - val_loss: 0.7819\nEpoch 2/40\n750/750 [==============================] - 98s 131ms/step - loss: 0.5758 - val_loss: 0.6667\nEpoch 3/40\n750/750 [==============================] - 144s 191ms/step - loss: 0.5051 - val_loss: 0.6056\nEpoch 4/40\n750/750 [==============================] - 171s 229ms/step - loss: 0.4589 - val_loss: 0.5569\nEpoch 5/40\n750/750 [==============================] - 159s 213ms/step - loss: 0.4232 - val_loss: 0.5200\nEpoch 6/40\n750/750 [==============================] - 154s 205ms/step - loss: 0.3958 - val_loss: 0.4920\nEpoch 7/40\n750/750 [==============================] - 109s 145ms/step - loss: 0.3745 - val_loss: 0.4701\nEpoch 8/40\n750/750 [==============================] - 105s 140ms/step - loss: 0.3572 - val_loss: 0.4552\nEpoch 9/40\n750/750 [==============================] - 119s 159ms/step - loss: 0.3429 - val_loss: 0.4391\nEpoch 10/40\n750/750 [==============================] - 163s 218ms/step - loss: 0.3306 - val_loss: 0.4275\nEpoch 11/40\n750/750 [==============================] - 164s 219ms/step - loss: 0.3201 - val_loss: 0.4184\nEpoch 12/40\n750/750 [==============================] - 160s 213ms/step - loss: 0.3111 - val_loss: 0.4119\nEpoch 13/40\n750/750 [==============================] - 133s 177ms/step - loss: 0.3031 - val_loss: 0.4011\nEpoch 14/40\n750/750 [==============================] - 101s 135ms/step - loss: 0.2959 - val_loss: 0.3956\nEpoch 15/40\n750/750 [==============================] - 101s 135ms/step - loss: 0.2893 - val_loss: 0.3928\nEpoch 16/40\n750/750 [==============================] - 141s 188ms/step - loss: 0.2832 - val_loss: 0.3868\nEpoch 17/40\n750/750 [==============================] - 173s 230ms/step - loss: 0.2778 - val_loss: 0.3798\nEpoch 18/40\n750/750 [==============================] - 161s 215ms/step - loss: 0.2727 - val_loss: 0.3781\nEpoch 19/40\n750/750 [==============================] - 152s 202ms/step - loss: 0.2679 - val_loss: 0.3755\nEpoch 20/40\n750/750 [==============================] - 117s 156ms/step - loss: 0.2635 - val_loss: 0.3704\nEpoch 21/40\n750/750 [==============================] - 105s 140ms/step - loss: 0.2593 - val_loss: 0.3687\nEpoch 22/40\n750/750 [==============================] - 123s 164ms/step - loss: 0.2553 - val_loss: 0.3656\nEpoch 23/40\n750/750 [==============================] - 162s 216ms/step - loss: 0.2517 - val_loss: 0.3626\nEpoch 24/40\n750/750 [==============================] - 162s 217ms/step - loss: 0.2482 - val_loss: 0.3618\nEpoch 25/40\n750/750 [==============================] - 157s 209ms/step - loss: 0.2448 - val_loss: 0.3602\nEpoch 26/40\n750/750 [==============================] - 135s 180ms/step - loss: 0.2414 - val_loss: 0.3577\nEpoch 27/40\n750/750 [==============================] - 98s 131ms/step - loss: 0.2385 - val_loss: 0.3569\nEpoch 28/40\n750/750 [==============================] - 98s 131ms/step - loss: 0.2355 - val_loss: 0.3562\nEpoch 29/40\n750/750 [==============================] - 150s 200ms/step - loss: 0.2325 - val_loss: 0.3536\nEpoch 30/40\n750/750 [==============================] - 172s 229ms/step - loss: 0.2299 - val_loss: 0.3517\nEpoch 31/40\n750/750 [==============================] - 161s 214ms/step - loss: 0.2271 - val_loss: 0.3520\nEpoch 32/40\n750/750 [==============================] - 156s 208ms/step - loss: 0.2246 - val_loss: 0.3518\nEpoch 33/40\n750/750 [==============================] - 110s 147ms/step - loss: 0.2222 - val_loss: 0.3504\nEpoch 34/40\n750/750 [==============================] - 107s 143ms/step - loss: 0.2199 - val_loss: 0.3494\nEpoch 35/40\n750/750 [==============================] - 128s 171ms/step - loss: 0.2177 - val_loss: 0.3502\nEpoch 36/40\n750/750 [==============================] - 168s 224ms/step - loss: 0.2152 - val_loss: 0.3493\nEpoch 37/40\n750/750 [==============================] - 166s 221ms/step - loss: 0.2131 - val_loss: 0.3479\nEpoch 38/40\n750/750 [==============================] - 154s 205ms/step - loss: 0.2111 - val_loss: 0.3492\nEpoch 39/40\n750/750 [==============================] - 122s 162ms/step - loss: 0.2091 - val_loss: 0.3499\nEpoch 40/40\n750/750 [==============================] - 98s 131ms/step - loss: 0.2070 - val_loss: 0.3497\n\n\n&lt;keras.callbacks.History at 0x7fe721864a30&gt;"
  },
  {
    "objectID": "posts/ml_basic/2023-05-28-Sequence-to-Sequence, seq2seq.html#seq2seq-기계-번역기-동작",
    "href": "posts/ml_basic/2023-05-28-Sequence-to-Sequence, seq2seq.html#seq2seq-기계-번역기-동작",
    "title": "Sequence-to-Sequence, seq2seq",
    "section": "seq2seq 기계 번역기 동작",
    "text": "seq2seq 기계 번역기 동작\nSTEP 1. 번역하고자 하는 입력 문장이 인코더에 들어가 은닉 상태와 셀 상태를 얻는다.\nSTEP 2. 상태와 &lt;sos&gt;에 해당하는 \\t 를 디코더로 보낸다.\nSTEP 3. elzhejrk &lt;eos&gt;에 해당하는 \\n이 나올 때까지 다음 문자를 예측하는 행동을 반복한다.\n\nencoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n\n인코더 정의\n\n# 이전 시점의 상태들을 저장하는 텐서\ndecoder_state_input_h = Input(shape=(256,))\ndecoder_state_input_c = Input(shape=(256,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\n# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용.\n# 뒤의 함수 decode_sequence()에 동작을 구현 예정\ndecoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n\n# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태를 버리지 않음.\ndecoder_states = [state_h, state_c]\ndecoder_outputs = decoder_softmax_layer(decoder_outputs)\ndecoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n\n\ndecoder_inputs\n\n&lt;KerasTensor: shape=(None, None, 103) dtype=float32 (created by layer 'input_2')&gt;\n\n\n\ndecoder_states_inputs\n\n[&lt;KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'input_5')&gt;,\n &lt;KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'input_6')&gt;]\n\n\n디코더 설계\n\nindex_to_src = dict((i, char) for char, i in src_to_index.items())\nindex_to_tar = dict((i, char) for char, i in tar_to_index.items())\n\n인덱스에서 단어를 얻을 수 있도록 index_to_~설계\n\ndef decode_sequence(input_seq):\n    # 입력으로부터 인코더의 상태를 얻음\n    states_value = encoder_model.predict(input_seq)\n\n    # &lt;SOS&gt;에 해당하는 원-핫 벡터 생성\n    target_seq = np.zeros((1, 1, tar_vocab_size))\n    target_seq[0, 0, tar_to_index['\\t']] = 1.\n\n    stop_condition = False\n    decoded_sentence = \"\"\n\n    # stop_condition이 True가 될 때까지 루프 반복\n    while not stop_condition:\n        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n\n    # 예측 결과를 문자로 변환\n    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n    sampled_char = index_to_tar[sampled_token_index]\n\n    # 현재 시점의 예측 문자를 예측 문장에 추가\n    decoded_sentence += sampled_char\n\n    # &lt;eos&gt;에 도달하거나 최대 길이를 넘으면 중단.\n    if (sampled_char == '\\n' or\n        len(decoded_sentence) &gt; max_tar_len):\n        stop_condition = True\n\n    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n    target_seq = np.zeros((1, 1, tar_vocab_size))\n    target_seq[0, 0, sampled_token_index] = 1.\n\n    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n    states_value = [h, c]\n\n    return decoded_sentence\n\n\nstep by step\n\ninput_seq = encoder_input[5:10]\n\n\nstates_value = encoder_model.predict(input_seq)\n\n1/1 [==============================] - 0s 31ms/step\n\n\n\n# &lt;SOS&gt;에 해당하는 원-핫 벡터 생성\ntarget_seq = np.zeros((1, 1, tar_vocab_size))\n\n\ntarget_seq\n\narray([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0.]]])\n\n\n\ntarget_seq[0, 0, tar_to_index['\\t']] = 1.\n\n\ntarget_seq\n\narray([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0.]]])\n\n\n\nstop_condition = False\n\n\ndecoded_sentence = \"\"\n\n\n# Check dimensions of input arrays\nprint(target_seq.shape)            # Shape of target_seq\nprint(states_value[0].shape)       # Shape of states_value[0]\nprint(states_value[1].shape)       # Shape of states_value[1]\nprint(states_value[0][1,:].reshape(1,-1).shape)\nprint(states_value[1][1,:].reshape(1,-1).shape)\n\n(1, 1, 103)\n(5, 256)\n(5, 256)\n(1, 256)\n(1, 256)\n\n\n\nstates_value_tmp = [states_value[0][1,:].reshape(1,-1), states_value[1][1,:].reshape(1,-1)]\n\n\n# stop_condition이 True가 될 때까지 루프 반복\nwhile not stop_condition:\n    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n    output_tokens, h, c = decoder_model.predict([target_seq] + states_value_tmp)\n\n\noutput_tokens, h, c = decoder_model.predict([target_seq] + states_value_tmp)\n\n\n# 예측 결과를 문자로 변환\nsampled_token_index = np.argmax(output_tokens[0, -1, :])\nsampled_token_index\n\n\nsampled_char = index_to_tar[sampled_token_index]\nsampled_char\n\n\n# 현재 시점의 예측 문자를 예측 문장에 추가\ndecoded_sentence += sampled_char\n\n\n# &lt;eos&gt;에 도달하거나 최대 길이를 넘으면 중단.\nif (sampled_char == '\\n' or\n    len(decoded_sentence) &gt; max_tar_len):\n    stop_condition = True\n\n\n# 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\ntarget_seq = np.zeros((1, 1, tar_vocab_size))\ntarget_seq\n\n\ntarget_seq[0, 0, sampled_token_index] = 1.\n\n\n# 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\nstates_value = [h, c]\n\n\nprint('입력 문장:', lines.src[5])\nprint('정답 문장:', lines.tar[5][2:len(lines.tar[5])-1]) # '\\t'와 '\\n'을 빼고 출력\nprint('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력\n\n\nfor seq_index in [3,4]: # 입력 문장의 인덱스\n    input_seq = encoder_input[seq_index:seq_index+1]\n    decoded_sentence = decode_sequence(input_seq)\n    # print(35 * \"-\")\n    print('입력 문장:', lines.src[seq_index])\n    print('정답 문장:', lines.tar[seq_index][2:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n    print('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
  },
  {
    "objectID": "posts/ml_basic/2023-03-23-Support Vector Machine.html",
    "href": "posts/ml_basic/2023-03-23-Support Vector Machine.html",
    "title": "Support Vector Machine",
    "section": "",
    "text": "Support Vector Machine\nReference : 핸즈 온 머신러닝, 머신러닝 도감, 사이킷런 홈페이지\n마진이 아래 식으로 구해지는 이유\n어딘가의 SVM lecture 노트임!\n힌지 손실 Hinge Loss"
  },
  {
    "objectID": "posts/ml_basic/2023-03-23-Support Vector Machine.html#하드-마진-분류",
    "href": "posts/ml_basic/2023-03-23-Support Vector Machine.html#하드-마진-분류",
    "title": "Support Vector Machine",
    "section": "1) 하드 마진 분류",
    "text": "1) 하드 마진 분류\n\n클래스 분류의 경계에 샘플이 없을 때 = 마진 오류가 하나도 없을때, 하드 마진 분류\n\n선형적으로 구분되어야 함\n이상치에 민감함\n\n\n이 때 생기는 이상치를 마진 오류로 본다.\n\n이상치 \\(\\to\\) 클래스 구분했을때 그어지는 선에 걸쳐지는 값들 \\(\\to\\) 마진 오류 margin violation\n\n적절한 균형 잡는 것이 필요\n\\(minimize_{w,b} ||w||^2_2\\)\nsubject to \\(y_i(w^\\top x_i - b) \\ge 1 \\forall_i \\in \\{1, \\dots , n \\}\\)\n\n거의 불가능..한 자료 구조.."
  },
  {
    "objectID": "posts/ml_basic/2023-03-23-Support Vector Machine.html#소프트-마진-분류",
    "href": "posts/ml_basic/2023-03-23-Support Vector Machine.html#소프트-마진-분류",
    "title": "Support Vector Machine",
    "section": "2) 소프트 마진 분류",
    "text": "2) 소프트 마진 분류\n소프트 마진 분류 필요한 이유.\n\nhyper parameter C가 너무 크면 과대적합 가능성 존재\n\n손실함수는 힌지 손실 Hinge Loss\n\n주로 SVM과 함께 쓰임. \\(max(0,1-y), max(0,1+y)\\) 로 \\(y\\)의 범위가 [-1,1]에 오도록 함\n\n\\(minimize_{w,b,\\zeta} ||w||^2_2 + C\\sum^n_{i=1} \\zeta_i\\)\nsubject to \\(y_i(w^\\top x_i - b) \\ge 1-\\zeta_i, \\zeta_i \\ge 0 \\forall_i \\in \\{ 1 ,\\dots, n\\}\\)\n\n\\(1-\\zeta_i\\)로 잡음으로써 더 유연하게 이상치 정의 및 경계선 정의\n위처럼 선에 걸친게 마진 오류 margin violation"
  },
  {
    "objectID": "posts/ml_basic/2023-03-23-Support Vector Machine.html#다항식-커널",
    "href": "posts/ml_basic/2023-03-23-Support Vector Machine.html#다항식-커널",
    "title": "Support Vector Machine",
    "section": "1) 다항식 커널",
    "text": "1) 다항식 커널\n\n다항식은 잘 작동하기는 한데 설명변수가 너무 많아지면 오히려 모델을 느리게 만들어서 안 좋아.."
  },
  {
    "objectID": "posts/ml_basic/2023-03-23-Support Vector Machine.html#유사도-특성",
    "href": "posts/ml_basic/2023-03-23-Support Vector Machine.html#유사도-특성",
    "title": "Support Vector Machine",
    "section": "2) 유사도 특성",
    "text": "2) 유사도 특성\n\n특정 랜드마크와 얼마나 닮았는지 유사도 함수 similarity function = similarity measure = similarity metric 로 계산1\n\n특정 랜드마크 -&gt; 데이터 분포가 있을떄 뽑아진 임의의 점?\n\n\n유사도 함수의 종류\n\n유클리디안 거리 Euclidean Distance ; 모든 속성 고려\n코사인 유사도 Cosine Similarity ; 각으로 고려; -1~1사이\n마할라라비스 거리 ; 값들 사이의 공분산 이용\n민코스키 거리 Minkowski Distance ; 가장 큰 값만 고려"
  },
  {
    "objectID": "posts/ml_basic/2023-03-23-Support Vector Machine.html#가우시안-rbf-커널",
    "href": "posts/ml_basic/2023-03-23-Support Vector Machine.html#가우시안-rbf-커널",
    "title": "Support Vector Machine",
    "section": "3) 가우시안 RBF 커널2",
    "text": "3) 가우시안 RBF 커널2\n\nGaussian Radical Basis Function = Gaussian Kernel"
  },
  {
    "objectID": "posts/ml_basic/2023-03-23-Support Vector Machine.html#계산-복잡도",
    "href": "posts/ml_basic/2023-03-23-Support Vector Machine.html#계산-복잡도",
    "title": "Support Vector Machine",
    "section": "4) 계산 복잡도",
    "text": "4) 계산 복잡도\n\\(O(m\\times n)\\)\ncomputational complexity theory"
  },
  {
    "objectID": "posts/ml_basic/2023-03-23-Support Vector Machine.html#결정-함수와-예측",
    "href": "posts/ml_basic/2023-03-23-Support Vector Machine.html#결정-함수와-예측",
    "title": "Support Vector Machine",
    "section": "1) 결정 함수와 예측",
    "text": "1) 결정 함수와 예측\n선형 SVM을 훈련한다 = 마진 오류를 하나도 발생하지 않거나(하드 마진) 제한적인 마진 오류를 가지면서(소프트 마진) 가능한 한 마진을 크게 하는 \\(\\mathbb{w}\\)와 \\(b\\)를 찾는 것\n단순히 선형 회귀식 계산해서 0인지 1인지를 나눈다.\n\\(\\hat{y} = \\begin{cases} 0 & \\mathbb{w}^\\top \\mathbb{x} + b &lt; 0 \\text{ 일 때} \\\\ 1 & \\mathbb{w}^\\top \\mathbb{x} + b \\ge 0 \\text{ 일 때} \\end{cases}\\)"
  },
  {
    "objectID": "posts/ml_basic/2023-03-23-Support Vector Machine.html#목적-함수",
    "href": "posts/ml_basic/2023-03-23-Support Vector Machine.html#목적-함수",
    "title": "Support Vector Machine",
    "section": "2) 목적 함수",
    "text": "2) 목적 함수\n결정 함수의 기울기는 가중치 벡터의 노름 \\(||w||\\)와 같다.\n\n마진 크게 = \\(||w||\\) 최소화\n\n하드 마진 선형 SVM 분류기의 목적 함수\n\\(minimize_{w,b} \\frac{1}{2} \\mathbb{w^\\top w}\\)\n\\(\\star\\) 왜 \\(\\frac{1}{2} \\mathbb{w^\\top w}\\)? \\(||w||\\)는 \\(w=0\\)에서 미분도 되지 않음\n소프트 마진 선형 SVM 분류기의 목적 함수\n\n슬랙 변수 slack variable \\(\\zeta^{(i)} \\ge 0\\) 도입\n\ni번째 샘플이 얼마나 마진을 위반할지 정함\n\\(x &gt; b\\)\n\\(x = b + slack\\)\n\n\n-&gt; 슬랙변수는 경계를 나눌때 생기는 최소한의 오차로 생각하자\n마진 오류 최소화 방법\n\n슬랙 변수 값을 작게 만들기\n마진 크게 하기 위해 \\(\\frac{1}{2} \\mathbb{w^\\top w}\\) 최소화\n\n\\(minimize_{w,b,\\zeta} \\frac{1}{2} \\mathbb{w^\\top w} + C \\sum^m_{i=1}\\zeta^{(i)}\\)\n\\(\\star\\) hyper parameter \\(C\\) \\(\\to\\) 두 목표object 사이의 트레이드 오프 정의"
  },
  {
    "objectID": "posts/ml_basic/2023-03-23-Support Vector Machine.html#콰드라틱-프로그래밍",
    "href": "posts/ml_basic/2023-03-23-Support Vector Machine.html#콰드라틱-프로그래밍",
    "title": "Support Vector Machine",
    "section": "3) 콰드라틱 프로그래밍",
    "text": "3) 콰드라틱 프로그래밍\n콰드라틱 프로그래밍 Quadratic Programming, QP = 하드 마진과 소프트 마진 문제는 모두 선형적인 제약 조건이 있는 볼록 함수의 이차 최적화 문제"
  },
  {
    "objectID": "posts/ml_basic/2023-03-23-Support Vector Machine.html#쌍대-문제",
    "href": "posts/ml_basic/2023-03-23-Support Vector Machine.html#쌍대-문제",
    "title": "Support Vector Machine",
    "section": "4) 쌍대 문제",
    "text": "4) 쌍대 문제"
  },
  {
    "objectID": "posts/ml_basic/2023-03-23-Support Vector Machine.html#커널-svm",
    "href": "posts/ml_basic/2023-03-23-Support Vector Machine.html#커널-svm",
    "title": "Support Vector Machine",
    "section": "5) 커널 SVM",
    "text": "5) 커널 SVM\n원래 선형 분리할 수 없는 비선형 데이터를 커널을 통해서 선형화 시킴!\n\\(\\star\\) 가우시안 커널이 복잡한 결정 경게를 학습한다고 데이터에 무조건 비선형 커널 기법을 적용하지 말고(분석에 의미가 없을 수 있음), 선형 커널을 이용한 분석으로 확린 후 커널 함수를 적용한 분석을 하는 것이 좋음\n\n\n\nimage\n\n\n커널의 종류\n\n선형 커널 linear kernel 예시, 선형, 비선형 포함\n\n\\(&lt;x,x'&gt;\\)\n\n시그모이드 커널 sigmoid kernel\n\n\\(\\tanh(\\gamma&lt;x,x'&gt;+r)\\)\nwhere \\(r\\) is specified by coef0.\n\n다항 커널 polynomial kernel\n\n\\((\\gamma&lt;x,x'&gt; + r)^d\\)\nwhere \\(d\\) is specified by parameter degree, \\(r\\) by coef0.\n\nRBF 커널 = 가우시안 커널 rbf kernel\n\n\\(exp(-\\gamma||x - x'||^2)\\)\nwhere \\(r\\) is specified by parameter gamma, must be grater than 0\n\n복잡한 결정 경계 다룰때 좋을 듯\n\n\n\n\n\n\nimage.png\n\n\n쓰는 법\nlinear_svc = svm.SVC(kernel='linear')\nlinear_svc.kernel\n선형 커널\nlinear_svc = svm.SVC(kernel='sigmoid')\nlinear_svc.kernel\n시그모이드 커널\nlinear_svc = svm.SVC(kernel='poly')\nlinear_svc.kernel\n다항 커널\nrbf_svc = svm.SVC(kernel='rbf')\nrbf_svc.kernel\nrbf 커널"
  },
  {
    "objectID": "posts/ml_basic/2023-03-23-Support Vector Machine.html#온라인-svm",
    "href": "posts/ml_basic/2023-03-23-Support Vector Machine.html#온라인-svm",
    "title": "Support Vector Machine",
    "section": "6) 온라인 SVM",
    "text": "6) 온라인 SVM"
  },
  {
    "objectID": "posts/rl/index.html",
    "href": "posts/rl/index.html",
    "title": "Advanced Regression Analysis",
    "section": "",
    "text": "Those are posts of Advanced Regression Analysis."
  },
  {
    "objectID": "posts/rl/2022-12-05-rl-CH11.html",
    "href": "posts/rl/2022-12-05-rl-CH11.html",
    "title": "고급회귀분석 실습 CH11",
    "section": "",
    "text": "chapter 11 변수선택"
  },
  {
    "objectID": "posts/rl/2022-12-05-rl-CH11.html#단계적선택법",
    "href": "posts/rl/2022-12-05-rl-CH11.html#단계적선택법",
    "title": "고급회귀분석 실습 CH11",
    "section": "단계적선택법",
    "text": "단계적선택법\n\nm0 = lm(y ~ 1, data = dt)\n\n\nadd1(m0, \n     scope = y ~  x1 + x2 + x3+ x4,\n     test = \"F\")  ## x4추가\n\n\nA anova: 5 × 6\n\n\n\nDf\nSum of Sq\nRSS\nAIC\nF value\nPr(&gt;F)\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n&lt;none&gt;\nNA\nNA\n2715.7631\n71.44443\nNA\nNA\n\n\nx1\n1\n1450.0763\n1265.6867\n63.51947\n12.602518\n0.0045520446\n\n\nx2\n1\n1809.4267\n906.3363\n59.17799\n21.960605\n0.0006648249\n\n\nx3\n1\n776.3626\n1939.4005\n69.06740\n4.403417\n0.0597623242\n\n\nx4\n1\n1831.8962\n883.8669\n58.85164\n22.798520\n0.0005762318\n\n\n\n\n\n\nm1 &lt;- update(m0, ~ . +x4)\n\n\nsummary(m1)\n\n\nCall:\nlm(formula = y ~ x4, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-12.589  -8.228   1.495   4.726  17.524 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 117.5679     5.2622  22.342 1.62e-10 ***\nx4           -0.7382     0.1546  -4.775 0.000576 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 8.964 on 11 degrees of freedom\nMultiple R-squared:  0.6745,    Adjusted R-squared:  0.645 \nF-statistic:  22.8 on 1 and 11 DF,  p-value: 0.0005762\n\n\n\nadd1(m1, \n     scope = y ~  x1 + x2 + x3+ x4,\n     test = \"F\")  ## x1추가\n\n\nA anova: 4 × 6\n\n\n\nDf\nSum of Sq\nRSS\nAIC\nF value\nPr(&gt;F)\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n&lt;none&gt;\nNA\nNA\n883.86692\n58.85164\nNA\nNA\n\n\nx1\n1\n809.10480\n74.76211\n28.74170\n108.2239093\n1.105281e-06\n\n\nx2\n1\n14.98679\n868.88013\n60.62933\n0.1724839\n6.866842e-01\n\n\nx3\n1\n708.12891\n175.73800\n39.85258\n40.2945802\n8.375467e-05\n\n\n\n\n\n\nm2 &lt;- update(m1, ~ . +x1)\n\n\nsummary(m2)  #제거 없음\n\n\nCall:\nlm(formula = y ~ x4 + x1, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0234 -1.4737  0.1371  1.7305  3.7701 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 103.09738    2.12398   48.54 3.32e-13 ***\nx4           -0.61395    0.04864  -12.62 1.81e-07 ***\nx1            1.43996    0.13842   10.40 1.11e-06 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 2.734 on 10 degrees of freedom\nMultiple R-squared:  0.9725,    Adjusted R-squared:  0.967 \nF-statistic: 176.6 on 2 and 10 DF,  p-value: 1.581e-08\n\n\n\nadd1(m2, \n     scope = y ~  x1 + x2 + x3+ x4,\n     test = \"F\")  ## x2추가\n\n\nA anova: 3 × 6\n\n\n\nDf\nSum of Sq\nRSS\nAIC\nF value\nPr(&gt;F)\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n&lt;none&gt;\nNA\nNA\n74.76211\n28.74170\nNA\nNA\n\n\nx2\n1\n26.78938\n47.97273\n24.97388\n5.025865\n0.05168735\n\n\nx3\n1\n23.92599\n50.83612\n25.72755\n4.235846\n0.06969226\n\n\n\n\n\n\nm3 &lt;- update(m2, ~ . +x2)\n\n\nsummary(m3)  #x4 제거\n\n\nCall:\nlm(formula = y ~ x4 + x1 + x2, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0919 -1.8016  0.2562  1.2818  3.8982 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  71.6483    14.1424   5.066 0.000675 ***\nx4           -0.2365     0.1733  -1.365 0.205395    \nx1            1.4519     0.1170  12.410 5.78e-07 ***\nx2            0.4161     0.1856   2.242 0.051687 .  \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 2.309 on 9 degrees of freedom\nMultiple R-squared:  0.9823,    Adjusted R-squared:  0.9764 \nF-statistic: 166.8 on 3 and 9 DF,  p-value: 3.323e-08\n\n\n\nm4 &lt;- update(m3, ~ . -x4)\n\n\nadd1(m4, \n     scope = y ~  x1 + x2 + x3+ x4,\n     test = \"F\") #stop\n\n\nA anova: 3 × 6\n\n\n\nDf\nSum of Sq\nRSS\nAIC\nF value\nPr(&gt;F)\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n&lt;none&gt;\nNA\nNA\n57.90448\n25.41999\nNA\nNA\n\n\nx3\n1\n9.793869\n48.11061\n25.01120\n1.832128\n0.2088895\n\n\nx4\n1\n9.931754\n47.97273\n24.97388\n1.863262\n0.2053954\n\n\n\n\n\n\n#install.packages(\"leaps\")\n\n\nlibrary(leaps)\n\n\nfit&lt;-regsubsets(y~., data=dt, nbest=1,nvmax=4,\n                # method=c(\"exhaustive\",\"backward\", \n                #          \"forward\", \"seqrep\")\n                method='forward',\n                )\n\nfull model, nbest = 1개만 추가 nvmax 최대 4개 포함 가능\n\na &lt;- summary(fit)\n\n\nstr(a)\n\nList of 8\n $ which : logi [1:4, 1:5] TRUE TRUE TRUE TRUE FALSE TRUE ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:4] \"1\" \"2\" \"3\" \"4\"\n  .. ..$ : chr [1:5] \"(Intercept)\" \"x1\" \"x2\" \"x3\" ...\n $ rsq   : num [1:4] 0.675 0.972 0.982 0.982\n $ rss   : num [1:4] 883.9 74.8 48 47.9\n $ adjr2 : num [1:4] 0.645 0.967 0.976 0.974\n $ cp    : num [1:4] 138.73 5.5 3.02 5\n $ bic   : num [1:4] -9.46 -39.01 -42.21 -39.68\n $ outmat: chr [1:4, 1:4] \" \" \"*\" \"*\" \"*\" ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:4] \"1  ( 1 )\" \"2  ( 1 )\" \"3  ( 1 )\" \"4  ( 1 )\"\n  .. ..$ : chr [1:4] \"x1\" \"x2\" \"x3\" \"x4\"\n $ obj   :List of 28\n  ..$ np       : int 5\n  ..$ nrbar    : int 10\n  ..$ d        : num [1:5] 13 3362 390.2 154.7 10.5\n  ..$ rbar     : num [1:10] 30 7.4615 48.1538 11.7692 -0.0863 ...\n  ..$ thetab   : num [1:5] 95.423 -0.738 1.44 0.416 0.102\n  ..$ first    : int 2\n  ..$ last     : int 5\n  ..$ vorder   : int [1:5] 1 5 2 3 4\n  ..$ tol      : num [1:5] 1.80e-09 9.67e-08 2.36e-08 1.19e-07 3.72e-08\n  ..$ rss      : num [1:5] 2715.8 883.9 74.8 48 47.9\n  ..$ bound    : num [1:5] 2715.8 1265.7 57.9 48.1 47.9\n  ..$ nvmax    : int 5\n  ..$ ress     : num [1:5, 1] 2715.8 883.9 74.8 48 47.9\n  ..$ ir       : int 5\n  ..$ nbest    : num 1\n  ..$ lopt     : int [1:15, 1] 1 1 5 1 5 2 1 5 2 3 ...\n  ..$ il       : int 15\n  ..$ ier      : int 0\n  ..$ xnames   : chr [1:5] \"(Intercept)\" \"x1\" \"x2\" \"x3\" ...\n  ..$ method   : chr \"forward\"\n  ..$ force.in : Named logi [1:5] TRUE FALSE FALSE FALSE FALSE\n  .. ..- attr(*, \"names\")= chr [1:5] \"\" \"x1\" \"x2\" \"x3\" ...\n  ..$ force.out: Named logi [1:5] FALSE FALSE FALSE FALSE FALSE\n  .. ..- attr(*, \"names\")= chr [1:5] \"\" \"x1\" \"x2\" \"x3\" ...\n  ..$ sserr    : num 47.9\n  ..$ intercept: logi TRUE\n  ..$ lindep   : logi [1:5] FALSE FALSE FALSE FALSE FALSE\n  ..$ nullrss  : num 2716\n  ..$ nn       : int 13\n  ..$ call     : language regsubsets.formula(y ~ ., data = dt, nbest = 1, nvmax = 4, method = \"forward\",      )\n  ..- attr(*, \"class\")= chr \"regsubsets\"\n - attr(*, \"class\")= chr \"summary.regsubsets\"\n\n\n\nwith(summary(fit),\n     round(cbind(which,rss,rsq,adjr2, cp, bic),3))\n\n\nA matrix: 4 × 10 of type dbl\n\n\n\n(Intercept)\nx1\nx2\nx3\nx4\nrss\nrsq\nadjr2\ncp\nbic\n\n\n\n\n1\n1\n0\n0\n0\n1\n883.867\n0.675\n0.645\n138.731\n-9.463\n\n\n2\n1\n1\n0\n0\n1\n74.762\n0.972\n0.967\n5.496\n-39.008\n\n\n3\n1\n1\n1\n0\n1\n47.973\n0.982\n0.976\n3.018\n-42.211\n\n\n4\n1\n1\n1\n1\n1\n47.864\n0.982\n0.974\n5.000\n-39.675\n\n\n\n\n\n설명변수 하나 썼을때, 2개 썼을때,,, 선택되는 변수들\n설명변수2개.3개일때 Radj별로 차이 없어서 BIC 기준으로 2번째 꺼 선택\ncp &lt;= p+1(각 줄의 cp가 2,3,4,5보다 커야 함) -&gt; 2번째꺼 선택!\nstep- r 기본 함수\nm은 꼭 full model로 적어주기\n\n###Backward - AIC\nmodel_back = step(m, direction = \"backward\")\n\nStart:  AIC=26.94\ny ~ x1 + x2 + x3 + x4\n\n       Df Sum of Sq    RSS    AIC\n- x3    1    0.1091 47.973 24.974\n- x4    1    0.2470 48.111 25.011\n- x2    1    2.9725 50.836 25.728\n&lt;none&gt;              47.864 26.944\n- x1    1   25.9509 73.815 30.576\n\nStep:  AIC=24.97\ny ~ x1 + x2 + x4\n\n       Df Sum of Sq    RSS    AIC\n&lt;none&gt;               47.97 24.974\n- x4    1      9.93  57.90 25.420\n- x2    1     26.79  74.76 28.742\n- x1    1    820.91 868.88 60.629\n\n\nAIC 가장 작게하는 모형 기준으로 정렬되어 있음\n24.97 가장 작아 최종 모형 결정됌\n\nsummary(model_back)\n\n\nCall:\nlm(formula = y ~ x1 + x2 + x4, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0919 -1.8016  0.2562  1.2818  3.8982 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  71.6483    14.1424   5.066 0.000675 ***\nx1            1.4519     0.1170  12.410 5.78e-07 ***\nx2            0.4161     0.1856   2.242 0.051687 .  \nx4           -0.2365     0.1733  -1.365 0.205395    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 2.309 on 9 degrees of freedom\nMultiple R-squared:  0.9823,    Adjusted R-squared:  0.9764 \nF-statistic: 166.8 on 3 and 9 DF,  p-value: 3.323e-08\n\n\n\n###Forward - AIC\nmodel_forward = step(\n  m0, \n  scope = y ~  x1 + x2 + x3+ x4, \n  direction = \"forward\")\n\nStart:  AIC=71.44\ny ~ 1\n\n       Df Sum of Sq     RSS    AIC\n+ x4    1   1831.90  883.87 58.852\n+ x2    1   1809.43  906.34 59.178\n+ x1    1   1450.08 1265.69 63.519\n+ x3    1    776.36 1939.40 69.067\n&lt;none&gt;              2715.76 71.444\n\nStep:  AIC=58.85\ny ~ x4\n\n       Df Sum of Sq    RSS    AIC\n+ x1    1    809.10  74.76 28.742\n+ x3    1    708.13 175.74 39.853\n&lt;none&gt;              883.87 58.852\n+ x2    1     14.99 868.88 60.629\n\nStep:  AIC=28.74\ny ~ x4 + x1\n\n       Df Sum of Sq    RSS    AIC\n+ x2    1    26.789 47.973 24.974\n+ x3    1    23.926 50.836 25.728\n&lt;none&gt;              74.762 28.742\n\nStep:  AIC=24.97\ny ~ x4 + x1 + x2\n\n       Df Sum of Sq    RSS    AIC\n&lt;none&gt;              47.973 24.974\n+ x3    1   0.10909 47.864 26.944\n\n\n정해진 식에서 설명변수만 추가하고\n\nsummary(model_forward)\n\n\nCall:\nlm(formula = y ~ x4 + x1 + x2, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0919 -1.8016  0.2562  1.2818  3.8982 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  71.6483    14.1424   5.066 0.000675 ***\nx4           -0.2365     0.1733  -1.365 0.205395    \nx1            1.4519     0.1170  12.410 5.78e-07 ***\nx2            0.4161     0.1856   2.242 0.051687 .  \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 2.309 on 9 degrees of freedom\nMultiple R-squared:  0.9823,    Adjusted R-squared:  0.9764 \nF-statistic: 166.8 on 3 and 9 DF,  p-value: 3.323e-08\n\n\n\n###Step - AIC\nmodel_step = step(\n  m0, \n  scope =  y ~  x1 + x2 + x3+ x4, \n  direction = \"both\")\n\nStart:  AIC=71.44\ny ~ 1\n\n       Df Sum of Sq     RSS    AIC\n+ x4    1   1831.90  883.87 58.852\n+ x2    1   1809.43  906.34 59.178\n+ x1    1   1450.08 1265.69 63.519\n+ x3    1    776.36 1939.40 69.067\n&lt;none&gt;              2715.76 71.444\n\nStep:  AIC=58.85\ny ~ x4\n\n       Df Sum of Sq     RSS    AIC\n+ x1    1    809.10   74.76 28.742\n+ x3    1    708.13  175.74 39.853\n&lt;none&gt;               883.87 58.852\n+ x2    1     14.99  868.88 60.629\n- x4    1   1831.90 2715.76 71.444\n\nStep:  AIC=28.74\ny ~ x4 + x1\n\n       Df Sum of Sq     RSS    AIC\n+ x2    1     26.79   47.97 24.974\n+ x3    1     23.93   50.84 25.728\n&lt;none&gt;                74.76 28.742\n- x1    1    809.10  883.87 58.852\n- x4    1   1190.92 1265.69 63.519\n\nStep:  AIC=24.97\ny ~ x4 + x1 + x2\n\n       Df Sum of Sq    RSS    AIC\n&lt;none&gt;               47.97 24.974\n- x4    1      9.93  57.90 25.420\n+ x3    1      0.11  47.86 26.944\n- x2    1     26.79  74.76 28.742\n- x1    1    820.91 868.88 60.629\n\n\n\nsummary(model_step)\n\n\nCall:\nlm(formula = y ~ x4 + x1 + x2, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0919 -1.8016  0.2562  1.2818  3.8982 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  71.6483    14.1424   5.066 0.000675 ***\nx4           -0.2365     0.1733  -1.365 0.205395    \nx1            1.4519     0.1170  12.410 5.78e-07 ***\nx2            0.4161     0.1856   2.242 0.051687 .  \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 2.309 on 9 degrees of freedom\nMultiple R-squared:  0.9823,    Adjusted R-squared:  0.9764 \nF-statistic: 166.8 on 3 and 9 DF,  p-value: 3.323e-08\n\n\n\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\n\nround(cor(mtcars),2)\n\n\nA matrix: 11 × 11 of type dbl\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nmpg\n1.00\n-0.85\n-0.85\n-0.78\n0.68\n-0.87\n0.42\n0.66\n0.60\n0.48\n-0.55\n\n\ncyl\n-0.85\n1.00\n0.90\n0.83\n-0.70\n0.78\n-0.59\n-0.81\n-0.52\n-0.49\n0.53\n\n\ndisp\n-0.85\n0.90\n1.00\n0.79\n-0.71\n0.89\n-0.43\n-0.71\n-0.59\n-0.56\n0.39\n\n\nhp\n-0.78\n0.83\n0.79\n1.00\n-0.45\n0.66\n-0.71\n-0.72\n-0.24\n-0.13\n0.75\n\n\ndrat\n0.68\n-0.70\n-0.71\n-0.45\n1.00\n-0.71\n0.09\n0.44\n0.71\n0.70\n-0.09\n\n\nwt\n-0.87\n0.78\n0.89\n0.66\n-0.71\n1.00\n-0.17\n-0.55\n-0.69\n-0.58\n0.43\n\n\nqsec\n0.42\n-0.59\n-0.43\n-0.71\n0.09\n-0.17\n1.00\n0.74\n-0.23\n-0.21\n-0.66\n\n\nvs\n0.66\n-0.81\n-0.71\n-0.72\n0.44\n-0.55\n0.74\n1.00\n0.17\n0.21\n-0.57\n\n\nam\n0.60\n-0.52\n-0.59\n-0.24\n0.71\n-0.69\n-0.23\n0.17\n1.00\n0.79\n0.06\n\n\ngear\n0.48\n-0.49\n-0.56\n-0.13\n0.70\n-0.58\n-0.21\n0.21\n0.79\n1.00\n0.27\n\n\ncarb\n-0.55\n0.53\n0.39\n0.75\n-0.09\n0.43\n-0.66\n-0.57\n0.06\n0.27\n1.00\n\n\n\n\n\n\nm_full &lt;- lm(mpg~., mtcars)\n\n\nsummary(m_full)\n\n\nCall:\nlm(formula = mpg ~ ., data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4506 -1.6044 -0.1196  1.2193  4.6271 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) 12.30337   18.71788   0.657   0.5181  \ncyl         -0.11144    1.04502  -0.107   0.9161  \ndisp         0.01334    0.01786   0.747   0.4635  \nhp          -0.02148    0.02177  -0.987   0.3350  \ndrat         0.78711    1.63537   0.481   0.6353  \nwt          -3.71530    1.89441  -1.961   0.0633 .\nqsec         0.82104    0.73084   1.123   0.2739  \nvs           0.31776    2.10451   0.151   0.8814  \nam           2.52023    2.05665   1.225   0.2340  \ngear         0.65541    1.49326   0.439   0.6652  \ncarb        -0.19942    0.82875  -0.241   0.8122  \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 2.65 on 21 degrees of freedom\nMultiple R-squared:  0.869, Adjusted R-squared:  0.8066 \nF-statistic: 13.93 on 10 and 21 DF,  p-value: 3.793e-07\n\n\n모형은 유의한데 변수들은 유의하지 않아 다중공선성 의심\n\nfit&lt;-regsubsets(mpg~., data=mtcars, nbest=1,nvmax=9,\n                # method=c(\"exhaustive\",\"backward\", \"forward\", \"seqrep\")\n                method='exhaustive',\n)\n\n변수 9개 이용 best 1개만 뽑기\n\nsummary(fit)\n\nSubset selection object\nCall: regsubsets.formula(mpg ~ ., data = mtcars, nbest = 1, nvmax = 9, \n    method = \"exhaustive\", )\n10 Variables  (and intercept)\n     Forced in Forced out\ncyl      FALSE      FALSE\ndisp     FALSE      FALSE\nhp       FALSE      FALSE\ndrat     FALSE      FALSE\nwt       FALSE      FALSE\nqsec     FALSE      FALSE\nvs       FALSE      FALSE\nam       FALSE      FALSE\ngear     FALSE      FALSE\ncarb     FALSE      FALSE\n1 subsets of each size up to 9\nSelection Algorithm: exhaustive\n         cyl disp hp  drat wt  qsec vs  am  gear carb\n1  ( 1 ) \" \" \" \"  \" \" \" \"  \"*\" \" \"  \" \" \" \" \" \"  \" \" \n2  ( 1 ) \"*\" \" \"  \" \" \" \"  \"*\" \" \"  \" \" \" \" \" \"  \" \" \n3  ( 1 ) \" \" \" \"  \" \" \" \"  \"*\" \"*\"  \" \" \"*\" \" \"  \" \" \n4  ( 1 ) \" \" \" \"  \"*\" \" \"  \"*\" \"*\"  \" \" \"*\" \" \"  \" \" \n5  ( 1 ) \" \" \"*\"  \"*\" \" \"  \"*\" \"*\"  \" \" \"*\" \" \"  \" \" \n6  ( 1 ) \" \" \"*\"  \"*\" \"*\"  \"*\" \"*\"  \" \" \"*\" \" \"  \" \" \n7  ( 1 ) \" \" \"*\"  \"*\" \"*\"  \"*\" \"*\"  \" \" \"*\" \"*\"  \" \" \n8  ( 1 ) \" \" \"*\"  \"*\" \"*\"  \"*\" \"*\"  \" \" \"*\" \"*\"  \"*\" \n9  ( 1 ) \" \" \"*\"  \"*\" \"*\"  \"*\" \"*\"  \"*\" \"*\" \"*\"  \"*\" \n\n\n\nwith(summary(fit),\n     round(cbind(which,rss,rsq,adjr2, cp, bic),3))\n\n\nA matrix: 9 × 16 of type dbl\n\n\n\n(Intercept)\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\nrss\nrsq\nadjr2\ncp\nbic\n\n\n\n\n1\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n278.322\n0.753\n0.745\n11.627\n-37.795\n\n\n2\n1\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n191.172\n0.830\n0.819\n1.219\n-46.348\n\n\n3\n1\n0\n0\n0\n0\n1\n1\n0\n1\n0\n0\n169.286\n0.850\n0.834\n0.103\n-46.773\n\n\n4\n1\n0\n0\n1\n0\n1\n1\n0\n1\n0\n0\n160.066\n0.858\n0.837\n0.790\n-45.099\n\n\n5\n1\n0\n1\n1\n0\n1\n1\n0\n1\n0\n0\n153.438\n0.864\n0.838\n1.846\n-42.987\n\n\n6\n1\n0\n1\n1\n1\n1\n1\n0\n1\n0\n0\n150.093\n0.867\n0.835\n3.370\n-40.227\n\n\n7\n1\n0\n1\n1\n1\n1\n1\n0\n1\n1\n0\n148.528\n0.868\n0.830\n5.147\n-37.096\n\n\n8\n1\n0\n1\n1\n1\n1\n1\n0\n1\n1\n1\n147.843\n0.869\n0.823\n7.050\n-33.779\n\n\n9\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n147.574\n0.869\n0.815\n9.011\n-30.371\n\n\n\n\n\n3번째 줄이 cp 가장 작음\nrss = sse\n3,4,5 들이 좋은 모형이라 할 수 있다.\nBIC -46.773(3번째)가 가장 큼 절댓값으로\n4번이 좋은 모형으로 본다면?\n\nfit_4 &lt;- lm(mpg~hp+wt+qsec+am, mtcars)\n\n\nsummary(fit_4)\n\n\nCall:\nlm(formula = mpg ~ hp + wt + qsec + am, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4975 -1.5902 -0.1122  1.1795  4.5404 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept) 17.44019    9.31887   1.871  0.07215 . \nhp          -0.01765    0.01415  -1.247  0.22309   \nwt          -3.23810    0.88990  -3.639  0.00114 **\nqsec         0.81060    0.43887   1.847  0.07573 . \nam           2.92550    1.39715   2.094  0.04579 * \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 2.435 on 27 degrees of freedom\nMultiple R-squared:  0.8579,    Adjusted R-squared:  0.8368 \nF-statistic: 40.74 on 4 and 27 DF,  p-value: 4.589e-11"
  },
  {
    "objectID": "posts/rl/2022-11-23-rl-CH10.html",
    "href": "posts/rl/2022-11-23-rl-CH10.html",
    "title": "고급회귀분석 실습 CH10",
    "section": "",
    "text": "CH10"
  },
  {
    "objectID": "posts/rl/2022-11-23-rl-CH10.html#데이터-입력",
    "href": "posts/rl/2022-11-23-rl-CH10.html#데이터-입력",
    "title": "고급회귀분석 실습 CH10",
    "section": "데이터 입력",
    "text": "데이터 입력\n\ndt &lt;- data.frame(x = c(15,26,10,9,15,20,18,11,\n                       8,20,7,9,10,11,11,10,12,42,17,11,10),\n                 y = c(95,71,83,91,102,87,93,100,\n                       104,94,113,96,83,84,102,100,\n                       105,57,121,86,100))\n\n\n산점도\n\nplot(y~x, dt,pch  = 20,cex  = 2,col  = \"darkorange\")\n\n\n\n\n\n\n회귀적합\n\nmodel_reg &lt;- lm(y~x, dt)\n\n\nsummary(model_reg)\n\n\nCall:\nlm(formula = y ~ x, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.604  -8.731   1.396   4.523  30.285 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 109.8738     5.0678  21.681 7.31e-15 ***\nx            -1.1270     0.3102  -3.633  0.00177 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 11.02 on 19 degrees of freedom\nMultiple R-squared:   0.41, Adjusted R-squared:  0.3789 \nF-statistic:  13.2 on 1 and 19 DF,  p-value: 0.001769\n\n\n\nplot(y~x, dt,pch  = 20,cex  = 2,col  = \"darkorange\")\nabline(model_reg, col='steelblue', lwd=2)\n\n\n\n\n\n\n잔차\n\nresidual &lt;- model_reg$residuals  ## e_i = y_i - hat(y_i)\n## resid(model_reg)\n\n\n\n내적으로 표준화된 잔차\n\ns_residual&lt;- rstandard(model_reg)\n\n\n# # 또는\n# s_xx &lt;- sum((dt$x-mean(dt$x))^2)  #S_xx\n# h_ii &lt;- 1/21 + (dt$x- mean(dt$x))^2/s_xx\n# ## h_ii &lt;- influence(model_reg)$hat\n# hat_sigma &lt;-  summary(model_reg)$sigma   #hat sigma\n# s_residual &lt;- residual/(hat_sigma*sqrt(1-h_ii)) ## 내적\n\n\n\n외적으로 스튜던트화된 잔차\n\ns_residual_i &lt;- rstudent(model_reg) ## 외적으로 스튜던트화 잔차\n\n\n# # 또는\n# hat_sigma_i &lt;- sqrt(((21-1-1)*hat_sigma^2 - residual^2/(1-h_ii) )/(21-1-2))\n# ## hat_sigma_i &lt;- influence(model_reg)$sigma\n# s_residual_i &lt;-  residual/(hat_sigma_i*sqrt(1-h_ii)) ## 외적\n\n\n\n잔차그림\n\npar(mfrow = c(2, 2))\n\nplot(fitted(model_reg), residual, \n     pch=20,cex  = 2,col  = \"darkorange\",\n     xlab = \"Fitted\", ylab = \"Residuals\", \n     main = \"residual plot\")\nabline(h=0, lty=2)\n\nplot(fitted(model_reg), s_residual, \n     pch=20,cex  = 2,col  = \"darkorange\",\n     xlab = \"Fitted\", ylab = \"S_Residuals\", \n     ylim=c(min(-3, min(s_residual)), \n            max(3,max(s_residual))),\n     main = \"standardized residual plot\")\nabline(h=c(-2,0,2), lty=2)\n\nplot(fitted(model_reg), s_residual_i, \n     pch=20,cex  = 2,col  = \"darkorange\",\n     xlab = \"Fitted\", ylab = \"S_Residuals_(i)\", \n     ylim=c(min(-3, min(s_residual_i)), \n            max(3,max(s_residual_i))),\n     main = \"studentized residual plot\")\nabline(h=c(-3,-2,0,2,3), lty=2)\n\nplot(fitted(model_reg), s_residual_i, \n     pch=20,cex  = 2,col  = \"darkorange\",\n     xlab = \"Fitted\", ylab = \"S_Residuals_(i)\", \n     ylim=c(min(-3, min(s_residual_i)), \n            max(3,max(s_residual_i))),\n     main = \"studentized residual plot\")\nabline(h=c(-qt(0.975,21-2),0,qt(0.975,21-2)), lty=2)\ntext (fitted(model_reg)[which(abs(s_residual_i)&gt;qt(0.975,21-2))],\n      s_residual_i[which(abs(s_residual_i)&gt;qt(0.975,21-2))], \n      which(abs(s_residual_i)&gt;qt(0.975,21-2)),adj = c(0,1))\n\n\n\n\n\n## 이상치 검정\nqt(0.975,21-2) #기각역 \n\n2.09302405440831\n\n\n\ns_residual_i\n\n10.1839684933793942-0.9415833513782013-1.510811922917994-0.81426336315943850.8328629175207956-0.03063182753708870.31124676473215880.22971574964993190.289910136925676100.617660260595883111.0508471635886512-0.34283148352928113-1.5108119229179914-1.27977575448039150.413153195694502160.127393415386012170.79828114441511618-0.845110861537551193.6069797213043920-1.07648107628971210.127393415386012\n\n\n\ns_residual_i[which(abs(s_residual_i)&gt;qt(0.975,21-2))]\n\n19: 3.60697972130439\n\n\n\n## 정규성 검정\npar(mfrow=c(1,2))\nhist(resid(model_reg),\n     xlab   = \"Residuals\",\n     main   = \"Histogram of Residuals\",\n     col    = \"darkorange\",\n     border = \"dodgerblue\",\n     breaks = 20)\n\n\n\n\n\nqqnorm(resid(model_reg), \n       main = \"Normal Q-Q Plot\", \n       col = \"darkgrey\",\n       pch=16)\nqqline(resid(model_reg), col = \"dodgerblue\", lwd = 2)\n\n\n\n\n\ngraphics.off()\n\n\n\n독립성 검정\n\nlmtest::dwtest(model_reg)\n\n\n    Durbin-Watson test\n\ndata:  model_reg\nDW = 2.0844, p-value = 0.5716\nalternative hypothesis: true autocorrelation is greater than 0\n\n\n\n\n영향점\n\npar(mfrow=c(1,1))\nplot(y~x, dt,pch  = 20,cex  = 2,col  = \"darkorange\")\nabline(model_reg, col='steelblue', lwd=2)\n\n\n\n\n\n# influence(model_reg)\ninfluence.measures(model_reg)\n\nInfluence measures of\n     lm(formula = y ~ x, data = dt) :\n\n     dfb.1_    dfb.x    dffit cov.r   cook.d    hat inf\n1   0.01664  0.00328  0.04127 1.166 8.97e-04 0.0479    \n2   0.18862 -0.33480 -0.40252 1.197 8.15e-02 0.1545    \n3  -0.33098  0.19239 -0.39114 0.936 7.17e-02 0.0628    \n4  -0.20004  0.12788 -0.22433 1.115 2.56e-02 0.0705    \n5   0.07532  0.01487  0.18686 1.085 1.77e-02 0.0479    \n6   0.00113 -0.00503 -0.00857 1.201 3.88e-05 0.0726    \n7   0.00447  0.03266  0.07722 1.170 3.13e-03 0.0580    \n8   0.04430 -0.02250  0.05630 1.174 1.67e-03 0.0567    \n9   0.07907 -0.05427  0.08541 1.200 3.83e-03 0.0799    \n10 -0.02283  0.10141  0.17284 1.152 1.54e-02 0.0726    \n11  0.31560 -0.22889  0.33200 1.088 5.48e-02 0.0908    \n12 -0.08422  0.05384 -0.09445 1.183 4.68e-03 0.0705    \n13 -0.33098  0.19239 -0.39114 0.936 7.17e-02 0.0628    \n14 -0.24681  0.12536 -0.31367 0.992 4.76e-02 0.0567    \n15  0.07968 -0.04047  0.10126 1.159 5.36e-03 0.0567    \n16  0.02791 -0.01622  0.03298 1.187 5.74e-04 0.0628    \n17  0.13328 -0.05493  0.18717 1.096 1.79e-02 0.0521    \n18  0.83112 -1.11275 -1.15578 2.959 6.78e-01 0.6516   *\n19  0.14348  0.27317  0.85374 0.396 2.23e-01 0.0531   *\n20 -0.20761  0.10544 -0.26385 1.043 3.45e-02 0.0567    \n21  0.02791 -0.01622  0.03298 1.187 5.74e-04 0.0628    \n\n\n\nhatvalues(model_reg)\n\n10.047922479451021820.15451323429605630.062815775582535340.070545207752054950.047922479451021860.072618957846316370.057989593544981580.056669934394087990.0798582309026469100.0726189578463163110.0907548450343111120.0705452077520549130.0628157755825353140.0566699343940879150.0566699343940879160.0628157755825353170.0521076841867129180.65160998416409190.0530502978659226200.0566699343940879210.0628157755825353\n\n\n\ndffits(model_reg)  \n\n10.04127403575140562-0.4025206873025253-0.3911400454742154-0.22432853366080450.1868559838824216-0.0085717364067812270.077223952838937980.056303486522047690.085407472693718100.172840518129759110.33199685399425312-0.094449643042361813-0.39114004547421514-0.313673908094842150.101264129345836160.0329813827461469170.18716612805440518-1.15577873097521190.85373710713076620-0.263846244162542210.0329813827461469\n\n\n\ncooks.distance(model_reg)\n\n10.00089740639287069120.081497955150763530.071658144221383340.025615958245264150.017743662633501363.87762740910137e-0570.003130574802994980.0016682085781346990.00383194880672965100.0154395158127621110.0548101351203612120.00467762256482442130.0716581442213833140.0475978118328145150.00536121617564154160.000573584529113046170.017856495213809180.678112028575845190.223288273631179200.0345188940892692210.000573584529113046\n\n\n\ncovratio(model_reg)\n\n11.1658918168321921.1969989767629630.93634739734183941.1151026899392951.0850410825772861.2013199827549771.1701575789867381.1742372676080391.19966823450598101.15209128858604111.08783960928084121.18326164825873130.936347397341839140.992331347870996151.15904532932769161.18673688685713171.09643883044992182.95868271380702190.396431612340971201.04257281407241211.18673688685713\n\n\n\nsummary(influence.measures(model_reg))\n\nPotentially influential observations of\n     lm(formula = y ~ x, data = dt) :\n\n   dfb.1_ dfb.x   dffit   cov.r   cook.d hat    \n18  0.83  -1.11_* -1.16_*  2.96_*  0.68   0.65_*\n19  0.14   0.27    0.85    0.40_*  0.22   0.05  \n\n\n\n\n기각역\n\np &lt;- 1\n\n\nn &lt;- 21\n\n\n2*(p+1)/n #hat (h_ii)\n\n0.19047619047619\n\n\n\n2*sqrt((p+1)/(n-p-1)) #Dffits\n\n0.64888568452305\n\n\n\nqf(0.5, p+1, n-p-1) #Cook d\n\n0.719060569091733\n\n\n\npar(mfrow=c(2,2))\nplot(y~x, dt,pch  = 20,\n     cex  = 2,col  = \"darkorange\",\n     main = \"전체 데이터\")\nabline(model_reg, col='steelblue', lwd=2)\ntext (dt[18:19,],c('18', '19'),adj = c(0,0))\n\n## 18제거 전후 \nplot(y~x, dt,pch  = 20,\n     cex  = 2,col  = \"darkorange\",\n     main = \"18번 제거\")\nabline(model_reg, col='steelblue', lwd=2)\nabline(lm(y~x, dt[-18,]), col='red', lwd=2)\nlegend('topright', legend=c(\"full\", \"del(18)\"),\n       col=c('steelblue', 'red'), lty=1, lwd=2)\n# high leverage and high influence, not outlier\n\n## 19제거 전후 \nplot(y~x, dt,pch  = 20,\n     cex  = 2,col  = \"darkorange\",\n     main = \"19번 제거\")\nabline(model_reg, col='steelblue', lwd=2)\nabline(lm(y~x, dt[-19,]), col='red', lwd=2)\nlegend('topright', legend=c(\"full\", \"del(19)\"),\n       col=c('steelblue', 'red'), lty=1, lwd=2)\n# not leverage and high influence, outlier\n\n\n## 18, 19제거 전후 \nplot(y~x, dt,pch  = 20,\n     cex  = 2,col  = \"darkorange\",\n     main = \"18,19번 제거\")\nabline(model_reg, col='steelblue', lwd=2)\nabline(lm(y~x, dt[-c(18,19),]), col='red', lwd=2)\nlegend('topright', legend=c(\"full\", \"del(18,19)\"),\n       col=c('steelblue', 'red'), lty=1, lwd=2)\n\n\n\n\n\n\n회귀진단 그림\n\npar(mfrow = c(2, 2))\nplot(model_reg, pch=16)\n\n\n\n\n\n\nHitters\n\nlibrary(ISLR)\n\n\nhitters &lt;- na.omit(Hitters)\n\n\ndim(hitters)\n\n\n26320\n\n\n\nhead(hitters)\n\n\nA data.frame: 6 × 20\n\n\n\nAtBat\nHits\nHmRun\nRuns\nRBI\nWalks\nYears\nCAtBat\nCHits\nCHmRun\nCRuns\nCRBI\nCWalks\nLeague\nDivision\nPutOuts\nAssists\nErrors\nSalary\nNewLeague\n\n\n\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;fct&gt;\n&lt;fct&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;fct&gt;\n\n\n\n\n-Alan Ashby\n315\n81\n7\n24\n38\n39\n14\n3449\n835\n69\n321\n414\n375\nN\nW\n632\n43\n10\n475.0\nN\n\n\n-Alvin Davis\n479\n130\n18\n66\n72\n76\n3\n1624\n457\n63\n224\n266\n263\nA\nW\n880\n82\n14\n480.0\nA\n\n\n-Andre Dawson\n496\n141\n20\n65\n78\n37\n11\n5628\n1575\n225\n828\n838\n354\nN\nE\n200\n11\n3\n500.0\nN\n\n\n-Andres Galarraga\n321\n87\n10\n39\n42\n30\n2\n396\n101\n12\n48\n46\n33\nN\nE\n805\n40\n4\n91.5\nN\n\n\n-Alfredo Griffin\n594\n169\n4\n74\n51\n35\n11\n4408\n1133\n19\n501\n336\n194\nA\nW\n282\n421\n25\n750.0\nA\n\n\n-Al Newman\n185\n37\n1\n23\n8\n21\n2\n214\n42\n1\n30\n9\n24\nN\nE\n76\n127\n7\n70.0\nA\n\n\n\n\n\n\nreg_model &lt;- lm(Salary ~ AtBat + Hits + HmRun, hitters)\n\n\nsummary(reg_model)\n\n\nCall:\nlm(formula = Salary ~ AtBat + Hits + HmRun, data = hitters)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-884.75 -214.97  -58.05  175.88 1991.53 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  158.754     75.815   2.094  0.03724 *  \nAtBat         -1.564      0.641  -2.440  0.01536 *  \nHits           8.329      2.053   4.056 6.61e-05 ***\nHmRun          9.502      3.384   2.808  0.00536 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 398.9 on 259 degrees of freedom\nMultiple R-squared:  0.2271,    Adjusted R-squared:  0.2182 \nF-statistic: 25.37 on 3 and 259 DF,  p-value: 2.013e-14\n\n\n\nvcov(reg_model)\n\n\nA matrix: 4 × 4 of type dbl\n\n\n\n(Intercept)\nAtBat\nHits\nHmRun\n\n\n\n\n(Intercept)\n5747.87524\n-26.2127535\n48.158691\n21.0663196\n\n\nAtBat\n-26.21275\n0.4108477\n-1.249666\n-0.4193544\n\n\nHits\n48.15869\n-1.2496656\n4.216189\n0.1404930\n\n\nHmRun\n21.06632\n-0.4193544\n0.140493\n11.4506363\n\n\n\n\n\n\npairs(hitters[,c(1,2,3,19)])\n\n\n\n\n\n## 잔차그림 \nresidual &lt;- resid(reg_model)\nstad.res &lt;- rstandard(reg_model)\nstu.res &lt;- rstudent(reg_model)\n\n\npar(mfrow = c(2, 2))\nplot(fitted(reg_model), residual, \n     pch=20,cex  = 2,col  = \"darkorange\",\n     xlab = \"Fitted\", ylab = \"Residuals\", \n     main = \"residual plot\")\nabline(h=0, lty=2)\n\nplot(fitted(reg_model), stad.res, \n     pch=20,cex  = 2,col  = \"darkorange\",\n     xlab = \"Fitted\", ylab = \"S_Residuals\", \n     ylim=c(min(-3, min(stad.res)), \n            max(3,max(stad.res))),\n     main = \"standardized residual plot\")\nabline(h=c(-2,0,2), lty=2)\n\nplot(fitted(reg_model), stu.res, \n     pch=20,cex  = 2,col  = \"darkorange\",\n     xlab = \"Fitted\", ylab = \"S_Residuals_(i)\", \n     ylim=c(min(-3, min(stu.res)), \n            max(3,max(stu.res))),\n     main = \"studentized residual plot\")\nabline(h=c(-2,0,2), lty=2)\n\nplot(fitted(reg_model), stu.res, \n     pch=20,cex  = 2,col  = \"darkorange\",\n     xlab = \"Fitted\", ylab = \"S_Residuals_(i)\", \n     ylim=c(min(-3, min(stu.res)), \n            max(3,max(stu.res))),\n     main = \"studentized residual plot\")\nabline(h=c(-qt(0.975,nrow(hitters)-4),0,qt(0.975,nrow(hitters)-4)), lty=2)\ntext (fitted(reg_model)[which(abs(stu.res)&gt;qt(0.975,nrow(hitters)-4))],\n      stu.res[which(abs(stu.res)&gt;qt(0.975,nrow(hitters)-4))], \n      which(abs(stu.res)&gt;qt(0.975,nrow(hitters)-4)),adj = c(0,1))\n\n\n\n\n\nstu.res[abs(stu.res)&gt;qt(0.975,nrow(hitters)-4)]\n\n-Dale Murphy2.74033829619024-Dave Winfield2.88089264730221-Eddie Murray4.31895378037471-George Brett2.05782174934042-Gary Carter3.24866258649007-Joe Carter-2.08071298999844-Jack Clark2.44291700843437-Jim Rice3.5583979165244-Keith Hernandez2.44056603081697-Kirby Puckett-2.29372779175543-Mike Schmidt5.33366401188885-Ozzie Smith3.5948319898282-Rickey Henderson2.20244386003162-Steve Garvey1.97931624811918-Steve Sax-2.30201279255003\n\n\n\nwhich(abs(stu.res)&gt;qt(0.975,nrow(hitters)-4))\n\n-Dale Murphy63-Dave Winfield74-Eddie Murray77-George Brett82-Gary Carter84-Joe Carter110-Jack Clark111-Jim Rice127-Keith Hernandez140-Kirby Puckett148-Mike Schmidt173-Ozzie Smith183-Rickey Henderson200-Steve Garvey226-Steve Sax230\n\n\n\ninfluence(reg_model)\n\n\n    $hat\n        -Alan Ashby0.00540428715355245-Alvin Davis0.00589170670784522-Andre Dawson0.00832644882765465-Andres Galarraga0.00543756565246947-Alfredo Griffin0.0246137118709988-Al Newman0.0141225554276349-Argenis Salazar0.010928273983481-Andres Thomas0.00583280157863637-Andre Thornton0.0118104032344835-Alan Trammell0.00994920971431027-Alex Trevino0.0116023974454147-Andy VanSlyke0.00392214855226506-Alan Wiggins0.01133266253963-Bill Almon0.0120577739078933-Buddy Bell0.00926235909199221-Buddy Biancalana0.012342136255686-Bruce Bochy0.0204159574317937-Barry Bonds0.0140367315219278-Bobby Bonilla0.0110632944090634-Bob Brenly0.00872907614618226-Bill Buckner0.0139048245540849-Brett Butler0.023168413560765-Bob Dernier0.0102008268559032-Bo Diaz0.00579243488480162-Bill Doran0.015434760936016-Brian Downing0.00777622895232283-Billy Hatcher0.00709689247443314-Brook Jacoby0.0108511422285614-Bob Kearney0.0108810262666556-Bill Madlock0.00473465384983353-Bob Melvin0.00900012174203842-BillyJo Robidoux0.0133294228418443-Bill Schroeder0.0112763637277587-Chris Bando0.00978612142405515-Chris Brown0.0166260339272529-Carmen Castillo0.0130280396536268-Chili Davis0.00704454319748951-Carlton Fisk0.017822764593868-Curt Ford0.0109708972674672-Carney Lansford0.0107121199405846-Chet Lemon0.004977264802092-Candy Maldonado0.00764992031384351-Carmelo Martinez0.0089685788087143-Craig Reynolds0.00600742640963073-Cal Ripken0.0154842953466146-Cory Snyder0.0142384557435194-Chris Speier0.0176408073638382-Curt Wilkerson0.011580828583756-Dave Anderson0.0114107120327874-Don Baylor0.0352479469918076-Daryl Boston0.0120025169206652-Darnell Coles0.00768936788078936-Dave Concepcion0.00754097071158992-Doug DeCinces0.016164784133267-Darrell Evans0.0264058825441862-Dwight Evans0.0156073759122261-Damaso Garcia0.00737202574736494-Dan Gladden0.00732057564815775-Dave Henderson0.00493766296992215-Donnie Hill0.00802999130926279-Davey Lopes0.00867219904074439-Don Mattingly0.0903700111079589-Dale Murphy0.0205781074488089-Dwayne Murphy0.00499065937964354-Dave Parker0.0233401084346804-Dan Pasqua0.0148260514260301-Darrell Porter0.0212335628824219-Dick Schofield0.00692844758375807-Don Slaught0.00665433551016605-Darryl Strawberry0.017694944503085-Dale Sveum0.00583616542870044-Danny Tartabull0.0128297967927647-Denny Walling0.0124382760330085-Dave Winfield0.0133528039520951-Eric Davis0.0205166608140052-Eddie Milner0.00477555388471096-Eddie Murray0.0126894264569264-Ed Romero0.0120154735656705-Frank White0.0103217756795036-George Bell0.0344024597514498-Glenn Braggs0.0102378206814018-George Brett0.0070249800741032-Greg Brock0.0102483444612376-Gary Carter0.0133493295035423-Glenn Davis0.0233784484234977-Gary Gaetti0.0300641988907722-Greg Gagne0.00756816838324455-George Hendrick0.00993821578501312-Glenn Hubbard0.0144050547662455-Garth Iorg0.00750828700013946-Gary Matthews0.0119812939218614-Graig Nettles0.0135988964718854-Gary Pettis0.0180946787493926-Gary Redus0.00533116613569048-Garry Templeton0.0231472795912073-Greg Walker0.00954059659043919-Gary Ward0.0158776584493562-Glenn Wilson0.0102664940810771-Harold Baines0.0136874329182192-Hubie Brooks0.0245534617574867-Howard Johnson0.0111605903106341-Hal McRae0.00660970775119084-Harold Reynolds0.0266174645810819-Harry Spilman0.0178175584405383-Herm Winningham0.0125072976893885-Jesse Barfield0.0472745129906935-Juan Beniquez0.0098405887950288-John Cangelosi0.0185585370145323-Jose Canseco0.0385966269231462-Joe Carter0.0279123839207128-Jack Clark0.00976153800810466-Jose Cruz0.00621927886532388-Jody Davis0.0125836354713245-Jim Dwyer0.0159318273881519-Julio Franco0.0230480594602062-Jim Gantner0.00960427626759017-Johnny Grubb0.0249337849541658-Jack Howell0.0166783571884679-John Kruk0.0135348618245948-Jeffrey Leonard0.00621692194497029-Jim Morrison0.0104347491092473-John Moses0.00955816927339891-Jerry Mumphrey0.0114527911454454-Jim Presley0.0181732014300399-Johnny Ray0.0222264061248388-Jeff Reed0.0141048942273143-Jim Rice0.0341630071931888-Jerry Royster0.00786584848798418-John Russell0.00732221183848203-Juan Samuel0.011233958379014-John Shelby0.0105769969697364-Joel Skinner0.00820725725265926-Jim Sundberg0.0196190015932163-Jose Uribe0.0243170465990865-Joel Youngblood0.0127513647950321-Kevin Bass0.0219191326187113-Kal Daniels0.0194979541215839-Kirk Gibson0.020556919885839-Ken Griffey0.0157391819211111-Keith Hernandez0.0186125240001884-Kent Hrbek0.0192503945544296-Ken Landreaux0.00738914265279174-Kevin McReynolds0.0156330543753078-Kevin Mitchell0.00623609661997075-Keith Moreland0.0121555120488774-Ken Oberkfell0.0126467584348519-Ken Phelps0.0198333298123843-Kirby Puckett0.0552718094796791-Kurt Stillwell0.011990041252144-Leon Durham0.00780417454171992-Len Dykstra0.00857784296541703-Larry Herndon0.0064990040160584-Lee Lacy0.00742301328937459-Len Matuszek0.0129926810188161-Lloyd Moseby0.0154094589566827-Lance Parrish0.0168397241242445-Larry Parrish0.0195480106203573-Larry Sheets0.0102053644915363-Lou Whitaker0.0103736298972029-Mike Aldrete0.0108976777772544-Marty Barrett0.0291908907582424-Mike Davis0.00667586668426171-Mike Diaz0.0147105547379761-Mariano Duncan0.0115422666932657-Mike Easler0.010820500442813-Mel Hall0.00976796679777078-Mike Heath0.0081507738805316-Mike Kingery0.0111519990806471-Mike LaValliere0.00901026773489625-Mike Marshall0.013711182342755-Mike Pagliarulo0.0255437587312095-Mark Salas0.00824038954487028-Mike Schmidt0.0308861245462707-Mike Scioscia0.00698057071979755-Mickey Tettleton0.0135500510047471-Milt Thompson0.00617205972690294-Mitch Webster0.0169403513647917-Mookie Wilson0.00619444773498657-Marvell Wynne0.0063403620095783-Mike Young0.00474275439485779-Ozzie Guillen0.0271620505926552-Oddibe McDowell0.00964328420757499-Ozzie Smith0.0229502793106078-Ozzie Virgil0.0114067190696189-Phil Bradley0.0168810816259417-Phil Garner0.00535812295602376-Pete Incaviglia0.025161431654974-Paul Molitor0.00570944294085908-Pete Rose0.0126156272171943-Pat Sheridan0.00888970164559414-Pat Tabler0.026279450164693-Rafael Belliard0.0123374671998298-Rick Burleson0.00906906701865493-Randy Bush0.00495753180334833-Rick Cerone0.0104730023394748-Ron Cey0.0113956391454122-Rob Deer0.0395521316143585-Rick Dempsey0.0136529420759308-Ron Hassey0.0158151139459369-Rickey Henderson0.0194628445140604-Reggie Jackson0.00963058080211747-Ron Kittle0.0195094238607815-Ray Knight0.0100975869646124-Rick Leach0.0140249162441515-Rick Manning0.0115898080723435-Rance Mulliniks0.00450212481049989-Ron Oester0.0122552708544235-Rey Quinones0.0128781945206417-Rafael Ramirez0.0155619012974591-Ronn Reynolds0.0174189559060563-Ron Roenicke0.007216482671799-Ryne Sandberg0.0148031952946029-Rafael Santana0.0213487186421553-Rick Schu0.0124262441988659-Ruben Sierra0.00575359430765965-Roy Smalley0.0106124476383773-Robby Thompson0.0140106441432452-Rob Wilfong0.0109282567228258-Robin Yount0.0199323190913311-Steve Balboni0.032832608857617-Scott Bradley0.013819143124654-Sid Bream0.0064848822413407-Steve Buechele0.010047792882046-Shawon Dunston0.0154878353515676-Scott Fletcher0.0231584911833167-Steve Garvey0.0124707214778381-Steve Jeltz0.0294334036298904-Steve Lombardozzi0.0163703558064671-Spike Owen0.0361863260829997-Steve Sax0.056205798190448-Tony Bernazard0.0137201779926164-Tom Brookens0.00842727602684437-Tom Brunansky0.0155535640161956-Tony Fernandez0.0384149427739519-Tim Flannery0.00879815995334561-Tom Foley0.010178072996595-Tony Gwynn0.0441255560927934-Terry Harper0.00728359774271928-Tommy Herr0.0283062395596944-Tim Hulett0.0193407789424842-Terry Kennedy0.0326924785968483-Tito Landrum0.0124610368212244-Tim Laudner0.0137152102414128-Tom Paciorek0.0126750030530696-Tony Pena0.00921261317536243-Terry Pendleton0.0411002808615697-Tony Phillips0.00947681648702826-Terry Puhl0.013480153488892-Ted Simmons0.0183540764261599-Tim Teufel0.00754075413540749-Tim Wallach0.014724129247963-Vince Coleman0.0540676127419561-Von Hayes0.0192039404330803-Vance Law0.0113459171671123-Wally Backman0.022556121420949-Wade Boggs0.0736687853777228-Will Clark0.00548420107775056-Wally Joyner0.01320331340394-Willie McGee0.0115854961579362-Willie Randolph0.011798792067581-Wayne Tolleson0.0136448610296419-Willie Upshaw0.0189725147824934-Willie Wilson0.0210111323582833\n\n    $coefficients\n        \n\nA matrix: 263 × 4 of type dbl\n\n\n\n(Intercept)\nAtBat\nHits\nHmRun\n\n\n\n\n-Alan Ashby\n0.65924938\n-4.086660e-04\n-1.281158e-03\n-0.0083503671\n\n\n-Alvin Davis\n0.19498183\n-6.704304e-04\n-2.345890e-04\n-0.0516648778\n\n\n-Andre Dawson\n0.06576750\n1.100954e-02\n-4.016280e-02\n-0.0970298280\n\n\n-Andres Galarraga\n-4.21682830\n1.761848e-02\n-3.703466e-02\n-0.0320576617\n\n\n-Alfredo Griffin\n-0.77018454\n2.388378e-03\n9.127765e-03\n-0.0763167161\n\n\n-Al Newman\n-2.01620004\n-2.341329e-03\n2.006901e-02\n0.0297530788\n\n\n-Argenis Salazar\n-1.85154500\n-6.368273e-03\n2.098820e-02\n0.1194087080\n\n\n-Andres Thomas\n-2.56590064\n-5.396923e-03\n2.574708e-02\n0.0672680286\n\n\n-Andre Thornton\n0.10303912\n6.698207e-02\n-2.553939e-01\n0.2464785215\n\n\n-Alan Trammell\n2.03660813\n-3.586078e-03\n-7.094059e-03\n-0.0733319660\n\n\n-Alex Trevino\n3.73771207\n-1.346635e-02\n2.388866e-02\n-0.0125752009\n\n\n-Andy VanSlyke\n-0.06284050\n1.416493e-04\n-5.027719e-04\n-0.0013033606\n\n\n-Alan Wiggins\n6.26418239\n-7.921075e-03\n6.495036e-03\n-0.1867461933\n\n\n-Bill Almon\n-0.66310602\n5.527425e-04\n3.398486e-03\n-0.0058770693\n\n\n-Buddy Bell\n0.00952803\n-1.127743e-05\n-6.277069e-05\n-0.0002924174\n\n\n-Buddy Biancalana\n-1.70759169\n3.655244e-03\n-2.793180e-03\n0.0165104010\n\n\n-Bruce Bochy\n-4.44090060\n1.869447e-02\n-2.742246e-02\n-0.0687457299\n\n\n-Barry Bonds\n0.65494620\n-4.598393e-02\n1.642284e-01\n-0.0928787697\n\n\n-Bobby Bonilla\n0.21192170\n-2.260935e-02\n4.828845e-02\n0.2152155106\n\n\n-Bob Brenly\n-0.27252701\n6.233813e-03\n-1.957537e-02\n0.0088001622\n\n\n-Bill Buckner\n-0.45485652\n2.949080e-03\n-5.416430e-03\n-0.0026034641\n\n\n-Brett Butler\n-1.41235128\n7.937832e-03\n1.993044e-03\n-0.1295576882\n\n\n-Bob Dernier\n2.22713238\n3.647360e-02\n-1.260762e-01\n-0.1530605674\n\n\n-Bo Diaz\n-0.26184766\n3.227393e-03\n1.145628e-03\n-0.0465005599\n\n\n-Bill Doran\n-0.02728711\n1.626614e-04\n5.683137e-05\n-0.0026675099\n\n\n-Brian Downing\n-0.91568606\n6.678274e-03\n-1.681666e-02\n0.0729610721\n\n\n-Billy Hatcher\n-0.20437836\n-1.872251e-02\n4.266133e-02\n0.1567504397\n\n\n-Brook Jacoby\n1.34598144\n4.664552e-03\n-3.759005e-02\n0.0063911208\n\n\n-Bob Kearney\n-0.08820219\n1.879015e-04\n-2.026282e-05\n-0.0003393462\n\n\n-Bill Madlock\n2.18222420\n-1.384198e-02\n4.418954e-02\n-0.0163762368\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n-Tony Fernandez\n7.06537284\n0.0565156366\n-0.351299510\n0.483422041\n\n\n-Tim Flannery\n-1.01933468\n0.0045248195\n-0.020810894\n0.076494461\n\n\n-Tom Foley\n-1.28244788\n0.0034576426\n-0.008433418\n0.038790823\n\n\n-Tony Gwynn\n1.25204500\n0.0641744467\n-0.275670947\n0.116733745\n\n\n-Terry Harper\n0.54502374\n-0.0013766830\n0.001170777\n0.002694023\n\n\n-Tommy Herr\n-5.99483011\n0.0763894855\n-0.160940404\n-0.493581322\n\n\n-Tim Hulett\n3.59601814\n-0.0625005547\n0.192278681\n-0.029916225\n\n\n-Terry Kennedy\n26.55838372\n-0.1158123257\n0.201345158\n0.122066179\n\n\n-Tito Landrum\n1.13024912\n0.0015617120\n-0.012017503\n-0.016340543\n\n\n-Tim Laudner\n-1.98257829\n0.0061722430\n-0.004098792\n-0.038386487\n\n\n-Tom Paciorek\n-2.77226979\n0.0144500766\n-0.034564760\n0.012078742\n\n\n-Tony Pena\n-0.98487182\n-0.0136270227\n0.095360137\n-0.171708913\n\n\n-Terry Pendleton\n4.54802865\n-0.0638023359\n0.153211680\n0.316621222\n\n\n-Tony Phillips\n0.05485979\n-0.0024171333\n0.005349894\n0.018807172\n\n\n-Terry Puhl\n13.38730788\n-0.0374062086\n0.043150123\n-0.043522054\n\n\n-Ted Simmons\n6.09400873\n-0.0236603094\n0.037567620\n0.027284006\n\n\n-Tim Teufel\n-0.67151496\n-0.0001857344\n0.003288409\n0.014743759\n\n\n-Tim Wallach\n-1.61211169\n0.0356716192\n-0.116871942\n0.063226245\n\n\n-Vince Coleman\n4.75964847\n-0.0674930368\n0.167442603\n0.305677592\n\n\n-Von Hayes\n-2.07154896\n-0.0374915002\n0.170440619\n0.020979381\n\n\n-Vance Law\n0.41809764\n0.0241963127\n-0.078369026\n-0.080688279\n\n\n-Wally Backman\n-0.46933529\n0.0066426159\n-0.025722440\n0.033033473\n\n\n-Wade Boggs\n2.53680391\n-0.1858604097\n0.733772104\n-0.377519798\n\n\n-Will Clark\n-2.78654493\n0.0285231362\n-0.100429173\n0.023143027\n\n\n-Wally Joyner\n4.73172625\n0.0304243580\n-0.159518442\n-0.218513250\n\n\n-Willie McGee\n-1.25566058\n0.0201839892\n-0.045081166\n-0.110406929\n\n\n-Willie Randolph\n-0.95975323\n0.0075263046\n0.014433543\n-0.211613919\n\n\n-Wayne Tolleson\n0.39638021\n-0.0070850671\n0.009543190\n0.087366853\n\n\n-Willie Upshaw\n-5.67666776\n0.0673426811\n-0.157285698\n-0.253588560\n\n\n-Willie Wilson\n-5.06778235\n0.0352735234\n-0.046913737\n-0.244613940\n\n\n\n\n\n    $sigma\n        -Alan Ashby399.634203569099-Alvin Davis399.492597339658-Andre Dawson399.357259506549-Andres Galarraga398.933958984569-Alfredo Griffin399.628837026824-Al Newman399.589183690645-Argenis Salazar399.45913958176-Andres Thomas399.186969057154-Andre Thornton397.63748684862-Alan Trammell399.305567442193-Alex Trevino399.47898208154-Andy VanSlyke399.654722352462-Alan Wiggins398.809647826131-Bill Almon399.649936999163-Buddy Bell399.656593829134-Buddy Biancalana399.617963490199-Bruce Bochy399.517436655539-Barry Bonds399.117135210789-Bobby Bonilla399.173453123254-Bob Brenly399.638214399165-Bill Buckner399.651742803744-Brett Butler399.574300125236-Bob Dernier398.830912043822-Bo Diaz399.52670812524-Bill Doran399.656542576923-Brian Downing399.435802080694-Billy Hatcher399.058122239888-Brook Jacoby399.469820860983-Bob Kearney399.656489418298-Bill Madlock399.199661955533-Bob Melvin399.466996751965-BillyJo Robidoux399.532114622873-Bill Schroeder399.617758642113-Chris Bando399.648029050811-Chris Brown398.616310438533-Carmen Castillo399.558389784502-Chili Davis399.561670241124-Carlton Fisk398.625143843004-Curt Ford399.431008718328-Carney Lansford398.926230716375-Chet Lemon399.478161122053-Candy Maldonado399.572887009363-Carmelo Martinez399.656443141091-Craig Reynolds399.648479206124-Cal Ripken398.612250898437-Cory Snyder397.956233002957-Chris Speier399.635873837542-Curt Wilkerson399.653274124473-Dave Anderson399.645838956195-Don Baylor399.332313144429-Daryl Boston399.320992119561-Darnell Coles397.824487497975-Dave Concepcion399.641570126188-Doug DeCinces399.539814233217-Darrell Evans399.581917564588-Dwight Evans399.431220069416-Damaso Garcia399.198095338432-Dan Gladden399.361682500835-Dave Henderson399.404765367991-Donnie Hill399.478033157219-Davey Lopes399.648557868608-Don Mattingly397.743646040557-Dale Murphy393.964283305825-Dwayne Murphy399.500396526051-Dave Parker399.565499922729-Dan Pasqua398.677165239333-Darrell Porter399.59464075442-Dick Schofield399.648624041364-Don Slaught399.643928622877-Darryl Strawberry398.303115961143-Dale Sveum399.190292541126-Danny Tartabull397.875762023231-Denny Walling399.624442702131-Dave Winfield393.379419635538-Eric Davis398.765458160105-Eddie Milner399.636464677271-Eddie Murray385.948066373798-Ed Romero399.540856668197-Frank White399.655475127278-George Bell399.628236270768-Glenn Braggs399.429525938891-George Brett396.416592064954-Greg Brock399.644129572991-Gary Carter391.724908196771-Glenn Davis397.825873937425-Gary Gaetti399.629327956353-Greg Gagne399.014594348095-George Hendrick399.441514335659-Glenn Hubbard399.472407530578-Garth Iorg399.654394940912-Gary Matthews399.539923897956-Graig Nettles399.462993329827-Gary Pettis399.584369549925-Gary Redus399.651883210097-Garry Templeton399.185460011545-Greg Walker399.656193673305-Gary Ward399.655966022193-Glenn Wilson399.648238491901-Harold Baines399.628458110819-Hubie Brooks399.631800047401-Howard Johnson399.637790944298-Hal McRae399.645132646166-Harold Reynolds399.438307895792-Harry Spilman399.5700147204-Herm Winningham399.545267959526-Jesse Barfield399.444717016645-Juan Beniquez399.600368849692-John Cangelosi399.346282156929-Jose Canseco398.02468475877-Joe Carter396.345005739808-Jack Clark395.113012819977-Jose Cruz399.530072034124-Jody Davis398.960009857206-Jim Dwyer399.650790727091-Julio Franco399.634941644984-Jim Gantner399.30120909998-Johnny Grubb399.509727897045-Jack Howell399.4451037316-John Kruk398.989538398825-Jeffrey Leonard398.974767418778-Jim Morrison398.505945585891-John Moses399.114195166899-Jerry Mumphrey399.613137347821-Jim Presley397.818000372507-Johnny Ray399.594524245333-Jeff Reed399.515249933965-Jim Rice390.196208465802-Jerry Royster399.603735704486-John Russell399.30666953672-Juan Samuel399.642278659429-John Shelby399.609869907446-Joel Skinner399.437654115013-Jim Sundberg398.584394963321-Jose Uribe399.579000294072-Joel Youngblood399.560223620739-Kevin Bass399.126373002493-Kal Daniels399.12015978781-Kirk Gibson397.975247493125-Ken Griffey399.53237331735-Keith Hernandez395.12160557951-Kent Hrbek398.360454780228-Ken Landreaux398.997937387274-Kevin McReynolds399.358715010895-Kevin Mitchell398.903463941795-Keith Moreland399.00989140517-Ken Oberkfell399.510017390875-Ken Phelps399.330435852697-Kirby Puckett395.642946606445-Kurt Stillwell399.496801962796-Leon Durham398.261636678748-Len Dykstra398.809639978878-Larry Herndon399.54653974752-Lee Lacy399.554332681094-Len Matuszek399.606362918436-Lloyd Moseby399.597604730663-Lance Parrish399.36277824941-Larry Parrish399.500451278616-Larry Sheets398.781597712039-Lou Whitaker399.145067821065-Mike Aldrete399.430603303995-Marty Barrett399.565465636137-Mike Davis399.592637413193-Mike Diaz399.145038102774-Mariano Duncan399.413058360128-Mike Easler399.640085387524-Mel Hall399.498717574299-Mike Heath399.142076130073-Mike Kingery399.369015887524-Mike LaValliere399.451525535306-Mike Marshall399.448864415595-Mike Pagliarulo398.597729793777-Mark Salas399.472597477717-Mike Schmidt379.292250579782-Mike Scioscia398.572806263645-Mickey Tettleton399.527735602914-Milt Thompson399.392147441609-Mitch Webster398.347346283402-Mookie Wilson399.385964043788-Marvell Wynne399.519163457209-Mike Young399.615621049389-Ozzie Guillen399.242206269624-Oddibe McDowell398.425124104216-Ozzie Smith390.008483574748-Ozzie Virgil399.232670321634-Phil Bradley399.640200646453-Phil Garner399.656525133287-Pete Incaviglia398.140184239167-Paul Molitor397.429741229718-Pete Rose398.280795633753-Pat Sheridan399.582502621366-Pat Tabler399.497740921433-Rafael Belliard399.553174081354-Rick Burleson399.65322242696-Randy Bush399.521546684067-Rick Cerone399.62878918092-Ron Cey397.973834039668-Rob Deer398.730746953908-Rick Dempsey399.637209844612-Ron Hassey399.634427225238-Rickey Henderson395.951714392753-Reggie Jackson399.652720587124-Ron Kittle399.652676908848-Ray Knight399.438845758554-Rick Leach399.450896732263-Rick Manning399.642943281909-Rance Mulliniks399.654922439105-Ron Oester399.44241283954-Rey Quinones399.486378350133-Rafael Ramirez398.766407058046-Ronn Reynolds399.653501886057-Ron Roenicke399.544472584493-Ryne Sandberg399.642443719266-Rafael Santana399.65494440862-Rick Schu399.363722079039-Ruben Sierra398.636609618147-Roy Smalley399.518322924908-Robby Thompson398.579898644176-Rob Wilfong399.625113730433-Robin Yount399.428710993818-Steve Balboni398.360706238665-Scott Bradley399.146876060407-Sid Bream398.620806071406-Steve Buechele398.846032824028-Shawon Dunston398.593654297952-Scott Fletcher399.442652563701-Steve Garvey396.65636455604-Steve Jeltz399.58260056726-Steve Lombardozzi399.272349470646-Spike Owen399.656235335859-Steve Sax395.614338602903-Tony Bernazard399.156464351707-Tom Brookens399.649134852872-Tom Brunansky399.408904165723-Tony Fernandez397.817017292335-Tim Flannery399.556718137648-Tom Foley399.616988419874-Tony Gwynn399.184364023896-Terry Harper399.64941906511-Tommy Herr398.657363966685-Tim Hulett399.145382261934-Terry Kennedy396.840786363831-Tito Landrum399.631568221619-Tim Laudner399.609029909848-Tom Paciorek399.564853400074-Tony Pena398.575984199143-Terry Pendleton399.33123547191-Tony Phillips399.651379214157-Terry Puhl397.688749711276-Ted Simmons399.38288948683-Tim Teufel399.640405908538-Tim Wallach399.377418080339-Vince Coleman399.412859480921-Von Hayes398.995072376167-Vance Law399.446049912437-Wally Backman399.646230007602-Wade Boggs398.079495263796-Will Clark398.533481524676-Wally Joyner397.186759775293-Willie McGee399.471318558753-Willie Randolph399.198237604745-Wayne Tolleson399.598450704678-Willie Upshaw398.81428332845-Willie Wilson399.12738883149\n\n    $wt.res\n        -Alan Ashby67.7800562087087-Alvin Davis-183.345293019541-Andre Dawson-247.375182642532-Andres Galarraga-384.813327418291-Alfredo Griffin74.7315286332977-Al Newman-117.07197395248-Argenis Salazar-200.665020800462-Andres Thomas-310.205917546153-Andre Thornton640.648615530166-Alan Trammell-267.656083228693-Alex Trevino190.25352752117-Andy VanSlyke-19.6536365997382-Alan Wiggins415.330079297421-Bill Almon-36.8517287339844-Buddy Bell-1.35241541753995-Buddy Biancalana-88.7106348656366-Bruce Bochy-167.655635510768-Barry Bonds-331.081398558356-Bobby Bonilla-313.806646549598-Bob Brenly61.3099969638083-Bill Buckner31.4371793372293-Brett Butler128.754601606279-Bob Dernier410.323289380803-Bo Diaz163.180113095525-Bill Doran3.49626524769039-Brian Downing212.526647532097-Billy Hatcher-349.932396304933-Brook Jacoby-195.171249913134-Bob Kearney-4.80870487790564-Bill Madlock306.156580178178-Bob Melvin-196.82474768404-BillyJo Robidoux-159.141935211524-Bill Schroeder-88.993441680264-Chris Bando-41.8422889642001-Chris Brown-459.010482523421-Carmen Castillo-141.376931971695-Chili Davis139.416761251418-Carlton Fisk456.781868012672-Curt Ford-214.474379654876-Carney Lansford385.836455594581-Chet Lemon191.330626342117-Candy Maldonado-130.882535697752-Carmelo Martinez-5.71193253559322-Craig Reynolds40.8066844825446-Cal Ripken460.170947533131-Cory Snyder-587.304792470144-Chris Speier-64.8017087996083-Curt Wilkerson-26.0478888596196-Dave Anderson-46.8442929092329-Don Baylor253.953744692514-Daryl Boston-261.440549141057-Darnell Coles-611.603935126123-Dave Concepcion-55.4674758077263-Doug DeCinces153.921018529722-Darrell Evans-122.448748207027-Dwight Evans213.870844722575-Damaso Garcia306.274048898031-Dan Gladden-245.665992427704-Dave Henderson-227.29254394042-Donnie Hill-191.105371028528-Davey Lopes40.554165593647-Don Mattingly598.319277598617-Dale Murphy1068.42965654213-Dwayne Murphy179.014700419564-Dave Parker135.45070641864-Dan Pasqua-445.807053482183-Darrell Porter-111.828849079933-Dick Schofield-40.4225403345766-Don Slaught-50.9535759790935-Darryl Strawberry523.179287889077-Dale Sveum-309.106462763598-Danny Tartabull-601.440367261628-Denny Walling-80.9282759858087-Dave Winfield1125.69219116458-Eric Davis-424.032103920511-Eddie Milner-64.2884097306572-Eddie Murray1656.28214419654-Ed Romero153.55543035292-Frank White-15.1706074829492-George Bell75.1556565287132-Glenn Braggs-215.25760276689-George Brett812.88430477159-Greg Brock-50.4565048468612-Gary Carter1264.0594565789-Glenn Davis-606.520649566213-Gary Gaetti-73.8606997041783-Greg Gagne-362.338576182642-George Hendrick209.531632083408-Glenn Hubbard193.466934012087-Garth Iorg-21.2576387351008-Gary Matthews154.175498873463-Graig Nettles-198.429297664118-Gary Pettis-120.935011745943-Gary Redus-31.1141247211481-Garry Templeton307.986106586873-Greg Walker9.14124868112292-Gary Ward-11.3679009173431-Glenn Wilson-41.3180421898229-Harold Baines75.6599531231978-Hubie Brooks70.6338894140339-Howard Johnson-61.9357958533628-Hal McRae-48.474066324933-Harold Reynolds-209.301620327783-Harry Spilman-132.424978895246-Herm Winningham-150.563795884441-Jesse Barfield204.007229803057-Juan Beniquez-107.15312797439-John Cangelosi-250.565658249054-Jose Canseco-568.233122374574-Joe Carter-813.089352277853-Jack Clark960.505689659938-Jose Cruz161.019061085732-Jody Davis376.459891359261-Jim Dwyer-34.3434710507558-Julio Franco-66.0601688331282-Jim Gantner269.358699127131-Johnny Grubb-171.838022127467-Jack Howell-207.067953446457-John Kruk-368.223751958345-Jeffrey Leonard-373.653104622136-Jim Morrison-484.228919189103-John Moses-332.734871510109-Jerry Mumphrey94.1298253578462-Jim Presley-609.438149799754-Johnny Ray-111.877142843771-Jeff Reed-169.510879992981-Jim Rice1364.55006368818-Jerry Royster-103.999639155523-John Russell-267.590083275267-Juan Samuel-54.0437192880373-John Shelby-97.6467732452258-Joel Skinner-211.587726780924-Jim Sundberg465.279368155062-Jose Uribe-124.950915616423-Joel Youngblood140.070604499256-Kevin Bass-326.921657688736-Kal Daniels-329.236976542924-Kirk Gibson582.14402580365-Ken Griffey158.782267361893-Keith Hernandez955.303999211567-Kent Hrbek511.590308251624-Ken Landreaux367.038202402703-Kevin McReynolds-245.862477419598-Kevin Mitchell-392.683613419869-Keith Moreland362.820757982595-Ken Oberkfell172.746852451584-Ken Phelps-256.714055315183-Kirby Puckett-882.06124667897-Kurt Stillwell-180.42432563195-Leon Durham533.788943932952-Len Dykstra-415.910238696257-Larry Herndon-150.156223654492-Lee Lacy-144.676170013163-Len Matuszek-101.120476392784-Lloyd Moseby109.445769501835-Lance Parrish244.030830326028-Larry Parrish-177.669210096705-Larry Sheets-422.384856127069-Lou Whitaker-323.000076354027-Mike Aldrete-214.674900219887-Marty Barrett-135.06978793439-Mike Davis114.463998835635-Mike Diaz-322.300899557089-Mariano Duncan-222.776983156224-Mike Easler-58.0459834544182-Mel Hall-179.541420331312-Mike Heath324.306227919313-Mike Kingery-242.124936548447-Mike LaValliere-204.694391158619-Mike Marshall205.52862360045-Mike Pagliarulo-460.981610247946-Mark Salas-193.970967587303-Mike Schmidt1991.53081105811-Mike Scioscia470.789169935772-Mickey Tettleton-161.898200722661-Milt Thompson-232.770673155091-Mitch Webster-514.771716718755-Mookie Wilson235.472665331111-Marvell Wynne-167.805169548164-Mike Young-91.7107068988726-Ozzie Guillen-288.259770879492-Oddibe McDowell-501.121239537188-Ozzie Smith1385.83327291096-Ozzie Virgil293.907257636743-Phil Bradley-57.6656386051236-Phil Garner3.99086175422808-Pete Incaviglia-551.609693048556-Paul Molitor674.785595483477-Pete Rose528.830102649674-Pat Sheridan-123.060530334477-Pat Tabler-178.587959125593-Rafael Belliard-145.132631319866-Rick Burleson26.2827152966923-Randy Bush-166.459873267454-Rick Cerone-75.3361148411943-Ron Cey585.105514035373-Rob Deer-427.981756862369-Rick Dempsey62.805798909155-Ron Hassey-67.0869313322284-Rickey Henderson863.533325149634-Reggie Jackson-28.1581764674054-Ron Kittle-28.1745560525503-Ray Knight-210.810121188791-Rick Leach-204.488532219717-Rick Manning52.7655700191927-Rance Mulliniks-18.5732077775455-Ron Oester208.848830444002-Rey Quinones-186.130873802358-Rafael Ramirez424.877109067089-Ronn Reynolds-25.0665888740822-Ron Roenicke-151.504821453376-Ryne Sandberg-53.6343768278081-Rafael Santana-18.2946008972326-Rick Schu-244.184962221945-Ruben Sierra-457.021589556042-Roy Smalley167.955201592851-Robby Thompson-467.584330386837-Rob Wilfong80.1407632780496-Robin Yount214.584722465971-Steve Balboni-507.986296633222-Scott Bradley-321.867266069112-Sid Bream-460.374516763279-Steve Buechele-406.584104350852-Shawon Dunston-464.243720588218-Scott Fletcher-207.576715133793-Steve Garvey780.197594958407-Steve Jeltz-121.697951720275-Steve Lombardozzi-279.11845097516-Spike Owen-8.54596640943839-Steve Sax-884.745594770179-Tony Bernazard-318.843538559565-Tom Brookens-39.0776713143429-Tom Brunansky224.212014148684-Tony Fernandez-603.284068119108-Tim Flannery-142.880059322374-Tom Foley-89.9212735988276-Tony Gwynn-305.015041218915-Terry Harper38.3489586433606-Tommy Herr447.1941065268-Tim Hulett-321.434595545371-Terry Kennedy748.146213034522-Tito Landrum71.4017150776481-Tim Laudner-98.3640208138739-Tom Paciorek-136.670586581832-Tony Pena469.570742925334-Terry Pendleton-253.602476951105-Tony Phillips-32.6650132185081-Terry Puhl631.949441316095-Ted Simmons235.352792139137-Tim Teufel-57.5752552727432-Tim Wallach238.131704064234-Vince Coleman-218.02109227197-Von Hayes365.639256842471-Vance Law207.163816279912-Wally Backman-45.7255454440639-Wade Boggs548.344227020477-Will Clark-479.603323533331-Wally Joyner-707.855886902391-Willie McGee194.315202710728-Willie Randolph305.542963369166-Wayne Tolleson-108.755647406025-Willie Upshaw412.589715777102-Willie Wilson326.760120586328\n\n\n\n\n\ninfluence.measures(reg_model)\n\nInfluence measures of\n     lm(formula = Salary ~ AtBat + Hits + HmRun, data = hitters) :\n\n                      dfb.1_  dfb.AtBt  dfb.Hits  dfb.HmRn     dffit cov.r\n-Alan Ashby         8.68e-03 -6.36e-04 -6.23e-04 -2.46e-03  0.012536 1.021\n-Alvin Davis        2.57e-03 -1.04e-03 -1.14e-04 -1.52e-02 -0.035436 1.018\n-Andre Dawson       8.66e-04  1.72e-02 -1.95e-02 -2.86e-02 -0.056997 1.018\n-Andres Galarraga  -5.56e-02  2.75e-02 -1.80e-02 -9.47e-03 -0.071519 1.006\n-Alfredo Griffin   -1.01e-02  3.72e-03  4.44e-03 -2.25e-02  0.030079 1.041\n-Al Newman         -2.65e-02 -3.65e-03  9.76e-03  8.78e-03 -0.035316 1.029\n-Argenis Salazar   -2.44e-02 -9.92e-03  1.02e-02  3.52e-02 -0.053094 1.023\n-Andres Thomas     -3.38e-02 -8.41e-03  1.25e-02  1.99e-02 -0.059697 1.012\n-Andre Thornton     1.36e-03  1.05e-01 -1.25e-01  7.31e-02  0.177184 0.987\n-Alan Trammell      2.68e-02 -5.59e-03 -3.45e-03 -2.16e-02 -0.067532 1.019\n-Alex Trevino       4.92e-02 -2.10e-02  1.16e-02 -3.71e-03  0.051902 1.024\n-Andy VanSlyke     -8.27e-04  2.21e-04 -2.44e-04 -3.84e-04 -0.003092 1.020\n-Alan Wiggins       8.26e-02 -1.24e-02  3.16e-03 -5.52e-02  0.112136 1.010\n-Bill Almon        -8.73e-03  8.61e-04  1.65e-03 -1.73e-03 -0.010249 1.028\n-Buddy Bell         1.25e-04 -1.76e-05 -3.05e-05 -8.62e-05 -0.000329 1.025\n-Buddy Biancalana  -2.25e-02  5.69e-03 -1.36e-03  4.87e-03 -0.024970 1.027\n-Bruce Bochy       -5.85e-02  2.91e-02 -1.33e-02 -2.03e-02 -0.061210 1.034\n-Barry Bonds        8.63e-03 -7.17e-02  7.99e-02 -2.74e-02 -0.099680 1.019\n-Bobby Bonilla      2.79e-03 -3.52e-02  2.35e-02  6.36e-02 -0.083613 1.017\n-Bob Brenly        -3.59e-03  9.71e-03 -9.52e-03  2.60e-03  0.014460 1.024\n-Bill Buckner      -5.99e-03  4.59e-03 -2.63e-03 -7.68e-04  0.009406 1.030\n-Brett Butler      -1.86e-02  1.24e-02  9.69e-04 -3.82e-02  0.050210 1.038\n-Bob Dernier        2.94e-02  5.69e-02 -6.14e-02 -4.52e-02  0.104980 1.009\n-Bo Diaz           -3.45e-03  5.03e-03  5.57e-04 -1.37e-02  0.031266 1.019\n-Bill Doran        -3.59e-04  2.53e-04  2.76e-05 -7.87e-04  0.001104 1.032\n-Brian Downing     -1.21e-02  1.04e-02 -8.18e-03  2.15e-02  0.047287 1.019\n-Billy Hatcher     -2.69e-03 -2.92e-02  2.08e-02  4.63e-02 -0.074400 1.011\n-Brook Jacoby       1.77e-02  7.27e-03 -1.83e-02  1.89e-03 -0.051453 1.023\n-Bob Kearney       -1.16e-03  2.93e-04 -9.85e-06 -1.00e-04 -0.001269 1.027\n-Bill Madlock       2.88e-02 -2.16e-02  2.15e-02 -4.84e-03  0.053022 1.011\n-Bob Melvin        -2.82e-02 -1.33e-02  2.01e-02  9.44e-03 -0.047168 1.021\n-BillyJo Robidoux  -4.00e-02  5.53e-03  2.48e-03  1.13e-02 -0.046609 1.027\n-Bill Schroeder    -1.80e-02 -2.22e-03  7.72e-03 -2.78e-03 -0.023918 1.026\n-Chris Bando       -8.41e-03  3.17e-03 -2.29e-03  4.15e-03 -0.010460 1.025\n-Chris Brown       -5.22e-02  1.06e-01 -1.23e-01  4.74e-02 -0.150988 1.011\n-Carmen Castillo   -3.90e-02  2.32e-02 -1.46e-02 -9.22e-03 -0.040920 1.027\n-Chili Davis       -8.54e-03  2.74e-03  3.53e-03 -7.85e-03  0.029494 1.021\n-Carlton Fisk      -4.14e-02  1.34e-01 -1.36e-01  3.39e-03  0.155755 1.013\n-Curt Ford         -4.91e-02  1.14e-02 -2.96e-03  1.54e-02 -0.056865 1.022\n-Carney Lansford   -4.05e-02 -5.02e-03  2.46e-02  1.04e-02  0.101187 1.012\n-Chet Lemon         4.79e-03  1.53e-02 -1.64e-02  1.31e-03  0.033959 1.017\n-Candy Maldonado   -4.62e-03 -6.67e-03  1.02e-02 -1.75e-02 -0.028870 1.022\n-Carmelo Martinez  -1.11e-03  1.25e-04  1.93e-04 -3.20e-04 -0.001366 1.025\n-Craig Reynolds     4.84e-03  9.61e-04 -1.67e-03 -2.32e-03  0.007962 1.022\n-Cal Ripken        -6.35e-02 -1.31e-03  2.06e-02  6.02e-02  0.145912 1.010\n-Cory Snyder       -3.92e-02  3.85e-02 -1.48e-02 -1.52e-01 -0.178644 0.996\n-Chris Speier      -2.15e-02  1.29e-02 -8.23e-03 -3.79e-03 -0.021924 1.033\n-Curt Wilkerson    -4.92e-03 -1.98e-04  8.58e-04  3.42e-03 -0.007096 1.027\n-Dave Anderson     -1.04e-02  1.91e-03 -2.65e-04  4.45e-03 -0.012665 1.027\n-Don Baylor        -4.88e-02  7.07e-02 -7.44e-02  7.34e-02  0.123757 1.046\n-Daryl Boston      -6.99e-02  3.31e-02 -1.91e-02 -1.14e-03 -0.072599 1.021\n-Darnell Coles      3.33e-02 -1.21e-02  2.66e-03 -5.92e-02 -0.135855 0.987\n-Dave Concepcion   -7.21e-03  5.03e-04 -2.47e-04  6.59e-03 -0.012144 1.023\n-Doug DeCinces     -1.06e-02  1.46e-02 -1.71e-02  3.55e-02  0.049785 1.030\n-Darrell Evans      1.10e-02 -2.15e-02  2.57e-02 -3.68e-02 -0.051147 1.042\n-Dwight Evans      -1.75e-02  1.92e-02 -2.10e-02  4.68e-02  0.067953 1.027\n-Damaso Garcia      1.25e-02 -9.79e-03  1.97e-02 -4.08e-02  0.066363 1.014\n-Dan Gladden       -2.67e-02  1.19e-02 -1.44e-02  3.06e-02 -0.053020 1.017\n-Dave Henderson    -1.61e-02  4.05e-03  2.35e-04 -1.89e-02 -0.040187 1.016\n-Donnie Hill       -2.50e-02  1.62e-02 -1.76e-02  2.21e-02 -0.043215 1.020\n-Davey Lopes        8.74e-03 -4.75e-03  3.20e-03  3.12e-04  0.009532 1.024\n-Don Mattingly      6.38e-03 -3.78e-01  4.24e-01  1.54e-01  0.497138 1.074\n-Dale Murphy       -1.73e-01  1.10e-01 -9.41e-02  2.43e-01  0.397212 0.925\n-Dwayne Murphy      1.95e-02  2.57e-03 -6.47e-03 -7.29e-04  0.031814 1.018\n-Dave Parker       -2.20e-02  6.86e-03 -4.20e-03  3.43e-02  0.053028 1.038\n-Dan Pasqua        -1.01e-01  9.04e-02 -6.41e-02 -8.27e-02 -0.138206 1.011\n-Darrell Porter    -3.70e-02  2.10e-02 -1.01e-02 -2.10e-02 -0.041665 1.036\n-Dick Schofield     1.66e-03 -5.59e-03  5.19e-03  4.62e-04 -0.008478 1.023\n-Don Slaught       -7.59e-03  3.20e-03 -1.18e-03 -4.75e-03 -0.010470 1.022\n-Darryl Strawberry -9.32e-03  2.04e-02 -3.76e-02  1.47e-01  0.177875 1.006\n-Dale Sveum        -3.46e-02 -1.10e-02  1.72e-02  1.20e-02 -0.059502 1.012\n-Danny Tartabull    2.40e-02 -4.75e-03  9.49e-03 -1.28e-01 -0.173445 0.993\n-Denny Walling     -1.18e-02  1.88e-02 -1.86e-02 -4.02e-03 -0.022870 1.028\n-Dave Winfield     -1.37e-01  1.24e-01 -1.08e-01  1.71e-01  0.335145 0.907\n-Eric Davis        -3.51e-02  4.56e-02 -2.41e-02 -1.39e-01 -0.155503 1.019\n-Eddie Milner      -1.32e-03 -2.68e-03  3.12e-03 -3.65e-03 -0.011170 1.020\n-Eddie Murray       5.79e-02 -3.17e-01  3.64e-01  9.46e-02  0.489635 0.778\n-Ed Romero          2.63e-02  1.13e-02 -1.72e-02 -1.35e-02  0.042641 1.026\n-Frank White        1.53e-03 -6.98e-04  3.17e-04 -1.63e-03 -0.003897 1.026\n-George Bell       -5.58e-03 -1.77e-02  2.05e-02  1.95e-02  0.036125 1.051\n-Glenn Braggs      -4.78e-02  7.01e-03  3.28e-03  6.51e-03 -0.055092 1.021\n-George Brett       4.71e-02 -9.45e-02  9.83e-02  5.71e-02  0.173086 0.958\n-Greg Brock        -5.17e-03 -2.81e-03  5.50e-03 -7.43e-03 -0.012914 1.026\n-Gary Carter       -6.17e-02  1.13e-01 -1.35e-01  2.62e-01  0.377879 0.877\n-Glenn Davis        6.84e-02 -4.07e-02  4.56e-02 -1.81e-01 -0.238690 1.002\n-Gary Gaetti        5.82e-03  6.93e-03 -6.77e-03 -2.60e-02 -0.033040 1.047\n-Greg Gagne         2.08e-02 -5.44e-02  4.75e-02  1.55e-02 -0.079601 1.010\n-George Hendrick    4.09e-02 -2.49e-02  1.37e-02  2.89e-02  0.052819 1.021\n-Glenn Hubbard     -5.46e-03  4.28e-02 -3.89e-02 -3.31e-02  0.058976 1.027\n-Garth Iorg        -2.36e-03 -1.37e-04  1.10e-04  2.77e-03 -0.004644 1.023\n-Gary Matthews      1.44e-02 -4.54e-03 -3.11e-03  3.47e-02  0.042751 1.026\n-Graig Nettles     -8.56e-03 -3.21e-02  4.14e-02 -2.49e-02 -0.058726 1.026\n-Gary Pettis        1.61e-02 -2.34e-02  1.45e-02  2.93e-02 -0.041462 1.033\n-Gary Redus        -2.88e-03 -1.19e-03  2.01e-03 -9.42e-04 -0.005715 1.021\n-Garry Templeton   -3.95e-02  7.73e-02 -5.56e-02 -8.91e-02  0.120165 1.030\n-Greg Walker        1.82e-03 -1.20e-03  7.46e-04  1.07e-03  0.002256 1.025\n-Gary Ward         -1.60e-03  2.50e-03 -2.82e-03  1.37e-03 -0.003642 1.032\n-Glenn Wilson       5.65e-03 -4.08e-03  1.71e-03  2.31e-03 -0.010584 1.026\n-Harold Baines     -3.89e-03 -9.03e-03  1.20e-02  6.58e-03  0.022457 1.029\n-Hubie Brooks       1.82e-02 -2.57e-02  2.35e-02  9.08e-03  0.028393 1.041\n-Howard Johnson    -1.45e-02  4.60e-03 -4.42e-04 -5.91e-03 -0.016557 1.027\n-Hal McRae         -7.99e-03  1.15e-03  4.67e-04  5.00e-04 -0.009927 1.022\n-Harold Reynolds    2.01e-02 -6.84e-02  5.94e-02  5.59e-02 -0.087826 1.039\n-Harry Spilman     -4.44e-02  2.41e-02 -1.43e-02 -5.96e-03 -0.045041 1.032\n-Herm Winningham   -3.67e-02  2.79e-03  6.44e-03  1.44e-03 -0.042678 1.026\n-Jesse Barfield    -1.17e-02 -2.82e-02  2.26e-02  1.02e-01  0.116556 1.061\n-Juan Beniquez     -1.65e-02  1.75e-02 -1.81e-02  7.94e-03 -0.026865 1.025\n-John Cangelosi     1.54e-02 -6.05e-02  5.05e-02  5.93e-02 -0.087092 1.028\n-Jose Canseco       1.15e-01 -1.54e-01  1.63e-01 -1.84e-01 -0.291733 1.022\n-Joe Carter         9.69e-02  1.31e-01 -1.72e-01 -1.61e-01 -0.352580 0.977\n-Jack Clark         2.03e-01 -3.27e-02 -2.58e-02  6.29e-02  0.242548 0.936\n-Jose Cruz         -2.58e-03  2.92e-04  5.81e-03 -1.40e-02  0.031982 1.019\n-Jody Davis        -4.09e-02  6.34e-02 -6.09e-02  4.15e-02  0.107199 1.014\n-Jim Dwyer         -1.04e-02  4.29e-03 -1.47e-03 -3.30e-03 -0.011022 1.032\n-Julio Franco       5.20e-03  8.60e-03 -1.50e-02  1.13e-02 -0.025687 1.039\n-Jim Gantner       -1.31e-02  1.36e-02  1.21e-03 -4.45e-02  0.066750 1.018\n-Johnny Grubb      -5.67e-02  5.67e-02 -4.45e-02 -3.00e-02 -0.069655 1.039\n-Jack Howell       -6.71e-02  3.52e-02 -2.12e-02 -3.63e-03 -0.068083 1.028\n-John Kruk         -8.31e-02  7.74e-02 -7.30e-02  2.61e-02 -0.108842 1.016\n-Jeffrey Leonard   -4.71e-02  2.71e-02 -2.69e-02  2.78e-02 -0.074305 1.008\n-Jim Morrison       3.10e-02 -5.12e-03 -1.49e-04 -7.27e-02 -0.125433 1.003\n-John Moses        -7.36e-03 -2.96e-02  2.05e-02  6.08e-02 -0.082292 1.014\n-Jerry Mumphrey     1.80e-02 -1.75e-02  1.72e-02 -6.72e-03  0.025500 1.026\n-Jim Presley        1.02e-01 -7.23e-02  5.83e-02 -1.10e-01 -0.210342 0.997\n-Johnny Ray         8.54e-03  9.75e-03 -2.07e-02  2.48e-02 -0.042689 1.037\n-Jeff Reed         -4.76e-02  1.35e-02 -3.51e-03  6.30e-03 -0.051111 1.027\n-Jim Rice          -4.77e-02 -4.34e-01  5.39e-01  5.10e-02  0.669238 0.868\n-Jerry Royster     -1.99e-02  5.33e-03 -1.91e-03  3.92e-03 -0.023265 1.023\n-John Russell      -3.18e-02 -7.34e-03  1.91e-02 -2.43e-02 -0.057767 1.016\n-Juan Samuel        8.35e-03 -7.32e-03  4.38e-03  2.18e-03 -0.014496 1.027\n-John Shelby        1.47e-03 -1.95e-02  2.03e-02  1.73e-03 -0.025399 1.025\n-Joel Skinner      -1.96e-02 -2.06e-02  2.41e-02  1.72e-02 -0.048386 1.020\n-Jim Sundberg      -3.39e-02  1.46e-01 -1.49e-01 -7.63e-03  0.166777 1.014\n-Jose Uribe         1.27e-02 -4.06e-02  3.59e-02  2.86e-02 -0.049979 1.039\n-Joel Youngblood    3.87e-02 -1.59e-02  7.41e-03  2.04e-03  0.040097 1.027\n-Kevin Bass         1.28e-02  7.12e-02 -9.02e-02 -1.74e-02 -0.123985 1.027\n-Kal Daniels       -1.09e-01  8.83e-02 -6.92e-02 -1.37e-02 -0.117476 1.025\n-Kirk Gibson        2.27e-02 -2.47e-02 -2.73e-03  1.92e-01  0.214128 1.003\n-Ken Griffey        7.61e-03 -3.34e-02  3.51e-02  2.31e-02  0.050656 1.029\n-Keith Hernandez   -1.52e-02 -1.83e-01  2.48e-01 -6.77e-02  0.336103 0.945\n-Kent Hrbek        -4.24e-02  1.99e-02 -2.45e-02  1.39e-01  0.181680 1.009\n-Ken Landreaux      6.06e-02 -1.48e-02  7.99e-03 -2.84e-02  0.079663 1.010\n-Kevin McReynolds   1.30e-02  2.02e-02 -2.35e-02 -4.94e-02 -0.078198 1.026\n-Kevin Mitchell    -5.85e-02  3.95e-02 -2.86e-02 -2.47e-02 -0.078225 1.007\n-Keith Moreland    -5.18e-02  3.89e-02 -1.36e-02 -4.43e-02  0.101486 1.015\n-Ken Oberkfell     -1.13e-02  1.44e-02 -3.38e-03 -3.68e-02  0.049249 1.026\n-Ken Phelps        -2.88e-02  2.99e-03  1.60e-02 -7.95e-02 -0.092367 1.029\n-Kirby Puckett      5.34e-02  3.55e-01 -4.12e-01 -2.14e-01 -0.554805 0.992\n-Kurt Stillwell    -2.29e-02 -1.51e-02  1.71e-02  2.94e-02 -0.050053 1.025\n-Leon Durham       -1.79e-02  2.93e-02 -3.04e-02  6.50e-02  0.119335 0.995\n-Len Dykstra       -2.56e-02  4.61e-02 -5.92e-02  3.91e-02 -0.097424 1.007\n-Larry Herndon     -2.34e-02  1.15e-03  4.27e-03 -1.07e-03 -0.030495 1.020\n-Lee Lacy           1.21e-03  7.57e-03 -1.36e-02  1.06e-02 -0.031430 1.021\n-Len Matuszek      -2.73e-02  1.32e-02 -6.25e-03 -9.11e-03 -0.029224 1.028\n-Lloyd Moseby      -1.91e-02  2.26e-02 -1.93e-02  7.31e-03  0.034531 1.030\n-Lance Parrish      3.46e-02 -1.47e-02 -2.45e-03  6.80e-02  0.080653 1.027\n-Larry Parrish     -5.09e-03  1.29e-02 -6.60e-03 -5.55e-02 -0.063419 1.033\n-Larry Sheets      -6.01e-02  4.13e-02 -2.12e-02 -7.80e-02 -0.108104 1.008\n-Lou Whitaker       4.27e-02 -2.92e-02  1.69e-02 -1.65e-02 -0.083285 1.016\n-Mike Aldrete      -4.90e-02  1.23e-02 -4.10e-03  1.57e-02 -0.056724 1.022\n-Marty Barrett      2.22e-02 -7.08e-03 -9.51e-03  4.39e-02 -0.059492 1.044\n-Mike Davis        -3.44e-03  3.40e-03 -2.79e-03  1.11e-02  0.023562 1.021\n-Mike Diaz         -8.72e-02  4.92e-02 -2.48e-02 -4.78e-02 -0.099399 1.020\n-Mariano Duncan     5.10e-03 -4.73e-02  4.63e-02  1.88e-02 -0.060623 1.022\n-Mike Easler       -1.58e-03  9.03e-03 -1.11e-02  3.61e-04 -0.015274 1.026\n-Mel Hall          -1.28e-02  2.82e-02 -2.81e-02 -2.03e-02 -0.044855 1.022\n-Mike Heath         4.06e-02  2.41e-02 -3.66e-02  6.25e-04  0.073957 1.013\n-Mike Kingery      -5.95e-02  2.18e-02 -1.13e-02  1.12e-02 -0.064746 1.021\n-Mike LaValliere   -2.20e-02 -1.68e-02  1.94e-02  2.36e-02 -0.049084 1.021\n-Mike Marshall      2.08e-02  1.06e-02 -2.35e-02  4.29e-02  0.061086 1.025\n-Mike Pagliarulo    4.30e-02 -8.89e-02  1.04e-01 -1.29e-01 -0.189683 1.020\n-Mark Salas        -3.31e-02 -2.78e-03  1.21e-02 -4.68e-03 -0.044444 1.020\n-Mike Schmidt       9.44e-01 -4.08e-01  1.81e-01  5.15e-02  0.952182 0.690\n-Mike Scioscia      2.27e-02  3.67e-02 -3.22e-02 -5.76e-02  0.099382 1.001\n-Mickey Tettleton  -3.39e-02 -4.09e-03  1.65e-02 -1.62e-02 -0.047818 1.027\n-Milt Thompson     -3.20e-02 -8.94e-04  6.04e-03  1.09e-02 -0.046072 1.017\n-Mitch Webster      4.95e-02  8.30e-03 -5.39e-02  1.03e-01 -0.171094 1.006\n-Mookie Wilson      2.45e-02 -2.53e-02  2.69e-02 -8.88e-03  0.046693 1.016\n-Marvell Wynne     -2.80e-02  9.59e-03 -4.99e-03  2.78e-03 -0.033658 1.019\n-Mike Young        -5.67e-03 -4.87e-03  5.52e-03  3.00e-03 -0.015880 1.020\n-Ozzie Guillen      4.79e-02 -7.69e-02  5.21e-02  9.14e-02 -0.122317 1.035\n-Oddibe McDowell    6.49e-02 -5.61e-02  3.61e-02 -8.15e-03 -0.124714 1.000\n-Ozzie Smith       -9.51e-02  7.13e-02  5.76e-02 -4.69e-01  0.550953 0.855\n-Ozzie Virgil       1.25e-02  4.37e-02 -5.55e-02  2.95e-02  0.079533 1.019\n-Phil Bradley      -3.04e-04  1.08e-02 -1.43e-02  4.26e-03 -0.019070 1.033\n-Phil Garner        5.74e-04 -2.01e-04  1.01e-04  3.37e-05  0.000735 1.021\n-Pete Incaviglia    5.99e-02 -7.98e-02  9.24e-02 -1.65e-01 -0.225440 1.011\n-Paul Molitor       2.29e-02 -2.78e-02  4.57e-02 -5.30e-02  0.129029 0.977\n-Pete Rose          9.07e-02  3.25e-02 -4.72e-02 -7.08e-02  0.151041 1.001\n-Pat Sheridan      -2.45e-02  2.13e-03  3.72e-03  3.06e-04 -0.029298 1.023\n-Pat Tabler        -1.35e-02  4.82e-02 -6.01e-02  2.96e-02 -0.074424 1.040\n-Rafael Belliard   -1.36e-02 -1.55e-02  1.55e-02  2.68e-02 -0.040850 1.026\n-Rick Burleson      5.39e-03 -3.42e-03  2.82e-03 -1.20e-03  0.006320 1.025\n-Randy Bush        -1.61e-02  4.00e-03 -3.97e-03  1.09e-02 -0.029482 1.018\n-Rick Cerone       -1.81e-02  6.80e-03 -3.47e-03  2.24e-03 -0.019496 1.026\n-Ron Cey            1.32e-01 -8.12e-02  4.58e-02  7.98e-02  0.158755 0.993\n-Rob Deer           2.11e-02 -7.19e-02  1.01e-01 -1.81e-01 -0.222258 1.038\n-Rick Dempsey       3.82e-03  1.10e-02 -1.40e-02  5.00e-03  0.018617 1.029\n-Ron Hassey        -1.30e-02  1.82e-02 -1.81e-02  4.33e-04 -0.021450 1.031\n-Rickey Henderson  -1.39e-01  1.03e-01 -8.99e-02  1.80e-01  0.310296 0.961\n-Reggie Jackson    -1.87e-05 -3.39e-03  4.09e-03 -3.46e-03 -0.006982 1.025\n-Ron Kittle        -6.74e-04 -4.78e-03  6.41e-03 -6.15e-03 -0.010043 1.036\n-Ray Knight        -3.94e-03  2.58e-02 -3.50e-02  1.44e-02 -0.053574 1.021\n-Rick Leach        -5.26e-02  4.51e-02 -3.92e-02  5.45e-03 -0.061488 1.026\n-Rick Manning       1.35e-02 -5.40e-03  2.01e-03  3.37e-03  0.014381 1.027\n-Rance Mulliniks   -1.84e-03  5.85e-05  3.26e-04 -4.75e-04 -0.003132 1.020\n-Ron Oester        -2.26e-02  3.44e-02 -2.27e-02 -3.44e-02  0.058600 1.024\n-Rey Quinones      -1.38e-02 -2.98e-02  3.16e-02  2.70e-02 -0.053564 1.025\n-Rafael Ramirez    -4.85e-02  1.08e-01 -9.09e-02 -6.30e-02  0.135017 1.013\n-Ronn Reynolds     -8.04e-03  2.36e-03 -3.87e-04 -3.01e-04 -0.008425 1.034\n-Ron Roenicke      -2.42e-02  4.54e-04  3.78e-03  7.77e-03 -0.032447 1.021\n-Ryne Sandberg      8.20e-03 -1.64e-03 -2.84e-03  5.71e-03 -0.016574 1.031\n-Rafael Santana     6.45e-04 -5.08e-03  4.65e-03  4.18e-03 -0.006834 1.038\n-Rick Schu         -6.57e-02  3.72e-02 -2.24e-02 -1.53e-02 -0.069016 1.022\n-Ruben Sierra      -3.57e-02  9.90e-03  1.59e-03 -4.98e-02 -0.087465 1.001\n-Roy Smalley       -5.91e-03  2.12e-02 -2.40e-02  2.31e-02  0.043772 1.024\n-Robby Thompson     5.19e-02 -4.75e-02  1.27e-02  9.53e-02 -0.140832 1.008\n-Rob Wilfong        8.69e-03  9.61e-03 -1.13e-02 -8.49e-03  0.021196 1.026\n-Robin Yount        1.89e-03 -4.12e-02  5.64e-02 -2.92e-02  0.077390 1.032\n-Steve Balboni      6.22e-02 -1.33e-01  1.52e-01 -1.51e-01 -0.238906 1.023\n-Scott Bradley     -8.83e-02  6.52e-02 -5.21e-02  2.83e-03 -0.096123 1.019\n-Sid Bream          3.29e-02 -2.99e-02  1.65e-02 -4.34e-03 -0.093611 1.001\n-Steve Buechele     1.92e-02 -6.31e-02  6.69e-02 -3.78e-02 -0.103221 1.009\n-Shawon Dunston     8.37e-02 -1.12e-01  9.27e-02  6.61e-03 -0.147228 1.010\n-Scott Fletcher     7.47e-03  1.75e-02 -3.68e-02  5.70e-02 -0.080957 1.035\n-Steve Garvey      -1.04e-01  1.28e-01 -1.12e-01  7.07e-02  0.222426 0.968\n-Steve Jeltz        1.18e-02 -4.20e-02  3.67e-02  3.48e-02 -0.053836 1.045\n-Steve Lombardozzi  2.34e-02 -7.74e-02  7.16e-02  3.31e-02 -0.090932 1.025\n-Spike Owen         1.61e-03 -3.28e-03  2.63e-03  2.82e-03 -0.004220 1.054\n-Steve Sax          4.74e-02  2.88e-01 -4.15e-01  2.57e-01 -0.561771 0.992\n-Tony Bernazard     1.30e-02  4.32e-02 -6.01e-02 -2.28e-03 -0.094867 1.019\n-Tom Brookens      -6.87e-03  2.70e-03 -2.15e-03  3.78e-03 -0.009053 1.024\n-Tom Brunansky     -3.76e-02  3.98e-02 -3.40e-02  2.41e-02  0.071115 1.027\n-Tony Fernandez     9.34e-02  8.84e-02 -1.72e-01  1.43e-01 -0.309101 1.018\n-Tim Flannery      -1.34e-02  7.05e-03 -1.01e-02  2.26e-02 -0.033840 1.023\n-Tom Foley         -1.69e-02  5.38e-03 -4.10e-03  1.14e-02 -0.022935 1.025\n-Tony Gwynn         1.65e-02  1.00e-01 -1.34e-01  3.45e-02 -0.167916 1.052\n-Terry Harper       7.18e-03 -2.14e-03  5.69e-04  7.95e-04  0.008249 1.023\n-Tommy Herr        -7.91e-02  1.19e-01 -7.84e-02 -1.46e-01  0.194226 1.024\n-Tim Hulett         4.74e-02 -9.74e-02  9.36e-02 -8.84e-03 -0.114204 1.025\n-Terry Kennedy      3.52e-01 -1.82e-01  9.86e-02  3.63e-02  0.352395 0.992\n-Tito Landrum       1.49e-02  2.43e-03 -5.84e-03 -4.82e-03  0.020196 1.028\n-Tim Laudner       -2.61e-02  9.61e-03 -1.99e-03 -1.13e-02 -0.029228 1.029\n-Tom Paciorek      -3.65e-02  2.25e-02 -1.68e-02  3.56e-03 -0.039003 1.027\n-Tony Pena         -1.30e-02 -2.13e-02  4.65e-02 -5.08e-02  0.114130 1.003\n-Terry Pendleton    5.99e-02 -9.94e-02  7.45e-02  9.35e-02 -0.134267 1.052\n-Tony Phillips      7.22e-04 -3.76e-03  2.60e-03  5.55e-03 -0.008033 1.025\n-Terry Puhl         1.77e-01 -5.85e-02  2.11e-02 -1.29e-02  0.187017 0.990\n-Ted Simmons        8.03e-02 -3.69e-02  1.83e-02  8.05e-03  0.081328 1.029\n-Tim Teufel        -8.84e-03 -2.89e-04  1.60e-03  4.35e-03 -0.012606 1.023\n-Tim Wallach       -2.12e-02  5.56e-02 -5.68e-02  1.87e-02  0.073433 1.025\n-Vince Coleman      6.27e-02 -1.05e-01  8.14e-02  9.02e-02 -0.134179 1.068\n-Von Hayes         -2.73e-02 -5.85e-02  8.30e-02  6.20e-03  0.129480 1.022\n-Vance Law          5.51e-03  3.77e-02 -3.81e-02 -2.38e-02  0.055877 1.023\n-Wally Backman     -6.18e-03  1.03e-02 -1.25e-02  9.74e-03 -0.017580 1.039\n-Wade Boggs         3.35e-02 -2.91e-01  3.58e-01 -1.12e-01  0.403607 1.062\n-Will Clark        -3.68e-02  4.45e-02 -4.90e-02  6.85e-03 -0.089611 0.998\n-Wally Joyner       6.27e-02  4.77e-02 -7.80e-02 -6.49e-02 -0.207522 0.979\n-Willie McGee      -1.65e-02  3.14e-02 -2.19e-02 -3.26e-02  0.052971 1.024\n-Willie Randolph   -1.26e-02  1.17e-02  7.02e-03 -6.25e-02  0.084131 1.018\n-Wayne Tolleson     5.22e-03 -1.10e-02  4.64e-03  2.58e-02 -0.032231 1.028\n-Willie Upshaw     -7.49e-02  1.05e-01 -7.66e-02 -7.50e-02  0.145254 1.018\n-Willie Wilson     -6.68e-02  5.50e-02 -2.28e-02 -7.22e-02  0.121217 1.026\n                     cook.d     hat inf\n-Alan Ashby        3.94e-05 0.00540    \n-Alvin Davis       3.15e-04 0.00589    \n-Andre Dawson      8.14e-04 0.00833    \n-Andres Galarraga  1.28e-03 0.00544    \n-Alfredo Griffin   2.27e-04 0.02461    \n-Al Newman         3.13e-04 0.01412    \n-Argenis Salazar   7.07e-04 0.01093    \n-Andres Thomas     8.92e-04 0.00583    \n-Andre Thornton    7.80e-03 0.01181    \n-Alan Trammell     1.14e-03 0.00995    \n-Alex Trevino      6.75e-04 0.01160    \n-Andy VanSlyke     2.40e-06 0.00392    \n-Alan Wiggins      3.14e-03 0.01133    \n-Bill Almon        2.64e-05 0.01206    \n-Buddy Bell        2.71e-08 0.00926    \n-Buddy Biancalana  1.56e-04 0.01234    \n-Bruce Bochy       9.40e-04 0.02042    \n-Barry Bonds       2.49e-03 0.01404    \n-Bobby Bonilla     1.75e-03 0.01106    \n-Bob Brenly        5.25e-05 0.00873    \n-Bill Buckner      2.22e-05 0.01390    \n-Brett Butler      6.32e-04 0.02317    \n-Bob Dernier       2.75e-03 0.01020    \n-Bo Diaz           2.45e-04 0.00579    \n-Bill Doran        3.06e-07 0.01543    \n-Brian Downing     5.61e-04 0.00778    \n-Billy Hatcher     1.39e-03 0.00710    \n-Brook Jacoby      6.64e-04 0.01085    \n-Bob Kearney       4.04e-07 0.01088    \n-Bill Madlock      7.04e-04 0.00473    \n-Bob Melvin        5.58e-04 0.00900    \n-BillyJo Robidoux  5.45e-04 0.01333    \n-Bill Schroeder    1.44e-04 0.01128    \n-Chris Bando       2.75e-05 0.00979    \n-Chris Brown       5.69e-03 0.01663    \n-Carmen Castillo   4.20e-04 0.01303    \n-Chili Davis       2.18e-04 0.00704    \n-Carlton Fisk      6.06e-03 0.01782    \n-Curt Ford         8.11e-04 0.01097    \n-Carney Lansford   2.56e-03 0.01071    \n-Chet Lemon        2.89e-04 0.00498    \n-Candy Maldonado   2.09e-04 0.00765    \n-Carmelo Martinez  4.68e-07 0.00897    \n-Craig Reynolds    1.59e-05 0.00601    \n-Cal Ripken        5.32e-03 0.01548    \n-Cory Snyder       7.94e-03 0.01424    \n-Chris Speier      1.21e-04 0.01764    \n-Curt Wilkerson    1.26e-05 0.01158    \n-Dave Anderson     4.03e-05 0.01141    \n-Don Baylor        3.84e-03 0.03525    \n-Daryl Boston      1.32e-03 0.01200    \n-Darnell Coles     4.59e-03 0.00769    \n-Dave Concepcion   3.70e-05 0.00754    \n-Doug DeCinces     6.22e-04 0.01616    \n-Darrell Evans     6.56e-04 0.02641    \n-Dwight Evans      1.16e-03 0.01561    \n-Damaso Garcia     1.10e-03 0.00737    \n-Dan Gladden       7.04e-04 0.00732    \n-Dave Henderson    4.05e-04 0.00494    \n-Donnie Hill       4.68e-04 0.00803    \n-Davey Lopes       2.28e-05 0.00867    \n-Don Mattingly     6.14e-02 0.09037   *\n-Dale Murphy       3.85e-02 0.02058   *\n-Dwayne Murphy     2.54e-04 0.00499    \n-Dave Parker       7.05e-04 0.02334    \n-Dan Pasqua        4.77e-03 0.01483    \n-Darrell Porter    4.36e-04 0.02123    \n-Dick Schofield    1.80e-05 0.00693    \n-Don Slaught       2.75e-05 0.00665    \n-Darryl Strawberry 7.89e-03 0.01769    \n-Dale Sveum        8.86e-04 0.00584    \n-Danny Tartabull   7.48e-03 0.01283    \n-Denny Walling     1.31e-04 0.01244    \n-Dave Winfield     2.73e-02 0.01335   *\n-Eric Davis        6.04e-03 0.02052    \n-Eddie Milner      3.13e-05 0.00478    \n-Eddie Murray      5.61e-02 0.01269   *\n-Ed Romero         4.56e-04 0.01202    \n-Frank White       3.81e-06 0.01032    \n-George Bell       3.27e-04 0.03440   *\n-Glenn Braggs      7.61e-04 0.01024    \n-George Brett      7.40e-03 0.00702    \n-Greg Brock        4.18e-05 0.01025    \n-Gary Carter       3.44e-02 0.01335   *\n-Glenn Davis       1.42e-02 0.02338    \n-Gary Gaetti       2.74e-04 0.03006   *\n-Greg Gagne        1.59e-03 0.00757    \n-George Hendrick   6.99e-04 0.00994    \n-Glenn Hubbard     8.72e-04 0.01441    \n-Garth Iorg        5.41e-06 0.00751    \n-Gary Matthews     4.58e-04 0.01198    \n-Graig Nettles     8.65e-04 0.01360    \n-Gary Pettis       4.31e-04 0.01809    \n-Gary Redus        8.20e-06 0.00533    \n-Garry Templeton   3.62e-03 0.02315    \n-Greg Walker       1.28e-06 0.00954    \n-Gary Ward         3.33e-06 0.01588    \n-Glenn Wilson      2.81e-05 0.01027    \n-Harold Baines     1.27e-04 0.01369    \n-Hubie Brooks      2.02e-04 0.02455    \n-Howard Johnson    6.88e-05 0.01116    \n-Hal McRae         2.47e-05 0.00661    \n-Harold Reynolds   1.93e-03 0.02662    \n-Harry Spilman     5.09e-04 0.01782    \n-Herm Winningham   4.57e-04 0.01251    \n-Jesse Barfield    3.41e-03 0.04727   *\n-Juan Beniquez     1.81e-04 0.00984    \n-John Cangelosi    1.90e-03 0.01856    \n-Jose Canseco      2.12e-02 0.03860    \n-Joe Carter        3.07e-02 0.02791    \n-Jack Clark        1.44e-02 0.00976   *\n-Jose Cruz         2.57e-04 0.00622    \n-Jody Davis        2.87e-03 0.01258    \n-Jim Dwyer         3.05e-05 0.01593    \n-Julio Franco      1.66e-04 0.02305    \n-Jim Gantner       1.12e-03 0.00960    \n-Johnny Grubb      1.22e-03 0.02493    \n-Jack Howell       1.16e-03 0.01668    \n-John Kruk         2.96e-03 0.01353    \n-Jeffrey Leonard   1.38e-03 0.00622    \n-Jim Morrison      3.93e-03 0.01043    \n-John Moses        1.69e-03 0.00956    \n-Jerry Mumphrey    1.63e-04 0.01145    \n-Jim Presley       1.10e-02 0.01817    \n-Johnny Ray        4.57e-04 0.02223    \n-Jeff Reed         6.55e-04 0.01410    \n-Jim Rice          1.07e-01 0.03416   *\n-Jerry Royster     1.36e-04 0.00787    \n-John Russell      8.36e-04 0.00732    \n-Juan Samuel       5.27e-05 0.01123    \n-John Shelby       1.62e-04 0.01058    \n-Joel Skinner      5.87e-04 0.00821    \n-Jim Sundberg      6.94e-03 0.01962    \n-Jose Uribe        6.27e-04 0.02432    \n-Joel Youngblood   4.03e-04 0.01275    \n-Kevin Bass        3.85e-03 0.02192    \n-Kal Daniels       3.45e-03 0.01950    \n-Kirk Gibson       1.14e-02 0.02056    \n-Ken Griffey       6.44e-04 0.01574    \n-Keith Hernandez   2.77e-02 0.01861   *\n-Kent Hrbek        8.23e-03 0.01925    \n-Ken Landreaux     1.59e-03 0.00739    \n-Kevin McReynolds  1.53e-03 0.01563    \n-Kevin Mitchell    1.53e-03 0.00624    \n-Keith Moreland    2.58e-03 0.01216    \n-Ken Oberkfell     6.08e-04 0.01265    \n-Ken Phelps        2.14e-03 0.01983    \n-Kirby Puckett     7.57e-02 0.05527   *\n-Kurt Stillwell    6.28e-04 0.01199    \n-Leon Durham       3.55e-03 0.00780    \n-Len Dykstra       2.37e-03 0.00858    \n-Larry Herndon     2.33e-04 0.00650    \n-Lee Lacy          2.48e-04 0.00742    \n-Len Matuszek      2.14e-04 0.01299    \n-Lloyd Moseby      2.99e-04 0.01541    \n-Lance Parrish     1.63e-03 0.01684    \n-Larry Parrish     1.01e-03 0.01955    \n-Larry Sheets      2.92e-03 0.01021    \n-Lou Whitaker      1.74e-03 0.01037    \n-Mike Aldrete      8.07e-04 0.01090    \n-Marty Barrett     8.88e-04 0.02919    \n-Mike Davis        1.39e-04 0.00668    \n-Mike Diaz         2.47e-03 0.01471    \n-Mariano Duncan    9.21e-04 0.01154    \n-Mike Easler       5.85e-05 0.01082    \n-Mel Hall          5.05e-04 0.00977    \n-Mike Heath        1.37e-03 0.00815    \n-Mike Kingery      1.05e-03 0.01115    \n-Mike LaValliere   6.04e-04 0.00901    \n-Mike Marshall     9.36e-04 0.01371    \n-Mike Pagliarulo   8.98e-03 0.02554    \n-Mark Salas        4.95e-04 0.00824    \n-Mike Schmidt      2.05e-01 0.03089   *\n-Mike Scioscia     2.47e-03 0.00698    \n-Mickey Tettleton  5.73e-04 0.01355    \n-Milt Thompson     5.32e-04 0.00617    \n-Mitch Webster     7.30e-03 0.01694    \n-Mookie Wilson     5.46e-04 0.00619    \n-Marvell Wynne     2.84e-04 0.00634    \n-Mike Young        6.33e-05 0.00474    \n-Ozzie Guillen     3.75e-03 0.02716    \n-Oddibe McDowell   3.88e-03 0.00964    \n-Ozzie Smith       7.25e-02 0.02295   *\n-Ozzie Virgil      1.58e-03 0.01141    \n-Phil Bradley      9.13e-05 0.01688    \n-Phil Garner       1.36e-07 0.00536    \n-Pete Incaviglia   1.27e-02 0.02516    \n-Paul Molitor      4.13e-03 0.00571    \n-Pete Rose         5.69e-03 0.01262    \n-Pat Sheridan      2.15e-04 0.00889    \n-Pat Tabler        1.39e-03 0.02628    \n-Rafael Belliard   4.19e-04 0.01234    \n-Rick Burleson     1.00e-05 0.00907    \n-Randy Bush        2.18e-04 0.00496    \n-Rick Cerone       9.54e-05 0.01047    \n-Ron Cey           6.27e-03 0.01140    \n-Rob Deer          1.23e-02 0.03955    \n-Rick Dempsey      8.70e-05 0.01365    \n-Ron Hassey        1.15e-04 0.01582    \n-Rickey Henderson  2.37e-02 0.01946    \n-Reggie Jackson    1.22e-05 0.00963    \n-Ron Kittle        2.53e-05 0.01951    \n-Ray Knight        7.20e-04 0.01010    \n-Rick Leach        9.48e-04 0.01402    \n-Rick Manning      5.19e-05 0.01159    \n-Rance Mulliniks   2.46e-06 0.00450    \n-Ron Oester        8.61e-04 0.01226    \n-Rey Quinones      7.19e-04 0.01288    \n-Rafael Ramirez    4.55e-03 0.01556    \n-Ronn Reynolds     1.78e-05 0.01742    \n-Ron Roenicke      2.64e-04 0.00722    \n-Ryne Sandberg     6.89e-05 0.01480    \n-Rafael Santana    1.17e-05 0.02135    \n-Rick Schu         1.19e-03 0.01243    \n-Ruben Sierra      1.91e-03 0.00575    \n-Roy Smalley       4.81e-04 0.01061    \n-Robby Thompson    4.95e-03 0.01401    \n-Rob Wilfong       1.13e-04 0.01093    \n-Robin Yount       1.50e-03 0.01993    \n-Steve Balboni     1.42e-02 0.03283    \n-Scott Bradley     2.31e-03 0.01382    \n-Sid Bream         2.19e-03 0.00648    \n-Steve Buechele    2.66e-03 0.01005    \n-Shawon Dunston    5.41e-03 0.01549    \n-Scott Fletcher    1.64e-03 0.02316    \n-Steve Garvey      1.22e-02 0.01247    \n-Steve Jeltz       7.27e-04 0.02943    \n-Steve Lombardozzi 2.07e-03 0.01637    \n-Spike Owen        4.47e-06 0.03619   *\n-Steve Sax         7.76e-02 0.05621   *\n-Tony Bernazard    2.25e-03 0.01372    \n-Tom Brookens      2.06e-05 0.00843    \n-Tom Brunansky     1.27e-03 0.01555    \n-Tony Fernandez    2.38e-02 0.03841    \n-Tim Flannery      2.87e-04 0.00880    \n-Tom Foley         1.32e-04 0.01018    \n-Tony Gwynn        7.06e-03 0.04413   *\n-Terry Harper      1.71e-05 0.00728    \n-Tommy Herr        9.42e-03 0.02831    \n-Tim Hulett        3.26e-03 0.01934    \n-Terry Kennedy     3.07e-02 0.03269    \n-Tito Landrum      1.02e-04 0.01246    \n-Tim Laudner       2.14e-04 0.01372    \n-Tom Paciorek      3.82e-04 0.01268    \n-Tony Pena         3.25e-03 0.00921    \n-Terry Pendleton   4.52e-03 0.04110   *\n-Tony Phillips     1.62e-05 0.00948    \n-Terry Puhl        8.69e-03 0.01348    \n-Ted Simmons       1.66e-03 0.01835    \n-Tim Teufel        3.99e-05 0.00754    \n-Tim Wallach       1.35e-03 0.01472    \n-Vince Coleman     4.51e-03 0.05407   *\n-Von Hayes         4.19e-03 0.01920    \n-Vance Law         7.83e-04 0.01135    \n-Wally Backman     7.76e-05 0.02256    \n-Wade Boggs        4.06e-02 0.07367   *\n-Will Clark        2.00e-03 0.00548    \n-Wally Joyner      1.07e-02 0.01320    \n-Willie McGee      7.04e-04 0.01159    \n-Willie Randolph   1.77e-03 0.01180    \n-Wayne Tolleson    2.61e-04 0.01364    \n-Willie Upshaw     5.27e-03 0.01897    \n-Willie Wilson     3.68e-03 0.02101    \n\n\n\nsummary(influence.measures(reg_model))\n\nPotentially influential observations of\n     lm(formula = Salary ~ AtBat + Hits + HmRun, data = hitters) :\n\n                 dfb.1_ dfb.AtBt dfb.Hits dfb.HmRn dffit   cov.r   cook.d\n-Don Mattingly    0.01  -0.38     0.42     0.15     0.50_*  1.07_*  0.06 \n-Dale Murphy     -0.17   0.11    -0.09     0.24     0.40_*  0.92_*  0.04 \n-Dave Winfield   -0.14   0.12    -0.11     0.17     0.34    0.91_*  0.03 \n-Eddie Murray     0.06  -0.32     0.36     0.09     0.49_*  0.78_*  0.06 \n-George Bell     -0.01  -0.02     0.02     0.02     0.04    1.05_*  0.00 \n-Gary Carter     -0.06   0.11    -0.13     0.26     0.38_*  0.88_*  0.03 \n-Gary Gaetti      0.01   0.01    -0.01    -0.03    -0.03    1.05_*  0.00 \n-Jesse Barfield  -0.01  -0.03     0.02     0.10     0.12    1.06_*  0.00 \n-Jack Clark       0.20  -0.03    -0.03     0.06     0.24    0.94_*  0.01 \n-Jim Rice        -0.05  -0.43     0.54     0.05     0.67_*  0.87_*  0.11 \n-Keith Hernandez -0.02  -0.18     0.25    -0.07     0.34    0.94_*  0.03 \n-Kirby Puckett    0.05   0.36    -0.41    -0.21    -0.55_*  0.99    0.08 \n-Mike Schmidt     0.94  -0.41     0.18     0.05     0.95_*  0.69_*  0.20 \n-Ozzie Smith     -0.10   0.07     0.06    -0.47     0.55_*  0.85_*  0.07 \n-Spike Owen       0.00   0.00     0.00     0.00     0.00    1.05_*  0.00 \n-Steve Sax        0.05   0.29    -0.41     0.26    -0.56_*  0.99    0.08 \n-Tony Gwynn       0.02   0.10    -0.13     0.03    -0.17    1.05_*  0.01 \n-Terry Pendleton  0.06  -0.10     0.07     0.09    -0.13    1.05_*  0.00 \n-Vince Coleman    0.06  -0.11     0.08     0.09    -0.13    1.07_*  0.00 \n-Wade Boggs       0.03  -0.29     0.36    -0.11     0.40_*  1.06_*  0.04 \n                 hat    \n-Don Mattingly    0.09_*\n-Dale Murphy      0.02  \n-Dave Winfield    0.01  \n-Eddie Murray     0.01  \n-George Bell      0.03  \n-Gary Carter      0.01  \n-Gary Gaetti      0.03  \n-Jesse Barfield   0.05_*\n-Jack Clark       0.01  \n-Jim Rice         0.03  \n-Keith Hernandez  0.02  \n-Kirby Puckett    0.06_*\n-Mike Schmidt     0.03  \n-Ozzie Smith      0.02  \n-Spike Owen       0.04  \n-Steve Sax        0.06_*\n-Tony Gwynn       0.04  \n-Terry Pendleton  0.04  \n-Vince Coleman    0.05_*\n-Wade Boggs       0.07_*\n\n\n\n\n기각역\n\np &lt;- 3\n\n\nn &lt;- nrow(hitters)\n\n\n2*(p+1)/n #hat (h_ii)\n\n0.0304182509505703\n\n\n\n3*sqrt((p+1)/(n-p-1)) #Dffits\n\n0.37282185960072\n\n\n\n2*sqrt((p+1)/(n)) #Dffits\n\n0.246650566391283\n\n\n\nqf(0.5, p+1, n-p-1) #Cook d\n\n0.841375151461702\n\n\n\n\n변수 변환\n\nhitters$log_Salary &lt;- log(hitters$Salary)\n\n\nreg_model_2 &lt;- lm(log_Salary ~ AtBat + Hits + HmRun, hitters)\n\n\nsummary(reg_model_2)\n\n\nCall:\nlm(formula = log_Salary ~ AtBat + Hits + HmRun, data = hitters)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.2664 -0.6572  0.1122  0.5639  2.5886 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  5.103575   0.149615  34.111  &lt; 2e-16 ***\nAtBat       -0.002179   0.001265  -1.722 0.086196 .  \nHits         0.014012   0.004052   3.458 0.000636 ***\nHmRun        0.016540   0.006678   2.477 0.013895 *  \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.7872 on 259 degrees of freedom\nMultiple R-squared:  0.2253,    Adjusted R-squared:  0.2163 \nF-statistic:  25.1 on 3 and 259 DF,  p-value: 2.729e-14\n\n\n\n\n잔차그림\n\nresidual &lt;- resid(reg_model_2)\nstad.res &lt;- rstandard(reg_model_2)\nstu.res &lt;- rstudent(reg_model_2)\n\n\npar(mfrow = c(2, 2))\nplot(fitted(reg_model_2), residual, \n     pch=20,cex  = 2,col  = \"darkorange\",\n     xlab = \"Fitted\", ylab = \"Residuals\", \n     main = \"residual plot\")\nabline(h=0, lty=2)\n\nplot(fitted(reg_model_2), stad.res, \n     pch=20,cex  = 2,col  = \"darkorange\",\n     xlab = \"Fitted\", ylab = \"S_Residuals\", \n     ylim=c(min(-3, min(stad.res)), \n            max(3,max(stad.res))),\n     main = \"standardized residual plot\")\nabline(h=c(-2,0,2), lty=2)\n\nplot(fitted(reg_model_2), stu.res, \n     pch=20,cex  = 2,col  = \"darkorange\",\n     xlab = \"Fitted\", ylab = \"S_Residuals_(i)\", \n     ylim=c(min(-3, min(stu.res)), \n            max(3,max(stu.res))),\n     main = \"studentized residual plot\")\nabline(h=c(-2,0,2), lty=2)\n\nplot(fitted(reg_model_2), stu.res, \n     pch=20,cex  = 2,col  = \"darkorange\",\n     xlab = \"Fitted\", ylab = \"S_Residuals_(i)\", \n     ylim=c(min(-3, min(stu.res)), \n            max(3,max(stu.res))),\n     main = \"studentized residual plot\")\nabline(h=c(-qt(0.975,nrow(hitters)-4),0,qt(0.975,nrow(hitters)-4)), lty=2)\ntext (fitted(reg_model_2)[which(abs(stu.res)&gt;qt(0.975,nrow(hitters)-4))],\n      stu.res[which(abs(stu.res)&gt;qt(0.975,nrow(hitters)-4))], \n      which(abs(stu.res)&gt;qt(0.975,nrow(hitters)-4)),adj = c(0,1))\n\n\n\n\n\nstu.res[abs(stu.res)&gt;qt(0.975,nrow(hitters)-4)]\n\n-Cory Snyder-2.16182826573383-Darnell Coles-2.09872610566858-Jack Clark2.12385831075298-Mike Schmidt3.40826964934749-Ozzie Smith2.0286158569726-Steve Sax-3.00934037017267-Terry Kennedy2.19849337509094\n\n\n\nwhich(abs(stu.res)&gt;qt(0.975,nrow(hitters)-4))\n\n-Cory Snyder46-Darnell Coles52-Jack Clark111-Mike Schmidt173-Ozzie Smith183-Steve Sax230-Terry Kennedy241\n\n\n\ninfluence(reg_model_2)\n\n\n    $hat\n        -Alan Ashby0.00540428715355245-Alvin Davis0.00589170670784522-Andre Dawson0.00832644882765465-Andres Galarraga0.00543756565246947-Alfredo Griffin0.0246137118709988-Al Newman0.0141225554276349-Argenis Salazar0.010928273983481-Andres Thomas0.00583280157863637-Andre Thornton0.0118104032344835-Alan Trammell0.00994920971431027-Alex Trevino0.0116023974454147-Andy VanSlyke0.00392214855226506-Alan Wiggins0.01133266253963-Bill Almon0.0120577739078933-Buddy Bell0.00926235909199221-Buddy Biancalana0.012342136255686-Bruce Bochy0.0204159574317937-Barry Bonds0.0140367315219278-Bobby Bonilla0.0110632944090634-Bob Brenly0.00872907614618226-Bill Buckner0.0139048245540849-Brett Butler0.023168413560765-Bob Dernier0.0102008268559032-Bo Diaz0.00579243488480162-Bill Doran0.015434760936016-Brian Downing0.00777622895232283-Billy Hatcher0.00709689247443314-Brook Jacoby0.0108511422285614-Bob Kearney0.0108810262666556-Bill Madlock0.00473465384983353-Bob Melvin0.00900012174203842-BillyJo Robidoux0.0133294228418443-Bill Schroeder0.0112763637277587-Chris Bando0.00978612142405515-Chris Brown0.0166260339272529-Carmen Castillo0.0130280396536268-Chili Davis0.00704454319748951-Carlton Fisk0.017822764593868-Curt Ford0.0109708972674672-Carney Lansford0.0107121199405846-Chet Lemon0.004977264802092-Candy Maldonado0.00764992031384351-Carmelo Martinez0.0089685788087143-Craig Reynolds0.00600742640963073-Cal Ripken0.0154842953466146-Cory Snyder0.0142384557435194-Chris Speier0.0176408073638382-Curt Wilkerson0.011580828583756-Dave Anderson0.0114107120327874-Don Baylor0.0352479469918076-Daryl Boston0.0120025169206652-Darnell Coles0.00768936788078936-Dave Concepcion0.00754097071158992-Doug DeCinces0.016164784133267-Darrell Evans0.0264058825441862-Dwight Evans0.0156073759122261-Damaso Garcia0.00737202574736494-Dan Gladden0.00732057564815775-Dave Henderson0.00493766296992215-Donnie Hill0.00802999130926279-Davey Lopes0.00867219904074439-Don Mattingly0.0903700111079589-Dale Murphy0.0205781074488089-Dwayne Murphy0.00499065937964354-Dave Parker0.0233401084346804-Dan Pasqua0.0148260514260301-Darrell Porter0.0212335628824219-Dick Schofield0.00692844758375807-Don Slaught0.00665433551016605-Darryl Strawberry0.017694944503085-Dale Sveum0.00583616542870044-Danny Tartabull0.0128297967927647-Denny Walling0.0124382760330085-Dave Winfield0.0133528039520951-Eric Davis0.0205166608140052-Eddie Milner0.00477555388471096-Eddie Murray0.0126894264569264-Ed Romero0.0120154735656705-Frank White0.0103217756795036-George Bell0.0344024597514498-Glenn Braggs0.0102378206814018-George Brett0.0070249800741032-Greg Brock0.0102483444612376-Gary Carter0.0133493295035423-Glenn Davis0.0233784484234977-Gary Gaetti0.0300641988907722-Greg Gagne0.00756816838324455-George Hendrick0.00993821578501312-Glenn Hubbard0.0144050547662455-Garth Iorg0.00750828700013946-Gary Matthews0.0119812939218614-Graig Nettles0.0135988964718854-Gary Pettis0.0180946787493926-Gary Redus0.00533116613569048-Garry Templeton0.0231472795912073-Greg Walker0.00954059659043919-Gary Ward0.0158776584493562-Glenn Wilson0.0102664940810771-Harold Baines0.0136874329182192-Hubie Brooks0.0245534617574867-Howard Johnson0.0111605903106341-Hal McRae0.00660970775119084-Harold Reynolds0.0266174645810819-Harry Spilman0.0178175584405383-Herm Winningham0.0125072976893885-Jesse Barfield0.0472745129906935-Juan Beniquez0.0098405887950288-John Cangelosi0.0185585370145323-Jose Canseco0.0385966269231462-Joe Carter0.0279123839207128-Jack Clark0.00976153800810466-Jose Cruz0.00621927886532388-Jody Davis0.0125836354713245-Jim Dwyer0.0159318273881519-Julio Franco0.0230480594602062-Jim Gantner0.00960427626759017-Johnny Grubb0.0249337849541658-Jack Howell0.0166783571884679-John Kruk0.0135348618245948-Jeffrey Leonard0.00621692194497029-Jim Morrison0.0104347491092473-John Moses0.00955816927339891-Jerry Mumphrey0.0114527911454454-Jim Presley0.0181732014300399-Johnny Ray0.0222264061248388-Jeff Reed0.0141048942273143-Jim Rice0.0341630071931888-Jerry Royster0.00786584848798418-John Russell0.00732221183848203-Juan Samuel0.011233958379014-John Shelby0.0105769969697364-Joel Skinner0.00820725725265926-Jim Sundberg0.0196190015932163-Jose Uribe0.0243170465990865-Joel Youngblood0.0127513647950321-Kevin Bass0.0219191326187113-Kal Daniels0.0194979541215839-Kirk Gibson0.020556919885839-Ken Griffey0.0157391819211111-Keith Hernandez0.0186125240001884-Kent Hrbek0.0192503945544296-Ken Landreaux0.00738914265279174-Kevin McReynolds0.0156330543753078-Kevin Mitchell0.00623609661997075-Keith Moreland0.0121555120488774-Ken Oberkfell0.0126467584348519-Ken Phelps0.0198333298123843-Kirby Puckett0.0552718094796791-Kurt Stillwell0.011990041252144-Leon Durham0.00780417454171992-Len Dykstra0.00857784296541703-Larry Herndon0.0064990040160584-Lee Lacy0.00742301328937459-Len Matuszek0.0129926810188161-Lloyd Moseby0.0154094589566827-Lance Parrish0.0168397241242445-Larry Parrish0.0195480106203573-Larry Sheets0.0102053644915363-Lou Whitaker0.0103736298972029-Mike Aldrete0.0108976777772544-Marty Barrett0.0291908907582424-Mike Davis0.00667586668426171-Mike Diaz0.0147105547379761-Mariano Duncan0.0115422666932657-Mike Easler0.010820500442813-Mel Hall0.00976796679777078-Mike Heath0.0081507738805316-Mike Kingery0.0111519990806471-Mike LaValliere0.00901026773489625-Mike Marshall0.013711182342755-Mike Pagliarulo0.0255437587312095-Mark Salas0.00824038954487028-Mike Schmidt0.0308861245462707-Mike Scioscia0.00698057071979755-Mickey Tettleton0.0135500510047471-Milt Thompson0.00617205972690294-Mitch Webster0.0169403513647917-Mookie Wilson0.00619444773498657-Marvell Wynne0.0063403620095783-Mike Young0.00474275439485779-Ozzie Guillen0.0271620505926552-Oddibe McDowell0.00964328420757499-Ozzie Smith0.0229502793106078-Ozzie Virgil0.0114067190696189-Phil Bradley0.0168810816259417-Phil Garner0.00535812295602376-Pete Incaviglia0.025161431654974-Paul Molitor0.00570944294085908-Pete Rose0.0126156272171943-Pat Sheridan0.00888970164559414-Pat Tabler0.026279450164693-Rafael Belliard0.0123374671998298-Rick Burleson0.00906906701865493-Randy Bush0.00495753180334833-Rick Cerone0.0104730023394748-Ron Cey0.0113956391454122-Rob Deer0.0395521316143585-Rick Dempsey0.0136529420759308-Ron Hassey0.0158151139459369-Rickey Henderson0.0194628445140604-Reggie Jackson0.00963058080211747-Ron Kittle0.0195094238607815-Ray Knight0.0100975869646124-Rick Leach0.0140249162441515-Rick Manning0.0115898080723435-Rance Mulliniks0.00450212481049989-Ron Oester0.0122552708544235-Rey Quinones0.0128781945206417-Rafael Ramirez0.0155619012974591-Ronn Reynolds0.0174189559060563-Ron Roenicke0.007216482671799-Ryne Sandberg0.0148031952946029-Rafael Santana0.0213487186421553-Rick Schu0.0124262441988659-Ruben Sierra0.00575359430765965-Roy Smalley0.0106124476383773-Robby Thompson0.0140106441432452-Rob Wilfong0.0109282567228258-Robin Yount0.0199323190913311-Steve Balboni0.032832608857617-Scott Bradley0.013819143124654-Sid Bream0.0064848822413407-Steve Buechele0.010047792882046-Shawon Dunston0.0154878353515676-Scott Fletcher0.0231584911833167-Steve Garvey0.0124707214778381-Steve Jeltz0.0294334036298904-Steve Lombardozzi0.0163703558064671-Spike Owen0.0361863260829997-Steve Sax0.056205798190448-Tony Bernazard0.0137201779926164-Tom Brookens0.00842727602684437-Tom Brunansky0.0155535640161956-Tony Fernandez0.0384149427739519-Tim Flannery0.00879815995334561-Tom Foley0.010178072996595-Tony Gwynn0.0441255560927934-Terry Harper0.00728359774271928-Tommy Herr0.0283062395596944-Tim Hulett0.0193407789424842-Terry Kennedy0.0326924785968483-Tito Landrum0.0124610368212244-Tim Laudner0.0137152102414128-Tom Paciorek0.0126750030530696-Tony Pena0.00921261317536243-Terry Pendleton0.0411002808615697-Tony Phillips0.00947681648702826-Terry Puhl0.013480153488892-Ted Simmons0.0183540764261599-Tim Teufel0.00754075413540749-Tim Wallach0.014724129247963-Vince Coleman0.0540676127419561-Von Hayes0.0192039404330803-Vance Law0.0113459171671123-Wally Backman0.022556121420949-Wade Boggs0.0736687853777228-Will Clark0.00548420107775056-Wally Joyner0.01320331340394-Willie McGee0.0115854961579362-Willie Randolph0.011798792067581-Wayne Tolleson0.0136448610296419-Willie Upshaw0.0189725147824934-Willie Wilson0.0210111323582833\n\n    $coefficients\n        \n\nA matrix: 263 × 4 of type dbl\n\n\n\n(Intercept)\nAtBat\nHits\nHmRun\n\n\n\n\n-Alan Ashby\n4.817418e-03\n-2.986297e-06\n-9.361969e-06\n-6.101971e-05\n\n\n-Alvin Davis\n5.783712e-06\n-1.988686e-08\n-6.958574e-09\n-1.532526e-06\n\n\n-Andre Dawson\n3.051739e-05\n5.108640e-06\n-1.863631e-05\n-4.502371e-05\n\n\n-Andres Galarraga\n-1.394196e-02\n5.825139e-05\n-1.224464e-04\n-1.059912e-04\n\n\n-Alfredo Griffin\n-3.880218e-03\n1.203274e-05\n4.598602e-05\n-3.844865e-04\n\n\n-Al Newman\n-1.699795e-02\n-1.973901e-05\n1.691955e-04\n2.508389e-04\n\n\n-Argenis Salazar\n-8.046090e-03\n-2.767402e-05\n9.120649e-05\n5.189035e-04\n\n\n-Andres Thomas\n-1.089006e-02\n-2.290534e-05\n1.092744e-04\n2.854954e-04\n\n\n-Andre Thornton\n1.934670e-04\n1.257660e-04\n-4.795294e-04\n4.627899e-04\n\n\n-Alan Trammell\n1.368784e-03\n-2.410167e-06\n-4.767847e-06\n-4.928569e-05\n\n\n-Alex Trevino\n1.506924e-02\n-5.429191e-05\n9.631131e-05\n-5.069911e-05\n\n\n-Andy VanSlyke\n1.018986e-03\n-2.296905e-06\n8.152666e-06\n2.113456e-05\n\n\n-Alan Wiggins\n1.700556e-02\n-2.150357e-05\n1.763226e-05\n-5.069653e-04\n\n\n-Bill Almon\n1.543927e-03\n-1.286964e-06\n-7.912781e-06\n1.368373e-05\n\n\n-Buddy Bell\n-1.705882e-03\n2.019092e-06\n1.123836e-05\n5.235392e-05\n\n\n-Buddy Biancalana\n-3.897104e-03\n8.342080e-06\n-6.374658e-06\n3.768041e-05\n\n\n-Bruce Bochy\n-1.330506e-02\n5.600915e-05\n-8.215845e-05\n-2.059641e-04\n\n\n-Barry Bonds\n2.279533e-03\n-1.600465e-04\n5.715951e-04\n-3.232635e-04\n\n\n-Bobby Bonilla\n6.803360e-04\n-7.258320e-05\n1.550213e-04\n6.909102e-04\n\n\n-Bob Brenly\n-1.918921e-03\n4.389361e-05\n-1.378344e-04\n6.196381e-05\n\n\n-Bill Buckner\n-3.908655e-03\n2.534192e-05\n-4.654425e-05\n-2.237198e-05\n\n\n-Brett Butler\n-5.102074e-03\n2.867516e-05\n7.199807e-06\n-4.680230e-04\n\n\n-Bob Dernier\n5.841442e-03\n9.566493e-05\n-3.306795e-04\n-4.014555e-04\n\n\n-Bo Diaz\n-9.247399e-04\n1.139785e-05\n4.045893e-06\n-1.642212e-04\n\n\n-Bill Doran\n-2.368204e-03\n1.411712e-05\n4.932303e-06\n-2.315089e-04\n\n\n-Brian Downing\n-2.439010e-03\n1.778817e-05\n-4.479265e-05\n1.943382e-04\n\n\n-Billy Hatcher\n-6.440503e-04\n-5.899958e-05\n1.344372e-04\n4.939621e-04\n\n\n-Brook Jacoby\n3.516924e-04\n1.218804e-06\n-9.821930e-06\n1.669940e-06\n\n\n-Bob Kearney\n4.747801e-03\n-1.011448e-05\n1.090719e-06\n1.826653e-05\n\n\n-Bill Madlock\n5.821589e-03\n-3.692670e-05\n1.178859e-04\n-4.368741e-05\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n-Tony Fernandez\n1.052602e-02\n8.419720e-05\n-5.233673e-04\n7.202039e-04\n\n\n-Tim Flannery\n-4.068231e-05\n1.805885e-07\n-8.305763e-07\n3.052943e-06\n\n\n-Tom Foley\n-9.240389e-05\n2.491327e-07\n-6.076509e-07\n2.794985e-06\n\n\n-Tony Gwynn\n1.174950e-03\n6.022291e-05\n-2.586965e-04\n1.095459e-04\n\n\n-Terry Harper\n6.264040e-03\n-1.582243e-05\n1.345592e-05\n3.096281e-05\n\n\n-Tommy Herr\n-1.253907e-02\n1.597799e-04\n-3.366306e-04\n-1.032398e-03\n\n\n-Tim Hulett\n7.975363e-03\n-1.386157e-04\n4.264418e-04\n-6.634915e-05\n\n\n-Terry Kennedy\n5.997923e-02\n-2.615496e-04\n4.547162e-04\n2.756732e-04\n\n\n-Tito Landrum\n5.790292e-03\n8.000686e-06\n-6.156594e-05\n-8.371297e-05\n\n\n-Tim Laudner\n-1.164993e-04\n3.626904e-07\n-2.408513e-07\n-2.255649e-06\n\n\n-Tom Paciorek\n-2.044713e-03\n1.065779e-05\n-2.549355e-05\n8.908786e-06\n\n\n-Tony Pena\n-1.740733e-03\n-2.408537e-05\n1.685463e-04\n-3.034906e-04\n\n\n-Terry Pendleton\n1.289931e-02\n-1.809589e-04\n4.345455e-04\n8.980146e-04\n\n\n-Tony Phillips\n-4.086001e-04\n1.800300e-05\n-3.984644e-05\n-1.400773e-04\n\n\n-Terry Puhl\n3.040861e-02\n-8.496636e-05\n9.801338e-05\n-9.885820e-05\n\n\n-Ted Simmons\n2.260963e-02\n-8.778308e-05\n1.393812e-04\n1.012275e-04\n\n\n-Tim Teufel\n1.132868e-03\n3.133402e-07\n-5.547655e-06\n-2.487321e-05\n\n\n-Tim Wallach\n-4.706632e-03\n1.041449e-04\n-3.412129e-04\n1.845919e-04\n\n\n-Vince Coleman\n1.460109e-02\n-2.070472e-04\n5.136607e-04\n9.377216e-04\n\n\n-Von Hayes\n-2.691757e-03\n-4.871620e-05\n2.214694e-04\n2.726047e-05\n\n\n-Vance Law\n1.466223e-03\n8.485382e-05\n-2.748316e-04\n-2.829650e-04\n\n\n-Wally Backman\n3.033118e-03\n-4.292845e-05\n1.662334e-04\n-2.134815e-04\n\n\n-Wade Boggs\n2.336669e-03\n-1.711974e-04\n6.758830e-04\n-3.477363e-04\n\n\n-Will Clark\n-7.253841e-03\n7.425048e-05\n-2.614339e-04\n6.024516e-05\n\n\n-Wally Joyner\n9.890247e-03\n6.359295e-05\n-3.334252e-04\n-4.567361e-04\n\n\n-Willie McGee\n-4.103649e-03\n6.596369e-05\n-1.473306e-04\n-3.608230e-04\n\n\n-Willie Randolph\n-2.369271e-03\n1.857962e-05\n3.563100e-05\n-5.223953e-04\n\n\n-Wayne Tolleson\n-2.531200e-04\n4.524374e-06\n-6.094079e-06\n-5.579062e-05\n\n\n-Willie Upshaw\n-1.162878e-02\n1.379530e-04\n-3.222032e-04\n-5.194818e-04\n\n\n-Willie Wilson\n-1.005121e-02\n6.995994e-05\n-9.304662e-05\n-4.851564e-04\n\n\n\n\n\n    $sigma\n        -Alan Ashby0.788087989207047-Alvin Davis0.788694226481284-Andre Dawson0.788661650873323-Andres Galarraga0.784684794952982-Alfredo Griffin0.788337114130146-Al Newman0.786262541299155-Argenis Salazar0.786802916611473-Andres Thomas0.784398464793053-Andre Thornton0.7850881428335-Alan Trammell0.788613981103893-Alex Trevino0.787230271479112-Andy VanSlyke0.788443711432741-Alan Wiggins0.785528352743374-Bill Almon0.788675988334844-Buddy Bell0.788548875937367-Buddy Biancalana0.788592315971829-Bruce Bochy0.788061155890424-Barry Bonds0.785378068169425-Bobby Bonilla0.786168555191178-Bob Brenly0.788232201709835-Bill Buckner0.788512427646438-Brett Butler0.788149915578498-Bob Dernier0.785813660772349-Bo Diaz0.787873065428321-Bill Doran0.788464477186018-Brian Downing0.787900316001232-Billy Hatcher0.7856791859616-Brook Jacoby0.788687839162256-Bob Kearney0.788527835166416-Bill Madlock0.787045649653056-Bob Melvin0.786484980327064-BillyJo Robidoux0.785740087144776-Bill Schroeder0.788596702820322-Chris Bando0.788610055889589-Chris Brown0.787125654887832-Carmen Castillo0.788679721825813-Chili Davis0.78811228983753-Carlton Fisk0.786089349695099-Curt Ford0.785317749724202-Carney Lansford0.78778198480267-Chet Lemon0.787566707678007-Candy Maldonado0.788678389348269-Carmelo Martinez0.788477865126042-Craig Reynolds0.788261244175587-Cal Ripken0.787863635256176-Cory Snyder0.781646564196697-Chris Speier0.788648618053139-Curt Wilkerson0.788684111170213-Dave Anderson0.788692872574602-Don Baylor0.787874897329411-Daryl Boston0.785236358622793-Darnell Coles0.782046884888717-Dave Concepcion0.78863268553584-Doug DeCinces0.788090534667608-Darrell Evans0.788671904266285-Dwight Evans0.787971280700316-Damaso Garcia0.787113204199-Dan Gladden0.788263659758164-Dave Henderson0.78862647579947-Donnie Hill0.788631269315016-Davey Lopes0.788158992681009-Don Mattingly0.788660291719989-Dale Murphy0.786078844438097-Dwayne Murphy0.787489141251169-Dave Parker0.788494124485019-Dan Pasqua0.78505429388851-Darrell Porter0.788693101647752-Dick Schofield0.788545491516604-Don Slaught0.788514203312617-Darryl Strawberry0.786807858453041-Dale Sveum0.784020227306241-Danny Tartabull0.784072466595428-Denny Walling0.788557073242349-Dave Winfield0.785184552147012-Eric Davis0.787925190716413-Eddie Milner0.78856906723733-Eddie Murray0.783899833933777-Ed Romero0.787764264758121-Frank White0.788565273918371-George Bell0.788680010666088-Glenn Braggs0.785303522751869-George Brett0.785626689374899-Greg Brock0.788564990901053-Gary Carter0.783947247342071-Glenn Davis0.785504133898955-Gary Gaetti0.788690454472167-Greg Gagne0.78675852038659-George Hendrick0.787283500279756-Glenn Hubbard0.787525873996843-Garth Iorg0.788525285594942-Gary Matthews0.787775386753804-Graig Nettles0.788339141078181-Gary Pettis0.788691757229353-Gary Redus0.788514562427462-Garry Templeton0.787032933366841-Greg Walker0.788261767785901-Gary Ward0.788375741945489-Glenn Wilson0.788592135020008-Harold Baines0.788499761629795-Hubie Brooks0.788078317104342-Howard Johnson0.78863904171628-Hal McRae0.78860563198926-Harold Reynolds0.78581978830625-Harry Spilman0.788529822154808-Herm Winningham0.786989228651752-Jesse Barfield0.788524019432133-Juan Beniquez0.788626689107663-John Cangelosi0.786082973427543-Jose Canseco0.78466538475743-Joe Carter0.783583328956248-Jack Clark0.781888793397349-Jose Cruz0.787913602863617-Jody Davis0.787233018430974-Jim Dwyer0.788610664564018-Julio Franco0.788655136326588-Jim Gantner0.787466856890579-Johnny Grubb0.788685819316832-Jack Howell0.786838108703902-John Kruk0.785844834141431-Jeffrey Leonard0.785209714654203-Jim Morrison0.78730398923047-John Moses0.784286439448128-Jerry Mumphrey0.78789542704568-Jim Presley0.78512023158689-Johnny Ray0.788673142619015-Jeff Reed0.786167187870066-Jim Rice0.786639414899379-Jerry Royster0.788692120188429-John Russell0.787635584676733-Juan Samuel0.788612862554493-John Shelby0.788694081135428-Joel Skinner0.787016999672412-Jim Sundberg0.785803777422643-Jose Uribe0.788454677863981-Joel Youngblood0.78759185955881-Kevin Bass0.788498434532896-Kal Daniels0.785309017100759-Kirk Gibson0.786610160831-Ken Griffey0.788248228927591-Keith Hernandez0.786279047403214-Kent Hrbek0.787346614303741-Ken Landreaux0.786148743042568-Kevin McReynolds0.788651014227156-Kevin Mitchell0.786045224892181-Keith Moreland0.787485053806796-Ken Oberkfell0.787826973031995-Ken Phelps0.788551952316283-Kirby Puckett0.783872240140299-Kurt Stillwell0.7858150616285-Leon Durham0.786610355579879-Len Dykstra0.787240122046691-Larry Herndon0.788610518123156-Lee Lacy0.788681477057886-Len Matuszek0.788691711033513-Lloyd Moseby0.788267571453955-Lance Parrish0.78727738986167-Larry Parrish0.788692526849978-Larry Sheets0.786319900331611-Lou Whitaker0.788437446953203-Mike Aldrete0.785653958052293-Marty Barrett0.78869060236359-Mike Davis0.788144626007235-Mike Diaz0.785494591022498-Mariano Duncan0.787670235764994-Mike Easler0.78858498201182-Mel Hall0.788691070813871-Mike Heath0.78641840420225-Mike Kingery0.784895250874634-Mike LaValliere0.786759899681058-Mike Marshall0.787367322394461-Mike Pagliarulo0.786242684868245-Mark Salas0.787818100074675-Mike Schmidt0.771516966354341-Mike Scioscia0.785772232406313-Mickey Tettleton0.787722898084898-Milt Thompson0.787614518459424-Mitch Webster0.786320351821897-Mookie Wilson0.787408039816236-Marvell Wynne0.788617570645859-Mike Young0.788666377633358-Ozzie Guillen0.787456625441716-Oddibe McDowell0.786275765146475-Ozzie Smith0.782478446295041-Ozzie Virgil0.786851189258332-Phil Bradley0.788613223218722-Phil Garner0.788345387520181-Pete Incaviglia0.785251799394364-Paul Molitor0.785615452318523-Pete Rose0.784449682022727-Pat Sheridan0.788567349137213-Pat Tabler0.788691562821052-Rafael Belliard0.787880816142943-Rick Burleson0.788226027049855-Randy Bush0.788677326352094-Rick Cerone0.788690776433792-Ron Cey0.785017275015262-Rob Deer0.787149192514477-Rick Dempsey0.788228157249776-Ron Hassey0.788502502037285-Rickey Henderson0.786492679287534-Reggie Jackson0.788491779433869-Ron Kittle0.788509683612867-Ray Knight0.788689546024379-Rick Leach0.788600745065715-Rick Manning0.788136514799188-Rance Mulliniks0.788440138683998-Ron Oester0.787699869276881-Rey Quinones0.785330598643259-Rafael Ramirez0.786430947960566-Ronn Reynolds0.788694050873503-Ron Roenicke0.788489466758294-Ryne Sandberg0.788642960122429-Rafael Santana0.788686776152599-Rick Schu0.78767529465952-Ruben Sierra0.784033196925155-Roy Smalley0.78783231649691-Robby Thompson0.785279183689162-Rob Wilfong0.78824466462335-Robin Yount0.788045263286404-Steve Balboni0.782942077266366-Scott Bradley0.785495385383538-Sid Bream0.786713951592677-Steve Buechele0.785895356612354-Shawon Dunston0.785628626425154-Scott Fletcher0.788684304146463-Steve Garvey0.785934312873395-Steve Jeltz0.788106821061602-Steve Lombardozzi0.785997102203074-Spike Owen0.78861285067638-Steve Sax0.775206275387361-Tony Bernazard0.788531731187791-Tom Brookens0.78856550988956-Tom Brunansky0.788008475661489-Tony Fernandez0.786627372789857-Tim Flannery0.788694218978449-Tom Foley0.788694195380288-Tony Gwynn0.788483659759081-Terry Harper0.78821331159661-Tommy Herr0.786478697056646-Tim Hulett0.787419866834543-Terry Kennedy0.781408804911603-Tito Landrum0.788361296031385-Tim Laudner0.788694216357093-Tom Paciorek0.788669010558951-Tony Pena0.786984130261975-Terry Pendleton0.787367431923881-Tony Phillips0.788547450382495-Terry Puhl0.783545249747788-Ted Simmons0.786783423090058-Tim Teufel0.788670940584408-Tim Wallach0.787487929036171-Vince Coleman0.787531460932664-Von Hayes0.788128574373877-Vance Law0.787381401320859-Wally Backman0.788474746198881-Wade Boggs0.788017299170636-Will Clark0.784833631339206-Wally Joyner0.783224300001469-Willie McGee0.787691098008247-Willie Randolph0.787278372318702-Wayne Tolleson0.788682284024342-Willie Upshaw0.786902984445929-Willie Wilson0.787639393843468\n\n    $wt.res\n        -Alan Ashby0.495297931132064-Alvin Davis-0.00543853956028187-Andre Dawson-0.114786848849309-Andres Galarraga-1.27229531063985-Alfredo Griffin0.376500219971959-Al Newman-0.986997038544126-Argenis Salazar-0.872011685580675-Andres Thomas-1.31655958876089-Andre Thornton1.20288647089233-Alan Trammell-0.179889013669906-Alex Trevino0.767040183099494-Andy VanSlyke0.318692333260666-Alan Wiggins1.12750852603613-Bill Almon0.0858028115614627-Buddy Bell0.24213414596455-Buddy Biancalana-0.202457390121689-Bruce Bochy-0.502300973698605-Barry Bonds-1.15232499810785-Bobby Bonilla-1.00741907658686-Bob Brenly0.431696722119547-Bill Buckner0.270144689736068-Brett Butler0.465121886329366-Bob Dernier1.07621794940745-Bo Diaz0.576286113193403-Bill Doran0.303435223205402-Brian Downing0.566083438554661-Billy Hatcher-1.10272955204631-Brook Jacoby-0.0509964324186427-Bob Kearney0.258845886332418-Bill Madlock0.816743698554709-Bob Melvin-0.943280569128019-BillyJo Robidoux-1.08812574734023-Bill Schroeder-0.198162260202405-Chris Bando0.184247170768769-Chris Brown-0.791926357419985-Carmen Castillo-0.076520019321227-Chili Davis0.484874205163271-Carlton Fisk1.01956500509913-Curt Ford-1.16454157784575-Carney Lansford0.605880918884638-Chet Lemon0.675486069950702-Candy Maldonado0.080158182728543-Carmelo Martinez0.295431177832217-Craig Reynolds0.418487879923019-Cal Ripken0.576751757234697-Cory Snyder-1.67771253764946-Chris Speier0.135138292021446-Curt Wilkerson0.0640179564537409-Dave Anderson0.0239608031254833-Don Baylor0.567051895161756-Daryl Boston-1.17784829349113-Darnell Coles-1.63497974751705-Dave Concepcion0.157749106577464-Doug DeCinces0.491576588246525-Darrell Evans0.094198452230805-Dwight Evans0.538069833035215-Damaso Garcia0.798792036697478-Dan Gladden-0.417043656520249-Dave Henderson-0.165724241440638-Donnie Hill-0.159512381291457-Davey Lopes0.464638898408859-Don Mattingly0.11220097338442-Dale Murphy1.02018138621454-Dwayne Murphy0.69831097433263-Dave Parker0.282051460542273-Dan Pasqua-1.20666029338326-Darrell Porter0.0218442236260971-Dick Schofield0.245223583138745-Don Slaught0.269809338287861-Darryl Strawberry0.867888978101088-Dale Sveum-1.3731294906825-Danny Tartabull-1.36064602790244-Denny Walling0.234834114695889-Dave Winfield1.1858080084532-Eric Davis-0.553561319997254-Eddie Milner0.225206411062808-Eddie Murray1.38584665743496-Ed Romero0.611330145173554-Frank White0.22795362953804-George Bell0.0749333382164492-Glenn Braggs-1.16741951227088-George Brett1.11230975245218-Greg Brock0.228211945679811-Gary Carter1.3785370379044-Glenn Davis-1.12488820474076-Gary Gaetti0.0389587510529879-Greg Gagne-0.883671415014483-George Hendrick0.753613498492403-Glenn Hubbard0.684333906230093-Garth Iorg0.261264686417221-Gary Matthews0.607676452682857-Graig Nettles-0.3775445392702-Gary Pettis0.0318736856719171-Gary Redus0.269719691207034-Garry Templeton0.812264750944759-Greg Walker0.417490899934653-Gary Ward0.35715267367006-Glenn Wilson0.202849728341657-Harold Baines0.279422827143254-Hubie Brooks0.494402098669122-Howard Johnson0.149118513263513-Hal McRae0.189325638832865-Harold Reynolds-1.06612201690011-Harry Spilman-0.256392787789728-Herm Winningham-0.82733714649685-Jesse Barfield0.256934056623595-Juan Beniquez0.1650552994761-John Cangelosi-1.02042756801519-Jose Canseco-1.2539225887893-Joe Carter-1.4196420952158-Jack Clark1.65249602766754-Jose Cruz0.5617695116793-Jody Davis0.765940435992398-Jim Dwyer0.183009814363443-Julio Franco0.124781398953848-Jim Gantner0.703096854658612-Johnny Grubb0.058009620489294-Jack Howell-0.861355915223531-John Kruk-1.06858519077484-Jeffrey Leonard-1.18582417695497-Jim Morrison-0.747938383666698-John Moses-1.33106708932092-Jerry Mumphrey0.566769738808514-Jim Presley-1.19367328735601-Johnny Ray0.0917534055033484-Jeff Reed-1.00614045295719-Jim Rice0.89813533469396-Jerry Royster-0.0296642100248916-John Russell-0.65377314201143-Juan Samuel0.181019658560744-John Shelby0.00937888697530022-Joel Skinner-0.822363835805777-Jim Sundberg1.07291795974715-Jose Uribe-0.308435009470071-Joel Youngblood0.665300948412535-Kevin Bass-0.279201727455344-Kal Daniels-1.16100578596754-Kirk Gibson0.910846136755323-Ken Griffey0.422644006978702-Keith Hernandez0.981404296809048-Kent Hrbek0.733106231900006-Ken Landreaux1.013233117435-Kevin McReynolds-0.13168074893095-Kevin Mitchell-1.03419617740358-Keith Moreland0.696970267256109-Ken Oberkfell0.590183918257675-Ken Phelps-0.238278110767064-Kirby Puckett-1.35951525760211-Kurt Stillwell-1.07498379497533-Leon Durham0.91671397527474-Len Dykstra-0.76562648945727-Larry Herndon-0.184045754021215-Lee Lacy0.0719691618070511-Len Matuszek0.0322454099378014-Lloyd Moseby0.413450878076408-Lance Parrish0.752605367472884-Larry Parrish0.0265959016015816-Larry Sheets-0.97724062248002-Lou Whitaker-0.321604031482053-Mike Aldrete-1.1052029976205-Marty Barrett0.0382193829021389-Mike Davis0.471304347125559-Mike Diaz-1.13155430682788-Mariano Duncan-0.641624213888835-Mike Easler0.209771608294576-Mel Hall0.0360716698727379-Mike Heath0.957777537445586-Mike Kingery-1.23497391828789-Mike LaValliere-0.882714891032766-Mike Marshall0.729508294750628-Mike Pagliarulo-0.985255175700308-Mark Salas-0.594515609271486-Mike Schmidt2.58861124879423-Mike Scioscia1.08567675933308-Mickey Tettleton-0.624284207184772-Milt Thompson-0.660623431696097-Mitch Webster-0.973817706371425-Mookie Wilson0.720969866122022-Marvell Wynne-0.176143684321503-Mike Young0.106344726946941-Ozzie Guillen-0.699732692751414-Oddibe McDowell-0.986547428059776-Ozzie Smith1.56902741497459-Ozzie Virgil0.860616801361628-Phil Bradley0.18010186908473-Phil Garner0.375770369109625-Pete Incaviglia-1.16736890038625-Paul Molitor1.11507910094352-Pete Rose1.30423694379153-Pat Sheridan-0.226276705627592-Pat Tabler0.032931772331738-Rafael Belliard-0.571670571974861-Rick Burleson0.434495984612881-Randy Bush-0.0829048675935128-Rick Cerone0.037666782549679-Ron Cey1.21487599177564-Rob Deer-0.776752363629396-Rick Dempsey0.432503050620572-Ron Hassey0.277148590255229-Rickey Henderson0.936653904475687-Reggie Jackson0.285682776968674-Ron Kittle0.27140018527723-Ray Knight-0.0437607252858133-Rick Leach-0.19374552988617-Rick Manning0.473591985068541-Rance Mulliniks0.320862346100393-Ron Oester0.63205053109618-Rey Quinones-1.1612071824936-Rafael Ramirez0.951563162601697-Ronn Reynolds-0.00997277788536639-Ron Roenicke-0.287659066189093-Ryne Sandberg0.143469410559807-Rafael Santana0.054739436545673-Rick Schu-0.639752203826063-Ruben Sierra-1.37128568405934-Roy Smalley0.588969901920232-Robby Thompson-1.16935774286535-Rob Wilfong0.425364489884647-Robin Yount0.508689021003016-Steve Balboni-1.50194677789557-Scott Bradley-1.13192581459033-Sid Bream-0.894261240233036-Steve Buechele-1.0609567729455-Shawon Dunston-1.10721059377824-Scott Fletcher-0.0630363308078193-Steve Garvey1.05227053225554-Steve Jeltz-0.481622738162541-Steve Lombardozzi-1.03819695469136-Spike Owen0.178734002234065-Steve Sax-2.26635137322017-Tony Bernazard-0.255431800411695-Tom Brookens0.227962979641856-Tom Brunansky0.524067383819616-Tony Fernandez-0.898774781417493-Tim Flannery-0.00570243569300807-Tom Foley-0.00647907478902504-Tony Gwynn-0.286233774284674-Terry Harper0.440750379047368-Tommy Herr0.93537253898349-Tim Hulett-0.712887845356798-Terry Kennedy1.68960717126566-Tito Landrum0.365792597371603-Tim Laudner-0.00578002022214194-Tom Paciorek-0.100802635353543-Tony Pena0.829952885309686-Terry Pendleton-0.719278147835191-Tony Phillips0.243291598575366-Terry Puhl1.43544207712413-Ted Simmons0.873191963164239-Tim Teufel0.0971313685052364-Tim Wallach0.695236162812252-Vince Coleman-0.668819368913094-Von Hayes0.475109192778092-Vance Law0.726500821547648-Wally Backman0.295505090214498-Wade Boggs0.505083990007538-Will Clark-1.2484874081587-Wally Joyner-1.47955927048621-Willie McGee0.63504531094061-Willie Randolph0.754270908480397-Wayne Tolleson0.0694490523617452-Willie Upshaw0.845199148995055-Willie Wilson0.648081520500237\n\n\n\n\n\ninfluence.measures(reg_model_2)\n\nInfluence measures of\n     lm(formula = log_Salary ~ AtBat + Hits + HmRun, data = hitters) :\n\n                      dfb.1_  dfb.AtBt  dfb.Hits  dfb.HmRn     dffit cov.r\n-Alan Ashby         3.22e-02 -2.36e-03 -2.31e-03 -9.13e-03  0.046453 1.015\n-Alvin Davis        3.86e-05 -1.57e-05 -1.71e-06 -2.29e-04 -0.000532 1.022\n-Andre Dawson       2.04e-04  4.03e-03 -4.59e-03 -6.73e-03 -0.013393 1.024\n-Andres Galarraga  -9.35e-02  4.62e-02 -3.03e-02 -1.59e-02 -0.120216 0.980\n-Alfredo Griffin   -2.59e-02  9.50e-03  1.13e-02 -5.75e-02  0.076818 1.037\n-Al Newman         -1.14e-01 -1.56e-02  4.18e-02  3.76e-02 -0.151315 1.005\n-Argenis Salazar   -5.38e-02 -2.19e-02  2.25e-02  7.77e-02 -0.117140 1.007\n-Andres Thomas     -7.30e-02 -1.82e-02  2.71e-02  4.29e-02 -0.128939 0.978\n-Andre Thornton     1.30e-03  9.97e-02 -1.19e-01  6.95e-02  0.168499 0.991\n-Alan Trammell      9.13e-03 -1.90e-03 -1.17e-03 -7.37e-03 -0.022981 1.025\n-Alex Trevino       1.01e-01 -4.29e-02  2.38e-02 -7.59e-03  0.106184 1.012\n-Andy VanSlyke      6.80e-03 -1.81e-03  2.01e-03  3.16e-03  0.025414 1.017\n-Alan Wiggins       1.14e-01 -1.70e-02  4.36e-03 -7.61e-02  0.154552 0.995\n-Bill Almon         1.03e-02 -1.02e-03 -1.95e-03  2.05e-03  0.012092 1.028\n-Buddy Bell        -1.14e-02  1.59e-03  2.77e-03  7.83e-03  0.029828 1.024\n-Buddy Biancalana  -2.60e-02  6.58e-03 -1.57e-03  5.63e-03 -0.028878 1.027\n-Bruce Bochy       -8.88e-02  4.42e-02 -2.03e-02 -3.08e-02 -0.092971 1.030\n-Barry Bonds        1.53e-02 -1.27e-01  1.41e-01 -4.85e-02 -0.176307 0.996\n-Bobby Bonilla      4.55e-03 -5.75e-02  3.83e-02  1.04e-01 -0.136291 1.001\n-Bob Brenly        -1.28e-02  3.47e-02 -3.40e-02  9.27e-03  0.051620 1.020\n-Bill Buckner      -2.61e-02  2.00e-02 -1.15e-02 -3.34e-03  0.040969 1.028\n-Brett Butler      -3.41e-02  2.26e-02  1.77e-03 -7.00e-02  0.091957 1.034\n-Bob Dernier        3.91e-02  7.58e-02 -8.17e-02 -6.02e-02  0.139750 0.996\n-Bo Diaz           -6.18e-03  9.00e-03  9.98e-04 -2.46e-02  0.055993 1.013\n-Bill Doran        -1.58e-02  1.11e-02  1.22e-03 -3.46e-02  0.048561 1.029\n-Brian Downing     -1.63e-02  1.40e-02 -1.10e-02  2.91e-02  0.063853 1.015\n-Billy Hatcher     -4.31e-03 -4.67e-02  3.32e-02  7.41e-02 -0.119083 0.992\n-Brook Jacoby       2.35e-03  9.62e-04 -2.42e-03  2.50e-04 -0.006809 1.027\n-Bob Kearney        3.17e-02 -7.98e-03  2.69e-04  2.73e-03  0.034619 1.025\n-Bill Madlock       3.89e-02 -2.92e-02  2.91e-02 -6.54e-03  0.071745 1.003\n-Bob Melvin        -6.87e-02 -3.23e-02  4.89e-02  2.30e-02 -0.114816 1.002\n-BillyJo Robidoux  -1.39e-01  1.92e-02  8.61e-03  3.91e-02 -0.162044 0.999\n-Bill Schroeder    -2.04e-02 -2.51e-03  8.72e-03 -3.14e-03 -0.026988 1.026\n-Chris Bando        1.88e-02 -7.08e-03  5.11e-03 -9.26e-03  0.023341 1.025\n-Chris Brown       -4.56e-02  9.28e-02 -1.07e-01  4.15e-02 -0.131922 1.016\n-Carmen Castillo   -1.07e-02  6.37e-03 -4.01e-03 -2.53e-03 -0.011220 1.029\n-Chili Davis       -1.51e-02  4.82e-03  6.22e-03 -1.38e-02  0.052004 1.017\n-Carlton Fisk      -4.68e-02  1.52e-01 -1.53e-01  3.84e-03  0.176295 1.007\n-Curt Ford         -1.35e-01  3.14e-02 -8.18e-03  4.26e-02 -0.157044 0.992\n-Carney Lansford   -3.22e-02 -3.99e-03  1.95e-02  8.29e-03  0.080463 1.017\n-Chet Lemon         8.58e-03  2.73e-02 -2.94e-02  2.34e-03  0.060812 1.009\n-Candy Maldonado    1.43e-03  2.07e-03 -3.17e-03  5.44e-03  0.008958 1.023\n-Carmelo Martinez   2.92e-02 -3.28e-03 -5.06e-03  8.39e-03  0.035805 1.023\n-Craig Reynolds     2.52e-02  5.00e-03 -8.66e-03 -1.21e-02  0.041397 1.017\n-Cal Ripken        -4.02e-02 -8.32e-04  1.31e-02  3.82e-02  0.092525 1.023\n-Cory Snyder       -5.69e-02  5.60e-02 -2.15e-02 -2.21e-01 -0.259816 0.959\n-Chris Speier       2.27e-02 -1.37e-02  8.69e-03  4.00e-03  0.023168 1.033\n-Curt Wilkerson     6.13e-03  2.46e-04 -1.07e-03 -4.26e-03  0.008837 1.027\n-Dave Anderson      2.70e-03 -4.95e-04  6.86e-05 -1.15e-03  0.003283 1.027\n-Don Baylor        -5.52e-02  8.00e-02 -8.42e-02  8.30e-02  0.140061 1.044\n-Daryl Boston      -1.60e-01  7.59e-02 -4.38e-02 -2.60e-03 -0.166329 0.992\n-Darnell Coles      4.52e-02 -1.65e-02  3.62e-03 -8.05e-02 -0.184747 0.956\n-Dave Concepcion    1.04e-02 -7.25e-04  3.56e-04 -9.50e-03  0.017502 1.023\n-Doug DeCinces     -1.71e-02  2.36e-02 -2.76e-02  5.75e-02  0.080608 1.026\n-Darrell Evans     -4.28e-03  8.38e-03 -1.00e-02  1.43e-02  0.019935 1.043\n-Dwight Evans      -2.23e-02  2.45e-02 -2.68e-02  5.97e-02  0.086661 1.024\n-Damaso Garcia      1.66e-02 -1.30e-02  2.61e-02 -5.40e-02  0.087782 1.007\n-Dan Gladden       -2.30e-02  1.02e-02 -1.24e-02  2.63e-02 -0.045601 1.019\n-Dave Henderson    -5.96e-03  1.49e-03  8.68e-05 -6.98e-03 -0.014840 1.020\n-Donnie Hill       -1.06e-02  6.84e-03 -7.43e-03  9.34e-03 -0.018272 1.023\n-Davey Lopes        5.08e-02 -2.76e-02  1.86e-02  1.82e-03  0.055380 1.019\n-Don Mattingly      6.03e-04 -3.58e-02  4.01e-02  1.46e-02  0.047017 1.116\n-Dale Murphy       -8.26e-02  5.28e-02 -4.50e-02  1.16e-01  0.190083 1.010\n-Dwayne Murphy      3.86e-02  5.09e-03 -1.28e-02 -1.44e-03  0.062959 1.008\n-Dave Parker       -2.32e-02  7.24e-03 -4.43e-03  3.62e-02  0.055955 1.038\n-Dan Pasqua        -1.39e-01  1.24e-01 -8.81e-02 -1.14e-01 -0.189970 0.993\n-Darrell Porter     3.66e-03 -2.08e-03  1.00e-03  2.08e-03  0.004123 1.038\n-Dick Schofield    -5.11e-03  1.72e-02 -1.59e-02 -1.42e-03  0.026066 1.021\n-Don Slaught        2.04e-02 -8.60e-03  3.17e-03  1.27e-02  0.028100 1.021\n-Darryl Strawberry -7.83e-03  1.72e-02 -3.16e-02  1.23e-01  0.149374 1.014\n-Dale Sveum        -7.82e-02 -2.49e-02  3.90e-02  2.71e-02 -0.134583 0.974\n-Danny Tartabull    2.76e-02 -5.45e-03  1.09e-02 -1.46e-01 -0.199116 0.982\n-Denny Walling      1.73e-02 -2.76e-02  2.74e-02  5.91e-03  0.033631 1.027\n-Dave Winfield     -7.23e-02  6.53e-02 -5.71e-02  9.04e-02  0.176875 0.993\n-Eric Davis        -2.32e-02  3.01e-02 -1.59e-02 -9.16e-02 -0.102739 1.029\n-Eddie Milner       2.34e-03  4.75e-03 -5.54e-03  6.48e-03  0.019830 1.019\n-Eddie Murray       2.38e-02 -1.31e-01  1.50e-01  3.90e-02  0.201707 0.980\n-Ed Romero          5.30e-02  2.29e-02 -3.47e-02 -2.73e-02  0.086099 1.018\n-Frank White       -1.17e-02  5.32e-03 -2.41e-03  1.24e-02  0.029675 1.025\n-George Bell       -2.82e-03 -8.96e-03  1.04e-02  9.84e-03  0.018250 1.052\n-Glenn Braggs      -1.32e-01  1.93e-02  9.04e-03  1.79e-02 -0.151972 0.991\n-George Brett       3.25e-02 -6.52e-02  6.79e-02  3.94e-02  0.119507 0.991\n-Greg Brock         1.19e-02  6.44e-03 -1.26e-02  1.70e-02  0.029601 1.025\n-Gary Carter       -3.36e-02  6.16e-02 -7.35e-02  1.43e-01  0.205920 0.981\n-Glenn Davis        6.42e-02 -3.82e-02  4.28e-02 -1.70e-01 -0.224204 1.007\n-Gary Gaetti       -1.56e-03 -1.85e-03  1.81e-03  6.96e-03  0.008830 1.047\n-Greg Gagne         2.58e-02 -6.73e-02  5.87e-02  1.92e-02 -0.098456 1.003\n-George Hendrick    7.46e-02 -4.55e-02  2.49e-02  5.27e-02  0.096385 1.011\n-Glenn Hubbard     -9.79e-03  7.68e-02 -6.98e-02 -5.95e-02  0.105819 1.018\n-Garth Iorg         1.47e-02  8.55e-04 -6.87e-04 -1.73e-02  0.028927 1.022\n-Gary Matthews      2.88e-02 -9.08e-03 -6.21e-03  6.93e-02  0.085459 1.018\n-Graig Nettles     -8.25e-03 -3.09e-02  3.99e-02 -2.40e-02 -0.056618 1.026\n-Gary Pettis       -2.15e-03  3.13e-03 -1.94e-03 -3.91e-03  0.005536 1.034\n-Gary Redus         1.27e-02  5.23e-03 -8.83e-03  4.14e-03  0.025109 1.019\n-Garry Templeton   -5.28e-02  1.03e-01 -7.44e-02 -1.19e-01  0.160741 1.022\n-Greg Walker        4.22e-02 -2.78e-02  1.73e-02  2.48e-02  0.052231 1.021\n-Gary Ward          2.54e-02 -3.99e-02  4.49e-02 -2.19e-02  0.058005 1.029\n-Glenn Wilson      -1.41e-02  1.01e-02 -4.25e-03 -5.75e-03  0.026334 1.025\n-Harold Baines     -7.27e-03 -1.69e-02  2.25e-02  1.23e-02  0.042035 1.028\n-Hubie Brooks       6.44e-02 -9.14e-02  8.34e-02  3.22e-02  0.100778 1.035\n-Howard Johnson     1.77e-02 -5.61e-03  5.40e-04  7.21e-03  0.020201 1.026\n-Hal McRae          1.58e-02 -2.28e-03 -9.24e-04 -9.89e-04  0.019648 1.021\n-Harold Reynolds    5.20e-02 -1.77e-01  1.54e-01  1.45e-01 -0.227396 1.013\n-Harry Spilman     -4.36e-02  2.37e-02 -1.40e-02 -5.84e-03 -0.044190 1.032\n-Herm Winningham   -1.02e-01  7.79e-03  1.80e-02  4.02e-03 -0.119059 1.011\n-Jesse Barfield    -7.48e-03 -1.80e-02  1.44e-02  6.49e-02  0.074362 1.064\n-Juan Beniquez      1.29e-02 -1.37e-02  1.41e-02 -6.20e-03  0.020968 1.025\n-John Cangelosi     3.20e-02 -1.25e-01  1.04e-01  1.23e-01 -0.180186 1.008\n-Jose Canseco       1.29e-01 -1.72e-01  1.82e-01 -2.06e-01 -0.326554 1.014\n-Joe Carter         8.56e-02  1.16e-01 -1.52e-01 -1.42e-01 -0.311377 0.992\n-Jack Clark         1.77e-01 -2.84e-02 -2.24e-02  5.46e-02  0.210870 0.957\n-Jose Cruz         -4.56e-03  5.17e-04  1.03e-02 -2.48e-02  0.056579 1.014\n-Jody Davis        -4.21e-02  6.53e-02 -6.28e-02  4.28e-02  0.110534 1.013\n-Jim Dwyer          2.81e-02 -1.16e-02  3.96e-03  8.92e-03  0.029766 1.031\n-Julio Franco      -4.98e-03 -8.23e-03  1.44e-02 -1.08e-02  0.024587 1.039\n-Jim Gantner       -1.74e-02  1.79e-02  1.61e-03 -5.88e-02  0.088350 1.013\n-Johnny Grubb       9.70e-03 -9.70e-03  7.62e-03  5.12e-03  0.011911 1.041\n-Jack Howell       -1.42e-01  7.44e-02 -4.47e-02 -7.68e-03 -0.143773 1.014\n-John Kruk         -1.22e-01  1.14e-01 -1.08e-01  3.84e-02 -0.160368 1.000\n-Jeffrey Leonard   -7.59e-02  4.37e-02 -4.34e-02  4.49e-02 -0.119820 0.986\n-Jim Morrison       2.43e-02 -4.00e-03 -1.17e-04 -5.68e-02 -0.098066 1.012\n-John Moses        -1.50e-02 -6.03e-02  4.18e-02  1.24e-01 -0.167527 0.980\n-Jerry Mumphrey     5.49e-02 -5.36e-02  5.25e-02 -2.05e-02  0.077875 1.019\n-Jim Presley        1.01e-01 -7.18e-02  5.79e-02 -1.09e-01 -0.208752 0.997\n-Johnny Ray        -3.55e-03 -4.05e-03  8.60e-03 -1.03e-02  0.017739 1.038\n-Jeff Reed         -1.44e-01  4.06e-02 -1.06e-02  1.90e-02 -0.154169 1.004\n-Jim Rice          -1.56e-02 -1.42e-01  1.76e-01  1.67e-02  0.218494 1.030\n-Jerry Royster     -2.88e-03  7.71e-04 -2.76e-04  5.67e-04 -0.003362 1.024\n-John Russell      -3.94e-02 -9.09e-03  2.37e-02 -3.00e-02 -0.071551 1.012\n-Juan Samuel       -1.42e-02  1.24e-02 -7.43e-03 -3.70e-03  0.024606 1.026\n-John Shelby       -7.14e-05  9.49e-04 -9.87e-04 -8.43e-05  0.001236 1.026\n-Joel Skinner      -3.87e-02 -4.07e-02  4.76e-02  3.40e-02 -0.095446 1.007\n-Jim Sundberg      -3.97e-02  1.70e-01 -1.74e-01 -8.92e-03  0.195072 1.006\n-Jose Uribe         1.59e-02 -5.09e-02  4.49e-02  3.58e-02 -0.062522 1.038\n-Joel Youngblood    9.32e-02 -3.83e-02  1.78e-02  4.92e-03  0.096620 1.017\n-Kevin Bass         5.52e-03  3.08e-02 -3.90e-02 -7.53e-03 -0.053599 1.036\n-Kal Daniels       -1.96e-01  1.58e-01 -1.24e-01 -2.46e-02 -0.210543 1.001\n-Kirk Gibson        1.80e-02 -1.96e-02 -2.16e-03  1.52e-01  0.169506 1.015\n-Ken Griffey        1.03e-02 -4.51e-02  4.74e-02  3.11e-02  0.068343 1.027\n-Keith Hernandez   -7.84e-03 -9.44e-02  1.28e-01 -3.50e-02  0.173514 1.010\n-Kent Hrbek        -3.07e-02  1.44e-02 -1.77e-02  1.01e-01  0.131723 1.021\n-Ken Landreaux      8.49e-02 -2.08e-02  1.12e-02 -3.98e-02  0.111615 0.997\n-Kevin McReynolds   3.53e-03  5.46e-03 -6.38e-03 -1.34e-02 -0.021208 1.031\n-Kevin Mitchell    -7.82e-02  5.29e-02 -3.82e-02 -3.31e-02 -0.104551 0.995\n-Keith Moreland    -5.04e-02  3.79e-02 -1.32e-02 -4.31e-02  0.098780 1.016\n-Ken Oberkfell     -1.96e-02  2.49e-02 -5.85e-03 -6.38e-02  0.085324 1.020\n-Ken Phelps        -1.36e-02  1.41e-03  7.52e-03 -3.74e-02 -0.043416 1.035\n-Kirby Puckett      4.15e-02  2.77e-01 -3.20e-01 -1.66e-01 -0.431602 1.024\n-Kurt Stillwell    -6.94e-02 -4.57e-02  5.18e-02  8.92e-02 -0.151611 0.998\n-Leon Durham       -1.56e-02  2.55e-02 -2.64e-02  5.65e-02  0.103762 1.002\n-Len Dykstra       -2.38e-02  4.30e-02 -5.53e-02  3.65e-02 -0.090853 1.009\n-Larry Herndon     -1.45e-02  7.11e-04  2.65e-03 -6.66e-04 -0.018937 1.021\n-Lee Lacy          -3.05e-04 -1.91e-03  3.43e-03 -2.66e-03  0.007921 1.023\n-Len Matuszek       4.42e-03 -2.14e-03  1.01e-03  1.47e-03  0.004722 1.029\n-Lloyd Moseby      -3.65e-02  4.33e-02 -3.69e-02  1.40e-02  0.066128 1.027\n-Lance Parrish      5.42e-02 -2.31e-02 -3.84e-03  1.06e-01  0.126178 1.018\n-Larry Parrish      3.86e-04 -9.79e-04  5.01e-04  4.21e-03  0.004809 1.036\n-Larry Sheets      -7.05e-02  4.84e-02 -2.48e-02 -9.15e-02 -0.126844 1.002\n-Lou Whitaker       2.15e-02 -1.47e-02  8.50e-03 -8.32e-03 -0.041981 1.024\n-Mike Aldrete      -1.28e-01  3.22e-02 -1.07e-02  4.11e-02 -0.148469 0.996\n-Marty Barrett     -3.19e-03  1.02e-03  1.36e-03 -6.29e-03  0.008528 1.046\n-Mike Davis        -7.19e-03  7.11e-03 -5.83e-03  2.32e-02  0.049188 1.017\n-Mike Diaz         -1.56e-01  8.78e-02 -4.42e-02 -8.52e-02 -0.177330 0.998\n-Mariano Duncan     7.45e-03 -6.91e-02  6.76e-02  2.74e-02 -0.088537 1.017\n-Mike Easler        2.90e-03 -1.65e-02  2.03e-02 -6.61e-04  0.027973 1.026\n-Mel Hall           1.30e-03 -2.87e-03  2.86e-03  2.06e-03  0.004565 1.026\n-Mike Heath         6.08e-02  3.62e-02 -5.48e-02  9.36e-04  0.110857 1.001\n-Mike Kingery      -1.54e-01  5.65e-02 -2.93e-02  2.90e-02 -0.168032 0.988\n-Mike LaValliere   -4.82e-02 -3.67e-02  4.25e-02  5.17e-02 -0.107468 1.005\n-Mike Marshall      3.75e-02  1.90e-02 -4.23e-02  7.73e-02  0.109998 1.016\n-Mike Pagliarulo    4.65e-02 -9.63e-02  1.13e-01 -1.40e-01 -0.205529 1.017\n-Mark Salas        -5.14e-02 -4.32e-03  1.87e-02 -7.28e-03 -0.069072 1.015\n-Mike Schmidt       6.04e-01 -2.61e-01  1.16e-01  3.29e-02  0.608455 0.879\n-Mike Scioscia      2.65e-02  4.29e-02 -3.77e-02 -6.73e-02  0.116250 0.993\n-Mickey Tettleton  -6.64e-02 -8.00e-03  3.22e-02 -3.16e-02 -0.093520 1.019\n-Milt Thompson     -4.60e-02 -1.29e-03  8.69e-03  1.57e-02 -0.066305 1.011\n-Mitch Webster      4.75e-02  7.95e-03 -5.16e-02  9.84e-02 -0.163968 1.008\n-Mookie Wilson      3.80e-02 -3.93e-02  4.17e-02 -1.38e-02  0.072513 1.009\n-Marvell Wynne     -1.49e-02  5.10e-03 -2.65e-03  1.48e-03 -0.017899 1.021\n-Mike Young         3.33e-03  2.86e-03 -3.24e-03 -1.76e-03  0.009330 1.020\n-Ozzie Guillen      5.89e-02 -9.46e-02  6.41e-02  1.12e-01 -0.150538 1.031\n-Oddibe McDowell    6.48e-02 -5.60e-02  3.60e-02 -8.13e-03 -0.124412 1.001\n-Ozzie Smith       -5.37e-02  4.02e-02  3.25e-02 -2.65e-01  0.310911 0.976\n-Ozzie Virgil       1.85e-02  6.50e-02 -8.25e-02  4.39e-02  0.118163 1.008\n-Phil Bradley       4.81e-04 -1.71e-02  2.26e-02 -6.75e-03  0.030182 1.032\n-Phil Garner        2.74e-02 -9.59e-03  4.81e-03  1.61e-03  0.035079 1.017\n-Pete Incaviglia    6.42e-02 -8.56e-02  9.92e-02 -1.77e-01 -0.241899 1.006\n-Paul Molitor       1.92e-02 -2.32e-02  3.82e-02 -4.43e-02  0.107865 0.990\n-Pete Rose          1.14e-01  4.07e-02 -5.91e-02 -8.86e-02  0.189130 0.985\n-Pat Sheridan      -2.28e-02  1.98e-03  3.47e-03  2.85e-04 -0.027297 1.023\n-Pat Tabler         1.26e-03 -4.50e-03  5.61e-03 -2.76e-03  0.006952 1.043\n-Rafael Belliard   -2.71e-02 -3.09e-02  3.09e-02  5.36e-02 -0.081600 1.020\n-Rick Burleson      4.52e-02 -2.87e-02  2.37e-02 -1.01e-02  0.052975 1.020\n-Randy Bush        -4.05e-03  1.01e-03 -1.00e-03  2.74e-03 -0.007438 1.020\n-Rick Cerone        4.58e-03 -1.72e-03  8.78e-04 -5.67e-04  0.004939 1.026\n-Ron Cey            1.39e-01 -8.55e-02  4.82e-02  8.40e-02  0.167109 0.990\n-Rob Deer           1.94e-02 -6.61e-02  9.31e-02 -1.66e-01 -0.204332 1.041\n-Rick Dempsey       1.33e-02  3.85e-02 -4.89e-02  1.75e-02  0.065001 1.025\n-Ron Hassey         2.71e-02 -3.82e-02  3.80e-02 -9.06e-04  0.044913 1.030\n-Rickey Henderson  -7.61e-02  5.65e-02 -4.91e-02  9.83e-02  0.169443 1.013\n-Reggie Jackson     9.62e-05  1.74e-02 -2.10e-02  1.78e-02  0.035902 1.023\n-Ron Kittle         3.29e-03  2.33e-02 -3.13e-02  3.00e-02  0.049032 1.034\n-Ray Knight        -4.14e-04  2.71e-03 -3.68e-03  1.51e-03 -0.005632 1.026\n-Rick Leach        -2.53e-02  2.17e-02 -1.88e-02  2.61e-03 -0.029509 1.029\n-Rick Manning       6.13e-02 -2.46e-02  9.16e-03  1.53e-02  0.065449 1.022\n-Rance Mulliniks    1.61e-02 -5.13e-04 -2.86e-03  4.16e-03  0.027430 1.018\n-Ron Oester        -3.47e-02  5.27e-02 -3.48e-02 -5.28e-02  0.089931 1.018\n-Rey Quinones      -4.39e-02 -9.47e-02  1.00e-01  8.58e-02 -0.169986 0.994\n-Rafael Ramirez    -5.50e-02  1.23e-01 -1.03e-01 -7.16e-02  0.153327 1.008\n-Ronn Reynolds     -1.62e-03  4.75e-04 -7.79e-05 -6.08e-05 -0.001698 1.034\n-Ron Roenicke      -2.33e-02  4.36e-04  3.63e-03  7.47e-03 -0.031217 1.021\n-Ryne Sandberg     -1.11e-02  2.22e-03  3.85e-03 -7.74e-03  0.022466 1.030\n-Rafael Santana    -9.78e-04  7.70e-03 -7.05e-03 -6.34e-03  0.010362 1.038\n-Rick Schu         -8.73e-02  4.94e-02 -2.98e-02 -2.04e-02 -0.091678 1.018\n-Ruben Sierra      -5.44e-02  1.51e-02  2.43e-03 -7.59e-02 -0.133435 0.974\n-Roy Smalley       -1.05e-02  3.77e-02 -4.26e-02  4.11e-02  0.077840 1.018\n-Robby Thompson     6.59e-02 -6.03e-02  1.61e-02  1.21e-01 -0.178764 0.995\n-Rob Wilfong        2.34e-02  2.59e-02 -3.04e-02 -2.28e-02  0.057036 1.022\n-Robin Yount        2.27e-03 -4.95e-02  6.78e-02 -3.51e-02  0.092987 1.029\n-Steve Balboni      9.36e-02 -2.00e-01  2.28e-01 -2.28e-01 -0.359398 0.990\n-Scott Bradley     -1.58e-01  1.17e-01 -9.31e-02  5.05e-03 -0.171774 0.997\n-Sid Bream          3.24e-02 -2.95e-02  1.63e-02 -4.27e-03 -0.092135 1.002\n-Steve Buechele     2.54e-02 -8.36e-02  8.86e-02 -5.01e-02 -0.136695 0.997\n-Shawon Dunston     1.01e-01 -1.35e-01  1.12e-01  8.00e-03 -0.178151 1.000\n-Scott Fletcher     1.15e-03  2.69e-03 -5.66e-03  8.76e-03 -0.012451 1.040\n-Steve Garvey      -7.05e-02  8.68e-02 -7.66e-02  4.81e-02  0.151404 1.000\n-Steve Jeltz        2.37e-02 -8.42e-02  7.36e-02  6.98e-02 -0.108023 1.040\n-Steve Lombardozzi  4.43e-02 -1.46e-01  1.35e-01  6.25e-02 -0.171813 1.005\n-Spike Owen        -1.71e-02  3.48e-02 -2.79e-02 -2.99e-02  0.044732 1.053\n-Steve Sax          6.20e-02  3.77e-01 -5.42e-01  3.35e-01 -0.734384 0.937\n-Tony Bernazard     5.29e-03  1.75e-02 -2.44e-02 -9.23e-04 -0.038471 1.028\n-Tom Brookens       2.03e-02 -7.98e-03  6.36e-03 -1.12e-02  0.026764 1.023\n-Tom Brunansky     -4.45e-02  4.71e-02 -4.03e-02  2.86e-02  0.084252 1.024\n-Tony Fernandez     7.04e-02  6.66e-02 -1.29e-01  1.08e-01 -0.232886 1.034\n-Tim Flannery      -2.71e-04  1.42e-04 -2.05e-04  4.56e-04 -0.000684 1.025\n-Tom Foley         -6.16e-04  1.97e-04 -1.50e-04  4.18e-04 -0.000837 1.026\n-Tony Gwynn         7.84e-03  4.75e-02 -6.37e-02  1.64e-02 -0.079776 1.060\n-Terry Harper       4.18e-02 -1.25e-02  3.32e-03  4.63e-03  0.048072 1.018\n-Tommy Herr        -8.39e-02  1.26e-01 -8.31e-02 -1.55e-01  0.205925 1.022\n-Tim Hulett         5.33e-02 -1.10e-01  1.05e-01 -9.93e-03 -0.128391 1.022\n-Terry Kennedy      4.04e-01 -2.08e-01  1.13e-01  4.16e-02  0.404173 0.975\n-Tito Landrum       3.86e-02  6.32e-03 -1.52e-02 -1.25e-02  0.052448 1.025\n-Tim Laudner       -7.77e-04  2.86e-04 -5.93e-05 -3.37e-04 -0.000870 1.030\n-Tom Paciorek      -1.36e-02  8.41e-03 -6.28e-03  1.33e-03 -0.014574 1.028\n-Tony Pena         -1.16e-02 -1.90e-02  4.16e-02 -4.55e-02  0.102164 1.007\n-Terry Pendleton    8.62e-02 -1.43e-01  1.07e-01  1.34e-01 -0.193138 1.045\n-Tony Phillips     -2.73e-03  1.42e-02 -9.82e-03 -2.09e-02  0.030323 1.024\n-Terry Puhl         2.04e-01 -6.75e-02  2.43e-02 -1.49e-02  0.215607 0.977\n-Ted Simmons        1.51e-01 -6.94e-02  3.44e-02  1.52e-02  0.153167 1.015\n-Tim Teufel         7.56e-03  2.47e-04 -1.37e-03 -3.72e-03  0.010776 1.023\n-Tim Wallach       -3.14e-02  8.23e-02 -8.42e-02  2.76e-02  0.108729 1.018\n-Vince Coleman      9.75e-02 -1.64e-01  1.27e-01  1.40e-01 -0.208761 1.061\n-Von Hayes         -1.80e-02 -3.85e-02  5.46e-02  4.08e-03  0.085175 1.030\n-Vance Law          9.80e-03  6.71e-02 -6.78e-02 -4.24e-02  0.099409 1.014\n-Wally Backman      2.02e-02 -3.39e-02  4.10e-02 -3.19e-02  0.057586 1.037\n-Wade Boggs         1.56e-02 -1.35e-01  1.67e-01 -5.20e-02  0.187803 1.089\n-Will Clark        -4.86e-02  5.89e-02 -6.47e-02  9.05e-03 -0.118454 0.982\n-Wally Joyner       6.64e-02  5.05e-02 -8.27e-02 -6.87e-02 -0.219968 0.973\n-Willie McGee      -2.74e-02  5.21e-02 -3.63e-02 -5.40e-02  0.087794 1.017\n-Willie Randolph   -1.58e-02  1.47e-02  8.79e-03 -7.82e-02  0.105311 1.013\n-Wayne Tolleson    -1.69e-03  3.57e-03 -1.50e-03 -8.34e-03  0.010428 1.030\n-Willie Upshaw     -7.78e-02  1.09e-01 -7.95e-02 -7.78e-02  0.150806 1.017\n-Willie Wilson     -6.71e-02  5.53e-02 -2.29e-02 -7.26e-02  0.121829 1.026\n                     cook.d     hat inf\n-Alan Ashby        5.41e-04 0.00540    \n-Alvin Davis       7.11e-08 0.00589    \n-Andre Dawson      4.50e-05 0.00833    \n-Andres Galarraga  3.59e-03 0.00544    \n-Alfredo Griffin   1.48e-03 0.02461    \n-Al Newman         5.71e-03 0.01412    \n-Argenis Salazar   3.43e-03 0.01093    \n-Andres Thomas     4.13e-03 0.00583    \n-Andre Thornton    7.06e-03 0.01181    \n-Alan Trammell     1.33e-04 0.00995    \n-Alex Trevino      2.82e-03 0.01160    \n-Andy VanSlyke     1.62e-04 0.00392    \n-Alan Wiggins      5.95e-03 0.01133    \n-Bill Almon        3.67e-05 0.01206    \n-Buddy Bell        2.23e-04 0.00926    \n-Buddy Biancalana  2.09e-04 0.01234    \n-Bruce Bochy       2.17e-03 0.02042    \n-Barry Bonds       7.74e-03 0.01404    \n-Bobby Bonilla     4.63e-03 0.01106    \n-Bob Brenly        6.68e-04 0.00873    \n-Bill Buckner      4.21e-04 0.01390    \n-Brett Butler      2.12e-03 0.02317    \n-Bob Dernier       4.87e-03 0.01020    \n-Bo Diaz           7.85e-04 0.00579    \n-Bill Doran        5.91e-04 0.01543    \n-Brian Downing     1.02e-03 0.00778    \n-Billy Hatcher     3.53e-03 0.00710    \n-Brook Jacoby      1.16e-05 0.01085    \n-Bob Kearney       3.01e-04 0.01088    \n-Bill Madlock      1.29e-03 0.00473    \n-Bob Melvin        3.29e-03 0.00900    \n-BillyJo Robidoux  6.54e-03 0.01333    \n-Bill Schroeder    1.83e-04 0.01128    \n-Chris Bando       1.37e-04 0.00979    \n-Chris Brown       4.35e-03 0.01663    \n-Carmen Castillo   3.16e-05 0.01303    \n-Chili Davis       6.78e-04 0.00704    \n-Carlton Fisk      7.75e-03 0.01782    \n-Curt Ford         6.14e-03 0.01097    \n-Carney Lansford   1.62e-03 0.01071    \n-Chet Lemon        9.25e-04 0.00498    \n-Candy Maldonado   2.01e-05 0.00765    \n-Carmelo Martinez  3.22e-04 0.00897    \n-Craig Reynolds    4.30e-04 0.00601    \n-Cal Ripken        2.14e-03 0.01548    \n-Cory Snyder       1.66e-02 0.01424    \n-Chris Speier      1.35e-04 0.01764    \n-Curt Wilkerson    1.96e-05 0.01158    \n-Dave Anderson     2.70e-06 0.01141    \n-Don Baylor        4.91e-03 0.03525    \n-Daryl Boston      6.88e-03 0.01200    \n-Darnell Coles     8.42e-03 0.00769    \n-Dave Concepcion   7.69e-05 0.00754    \n-Doug DeCinces     1.63e-03 0.01616    \n-Darrell Evans     9.97e-05 0.02641    \n-Dwight Evans      1.88e-03 0.01561    \n-Damaso Garcia     1.93e-03 0.00737    \n-Dan Gladden       5.21e-04 0.00732    \n-Dave Henderson    5.53e-05 0.00494    \n-Donnie Hill       8.38e-05 0.00803    \n-Davey Lopes       7.69e-04 0.00867    \n-Don Mattingly     5.55e-04 0.09037   *\n-Dale Murphy       9.01e-03 0.02058    \n-Dwayne Murphy     9.92e-04 0.00499    \n-Dave Parker       7.85e-04 0.02334    \n-Dan Pasqua        8.97e-03 0.01483    \n-Darrell Porter    4.27e-06 0.02123    \n-Dick Schofield    1.70e-04 0.00693    \n-Don Slaught       1.98e-04 0.00665    \n-Darryl Strawberry 5.57e-03 0.01769    \n-Dale Sveum        4.49e-03 0.00584    \n-Danny Tartabull   9.83e-03 0.01283    \n-Denny Walling     2.84e-04 0.01244    \n-Dave Winfield     7.78e-03 0.01335    \n-Eric Davis        2.64e-03 0.02052    \n-Eddie Milner      9.87e-05 0.00478    \n-Eddie Murray      1.01e-02 0.01269    \n-Ed Romero         1.86e-03 0.01202    \n-Frank White       2.21e-04 0.01032    \n-George Bell       8.36e-05 0.03440   *\n-Glenn Braggs      5.75e-03 0.01024    \n-George Brett      3.56e-03 0.00702    \n-Greg Brock        2.20e-04 0.01025    \n-Gary Carter       1.05e-02 0.01335    \n-Glenn Davis       1.25e-02 0.02338    \n-Gary Gaetti       1.96e-05 0.03006   *\n-Greg Gagne        2.42e-03 0.00757    \n-George Hendrick   2.32e-03 0.00994    \n-Glenn Hubbard     2.80e-03 0.01441    \n-Garth Iorg        2.10e-04 0.00751    \n-Gary Matthews     1.83e-03 0.01198    \n-Graig Nettles     8.04e-04 0.01360    \n-Gary Pettis       7.69e-06 0.01809    \n-Gary Redus        1.58e-04 0.00533    \n-Garry Templeton   6.46e-03 0.02315    \n-Greg Walker       6.84e-04 0.00954    \n-Gary Ward         8.44e-04 0.01588    \n-Glenn Wilson      1.74e-04 0.01027    \n-Harold Baines     4.43e-04 0.01369    \n-Hubie Brooks      2.54e-03 0.02455    \n-Howard Johnson    1.02e-04 0.01116    \n-Hal McRae         9.69e-05 0.00661    \n-Harold Reynolds   1.29e-02 0.02662    \n-Harry Spilman     4.90e-04 0.01782    \n-Herm Winningham   3.54e-03 0.01251    \n-Jesse Barfield    1.39e-03 0.04727   *\n-Juan Beniquez     1.10e-04 0.00984    \n-John Cangelosi    8.09e-03 0.01856    \n-Jose Canseco      2.65e-02 0.03860    \n-Joe Carter        2.40e-02 0.02791    \n-Jack Clark        1.10e-02 0.00976    \n-Jose Cruz         8.02e-04 0.00622    \n-Jody Davis        3.05e-03 0.01258    \n-Jim Dwyer         2.22e-04 0.01593    \n-Julio Franco      1.52e-04 0.02305    \n-Jim Gantner       1.95e-03 0.00960    \n-Johnny Grubb      3.56e-05 0.02493    \n-Jack Howell       5.16e-03 0.01668    \n-John Kruk         6.41e-03 0.01353    \n-Jeffrey Leonard   3.57e-03 0.00622    \n-Jim Morrison      2.41e-03 0.01043    \n-John Moses        6.96e-03 0.00956    \n-Jerry Mumphrey    1.52e-03 0.01145    \n-Jim Presley       1.08e-02 0.01817    \n-Johnny Ray        7.90e-05 0.02223    \n-Jeff Reed         5.93e-03 0.01410    \n-Jim Rice          1.19e-02 0.03416    \n-Jerry Royster     2.84e-06 0.00787    \n-John Russell      1.28e-03 0.00732    \n-Juan Samuel       1.52e-04 0.01123    \n-John Shelby       3.83e-07 0.01058    \n-Joel Skinner      2.28e-03 0.00821    \n-Jim Sundberg      9.48e-03 0.01962    \n-Jose Uribe        9.80e-04 0.02432    \n-Joel Youngblood   2.34e-03 0.01275    \n-Kevin Bass        7.21e-04 0.02192    \n-Kal Daniels       1.10e-02 0.01950    \n-Kirk Gibson       7.17e-03 0.02056    \n-Ken Griffey       1.17e-03 0.01574    \n-Keith Hernandez   7.51e-03 0.01861    \n-Kent Hrbek        4.34e-03 0.01925    \n-Ken Landreaux     3.11e-03 0.00739    \n-Kevin McReynolds  1.13e-04 0.01563    \n-Kevin Mitchell    2.72e-03 0.00624    \n-Keith Moreland    2.44e-03 0.01216    \n-Ken Oberkfell     1.82e-03 0.01265    \n-Ken Phelps        4.73e-04 0.01983    \n-Kirby Puckett     4.62e-02 0.05527   *\n-Kurt Stillwell    5.73e-03 0.01199    \n-Leon Durham       2.69e-03 0.00780    \n-Len Dykstra       2.06e-03 0.00858    \n-Larry Herndon     9.00e-05 0.00650    \n-Lee Lacy          1.57e-05 0.00742    \n-Len Matuszek      5.59e-06 0.01299    \n-Lloyd Moseby      1.10e-03 0.01541    \n-Lance Parrish     3.98e-03 0.01684    \n-Larry Parrish     5.80e-06 0.01955    \n-Larry Sheets      4.01e-03 0.01021    \n-Lou Whitaker      4.42e-04 0.01037    \n-Mike Aldrete      5.49e-03 0.01090    \n-Marty Barrett     1.83e-05 0.02919    \n-Mike Davis        6.06e-04 0.00668    \n-Mike Diaz         7.83e-03 0.01471    \n-Mariano Duncan    1.96e-03 0.01154    \n-Mike Easler       1.96e-04 0.01082    \n-Mel Hall          5.23e-06 0.00977    \n-Mike Heath        3.07e-03 0.00815    \n-Mike Kingery      7.02e-03 0.01115    \n-Mike LaValliere   2.88e-03 0.00901    \n-Mike Marshall     3.03e-03 0.01371    \n-Mike Pagliarulo   1.05e-02 0.02554    \n-Mark Salas        1.19e-03 0.00824    \n-Mike Schmidt      8.89e-02 0.03089   *\n-Mike Scioscia     3.37e-03 0.00698    \n-Mickey Tettleton  2.19e-03 0.01355    \n-Milt Thompson     1.10e-03 0.00617    \n-Mitch Webster     6.71e-03 0.01694    \n-Mookie Wilson     1.32e-03 0.00619    \n-Marvell Wynne     8.04e-05 0.00634    \n-Mike Young        2.18e-05 0.00474    \n-Ozzie Guillen     5.67e-03 0.02716    \n-Oddibe McDowell   3.86e-03 0.00964    \n-Ozzie Smith       2.39e-02 0.02295    \n-Ozzie Virgil      3.49e-03 0.01141    \n-Phil Bradley      2.29e-04 0.01688    \n-Phil Garner       3.09e-04 0.00536    \n-Pete Incaviglia   1.46e-02 0.02516    \n-Paul Molitor      2.90e-03 0.00571    \n-Pete Rose         8.88e-03 0.01262    \n-Pat Sheridan      1.87e-04 0.00889    \n-Pat Tabler        1.21e-05 0.02628    \n-Rafael Belliard   1.67e-03 0.01234    \n-Rick Burleson     7.03e-04 0.00907    \n-Randy Bush        1.39e-05 0.00496    \n-Rick Cerone       6.12e-06 0.01047    \n-Ron Cey           6.94e-03 0.01140    \n-Rob Deer          1.04e-02 0.03955    \n-Rick Dempsey      1.06e-03 0.01365    \n-Ron Hassey        5.06e-04 0.01582    \n-Rickey Henderson  7.17e-03 0.01946    \n-Reggie Jackson    3.23e-04 0.00963    \n-Ron Kittle        6.03e-04 0.01951    \n-Ray Knight        7.96e-06 0.01010    \n-Rick Leach        2.18e-04 0.01402    \n-Rick Manning      1.07e-03 0.01159    \n-Rance Mulliniks   1.89e-04 0.00450    \n-Ron Oester        2.02e-03 0.01226    \n-Rey Quinones      7.19e-03 0.01288    \n-Rafael Ramirez    5.87e-03 0.01556    \n-Ronn Reynolds     7.24e-07 0.01742    \n-Ron Roenicke      2.44e-04 0.00722    \n-Ryne Sandberg     1.27e-04 0.01480    \n-Rafael Santana    2.69e-05 0.02135    \n-Rick Schu         2.10e-03 0.01243    \n-Ruben Sierra      4.42e-03 0.00575    \n-Roy Smalley       1.52e-03 0.01061    \n-Robby Thompson    7.95e-03 0.01401    \n-Rob Wilfong       8.15e-04 0.01093    \n-Robin Yount       2.17e-03 0.01993    \n-Steve Balboni     3.19e-02 0.03283    \n-Scott Bradley     7.35e-03 0.01382    \n-Sid Bream         2.12e-03 0.00648    \n-Steve Buechele    4.66e-03 0.01005    \n-Shawon Dunston    7.90e-03 0.01549    \n-Scott Fletcher    3.89e-05 0.02316    \n-Steve Garvey      5.71e-03 0.01247    \n-Steve Jeltz       2.92e-03 0.02943    \n-Steve Lombardozzi 7.36e-03 0.01637    \n-Spike Owen        5.02e-04 0.03619   *\n-Steve Sax         1.31e-01 0.05621   *\n-Tony Bernazard    3.71e-04 0.01372    \n-Tom Brookens      1.80e-04 0.00843    \n-Tom Brunansky     1.78e-03 0.01555    \n-Tony Fernandez    1.35e-02 0.03841    \n-Tim Flannery      1.17e-07 0.00880    \n-Tom Foley         1.76e-07 0.01018    \n-Tony Gwynn        1.60e-03 0.04413   *\n-Terry Harper      5.79e-04 0.00728    \n-Tommy Herr        1.06e-02 0.02831    \n-Tim Hulett        4.12e-03 0.01934    \n-Terry Kennedy     4.02e-02 0.03269   *\n-Tito Landrum      6.90e-04 0.01246    \n-Tim Laudner       1.90e-07 0.01372    \n-Tom Paciorek      5.33e-05 0.01268    \n-Tony Pena         2.61e-03 0.00921    \n-Terry Pendleton   9.33e-03 0.04110    \n-Tony Phillips     2.31e-04 0.00948    \n-Terry Puhl        1.15e-02 0.01348    \n-Ted Simmons       5.86e-03 0.01835    \n-Tim Teufel        2.91e-05 0.00754    \n-Tim Wallach       2.96e-03 0.01472    \n-Vince Coleman     1.09e-02 0.05407   *\n-Von Hayes         1.82e-03 0.01920    \n-Vance Law         2.47e-03 0.01135    \n-Wally Backman     8.32e-04 0.02256    \n-Wade Boggs        8.84e-03 0.07367   *\n-Will Clark        3.49e-03 0.00548    \n-Wally Joyner      1.20e-02 0.01320    \n-Willie McGee      1.93e-03 0.01159    \n-Willie Randolph   2.77e-03 0.01180    \n-Wayne Tolleson    2.73e-05 0.01364    \n-Willie Upshaw     5.68e-03 0.01897    \n-Willie Wilson     3.71e-03 0.02101    \n\n\n\nsummary(influence.measures(reg_model_2))\n\nPotentially influential observations of\n     lm(formula = log_Salary ~ AtBat + Hits + HmRun, data = hitters) :\n\n                dfb.1_ dfb.AtBt dfb.Hits dfb.HmRn dffit   cov.r   cook.d\n-Don Mattingly   0.00  -0.04     0.04     0.01     0.05    1.12_*  0.00 \n-George Bell     0.00  -0.01     0.01     0.01     0.02    1.05_*  0.00 \n-Gary Gaetti     0.00   0.00     0.00     0.01     0.01    1.05_*  0.00 \n-Jesse Barfield -0.01  -0.02     0.01     0.06     0.07    1.06_*  0.00 \n-Kirby Puckett   0.04   0.28    -0.32    -0.17    -0.43_*  1.02    0.05 \n-Mike Schmidt    0.60  -0.26     0.12     0.03     0.61_*  0.88_*  0.09 \n-Spike Owen     -0.02   0.03    -0.03    -0.03     0.04    1.05_*  0.00 \n-Steve Sax       0.06   0.38    -0.54     0.34    -0.73_*  0.94_*  0.13 \n-Tony Gwynn      0.01   0.05    -0.06     0.02    -0.08    1.06_*  0.00 \n-Terry Kennedy   0.40  -0.21     0.11     0.04     0.40_*  0.97    0.04 \n-Vince Coleman   0.10  -0.16     0.13     0.14    -0.21    1.06_*  0.01 \n-Wade Boggs      0.02  -0.14     0.17    -0.05     0.19    1.09_*  0.01 \n                hat    \n-Don Mattingly   0.09_*\n-George Bell     0.03  \n-Gary Gaetti     0.03  \n-Jesse Barfield  0.05_*\n-Kirby Puckett   0.06_*\n-Mike Schmidt    0.03  \n-Spike Owen      0.04  \n-Steve Sax       0.06_*\n-Tony Gwynn      0.04  \n-Terry Kennedy   0.03  \n-Vince Coleman   0.05_*\n-Wade Boggs      0.07_*\n\n\n\nsummary(influence.measures(reg_model))\n\nPotentially influential observations of\n     lm(formula = Salary ~ AtBat + Hits + HmRun, data = hitters) :\n\n                 dfb.1_ dfb.AtBt dfb.Hits dfb.HmRn dffit   cov.r   cook.d\n-Don Mattingly    0.01  -0.38     0.42     0.15     0.50_*  1.07_*  0.06 \n-Dale Murphy     -0.17   0.11    -0.09     0.24     0.40_*  0.92_*  0.04 \n-Dave Winfield   -0.14   0.12    -0.11     0.17     0.34    0.91_*  0.03 \n-Eddie Murray     0.06  -0.32     0.36     0.09     0.49_*  0.78_*  0.06 \n-George Bell     -0.01  -0.02     0.02     0.02     0.04    1.05_*  0.00 \n-Gary Carter     -0.06   0.11    -0.13     0.26     0.38_*  0.88_*  0.03 \n-Gary Gaetti      0.01   0.01    -0.01    -0.03    -0.03    1.05_*  0.00 \n-Jesse Barfield  -0.01  -0.03     0.02     0.10     0.12    1.06_*  0.00 \n-Jack Clark       0.20  -0.03    -0.03     0.06     0.24    0.94_*  0.01 \n-Jim Rice        -0.05  -0.43     0.54     0.05     0.67_*  0.87_*  0.11 \n-Keith Hernandez -0.02  -0.18     0.25    -0.07     0.34    0.94_*  0.03 \n-Kirby Puckett    0.05   0.36    -0.41    -0.21    -0.55_*  0.99    0.08 \n-Mike Schmidt     0.94  -0.41     0.18     0.05     0.95_*  0.69_*  0.20 \n-Ozzie Smith     -0.10   0.07     0.06    -0.47     0.55_*  0.85_*  0.07 \n-Spike Owen       0.00   0.00     0.00     0.00     0.00    1.05_*  0.00 \n-Steve Sax        0.05   0.29    -0.41     0.26    -0.56_*  0.99    0.08 \n-Tony Gwynn       0.02   0.10    -0.13     0.03    -0.17    1.05_*  0.01 \n-Terry Pendleton  0.06  -0.10     0.07     0.09    -0.13    1.05_*  0.00 \n-Vince Coleman    0.06  -0.11     0.08     0.09    -0.13    1.07_*  0.00 \n-Wade Boggs       0.03  -0.29     0.36    -0.11     0.40_*  1.06_*  0.04 \n                 hat    \n-Don Mattingly    0.09_*\n-Dale Murphy      0.02  \n-Dave Winfield    0.01  \n-Eddie Murray     0.01  \n-George Bell      0.03  \n-Gary Carter      0.01  \n-Gary Gaetti      0.03  \n-Jesse Barfield   0.05_*\n-Jack Clark       0.01  \n-Jim Rice         0.03  \n-Keith Hernandez  0.02  \n-Kirby Puckett    0.06_*\n-Mike Schmidt     0.03  \n-Ozzie Smith      0.02  \n-Spike Owen       0.04  \n-Steve Sax        0.06_*\n-Tony Gwynn       0.04  \n-Terry Pendleton  0.04  \n-Vince Coleman    0.05_*\n-Wade Boggs       0.07_*\n\n\n\nplot(reg_model, pch=16)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot(reg_model_2, pch=16)"
  },
  {
    "objectID": "posts/rl/2022-12-11-rl-Ch10.html",
    "href": "posts/rl/2022-12-11-rl-Ch10.html",
    "title": "고급회귀분석 CH10",
    "section": "",
    "text": "이상치\n\n\nlibrary(ggplot2)\n\n\n회귀진단\n\n오차항의 검토\n적절한 모형의 선택\n독립변수들 간의 상관관계 검토\n지렛대점(leverage point)의 검출\n이상치(outlier) 화인\n영향점(influential observation)의 검출\n\n추정된 회귀직선\n\\[\\hat{y} = X(X^\\top X)^{-1} X^\\top y = Hy\\]\nH: hat matrix, \\(n \\times n\\) matrix\n\\(Var(\\hat{y}) = \\sigma^2 H\\)\n\\(Var(e) = (I_N - H) \\sigma^2\\)\n\\(h_{i,j} = x_i^\\top (X^\\top X) ^{-1} x_j\\)\n\\(h_{ij}\\) : H의 대각원소\n\\(H = X(X^\\top X)^{-1} X^\\top\\)\n\\(HH = H\\)\n\\(rank(H) = p+1\\)\n\\(tr(H) = \\sum^n_{i=1}h_{ii} = p+1\\)\n\\(H\\) : 양반정치행렬 positive definite\n\\(0 \\le h_{ii} &lt;1 , -\\frac{1}{2} \\le h_{ij} \\le -\\frac{1}{2}\\)\n\\(p=1, h_{ii} = \\frac{1}{n} + \\frac{(x_{u} - \\bar{x})^2}{S_{xx}}\\)\n\\(p&gt;1, h_{ii} = \\frac{1}{n} + (x_i - \\bar{x})^\\top (X^\\top X)^{-1} (x_i - \\bar{x})\\)\n\n지렛대점(leverage point)\n\\(h_{ii} &gt; s\\bar{h}\\) 이면, i번째 관측치가 leverage point로 고려 가능\n\\[\\bar{h} = \\frac{1}{n} \\sum^n_{i=1}h_{ii} = \\frac{p+1}{n}\\]\n\n\n잔차(Residual)\n\\(e = y − \\hat{y} = y − X \\hat{\\beta}\\)\n\\(= y − X(X^\\top X)^{-1} X^\\top y\\)\n\\(= (In − X(X^\\to X)^{-1}X^\\to )y = (I_n − H)y\\)\n\\(E(e) = 0_n, Var(e) = (I_n − H)σ^2\\)\n\\(E(e_i) = 0, Var(e_i) = (1 − h_{ii})σ^2\\)\n\\(Cov(e_i,e_j) = −h_{ij} σ^2\\)\n\\(ρ_{ij} = \\frac{−h_{ij} σ^2}{ \\sqrt{(1 − h_{ii})(1 − h_{jj})σ^4} }=\\frac{ −h_{ij}}{\\sqrt{(1 − h_{ii})(1 − h_{jj})}}\\)\n\n\n표준화잔차(standardized residual)\n\\(y \\sim N(Xβ,I_nσ^2)\\)\n\\(e \\sim N(0_n,(I_n−H)σ^2)\\)\n\\(e_i \\sim N(0,(1−h_{ii})σ^2)\\)\n\\(\\star \\frac{e_i}{\\sigma\\sqrt{1-h_{ii}}} \\sim N(0,1)\\)\n\n내적 스튜던트화 잔차(internally studentized residual)\n\\(r_i = \\frac{e_i}{\\hat{\\sigma}\\sqrt{1−h_{ii}}}\\)\n\\(\\hat{\\sigma}^2 = MSE\\)\n이러한 표준화 잔차에 대한 표본분포는 분자와 분모가 서로 독립이 아니기 때문에 \\(t\\) 분포로 근사할 수 없는데, \\(|e_i|\\)가 큰 경우, \\(s\\)도 역시 커지게 되기 때문이다.\n\n\n외적 스튜던트화 잔차(externally studentized residual)\n\\(r_i^{*} = \\frac{e_i}{\\hat{\\sigma}_{(i)}\\sqrt{1 − h_{ii}}} \\sim t(n-p-1-1)\\)\n\\(\\hat{\\sigma}^2_{(i)} = [(n-p-1)\\hat{\\sigma} - \\frac{e^2_{(i)}}{1-h_{ii}}]/(n-p-2)\\)\n\\(|r_i^{*}| ≥ t_{α/2}(n − p − 2)\\) 이면 유의수준\\(\\alpha\\)에서 \\(y_i\\)를 이상점이라고 판정\n\\(\\star\\)\n\\(t_{i} = \\frac{y_i - \\tilde{y}_i}{\\hat{\\sigma}\\sqrt{1 + x_i^\\top [X{i}^\\top X(i)]^{-1} x_i}} \\sim t(n-p-2)\\)\n\\(|r_i^{*}| \\sim t_{i}\\)\n\n\n\n예제 10.1\n\ndf = data.frame('x' =  c(15, 26, 10, 9, 15, 20, 18, 11, 8, 20, 7, 9, 10, 11, 11, 10, 12, 42, 17, 11, 10),\n    'y' = c(95, 71, 83, 91, 102, 87, 93, 100, 104, 94, 113, 96, 83, 84, 102, 100, 105, 57, 121, 86, 100))\n\n\nmodel = lm(y~x,df)\n\n\nsummary(model)\n\n\nCall:\nlm(formula = y ~ x, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.604  -8.731   1.396   4.523  30.285 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 109.8738     5.0678  21.681 7.31e-15 ***\nx            -1.1270     0.3102  -3.633  0.00177 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 11.02 on 19 degrees of freedom\nMultiple R-squared:   0.41, Adjusted R-squared:  0.3789 \nF-statistic:  13.2 on 1 and 19 DF,  p-value: 0.001769\n\n\n\\(y = 109.8738 -1.1270 x\\)\n\nplot(df$x,df$y)\nabline(model, col='steelblue', lwd=2)\n\n\n\n\n\nanova(model)\n\n\nA anova: 2 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nx\n1\n1604.081\n1604.0809\n13.20182\n0.001768622\n\n\nResiduals\n19\n2308.586\n121.5045\nNA\nNA\n\n\n\n\n\n\nqf(0.95,1,19)\n\n4.3807496923318\n\n\n\\(F_0 = 13.20 &gt; F_{0.05}(1,19) = 4.38\\), 회귀직선은 유의하다\n\\(\\sigma^2 \\sim MSE\\)\n\nMSE = 121.505\n\n\nsqrt(MSE)\n\n11.0229306447968\n\n\n손계산\n\nres = df$y - (109.874 - 1.127*df$x)\n\n\nh = 1/21 + (df$x - mean(df$x))^2/(1604.08)\n\n\nri = res/(sqrt(MSE)*sqrt(1-h))\n\n\nri2 = res/(((19*sqrt(MSE) - res^2/(1-h))/18)*sqrt(1-h))\n\n\nrstudent(model)\n\n10.1839684933793942-0.9415833513782013-1.510811922917994-0.81426336315943850.8328629175207956-0.03063182753708870.31124676473215880.22971574964993190.289910136925676100.617660260595883111.0508471635886512-0.34283148352928113-1.5108119229179914-1.27977575448039150.413153195694502160.127393415386012170.79828114441511618-0.845110861537551193.6069797213043920-1.07648107628971210.127393415386012\n\n\n\nrstudent(model)[abs(rstudent(model))&gt;qt(0.975,258)]\n\n19: 3.60697972130439\n\n\n\nround(data.frame(rep(1:21),res,h,ri,ri2),4)\n\n\nA data.frame: 21 × 5\n\n\nrep.1.21.\nres\nh\nri\nri2\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n2.031\n0.0479\n0.1888\n0.1827\n\n\n2\n-9.572\n0.1318\n-0.9319\n-1.7796\n\n\n3\n-15.604\n0.0596\n-1.4598\n5.8540\n\n\n4\n-8.731\n0.0657\n-0.8194\n-1.2717\n\n\n5\n9.031\n0.0479\n0.8396\n1.3459\n\n\n6\n-0.334\n0.0673\n-0.0314\n-0.0297\n\n\n7\n3.412\n0.0558\n0.3185\n0.3207\n\n\n8\n2.523\n0.0547\n0.2354\n0.2304\n\n\n9\n3.142\n0.0730\n0.2961\n0.2955\n\n\n10\n6.666\n0.0673\n0.6262\n0.7679\n\n\n11\n11.015\n0.0816\n1.0427\n2.6755\n\n\n12\n-3.731\n0.0657\n-0.3502\n-0.3571\n\n\n13\n-15.604\n0.0596\n-1.4598\n5.8540\n\n\n14\n-13.477\n0.0547\n-1.2575\n-14.4335\n\n\n15\n4.523\n0.0547\n0.4220\n0.4459\n\n\n16\n1.396\n0.0596\n0.1306\n0.1250\n\n\n17\n8.650\n0.0512\n0.8056\n1.2241\n\n\n18\n-5.540\n0.5232\n-0.7278\n-0.9954\n\n\n19\n30.285\n0.0519\n2.8216\n-0.7386\n\n\n20\n-11.477\n0.0547\n-1.0709\n-3.0318\n\n\n21\n1.396\n0.0596\n0.1306\n0.1250\n\n\n\n\n\n\\(2\\bar{h}\\)\n\n2*(2/21)\n\n0.19047619047619\n\n\n18번째가 2hbar 보다 크니까 지렛대점\n\nqt(0.975,18)\n\n2.10092204024104\n\n\n19번째가 ri2 t보다 크니까 이상점\n\nsummary(influence.measures( model))\n\nPotentially influential observations of\n     lm(formula = y ~ x, data = df) :\n\n   dfb.1_ dfb.x   dffit   cov.r   cook.d hat    \n18  0.83  -1.11_* -1.16_*  2.96_*  0.68   0.65_*\n19  0.14   0.27    0.85    0.40_*  0.22   0.05  \n\n\n\n\n영향점(influential observation)\n\nDIFFITS\n\\(DIFFITS(i) = (\\frac{h_{ii}}{10h_{ii}})^{1/2} r^{*}_i\\)\n\\(DIFFITS(i) \\ge 2(\\frac{p+1}{n})^{1/2}\\) 이 되는 i번째 관측칠가 영향점이라고 말함\n\n\nCook의 통계량\n\\(D(i) = \\frac{r^2_i}{p+1} \\frac{h_{ii}}{1-h_{ii}}\\)\n대략적으로 \\(D(i) \\ge F_{0.5}(p+1,n-p-1)\\)이면 영향을 크게 주는 측정값으로 의심\nh\n\nhatvalues(model)\n\n10.047922479451021820.15451323429605630.062815775582535340.070545207752054950.047922479451021860.072618957846316370.057989593544981580.056669934394087990.0798582309026469100.0726189578463163110.0907548450343111120.0705452077520549130.0628157755825353140.0566699343940879150.0566699343940879160.0628157755825353170.0521076841867129180.65160998416409190.0530502978659226200.0566699343940879210.0628157755825353\n\n\ndiffits\n\ndffits(model)\n\n10.04127403575140562-0.4025206873025253-0.3911400454742154-0.22432853366080450.1868559838824216-0.0085717364067812270.077223952838937980.056303486522047690.085407472693718100.172840518129759110.33199685399425312-0.094449643042361813-0.39114004547421514-0.313673908094842150.101264129345836160.0329813827461469170.18716612805440518-1.15577873097521190.85373710713076620-0.263846244162542210.0329813827461469\n\n\ncooksdistance, D\n\ncooks.distance(model)\n\n10.00089740639287069120.081497955150763530.071658144221383340.025615958245264150.017743662633501363.87762740910137e-0570.003130574802994980.0016682085781346990.00383194880672965100.0154395158127621110.0548101351203612120.00467762256482442130.0716581442213833140.0475978118328145150.00536121617564154160.000573584529113046170.017856495213809180.678112028575845190.223288273631179200.0345188940892692210.000573584529113046\n\n\nCOVRATIO\n\ncovratio(model) \n\n11.1658918168321921.1969989767629630.93634739734183941.1151026899392951.0850410825772861.2013199827549771.1701575789867381.1742372676080391.19966823450598101.15209128858604111.08783960928084121.18326164825873130.936347397341839140.992331347870996151.15904532932769161.18673688685713171.09643883044992182.95868271380702190.396431612340971201.04257281407241211.18673688685713\n\n\n\ninfluence.measures( model)\n\nInfluence measures of\n     lm(formula = y ~ x, data = df) :\n\n     dfb.1_    dfb.x    dffit cov.r   cook.d    hat inf\n1   0.01664  0.00328  0.04127 1.166 8.97e-04 0.0479    \n2   0.18862 -0.33480 -0.40252 1.197 8.15e-02 0.1545    \n3  -0.33098  0.19239 -0.39114 0.936 7.17e-02 0.0628    \n4  -0.20004  0.12788 -0.22433 1.115 2.56e-02 0.0705    \n5   0.07532  0.01487  0.18686 1.085 1.77e-02 0.0479    \n6   0.00113 -0.00503 -0.00857 1.201 3.88e-05 0.0726    \n7   0.00447  0.03266  0.07722 1.170 3.13e-03 0.0580    \n8   0.04430 -0.02250  0.05630 1.174 1.67e-03 0.0567    \n9   0.07907 -0.05427  0.08541 1.200 3.83e-03 0.0799    \n10 -0.02283  0.10141  0.17284 1.152 1.54e-02 0.0726    \n11  0.31560 -0.22889  0.33200 1.088 5.48e-02 0.0908    \n12 -0.08422  0.05384 -0.09445 1.183 4.68e-03 0.0705    \n13 -0.33098  0.19239 -0.39114 0.936 7.17e-02 0.0628    \n14 -0.24681  0.12536 -0.31367 0.992 4.76e-02 0.0567    \n15  0.07968 -0.04047  0.10126 1.159 5.36e-03 0.0567    \n16  0.02791 -0.01622  0.03298 1.187 5.74e-04 0.0628    \n17  0.13328 -0.05493  0.18717 1.096 1.79e-02 0.0521    \n18  0.83112 -1.11275 -1.15578 2.959 6.78e-01 0.6516   *\n19  0.14348  0.27317  0.85374 0.396 2.23e-01 0.0531   *\n20 -0.20761  0.10544 -0.26385 1.043 3.45e-02 0.0567    \n21  0.02791 -0.01622  0.03298 1.187 5.74e-04 0.0628"
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html",
    "href": "posts/rl/2022-09-21-rl_HW1.html",
    "title": "Regression HW 1",
    "section": "",
    "text": "고급회귀분석 과제, CH03, CH04\n과제1\n풀이 :\nR 이용하지 않고 직접 계산. (R로 단순 계산은 해도 됨)\n모든 문제에는 풀이가 있어야 함.\n풀이 없이 답만 있는 경우 ’0’점 처리.\n제출 방법 :\n직접 제출 (607호) 또는 스캔, 사진, tex 작업, 문서 작업 등 후 pdf로 변환 후 제출\npdf 아닌 경우 미제출 처리"
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html#section-2",
    "href": "posts/rl/2022-09-21-rl_HW1.html#section-2",
    "title": "Regression HW 1",
    "section": "(1)",
    "text": "(1)\n이 데이터의 산점도를 그리시오.\n\ndt &lt;- data.frame(x = c(0.9,1.3,2.1,2.5,2.4,1.7,0.7,1.2,1.6),\n                 y = c(2.0,2.6,4.3,5.8,5.1,3.2,1.8,2.3,3.0))\ndt\n\n\nA data.frame: 9 × 2\n\n\nx\ny\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n0.9\n2.0\n\n\n1.3\n2.6\n\n\n2.1\n4.3\n\n\n2.5\n5.8\n\n\n2.4\n5.1\n\n\n1.7\n3.2\n\n\n0.7\n1.8\n\n\n1.2\n2.3\n\n\n1.6\n3.0\n\n\n\n\n\nAnswer\n\nplot(y~x, \n     data = dt,\n     xlab = \"무게\",\n     ylab = \"에너지소모량\",\n     pch  = 16,\n     cex  = 1,\n     col  = \"darkorange\")\n\n\n\n\n\n양의 상관관계가 있어보인다.\n무게가 커질수록 에너지소모량도 큰 경향이 보이기 때문이다.\n우상향의 모양이라, 단순상관선형 적용해보면 되겠다."
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html#section-3",
    "href": "posts/rl/2022-09-21-rl_HW1.html#section-3",
    "title": "Regression HW 1",
    "section": "(2)",
    "text": "(2)\n최소제곱법의 의한 회귀직선을 적합시키시오.\nAnswer\n\ndt1 &lt;- data.frame(\n  i = 1:nrow(dt),\n  x = dt$x,\n  y = dt$y,\n  x_barx = dt$x - mean(dt$x),\n  y_bary = dt$y - mean(dt$y)) \n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주기 위해 \\(x_i - \\bar{x}, y_i - \\bar{y}\\)를 구했다.\n\n\ndt1$x_barx2 &lt;- dt1$x_barx^2\ndt1$y_bary2 &lt;- dt1$y_bary^2\ndt1$xy &lt;-dt1$x_barx * dt1$y_bary\n\n\n\\(S_{xx}, S_{yy},S_{xy}\\)를 구해주었다.\n\n\ndt1\n\n\nA data.frame: 9 × 8\n\n\ni\nx\ny\nx_barx\ny_bary\nx_barx2\ny_bary2\nxy\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n0.9\n2.0\n-0.7\n-1.3444444\n0.49\n1.8075309\n0.94111111\n\n\n2\n1.3\n2.6\n-0.3\n-0.7444444\n0.09\n0.5541975\n0.22333333\n\n\n3\n2.1\n4.3\n0.5\n0.9555556\n0.25\n0.9130864\n0.47777778\n\n\n4\n2.5\n5.8\n0.9\n2.4555556\n0.81\n6.0297531\n2.21000000\n\n\n5\n2.4\n5.1\n0.8\n1.7555556\n0.64\n3.0819753\n1.40444444\n\n\n6\n1.7\n3.2\n0.1\n-0.1444444\n0.01\n0.0208642\n-0.01444444\n\n\n7\n0.7\n1.8\n-0.9\n-1.5444444\n0.81\n2.3853086\n1.39000000\n\n\n8\n1.2\n2.3\n-0.4\n-1.0444444\n0.16\n1.0908642\n0.41777778\n\n\n9\n1.6\n3.0\n0.0\n-0.3444444\n0.00\n0.1186420\n0.00000000\n\n\n\n\n\n\n반올림 해주었다.\n\n\nround(colSums(dt1),3)\n\ni45x14.4y30.1x_barx0y_bary0x_barx23.26y_bary216.002xy7.05\n\n\n\\(\\hat{\\beta_1} = \\frac{S_{xy}}{S_{xx}}\\)\n\\(\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x}\\)\n\nbeta1 &lt;- as.numeric(colSums(dt1)[8]/colSums(dt1)[6])\nbeta0 &lt;- mean(dt$y) - beta1 *  mean(dt$x)\n\n\ncat(\"hat beta0 = \", beta0)\ncat(\"hat beta1 = \", beta1)\n\nhat beta0 =  -0.1156783hat beta1 =  2.162577\n\n\n\n\\(\\hat{y} = -0.1156783 + 2.162577x\\)의 모형으로 적합되었다.\n\n\nlm(y~x,dt)\n\n\nCall:\nlm(formula = y ~ x, data = dt)\n\nCoefficients:\n(Intercept)            x  \n    -0.1157       2.1626"
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html#section-4",
    "href": "posts/rl/2022-09-21-rl_HW1.html#section-4",
    "title": "Regression HW 1",
    "section": "(3)",
    "text": "(3)\n데이터의 산점도를 그리고 추정한 회귀직선을 (1)에서 그린 산점도 위에 그리시오.\nAnswer\n\nplot(y~x, \n     data = dt,\n     xlab = \"무게\",\n     ylab = \"에너지소모량\",\n     pch  = 16,\n     cex  = 1,\n     col  = \"darkorange\")\npar(new=TRUE)\nplot(-0.1156783 +  2.162577*x~x,\n     data = dt,\n     xlab = \"\",\n     ylab = \"\",\n     pch  = 16,\n     cex  = 1,type='l',\n     col  = \"blue\")\n\n\n\n\n\n추정한 회귀직선을 그려보니 오차가 클 것처럼 y와 \\(\\hat{y}\\)가 떨어진 값이 많아보인다."
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html#section-5",
    "href": "posts/rl/2022-09-21-rl_HW1.html#section-5",
    "title": "Regression HW 1",
    "section": "(4)",
    "text": "(4)\n결정계수와 상관계수를 구하시오.\n\\(r_{xy} = \\frac{S_{xy}}{\\sqrt{S_{xx}S_{yy}}}\\)\n\nrxy = colSums(dt1)[8]/sqrt(colSums(dt1)[6]*colSums(dt1)[7])\nrxy\n\nxy: 0.976090685311348\n\n\n\n상관계수는 약 98% 로, \\(x,y\\)간 높은 양의 상관관계가 있었다.\n\n\\(R^2 = \\frac{SSR}{SST} = r^2\\)\n\nSST = sum((dt$y - mean(dt$y))^2)\n\n\nSSR = sum( ( (-0.1156783 +  2.162577*dt$x)-mean(dt$y) )^2 )\n\n\nSSE = sum( ( dt$y-(-0.1156783 +  2.162577*dt$x))^2 )\n\n\ncat(\"SST = \", SST)\ncat(\"\\nSSR = \", SSR)\ncat(\"\\nSSE = \", SSE)\n\nSST =  16.00222\nSSR =  15.24617\nSSE =  0.7560566\n\n\n\nSSR/SST\n\n0.95275330164195\n\n\n\nrxy**2\n\nxy: 0.952753025951577\n\n\n\n결정계수는 약 95%로, 설명력도 높은 편이라고 말할 수 있지만, 결정계수는 다른 모델과 비교할때 언급되는 것이 적절하다."
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html#section-6",
    "href": "posts/rl/2022-09-21-rl_HW1.html#section-6",
    "title": "Regression HW 1",
    "section": "(5)",
    "text": "(5)\n분산분석표를 작성하고 회귀직선의 유의 여부를 검정하시오 (유의수준 \\(α = 0.05\\) 사용).\n\nMSR = SSR/1\nMSE = SSE/7\n\n\ncat(\"MSR = \", MSR)\ncat(\"\\nMSE = \", MSE)\n\nMSR =  15.24617\nMSE =  0.1080081\n\n\n\nFvalue = MSR/MSE\n\n\ncat(\"F value = \",Fvalue)\n\nF value =  141.1577\n\n\n\ncat(\"p value = \",df(Fvalue,1,7))\n\np value =  1.614709e-07\n\n\n\n\n\n\ndf\nsum of square\nmean of square\nF value\np value\n\n\n\n\nx\n1\n15.24617\n15.24617\n141.1584\n1.614672e-07\n\n\nResiduals\n7\n0.7560522\n0.1080075\n\n\n\n\n\n\nF값은 141.1584, p value는 1.614672e-07가 나왔다.\n유의수준 5%에서 모형이 유의하다는 것을 알 수 있었다.\n\n\nanova(lm(y~x,dt))\n\n\nA anova: 2 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nx\n1\n15.2461656\n15.2461656\n141.1576\n6.798033e-06\n\n\nResiduals\n7\n0.7560566\n0.1080081\nNA\nNA"
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html#section-7",
    "href": "posts/rl/2022-09-21-rl_HW1.html#section-7",
    "title": "Regression HW 1",
    "section": "(6)",
    "text": "(6)\n\\(\\beta_0,\\beta_1\\) 에 대한 90% 신뢰구간을 구하시오.\nAnswer\n\\[\\hat{\\beta_0} \\pm t_{(\\alpha/2,n-2)}\\hat{\\sigma} \\sqrt{\\frac{1}{n} + \\frac{\\bar{x}^2}{S_{xx}}}\\]\n\ncat(\"Beta0 confidence level\",beta0 + qt(0.025, 7) * sqrt((MSE)*(1/9 + mean(dt$x)^2/sum((dt$x - mean(dt$x))^2))),\"~\",beta0 + qt(0.975, 7) * sqrt((MSE)*(1/9 + mean(dt$x)^2/sum((dt$x - mean(dt$x))^2))))\n\nBeta0 confidence level -0.8514415 ~ 0.620085\n\n\n\\[\\hat{\\beta_1} \\pm t_{(\\alpha/2,n-2)} \\sqrt{\\frac{MSE}{S_{xx}}}\\]\n\ncat(\"Beta1 confidence level\",beta1 + qt(0.025, 7) * sqrt((MSE)/sum((dt$x - mean(dt$x))^2)),'~',beta1 + qt(0.975, 7) * sqrt((MSE)/sum((dt$x - mean(dt$x))^2)))\n\nBeta1 confidence level 1.732168 ~ 2.592986\n\n\n\n\\(\\beta_0\\)의 신뢰구간은 0을 포함하였다.(\\(H_0 : \\beta_0=0\\) 채택)\n\\(\\beta_1\\)의 신뢰구간은 0을 포함하지 않았다.(\\(H_0 : \\beta_1=0\\) 기각)\n신뢰구간으로 신뢰구간에 0이 포함된 \\(\\beta_1\\) 계수만 유의미하다는 것을 알 수 있다."
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html#section-8",
    "href": "posts/rl/2022-09-21-rl_HW1.html#section-8",
    "title": "Regression HW 1",
    "section": "(7)",
    "text": "(7)\n\\(H_0 :\\beta_1 =1\\) vs. \\(H_1 :\\beta_1 \\ne 1\\)의 가설검정을 유의수준 \\(α=0.1\\)에서 수행하시오.\n\\[\\text{t value} = \\frac{\\hat{\\beta_1} - 1}{s.e(\\hat{\\beta_1})}\\]\n\nTvalue = (beta1 - 1)/(sqrt((MSE/sum((dt$x - mean(dt$x))^2))))\n\n\nTvalue\n\n6.3870789106442\n\n\n\n-Tvalue\n\n-6.3870789106442\n\n\n\nqt(0.95,7)\n\n1.89457860509001\n\n\n\nqt(0.05,7)\n\n-1.89457860509001\n\n\n\n구힌 t value = 6.39가 유의수준 \\(\\alpha = 0.1\\) 에서의 t value = 1.89보다 크기 때문에 유의하다는 결과가 나와 귀무가설을 기각한다.\n따라서 \\(\\beta_1\\)은 1이 아니다.\n\nfigure로 표현\n\npar(mfrow=c(1,1))\nbasic &lt;- seq(-3,3,by=0.01)\nplot(basic,dt(basic,df=7),type=\"l\",xlim=c(-8,8))\nabline(v=Tvalue,col=\"red\",lty=2)\nabline(v=qt(0.95,7),col=\"blue\",lty=2)\ntext(x=Tvalue, y=c(0.2), labels=c(\"tvalue\\n6.39\"), pos=4, col=\"black\")\ntext(x=qt(0.95,7), y=c(0.2), labels=c(\"t(0.05,7)\\n1.89\"), pos=4, col=\"black\")\nabline(v=-Tvalue,col=\"red\",lty=2)\nabline(v=qt(0.05,7),col=\"blue\",lty=2)"
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html#section-9",
    "href": "posts/rl/2022-09-21-rl_HW1.html#section-9",
    "title": "Regression HW 1",
    "section": "(8)",
    "text": "(8)\n무게가 3,000kg 이 되는 차량의 평균 에너지 소모량을 예측하시오. 이것은 무게가 1,000kg이 되는 차량의 에너지 소모량의 몇 배인가?\n\\[\\hat{\\mu}_0 = \\hat{\\beta_0} + \\hat{\\beta_1} x_0\\]\n\ncat(\"평균 에너지 소모량 = \",beta0 + beta1 * 3)\n\n평균 에너지 소모량 =  6.372052\n\n\n\ncat(\"무게가 3,000kg 이 되는 차량의 평균 에너지 소모량을 예측해보니 무게가 1,000kg이 되는 차량의 에너지 소모량의\",(beta0 + beta1 * 3)/(beta0 + beta1 * 1),\"배 였다.\")\n\n무게가 3,000kg 이 되는 차량의 평균 에너지 소모량을 예측해보니 무게가 1,000kg이 되는 차량의 에너지 소모량의 3.113028 배 였다."
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html#section-10",
    "href": "posts/rl/2022-09-21-rl_HW1.html#section-10",
    "title": "Regression HW 1",
    "section": "(9)",
    "text": "(9)\n무게가 3,000kg 이 되는 차량의 평균 에너지 소모량과 하나의 개별 \\(y\\) 값의 90% 신뢰구간을 각각 구하시오.\nAnswer\n\ncat(\"무게가 3,000kg 이 되는 차량의 평균 에너지 소모량은\",beta0 + beta1 * 3,\"이다.\")\n\n무게가 3,000kg 이 되는 차량의 평균 에너지 소모량은 6.372052 이다.\n\n\n\\[\\hat{Var(\\hat{\\mu}_0}) = \\sigma (\\frac{1}{n} + \\frac{(x_0 - \\bar{x})^2}{S_{xx}})\\]\n\nsigma = MSE\n\n\nmean(dt$x)\n\n1.6\n\n\n\\(S_{xx}\\)\n\nsum((dt$x - mean(dt$x))^2)\n\n3.26\n\n\n\ncolSums(dt1)[6]\n\nx_barx2: 3.26\n\n\n\\(\\hat{Var(\\hat{\\mu_0})}\\)\n\nsqrt(sigma)*(1/9 + (3-1.6)^2/3.26)\n\n0.234106948837031\n\n\n\ncat(\"hat var(hat mu zero) = \",sqrt(sigma)*(1/9 + (3-1.6)^2/3.26))\n\nhat var(hat mu zero) =  0.2341069\n\n\n\\(\\hat{\\sigma}_{\\hat{\\mu_0}}\\)\n\nsqrt(sqrt(sigma)*(1/9 + (3-1.6)^2/3.26))\n\n0.483845997024912\n\n\n\ncat(\"hat sigma(hat mu zero) = \", sqrt(sqrt(sigma)*(1/9 + (3-1.6)^2/3.26)))\n\nhat sigma(hat mu zero) =  0.483846\n\n\n\\(\\hat{\\mu_0} \\pm t_{(\\alpha/2,(n-2))}\\hat{\\sigma_{\\hat{\\mu_0}}}\\)\n\n6.372052 + qt(0.95,7)*sqrt(sqrt(sigma)*(1/9 + (3-1.6)^2/3.26))\n\n7.28873627412184\n\n\n\n6.372052 - qt(0.95,7)*sqrt(sqrt(sigma)*(1/9 + (3-1.6)^2/3.26))\n\n5.45536772587816\n\n\n\ncat(\"개별 y값의 90% 신뢰구간은 (\",5.4553690631157,\"~\",7.2887349368843,\") 이다.\")\n\n개별 y값의 90% 신뢰구간은 ( 5.455369 ~ 7.288735 ) 이다."
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html#section-11",
    "href": "posts/rl/2022-09-21-rl_HW1.html#section-11",
    "title": "Regression HW 1",
    "section": "(10)",
    "text": "(10)\n잔차 \\(e_i = y_i − \\hat{y}_i\\) 를 구하고 잔차의 합이 0 임을 확인하시오.\nAnswer\n\nepsilon = dt$y - (beta0 + beta1*dt$x)\n\n\nepsilon\n\n\n0.169359236537151-0.0956714383094752-0.1257327880027260.5092365371506480.0254942058623033-0.36070211315610.401874573960464-0.179413769597819-0.344444444444445\n\n\n\ncat(\"잔차의 합 = \",sum(epsilon))\n\n잔차의 합 =  8.881784e-16\n\n\n합이 0인 것을 확인했다."
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html#section-12",
    "href": "posts/rl/2022-09-21-rl_HW1.html#section-12",
    "title": "Regression HW 1",
    "section": "(11)",
    "text": "(11)\n잔차들의 \\(x_i\\) 에 대한 가중합, \\(\\sum x_ie_i\\) 를 구하시오.\n\nsum(dt$x * epsilon)\n\n9.99200722162641e-16\n\n\n잔차들의 \\(x_i\\) 에 대한 가중합, \\(\\sum x_ie_i\\)이 0인 것을 확인했다."
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html#section-13",
    "href": "posts/rl/2022-09-21-rl_HW1.html#section-13",
    "title": "Regression HW 1",
    "section": "(12)",
    "text": "(12)\n잔차들의 \\(\\hat{y}\\)에 대한 가중합 \\(\\sum \\hat{y}_ie_i\\), 를 구하시오.\n\nsum((beta0 + beta1*dt$x)*epsilon)\n\n1.74860126378462e-15\n\n\n잔차들의 \\(\\hat{y}\\)에 대한 가중합 \\(\\sum \\hat{y}_ie_i\\)이 0인 것을 확인했다."
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html#section-14",
    "href": "posts/rl/2022-09-21-rl_HW1.html#section-14",
    "title": "Regression HW 1",
    "section": "(13)",
    "text": "(13)\n원점을 지나는 회귀직선을 구하시오.\nAnswer\n\\(\\hat{\\beta_1} = \\frac{\\sum(x_iy_i)}{\\sum(x_i^2)}\\)\n\nsum(dt$x * dt$y)/sum((dt$x^2))\n\n2.09923954372624\n\n\n\nbeta1_0 &lt;- sum(dt$x * dt$y)/sum((dt$x^2))\n\n\ncat(\"hat beta1_0 = \", beta1_0)\n\nhat beta1_0 =  2.09924\n\n\n\n원점을 지나는 회귀직선은 \\(\\hat{y} = 2.09924x\\)의 모형으로 적합되었다."
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html#section-15",
    "href": "posts/rl/2022-09-21-rl_HW1.html#section-15",
    "title": "Regression HW 1",
    "section": "(14)",
    "text": "(14)\n위 회귀직선에서 회귀계수(기울기)의 90% 신뢰구간을 구하시오.\nAnswer\n\\[\\hat{\\beta_1} \\pm t_{(\\alpha/2,n-1)}\\frac{\\hat{\\sigma}}{\\sqrt{S_{xx}}}\\]\n\ncolSums(dt1)[6]\n\nx_barx2: 3.26\n\n\n\nSSR_0 = sum( ( (2.09924*dt$x) )^2 )\n\n\nSSE_0 = sum((dt$y - 2.09924*dt$x)^2)\n\n\nSST_0 = sum(dt$y^2)\n\n\nMSE_0 = SSE_0/8\n\n\nMSR_0 = SSR_0/1\n\n\nsigma_0 = sqrt(MSE_0)\n\n\nbeta1_0 + qt(0.95,8) * sigma_0/sqrt(3.26)\n\n2.41896448320474\n\n\n\nbeta1_0 - qt(0.95,8) * sigma_0/sqrt(3.26)\n\n1.77951460424773\n\n\n\ncat(\"원점을 지나는 회귀직선에서 회귀계수(기울기)의 90% 신뢰구간은 (\",beta1_0 - qt(0.95,8) * sigma_0/sqrt(3.26),\"~\",beta1_0 + qt(0.95,8) * sigma_0/sqrt(3.26),\")이다.\")\n\n원점을 지나는 회귀직선에서 회귀계수(기울기)의 90% 신뢰구간은 ( 1.779515 ~ 2.418964 )이다.\n\n\n\n\\(\\beta_1\\)의 신뢰구간은 0을 포함하지 않았다.(\\(H_0 : \\beta_1=0\\) 기각)\n신뢰구간으로 신뢰구간에 0이 포함된 \\(\\beta_1\\) 계수가 유의미하다는 것을 알 수 있다."
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html#section-16",
    "href": "posts/rl/2022-09-21-rl_HW1.html#section-16",
    "title": "Regression HW 1",
    "section": "(15)",
    "text": "(15)\n원점을 지나는 회귀직선의 결정계수를 구하시오.\nAnswer\n\\(R^2 = \\frac{SSR}{SST} = r^2\\)\n\nSSR_0/SST_0\n\n0.993392179573841\n\n\n\ncat(\"원점을 지나는 회귀직선의 결정계수는 \", SSR_0/SST_0,\"로 약\",round(SSR_0/SST_0,2),\"% 였다.\")\n\n원점을 지나는 회귀직선의 결정계수는  0.9933922 로 약 0.99 % 였다."
  },
  {
    "objectID": "posts/rl/2022-09-21-rl_HW1.html#section-17",
    "href": "posts/rl/2022-09-21-rl_HW1.html#section-17",
    "title": "Regression HW 1",
    "section": "(16)",
    "text": "(16)\n원점을 포함한 회귀직선과 포함하지 않은 회귀직선의 결과를 비교하여라.\nAnswer\n\ncat(\"원점을 포함하지 않는 회귀직선의 결정계수는 \",SSR/SST,\"로, 원점을 포함하는 회귀직선의 결정계수인 \",SSR_0/SST_0,\"보다 작다.\")\n\n원점을 포함하지 않는 회귀직선의 결정계수는  0.9527533 로, 원점을 포함하는 회귀직선의 결정계수인  0.9933922 보다 작다.\n\n\n\ncat(\"원점을 포함하지 않는 회귀직선의 평균재곱오차는 \",MSE,\"이며, 원점을 포함하는 회귀직선의 평균제곱오차는 \",MSE_0,\"이다. 원점을 포함하는 모형의 오차가 조금 더 작았다.\")\n\n원점을 포함하지 않는 회귀직선의 평균재곱오차는  0.1080081 이며, 원점을 포함하는 회귀직선의 평균제곱오차는  0.0963731 이다. 원점을 포함하는 모형의 오차가 조금 더 작았다.\n\n\n\nFvalue = MSR/MSE\n\n\nFvalue_0 = MSR_0 / MSE_0\n\n\ncat(\"원점을 포함하지 않는 회귀직선의 F 값은 \",Fvalue,\"로, 원점을 포함하는 회귀직선의 F 값인 \",Fvalue_0,\"보다 작다. 따라서 원점을 포함한 모델이 회귀모형애 의해 설명되는 부분이 더 크며, 오차항에 기인된 부분이 더 작다.\")\n\n원점을 포함하지 않는 회귀직선의 F 값은  141.1577 로, 원점을 포함하는 회귀직선의 F 값인  1202.608 보다 작다. 따라서 원점을 포함한 모델이 회귀모형애 의해 설명되는 부분이 더 크며, 오차항에 기인된 부분이 더 작다.\n\n\n\ncat(\"원점을 포함하지 않는 회귀직선의 p value 는 \",df(Fvalue,1,7),\"로, 원점을 포함하는 회귀직선의 p value인\",df(Fvalue_0,1,8),\"과 같이 p value이 충분히 작아 두 모형이 모두 유의함을 알 수 있었다.\")\n\n원점을 포함하지 않는 회귀직선의 p value 는  1.614709e-07 로, 원점을 포함하는 회귀직선의 p value인 1.728622e-12 과 같이 p value이 충분히 작아 두 모형이 모두 유의함을 알 수 있었다.\n\n\n\nplot(beta0 + beta1*x~x,\n     data = dt,\n     xlab = \"원점을 지나지 않는 모형\",\n     ylab = \"\",\n     pch  = 16,\n     cex  = 1,type='l',\n     col  = \"blue\")\nplot(beta1_0*x~x,\n     data = dt,\n     xlab = \"원점을 지나는 모형\",\n     ylab = \"\",\n     pch  = 16,\n     cex  = 1,type='l',\n     col  = \"red\")\n\n\n\n\n\n\n\n\n선형성 만족\n\n\nepsilon = dt$y - beta0 + beta1*dt$x\nepsilon_0 = dt$y - beta1_0*dt$x\n\n\nplot(epsilon,\n     xlab = \"원점을 지나지 않는 모형\",\n     ylab = \"\",\n     pch  = 16,\n     cex  = 1,\n     col  = \"blue\")\nplot(epsilon_0,\n     xlab = \"원점을 지나는 모형\",\n     ylab = \"\",\n     pch  = 16,\n     cex  = 1,\n     col  = \"red\")\n\n\n\n\n\n\n\n\n원점을 지나지 않는 모형이 한쪽 부호에 머무는 경향이 있어보인다.(독립성을 만족하지 않을 수 있다.)\n원점을 지나는 모형은 그러한 경향이 없고, 등분산성을 만족하는 것처럼 보인다.\n\n\nshapiro.test(beta0 + beta1*dt$x)\n\n\n    Shapiro-Wilk normality test\n\ndata:  beta0 + beta1 * dt$x\nW = 0.95279, p-value = 0.7207\n\n\n\nshapiro.test(beta1_0*dt$x)\n\n\n    Shapiro-Wilk normality test\n\ndata:  beta1_0 * dt$x\nW = 0.95279, p-value = 0.7207\n\n\n\n두 모형 모두 정규성 가정을 만족했다.\n\nANOVA table 비교\n\n\n\ny=beta0+beta1x\ndf\nsum of square\nmean of square\nF value\np value\n\n\n\n\nx\n1\n15.24617\n15.24617\n141.1584\n1.614672e-07\n\n\nResiduals\n7\n0.7560522\n0.1080075\n\n\n\n\n\n\n\n\ny=beta1x\ndf\nsum of square\nmean of square\nF value\np value\n\n\n\n\nx\n1\n115.89906559088\n115.89906559088\n1202.60806139735\n1.728622e-12\n\n\nResiduals\n8\n0.77098479088\n0.09637309886"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html",
    "href": "posts/rl/2023-02-23-rl-final_term.html",
    "title": "Advanced Regression Analysis Final Term",
    "section": "",
    "text": "기말고사"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-1",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-1",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(1)",
    "text": "(1)\n\\(\\sum^n_{j=1} Var(\\hat{y}_j) = (p+1) \\sigma^2\\)\nanswer\n\\(\\hat{\\bf{y}}= X\\hat{\\beta} = X(X^\\top X)^{-1} X^\\top y = Hy\\)\n\\(Var(X\\hat{\\beta}) = XVar(\\hat{\\beta})X^\\top\\)\n\\(Var(\\hat{\\beta}) = Var((X^\\top X)^{-1} X^\\top y) = (X^\\top X)^{-1} X^\\top Var(y)X(X^\\top X)^{-1} = (X^\\top X)^{-1} X^\\top X(X^\\top X)^{-1} \\sigma^2 = (X^\\top X )^{-1} \\sigma^2\\)\n\\(Var(\\hat{y}) = Var(X\\hat{\\beta}) = X(X^\\top X)^{-1} X^\\top \\sigma^2\\)\n\\(\\to Var(\\hat{y}) = HVar(y) H^\\top = HH\\sigma^2 = H\\sigma^2\\)\n\\(\\star H^\\top = H, H^2 = H, Var(y) = I_n \\sigma^2\\)\n\\(\\sum^{n}_{j=1} Var(\\hat{y}_j) = tr(Var(\\hat{y})) = tr(H\\sigma^2) = \\sigma^2 tr(H) = tr((X^\\top X)^{-1} X^\\top X)\\sigma^2 = tr(I_{p+1})\\sigma^2 = (p+1)\\sigma^2\\)\n\\(\\star tr(X (X^\\top X)^{-1} X^\\top)\\)"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-2",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-2",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(2)",
    "text": "(2)\n\\(Cov(\\mathbf{e,y}) = \\sigma^2[I_n - X(X^\\top X)^{-1} X^\\top]\\)\nanswer\n\\(\\bf{e} = y - \\hat{y} = y - Hy = (I-H)y\\)\n\\(Cov(\\bf{e},y) = Cov((I-H)y,y) = (I-H)Var(y) = (I-H) \\sigma^2\\)\n\\(\\star Cov(Ax,y) = A Cov(X,Y)\\)\n\\(\\star Var(y) = \\sigma^2\\)"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-3",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-3",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(3)",
    "text": "(3)\n\\(Cov(\\mathbf{e,\\hat{y}}) = O_n\\)\nanswer\n\\(Cov(e(I - H)\\bf{y},Hy) = (I-H) Cov(y,y)H^\\top = (I-H)H\\sigma^2 = \\mathbb{O}_n \\sigma^2\\)\n\\(\\star Cov(Ax,By) = ACov(X,Y)B^\\top\\)\n\\(\\star H^\\top= H\\)\n\\(\\star H^2 = H\\)"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-4",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-4",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(4)",
    "text": "(4)\n\\(Cov(\\mathbf{e,\\hat{\\beta}}) = O_{n \\times (p+1)}\\)\nanswer\n\\(Cov((I-H)\\bf{y},(X^\\top X)^{-1} y) = (I-H) Cov(y,y) X (X^\\top X)^{-1} = (I - X(X^\\top X)^{-1} X^\\top ) X (X^\\top X)^{-1} \\sigma^2 = \\{ X(X^\\top X)^{-1} - X(X^\\top X)^{-1} \\} \\sigma^2 = \\mathbb{O}_{n \\times ([+1)}\\)"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-5",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-5",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(5)",
    "text": "(5)\n\\(Cov(\\mathbf{\\epsilon, \\hat{\\beta}}) = \\sigma^2 X(X^\\top X)^{-1}\\)\nanswer\n\\(\\bf{\\hat{\\beta}} = (X^\\top X)^{-1} X^\\top y = (X^\\top X)^{-1} X^\\top (X\\beta + \\epsilon) = \\beta + (X^\\top X)^{-1} X^\\top \\epsilon\\)\n\\(Cov(\\bf{\\epsilon} , \\beta + (X^\\top X)^{-1} X^\\top \\epsilon ) = Cov(\\epsilon, \\beta) + Cov(\\epsilon, \\epsilon)X(X^\\top X)^{-1} = \\sigma^2 X(X^\\top X)^{-1}\\)\n\\(\\star Cov(\\epsilon, \\beta) = 0\\)\n\\(\\star Cov(\\epsilon, \\epsilon) = I_n \\sigma^2\\)"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-6",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-6",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(6)",
    "text": "(6)\n\\(\\mathbf{e^\\top y} = SSE\\)\nanswer\n\\(\\sum^{n}_{j=1} e_j y_j = \\bf{e^\\top y} = \\{ (I - H)y\\}^\\top y = y^\\top (I-H)y\\)\n\\(\\star \\bf{e}^\\top (e_1, \\dots , e_n) = (y-\\hat{y})^\\top\\)\n\\(\\star \\bf{y}^\\top = (y_1 , \\dots , y_n)\\)\n\\(SSE = \\sum^n_{j=1} (y_i - \\hat{y}_j)^2 = (\\bf{y} - \\hat{y} ) ^\\top ( y - \\hat{y} ) = e^\\top e = \\{ (I - H)y \\}^\\top \\{ (I - H)y \\} = y^\\top (I - H) (I-H)y = y^\\top (I - H)y\\)\n\\(\\star I - H_H+H^2 = I-H, H^2 = H\\)\n\\(\\therefore \\sum^{n}_{j=1} e_j y_j = SSE\\)"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-7",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-7",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(7)",
    "text": "(7)\n\\(\\mathbf{e^\\top \\hat{y}}=0\\)\nanswer\n\\(\\sum^{n}_{j=1} \\bf{e_j \\hat{y}_j} = e^\\top \\hat{y} = y^\\top (I-H) Hy = y^\\top_{1\\times n} \\mathbb{O}_{n\\times n} y_{n \\times 1} = 0\\)\n\\(\\star H - H^2 = H - H = \\mathbb{O}_{n \\times n}\\)"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-8",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-8",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(8)",
    "text": "(8)\n\\(E(\\frac{SSE}{n-p-1}) = \\sigma^2\\)\nanswer\n정리 5.1\n\\(y \\sim N(\\mu,V)\\) 이면\n\\(E(y^\\top A y) = tr(AV) + \\mu^\\top A \\mu, cov(y,y^\\top A y) = 2VA\\mu\\)\n\\(\\frac{SSE}{\\sigma^2} = y^\\top \\frac{1}{\\sigma^2}(I-H)y\\)\n\\(B = \\frac{1}{\\sigma^2}(I-H)\\)\n\\(y \\sim N(X\\beta, I \\sigma^2)\\)\n\\(BV = \\frac{1}{\\sigma^2}(I-H)I\\sigma^2 = B, BV=B\\)\n\\(B, BV\\)는 멱등행렬\n\\(tr(BV) = tr(B) = tr(I-H) = tr(I) - tr(H) = n-p-1\\)\n\\(\\star\\) \\(X\\)가 \\(n \\times (p+1)\\) 행렬이고, \\(rank\\)가 \\(p+1\\), \\(\\therefore tr(H) = p+1\\)\n\\(\\mu = X B\\)\n\\(B = \\frac{1}{\\sigma^2}(I-H)\\)\n\\(B\\mu = \\frac{1}{\\sigma^2}(I-H) X \\beta = \\frac{1}{\\sigma^2}(X B - HXB) = 0\\)\n\\(\\star HX = X\\)\n\\(\\therefore \\mu^\\top B \\mu = 0\\)\n\\(E(\\frac{SSE}{\\sigma^2}) = n-p-1\\)\n\\(E(SSE) = (n-p-1)\\sigma^2\\)\n\\(\\therefore E(\\frac{SSE}{(n-p-1)}) = \\sigma^2\\)"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-10",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-10",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(1)",
    "text": "(1)\n행렬을 이용하여 중회귀모형을 정의하여라(\\(X,\\mathbf{y,\\beta,\\epsilon}\\)을 정확하게 표현)\nanswer\n\\(\\mathbf{y = X\\beta + \\epsilon, \\epsilon} \\sim N(X\\mathbf{\\beta}, I_n\\sigma^2)\\)\n\\(\\mathbf{y} = \\begin{pmatrix} 1 \\\\5\\\\0\\\\4\\\\4\\\\-1 \\end{pmatrix}, X = \\begin{pmatrix} 1&1&1\\\\1&2&1\\\\1&1&2\\\\1&3&1\\\\1&3&2\\\\1&3&3 \\end{pmatrix}, \\mathbf{\\beta} = \\begin{pmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2\\end{pmatrix}, \\mathbf{\\epsilon} = \\begin{pmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\epsilon_3 \\\\ \\epsilon_4 \\\\ \\epsilon_5 \\\\ \\epsilon_6\\end{pmatrix}\\)\n\n위에서 구한 \\(X,\\mathbf{y}\\)에 대하여 아래의 결과를 얻었을 때, 다음 물음에 답하여라.\n\n\\[(X^\\top X)^{-1} = \\begin{pmatrix} 1.52 & -0.35 & -0.36 \\\\ -0.35 & 0.23 & -0.09 \\\\ -0.36 & -0.09 & 0.34 \\end{pmatrix}, X^\\top \\mathbf{y} = \\begin{pmatrix} 13 \\\\ 32 \\\\ 15 \\end{pmatrix}, \\mathbf{y^\\top y} = 59\\]"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-11",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-11",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(2)",
    "text": "(2)\n\\(\\beta_0, \\beta_1, \\beta_2\\)를 추정하시오.\nanswer\n\\(\\mathbf{\\hat{\\beta}} = (X^\\top X)^{-1} X^\\top \\mathbf{y} = \\begin{pmatrix} 3.16 \\\\ 1.46 \\\\ -2.46 \\end{pmatrix}\\)"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-12",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-12",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(3)",
    "text": "(3)\n분산분석표를 작성하고, 유의수준 \\(\\alpha=0.1\\)에서 회귀직선에 대한 유의성 검정을 수행하시오.\nanswer\n\n\n\n\n\n\n\n\n\n\n요인\n제곱합(SS)\n자유도(df)\n평균제곱(MS)\n\\(F_0\\)\n\n\n\n\n회귀\n23.0769\n2\n11.5385\n4.4628\n\n\n잔차\n7.7564\n3\n2.5855\n\n\n\n계\n30.8333\n5\n\n\n\n\n\n\\(SST = \\mathbf{y^\\top y} - \\frac{1}{n}(\\sum y_i)^2 = 59 - 28.1667 = 30.8333\\)\n\\(SSR = SST - SSE\\)\n- \\(H_0: \\beta_1 = \\beta_2 = 0 \\text{ vs. } H_1 : \\text{ not } H_0\\)\n- 기각역: \\(F_0 \\ge F_{0.1}(2,3) = 5.46\\)\n- 결론: 기각역에 속하지 않으므로 \\(H_0\\) 기각 못함. 즉, 회귀모형은 유의수준 0.1에서 유의하지 않다."
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-13",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-13",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(4)",
    "text": "(4)\n결정계수(\\(R^2\\))와 수정된 결정계수(\\(R^2_{sdj}\\)) 구하시오.\nanswer\n\\(R^2 = \\frac{SSR}{SST} = 0.7484, R^2_{adj} = 1-\\frac{SSE/(n-p-1)}{SST/(n-1)} = 0.5807\\)"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-14",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-14",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(5)",
    "text": "(5)\n오차항의 분산 \\(\\sigma^2\\)에 대한 추정치를 구하시오.\nanswer\n\\(\\hat{\\sigma}^2 = MSE = \\frac{SSE}{n-p-1} = 2.5855\\)"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-15",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-15",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(6)",
    "text": "(6)\n\\(\\hat{\\beta}_2\\)의 의미를 설명하고, 가설 \\(H_0: \\beta_2 = 0, H_1 : \\beta_2 &lt;0\\)을 \\(\\alpha = 0.05\\)로 검정하시오.\nanswer\n\\(X_1\\)이 일정할 떄, \\(X_2\\)가 1단위 증가하면 \\(y\\)는 \\(\\hat{\\beta}_2\\)만큼 증가한다.\n가설검정\n- \\(Var(\\hat{\\beta}_2) = (X^\\top X)^{-1}_{(3,3)} \\sigma^2 = 0.34 \\sigma^2\\)\n- \\(\\hat{s.e.}(\\hat{\\beta}_2) = \\sqrt{0.34 \\times MSE } = \\sqrt{0.34 \\times 2.5855} = 0.9376\\)\n- \\(t_0 = \\frac{-2.46}{0.9376} = -2.62372\\)\n- 기각역: \\(t_0 &lt; -t_{0.05}(3) = -2.35\\)\n- 결론: \\(H_0\\)기각 가능, 즉 0보다 작다고 할 수 있다.\n\nround(qt(0.05,3),2)\n\n-2.35"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-16",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-16",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(7)",
    "text": "(7)\n\\(\\beta_1\\)의 \\(90\\)% 신뢰구간을 구하시오.\nanswer\n\\(Var(\\hat{\\beta}_1) = (X^\\top X)^{-1}_{(2,2)} \\sigma^2 = 0.23 \\sigma^2\\)\n\\(\\hat{s.e.}(\\hat{\\beta}_1) = \\sqrt{0.23 \\times 2.5855} = 0.7711\\)\n\\(t_{0.5}(3) = 2.35\\)\n\\(\\hat{\\beta}_1 \\pm t_{0.05}(3)\\hat{s.e.}(\\hat{\\beta}_1) = (-0.3521,3.2721)\\)\n\nround(qt(0.95,3),2)\n\n2.35"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-17",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-17",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(8)",
    "text": "(8)\n\\(x_1 = x_2 = 2\\)에서 \\(E(y)\\)의 \\(95\\)% 신뢰구간을 구하시오.\nanswer\n\\(x_0 = \\begin{pmatrix} 1 \\\\ 2\\\\2\\end{pmatrix}\\)\n\\(\\hat{\\mu}_0 = x^\\top_0 \\mathbf{\\hat{\\beta}} = \\begin{pmatrix} 1 &2&2\\end{pmatrix}\\begin{pmatrix}3.16\\\\1.46\\\\-2.46\\end{pmatrix} = 1.16\\)\n\\(Var(\\hat{\\mu}_0) = x_0^\\top(X^\\top X)^{-1} x_0 \\sigma^2 = 0.24 \\sigma^2\\)\n\\(\\star x_0^\\top(X^\\top X)^{-1} x_0 = \\begin{pmatrix}1&2&2\\end{pmatrix}\\begin{pmatrix}1.52&-0.35&-0.36\\\\-0.35&0.23&-0.09\\\\-0.36&-0.09&0.34\\end{pmatrix} \\begin{pmatrix}1\\\\2\\\\2 \\end{pmatrix} = 0.24\\)\n\\(\\hat{s.e.}(\\hat{\\mu}_0) = \\sqrt{0.24 \\times 2.5855} = 0.7877\\)\n\\(1.16 \\pm t_{0.025}(3) \\hat{s.e.}(\\hat{\\mu}_0) = (-1.3449,3.6649)\\)\n\nround(qt(0.975,3),2)\n\n3.18"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-19",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-19",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(1)",
    "text": "(1)\n혈압을 예측하기 위하여 교호작용을 포함하는 중회귀모형을 정의하시오.(성별의 경우 남자=1)\nanswer\n\\(y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3x_{i1}x_{i2} + \\epsilon_i, \\epsilon_i, i=1,\\dots,10, \\epsilon_i \\sim_{i.i.d.}N(0,\\sigma^2)\\)\n\\(x_1\\) : 체중, \\(y\\): 혈압\n\\(x_2\\): 성별, \\(x_2 = \\begin{cases}1 & \\text{남자}\\\\0 & \\text{여자}\\end{cases}\\)"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-20",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-20",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(2)",
    "text": "(2)\n위의 모형을 행렬 형태로 표현하시오.(\\(X,\\mathbf{y,\\beta,\\epsilon}\\)을 정확하게 표현)\nanswer\n\\(\\mathbf{y} = X\\mathbf{\\beta + \\epsilon}, \\mathbf{\\epsilon} \\sim N(0,I_n\\sigma^2)\\)\n\\(\\mathbf{y} = \\begin{pmatrix}120\\\\130\\\\130\\\\155\\\\149\\\\150\\\\160\\\\125\\\\135\\\\140\\end{pmatrix}, X = \\begin{pmatrix}1& 70&1&70\\\\1&60&0&0\\\\1&88&1&88\\\\1&101&0&0\\\\1&80&0&0\\\\1&98&1&98\\\\1&90&0&0\\\\1&77&1&77\\\\1&65&0&0\\\\1&70&0&0 \\end{pmatrix}, \\mathbf{\\beta} = \\begin{pmatrix}\\beta_0\\\\ \\beta_1 \\\\ \\beta_2 \\end{pmatrix}, \\mathbf{\\epsilon} = \\begin{pmatrix}\\epsilon_1 \\\\ \\epsilon_2\\\\ \\epsilon_3\\\\ \\epsilon_4\\\\ \\epsilon_5\\\\ \\epsilon_6\\\\ \\epsilon_7\\\\ \\epsilon_8\\\\ \\epsilon_9\\\\ \\epsilon_{10} \\end{pmatrix}\\)"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-21",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-21",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(3)",
    "text": "(3)\n위 모형의 적합 결과가 다음과 같다고 하자. 빈 칸을 채워 넣으시오. 마지막 칸에는 개별회귀계수에 대한 유의성검정을 위한 가설과, 검정결과(기각, 기각못함)를 적으시오.(풀이 있어야 함) 그리고 분산분석표를 이용하여 회귀모형의 유의성 검정을 하시오.(유의수준 \\(\\alpha = 0.05\\))\nanswer\n\\[\\text{추정}\\]\n\n\n\n\n\n\n\n\n\n\n\nEstimate\nStd.Error\nt value\n검정결과\n\n\n\n\n절편\\(\\beta_0\\)\n\\(\\hat{\\beta}_0\\)=70.681\n10.779\n6.557\n기각\n\n\n체중\\(\\beta_1\\)\n\\(\\hat{\\beta}_1\\)=0.988\n0.1461\n6.763\n기각\n\n\n성별\\(\\beta_2\\)\n\\(\\hat{\\beta}_2\\)=-32.435\n15.830\n-2.049\n기각못함\n\n\n교호작용\\(\\beta_3\\)\n\\(\\hat{\\beta}_3\\)=0.138\n0.197\n0.702\n기각못함\n\n\n\n\\(t_0 = \\frac{\\hat{\\beta}_i}{\\hat{s.e.}(\\hat{\\beta}_i)}\\), 기각역 \\(|t_0| &gt; t_{\\alpha/2}(n-p-1) = t_{0.025}(6) = 2.45\\)\n\\(H_0: \\beta_i = 0, H_1: \\beta_i \\neq 0\\)\n\nround(qt(0.975,6),2)\n\n2.45\n\n\n\\[\\text{분산분석표}\\]\n\n\n\n\n\n\n\n\n\n\n요인\n제곱합(SS)\n자유도(df)\n평균제곱(MS)\n\\(F_0\\)\n\n\n\n\n회귀\n1578.14\n3\n526.0467\n42.5031\n\n\n잔차\n74.26\n6\n12.3767\n\n\n\n계\n1652.4\n9\n\n\n\n\n\n\\(H_0 : \\beta_1 = \\beta_2 = \\beta_3 = 0 \\text{ vs. } H_1 \\text{ not } H_0\\)\n\\(F_0 &gt; F_{\\alpha}(p,n-p-1) = F_{0.05}(3,6) = 4.76\\)\n이므로 \\(H_0\\)기각 가능, 즉 유의수준 0.05에서 회귀직선 유의"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-22",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-22",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(4)",
    "text": "(4)\n(3)의 결과를 보고, 결정계수(\\(R^2\\)) 와 수정된 결정계수(\\(R^2_{sdj}\\)) 구하시오.\nanswer\n\\(R^2 = \\frac{SSR}{SST} = 0.9551, R^2_{adj} = 1-\\frac{SSE/(n-p-1)}{SST/(n-1)} = 0.9326\\)\n\nround(1578.14/1652.4,4)\n\n0.9551\n\n\n\nround(1-(74.26/6)/(1652.4/9),4)\n\n0.9326"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-23",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-23",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(5)",
    "text": "(5)\n(3)번의 결과를 보고 모형 적합 결과를 설명하여라.(각 회귀계수의 의미와 유의성 검정 결과)\nanswer\n\\(E(y|\\text{남성}) = \\beta_0 + \\beta_1 x_1+\\beta_2+\\beta_3x_1 = (\\beta_0+\\beta_2) + (\\beta_1 + \\beta_3)x_1\\)\n\\(E(y|\\text{여성}) = \\beta_0 + \\beta_1x_1\\)\n\\(\\hat{\\beta}_2\\): 유의하지 않음: 남성과 여성의 절편 차이 없음\n\\(\\hat{\\beta}_3\\): 유의하지 않음: 남성과 여성의 기울기 차이 없음\nanswer"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-24",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-24",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(6)",
    "text": "(6)\n이번에는 교호작용을 제외한 모형을 적합해 보았다. 모형을 정의하여라.\nanswer\n\\(y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\epsilon_i , i=1,\\dots, 10, \\epsilon_i \\sim N(0,\\sigma^2)\\)"
  },
  {
    "objectID": "posts/rl/2023-02-23-rl-final_term.html#section-25",
    "href": "posts/rl/2023-02-23-rl-final_term.html#section-25",
    "title": "Advanced Regression Analysis Final Term",
    "section": "(7)",
    "text": "(7)\n(7)번의 결과가 다음과 같을 때, 빈 칸을 채우고 적합 결과에 대해 설명하여라. (3)번 참고.\nanswer\n\n\n\n\n\n\n\n\n\n\n\nEstimate\nStd.Error\nt value\n검정결과\n\n\n\n\n절편\n65.137\n7.059\n9.227\n기각\n\n\n체중\n1.064\n0.094\n11.264\n기각\n\n\n성별\n-21.482\n2.508\n-8.565\n기각\n\n\n\n\\(H_0: \\beta_i = 0 \\text{ vs. } H_1 : \\beta_i \\neq 0, i=1,2,3\\)\n기각역: \\(|t_0| &gt; t_{\\alpha/2}(n-p-1) = t_{0.025}(7) = 2.36\\)\n\\(E(y|\\text{남성}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 = \\beta_0 + \\beta_2 + \\beta_1 x_1\\)\n\\(E(y|\\text{여성}) = \\beta_0 + \\beta_1x_1\\)\n\\(H_0:\\beta_2\\neq 0\\)을 기각할 수 있으므로, 성별에 따른 평균 혈압이 다르다고 할 수 있다.\n\nround(qt(0.975,7),2)\n\n2.36\n\n\n\ny &lt;- c(120,130,130,155,149,150,160,125,135,140) # 혈압\nx1 &lt;- c(70,60,88,101,80,98,90,77,65,70) # 체중\nx2 &lt;- c(1,0,1,0,0,1,0,1,0,0) # 성별, 남, 여, 남, 여, 여, 남, 여, 남, 여, 여\ndf &lt;- data.frame(y,x1,x2)\nanova(lm(y~x1+x2,df))\n\n\nA anova: 3 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nx1\n1\n729.9696\n729.96957\n27.92185\n0.001142928\n\n\nx2\n1\n739.4272\n739.42724\n28.28361\n0.001101377\n\n\nResiduals\n7\n183.0032\n26.14331\nNA\nNA"
  },
  {
    "objectID": "posts/rl/2022-11-14-rl_CH06, CH07.html",
    "href": "posts/rl/2022-11-14-rl_CH06, CH07.html",
    "title": "고급회귀분석 실습 CH06, CH07",
    "section": "",
    "text": "chapter 6, chapter 7\n\nlibrary(MASS)\n\n\ndata(Boston)\n\n\nhead(Boston)\n\n\nA data.frame: 6 × 14\n\n\n\ncrim\nzn\nindus\nchas\nnox\nrm\nage\ndis\nrad\ntax\nptratio\nblack\nlstat\nmedv\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n0.00632\n18\n2.31\n0\n0.538\n6.575\n65.2\n4.0900\n1\n296\n15.3\n396.90\n4.98\n24.0\n\n\n2\n0.02731\n0\n7.07\n0\n0.469\n6.421\n78.9\n4.9671\n2\n242\n17.8\n396.90\n9.14\n21.6\n\n\n3\n0.02729\n0\n7.07\n0\n0.469\n7.185\n61.1\n4.9671\n2\n242\n17.8\n392.83\n4.03\n34.7\n\n\n4\n0.03237\n0\n2.18\n0\n0.458\n6.998\n45.8\n6.0622\n3\n222\n18.7\n394.63\n2.94\n33.4\n\n\n5\n0.06905\n0\n2.18\n0\n0.458\n7.147\n54.2\n6.0622\n3\n222\n18.7\n396.90\n5.33\n36.2\n\n\n6\n0.02985\n0\n2.18\n0\n0.458\n6.430\n58.7\n6.0622\n3\n222\n18.7\n394.12\n5.21\n28.7\n\n\n\n\n\n\nnrow(Boston)\n\n506\n\n\n보스턴 집값 데이터 이 데이터는 보스턴 근교 지역의 집값 및 다른 정보를 포함한다.\nMASS 패키지를 설치하면 데이터를 로딩할 수 있다.\nB보스턴 근교 506개 지역에 대한 범죄율 (crim)등 14개의 변수로 구성\n• crim : 범죄율\n• zn: 25,000평방비트 기준 거지주 비율\n• indus: 비소매업종 점유 구역 비율\n• chas: 찰스강 인접 여부 (1=인접, 0=비인접)\n• nox: 일산화질소 농도 (천만개 당)\n• rm: 거주지의 평균 방 갯수 ***\n• age: 1940년 이전에 건축된 주택의 비율\n• dis: 보스턴 5대 사업지구와의 거리\n• rad: 고속도로 진입용이성 정도\n• tax: 재산세율 (10,000달러 당)\n• ptratio: 학생 대 교사 비율\n• black: 1000(B − 0.63)2, B: 아프리카계 미국인 비율\n• lstat : 저소득층 비율 ****\n• medv: 주택가격의 중앙값 (단위:1,000달러 당)\n\n데이터 세 변수만 가지고 산점도 그려보기\n음의 상관관계가 있는 것 같기도 하고~\n\n\npairs(Boston[,which(names(Boston) %in% c('medv', 'rm', 'lstat'))], pch=16, col='darkorange')\n\n\n\n\n\nlm(y ~ x_1 + x_2, data)\n\n\nfit_Boston&lt;-lm(medv~rm+lstat, data=Boston)\n\n\nF-statistic: 444.3 on 2 and 503 DF,  p-value: &lt; 2.2e-16\nR-squared:  0.6386\n\n집값 y의 총변동 중에 회귀모형이 63.86%정도 설명하고 있다.\n\nAdjusted R-squared:  0.6371\n\n설명변수가 증가하면 R-squared값이 증가하는 현상때문에 수정된 R-squared값이 필요\n모형 비교시 Adjusted R-squared가 나을 수도 있음\n\nrm,lstat의 p-value &lt;2e-16\n\n\nsummary(fit_Boston)\n\n\nCall:\nlm(formula = medv ~ rm + lstat, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-18.076  -3.516  -1.010   1.909  28.131 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.35827    3.17283  -0.428    0.669    \nrm           5.09479    0.44447  11.463   &lt;2e-16 ***\nlstat       -0.64236    0.04373 -14.689   &lt;2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 5.54 on 503 degrees of freedom\nMultiple R-squared:  0.6386,    Adjusted R-squared:  0.6371 \nF-statistic: 444.3 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\n\n\n원하는 변수만 추출해내서 회귀분석 진행가능\n\n\ndt &lt;- Boston[,which(names(Boston) %in% c('medv', 'rm', 'lstat'))]\n\n\nhead(dt)\n\n\nA data.frame: 6 × 3\n\n\n\nrm\nlstat\nmedv\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n6.575\n4.98\n24.0\n\n\n2\n6.421\n9.14\n21.6\n\n\n3\n7.185\n4.03\n34.7\n\n\n4\n6.998\n2.94\n33.4\n\n\n5\n7.147\n5.33\n36.2\n\n\n6\n6.430\n5.21\n28.7\n\n\n\n\n\n\n. 쓰면 설명변수 다 쓰겠다는 의미\n\n\nfit_Boston&lt;-lm(medv~., data=dt)\n\n\\(\\hat{y} = -1.3583 + 5.0948*rm - 0.6424*lstat\\)\n\n저소득층이 변하지 않고 방이 하나 더 증가한다면 집값의 중앙값은 5.0948 정도 증가한다.\n방의 수는 변하지 않고 저소득층이 증가한다면 집값의 중앙값은 0.6424 정도 감소한다.\nSSR = 41308.84 = 20654.42 + 20654.42\n밑의 F 통계량이 아니라 summary 의 F 통계량을 봐야 한다.\n\n\nanova(fit_Boston)\n\n\nA anova: 3 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nrm\n1\n20654.42\n20654.41622\n672.9039\n8.266887e-95\n\n\nlstat\n1\n6622.57\n6622.56999\n215.7579\n6.669365e-41\n\n\nResiduals\n503\n15439.31\n30.69445\nNA\nNA\n\n\n\n\n\n\\(var(\\hat{\\beta}) = (X^TX)^{-1} \\sigma^2\\)\n\nvcov(fit_Boston)  \n\n\nA matrix: 3 × 3 of type dbl\n\n\n\n(Intercept)\nrm\nlstat\n\n\n\n\n(Intercept)\n10.06683612\n-1.39248641\n-0.099178133\n\n\nrm\n-1.39248641\n0.19754958\n0.011930670\n\n\nlstat\n-0.09917813\n0.01193067\n0.001912441\n\n\n\n\n\n\nconfint(fit_Boston, level = 0.95)\n\n\nA matrix: 3 × 2 of type dbl\n\n\n\n2.5 %\n97.5 %\n\n\n\n\n(Intercept)\n-7.5919003\n4.8753547\n\n\nrm\n4.2215504\n5.9680255\n\n\nlstat\n-0.7282772\n-0.5564395\n\n\n\n\n\n\ncoef(fit_Boston) + qt(0.975, 503) * summary(fit_Boston)$coef[,2]\n\n(Intercept)4.87535465808389rm5.96802553290791lstat-0.556439501179164\n\n\n\ncoef(fit_Boston) - qt(0.975, 503) * summary(fit_Boston)$coef[,2]\n\n(Intercept)-7.59190028183298rm4.22155043576519lstat-0.728277167309095\n\n\n평균반응, 개별 y 추정\n\\(E(Y|x_0), y = E(Y|x_0) + \\epsilon\\)\n\nnew_dt &lt;- data.frame(rm=7, lstat=10)\n\n\\(\\hat{y}_0 = -1.3583 + 5.0948*7 - 0.6424*10\\)\n\npredict(fit_Boston, newdata = new_dt)\n\n1: 27.88165973604\n\n\n평균반응\n\npredict(fit_Boston, \n        newdata = new_dt,\n        interval = c(\"confidence\"), \n        level = 0.95)  \n\n\nA matrix: 1 × 3 of type dbl\n\n\n\nfit\nlwr\nupr\n\n\n\n\n1\n27.88166\n27.17347\n28.58985\n\n\n\n\n\n개별 y\n\npredict(fit_Boston, newdata = new_dt, \n        interval = c(\"prediction\"), \n        level = 0.95)  \n\n\nA matrix: 1 × 3 of type dbl\n\n\n\nfit\nlwr\nupr\n\n\n\n\n1\n27.88166\n16.97375\n38.78957\n\n\n\n\n\n\nfit은 같고 lwr,upr만 달라진다.\n\n잔차분석\n\\(\\epsilon\\) : 선형성, 등분산성, 정규성, 독립성\nyhat &lt;- fitted_values(fit_Boston)\n\nyhat &lt;- fitted(fit_Boston)\n\n\nres &lt;- resid(fit_Boston)\n\n잔차그림 - 대칭 아니다 - u 턴 커브 모형이다. - 애초에 산점도에서도 커브가 보였다. - 나중에 제곱텀 넣어볼 예정\n\nplot(res ~ yhat,pch=16, ylab = 'Residual')\nabline(h=0, lty=2, col='grey')\n\n\n\n\n\n제곱텀 필요해보인다.\n\n\nplot(res ~ dt$rm,pch=16, ylab = 'Residual')\nabline(h=0, lty=2, col='grey')\n\n\n\n\n\n제곱텀 필요해보인다.\n\n\nplot(res ~ dt$lstat,pch=16, ylab = 'Residual')\nabline(h=0, lty=2, col='grey')\n\n\n\n\n독립성검정 : DW test\n\nlibrary(lmtest)\n\n\\(H_0 : \\text{ uncorrelated vs } H_1 : \\rho \\neq 0\\)\n\ndwtest(fit_Boston, alternative = \"two.sided\")  \n\n\n    Durbin-Watson test\n\ndata:  fit_Boston\nDW = 0.83421, p-value &lt; 2.2e-16\nalternative hypothesis: true autocorrelation is not 0\n\n\n\np-value &lt; 2.2e-16로 귀무가설 기각한다. 잔차는 독립이 아니다.\n\n잔차의 QQ plot\n정규성 확인 결과도 좋지 않음\n\nqqnorm(res, pch=16)\nqqline(res, col = 2)\n\n\n\n\n\nhead(dt)\n\n\nA data.frame: 6 × 3\n\n\n\nrm\nlstat\nmedv\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n6.575\n4.98\n24.0\n\n\n2\n6.421\n9.14\n21.6\n\n\n3\n7.185\n4.03\n34.7\n\n\n4\n6.998\n2.94\n33.4\n\n\n5\n7.147\n5.33\n36.2\n\n\n6\n6.430\n5.21\n28.7\n\n\n\n\n\n\ndt$lstat2 &lt;- (dt$lstat)^2\n\n\nhead(dt)\n\n\nA data.frame: 6 × 4\n\n\n\nrm\nlstat\nmedv\nlstat2\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n6.575\n4.98\n24.0\n24.8004\n\n\n2\n6.421\n9.14\n21.6\n83.5396\n\n\n3\n7.185\n4.03\n34.7\n16.2409\n\n\n4\n6.998\n2.94\n33.4\n8.6436\n\n\n5\n7.147\n5.33\n36.2\n28.4089\n\n\n6\n6.430\n5.21\n28.7\n27.1441\n\n\n\n\n\n1번 방법\n\nfit_Boston2&lt;-lm(medv~., data=dt)\n\n# 이렇게 쓰면 위에와 결과 같음\nfit_Boston2&lt;-lm(medv~rm+lstat+lstat^2, data=Boston)\n2번 방법 변수 생성 없이 수행가능\n\nfit_Boston2&lt;-lm(medv~rm+lstat+I(lstat^2), data=Boston)\n\n\nAdjusted R-squared:  0.7013이 63%에서 증가한 모습\n\n\nsummary(fit_Boston2)\n\n\nCall:\nlm(formula = medv ~ rm + lstat + I(lstat^2), data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1427  -3.2429  -0.4829   2.3607  27.0256 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 11.68964    3.13810   3.725 0.000217 ***\nrm           4.22727    0.41172  10.267  &lt; 2e-16 ***\nlstat       -1.84863    0.12213 -15.136  &lt; 2e-16 ***\nI(lstat^2)   0.03634    0.00348  10.443  &lt; 2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 5.027 on 502 degrees of freedom\nMultiple R-squared:  0.7031,    Adjusted R-squared:  0.7013 \nF-statistic: 396.2 on 3 and 502 DF,  p-value: &lt; 2.2e-16\n\n\n\nyhat2 &lt;- fitted.values(fit_Boston2)\n\n\nres2 &lt;- resid(fit_Boston2)\n\n\n곡선 느낌은 사라지고 outlier는 보이고 있다.\n\n\nplot(res2 ~ yhat2,pch=16, ylab = 'Residual')\nabline(h=0, lty=2, col='grey')\n\n\n\n\n\n꼬리가 죽은 모습\n\n\nqqnorm(res2, pch=16)\nqqline(res2, col = 2)\n\n\n\n\n\\(H_0 : \\text{ uncorrelated vs } H_1 : \\rho \\neq 0\\)\n\ndwtest(fit_Boston2, alternative = \"two.sided\")\n\n\n    Durbin-Watson test\n\ndata:  fit_Boston2\nDW = 0.84831, p-value &lt; 2.2e-16\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n여전히 잔차가 독립이 아니고 기각한다.\n\n\nfit_Boston3 &lt;- lm(medv~rm, data=Boston)\n\n\nfit_Boston4 &lt;- lm(medv~lstat, data=Boston)\n\n\nsummary(fit_Boston3)\n\n\nCall:\nlm(formula = medv ~ rm, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-23.346  -2.547   0.090   2.986  39.433 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -34.671      2.650  -13.08   &lt;2e-16 ***\nrm             9.102      0.419   21.72   &lt;2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 6.616 on 504 degrees of freedom\nMultiple R-squared:  0.4835,    Adjusted R-squared:  0.4825 \nF-statistic: 471.8 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\n\n\nsummary(fit_Boston4)\n\n\nCall:\nlm(formula = medv ~ lstat, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 34.55384    0.56263   61.41   &lt;2e-16 ***\nlstat       -0.95005    0.03873  -24.53   &lt;2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\n\n\nx1&lt;-c(4,8,9,8,8,12,6,10,6,9)\nx2&lt;-c(4,10,8,5,10,15,8,13,5,12)\ny&lt;-c(9,20,22,15,17,30,18,25,10,20)\n\nFM\n\nfit&lt;-lm(y~x1+x2)\n\n\nsummary(fit)\n\n\nCall:\nlm(formula = y ~ x1 + x2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.4575 -1.9100  0.3314  0.6388  3.2628 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  -0.6507     2.9075  -0.224   0.8293  \nx1            1.5515     0.6462   2.401   0.0474 *\nx2            0.7599     0.3968   1.915   0.0970 .\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 2.278 on 7 degrees of freedom\nMultiple R-squared:  0.9014,    Adjusted R-squared:  0.8732 \nF-statistic:    32 on 2 and 7 DF,  p-value: 0.0003011\n\n\n\nanova(fit)\n\n\nA anova: 3 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nx1\n1\n313.04348\n313.043478\n60.323103\n0.0001100467\n\n\nx2\n1\n19.03040\n19.030400\n3.667135\n0.0970444465\n\n\nResiduals\n7\n36.32612\n5.189446\nNA\nNA\n\n\n\n\n\ninstall.packages(\"car\")\n\nlibrary(car)\n\n\\(H_0 : T\\times\\beta = c\\)\n$b_1-b_2=0 (0,1,-1) $\n\\(H_0 : \\beta_1 = \\beta_2\\)\n\nlinearHypothesis(fit, c(0,1,-1), 0)\n\n\nA anova: 2 × 6\n\n\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n8\n39.53514\nNA\nNA\nNA\nNA\n\n\n2\n7\n36.32612\n1\n3.209014\n0.6183731\n0.4574425\n\n\n\n\n\n\n제약조건, T matrix c(0,1,-1)\nc = 0\n\n\n3.209014 / (36.32612/7)\n\n0.618373170600108\n\n\n같다~\n\\(H_0 : \\beta_1 = 1\\)\n\nlinearHypothesis(fit, c(0,1,0), 1)\n\n\nA anova: 2 × 6\n\n\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n8\n40.10492\nNA\nNA\nNA\nNA\n\n\n2\n7\n36.32612\n1\n3.778797\n0.7281696\n0.4217136\n\n\n\n\n\n\n기각하지 못함\n\n\\(H_0 : \\beta_1 = \\beta_2 + 1\\)\n\nlinearHypothesis(fit, c(0,1,-1), 1)\n\n\nA anova: 2 × 6\n\n\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n8\n36.54865\nNA\nNA\nNA\nNA\n\n\n2\n7\n36.32612\n1\n0.2225273\n0.04288074\n0.841845\n\n\n\n\n\n\nF0\n\n0.0428807391894599\n\n\n\\(H_0 : \\beta_1 = \\beta_2 + 1\\)\n\\(y = b_0 + b_1x_1 + b_2x_2 + \\epsilon = b_0+x_1 + b_2(x_1+x_2)+\\epsilon\\)\n\\(y-x_1 = b_0+b_2(x_1+x_2)+\\epsilon\\) : RM\n\ny1 &lt;- y-x1\nz1 &lt;- x1 + x2\n\n\nfit2 &lt;- lm(y1~z1)\n\n\nsummary(fit2)\n\n\nCall:\nlm(formula = y1 ~ z1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.5054 -1.9294  0.4236  0.6821  3.4473 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -1.0014     2.2175  -0.452 0.663574    \nz1            0.6824     0.1242   5.493 0.000578 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 2.137 on 8 degrees of freedom\nMultiple R-squared:  0.7904,    Adjusted R-squared:  0.7642 \nF-statistic: 30.17 on 1 and 8 DF,  p-value: 0.0005785\n\n\n\nanova(fit2)\n\n\nA anova: 2 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nz1\n1\n137.85135\n137.851351\n30.17378\n0.0005784583\n\n\nResiduals\n8\n36.54865\n4.568581\nNA\nNA\n\n\n\n\n\nFM\n\nanova(fit)  \n\n\nA anova: 3 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nx1\n1\n313.04348\n313.043478\n60.323103\n0.0001100467\n\n\nx2\n1\n19.03040\n19.030400\n3.667135\n0.0970444465\n\n\nResiduals\n7\n36.32612\n5.189446\nNA\nNA\n\n\n\n\n\nRM\n\nanova(fit2)  \n\n\nA anova: 2 × 5\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nz1\n1\n137.85135\n137.851351\n30.17378\n0.0005784583\n\n\nResiduals\n8\n36.54865\n4.568581\nNA\nNA\n\n\n\n\n\n\\(F = {(SSE_RM - SSE_FM)/r} / {SSE_FM/(n-p-1)}\\)\nSSE_FM\n\nSSE_FM &lt;- anova(fit)$Sum[3]  \n\nSSE_RM\n\nSSE_RM &lt;- anova(fit2)$Sum[2]  \n\n\nF0 &lt;- (SSE_RM-SSE_FM)/(SSE_FM/7)\nF0\n\n0.0428807391894599\n\n\n기각역 \\(F_{0.05}(1,7)\\)\n\nqf(0.95, 1, 7)\n\n5.59144785122073\n\n\n기각할 수 없다.\\(\\beta_1\\)은 \\(\\beta_2\\)에 1 더한 값과 같다."
  },
  {
    "objectID": "posts/ml/index.html",
    "href": "posts/ml/index.html",
    "title": "Special Topics in Machine Learning",
    "section": "",
    "text": "Those are posts of Special Topics in Machine Learning."
  },
  {
    "objectID": "posts/ml/2022-11-09-ml-10w.html",
    "href": "posts/ml/2022-11-09-ml-10w.html",
    "title": "RNN (10주차)",
    "section": "",
    "text": "기계학습 특강 (10주차) 11월9일 [순환신경망– abc예제, abdc예제, abcde예제, AbAcAd예제]"
  },
  {
    "objectID": "posts/ml/2022-11-09-ml-10w.html#import",
    "href": "posts/ml/2022-11-09-ml-10w.html#import",
    "title": "RNN (10주차)",
    "section": "import",
    "text": "import\n\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n선행학습\n\nfor i in '123':\n    print(i)\n\n1\n2\n3\n\n\niterable object?\n\na = 3\nfor i in a:\n    print(i)\n\nTypeError: 'int' object is not iterable\n\n\n\na__iter__()\n\nNameError: name 'a__iter__' is not defined\n\n\n\nset(dir(a)) & {'__iter__'}\n\nset()\n\n\n이게 없어\n\na = '3'\nfor i in a:\n    print(i)\n\n3\n\n\n\nset(dir(a)) & {'__iter__'}\n\n{'__iter__'}\n\n\n이제 있음\n\na = [1,2,3]\nfor i in a:\n    print(i)\n\n1\n2\n3\n\n\n\nset(dir(a)) & {'__iter__'}\n\n{'__iter__'}\n\n\n\na.__iter__()\n\n&lt;list_iterator at 0x7f0f0e2b8bd0&gt;\n\n\n\naa = iter(a)\n\n\naa.__next__()\n\n1\n\n\n\naa.__next__()\n\n2\n\n\n\naa.__next__()\n\n3\n\n\n\naa.__next__()\n\nStopIteration: \n\n\nStopIteration iter 끝내는 옵션\n\na = range(3)\nfor i in a:\n    print(i)\n\n0\n1\n2\n\n\n\naa = a.__iter__()\n\n\naa.__next__()\n\n0\n\n\n\naa.__next__()\n\n1\n\n\n\naa.__next__()\n\n2\n\n\n\naa.__next__()\n\nStopIteration:"
  },
  {
    "objectID": "posts/ml/2022-11-09-ml-10w.html#예비학습-net.parameters의-의미",
    "href": "posts/ml/2022-11-09-ml-10w.html#예비학습-net.parameters의-의미",
    "title": "RNN (10주차)",
    "section": "예비학습: net.parameters()의 의미",
    "text": "예비학습: net.parameters()의 의미\n9월27일 강의노트 중 “net.parameters()의 의미?”를 설명한다.\n- iterator, generator의 개념필요 - https://guebin.github.io/IP2022/2022/06/06/(14주차)-6월6일.html, 클래스공부 8단계 참고\n- 탐구시작: 네트워크 생성\n\nnet = torch.nn.Linear(in_features=1,out_features=1)\nnet.weight\n\nParameter containing:\ntensor([[0.7520]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([-0.8206], requires_grad=True)\n\n\n- torch.optim.SGD? 를 확인하면 params에 대한설명에 아래와 같이 되어있음\nparams (iterable): iterable of parameters to optimize or dicts defining\n        parameter groups\n\nnet.parameters() ## generator = \n\n&lt;generator object Module.parameters at 0x7f6e8ac0f9d0&gt;\n\n\n- 설명을 읽어보면 params에 iterable object를 넣으라고 되어있음 (iterable object는 숨겨진 명령어로 __iter__를 가지고 있는 오브젝트를 의미)\n\nset(dir(net.parameters())) & {'__iter__'}\n\n{'__iter__'}\n\n\n- 무슨의미?\n\nfor param in net.parameters():\n    print(param)\n\nParameter containing:\ntensor([[0.7520]], requires_grad=True)\nParameter containing:\ntensor([-0.8206], requires_grad=True)\n\n\n- 그냥 이건 이런느낌인데?\n\nfor param in [net.weight,net.bias]:\n    print(param)\n\nParameter containing:\ntensor([[0.7520]], requires_grad=True)\nParameter containing:\ntensor([-0.8206], requires_grad=True)\n\n\n결론: net.parameters()는 net오브젝트에서 학습할 파라메터를 모두 모아 리스트같은 iterable object로 만드는 함수라 이해할 수 있다.\nyhat = net(x)\n꼭 이런 식으로 정의할 필요는 없다\n- 응용예제1\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022_backup/master/_notebooks/2022-09-22-regression.csv\") \nx=torch.tensor(df.x).float().reshape(100,1)\ny=torch.tensor(df.y).float().reshape(100,1)\n\n\nb = torch.tensor(-5.0,requires_grad=True)\nw = torch.tensor(10.0,requires_grad=True)\noptimizr = torch.optim.SGD([b,w],lr=1/10) ## 이렇게 전달하면 됩니당!!\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(w*x+b).data,'--')\n\n\n\n\n\nfor epoc in range(30):\n    ## step1\n    yhat = b+ w*x \n    ## step2\n    loss = torch.mean((y-yhat)**2)\n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(w*x+b).data,'--')\n\n\n\n\n- 응용예제2\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022_backup/master/_notebooks/2022-09-22-regression.csv\") \nx = torch.tensor(df.x).float().reshape(100,1)\ny = torch.tensor(df.y).float().reshape(100,1)\nX = torch.concat([torch.ones_like(x),x],axis=1)\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\noptimizr = torch.optim.SGD([What],lr=1/10) # What은 iterable 하지 않지만 [What]은 iterable 함\n\n\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(X@What).data,'--')\n\n\n\n\n\nfor epoc in range(30):\n    ## step1\n    yhat = X@What \n    ## step2 \n    loss = torch.mean((y-yhat)**2)\n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\nplt.plot(x,y,'o')\nplt.plot(x,(X@What).data,'--')\n\n\n\n\n\n스스로 학습 (중간고사 대체과제)\n아래와 같은 자료가 있다고 가정하자.\n\nx = torch.rand([1000,1])*2-1\ny = 3.14 + 6.28*x + torch.randn([1000,1]) \n\n\nplt.plot(x,y,'o',alpha=0.1)\n\n\n\n\n아래의 모형을 가정하고 \\(\\alpha_0,\\alpha_1,\\beta_0,\\beta_1\\)을 파이토치를 이용하여 추정하고자한다.\n\n\\(y_i = \\alpha_0+\\beta_0+ \\beta_1x_i + \\alpha_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n아래는 이를 수행하기 위한 코드이다. ???를 적절히 채워서 코드를 완성하라.\n\nalpha0 = torch.tensor([0.5], requires_grad=True)\nalpha1 = torch.tensor([[0.5]], requires_grad=True)\nbeta0 = torch.tensor([0.7], requires_grad=True)\nbeta1 = torch.tensor([[0.7]], requires_grad=True)\n\n\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD([alpha0,alpha1,beta0,beta1], lr=1/10)\n\n\nfor epoc in range(30):\n    ## 1\n    yhat = alpha0 + beta0 + alpha1*x + beta1*x \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nprint(alpha0+beta0)\n\ntensor([3.1279], grad_fn=&lt;AddBackward0&gt;)\n\n\n\n3.14 근처\n\n\nprint(alpha1+beta1)\n\ntensor([[6.0170]], grad_fn=&lt;AddBackward0&gt;)\n\n\n\n6.28 근처"
  },
  {
    "objectID": "posts/ml/2022-11-09-ml-10w.html#define-some-funtions",
    "href": "posts/ml/2022-11-09-ml-10w.html#define-some-funtions",
    "title": "RNN (10주차)",
    "section": "Define some funtions",
    "text": "Define some funtions\n\ndef f(txt,mapping):\n    return [mapping[key] for key in txt] \nsoft = torch.nn.Softmax(dim=1)"
  },
  {
    "objectID": "posts/ml/2022-11-09-ml-10w.html#exam2-abc",
    "href": "posts/ml/2022-11-09-ml-10w.html#exam2-abc",
    "title": "RNN (10주차)",
    "section": "Exam2: abc",
    "text": "Exam2: abc\n\ndata\n\ntxt = list('abc')*100\ntxt[:10]\n\n['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'a']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['a', 'b', 'c', 'a', 'b'], ['b', 'c', 'a', 'b', 'c'])\n\n\n\n\n하나의 은닉노드를 이용한 풀이 – 억지로 성공\n- 데이터정리\n\nmapping = {'a':0,'b':1,'c':2}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 0, 1]), tensor([1, 2, 0, 1, 2]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=3,embedding_dim=1),\n    torch.nn.Tanh(),\n    #===#\n    torch.nn.Linear(in_features=1,out_features=3)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    ## 2 \n    loss = loss_fn(net(x),y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\nnet[0] = embedding\nnet[1] = tanh\nnet[2] = linear\n- 결과해석\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nplt.plot(hidden[:9],'--o')\n\n\n\n\n\na blue\nb orange\nc green\n\n\nplt.plot(net(x).data[:9],'--o')\n\n\n\n\n\nplt.plot(yhat[:9],'--o')\n\n\n\n\n\n억지로 맞추고있긴한데 파라메터가 부족해보인다.\n\n- 결과시각화1\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n\n학습이 제대로 되었다면 0의 결과가 나오지 않지\nnet진행될때 거의 w만 곱한 결과가 나오는 것인데 0이 hidden에서 나오면 w만 곱해도 변화가 없잖아? 그래서 주황색 선이 나온 거고\n\n- 첫번째 그림 \\(\\to\\) 두번빼 그림\n\nnet[2].weight,net[2].bias\n\n(Parameter containing:\n tensor([[-4.6804],\n         [ 0.3071],\n         [ 5.2894]], requires_grad=True),\n Parameter containing:\n tensor([-1.5440,  0.9143, -1.3970], requires_grad=True))\n\n\n\nhidden[:9], (net[-1].weight.data).T, net[-1].bias.data\n\n(tensor([[-0.0147],\n         [ 0.9653],\n         [-0.9896],\n         [-0.0147],\n         [ 0.9653],\n         [-0.9896],\n         [-0.0147],\n         [ 0.9653],\n         [-0.9896]]),\n tensor([[-4.6804,  0.3071,  5.2894]]),\n tensor([-1.5440,  0.9143, -1.3970]))\n\n\n\nhidden[:9].shape\n\ntorch.Size([9, 1])\n\n\n\nnet[-1].weight.data.shape\n\ntorch.Size([3, 1])\n\n\n\n(net[-1].weight.data.T).shape\n\ntorch.Size([1, 3])\n\n\n\nhidden[:9]@(net[-1].weight.data).T + net[-1].bias.data\n\ntensor([[-1.4755,  0.9098, -1.4745],\n        [-6.0618,  1.2108,  3.7086],\n        [ 3.0875,  0.6104, -6.6312],\n        [-1.4755,  0.9098, -1.4745],\n        [-6.0618,  1.2108,  3.7086],\n        [ 3.0875,  0.6104, -6.6312],\n        [-1.4755,  0.9098, -1.4745],\n        [-6.0618,  1.2108,  3.7086],\n        [ 3.0875,  0.6104, -6.6312]])\n\n\n\n(파랑,주황,초록) 순서로 그려짐\n파랑 = hidden * (-4.6804) + (-1.5440)\n주황 = hidden * (0.3071) + (0.9143)\n초록 = hidden * (5.2894) + (-1.3970)\n\n- 내부동작을 잘 뜯어보니까 사실 엉성해. 엄청 위태위태하게 맞추고 있었음. - weight: 파랑과 초록을 구분하는 역할을 함 - weight + bias: 뭔가 교모하게 애매한 주황값을 만들어서 애매하게 ’b’라고 나올 확률을 학습시킨다. \\(\\to\\) 사실 학습하는 것 같지 않고 때려 맞추는 느낌, 쓸수있는 weight가 한정적이라서 생기는 현상 (양수,음수,0)\n\n참고: torch.nn.Linear()의 비밀? - 사실 \\({\\boldsymbol y}={\\boldsymbol x}{\\bf W} + {\\boldsymbol b}\\) 꼴에서의 \\({\\bf W}\\)와 \\({\\boldsymbol b}\\)가 저장되는게 아니다. - \\({\\boldsymbol y}={\\boldsymbol x}{\\bf A}^T + {\\boldsymbol b}\\) 꼴에서의 \\({\\bf A}\\)와 \\({\\boldsymbol b}\\)가 저장된다. - \\({\\bf W} = {\\bf A}^T\\) 인 관계에 있으므로 l1.weight 가 우리가 생각하는 \\({\\bf W}\\) 로 해석하려면 사실 transpose를 취해줘야 한다.\n왜 이렇게..? - 계산의 효율성 때문 (numpy의 구조를 알아야함) - \\({\\boldsymbol x}\\), \\({\\boldsymbol y}\\) 는 수학적으로는 col-vec 이지만 메모리에 저장할시에는 row-vec 로 해석하는 것이 자연스럽다. (사실 메모리는 격자모양으로 되어있지 않음)\n잠깐 딴소리!!\n(예시1)\n\n_arr = np.array(range(4)).reshape(2,2)\n_arr\n\narray([[0, 1],\n       [2, 3]])\n\n\n\n_arr.strides\n\n(16, 8)\n\n\n\n아래로 한칸 = 16칸 jump\n오른쪽으로 한칸 = 8칸 jump\n\n(예시2)\n\n_arr = np.array(range(6)).reshape(3,2)\n_arr\n\narray([[0, 1],\n       [2, 3],\n       [4, 5]])\n\n\n\n_arr.strides\n\n(16, 8)\n\n\n\n아래로 한칸 = 16칸 jump\n오른쪽으로 한칸 = 8칸 jump\n\n(예시3)\n\n_arr = np.array(range(6)).reshape(2,3)\n_arr\n\narray([[0, 1, 2],\n       [3, 4, 5]])\n\n\n\n_arr.strides\n\n(24, 8)\n\n\n\n아래로 한칸 = 24칸 jump\n오른쪽으로 한칸 = 8칸 jump\n\n(예시4)\n\n_arr = np.array(range(4),dtype=np.int8).reshape(2,2)\n_arr\n\narray([[0, 1],\n       [2, 3]], dtype=int8)\n\n\n\n_arr.strides\n\n(2, 1)\n\n\n\n아래로한칸 = 2칸 (= 2바이트 jump = 16비트 jump)\n오른쪽으로 한칸 = 1칸 jump (= 1바이트 jump = 8비트 jump)\n\n\n_arr = np.array(range(4),dtype=np.float64).reshape(2,2)\n_arr\n\narray([[0., 1.],\n       [2., 3.]])\n\n\n\n_arr.strides\n\n(16, 8)\n\n\n\n_arr = np.array(range(4),dtype=np.float32).reshape(2,2)\n_arr\n\narray([[0., 1.],\n       [2., 3.]], dtype=float32)\n\n\n\n_arr.strides\n\n(8, 4)\n\n\n진짜 참고..\n\n1바이트 = 8비트\n1바이트는 2^8=256 의 정보 표현\nnp.int8은 8비트로 정수를 저장한다는 의미\n\n\n2**8\n\n256\n\n\n\nprint(np.array(55,dtype=np.int8))\nprint(np.array(127,dtype=np.int8))\nprint(np.array(300,dtype=np.int8)) # overflow \n\n55\n127\n44\n\n\n딴소리 끝!!\nweight의 transfose가 저장되는 이유 끝!\n혼자 크다고 인식하면 바꾸는…\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([299, 7])\n\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n\nplt.matshow(combined[:15],vmin=-7,vmax=7,cmap='bwr')\nplt.xticks(range(7), labels=[r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')"
  },
  {
    "objectID": "posts/ml/2022-11-09-ml-10w.html#exam3-abcd",
    "href": "posts/ml/2022-11-09-ml-10w.html#exam3-abcd",
    "title": "RNN (10주차)",
    "section": "Exam3: abcd",
    "text": "Exam3: abcd\n\ndata\n\ntxt = list('abcd')*100\ntxt[:10]\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'a', 'b']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['a', 'b', 'c', 'd', 'a'], ['b', 'c', 'd', 'a', 'b'])\n\n\n\n\n하나의 은닉노드를 이용한 풀이 – 억지로 성공\n- 데이터정리\n\nmapping = {'a':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 0]), tensor([1, 2, 3, 0, 1]))\n\n\n- 학습\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=1),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nnet[0].weight.data = torch.tensor([[-0.3333],[-2.5000],[5.0000],[0.3333]])\n\nnet[-1].weight.data = torch.tensor([[1.5000],[-6.0000],[-2.0000],[6.0000]])\nnet[-1].bias.data = torch.tensor([0.1500, -2.0000,  0.1500, -2.000])\n\n\nfor epoc in range(5000):\n    ## 1\n    ## 2 \n    loss = loss_fn(net(x),y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([399, 9])\n\n\n\nplt.matshow(combined[:15],vmin=-15,vmax=15,cmap='bwr')\nplt.xticks(range(9), labels=[r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\n맞춘게 아니야. 0 근처인게 있잖아 hidden에서\n\n\n두개의 은닉노드를 이용한 풀이 – 깔끔한 성공\n- 데이터정리\n\nmapping = {'a':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 0]), tensor([1, 2, 3, 0, 1]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([399, 10])\n\n\n\nplt.matshow(combined[:15],vmin=-7,vmax=7,cmap='bwr')\nplt.xticks(range(10), labels=[r'$h$',r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\n\nhidden layer 2장만으로 4가지 state 표현"
  },
  {
    "objectID": "posts/ml/2022-11-09-ml-10w.html#exam4-abcde-스스로-공부",
    "href": "posts/ml/2022-11-09-ml-10w.html#exam4-abcde-스스로-공부",
    "title": "RNN (10주차)",
    "section": "Exam4: abcde (스스로 공부)",
    "text": "Exam4: abcde (스스로 공부)\n\ndata\n주어진 자료가 다음과 같다고 하자.\n\ntxt = list('abcde')*100\ntxt[:10]\n\n['a', 'b', 'c', 'd', 'e', 'a', 'b', 'c', 'd', 'e']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['a', 'b', 'c', 'd', 'e'], ['b', 'c', 'd', 'e', 'a'])\n\n\n아래 코드를 변형하여 적절한 네트워크를 설계하고 위의 자료를 학습하라. (깔끔한 성공을 위한 최소한의 은닉노드를 설정할 것)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=??,embedding_dim=??),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=??,out_features=??)\n)\n\n\n3개의 은닉노드를 이용한 풀이\na,b,c,d,e 를 표현함에 있어서 3개의 은닉노드면 충분하다. - 1개의 은닉노드 -&gt; 2개의 문자를 표현할 수 있음. (\\(2^1\\)) - 2개의 은닉노드 -&gt; 4개의 문자를 표현할 수 있음. (\\(2^2\\)) - 3개의 은닉노드 -&gt; 8개의 문자를 표현할 수 있음. (\\(2^3\\))\n\nmapping = {'a':0,'b':1,'c':2,'d':3,'e':4}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 4]), tensor([1, 2, 3, 4, 0]))\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=5,embedding_dim=3),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=3,out_features=5)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([499, 13])\n\n\n\nplt.matshow(combined[:15],vmin=-5,vmax=5,cmap='bwr')\nplt.xticks(range(13), labels=[r'$h$',r'$h$',r'$h$',\n                              r'$y=A?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$y=e?$',\n                              r'$P(y=A)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$',r'$P(y=e)$'],size=13)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')"
  },
  {
    "objectID": "posts/ml/2022-11-09-ml-10w.html#exam5-abacad",
    "href": "posts/ml/2022-11-09-ml-10w.html#exam5-abacad",
    "title": "RNN (10주차)",
    "section": "Exam5: AbAcAd",
    "text": "Exam5: AbAcAd\n\ndata\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])\n\n\n\n\n두개의 은닉노드를 이용한 풀이 – 실패\n- 데이터정리\n\nmapping = {'A':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 0, 2, 0]), tensor([1, 0, 2, 0, 3]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([599, 10])\n\n\n\nplt.matshow(combined[:15],vmin=-5,vmax=5,cmap='bwr')\nplt.xticks(range(10), labels=[r'$h$',r'$h$',r'$y=A?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=A)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\n\nA 뒤는 a,b,c 3개 중 하나, 따라서 1/3 의 확률이겠네 하고 학습해버렸다.\nobservation 마다 봐야하는 x가 달라(수가 )\n실패\n\n- 실패를 해결하는 순진한 접근방식: 위 문제를 해결하기 위해서는 아래와 같은 구조로 데이터를 다시 정리하면 될 것이다.\n\n\n\nX\ny\n\n\n\n\nA,b\nA\n\n\nb,A\nc\n\n\nA,c\nA\n\n\nc,A\nd\n\n\nA,d\nA\n\n\nd,A\nb\n\n\nA,b\nA\n\n\nb,A\nc\n\n\n…\n…\n\n\n\n- 순진한 접근방식의 비판: - 결국 정확하게 직전 2개의 문자를 보고 다음 문제를 예측하는 구조 - 만약에 직전 3개의 문자를 봐야하는 상황이 된다면 또 다시 코드를 수정해야함. - 그리고 실전에서는 직전 몇개의 문자를 봐야하는지 모름.\n이것에 대한 해결책은 순환신경망이다.\n\n\n순환망을 위하여 data 다시정리\n- 기존의 정리방식\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])\n\n\n\nx = torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))\n\n\nx[:8],y[:8]\n\n(tensor([0, 1, 0, 2, 0, 3, 0, 1]), tensor([1, 0, 2, 0, 3, 0, 1, 0]))\n\n\n- 이번엔 원핫인코딩형태까지 미리 정리하자. (임베딩 레이어 안쓸예정)\n숫자형태의 벡터형태라고 가정하고 학습하는 순환신경망\n\nx= torch.nn.functional.one_hot(x).float()\ny= torch.nn.functional.one_hot(y).float()\n\n\nx,y\n\n(tensor([[1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         ...,\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.]]),\n tensor([[0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         ...,\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.]]))\n\n\n\n\n실패했던 풀이의 재구현1\n- 방금 실패한 풀이\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n- Tanh까지만 클래스로 바꾸어서 구현 - 클래스를 이용하는 방법: https://guebin.github.io/DL2022/2022/11/01/(9주차)-11월1일.html#로지스틱-모형을-이용한-풀이\n\nclass Hnet(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(in_features=4,out_features=2)\n        self.tanh = torch.nn.Tanh()\n    def forward(self,x):\n        hidden = self.tanh(self.i2h(x))\n        return hidden\n\n- for문돌릴준비\n\ntorch.manual_seed(43052) \nhnet = Hnet()\nlinr = torch.nn.Linear(in_features=2,out_features=4)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(hnet.parameters())+list(linr.parameters()))\n\n- for문: 20회반복\n\nfor epoc in range(20): \n    ## 1 \n    ## 2 \n    hidden = hnet(x) \n    output = linr(hidden)\n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- linr(hnet(x)) 적합결과 &lt;– 숫자체크\n\nlinr(hnet(x))\n\ntensor([[-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.2912,  0.8140, -0.2032,  0.0178],\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        ...,\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.1065,  0.6307, -0.0874,  0.1821],\n        [-0.3589,  0.7921, -0.1970, -0.0302]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\n\n실패했던 풀이의 재구현2\n- Tanh까지 구현한 클래스\n\n#\n# class Hnet(torch.nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.i2h = torch.nn.Linear(in_features=4,out_features=2)\n#         self.tanh = torch.nn.Tanh()\n#     def forward(self,x):\n#         hidden = self.tanh(self.i2h(x))\n#         return hidden\n\n- for문돌릴준비\n\ntorch.manual_seed(43052) \nhnet = Hnet()\nlinr = torch.nn.Linear(in_features=2,out_features=4)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(hnet.parameters())+list(linr.parameters()))\n\n- for문: 20회 반복\n\nx[0].shape\n\ntorch.Size([4])\n\n\n\nx[[0]].shape\n\ntorch.Size([1, 4])\n\n\n\nT = len(x) \nfor epoc in range(20): \n    ## 1~2\n    loss = 0 \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = hnet(xt) \n        ot = linr(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- linr(hnet(x)) 적합결과 &lt;– 숫자체크\n\nlinr(hnet(x))\n\ntensor([[-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.2912,  0.8140, -0.2032,  0.0178],\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        ...,\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.1065,  0.6307, -0.0874,  0.1821],\n        [-0.3589,  0.7921, -0.1970, -0.0302]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\n4개가 필요한 원핫인코딩과 달리 hidden layer는 2개만으로 4state 표현했다\n\n\n\n순환신경망의 아이디어\n\n모티브\n(예비생각1) \\({\\boldsymbol h}\\)에 대한 이해\n\\({\\boldsymbol h}\\)는 사실 문자열 ’abcd’들을 숫자로 바꾼 또 다른 형식의 숫자표현이라 해석할 수 있음. 즉 원핫인코딩과 다른 또 다른 형태의 숫자표현이라 해석할 수 있다. (사실 원핫인코딩보다 약간 더 (1) 액기스만 남은 느낌 + (2) 숙성된 느낌을 준다) - (why1) h는 “학습을 용이하게 하기 위해서 x를 적당히 선형적으로 전처리한 상태”라고 이해가능 - (why2) 실제로 예시를 살펴보면 그러했다.\n결론: 사실 \\({\\boldsymbol h}\\)는 잘 숙성되어있는 입력정보 \\({\\bf X}\\) 그 자체로 해석 할 수 있다.\n(예비생각2) 수백년전통을 이어가는 방법\n“1리터에 500만원에 낙찰된 적 있습니다.”\n“2kg에 1억원 정도 추산됩니다.”\n“20여 종 종자장을 블렌딩해 100ml에 5000만원씩 분양 예정입니다.”\n\n모두 씨간장(종자장) 가격에 관한 실제 일화다.\n\n(중략...)\n\n위스키나 와인처럼 블렌딩을 하기도 한다. \n새로 담근 간장에 씨간장을 넣거나, 씨간장독에 햇간장을 넣어 맛을 유지하기도 한다. \n이를 겹장(또는 덧장)이라 한다. \n몇몇 종갓집에선 씨간장 잇기를 몇백 년째 해오고 있다. \n매년 새로 간장을 담가야 이어갈 수 있으니 불씨 꺼트리지 않는 것처럼 굉장히 어려운 일이다.\n이렇게 하는 이유는 집집마다 내려오는 고유 장맛을 잃지 않기 위함이다. \n씨간장이란 그만큼 소중한 주방의 자산이며 정체성이다.\n덧장: 새로운간장을 만들때, 옛날간장을 섞어서 만듬\n* 기존방식 - \\(\\text{콩물} \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}\\)\n* 수백년 전통의 간장맛을 유지하는 방식\n\n\\(\\text{콩물}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3\\)\n\n* 수백년 전통의 간장맛을 유지하면서 조리를 한다면?\n\n\\(\\text{콩물}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_1\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_3\\)\n\n점점 맛있는 간장계란밥이 탄생함\n* 알고리즘의 편의상 아래와 같이 생각해도 무방\n\n\\(\\text{콩물}_1, \\text{간장}_0 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_1\\), \\(\\text{간장}_0=\\text{맹물}\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_3\\)\n\n아이디어\n* 수백년 전통의 간장맛을 유지하면서 조리하는 과정을 수식으로?\n\n\\(\\boldsymbol{x}_1, \\boldsymbol{h}_0 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_1 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_1\\)\n\\(\\boldsymbol{x}_2, \\boldsymbol{h}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_2 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_2\\)\n\\(\\boldsymbol{x}_3, \\boldsymbol{h}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_3 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_3\\)\n\n이제 우리가 배울것은 (1) “\\(\\text{콩물}_{t}\\)”와 “\\(\\text{간장}_{t-1}\\)”로 “\\(\\text{간장}_t\\)”를 숙성하는 방법 (2) “\\(\\text{간장}_t\\)”로 “\\(\\text{간장계란밥}_t\\)를 조리하는 방법이다\n즉 숙성담당 네트워크와 조리담당 네트워크를 각각 만들어 학습하면 된다.\n\n\n알고리즘\n세부적인 알고리즘 (\\(t=0,1,2,\\dots\\)에 대하여 한줄 한줄 쓴 알고리즘)\n\n\\(t=0\\)\n\n\\({\\boldsymbol h}_0=[[0,0]]\\) &lt;– \\(\\text{간장}_0\\)은 맹물로 초기화\n\n\\(t=1\\)\n\n\\({\\boldsymbol h}_1= \\tanh({\\boldsymbol x}_1{\\bf W}_{ih}+{\\boldsymbol h}_0{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})\\) - \\({\\boldsymbol x}_1\\): (1,4) - \\({\\bf W}_{ih}\\): (4,2) - \\({\\boldsymbol h}_0\\): (1,2) - \\({\\bf W}_{hh}\\): (2,2) - \\({\\boldsymbol b}_{ih}\\): (1,2) - \\({\\boldsymbol b}_{hh}\\): (1,2)\n\\({\\boldsymbol o}_1= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}\\)\n\\(\\hat{\\boldsymbol y}_1 = \\text{soft}({\\boldsymbol o}_1)\\)\n\n\\(t=2\\) &lt;– 여기서부터는 \\(t=2\\)와 비슷\n\n\n좀 더 일반화된 알고리즘\n(ver1)\ninit \\(\\boldsymbol{h}_0\\)\nfor \\(t\\) in \\(1:T\\)\n\n\\({\\boldsymbol h}_t= \\tanh({\\boldsymbol x}_t{\\bf W}_{ih}+{\\boldsymbol h}_{t-1}{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})\\)\n\\({\\boldsymbol o}_t= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}\\)\n\\(\\hat{\\boldsymbol y}_t = \\text{soft}({\\boldsymbol o}_t)\\)\n\n(ver2)\ninit hidden\n\nfor t in 1:T \n    hidden = tanh(linr(x)+linr(hidden)) # $H_{t-1}$\n    output = linr(hidden)\n    yt_hat = soft(output)\n\n코드상으로는 \\(h_t\\)와 \\(h_{t-1}\\)의 구분이 교모하게 사라진다. (그래서 오히려 좋아)\n\n\n전체알고리즘은 대충 아래와 같은 형식으로 구현될 수 있음\n### \nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        linr1 = torch.nn.Linear(?,?) \n        linr2 = torch.nn.Linear(?,?) \n        tanh = torch.nn.Tanh()\n    def forward(self,x,hidden):\n        hidden = tanh(lrnr1(x)+lrnr2(hidden))\n        return hidden\n\ninit ht\nrnncell = rNNCell()\n\nfor t in 1:T \n    xt, yt = x[[t]], y[[t]] \n    ht = rnncell(xt, ht)\n    ot = linr(ht) \n    loss = loss + loss_fn(ot, yt)\n\n\n\n순환신경망 구현1 – 성공\n(1) 숙성담당 네트워크\n\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(4,2) \n        self.h2h = torch.nn.Linear(2,2) \n        self.tanh = torch.nn.Tanh()\n    def forward(self,x,hidden):\n        hidden = self.tanh(self.i2h(x)+self.h2h(hidden))\n        return hidden\n\n\ntorch.manual_seed(43052)\nrnncell = rNNCell() # 숙성담당 네트워크 \n\n(2) 조리담당 네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수, 옵티마이저 설계\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습 (6분정도 걸림)\n\nT = len(x) \nfor epoc in range(5000): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) \n        ot = cook(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수 \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]]) \n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nplt.matshow(yhat.data[-15:])\n\n&lt;matplotlib.image.AxesImage at 0x7f0f04614dd0&gt;\n\n\n\n\n\n\n아주 특이한 특징: yhat[:15], yhat[:-15] 의 적합결과가 다르다\n왜? 간장계란밥은 간장이 중요한데, 간장은 시간이 갈수록 맛있어지니까..\n\n\n\n순환신경망 구현2 (with RNNCell) – 성공\nref: https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html\n(1) 숙성네트워크\n선언\n\nrnncell = torch.nn.RNNCell(4,2)\n\n가중치초기화 (순환신경망 구현1과 동일하도록)\n\ntorch.manual_seed(43052)\n_rnncell = rNNCell()\n\n\nrnncell.weight_ih.data = _rnncell.i2h.weight.data \nrnncell.weight_hh.data = _rnncell.h2h.weight.data \nrnncell.bias_hh.data = _rnncell.h2h.bias.data \nrnncell.bias_ih.data = _rnncell.i2h.bias.data \n\n(2) 조리담당 네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수, 옵티마이저 설계\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습 (6분정도 걸림)\n\nT = len(x) \nfor epoc in range(5000): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) \n        ot = cook(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수 \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]]) \n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nplt.matshow(yhat.data[-15:])\n\n&lt;matplotlib.image.AxesImage at 0x7f0f0cfe77d0&gt;\n\n\n\n\n\n\n\n순환신경망 구현3 (with RNN) – 성공\n(예비학습)\n- 아무리 생각해도 yhat구하려면 좀 귀찮음\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수 \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]])\n\n\nsoft(cook(hidden))\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n- 이렇게 하면 쉽게(?) 구할 수 있음\n\nrnn = torch.nn.RNN(4,2) \n\n\nrnn.weight_hh_l0.data = rnncell.weight_hh.data \nrnn.bias_hh_l0.data = rnncell.bias_hh.data \nrnn.weight_ih_l0.data = rnncell.weight_ih.data \nrnn.bias_ih_l0.data = rnncell.bias_ih.data \n\n\n_water\n\ntensor([[0., 0.]])\n\n\n\nsoft(cook(rnn(x,_water)[0]))\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\n똑같음!\n\n- rnn(x,_water)의 결과는 (1) 599년치 간장 (2) 599번째 간장 이다\n\nrnn(x,_water)\n\n(tensor([[-0.2232,  0.9769],\n         [-0.9999, -0.9742],\n         [ 0.9154,  0.9992],\n         ...,\n         [ 0.9200,  0.9992],\n         [-0.9978, -0.0823],\n         [-0.9154,  0.9965]], grad_fn=&lt;SqueezeBackward1&gt;),\n tensor([[-0.9154,  0.9965]], grad_fn=&lt;SqueezeBackward1&gt;))\n\n\n(예비학습결론) torch.nn.RNN(4,2)는 torch.nn.RNNCell(4,2)의 batch 버전이다. (for문이 포함된 버전이다)\n\ntorch.nn.RNN(4,2)를 이용하여 구현하자.\n(1) 숙성네트워크\n선언\n\ntorch.manual_seed(43052)\nrnn = torch.nn.RNN(4,2)\n\n(2) 조리네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4)\n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters())) # 우리가 배울것: 숙성하는 방법 + 요리하는 방법 \n\n(4) 학습\n\nfor epoc in range(5000):\n    ## 1\n    _water = torch.zeros(1,2)\n    hidden, _ = rnn(x,_water)\n    output = cook(hidden)\n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nyhat = soft(cook(rnn(x,_water)[0]))\nyhat\n\ntensor([[1.9725e-02, 1.5469e-03, 8.2766e-01, 1.5106e-01],\n        [9.1875e-01, 1.6513e-04, 6.7703e-02, 1.3384e-02],\n        [2.0031e-02, 1.0659e-03, 8.5248e-01, 1.2642e-01],\n        ...,\n        [1.9640e-02, 1.3568e-03, 8.3705e-01, 1.4196e-01],\n        [9.9564e-01, 1.3114e-05, 3.5069e-03, 8.4108e-04],\n        [3.5473e-03, 1.5670e-01, 1.4102e-01, 6.9873e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nplt.matshow(yhat.data[:15])\n\n&lt;matplotlib.image.AxesImage at 0x7f0f159c0a10&gt;"
  },
  {
    "objectID": "posts/ml/2022-11-21-ml-11w.html",
    "href": "posts/ml/2022-11-21-ml-11w.html",
    "title": "RNN (11주차)",
    "section": "",
    "text": "기계학습 특강 (11주차) 11월16일 [순환신경망– abc예제, abdc예제, abcde예제, AbAcAd예제]"
  },
  {
    "objectID": "posts/ml/2022-11-21-ml-11w.html#import",
    "href": "posts/ml/2022-11-21-ml-11w.html#import",
    "title": "RNN (11주차)",
    "section": "import",
    "text": "import\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/ml/2022-11-21-ml-11w.html#define-some-funtions",
    "href": "posts/ml/2022-11-21-ml-11w.html#define-some-funtions",
    "title": "RNN (11주차)",
    "section": "Define some funtions",
    "text": "Define some funtions\n\ndef f(txt,mapping):\n    return [mapping[key] for key in txt] \nsig = torch.nn.Sigmoid()\nsoft = torch.nn.Softmax(dim=1)\ntanh = torch.nn.Tanh()"
  },
  {
    "objectID": "posts/ml/2022-11-21-ml-11w.html#exam4-abacad-2",
    "href": "posts/ml/2022-11-21-ml-11w.html#exam4-abacad-2",
    "title": "RNN (11주차)",
    "section": "Exam4: AbAcAd (2)",
    "text": "Exam4: AbAcAd (2)\n\ndata\n- 기존의 정리방식\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))).float()\n\n\nx,y\n\n(tensor([[1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         ...,\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.]]),\n tensor([[0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         ...,\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.]]))\n\n\n\n\n순환신경망 구현1 (손으로 직접구현) – 리뷰\n(1) 숙성담당 네트워크\n\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(4,2) \n        self.h2h = torch.nn.Linear(2,2) \n        self.tanh = torch.nn.Tanh()\n    def forward(self,x,hidden):\n        hidden = self.tanh(self.i2h(x)+self.h2h(hidden))\n        return hidden\n\n\ntorch.manual_seed(43052)\nrnncell = rNNCell() # 숙성담당 네트워크 \n\n(2) 조리담당 네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수, 옵티마이저 설계\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습 (6분정도 걸림)\n\nx[[2]].shape\n\ntorch.Size([1, 4])\n\n\n\nT = len(x) \nfor epoc in range(5000): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) \n        ot = cook(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수 \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]]) \n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nplt.matshow(yhat.data[-15:],cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f1160dcaa50&gt;\n\n\n\n\n\n\n\n순환신경망 구현2 (with RNNCell, hidden node 2)\nref: https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html\n\n구현1과 같은 초기값 (확인용)\n(1) 숙성네트워크\n\ntorch.manual_seed(43052)\n_rnncell = rNNCell() # 숙성담당 네트워크 \n\n\nrnncell = torch.nn.RNNCell(4,2)\n\n\ninput_size = 4\nhindden_size = 2\n\nrNNCell() 는 사실 torch.nn.RNNCell()와 같은 동작을 하도록 설계를 하였음.\n같은동작을 하는지 확인하기 위해서 동일한 초기상태에서 rNNCell()에 의하여 학습된 결과와 torch.nn.RNNCell()에 의하여 학습된 결과를 비교해보자.\n\nrnncell.weight_ih.shape\n\ntorch.Size([2, 4])\n\n\n\nrnncell.bias_ih.shape\n\ntorch.Size([2])\n\n\n\nrnncell.weight_hh.shape\n\ntorch.Size([2, 2])\n\n\n\nrnncell.bias_hh.shape \n\ntorch.Size([2])\n\n\n\nrnncell.weight_ih.data = _rnncell.i2h.weight.data\nrnncell.bias_ih.data = _rnncell.i2h.bias.data\nrnncell.weight_hh.data = _rnncell.h2h.weight.data\nrnncell.bias_hh.data = _rnncell.h2h.bias.data\n\n_rnncell 초기값을 rnncell에 넣어주기\n(2) 조리네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) # 숙성된 2차원의 단어를 다시 4차원으로 바꿔줘야지 나중에 softmax취할 수 있음\n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습\n\nT = len(x) \nfor epoc in range(5000):\n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht)\n        ot = cook(ht)\n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nhidden = torch.zeros(T,2) \n\n\n# t=0 \n_water = torch.zeros(1,2)\nhidden[[0]] = rnncell(x[[0]],_water)\n# t=1~T \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]])\n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nplt.matshow(yhat[:15].data,cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f1123dd2650&gt;\n\n\n\n\n\n\nplt.matshow(yhat[-15:].data,cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f11237d65d0&gt;\n\n\n\n\n\n뒷부분갈수록 잘 맞음\n\n\n새로운 초기값\n(1) 숙성네트워크\n\ntorch.manual_seed(43052)\ntorch.nn.RNNCell(4,2)\n\nRNNCell(4, 2)\n\n\n앞 부분은 잘 맞지 않고 뒷부분은 잘 맞을 것!\n(2) 조리네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) # 숙성된 2차원의 단어를 다시 4차원으로 바꿔줘야지 나중에 softmax취할 수 있음\n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습\n\nT = len(x) \nfor epoc in range(5000):\n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht)\n        ot = cook(ht)\n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\nx -&gt; h -&gt; o -&gt; yhat(softmax(o))\n네트워크만 학습된 상태, 따라서 hiddenlayer를 재구성해줘야 한다.\n\n\n\n순환신경망 구현3 (with RNN, hidden node 2) – 성공\n(예비학습)\n- 네트워크학습이후 yhat을 구하려면 번거로웠음\nhidden = torch.zeros(T,2) \n_water = torch.zeros(1,2)\nhidden[[0]] = rnncell(x[[0]],_water)\nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]])\nyhat = soft(cook(hidden))\n- 이렇게 하면 쉽게(?) 구할 수 있음\n\nrnn = torch.nn.RNN(4,2)\n\n\nrnn.weight_hh_l0.data = rnncell.weight_hh.data \nrnn.weight_ih_l0.data = rnncell.weight_ih.data\nrnn.bias_hh_l0.data = rnncell.bias_hh.data\nrnn.bias_ih_l0.data = rnncell.bias_ih.data\n\n- rnn(x,_water)의 결과는 (1) 599년치 간장 (2) 599번째 간장 이다\n\nrnn(x,_water), hidden\n\n((tensor([[-0.1271,  0.9965],\n          [-1.0000, -0.9987],\n          [ 0.9962,  1.0000],\n          ...,\n          [ 0.9962,  1.0000],\n          [-1.0000, -0.9897],\n          [ 0.9959,  1.0000]], grad_fn=&lt;SqueezeBackward1&gt;),\n  tensor([[0.9959, 1.0000]], grad_fn=&lt;SqueezeBackward1&gt;)),\n tensor([[-0.2232,  0.9769],\n         [-0.9999, -0.9742],\n         [ 0.9154,  0.9992],\n         ...,\n         [ 0.9200,  0.9992],\n         [-0.9978, -0.0823],\n         [-0.9154,  0.9965]], grad_fn=&lt;IndexPutBackward0&gt;))\n\n\n\nsoft(cook(rnn(x,_water)[0]))\n\ntensor([[6.0688e-02, 4.2958e-01, 2.9885e-01, 2.1088e-01],\n        [9.9700e-01, 8.2096e-04, 1.3663e-03, 8.1039e-04],\n        [2.2782e-03, 3.3203e-01, 3.3260e-01, 3.3309e-01],\n        ...,\n        [2.2779e-03, 3.3203e-01, 3.3260e-01, 3.3309e-01],\n        [9.9692e-01, 8.4633e-04, 1.4012e-03, 8.3072e-04],\n        [2.2803e-03, 3.3206e-01, 3.3260e-01, 3.3306e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n(예비학습결론) torch.nn.RNN(4,2)는 torch.nn.RNNCell(4,2)의 batch 버전이다. (for문이 포함된 버전이다)\n\ntorch.nn.RNN(4,2)를 이용하여 구현하자.\n(1) 숙성네트워크\n선언\n\nrnn = torch.nn.RNN(4,2)\n\n가중치초기화\n\ntorch.manual_seed(43052)\n_rnncell = torch.nn.RNNCell(4,2)\n\n\nrnn.weight_hh_l0.data = _rnncell.weight_hh.data \nrnn.weight_ih_l0.data = _rnncell.weight_ih.data\nrnn.bias_hh_l0.data = _rnncell.bias_hh.data\nrnn.bias_ih_l0.data = _rnncell.bias_ih.data\n\n(2) 조리네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters()))\n\n(4) 학습\n\n_water = torch.zeros(1,2) \nfor epoc in range(5000):\n    ## 1 \n    hidden,hT = rnn(x,_water)\n    output = cook(hidden) \n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n결과는 같을 것\n(5) 시각화1: yhat\n\nyhat = soft(output)\n\n\nplt.matshow(yhat.data[:15],cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f1123908710&gt;\n\n\n\n\n\n\n처음은 좀 틀렸음 ㅎㅎ\n\n\nplt.matshow(yhat.data[-15:],cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f11238cac90&gt;\n\n\n\n\n\n\n뒤에는 잘맞음\n\n실전팁: _water 대신에 hT를 대입 (사실 큰 차이는 없음)\nhT는 이미 값이 저장되어 있잖아\n\nrnn(x[:6],_water),rnn(x[:6],hT)\n\n((tensor([[-0.9912, -0.9117],\n          [ 0.0698, -1.0000],\n          [-0.9927, -0.9682],\n          [ 0.5761, -1.0000],\n          [-0.9960, -0.0173],\n          [ 0.9960, -1.0000]], grad_fn=&lt;SqueezeBackward1&gt;),\n  tensor([[ 0.9960, -1.0000]], grad_fn=&lt;SqueezeBackward1&gt;)),\n (tensor([[-0.9713, -1.0000],\n          [ 0.0535, -1.0000],\n          [-0.9925, -0.9720],\n          [ 0.5759, -1.0000],\n          [-0.9960, -0.0180],\n          [ 0.9960, -1.0000]], grad_fn=&lt;SqueezeBackward1&gt;),\n  tensor([[ 0.9960, -1.0000]], grad_fn=&lt;SqueezeBackward1&gt;)))\n\n\n(6) 시각화2: hidden, yhat\n\ncombinded = torch.concat([hidden,yhat],axis=1)\n\n\nplt.matshow(combinded[-15:].data,cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f1123881510&gt;\n\n\n\n\n\n\n히든노드의 해석이 어려움.\n\nhidden layer-&gt;layer 더 있음 좋겠다\n\n\n순환신경망 구현4 (with RNN, hidden node 3) – 성공\n(1) 숙성네트워크~ (2) 조리네트워크\n\ntorch.manual_seed(2) #1 \nrnn = torch.nn.RNN(4,3) \ncook = torch.nn.Linear(3,4) \n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters()))\n\n(4) 학습\n\n_water = torch.zeros(1,3) \nfor epoc in range(5000):\n    ## 1\n    hidden,hT = rnn(x,_water) \n    output = cook(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화1: yhat\n\nyhat = soft(output)\n\n\nplt.matshow(yhat[-15:].data,cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f1123e41f10&gt;\n\n\n\n\n\n(6) 시각화2: hidden, yhat\n\ncombinded = torch.concat([hidden,yhat],axis=1)\n\n\nplt.matshow(combinded[-15:].data,cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f1123a3fd10&gt;\n\n\n\n\n\n\n세번째 히든노드 = 대소문자(a/A)를 구분\n1,2 히든노드 = bcd를 구분"
  },
  {
    "objectID": "posts/ml/2022-11-21-ml-11w.html#gpu-실험",
    "href": "posts/ml/2022-11-21-ml-11w.html#gpu-실험",
    "title": "RNN (11주차)",
    "section": "GPU 실험",
    "text": "GPU 실험\n\n20000 len + 20 hidden nodes\ncpu\n\nimport time\n\n\nx = torch.randn([20000,4]) \ny = torch.randn([20000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n228.14399337768555\n\n\n왕 느려\ngpu\n\nx = torch.randn([20000,4]).to(\"cuda:0\")\ny = torch.randn([20000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n6.0587098598480225\n\n\n\n왜 빠른지?\n\n\n\n20000 len + 20 hidden nodes + 역전파주석처리\ncpu\n\nx = torch.randn([20000,4]) \ny = torch.randn([20000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n28.451032400131226\n\n\nloss 미분할 때 시간 많이 잡음ㅁ\ngpu\n\nx = torch.randn([20000,4]).to(\"cuda:0\")\ny = torch.randn([20000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n1.6839873790740967\n\n\n\n\n2000 len + 20 hidden nodes\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n10.069071292877197\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n1.7792012691497803\n\n\n\n\n2000 len + 20 hidden nodes + 역전파주석처리\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n2.7720658779144287\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n0.2116107940673828\n\n\n\n\n2000 len + 5000 hidden nodes\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,1000) \nlinr = torch.nn.Linear(1000,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n34.20541262626648\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,1000).to(\"cuda:0\")\nlinr = torch.nn.Linear(1000,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n4.586683511734009\n\n\n\n\n2000 len + 5000 hidden nodes + 역전파주석처리\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,1000) \nlinr = torch.nn.Linear(1000,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n8.695780992507935\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,1000).to(\"cuda:0\")\nlinr = torch.nn.Linear(1000,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n2.3646719455718994\n\n\n\n\n실험결과 요약\n\n\n\nlen\n# of hidden nodes\nbackward\ncpu\ngpu\nratio\n\n\n\n\n20000\n20\nO\n93.02\n3.26\n28.53\n\n\n20000\n20\nX\n18.85\n1.29\n14.61\n\n\n2000\n20\nO\n6.53\n0.75\n8.70\n\n\n2000\n20\nX\n1.25\n0.14\n8.93\n\n\n2000\n1000\nO\n58.99\n4.75\n12.41\n\n\n2000\n1000\nX\n13.16\n2.29\n5.74"
  },
  {
    "objectID": "posts/ml/2022-11-21-ml-11w.html#exam5-abcabc",
    "href": "posts/ml/2022-11-21-ml-11w.html#exam5-abcabc",
    "title": "RNN (11주차)",
    "section": "Exam5: abcabC",
    "text": "Exam5: abcabC\n\ndata\n\ntxt = list('abcabC')*100\ntxt[:8]\n\n['a', 'b', 'c', 'a', 'b', 'C', 'a', 'b']\n\n\n\ntxt_x = txt[:-1] \ntxt_y = txt[1:]\n\n\nmapping = {'a':0,'b':1,'c':2,'C':3} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx = x.to(\"cuda:0\")\ny = y.to(\"cuda:0\") \n\n\nx.shape\n\ntorch.Size([599, 4])\n\n\n\n\nRNN\n\nbc\nbC\nb의 수준이 2개\nabc\namC\n문맥 고려해서 \\(\\to\\) hiddenlayer = 3\n\n\ntorch.manual_seed(43052) \nrnn = torch.nn.RNN(4,3) \nlinr = torch.nn.Linear(3,4) \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+ list(linr.parameters()))\n\n\nrnn.to(\"cuda:0\") \nlinr.to(\"cuda:0\")\n\nLinear(in_features=3, out_features=4, bias=True)\n\n\n- 3000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\n어차피 시각화하려면 cpu에 있어야해\n나중 기억!\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f116f95fd10&gt;\n\n\n\n\n\n- 6000 epochs\n\n3: a일 확률\n4: b일 확률\n5: c일 확률\n6: C일 확률\n\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f1162b1ad10&gt;\n\n\n\n\n\n- 9000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f11627385d0&gt;\n\n\n\n\n\n- 12000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f11626b9950&gt;\n\n\n\n\n\n- 15000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-12:],cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f11624ce950&gt;\n\n\n\n\n\n\n15,000번 정도 하니 c와 C를 구분하는 모습\nhidden layer(0,1,2)의 색 순서에 따라 문맥상 다른 것을 알 수 있고 학습도 되는 모습을 볼 수 있다.\n\n\n\nLSTM\n- LSTM\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,3) \nlinr = torch.nn.Linear(3,4) \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters())+ list(linr.parameters()))\n\n\nlstm.to(\"cuda:0\") \nlinr.to(\"cuda:0\")\n\nLinear(in_features=3, out_features=4, bias=True)\n\n\n- 3000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, (hT,cT) = lstm(x,(_water,_water))\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f116245a750&gt;\n\n\n\n\n\n\n하얀부분이 0 파란 부분이 -1 빨간 부분이 +1\n\n- 6000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, (hT,cT) = lstm(x,(_water,_water))\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f11623e0a90&gt;\n\n\n\n\n\n\nrnn에 비해 lstm은 조금 돌려도 어느정도 비교 잘 해낸다\n\n\n\nRNN vs LSTM 성능비교실험\n- RNN\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,3).to(\"cuda:0\")\n        linr = torch.nn.Linear(3,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,3).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$RNN$\",size=20)\nfig.tight_layout()\n\n\n\n\n- LSTM\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(4,3).to(\"cuda:0\")\n        linr = torch.nn.Linear(3,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,3).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$LSTM$\",size=20)\nfig.tight_layout()\n\n\n\n\n\nlstm이 rnn보다 이런 상황에서는 더 잘 학습해낸다.\nlinear 의 hiddenlayer로 구분되어 있다."
  },
  {
    "objectID": "posts/ml/2022-11-21-ml-11w.html#exam6-abcdabcd",
    "href": "posts/ml/2022-11-21-ml-11w.html#exam6-abcdabcd",
    "title": "RNN (11주차)",
    "section": "Exam6: abcdabcD",
    "text": "Exam6: abcdabcD\n\ndata\n\ntxt = list('abcdabcD')*100\ntxt[:8]\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'D']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'a':0, 'b':1, 'c':2, 'd':3, 'D':4}\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx=x.to(\"cuda:0\")\ny=y.to(\"cuda:0\")\n\n\n\nRNN vs LSTM 성능비교실험\n- RNN\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(5,4).to(\"cuda:0\")\n        linr = torch.nn.Linear(4,5).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,4).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-8:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$RNN$\",size=20)\nfig.tight_layout()\n\n\n\n\n- LSTM\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(5,4).to(\"cuda:0\")\n        linr = torch.nn.Linear(4,5).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,4).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-8:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$LSTM$\",size=20)\nfig.tight_layout()\n\n\n\n\n- 관찰1: LSTM이 확실히 장기기억에 강하다.\n- 관찰2: LSTM은 hidden에 0이 잘 나온다.\n\n사실 확실히 구분되는 특징을 판별할때는 -1,1 로 히든레이어 값들이 설정되면 명확하다.\n히든레이어에 -1~1사이의 값이 나온다면 애매한 판단이 내려지게 된다.\n그런데 이 애매한 판단이 어떻게 보면 문맥의 뉘앙스를 이해하는데 더 잘 맞다.\n그런데 RNN은 -1,1로 셋팅된 상황에서 -1~1로의 변화가 더디다는 것이 문제임."
  },
  {
    "objectID": "posts/ml/2022-11-21-ml-11w.html#lstm의-계산과정",
    "href": "posts/ml/2022-11-21-ml-11w.html#lstm의-계산과정",
    "title": "RNN (11주차)",
    "section": "LSTM의 계산과정",
    "text": "LSTM의 계산과정\n\ndata: abaB\n\ntxt = list('abaB')*100\ntxt[:5]\n\n['a', 'b', 'a', 'B', 'a']\n\n\n\nab\naB\n로서 a의 수준이 2개로 나뉨 \\(\\to\\) hidden node = 2\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'a':0, 'b':1, 'B':2}\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\n\n1 epoch ver1 (with torch.nn.LSTMCell)\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2) \nlinr = torch.nn.Linear(2,3)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm_cell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nT = len(x) \nfor epoc in range(1):\n    ht = torch.zeros(1,2)\n    ct = torch.zeros(1,2)\n    loss = 0 \n    ## 1~2\n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht,ct = lstm_cell(xt,(ht,ct))\n        ot = linr(ht) \n        loss = loss + loss_fn(ot,yt)\n    loss = loss / T\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\n데이터 적으니까 cpu로 할 것임\n\n\nht,ct \n\n(tensor([[-0.0406,  0.2505]], grad_fn=&lt;MulBackward0&gt;),\n tensor([[-0.0975,  0.7134]], grad_fn=&lt;AddBackward0&gt;))\n\n\n\nhidden node가 많고 len 이 클수록 GPU가 효율이 좋다\n\n\n\n1 epoch ver2 (완전 손으로 구현)\n\nt=0 \\(\\to\\) t=1\n- lstm_cell 을 이용한 계산 (결과비교용)\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2) \nlinr = torch.nn.Linear(2,3)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm_cell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nT = len(x) \nfor epoc in range(1):\n    ht = torch.zeros(1,2)\n    ct = torch.zeros(1,2)\n    loss = 0 \n    ## 1~2\n    for t in range(1):\n        xt,yt = x[[t]], y[[t]]\n        ht,ct = lstm_cell(xt,(ht,ct))\n    #     ot = linr(ht) \n    #     loss = loss + loss_fn(ot,yt)\n    # loss = loss / T\n    # ## 3 \n    # loss.backward()\n    # ## 4 \n    # optimizr.step()\n    # optimizr.zero_grad()\n\n\nht,ct \n\n(tensor([[-0.0541,  0.0892]], grad_fn=&lt;MulBackward0&gt;),\n tensor([[-0.1347,  0.2339]], grad_fn=&lt;AddBackward0&gt;))\n\n\n\n이런결과를 어떻게 만드는걸까?\nhttps://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n\n\\(i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi})\\)\n\\(f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf})\\)\n\\(g_t = \\tanh (W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg})\\)\n\\(o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{hg})\\)\n\\(o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho})\\)\n\\(c_t = f_t \\odot c_{t-1} + i_t \\odot g_t\\)\n\\(h_t = o_t \\odot \\tanh (c_t)\\)\n\\(\\sigma = \\text{ Sigmoid }\\)\n\\(x_t, h_{t-1} \\underrightarrow{lin} \\text{ }\\circ \\text{ }\\underrightarrow{sig} \\text{ }i_t\\)\n\\(x_t, h_{t-1} \\underrightarrow{lin} \\text{ }\\square \\text{ } \\underrightarrow{sig} \\text{ }f_t\\)\n\\(x_t, h_{t-1} \\underrightarrow{lin} \\text{ }\\star \\text{ } \\underrightarrow{tanh} \\text{ }g_t\\)\n\\(x_t, h_{t-1} \\underrightarrow{lin} \\text{ } \\triangleleft \\text{ }\\underrightarrow{sig} \\text{ }o_t\\)\n\\(x_t, h_{t-1} \\underrightarrow{lin} \\text{ }\\circ \\text{ , } \\square \\text{, } \\star \\text{, } \\triangleleft \\text{ } \\to \\sigma(circ) \\text{, }\\sigma(\\square) \\text{ , }\\tanh(\\star)\\text{ , } \\sigma(\\triangleleft) \\sim i_t, f_t, g_t, o_t\\)\n\n위에 나온 W가 어떻게 계산되나\n\nweight_ih_l[k] – the learnable input-hidden weights of the \\(\\text{k}^{th}\\) layer \\((W_ii|W_if|W_ig|W_io)\\), of shape (4hidden_size, input_size) for \\(k = 0\\). Otherwise, the shape is (4hidden_size, num_directions * hidden_size). If proj_size &gt; 0 was specified, the shape will be (4hidden_size, num_directions  proj_size) for \\(k &gt; 0\\)\nweight_hh_l[k] – the learnable hidden-hidden weights of the \\(\\text{k}^{th}\\)layer \\((W_hi|W_hf|W_hg|W_ho)\\), of shape (4hidden_size, hidden_size). If proj_size &gt; 0 was specified, the shape will be (4hidden_size, proj_size).\n- 직접계산\n\n\\(o_t\\) = output_gate\n\\(f_t\\) = forget_gate\n\\(i_t\\) = input_gate\n\n\nht = torch.zeros(1,2)\nct = torch.zeros(1,2)\n\n\n_ifgo = xt @ lstm_cell.weight_ih.T + ht @ lstm_cell.weight_hh.T + lstm_cell.bias_ih + lstm_cell.bias_hh\n_ifgo\n\ntensor([[ 0.0137,  0.1495,  0.0879,  0.6436, -0.2615,  0.3974, -0.3506, -0.4550]],\n       grad_fn=&lt;AddBackward0&gt;)\n\n\n\\(\\circ \\text{ , } \\square \\text{, } \\star \\text{, } \\triangleleft\\)각 두 개씩\n\ninput_gate = sig(_ifgo[:,0:2])\nforget_gate = sig(_ifgo[:,2:4])\ngt = tanh(_ifgo[:,4:6])\noutput_gate = sig(_ifgo[:,6:8])\n\n\nct = forget_gate * ct + input_gate * gt\nht = output_gate * tanh(ct)\n\n\nht,ct\n\n(tensor([[-0.0812,  0.1327]], grad_fn=&lt;MulBackward0&gt;),\n tensor([[-0.1991,  0.3563]], grad_fn=&lt;AddBackward0&gt;))\n\n\n\n\nt=0 \\(\\to\\) t=T\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2) \nlinr = torch.nn.Linear(2,3)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm_cell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nT = len(x) \nfor epoc in range(1):\n    ht = torch.zeros(1,2)\n    ct = torch.zeros(1,2)\n    loss = 0 \n    ## 1~2\n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        \n        ## lstm_cell step1: calculate _ifgo \n        _ifgo = xt @ lstm_cell.weight_ih.T + ht @ lstm_cell.weight_hh.T + lstm_cell.bias_ih + lstm_cell.bias_hh\n        ## lstm_cell step2: decompose _ifgo \n        input_gate = sig(_ifgo[:,0:2])\n        forget_gate = sig(_ifgo[:,2:4])\n        gt = tanh(_ifgo[:,4:6])\n        output_gate = sig(_ifgo[:,6:8])\n        ## lstm_cell step3: calculate ht,ct \n        ct = forget_gate * ct + input_gate * gt\n        ht = output_gate * tanh(ct)\n        \n    #     ot = linr(ht) \n    #     loss = loss + loss_fn(ot,yt)\n    # loss = loss / T\n    # ## 3 \n    # loss.backward()\n    # ## 4 \n    # optimizr.step()\n    # optimizr.zero_grad()\n\n\nht,ct\n\n(tensor([[-0.0406,  0.2505]], grad_fn=&lt;MulBackward0&gt;),\n tensor([[-0.0975,  0.7134]], grad_fn=&lt;AddBackward0&gt;))\n\n\n\n\n\n1 epoch ver3 (with torch.nn.LSTM)\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2)\nlinr = torch.nn.Linear(2,3) \n\n\nlstm = torch.nn.LSTM(3,2) \n\n\nlstm.weight_hh_l0.data = lstm_cell.weight_hh.data \nlstm.bias_hh_l0.data = lstm_cell.bias_hh.data \nlstm.weight_ih_l0.data = lstm_cell.weight_ih.data \nlstm.bias_ih_l0.data = lstm_cell.bias_ih.data \n\n\n초기화된 가중치값들로 덮어씌우기\n\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters()) + list(linr.parameters()), lr=0.1) \n\n\n_water = torch.zeros(1,2) \nfor epoc in range(1): \n    ## step1 \n    hidden, (ht,ct) = lstm(x,(_water,_water))\n    output = linr(hidden)\n    # ## step2\n    # loss = loss_fn(output,y) \n    # ## step3\n    # loss.backward()\n    # ## step4 \n    # optimizr.step()\n    # optimizr.zero_grad() \n\n\nht,ct\n\n(tensor([[-0.0406,  0.2505]], grad_fn=&lt;SqueezeBackward1&gt;),\n tensor([[-0.0975,  0.7134]], grad_fn=&lt;SqueezeBackward1&gt;))"
  },
  {
    "objectID": "posts/ml/2022-11-21-ml-11w.html#lstm은-왜-강한가",
    "href": "posts/ml/2022-11-21-ml-11w.html#lstm은-왜-강한가",
    "title": "RNN (11주차)",
    "section": "LSTM은 왜 강한가?",
    "text": "LSTM은 왜 강한가?\n\ndata: abaB\n\ntxt = list('abaB')*100\ntxt[:5]\n\n['a', 'b', 'a', 'B', 'a']\n\n\n\nn_words = 3\n\n\nmapping = {'a':0, 'b':1, 'B':2}\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:10],txt_y[:10]\n\n(['a', 'b', 'a', 'B', 'a', 'b', 'a', 'B', 'a', 'b'],\n ['b', 'a', 'B', 'a', 'b', 'a', 'B', 'a', 'b', 'a'])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx,y\n\n(tensor([[1., 0., 0.],\n         [0., 1., 0.],\n         [1., 0., 0.],\n         ...,\n         [1., 0., 0.],\n         [0., 1., 0.],\n         [1., 0., 0.]]),\n tensor([[0., 1., 0.],\n         [1., 0., 0.],\n         [0., 0., 1.],\n         ...,\n         [0., 1., 0.],\n         [1., 0., 0.],\n         [0., 0., 1.]]))\n\n\n\n\n1000 epoch\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(3,2) \nlinr = torch.nn.Linear(2,3) \n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+ list(linr.parameters()),lr=0.1)\n\n\n_water = torch.zeros(1,2) \nfor epoc in range(1000): \n    ## step1 \n    hidden, (ht,ct) = lstm(x,(_water,_water))\n    output = linr(hidden)\n    ## step2\n    loss = loss_fn(output,y) \n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\n\n시각화\n\nT = len(x)\ninput_gate = torch.zeros(T,2)\nforget_gate = torch.zeros(T,2)\noutput_gate = torch.zeros(T,2)\ng = torch.zeros(T,2)\ncell = torch.zeros(T,2)\nh = torch.zeros(T,2) \n\n\n변수를 담을 빈 셋 설정\n\n\nfor t in range(T): \n    ## 1: calculate _ifgo \n    _ifgo = x[[t]] @ lstm.weight_ih_l0.T + h[[t]] @ lstm.weight_hh_l0.T + lstm.bias_ih_l0 + lstm.bias_hh_l0 \n    ## 2: decompose _ifgo \n    input_gate[[t]] = sig(_ifgo[:,0:2])\n    forget_gate[[t]] = sig(_ifgo[:,2:4])\n    g[[t]] = tanh(_ifgo[:,4:6])\n    output_gate[[t]] = sig(_ifgo[:,6:8])\n    ## 3: calculate ht,ct \n    cell[[t]] = forget_gate[[t]] * cell[[t]] + input_gate[[t]] * g[[t]]\n    h[[t]] = output_gate[[t]] * tanh(cell[[t]])\n\n\ncombinded1 = torch.concat([input_gate,forget_gate,output_gate],axis=1)\ncombinded2 = torch.concat([g,cell,h,soft(output)],axis=1)\n\n\nplt.matshow(combinded1[-8:].data,cmap='bwr',vmin=-1,vmax=1);\nplt.xticks(range(combinded1.shape[-1]),labels=['i']*2 + ['f']*2 + ['o']*2);\nplt.matshow(combinded2[-8:].data,cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(combinded2.shape[-1]),labels=['g']*2 + ['c']*2 + ['h']*2 + ['yhat']*3);\n\n\n\n\n\n\n\n\n상단그림은 게이트의 값들만 시각화, 하단그림은 게이트 이외의 값들을 시각화\n\n\n\n시각화의 해석I\n\nplt.matshow(combinded1[-8:].data,cmap='bwr',vmin=-1,vmax=1);\nplt.xticks(range(combinded1.shape[-1]),labels=['i']*2 + ['f']*2 + ['o']*2);\n\n\n\n\n- input_gate, forget_gate, output_gate는 모두 0~1 사이의 값을 가진다.\n- 이 값들은 각각 모두 \\({\\boldsymbol g}_t, {\\boldsymbol c}_{t-1}, \\tanh({\\boldsymbol c}_t)\\)에 곱해진다. 따라서 input_gate, forget_gate, output_gate 는 gate의 역할로 비유가능하다. (1이면 통과, 0이면 차단)\n\ninput_gate: \\({\\boldsymbol g}_t\\)의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정\nforget_gate: \\({\\boldsymbol c}_{t-1}\\)의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정\noutput_gate: \\(\\tanh({\\boldsymbol c}_t)\\)의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정\n\n(서연 필기)\n\n값들이 0과 1사이의 값을 가진다\n파 -1 흰 0 빨 1\n0 곱하면 어떤 값이든 0이 되니까 차단한다 표현\n\n\n\n시각화의 해석II\n\nplt.matshow(combinded2[-8:].data,cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(combinded2.shape[-1]),labels=['g']*2 + ['c']*2 + ['h']*2 + ['yhat']*3);\n\n\n\n\n- 결국 \\({\\boldsymbol g}_t\\to {\\boldsymbol c}_t \\to {\\boldsymbol h}_t \\to \\hat{\\boldsymbol y}\\) 의 느낌이다. (\\({\\boldsymbol h}_t\\)를 계산하기 위해서는 \\({\\boldsymbol c}_t\\)가 필요했고 \\({\\boldsymbol c}_t\\)를 계산하기 위해서는 \\({\\boldsymbol c}_{t-1}\\)과 \\({\\boldsymbol g}_t\\)가 필요했음)\n\n\\({\\boldsymbol h}_t= \\tanh({\\boldsymbol c}_t) \\odot {\\boldsymbol o}_t\\)\n\\({\\boldsymbol c}_t ={\\boldsymbol c}_{t-1} \\odot {\\boldsymbol f}_t + {\\boldsymbol g}_{t} \\odot {\\boldsymbol i}_t\\)\n\n- \\({\\boldsymbol g}_t,{\\boldsymbol c}_t,{\\boldsymbol h}_t\\) 모두 \\({\\boldsymbol x}_t\\)의 정보를 숙성시켜 가지고 있는 느낌이 든다.\n- \\({\\boldsymbol g}_t\\) 특징: 보통 -1,1 중 하나의 값을 가지도록 학습되어 있다. (마치 RNN의 hidden node처럼!)\n\n\\(\\boldsymbol{g}_t = \\tanh({\\boldsymbol x}_t {\\bf W}_{ig} + {\\boldsymbol h}_{t-1} {\\bf W}_{hg}+ {\\boldsymbol b}_{ig}+{\\boldsymbol b}_{hg})\\)\n\n- \\({\\boldsymbol c}_t\\) 특징: \\({\\boldsymbol g}_t\\)와 매우 비슷하지만 약간 다른값을 가진다. 그래서 \\({\\boldsymbol g}_t\\)와는 달리 -1,1 이외의 값도 종종 등장.\n\nprint(\"first row: gt={}, ct={}\".format(g[-8].data, cell[-8].data))\nprint(\"second row: gt={}, ct={}\".format(g[-7].data, cell[-7].data))\n#g[-7], cell[-7]\n\nfirst row: gt=tensor([ 0.9999, -0.9999]), ct=tensor([ 0.9647, -0.9984])\nsecond row: gt=tensor([ 0.9970, -0.9554]), ct=tensor([ 0.3592, -0.9373])\n\n\n- \\({\\boldsymbol h}_t\\) 특징: (1) \\({\\boldsymbol c}_t\\)의 느낌이 있음 하지만 약간의 변형이 있음. (2) -1~1 사이에의 값을 훨씬 다양하게 가진다. (tanh때문)\n(서연 필기)\n\ncomparison of g,c part\n\n보니까 빨간 색은 1에 가까운 값, 파란색은 -1에 가까운 값들을 띄었다.\n그리고 연한 빨간색인 부분은 0.3592로 낮았고, g부분과 c부분이 열별로 보았을 때 달랐다\n\n\n\nprint(\"first row: gt={}, ct={}, ht={}\".format(g[-8].data, cell[-8].data,h[-8].data))\nprint(\"second row: gt={}, ct={}, ht={}\".format(g[-7].data, cell[-7].data,h[-7].data))\n#g[-7], cell[-7]\n\nfirst row: gt=tensor([ 0.9999, -0.9999]), ct=tensor([ 0.9647, -0.9984]), ht=tensor([ 0.7370, -0.3323])\nsecond row: gt=tensor([ 0.9970, -0.9554]), ct=tensor([ 0.3592, -0.9373]), ht=tensor([ 0.0604, -0.6951])\n\n\n(서연 필기)\n\ncomparison of c,h part\n\nh는 c와 무관해보이지 않는다.\n단지 어떤 변형이 있는 것 같다.\n\n\n- 예전의문 해결\n\n실험적으로 살펴보니 LSTM이 RNN보다 장기기억에 유리했음.\n그 이유: RRN은 \\({\\boldsymbol h}_t\\)의 값이 -1 혹은 1로 결정되는 경우가 많았음. 그러나 경우에 따라서는 \\({\\boldsymbol h}_t\\)이 -1~1의 값을 가지는 것이 문맥적 뉘앙스를 포착하기에는 유리한데 LSTM이 이러한 방식으로 학습되는 경우가 많았음.\n왜 LSTM의 \\({\\boldsymbol h}_t\\)은 -1,1 이외의 값을 쉽게 가질 수 있는가? (1) gate들의 역할 (2) 마지막에 취해지는 tanh 때문\n\n\n\nLSTM의 알고리즘 리뷰 I (수식위주)\n(step1) calculate \\({\\tt ifgo}\\)\n\\({\\tt ifgo} = {\\boldsymbol x}_t \\big[{\\bf W}_{ii} | {\\bf W}_{if}| {\\bf W}_{ig} |{\\bf W}_{io}\\big] + {\\boldsymbol h}_{t-1} \\big[ {\\bf W}_{hi}|{\\bf W}_{hf} |{\\bf W}_{hg} | {\\bf W}_{ho} \\big] + bias\\)\n\\(=\\big[{\\boldsymbol x}_t{\\bf W}_{ii} + {\\boldsymbol h}_{t-1}{\\bf W}_{hi} ~\\big|~ {\\boldsymbol x}_t{\\bf W}_{if}+ {\\boldsymbol h}_{t-1}{\\bf W}_{hf}~ \\big|~ {\\boldsymbol x}_t{\\bf W}_{ig} + {\\boldsymbol h}_{t-1}{\\bf W}_{hg} ~\\big|~ {\\boldsymbol x}_t{\\bf W}_{io} + {\\boldsymbol h}_{t-1}{\\bf W}_{ho} \\big] + bias\\)\n참고: 위의 수식은 아래코드에 해당하는 부분\nifgo = xt @ lstm_cell.weight_ih.T + ht @ lstm_cell.weight_hh.T + lstm_cell.bias_ih + lstm_cell.bias_hh\n(step2) decompose \\({\\tt ifgo}\\) and get \\({\\boldsymbol i}_t\\), \\({\\boldsymbol f}_t\\), \\({\\boldsymbol g}_t\\), \\({\\boldsymbol o}_t\\)\n\\({\\boldsymbol i}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{ii} + {\\boldsymbol h}_{t-1} {\\bf W}_{hi} +bias )\\)\n\\({\\boldsymbol f}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{if} + {\\boldsymbol h}_{t-1} {\\bf W}_{hf} +bias )\\)\n\\({\\boldsymbol g}_t = \\tanh({\\boldsymbol x}_t {\\bf W}_{ig} + {\\boldsymbol h}_{t-1} {\\bf W}_{hg} +bias )\\)\n\\({\\boldsymbol o}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{io} + {\\boldsymbol h}_{t-1} {\\bf W}_{ho} +bias )\\)\n(step3) calculate \\({\\boldsymbol c}_t\\) and \\({\\boldsymbol h}_t\\)\n\\({\\boldsymbol c}_t = {\\boldsymbol i}_t \\odot {\\boldsymbol g}_t+ {\\boldsymbol f}_t \\odot {\\boldsymbol c}_{t-1}\\)\n\\({\\boldsymbol h}_t = \\tanh({\\boldsymbol o}_t \\odot {\\boldsymbol c}_t)\\)\n\n\nLSTM의 알고리즘 리뷰 II (느낌위주)\n\\(x_t, h_{t-1} \\underrightarrow{lin} \\text{ } \\triangleleft \\text{ }\\underrightarrow{sig} \\text{ }o_t\\)\n\\(x_t, h_{t-1} \\underrightarrow{lin} \\text{ }\\circ \\text{ , } \\square \\text{, } \\star \\text{, } \\triangleleft \\text{ } \\to \\sigma(circ) \\text{, }\\sigma(\\square) \\text{ , }\\tanh(\\star)\\text{ , } \\sigma(\\triangleleft) \\sim i_t, f_t, g_t, o_t\\)\n\n이해 및 암기를 돕기위해서 비유적으로 설명한 챕터입니다..\n\n- 느낌1: RNN이 콩물에서 간장을 한번에 숙성시키는 방법이라면 LSTM은 콩물에서 간장을 3차로 나누어 숙성하는 느낌이다.\n\n콩물: \\({\\boldsymbol x}_t\\)\n1차숙성: \\({\\boldsymbol g}_t\\)\n2차숙성: \\({\\boldsymbol c}_t\\)\n3차숙성: \\({\\boldsymbol h}_t\\)\n\n- 느낌2: \\({\\boldsymbol g}_t\\)에 대하여\n\n계산방법: \\({\\boldsymbol x}_t\\)와 \\({\\boldsymbol h}_{t-1}\\)를 \\({\\bf W}_{ig}, {\\bf W}_{hg}\\)를 이용해 선형결합하고 \\(\\tanh\\)를 취한 결과\nRNN에서 간장을 만들던 그 수식에서 \\(h_t\\)를 \\(g_t\\)로 바꾼것\n크게 2가지의 의미를 가진다 (1) 과거와 현재의 결합 (2) 활성화함수 \\(\\tanh\\)를 적용\n\n(서연 필기)\n\\(x_t, h_{t-1} \\underrightarrow{lin} \\text{ }\\circ \\text{ }\\underrightarrow{sig} \\text{ }i_t\\)\n\\(x_t, h_{t-1} \\underrightarrow{lin} \\text{ }\\square \\text{ } \\underrightarrow{sig} \\text{ }f_t\\)\n\\(x_t, h_{t-1} \\underrightarrow{lin} \\text{ }\\star \\text{ } \\underrightarrow{tanh} \\text{ }g_t\\)\n를 풀어서 쓰면\n\\(\\tanh(x_t W_{ig} + h_{t-1} W_{hg} + bias)\\)\nRNN: \\(h_t = \\tanh(x_t W + h_{t-1} W + bias)\\)\nLSTM: \\(g_t = \\tanh(x_t W + h_{t-1} W + bias)\\) - 과거\\(h_{t-1}\\)와 현재\\(x_t\\)의 결합\n- 느낌3: \\({\\boldsymbol c}_t\\)에 대하여 (1)\n\n계산방법: \\({\\boldsymbol g}_{t}\\)와 \\({\\boldsymbol c}_{t-1}\\)를 요소별로 선택하고 더하는 과정\n\\(g_t\\)는 (1) 과거와 현재의 결합 (2) 활성화함수 tanh를 적용으로 나누어지는데 이중에서 (1) 과거와 현재의 정보를 결합하는 과정만 해당한다. 차이점은 요소별 선택 후 덧셈\n\n\\(g_t\\)는 선형 결합\n\n이러한 결합을 쓰는 이유? 게이트를 이용하여 과거와 현재의 정보를 제어 (일반적인 설명, 솔직히 내가 좋아하는 설명은 아님)\n\n(서연 필기)\n\\(c_t = g_t \\odot Input + c_{t-1} \\odot Forget\\)\n- 느낌4: \\({\\boldsymbol c}_t\\)에 대하여 (2) // \\({\\boldsymbol c}_t\\)는 왜 과거와 현재의 정보를 제어한다고 볼 수 있는가?\n\\(t=1\\) 시점 계산과정관찰\n\ninput_gate[1],g[1],forget_gate[1],cell[0]\n\n(tensor([0.9065, 0.9999], grad_fn=&lt;SelectBackward0&gt;),\n tensor([0.9931, 0.9999], grad_fn=&lt;SelectBackward0&gt;),\n tensor([0.9931, 0.0014], grad_fn=&lt;SelectBackward0&gt;),\n tensor([ 0.3592, -0.9373], grad_fn=&lt;SelectBackward0&gt;))\n\n\n\\([0.9,1.0] \\odot {\\boldsymbol g}_t + [1.0,0.0] \\odot {\\boldsymbol c}_{t-1}\\)\n(서연 필기)\n여기서 곱은 element별 곱 - \\([0.9,1.0] \\odot g_t = [0.9,1.0]\\odot [g_1,g_2] = [0.9g_1(현재)_,1.0g_2(과거)]\\) - 여기서 0이 현재에 곱해지면 현재를 기억하지 않고 과거에 0이 곱해지면 과거를 기억하지 않도록 조정할 수 있음\n\\(\\star\\) gate없으면 조정 못 하나??\\(\\to\\) no, weigjht로도 조정할 수 있지 않을까?\n\nforget_gate는 \\(c_{t-1}\\)의 첫번째 원소는 기억하고, 두번째 원소는 잊으라고 말하고 있음 // forget_gate는 과거(\\(c_{t-1}\\))의 정보를 얼마나 잊을지 (= 얼마나 기억할지) 를 결정한다고 해석할 수 있다.\ninput_gate는 \\(g_{t}\\)의 첫번째 원소와 두번째 원소를 모두 기억하되 두번째 원소를 좀 더 중요하게 기억하라고 말하고 있음 // input_gate는 현재(\\(g_{t}\\))의 정보를 얼만큼 강하게 반영할지 결정한다.\n이 둘을 조합하면 \\({\\boldsymbol c}_t\\)가 현재와 과거의 정보중 어떠한 정보를 더 중시하면서 기억할지 결정한다고 볼 수 있다.\n\n\n이 설명은 제가 좀 싫어해요, 싫어하는 이유는 (1) “기억의 정도를 조절한다”와 “망각의 정도를 조절한다”는 사실 같은말임. 그래서 forget_gate의 용어가 모호함. (2) 기억과 망각을 조정하는 방식으로 꼭 gate의 개념을 사용해야 하는건 아님\n\n- 느낌5: \\({\\boldsymbol c}_t\\)에 대하여 (3)\n\n사실상 LSTM 알고리즘의 꽃이라 할 수 있음.\nLSTM은 long short term memory의 약자임. 기존의 RNN은 장기기억을 활용함에 약점이 있는데 LSTM은 단기기억/장기기억 모두 잘 활용함.\nLSTM이 장기기억을 잘 활용하는 비법은 바로 \\({\\boldsymbol c}_t\\)에 있다.\n\n(서연필기) \\(c_t\\)로 과거, 현재 기억 조절할 수 있기 때문에\n- 느낌6: \\({\\boldsymbol h}_t\\)에 대하여 - 계산방법: \\(\\tanh({\\boldsymbol c}_t)\\)를 요소별로 선택\n데이터 다 가져와서 선택하는 방식\n- RNN, LSTM의 변수들 비교 테이블\n\n\n\n\n\n\n\n\n\n\n\n\n\n과거정보\n현재정보\n과거와 현재의 결합방식\n활성화\n느낌\n비고\n\n\n\n\nRNN-\\({\\boldsymbol h}_t\\)\n\\({\\boldsymbol h}_{t-1}\\)\n\\({\\boldsymbol x}_t\\)\n\\(\\times\\) W \\(\\to\\) \\(+\\)\n\\(\\tanh\\)\n간장\n\n\n\n\n\n\n\n\n\n\n\n\nLSTM-\\({\\boldsymbol g}_t\\)\n\\({\\boldsymbol h}_{t-1}\\)\n\\({\\boldsymbol x}_t\\)\n\\(\\times\\)W \\(\\to\\) \\(+\\)\n\\(\\tanh\\)\n1차간장\n\n\n\nLSTM-\\({\\boldsymbol c}_t\\)\n\\({\\boldsymbol c}_{t-1}\\)\n\\({\\boldsymbol g}_t\\)\n\\(\\odot\\) W\\(\\to\\) \\(+\\)\nNone\n2차간장\ngate를 열림정도를 판단할때 \\({\\boldsymbol x}_t\\)와 \\({\\boldsymbol h}_{t-1}\\)을 이용\n\n\nLSTM-\\({\\boldsymbol h}_t\\)\nNone\n\\({\\boldsymbol c}_t\\)\nNone\n\\(\\tanh\\), \\(\\odot\\)\n3차간장\ngate를 열림정도를 판단할때 \\({\\boldsymbol x}_t\\)와 \\({\\boldsymbol h}_{t-1}\\)을 이용\n\n\n\n\nRNN은 기억할 과거정보가 \\({\\boldsymbol h}_{t-1}\\) 하나이지만 LSTM은 \\({\\boldsymbol c}_{t-1}\\), \\({\\boldsymbol h}_{t-1}\\) 2개이다.\n\n- 알고리즘리뷰 :\n\n콩물\\(x_t\\),과거3차간장\\(h_{t-1}\\) \\(\\overset{\\times,+,\\tanh}{\\longrightarrow}\\) 현재1차간장\\(g_t\\)\n현재1차간장\\(c_{t-1}\\), 과거2차간장 \\(\\overset{\\odot,+,\\tanh}{\\longrightarrow}\\) 현재2차간장\n현재2차간장\\(c_t\\) \\(\\overset{\\tanh,\\odot}{\\longrightarrow}\\) 현재3차간장\\(h_t\\)\n\n\n\nLSTM이 강한이유\n- LSTM이 장기기억에 유리함. 그 이유는 input, forget, output gate 들이 과거기억을 위한 역할을 하기 때문.\n\n비판: 아키텍처에 대한 이론적 근거는 없음. 장기기억을 위하여 꼭 LSTM같은 구조일 필요는 없음. (왜 3차간장을 만들때 tanh를 써야하는지? 게이트는 꼭3개이어야 하는지?)\n\n- 저는 사실 아까 살펴본 아래의 이유로 이해하고 있습니다.\n\n실험적으로 살펴보니 LSTM이 RNN보다 장기기억에 유리했음.\n그 이유: RRN은 \\({\\boldsymbol h}_t\\)의 값이 -1 혹은 1로 결정되는 경우가 많았음. 그러나 경우에 따라서는 \\({\\boldsymbol h}_t\\)이 -1~1의 값을 가지는 것이 문맥적 뉘앙스를 포착하기에는 유리한데 LSTM이 이러한 방식으로 학습되는 경우가 많았음.\n왜 LSTM의 \\({\\boldsymbol h}_t\\)은 -1,1 이외의 값을 쉽게 가질 수 있는가? (1) gate들의 역할 (2) 마지막에 취해지는 tanh 때문\n\n문잭적으로 이해 -&gt;유리하다 칭함"
  },
  {
    "objectID": "posts/ml/2022-11-21-ml-11w.html#참고자료들",
    "href": "posts/ml/2022-11-21-ml-11w.html#참고자료들",
    "title": "RNN (11주차)",
    "section": "참고자료들",
    "text": "참고자료들\n\nhttps://colah.github.io/posts/2015-08-Understanding-LSTMs/\nhttps://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\nhttps://arxiv.org/abs/1402.1128"
  },
  {
    "objectID": "posts/ml/2022-12-13-final_seoyeon.html",
    "href": "posts/ml/2022-12-13-final_seoyeon.html",
    "title": "Finalterm",
    "section": "",
    "text": "기말고사\nimport torch \nfrom fastai.text.all import *"
  },
  {
    "objectID": "posts/ml/2022-12-13-final_seoyeon.html#covid19-tweets-to-텍스트생성-30점",
    "href": "posts/ml/2022-12-13-final_seoyeon.html#covid19-tweets-to-텍스트생성-30점",
    "title": "Finalterm",
    "section": "1. COVID19 tweets \\(\\to\\) 텍스트생성 (30점)",
    "text": "1. COVID19 tweets \\(\\to\\) 텍스트생성 (30점)\n아래의 코드를 이용하여 자료를 다운로드 하라.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/STML2022/main/posts/Corona_NLP_train.csv',encoding=\"ISO-8859-1\")\ndf\n\n\n\n\n\n\n\n\nUserName\nScreenName\nLocation\nTweetAt\nOriginalTweet\nSentiment\n\n\n\n\n0\n3799\n48751\nLondon\n16-03-2020\n@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8\nNeutral\n\n\n1\n3800\n48752\nUK\n16-03-2020\nadvice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order\nPositive\n\n\n2\n3801\n48753\nVagabonds\n16-03-2020\nCoronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P\nPositive\n\n\n3\n3802\n48754\nNaN\n16-03-2020\nMy food stock is not the only one which is empty...\\r\\r\\n\\r\\r\\nPLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \\r\\r\\nStay calm, stay safe.\\r\\r\\n\\r\\r\\n#COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j\nPositive\n\n\n4\n3803\n48755\nNaN\n16-03-2020\nMe, ready to go at supermarket during the #COVID19 outbreak.\\r\\r\\n\\r\\r\\nNot because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\\r\\r\\n\\r\\r\\n#CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n\nExtremely Negative\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n41152\n44951\n89903\nWellington City, New Zealand\n14-04-2020\nAirline pilots offering to stock supermarket shelves in #NZ lockdown #COVID-19 https://t.co/cz89uA0HNp\nNeutral\n\n\n41153\n44952\n89904\nNaN\n14-04-2020\nResponse to complaint not provided citing COVID-19 related delays. Yet prompt in rejecting policy before consumer TAT is over. Way to go ?\nExtremely Negative\n\n\n41154\n44953\n89905\nNaN\n14-04-2020\nYou know itÂ’s getting tough when @KameronWilds is rationing toilet paper #coronavirus #toiletpaper @kroger martinsville, help us out!!\nPositive\n\n\n41155\n44954\n89906\nNaN\n14-04-2020\nIs it wrong that the smell of hand sanitizer is starting to turn me on?\\r\\r\\n\\r\\r\\n#coronavirus #COVID19 #coronavirus\nNeutral\n\n\n41156\n44955\n89907\ni love you so much || he/him\n14-04-2020\n@TartiiCat Well new/used Rift S are going for $700.00 on Amazon rn although the normal market price is usually $400.00 . Prices are really crazy right now for vr headsets since HL Alex was announced and it's only been worse with COVID-19. Up to you whethe\nNegative\n\n\n\n\n41157 rows × 6 columns\n\n\n\n(1) TextDataLoaders.from_df을 이용하여 dls오브젝트를 만들어라.\n\ntext_col=‘OriginalTweet’ 로 설정\nis_lm=True 로 설정\nseq_len=64 로 설정\n\n\n## 올바르게 dls를 생성하였을 경우 dls.show_batch()의 결과는 아래와 같음. \n\n\ndls = TextDataLoaders.from_df(df,is_lm=True,seq_len=64,text_col='OriginalTweet')\n\n\n\n\n\n\n\n\n\ndls.show_batch()\n\n\n\n\n\ntext\ntext_\n\n\n\n\n0\nxxbos xxmaj i 'd like to say i xxunk this up because of # covid_19 quarantine , but i work in a grocery store and thankfully i still have a job . \\r\\r\\n\\r\\r\\n i did have a blast making it . \\r\\r\\n\\r\\r\\n▁ # dinner # pasta # xxunk # xxunk …▁ https : / / t.co / xxunk xxbos @gavinnewsom gavinnewsom xxmaj gov .\nxxmaj i 'd like to say i xxunk this up because of # covid_19 quarantine , but i work in a grocery store and thankfully i still have a job . \\r\\r\\n\\r\\r\\n i did have a blast making it . \\r\\r\\n\\r\\r\\n▁ # dinner # pasta # xxunk # xxunk …▁ https : / / t.co / xxunk xxbos @gavinnewsom gavinnewsom xxmaj gov . xxmaj\n\n\n1\nhttps : / / t.co / xxunk xxbos xxmaj wow @donaldjtrumpjr do you have a pair of these xxunk just popped up in my xxmaj facebook feed ! xxmaj buying them to support online shopping and xxmaj trump ! https : / / t.co / xxunk # coronavirus # trump2020 https : / / t.co / xxunk xxbos xxmaj if you or your loved\n: / / t.co / xxunk xxbos xxmaj wow @donaldjtrumpjr do you have a pair of these xxunk just popped up in my xxmaj facebook feed ! xxmaj buying them to support online shopping and xxmaj trump ! https : / / t.co / xxunk # coronavirus # trump2020 https : / / t.co / xxunk xxbos xxmaj if you or your loved one\n\n\n2\nnow looking at some sort of super gel . i thought i was gon na save money by cooking b xxrep 4 u t that money is going to online shopping xxrep 5 ? \\r\\r\\n▁ # coronavirus # life xxbos xxup covid - alert : xxmaj coronavirus xxmaj crashes xxmaj prices for xxmaj hotels , xxmaj rental xxmaj cars , and xxmaj women 's\nlooking at some sort of super gel . i thought i was gon na save money by cooking b xxrep 4 u t that money is going to online shopping xxrep 5 ? \\r\\r\\n▁ # coronavirus # life xxbos xxup covid - alert : xxmaj coronavirus xxmaj crashes xxmaj prices for xxmaj hotels , xxmaj rental xxmaj cars , and xxmaj women 's xxmaj\n\n\n3\nthe window of a house in # xxmaj xxunk # xxmaj xxunk today while driving to supermarket . # happy # coronavirus # xxunk https : / / t.co / xxunk xxbos xxup covid 19 xxmaj requires xxmaj website xxmaj accessibility xxmaj xxunk for consumer - facing xxmaj businesses https : / / t.co / xxunk xxbos all these stores have sales cause of\nwindow of a house in # xxmaj xxunk # xxmaj xxunk today while driving to supermarket . # happy # coronavirus # xxunk https : / / t.co / xxunk xxbos xxup covid 19 xxmaj requires xxmaj website xxmaj accessibility xxmaj xxunk for consumer - facing xxmaj businesses https : / / t.co / xxunk xxbos all these stores have sales cause of covid-19\n\n\n4\nxxmaj business xxmaj alive xxmaj during xxmaj epidemic \\r\\r\\n▁ # xxup prices # xxmaj business # epidemic # socialmediamarketing # covid_19 # coronavirus # seo # xxunk # xxunk # smo # xxup ppc \\r\\r\\n https : / / t.co / xxunk https : / / t.co / xxunk xxbos xxunk xxunk xxmaj prices vary from mask to mask , however it is a\nbusiness xxmaj alive xxmaj during xxmaj epidemic \\r\\r\\n▁ # xxup prices # xxmaj business # epidemic # socialmediamarketing # covid_19 # coronavirus # seo # xxunk # xxunk # smo # xxup ppc \\r\\r\\n https : / / t.co / xxunk https : / / t.co / xxunk xxbos xxunk xxunk xxmaj prices vary from mask to mask , however it is a necessary\n\n\n5\n# inflation , rising prices and declining purchasing power are already unavoidable due to # xxup covid-19 and low oil prices , with implications for political stability and elections in # xxmaj russia . xxunk https : / / t.co / xxunk xxbos xxmaj iâ’m thrilled that xxunk proactively applied to xxunk and has since been approved to temporarily reduce overage charges and expand\ninflation , rising prices and declining purchasing power are already unavoidable due to # xxup covid-19 and low oil prices , with implications for political stability and elections in # xxmaj russia . xxunk https : / / t.co / xxunk xxbos xxmaj iâ’m thrilled that xxunk proactively applied to xxunk and has since been approved to temporarily reduce overage charges and expand internet\n\n\n6\nmacron has imposed a two - week lockdown , declaring a xxunk on # coronavirus ; cancelled municipal xxunk have been ordered to stay home and will only be allowed out for â“essential xxunk such as trips to the grocery store or pharmacy ! ? xxbos xxmaj we promise we 're not hoarding . xxmaj who could have know that donations into our #\nhas imposed a two - week lockdown , declaring a xxunk on # coronavirus ; cancelled municipal xxunk have been ordered to stay home and will only be allowed out for â“essential xxunk such as trips to the grocery store or pharmacy ! ? xxbos xxmaj we promise we 're not hoarding . xxmaj who could have know that donations into our # xxunk\n\n\n7\ncovid-19 . and i ( and other supermarket workers , and xxup nhs / hospital staff , and care workers ) will get little to nothing in return . xxbos \" # xxmaj travel xxmaj news : xxmaj xxunk xxmaj announces # xxmaj travel xxmaj industry 's xxmaj first and xxmaj only xxmaj daily xxmaj measure of # xxmaj consumer # xxmaj travel xxmaj\n. and i ( and other supermarket workers , and xxup nhs / hospital staff , and care workers ) will get little to nothing in return . xxbos \" # xxmaj travel xxmaj news : xxmaj xxunk xxmaj announces # xxmaj travel xxmaj industry 's xxmaj first and xxmaj only xxmaj daily xxmaj measure of # xxmaj consumer # xxmaj travel xxmaj patterns\n\n\n8\nis wrong with people ? xxmaj stop hoarding , you brainless , selfish xxup scum xxrep 3 ! # xxup covidiot # xxup covid?19 # coronavirus https : / / t.co / xxunk xxbos xxmaj never thought i d hear an interview like this on xxmaj health xxmaj secretary pleading with people to stop panic buying food and telling former nurses amp doctors your\nwrong with people ? xxmaj stop hoarding , you brainless , selfish xxup scum xxrep 3 ! # xxup covidiot # xxup covid?19 # coronavirus https : / / t.co / xxunk xxbos xxmaj never thought i d hear an interview like this on xxmaj health xxmaj secretary pleading with people to stop panic buying food and telling former nurses amp doctors your xxup\n\n\n\n\n\n(2) language_model_learner를 이용하여 오브젝트를 생성하라. lrnr.fine_tune(3,1e-1)을 이용하여 학습하라.\n\narch= AWD_LSTM 이용\nmetrics = [accuracy,perplexity]\n\n\nlrnr = language_model_learner(dls, arch= AWD_LSTM, metrics=[accuracy,perplexity] )\n\n\nlrnr.fine_tune(3,1e-1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\nperplexity\ntime\n\n\n\n\n0\n4.811512\n4.503637\n0.284446\n90.345108\n00:54\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\nperplexity\ntime\n\n\n\n\n0\n3.995195\n3.870983\n0.333415\n47.989555\n00:56\n\n\n1\n3.719837\n3.669204\n0.353983\n39.220692\n00:56\n\n\n2\n3.442434\n3.596037\n0.364176\n36.453487\n00:56\n\n\n\n\n\n(3) “the price of” 이후에 이어질 단어들을 생성하라. (n_words=20 으로 설정할 것)\n\n## 생성예시\n\n\n\n\n\n\n\n\n'the price of stuff increases in other states as a result of the # coronavirus pandemic . So it makes alternatives .'\n\n\n\nlrnr.predict('the price of', n_words=20) \n\n\n\n\n\n\n\n\n'the price of what we need is on Check out some Facebook websites Live with you and adapt to'"
  },
  {
    "objectID": "posts/ml/2022-12-13-final_seoyeon.html#covid19-tweets-to-분류-30점",
    "href": "posts/ml/2022-12-13-final_seoyeon.html#covid19-tweets-to-분류-30점",
    "title": "Finalterm",
    "section": "2. COVID19 tweets \\(\\to\\) 분류 (30점)",
    "text": "2. COVID19 tweets \\(\\to\\) 분류 (30점)\n아래의 코드를 이용하여 자료를 다운로드 하라.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/STML2022/main/posts/Corona_NLP_train.csv',encoding=\"ISO-8859-1\")\ndf\n\n\n\n\n\n\n\n\nUserName\nScreenName\nLocation\nTweetAt\nOriginalTweet\nSentiment\n\n\n\n\n0\n3799\n48751\nLondon\n16-03-2020\n@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8\nNeutral\n\n\n1\n3800\n48752\nUK\n16-03-2020\nadvice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order\nPositive\n\n\n2\n3801\n48753\nVagabonds\n16-03-2020\nCoronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P\nPositive\n\n\n3\n3802\n48754\nNaN\n16-03-2020\nMy food stock is not the only one which is empty...\\r\\r\\n\\r\\r\\nPLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \\r\\r\\nStay calm, stay safe.\\r\\r\\n\\r\\r\\n#COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j\nPositive\n\n\n4\n3803\n48755\nNaN\n16-03-2020\nMe, ready to go at supermarket during the #COVID19 outbreak.\\r\\r\\n\\r\\r\\nNot because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\\r\\r\\n\\r\\r\\n#CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n\nExtremely Negative\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n41152\n44951\n89903\nWellington City, New Zealand\n14-04-2020\nAirline pilots offering to stock supermarket shelves in #NZ lockdown #COVID-19 https://t.co/cz89uA0HNp\nNeutral\n\n\n41153\n44952\n89904\nNaN\n14-04-2020\nResponse to complaint not provided citing COVID-19 related delays. Yet prompt in rejecting policy before consumer TAT is over. Way to go ?\nExtremely Negative\n\n\n41154\n44953\n89905\nNaN\n14-04-2020\nYou know itÂ’s getting tough when @KameronWilds is rationing toilet paper #coronavirus #toiletpaper @kroger martinsville, help us out!!\nPositive\n\n\n41155\n44954\n89906\nNaN\n14-04-2020\nIs it wrong that the smell of hand sanitizer is starting to turn me on?\\r\\r\\n\\r\\r\\n#coronavirus #COVID19 #coronavirus\nNeutral\n\n\n41156\n44955\n89907\ni love you so much || he/him\n14-04-2020\n@TartiiCat Well new/used Rift S are going for $700.00 on Amazon rn although the normal market price is usually $400.00 . Prices are really crazy right now for vr headsets since HL Alex was announced and it's only been worse with COVID-19. Up to you whethe\nNegative\n\n\n\n\n41157 rows × 6 columns\n\n\n\n(1) TextDataLoaders.from_df을 이용하여 dls오브젝트를 만들어라.\n\ntext_col=’OriginalTweet’로 설정\nlabel_col=’Sentiment’로 설정\nseq_len=64 로 설정\n\n\n## 올바르게 dls를 생성하였을 경우 dls.show_batch()의 결과는 아래와 같음. \n\n\n\n\n\n\n\n\n\n\n\n\ntext\ncategory\n\n\n\n\n0\nxxbos xxrep 5 ? ? ? xxrep 7 ? ? ? xxrep 7 ? xxrep 4 ? xxrep 4 ? xxrep 11 ? ? ? xxrep 6 ? xxrep 4 ? , xxrep 3 ? xxrep 3 ? ? ? xxrep 3 ? xxrep 4 ? xxrep 3 ? ? ? ? ? xxrep 4 ? ? ? xxrep 3 ? , xxrep 4 ? ? ? ? ? xxrep 6 ? xxrep 3 ? xxrep 3 ? xxrep 3 ? ? ? xxrep 3 ? \\r\\r\\n▁ xxrep 5 ? xxrep 6 ? ? ? xxrep 3 ? xxrep 4 ? xxrep 4 ? ? ? xxrep 4 ? xxrep 6 ? xxrep 4 ? xxrep 8 ? ? ? xxrep 6 ? ? ? xxrep 5 ? ? ? xxrep 3 ? xxrep 4 ? ? ? xxrep 7 ? xxrep 5 ? - xxrep 8 ? xxrep 5\nNeutral\n\n\n1\nxxbos xxrep 5 ? xxrep 5 ? ? ? xxrep 6 ? xxrep 5 ? xxrep 3 ? ? ? xxrep 3 ? ? ? xxrep 4 ? xxrep 3 ? xxrep 3 ? xxrep 5 ? xxrep 10 ? xxrep 5 ? xxrep 5 ? xxrep 3 ? xxrep 5 ? ? ? xxrep 4 ? xxrep 7 ? xxrep 3 ? xxrep 3 ? \\r\\r\\n▁ # sindh government spokesman @murtazawahab1 terms # xxmaj quarantine facilities at # xxmaj xxunk border a joke . xxmaj watch the exclusive visuals of criminal negligence ? ? https : / / t.co / xxunk\nNegative\n\n\n2\nxxbos xxunk xxup very xxup soon xxup the xxup food xxup will xxup be xxup their xxup leverage xxup to xxup control xxup people . xxup hungry xxup people xxup are xxup easy xxup to xxup lead xxup if xxup you xxup promise xxup them xxup food . xxup they xxup are xxup not xxup just xxup killing xxup people xxup with xxup this xxup covid-19 , xxup but xxup the xxup big xxup farmers , xxup processors , xxup and xxup the xxup endless xxup chain xxup of xxup supply xxup and xxup dema\nExtremely Positive\n\n\n3\nxxbos xxmaj when xxmaj disneyland xxup reopens it will xxup feature a xxup harrowing xxup new xxup death - defying xxup xxunk -- xxup going to the xxup grocery xxup store & & xxup interacting w / xxup people w / in 6 ' when your xxup facemask xxup suddenly xxup slips , your xxup gloves xxup fall xxup off & & xxup you xxup forgot your xxup hand xxup sanitizer ! ! # xxmaj disneyland # xxunk # xxmaj covid_19 # xxup covid https : / / t.co / xxunk\nPositive\n\n\n4\nxxbos @gavinnewsom @govmurphy https : / / t.co / xxunk \\r\\r\\n xxup this xxup is xxup why xxup the # xxup coronavirus xxup is xxup so xxup contagious , a xxup single xxup cough xxup can xxup spread xxup across a xxup supermarket xxup aisle xxup right xxup over xxup the xxup aisle xxup and xxup into xxup the xxup next xxup aisle , xxup gross xxrep 4 ! xxup what xxup took xxup you xxup so xxup long xxup to xxup sign xxup an xxup eo xxup making xxup people\nExtremely Negative\n\n\n5\nxxbos # xxup xxunk : # xxup worldwide , xxup y' all xxup alright xxup out xxup there ? xxup the # xxup xxunk xxup is xxup indoors xxup xxunk ' xxup care xxup of # xxup xxunk xxup behind xxup the xxup scenes , xxup xxunk ' xxup this # xxup coronavirus xxup outbreak … supermarket xxup xxunk ' xxup daily : xxup xxunk ' xxup like # xxup xxunk xxup out xxup here … . xxup bought 20 xxup xxunk … https : / / t.co / xxunk\nExtremely Positive\n\n\n6\nxxbos # xxunk ? \\r\\r\\n\\r\\r\\n xxup with xxup no xxup sports xxup in xxup our xxup lives i xxup wanna xxup provide xxup y all xxup with xxup quality xxup xxunk xxup with xxup lower xxup prices xxup than xxup retail xxup all xxup xxunk xxup now xxup are 40 $ xxup each xxup until xxup sports xxup returns xxup due xxup to # xxmaj covid_19 \\r\\r\\n\\r\\r\\n xxup dms xxup are xxup always xxup open xxrep 4 ! xxup hmu xxrep 3 ! https : / / t.co / xxunk\nExtremely Negative\n\n\n7\nxxbos # xxup cbd xxup can not xxup cure xxup the # xxup coronavirus xxup but xxup it xxup can \\r\\r\\n▁ ? xxup cure xxup coronavirus xxup symptoms \\r\\r\\n▁ ? xxup ease xxup your xxup anxiety \\r\\r\\n▁ ? xxup boost xxup immune xxup system \\r\\r\\n▁ ? xxup act xxup as a xxup natural xxup painkiller ! \\r\\r\\n * prices have been reduced at this difficult time to help everyone ? ? \\r\\r\\n https : / / t.co / wrlhyzizaa # keep safe https : / / t.co / xxunk\nExtremely Positive\n\n\n8\nxxbos xxmaj what # coronavirus taught us : \\r\\r\\n 1 . xxmaj to stay at home and be with family . \\r\\r\\n 2 . xxmaj to eat home made , healthy , food . \\r\\r\\n 3 . xxmaj to maintain hygiene . \\r\\r\\n 4 . xxmaj to meditate . \\r\\r\\n 5 . xxmaj to give up junk food . \\r\\r\\n 6 . xxmaj to avoid unnecessary travel . \\r\\r\\n 7 . xxmaj to stockup groceries on time . \\r\\r\\n 8 . xxmaj help your spouse in daily xxunk .\nPositive\n\n\n\n\n\n\ndls = TextDataLoaders.from_df(df,text_col='OriginalTweet',label_col='Sentiment',seq_len=64)\n\n\n\n\n\n\n\n\n\ndls.show_batch()\n\n\n\n\n\ntext\ncategory\n\n\n\n\n0\nxxbos xxrep 5 ? ? ? xxrep 7 ? ? ? xxrep 7 ? xxrep 4 ? xxrep 4 ? xxrep 11 ? ? ? xxrep 6 ? xxrep 4 ? , xxrep 3 ? xxrep 3 ? ? ? xxrep 3 ? xxrep 4 ? xxrep 3 ? ? ? ? ? xxrep 4 ? ? ? xxrep 3 ? , xxrep 4 ? ? ? ? ? xxrep 6 ? xxrep 3 ? xxrep 3 ? xxrep 3 ? ? ? xxrep 3 ? \\r\\r\\n▁ xxrep 5 ? xxrep 6 ? ? ? xxrep 3 ? xxrep 4 ? xxrep 4 ? ? ? xxrep 4 ? xxrep 6 ? xxrep 4 ? xxrep 8 ? ? ? xxrep 6 ? ? ? xxrep 5 ? ? ? xxrep 3 ? xxrep 4 ? ? ? xxrep 7 ? xxrep 5 ? - xxrep 8 ? xxrep 5\nNeutral\n\n\n1\nxxbos xxrep 5 ? : xxrep 4 ? xxrep 6 ? ? xxrep 8 ? \\r\\r\\n . \\r\\r\\n ? ? xxrep 6 ? xxrep 4 ? ? ? 500 xxrep 5 ? xxrep 5 ? ? ? xxrep 5 ? xxrep 7 ? xxrep 4 ? xxrep 7 ? ? ? xxrep 3 ? xxrep 7 ? xxrep 4 ? xxrep 6 ? xxrep 9 ? \" xxrep 6 ? \" xxrep 4 ? xxrep 7 ? xxrep 4 ? xxrep 6 ? xxrep 7 ? xxrep 5 ? xxrep 6 ? xxrep 3 ? xxrep 7 ? ? ? xxrep 5 ? .. \\r\\r\\n▁ # xxrep 3 ? _ xxrep 4 ? _ xxrep 6 ? _ xxrep 4 ? _ xxrep 3 ? https : / / t.co / xxunk\nNeutral\n\n\n2\nxxbos xxup ask xxup your xxup self xxup what xxup do xxup you xxup think xxup is xxup going xxup to xxup happen xxup the xxup time xxup to xxup wake xxup up xxup is xxup now xxup do xxup you xxup think xxup food xxup going xxup to xxup be xxup xxunk xxup on xxup shop xxup shelfs .. no \\r\\r\\n xxup do xxup you xxup think xxup food xxup rise xxup in xxup price .. yes \\r\\r\\n xxup i m xxup going xxup to xxup stock xxup up xxup as xxup much i xxup can \\r\\r\\n xxup food xxup ladies xxup gentleman xxup is xxup most xxup valuable xxup asset \\r\\r\\n▁ # xxmaj coronavirus # xxup covid19 https : / / t.co / xxunk\nExtremely Positive\n\n\n3\nxxbos # coronavirus xxmaj people , xxup stop xxup panic xxup buying , xxup you xxup do xxup not xxup need xxup to xxup stock xxup up xxup on xxup food xxup like xxup you xxup wo n't xxup see xxup the xxup sun xxup for xxup the xxup rest xxup of xxup your xxup life , xxup no xxup one xxup told xxup us xxup to xxup stock xxup up xxup on xxup toilet xxup paper , xxup no xxup one xxup told xxup us xxup to xxup stock xxup up xxup on xxup hand xxup sanitizer , xxup just xxup regular xxup soap xxup works xxup better . ( 1 )\nPositive\n\n\n4\nxxbos xxup keep xxup your xxup home xxup safe & & xxup clean \\r\\r\\n xxmaj the xxmaj best xxmaj way to xxmaj avoid the # xxmaj coronavirus is in xxmaj clean xxmaj home \\r\\r\\n xxmaj absolutely xxmaj outstanding xxmaj cleaning @ xxmaj awesome xxmaj rates \\r\\r\\n xxmaj prices : 2 xxmaj hours 2 xxmaj maids $ 75 + \\r\\r\\n xxmaj serving xxmaj las # xxmaj vegas , # xxmaj summerlin , # xxmaj xxunk xxmaj city & & xxmaj more \\r\\r\\n https : / / t.co / xxunk \\r\\r\\n ( xxunk - xxunk \\r\\r\\n▁ # xxup xxunk # xxup xxunk # xxup xxunk https : / / t.co / xxunk\nExtremely Positive\n\n\n5\nxxbos # coronavirus # xxmaj kits xxrep 3 ! # xxmaj masks ( 3 ply ) , # handsanitizer ( 75 % ) # xxunk , # xxmaj xxunk , # xxunk . xxmaj order xxmaj now xxrep 3 ! \\r\\r\\n ( # xxmaj families # xxmaj corporations \\r\\r\\n▁ # xxmaj entrepreneurs # hypebeast \\r\\r\\n▁ # xxup ap # xxunk # xxmaj cnn # xxup cdc # newyork # xxmaj atlanta # stlouis # xxmaj denver # xxup xxunk \\r\\r\\n▁ # xxmaj mayors # xxup xxunk ) \\r\\r\\n xxmaj visit : \\r\\r\\n https : / / t.co / xxunk https : / / t.co / xxunk\nNeutral\n\n\n6\nxxbos # xxup lda xxmaj city xxmaj lahore xxmaj residential xxmaj files xxmaj prices xxmaj update \\r\\r\\n xxup lda xxmaj city xxmaj lahore 5 xxmaj marla xxunk xxmaj lacs \\r\\r\\n xxup lda xxmaj city xxmaj lahore 10 xxmaj marla xxunk xxmaj lacs \\r\\r\\n xxup lda xxmaj city xxmaj lahore 1 xxmaj xxunk xxunk xxmaj lacs \\r\\r\\n note : next xxmaj ballot will be xxmaj held on 18th xxmaj april 2020 \\r\\r\\n\\r\\r\\n xxmaj xxunk xxmaj xxunk \\r\\r\\n xxunk xxrep 3 3 41 xxrep 3 7 16 \\r\\r\\n\\r\\r\\n▁ # pandemic \\r\\r\\n▁ # coronavirusinpakistan \\r\\r\\n▁ # covid_19 https : / / t.co / xxunk\nNeutral\n\n\n7\nxxbos xxmaj so glad i donâ’t : \\r\\r\\n xxmaj live in a big city . \\r\\r\\n xxmaj rely on takeout / dine out . \\r\\r\\n xxmaj rely on delivery . \\r\\r\\n xxmaj rely on transport . \\r\\r\\n\\r\\r\\n xxmaj so glad i xxup do : \\r\\r\\n xxmaj have 6 month stock of food . \\r\\r\\n xxmaj own guns / ammo . \\r\\r\\n xxmaj have most family / friends within blocks . \\r\\r\\n xxmaj live in a small town with woods . \\r\\r\\n xxmaj have a big truck / fam car . \\r\\r\\n▁ # coronavirus https : / / t.co / xxunk\nExtremely Positive\n\n\n8\nxxbos xxmaj in the wake of xxup covid 19 , xxmaj lets xxmaj share xxmaj burden . \\r\\r\\n\\r\\r\\n xxmaj enjoy xxmaj flat 10 % xxmaj off + xxmaj free xxmaj shipping and xxmaj xxunk . ? ? \\r\\r\\n\\r\\r\\n xxmaj hurry and shop our xxmaj products at xxup flat 10 % xxup off ! \\r\\r\\n\\r\\r\\n * term and xxmaj conditions xxmaj apply \\r\\r\\n https : / / t.co / xxunk \\r\\r\\n▁ # xxunk # sale # trackers # xxmaj xxunk # xxmaj fleet # xxmaj covid # xxmaj shopping # xxmaj tracking https : / / t.co / xxunk\nExtremely Positive\n\n\n\n\n\n(2) text_classifier_learner를 이용하여 오브젝트를 생성하라. lrnr.fine_tune(5,1e-2)을 이용하여 학습하라.\n\narch= AWD_LSTM 이용\nmetrics = accuracy 이용\n\n\nlrnr = text_classifier_learner(dls,AWD_LSTM,metrics=accuracy).to_fp16()\n\n\nlrnr.fine_tune(5,1e-2)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.451519\n1.370851\n0.389625\n00:08\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.158805\n1.060165\n0.558012\n00:15\n\n\n1\n0.940539\n0.825643\n0.677317\n00:16\n\n\n2\n0.786679\n0.702226\n0.732839\n00:16\n\n\n3\n0.656008\n0.682333\n0.743288\n00:16\n\n\n4\n0.593655\n0.661963\n0.758596\n00:16\n\n\n\n\n\n(3) 아래의 텍스트에 대한 분류결과를 확인하라.\n\n“the government’s approach to the pendemic has been a complete disaster”\n“the new vaccines hold the promise of a quick return to economic growth”\n\nhint “the government’s approach to the pendemic has been a complete disaster” 에 대하여서는 부정으로, “the new vaccines hold the promise of a quick return to economic growth”에 대하여서는 긍정으로 예측되어야 적절하다.\nnegative\n\nlrnr.predict(\"the government's approach to the pendemic has been a complete disaster\") \n\n\n\n\n\n\n\n\n('Extremely Negative',\n tensor(0),\n tensor([8.7544e-01, 3.0173e-06, 1.2416e-01, 7.9043e-05, 3.0868e-04]))\n\n\npositive\n\nlrnr.predict(\"the new vaccines hold the promise of a quick return to economic growth\") \n\n\n\n\n\n\n\n\n('Extremely Positive',\n tensor(1),\n tensor([1.2628e-06, 9.2473e-01, 5.2453e-05, 4.5041e-05, 7.5169e-02]))"
  },
  {
    "objectID": "posts/ml/2022-12-13-final_seoyeon.html#human-numbers-5-40점",
    "href": "posts/ml/2022-12-13-final_seoyeon.html#human-numbers-5-40점",
    "title": "Finalterm",
    "section": "3. human numbers 5 (40점)",
    "text": "3. human numbers 5 (40점)\n아래와 같은 데이터가 있다고 하자.\n\ntxt = (['one',',','two',',','three',',','four',',','five',',']*100)[:-1]\nmapping = {',':0, 'one':1, 'two':2, 'three':3, 'four':4, 'five':5} \ntxt_x = txt[:-1]\ntxt_y = txt[1:] \n\n\ntxt_x[:5], txt_y[:5]\n\n(['one', ',', 'two', ',', 'three'], [',', 'two', ',', 'three', ','])\n\n\n\ndef f(txt,mapping):\n    return [mapping[key] for key in txt] \nsig = torch.nn.Sigmoid()\nsoft = torch.nn.Softmax(dim=1)\ntanh = torch.nn.Tanh()\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")\n\n\nx[:5],y[:5]\n\n(tensor([[0., 1., 0., 0., 0., 0.],\n         [1., 0., 0., 0., 0., 0.],\n         [0., 0., 1., 0., 0., 0.],\n         [1., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 1., 0., 0.]], device='cuda:0'),\n tensor([[1., 0., 0., 0., 0., 0.],\n         [0., 0., 1., 0., 0., 0.],\n         [1., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 1., 0., 0.],\n         [1., 0., 0., 0., 0., 0.]], device='cuda:0'))\n\n\n(1) torch.nn.RNNCell()을 이용하여 다음단어를 예측하는 신경망을 설계하고 학습하라.\n\ntorch.manual_seed(12345)\nrnncell=torch.nn.RNNCell(6,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,6).to(\"cuda:0\")\n\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(linr.parameters()))\n\n\nT = len(x) \nfor epoc in range(500): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,20).to(\"cuda:0\") \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) \n        ot = linr(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\n_water = torch.zeros(1,20).to(\"cuda:0\") \nhidden[[0]] = rnncell(x[[0]],_water)\nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]])\n\n\nyhat = soft(linr(hidden))\n\n\nplt.matshow(yhat[-20:].data.to(\"cpu\"),cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f7fee9c2c50&gt;\n\n\n\n\n\n(2) torch.nn.RNN()을 이용하여 다음단어를 예측하는 신경망을 설계하고 학습하라.\n\ntorch.manual_seed(12345)\nrnn = torch.nn.RNN(6,20).to(\"cuda:0\")\nlinr=torch.nn.Linear(20,6).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(linr.parameters()))\n\n\n_water = torch.zeros(1,20).to(\"cuda:0\")\nfor epoc in range(8000):\n    ## 1 \n    hidden,hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\n\n\nplt.matshow(yhat.data[-20:].to(\"cpu\"),cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f8083af6990&gt;\n\n\n\n\n\n(3) torch.nn.LSTMCell()을 이용하여 다음단어를 예측하는 신경망을 설계하고 학습하라.\n\ntorch.manual_seed(12345) \nlstmcell = torch.nn.LSTMCell(6,4).to(\"cuda:0\") \nlinr = torch.nn.Linear(4,6).to(\"cuda:0\") \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstmcell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(5000):\n    ## 1\n    hidden = []\n    ht = torch.zeros(4).to(\"cuda:0\")\n    ct = torch.zeros(4).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht,ct = lstmcell(xt,(ht,ct))\n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden)\n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\narray([[1., 0., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0.],\n       [1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0.],\n       [1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 1.],\n       [1., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0.]], dtype=float32)\n\n\n\nplt.matshow(yhat.to(\"cpu\").data[:20],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(6),labels=[',','one','two','three','four','five']);\n\n\n\n\n(4) torch.nn.LSTM()을 이용하여 다음단어를 예측하는 신경망을 설계하고 학습하라.\n\ntorch.manual_seed(12345) \nlstm = torch.nn.LSTM(6,20).to(\"cuda:0\") \nlinr = torch.nn.Linear(20,6).to(\"cuda:0\") \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(5000):\n    ## 1 \n    hidden, (hT,cT) =lstm(x)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()     \n\n\nplt.matshow(soft(output).data[-20:].to(\"cpu\"),cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(6),labels=[',','one','two','three','four','five']);\n\n\n\n\n\n참고: https://guebin.github.io/DL2022/posts/2022-11-29-13wk-2-final.html 의 1번풀이를 참고하세요"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html",
    "href": "posts/ml/2022-12-07-13wk.html",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "",
    "text": "copy"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#틀린이유",
    "href": "posts/ml/2022-12-07-13wk.html#틀린이유",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "틀린이유",
    "text": "틀린이유\n\nid(a)\n\n139660748276272\n\n\n\nid(b)\n\n139660748276272\n\n\n실제로는 a,b가 저장된 메모리 주소가 동일함"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제1",
    "href": "posts/ml/2022-12-07-13wk.html#예제1",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제1",
    "text": "예제1\n\na=[1,2,3]\nb=a\na.append(4)\nc=[1,2,3,4]\n\n여기에서 a,b,c는 모두 같은 value를 가진다.\n\na\n\n[1, 2, 3, 4]\n\n\n\nb\n\n[1, 2, 3, 4]\n\n\n\nc\n\n[1, 2, 3, 4]\n\n\n하지만 그 id까지 같은 것은 아니다.\n\nid(a), id(b), id(c)\n\n(139660748305984, 139660748305984, 139660748286224)"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제2",
    "href": "posts/ml/2022-12-07-13wk.html#예제2",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제2",
    "text": "예제2\n\na=[1,2,3] \nb=a \na=[1,2,3]+[4] \n\na를 다시 정의한 것이라 보면 될 듯\n\na,b\n\n([1, 2, 3, 4], [1, 2, 3])\n\n\n\nid(a), id(b)\n\n(139660748313296, 139660748290960)"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제1-1",
    "href": "posts/ml/2022-12-07-13wk.html#예제1-1",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제1",
    "text": "예제1\n\na=1+2021\nid(a)\n\n139660748450224\n\n\n일단 할당\n\nb=2023-1\nid(b)\n\n139660748450768\n\n\n독립적으로 오브젝트 만들었으니 id가 다르지\n\nid(2022)\n\n139660748450832"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제2-이제-다-이해했다고-생각했는데..",
    "href": "posts/ml/2022-12-07-13wk.html#예제2-이제-다-이해했다고-생각했는데..",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제2: 이제 다 이해했다고 생각했는데..",
    "text": "예제2: 이제 다 이해했다고 생각했는데..\n\na=1+2 \nid(a)\n\n7402432\n\n\n\nb=4-1\nid(b)\n\n7402432\n\n\n이게 왜 똑같지..?\n(해설) 파이썬의 경우 효율성을 위해서 -5~256까지의 정수를 미리 저장해둠.\n\nid(3)\n\n7402432"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제1-2",
    "href": "posts/ml/2022-12-07-13wk.html#예제1-2",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제1",
    "text": "예제1\n\n아래의 예제를 살펴보자. (참조를 제대로 이해했다면 아래의 예제는 자연스럽게 이해가능)\n\n\nl1 = [3, [66,55,44]]\nl2 = l1\n\n\nid(l1),id(l2)\n\n(139660748249920, 139660748249920)\n\n\n\nl1[0]=4\n\n\nl1\n\n[4, [66, 55, 44]]\n\n\n\nl2\n\n[4, [66, 55, 44]]\n\n\n\nl2.append(5)\nl2\n\n[4, [66, 55, 44], 5]\n\n\n\nl1\n\n[4, [66, 55, 44], 5]"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제2-r과-같이-를-쓰고-싶다면",
    "href": "posts/ml/2022-12-07-13wk.html#예제2-r과-같이-를-쓰고-싶다면",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제2: R과 같이 = 를 쓰고 싶다면?",
    "text": "예제2: R과 같이 = 를 쓰고 싶다면?\n\nl1 = [3, [66,55,44]]\nl2 = l1.copy()\n\n\nid(l1),id(l2) ## 드디어 주소가 달라졌다.\n\n(139660748530944, 139660748530784)\n\n\n주소 달라짐!!\n\nl1[0]=100\n\n\nl1\n\n[100, [66, 55, 44]]\n\n\n\nl2\n\n[3, [66, 55, 44]]"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제3-이제-다-이해했다고-생각했는데..",
    "href": "posts/ml/2022-12-07-13wk.html#예제3-이제-다-이해했다고-생각했는데..",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제3: 이제 다 이해했다고 생각했는데..",
    "text": "예제3: 이제 다 이해했다고 생각했는데..\n\n이제 다 이해했다고 생각했는데..\n\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\n\n\nid(l1),id(l2)\n\n(139660807804960, 139660807804560)\n\n\n\nl1[1].append(33)\n\n\nl1\n\n[3, [66, 55, 44, 33]]\n\n\n\nl2\n\n[3, [66, 55, 44, 33]]\n\n\n왜 또 참조한것마냥 l1과 l2가 같이 바뀌고 있지?"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제1-3",
    "href": "posts/ml/2022-12-07-13wk.html#예제1-3",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제1",
    "text": "예제1\n\na=2222\nb=2222\n\n\nid(a),id(b)\n\n(139660739479536, 139660739478192)\n\n\n메모리 상황\n\n2222라는 오브젝트가 어떤공간(id(a): 139753545300880)에 생성되고 그 공간에 a라는 라벨이 붙음\n2222라는 오브젝트가 어떤공간(id(b): 139753545300880)에 생성되고 그 공간에 b라는 라벨이 붙음\n\n즉 -5~256 이외의 2개의 메모리 공간을 추가적으로 사용"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제2-1",
    "href": "posts/ml/2022-12-07-13wk.html#예제2-1",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제2",
    "text": "예제2\n\na=[1,2,2222]\nb=[1,2,2222]\n\n메모리 공간에 1,2는 이미 저장되어 있어서 생성할 필요 없고 2022만 메모리 공간에 생성하면 된다.\n\nid(a), [id(a[0]),id(a[1]),id(a[2])] # a=[1,2,2222]\n\n(139660739560064, [7402368, 7402400, 139660739480272])\n\n\n\nid(b), [id(b[0]),id(b[1]),id(b[2])] # b=[1,2,2222] \n\n(139660739560864, [7402368, 7402400, 139660739479312])\n\n\n\na.append(4)\n\n\na\n\n[1, 2, 2222, 4]\n\n\n\nb\n\n[1, 2, 2222]\n\n\n메모리상황\n\n-5~256까지의 숫자는 미리 메모리에 저장되어 있다.(이터닝) 이중에서 1은 id(a[0]): 7394656, 2는 id(a[1]): 7394688에 저장되어있음.\n2222가 공간 id(a[2]): 139753178093776에서 만들어진다.\n어떠한 리스트오브젝트가 공간 id(a): 139753182327904에서 만들어지고 원소로 [1,2,2222]를 가진다. 이 공간에 a라는 포스트잇을 붙인다.\n2222가 공간 id(a)[2]: 139753178095568에서 만들어진다.\n어떠한 리스트오브젝트가 공간 id(b): 139753173818656에서 만들어지고 원소로 [1,2,2222]를 가진다. 이 공간에 b라는 포스트잇을 붙인다.\na라는 포스트잇이 붙은 공간으로 이동하여 원소에 4를 추가시킨다.\n\n즉 -5~256이외에 4개의 메모리 공간을 추가사용 (a,b,a의 2222,b의 2222)"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제3",
    "href": "posts/ml/2022-12-07-13wk.html#예제3",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제3",
    "text": "예제3\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\n\n\nid(l1), [id(l1[0]), id(l1[1])]\n\n(139660748288960, [7402432, 139660739562784])\n\n\n\nid(l2), [id(l2[0]), id(l2[1])]\n\n(139660739539504, [7402432, 139660739562784])\n\n\n메모리상황\n\n-5~256까지의 숫자가 메모리에 저장되어 있다.\n저장된 숫자중 66,55,44를 묶어서 리스트로 구성하고 이 리스트를 공간 id(l1[1]): 139753183707216에 저장.\n숫자 3과 공간 id(l1[1]): 139753183707216에 저장된 리스트 [66,55,44]를 하나로 묶어서 새로운 리스트를 구성하고 이를 공간 id(l1): 139753183437040에 저장. 공간 id(l1): 139753183437040에 l1이라는 포스트잇 생성.\n공간 id(l2): 139753182311120에 l1의 원소들을 모아서 새로운 리스트를 구성함. 공간 id(l2): 139753182311120에 l2라는 포스트잇 생성.\n\n\nl1[0] = 7777\nl1,l2\n\n([7777, [66, 55, 44]], [3, [66, 55, 44]])\n\n\n\nid(l1), [id(l1[0]), id(l1[1])]\n\n(139660748288960, [139660739478544, 139660739562784])\n\n\n\nid(l2), [id(l2[0]), id(l2[1])]\n\n(139660739539504, [7402432, 139660739562784])\n\n\n\nl1[0]은 원래 공간 7394720와 binding 되어 있었음.\n\n그런데 7777이라는 새로운 오브젝트가 공간 id(l1): 139753178092080에 생성되고 l1[0]이 공간 139753178092080와 다시 binding 됨."
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제4",
    "href": "posts/ml/2022-12-07-13wk.html#예제4",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제4",
    "text": "예제4\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\nl1.append(7777)\n\n\nl1,l2\n\n([3, [66, 55, 44], 7777], [3, [66, 55, 44]])\n\n\n\nid(l1), [id(l1[0]), id(l1[1]), id(l1[2])]\n\n(139660739540064, [7402432, 139660748258672, 139660739477968])\n\n\n\nid(l2), [id(l2[0]), id(l2[1])]\n\n(139660748282608, [7402432, 139660748258672])\n\n\n\n예제3, 예제4를 통하여 리스트가 가변형객체라는 것을 확인할 수 있다. 예제3의 경우 l1이 저장되어있던 메모리공간의 내용물이 [3,[66,55,44]] 에서 [7777,[66,55,44]] 로 바뀌었다. 예제4의 경우 l1이 저장되어있던 메모리공간의 내용물이 [3,[66,55,44]] 에서 [3,[66,55,44],7777] 로 바뀌었다."
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제5-우리를-힘들게-했던-그-예제.",
    "href": "posts/ml/2022-12-07-13wk.html#예제5-우리를-힘들게-했던-그-예제.",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제5: 우리를 힘들게 했던 그 예제.",
    "text": "예제5: 우리를 힘들게 했던 그 예제.\n(시점1)\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\n\n\nl1,l2\n\n([3, [66, 55, 44]], [3, [66, 55, 44]])\n\n\n\nid(l1), [id(l1[0]), id(l1[1])]\n\n(139660748600336, [7402432, 139660748255792])\n\n\n\nid(l2), [id(l2[0]), id(l2[1])]\n\n(139660748237712, [7402432, 139660748255792])\n\n\n(시점2)\n\nl1[1].append(7777)\n\nl1[1]의 묶음방식이 저장된 공간에 7777 추가할 거야\n\nl1,l2\n\n([3, [66, 55, 44, 7777]], [3, [66, 55, 44, 7777]])\n\n\n\nid(l1), [id(l1[0]), id(l1[1])]\n\n(139660748600336, [7402432, 139660748255792])\n\n\n\nid(l2), [id(l2[0]), id(l2[1])]\n\n(139660748237712, [7402432, 139660748255792])\n\n\n해설: 사실 시점1에서 메모리 주소상황을 잘 이해했다면 신기한 일이 아니다. .copy()는 l1과 l2의 주소만 다르게 만들 뿐 내용물인 l1[0],l1[1]는 동일하니까."
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제6-신임교수최규빈이영미",
    "href": "posts/ml/2022-12-07-13wk.html#예제6-신임교수최규빈이영미",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제6: 신임교수=[‘최규빈’,‘이영미’]",
    "text": "예제6: 신임교수=[‘최규빈’,‘이영미’]\n- 최규빈, 이영미는 신임교수임\n\n신임교수 = ['최규빈','이영미']\n\n\nid(신임교수), id('최규빈'), id('이영미')\n\n(139660748511984, 139660748209680, 139660748209200)\n\n\n- 신임교수를 누군가는 막내들이라고 부르기도 함.\n\n막내들 = 신임교수 \n\n참조\n\nid(막내들), id(신임교수)\n\n(139660748511984, 139660748511984)\n\n\n“막내들”이라는 단어와 “신임교수”라는 단어는 사실 같은 말임\n여기까지 참조 설명\n- 새로운 교수 “박혜원”이 뽑혔음.\n\n신임교수.append(\"박혜원\")\n\n\n신임교수, 막내들\n\n(['최규빈', '이영미', '박혜원'], ['최규빈', '이영미', '박혜원'])\n\n\n- 전북대 통계학과에서 R특강팀을 구성하여 방학중 R교육을 실시하고자함. 특강팀은 우선 신임교수들로 구성.\n\nR특강팀 = 신임교수.copy()\nR특강팀 \n\n['최규빈', '이영미', '박혜원']\n\n\n- R특강팀에 최혜미교수님 추가. (그렇지만 최혜미교수님이 막내는 아니야.. // 참조와 shallow copy의 차이점)\n\nR특강팀.append(\"최혜미\") \n\n\nR특강팀, 신임교수, 막내들\n\n(['최규빈', '이영미', '박혜원', '최혜미'], ['최규빈', '이영미', '박혜원'], ['최규빈', '이영미', '박혜원'])\n\n\n- R특강팀에서 양성준 교수를 추가하여 파이썬 특강팀을 구성\n\n파이썬특강팀 = [R특강팀, \"양성준\"]\n파이썬특강팀\n\n[['최규빈', '이영미', '박혜원', '최혜미'], '양성준']\n\n\n- 이영미교수는 다른 일이 많아서 R특강 팀에서 제외됨. (그럼 자연히 파이썬에서도 제외됨!!)\n\nR특강팀.remove(\"이영미\")\n\n\nR특강팀, 파이썬특강팀\n\n(['최규빈', '박혜원', '최혜미'], [['최규빈', '박혜원', '최혜미'], '양성준'])\n\n\n하지만 이영미교수는 여전히 신임교수이면서 막내들임\n\n신임교수, 막내들\n\n(['최규빈', '이영미', '박혜원'], ['최규빈', '이영미', '박혜원'])\n\n\n- 새로운 교수로 “손흥민”이 임용됨.\n\n막내들.append(\"손흥민\")\n\n\n막내들, 신임교수\n\n(['최규빈', '이영미', '박혜원', '손흥민'], ['최규빈', '이영미', '박혜원', '손흥민'])\n\n\n- 그렇다고 해서 손흥민 교수가 바로 R이나 파이썬 특강팀에 자동소속되는건 아님\nshallow copy로 id 주소가 각각 할당되었기 때문\n\nR특강팀, 파이썬특강팀\n\n(['최규빈', '박혜원', '최혜미'], [['최규빈', '박혜원', '최혜미'], '양성준'])"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제1-motivation-example",
    "href": "posts/ml/2022-12-07-13wk.html#예제1-motivation-example",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제1: Motivation example",
    "text": "예제1: Motivation example\n- 아래의 상황을 다시 생각해보자.\n\n파이썬특강팀 = [\"양성준\",[\"최규빈\",\"이영미\",\"최혜미\"]]\nADSP특강팀 = 파이썬특강팀.copy()\n파이썬특강팀[-1].remove(\"이영미\")\n\n\n파이썬특강팀, ADSP특강팀\n\n(['양성준', ['최규빈', '최혜미']], ['양성준', ['최규빈', '최혜미']])\n\n\n이슈: 이영미교수가 파이썬특강에서 제외되면서 ADSP특강팀에서도 제외되었음. 그런데 사실 이영미교수가 파이썬특강팀에서만 제외되길 원한 것이지 ADSP특강팀에서 제외되길 원한게 아닐수도 있음.\n해결: Deep copy의 사용\n\nimport copy\n\n패키지 필요\n\n파이썬특강팀 = [\"양성준\",[\"최규빈\",\"이영미\",\"최혜미\"]]\nADSP특강팀 = copy.deepcopy(파이썬특강팀)\n파이썬특강팀[-1].remove(\"이영미\")\n\n\n파이썬특강팀, ADSP특강팀\n\n(['양성준', ['최규빈', '최혜미']], ['양성준', ['최규빈', '이영미', '최혜미']])\n\n\n\ncopy?\n\n\nType:        module\nString form: &lt;module 'copy' from '/home/csy/anaconda3/envs/py37/lib/python3.7/copy.py'&gt;\nFile:        ~/anaconda3/envs/py37/lib/python3.7/copy.py\nDocstring:  \nGeneric (shallow and deep) copying operations.\nInterface summary:\n        import copy\n        x = copy.copy(y)        # make a shallow copy of y\n        x = copy.deepcopy(y)    # make a deep copy of y\nFor module specific errors, copy.Error is raised.\nThe difference between shallow and deep copying is only relevant for\ncompound objects (objects that contain other objects, like lists or\nclass instances).\n- A shallow copy constructs a new compound object and then (to the\n  extent possible) inserts *the same objects* into it that the\n  original contains.\n- A deep copy constructs a new compound object and then, recursively,\n  inserts *copies* into it of the objects found in the original.\nTwo problems often exist with deep copy operations that don't exist\nwith shallow copy operations:\n a) recursive objects (compound objects that, directly or indirectly,\n    contain a reference to themselves) may cause a recursive loop\n b) because deep copy copies *everything* it may copy too much, e.g.\n    administrative data structures that should be shared even between\n    copies\nPython's deep copy operation avoids these problems by:\n a) keeping a table of objects already copied during the current\n    copying pass\n b) letting user-defined classes override the copying operation or the\n    set of components copied\nThis version does not copy types like module, class, function, method,\nnor stack trace, stack frame, nor file, socket, window, nor array, nor\nany similar types.\nClasses can use the same interfaces to control copying that they use\nto control pickling: they can define methods called __getinitargs__(),\n__getstate__() and __setstate__().  See the documentation for module\n\"pickle\" for information on these methods."
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제2-2",
    "href": "posts/ml/2022-12-07-13wk.html#예제2-2",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제2",
    "text": "예제2\n- deepcopy\n\nl1 = [3,[66,[55,44]]] \nl2 = copy.deepcopy(l1)\n\n\nl2[1][1].append(33)\n\n\nl1,l2\n\n([3, [66, [55, 44]]], [3, [66, [55, 44, 33]]])\n\n\n\nprint('level 1')\nprint('l1:', id(l1))\nprint('l2:', id(l2))\n\nlevel 1\nl1: 139660748278352\nl2: 139660748540176\n\n\n\nprint('level 2')\nprint('l1:', id(l1), [id(l1[0]),id(l1[1])])\nprint('l2:', id(l2), [id(l2[0]),id(l2[1])])\n\nlevel 2\nl1: 139660748278352 [7402432, 139660739509776]\nl2: 139660748540176 [7402432, 139660739569056]\n\n\n\nprint('level 3')\nprint('l1:', id(l1), [id(l1[0]),[id(l1[1][0]),id(l1[1][1])]])\nprint('l2:', id(l2), [id(l2[0]),[id(l2[1][0]),id(l2[1][1])]])\n\nlevel 3\nl1: 139660748278352 [7402432, [7404448, 139660748244224]]\nl2: 139660748540176 [7402432, [7404448, 139660739567776]]\n\n\n묶음 방식이 달라지면서 다른 주소가 할당된 모습\n- 비교를 위한 shallow copy\n\nl1 = [3,[66,[55,44]]] \nl2 = l1.copy()\n\n\nl2[1][1].append(33)\n\n\nl1,l2\n\n([3, [66, [55, 44, 33]]], [3, [66, [55, 44, 33]]])\n\n\n\nprint('level 1')\nprint('l1:', id(l1))\nprint('l2:', id(l2))\n\nlevel 1\nl1: 139660739568976\nl2: 139660748318112\n\n\n\nprint('level 2')\nprint('l1:', id(l1), [id(l1[0]),id(l1[1])])\nprint('l2:', id(l2), [id(l2[0]),id(l2[1])])\n\nlevel 2\nl1: 139660739568976 [7402432, 139660807428768]\nl2: 139660748318112 [7402432, 139660807428768]\n\n\n\nprint('level 3')\nprint('l1:', id(l1), [id(l1[0]),[id(l1[1][0]),id(l1[1][1])]])\nprint('l2:', id(l2), [id(l2[0]),[id(l2[1][0]),id(l2[1][1])]])\n\nlevel 3\nl1: 139660739568976 [7402432, [7404448, 139660748313776]]\nl2: 139660748318112 [7402432, [7404448, 139660748313776]]\n\n\n- 비교를 위한 참조\n\nl1 = [3,[66,[55,44]]] \nl2 = l1\n\n\nl2[1][1].append(33)\n\n\nl1,l2\n\n([3, [66, [55, 44, 33]]], [3, [66, [55, 44, 33]]])\n\n\n\nprint('level 1')\nprint('l1:', id(l1))\nprint('l2:', id(l2))\n\nlevel 1\nl1: 139660748238432\nl2: 139660748238432\n\n\n\nprint('level 2')\nprint('l1:', id(l1), [id(l1[0]),id(l1[1])])\nprint('l2:', id(l2), [id(l2[0]),id(l2[1])])\n\nlevel 2\nl1: 139660748238432 [7402432, 139660748240128]\nl2: 139660748238432 [7402432, 139660748240128]\n\n\n\nprint('level 3')\nprint('l1:', id(l1), [id(l1[0]),[id(l1[1][0]),id(l1[1][1])]])\nprint('l2:', id(l2), [id(l2[0]),[id(l2[1][0]),id(l2[1][1])]])\n\nlevel 3\nl1: 139660748238432 [7402432, [7404448, 139660748531664]]\nl2: 139660748238432 [7402432, [7404448, 139660748531664]]\n\n\n주소 다 똑같아"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제1-4",
    "href": "posts/ml/2022-12-07-13wk.html#예제1-4",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제1",
    "text": "예제1\n- 아래의 코드결과를 예측하라. 결과가 나오는 이유를 설명하라.\n\nl1= [3,[66,55,44]]\nl2= l1.copy() \nl1[-1].append(33)\n\n\nl1,l2\n\n([3, [66, 55, 44, 33]], [3, [66, 55, 44, 33]])\n\n\nshallow copy 썼으니까 같이 추가된 모습"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제2-3",
    "href": "posts/ml/2022-12-07-13wk.html#예제2-3",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제2",
    "text": "예제2\n- 아래의 코드결과를 예측하라. 결과가 나오는 이유를 설명하라.\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] = l1[-1]+[33] \n\n\nl1,l2\n\n([3, [66, 55, 44, 33]], [3, [66, 55, 44]])\n\n\n\nid(l1),id(l2)\n\n(139660748276032, 139660748245744)\n\n\nl1에 재할당한 것이라 생각하면 된다."
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제3-1",
    "href": "posts/ml/2022-12-07-13wk.html#예제3-1",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제3",
    "text": "예제3\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] = l1[-1]+[33] \nl1[-1].remove(33)\n\n\nl1,l2\n\n([3, [66, 55, 44]], [3, [66, 55, 44]])\n\n\n\nid(l1),id(l2)\n\n(139660807804240, 139660748282048)"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제4-1",
    "href": "posts/ml/2022-12-07-13wk.html#예제4-1",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제4",
    "text": "예제4\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] = l1[-1]+[33] \nl1[-1].remove(33)\nl1[-1].append(33)\n\n(잘못된 상상) 아래의 코드와 결과가 같을거야!!\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \n# l1[-1] = l1[-1]+[33] \n# l1[-1].remove(33)\nl1[-1].append(33)\n\n\nl1,l2 \n\n([3, [66, 55, 44, 33]], [3, [66, 55, 44, 33]])\n\n\n(하지만 현실은)\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] = l1[-1]+[33] \nl1[-1].remove(33)\nl1[-1].append(33)\n\n\nl1,l2\n\n([3, [66, 55, 44, 33]], [3, [66, 55, 44]])\n\n\n재할당의 개념이 있었기 때문에 주소가 다른게 할당된 것이고, 결국 다른 결과가 나온다."
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#예제5",
    "href": "posts/ml/2022-12-07-13wk.html#예제5",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "예제5",
    "text": "예제5\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] += [33] # l1[-1] = l1[-1]+[33] \nl1[-1].remove(33)\nl1[-1].append(33)\n\n\nl1,l2\n\n([3, [66, 55, 44, 33]], [3, [66, 55, 44, 33]])\n\n\n\nid(l1),id(l2)\n\n(139660739562464, 139660739561344)\n\n\n주소는 다르지만 재할당의 개념이 없어!\nl1에 append 하는 식으로 되어서 묶음 방식이 같이 움직인다.\n\n??? 예제4랑 예제5는 같은코드가 아니었음!!! a += [1] 는 새로운 오브젝트를 만드는게 아니고, 기존의 오브젝트를 변형하는 스타일의 코드였음! (마치 append 메소드처럼)"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#motivation-example",
    "href": "posts/ml/2022-12-07-13wk.html#motivation-example",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "Motivation example",
    "text": "Motivation example\n- 우리는 이제 아래의 내용은 마스터함\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] += [33] # l1[-1].append(33)이랑 같은거..\n\n\nl1,l2\n\n([3, [66, 55, 44, 33]], [3, [66, 55, 44, 33]])\n\n\n- 아래의 결과를 한번 예측해볼까?\n\nl1=[3,(66,55,44)]\nl2=l1.copy()\nl2[1] += (33,)\n\n이번엔 튜플로\n\nl1,l2\n\n([3, (66, 55, 44)], [3, (66, 55, 44, 33)])"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#해설",
    "href": "posts/ml/2022-12-07-13wk.html#해설",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "해설",
    "text": "해설\n(시점1)\n\nl1=[3,(66,55,44)]\nl2=l1.copy()\n\n이번엔 리스트 안에 튜플을 넣어봄\n\nl1,l2\n\n([3, (66, 55, 44)], [3, (66, 55, 44)])\n\n\n\nprint('level 1')\nprint('l1:', id(l1))\nprint('l2:', id(l2))\n\nlevel 1\nl1: 139660739586080\nl2: 139660807832512\n\n\n\nprint('level 2')\nprint('l1:', id(l1), [id(l1[0]),id(l1[1])])\nprint('l2:', id(l2), [id(l2[0]),id(l2[1])])\n\nlevel 2\nl1: 139660739586080 [7402432, 139660748091792]\nl2: 139660807832512 [7402432, 139660748091792]\n\n\n(시점2)\n\nl2[1] += (33,)\n\n\nl1,l2\n\n([3, (66, 55, 44)], [3, (66, 55, 44, 33)])\n\n\n\nprint('level 1')\nprint('l1:', id(l1))\nprint('l2:', id(l2))\n\nlevel 1\nl1: 139660739586080\nl2: 139660807832512\n\n\n\nprint('level 2')\nprint('l1:', id(l1), [id(l1[0]),id(l1[1])])\nprint('l2:', id(l2), [id(l2[0]),id(l2[1])])\n\nlevel 2\nl1: 139660739586080 [7402432, 139660748091792]\nl2: 139660807832512 [7402432, 139660739627824]\n\n\n주소 139753182280032에 있는 값을 바꾸고 싶지만 불변형이라 못바꿈 \\(\\to\\) 그냥 새로 만들자. 그래서 그걸 139753174874064에 저장하자.\n튜플의 묶음 방식은 불변형! 정의: 값을 변환할 수 없는 오브젝트다~ 새로 오브젝트 만들어 저장함.\n리스트 : 값을 바꿀 수 있는 오브젝트다, 묶음 방식을 바꿀 수 있다."
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#차원의-실체",
    "href": "posts/ml/2022-12-07-13wk.html#차원의-실체",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "2차원의 실체",
    "text": "2차원의 실체\n- 2차원 array a,b를 선언하자.\n\na = np.array([[11,22,33,44]]).reshape(2,2)\nb = np.array([[11,22,33,44,55,66]]).reshape(2,3)\nc = np.array([11,22,33,44]).reshape(4,1)\nd = np.array([11,22,33,44])\n\n- a,b,c,d 속성비교\n\na.shape, b.shape, c.shape, d.shape ## 차원 \n\n((2, 2), (2, 3), (4, 1), (4,))\n\n\n\na.strides, b.strides, c.strides, d.strides ## 차원이랑 관련이 있어보임.. + 8의 배수 \n\n((16, 8), (24, 8), (8, 8), (8,))\n\n\n- strides는 무엇?\n\nstrides: (다음 행으로 가기위해서 JUMP해야하는 메모리 공간수, 다음 열로 가기위해서 JUMP해야하는 메모리 공간수)\n\n- 사실 a,b,c,d 는 모두 1차원으로 저장되어있음. (중첩된 리스트꼴이 아니라)\nshape이나 strides 등의 옵션으로 1차원이 아니게 보여지는 것 뿐"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#참조",
    "href": "posts/ml/2022-12-07-13wk.html#참조",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "참조",
    "text": "참조\n- a를 선언, b는 a의 참조\n\na=np.array([[1,2],[3,4]])\nb=a ## 참조 \n\n\na\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nb\n\narray([[1, 2],\n       [3, 4]])\n\n\n\na.shape\n\n(2, 2)\n\n\n\nb.shape\n\n(2, 2)\n\n\n- a의 shape을 바꾸어보자 \\(\\to\\) b도 같이 바뀐다\n\na.shape = (4,)\n\n\na\n\narray([1, 2, 3, 4])\n\n\n\nb\n\narray([1, 2, 3, 4])\n\n\n\nid(a),id(b)\n\n(139660739644368, 139660739644368)"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#view",
    "href": "posts/ml/2022-12-07-13wk.html#view",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "view",
    "text": "view\n- a를 선언, b는 a의 view\n\na=np.array([[1,2],[3,4]]) \nb=a.view() ## shallow copy 라고 부르기도 한다. \n\n\na\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nb\n\narray([[1, 2],\n       [3, 4]])\n\n\n\na.shape\n\n(2, 2)\n\n\n\nb.shape\n\n(2, 2)\n\n\n\na.shape= (4,1)\n\n\na\n\narray([[1],\n       [2],\n       [3],\n       [4]])\n\n\n\nb\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nid(a), id(b)\n\n(139660382911248, 139660382911344)\n\n\nview가 shallow copy 같은 이유 껍데기 주소만 복사해옴, 공간에 대한 주소는 같지 않음\n- 그런데..\n\na[0]=100\n\n\na\n\narray([[100],\n       [  2],\n       [  3],\n       [  4]])\n\n\n\nb\n\narray([[100,   2],\n       [  3,   4]])\n\n\n- 출생의 비밀\n\nb\n\narray([[100,   2],\n       [  3,   4]])\n\n\n\nb.base\n\narray([[100],\n       [  2],\n       [  3],\n       [  4]])\n\n\n\n? 이거 바뀐 a아니야?\n\n\nid(b.base), id(a)\n\n(139660382911248, 139660382911248)\n\n\n- View - b가 a의 뷰라는 의미는, b가 a를 소스로하여 만들어진 오브젝트란 의미이다. - 따라서 이때 b.base는 a가 된다. - b는 자체적으로 데이터를 가지고 있지 않으며 a와 공유한다. - 이러한 의미에서 view를 shallow copy 라고 부른다. (stride, shape과 같은 껍데기만 새로 생성, base는 유지)\nnote1 원본 ndarray의 일 경우는 .base가 None으로 나온다.\n\na.base\n\n\nprint(a.base)\n\nNone\n\n\nnote2 b.base의 shpae과 b의 shape은 아무 관련없다.\n\nb.shape\n\n(2, 2)\n\n\n\nb.base.shape\n\n(4, 1)"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#copy",
    "href": "posts/ml/2022-12-07-13wk.html#copy",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "copy",
    "text": "copy\n- a를 선언, b는 a의 copy\n\na=np.array([[1,2],[3,4]])\nb=a.copy() # 껍데기를 새로 생성 (strides, shape) + base도 새로생성 \n\n\nid(a),id(b)\n\n(139660382910288, 139660382910000)\n\n\n- a의 shape을 바꿔도 b에는 적용되지 않음\n\na.shape = (4,1)\na\n\narray([[1],\n       [2],\n       [3],\n       [4]])\n\n\n\nb\n\narray([[1, 2],\n       [3, 4]])\n\n\n- 그리고 a[0]의 값을 바꿔도 b에는 적용되지 않음.\n\na[0]=100\n\n\na\n\narray([[100],\n       [  2],\n       [  3],\n       [  4]])\n\n\n\nb\n\narray([[1, 2],\n       [3, 4]])\n\n\n- b의 출생을 조사해보니..\n\na.base,b.base\n\n(None, None)\n\n\n출생의 비밀은 없었다. 둘다 원본.\n- .view() 는 껍데기만, .copy() 는 껍데기 + base 까지 새로생성\n\nAppendix: .copy의 한계(?)\n\na=np.array([1,[1,2]],dtype='O')\na\n\narray([1, list([1, 2])], dtype=object)\n\n\n\nb=a.copy()\n\n\nb\n\narray([1, list([1, 2])], dtype=object)\n\n\n\na[0]=222\n\n\na\n\narray([222, list([1, 2])], dtype=object)\n\n\n\nb\n\narray([1, list([1, 2])], dtype=object)\n\n\n\na[1][0]=333\n\n\na\n\narray([222, list([333, 2])], dtype=object)\n\n\n\nb\n\narray([1, list([333, 2])], dtype=object)\n\n\n해결책: 더 깊은 복사\n\nimport copy \n\n\na=np.array([1,[1,2]],dtype='O')\nb=copy.deepcopy(a)\n\n\na\n\narray([1, list([1, 2])], dtype=object)\n\n\n\nb\n\narray([1, list([1, 2])], dtype=object)\n\n\n\na[0]=100\n\n\na,b\n\n(array([100, list([1, 2])], dtype=object),\n array([1, list([1, 2])], dtype=object))\n\n\n\na[1][0]=200\n\n\na,b\n\n(array([100, list([200, 2])], dtype=object),\n array([1, list([1, 2])], dtype=object))\n\n\n- 중간요약\n\n사실 .copy()는 온전한 deep copy 가 아니라 level 2 deep copy 이다.\n따라서 .copy()는 base의 정보를 shallow copy 한다 (level 1 deep copy 한다.)\n그래서 base가 다시 중첩구조를 가지는 경우는 온전한 deep-copy가 수행되지 않는다.\n그런데 일반적으로 넘파이를 이용할때 자주 사용하는 데이터 구조인 행렬, 텐서등은 base가 중첩구조를 가지지 않는다. (1차원 array로만 저장되어 있음)\n따라서 행렬, 텐서에 한정하면 .copy()는 온전한 deep copy라고 이해해도 무방하다.\n\n행/열 같지 않으면 numpy쓰면 힘들걸..\n모든 데이터 구조가 2차원까지로 정리 된다."
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#별명-뷰-카피",
    "href": "posts/ml/2022-12-07-13wk.html#별명-뷰-카피",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "별명, 뷰, 카피",
    "text": "별명, 뷰, 카피\n- test 함수 작성\n\ndef test(a,b): \n    if id(a) == id(b): \n        print(\"별명\")\n    elif id(a) == id(b.base) or id(a.base)==id(b): \n        print(\"뷰\")\n    elif (id(a.base)!=id(None) and id(b.base)!=id(None)) and id(a.base) == id(b.base):\n        print(\"공통의 base를 가짐\")\n    else: \n        print(\"카피, 혹은 아무 관련없는 오브젝트\") \n\n- 잘 동작하나?\n(테스트1)\n\na=np.array([1,2,3,4])\nb=a\n\n\ntest(a,b)\n\n별명\n\n\n참조\n(테스트2)\n\na=np.array([1,2,3,4])\nb=a.view()\n\n\ntest(a,b)\n\n뷰\n\n\n(테스트3)\n\na=np.array([1,2,3,4])\nb=a.view()\nc=a.view()\n\n\ntest(b,c)\n\n공통의 base를 가짐\n\n\n\ntest(a,b)\n\n뷰\n\n\n\ntest(a,c)\n\n뷰\n\n\n(테스트4)\n\na=np.array([1,2,3,4])\nb=a.copy()\n\n\ntest(a,b)\n\n카피, 혹은 아무 관련없는 오브젝트"
  },
  {
    "objectID": "posts/ml/2022-12-07-13wk.html#결론",
    "href": "posts/ml/2022-12-07-13wk.html#결론",
    "title": "A1: 깊은복사와 얕은복사 (12주차)",
    "section": "결론",
    "text": "결론\n- 우리가 사용했던 어떠한 것들이 뷰가 나올지 카피가 나올지 사실 잘 모른다. (그래서 원리를 이해해도 대응할 방법이 사실없음)\n\n예시1\n\na=np.array([1,2,3,4])\nb=a[:3]\n\n\na\n\narray([1, 2, 3, 4])\n\n\n\nb\n\narray([1, 2, 3])\n\n\n\ntest(a,b)\n\n뷰\n\n\n\nc=a[[0,1,2]]\nc\n\narray([1, 2, 3])\n\n\n\ntest(a,c)\n\n카피, 혹은 아무 관련없는 오브젝트\n\n\n\nd = a[3]\n\n\ntest(a,d)\n\n카피, 혹은 아무 관련없는 오브젝트\n\n\n\n\n예시2\n\na=np.array([[1,2],[3,4]])\na\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nb=a.flatten()\nc=a.ravel()\nd=a.reshape(-1)\n\n\ntest(a,b)\n\n카피, 혹은 아무 관련없는 오브젝트\n\n\n\ntest(a,c)\n\n뷰\n\n\n\ntest(a,d)\n\n뷰\n\n\n\ntest(c,d)\n\n공통의 base를 가짐\n\n\n\ntest(b,c)\n\n카피, 혹은 아무 관련없는 오브젝트"
  },
  {
    "objectID": "posts/ml/2022-10-26-ml_8w_2.html",
    "href": "posts/ml/2022-10-26-ml_8w_2.html",
    "title": "CNN (8주차) 2",
    "section": "",
    "text": "기계학습 특강 (8주차) 10월26일–(2) [이미지자료분석 - Transfer Learning, CAM (설명가능한 인공지능모형, XAI)]"
  },
  {
    "objectID": "posts/ml/2022-10-26-ml_8w_2.html#imports",
    "href": "posts/ml/2022-10-26-ml_8w_2.html#imports",
    "title": "CNN (8주차) 2",
    "section": "imports",
    "text": "imports\n\nimport torch \nimport torchvision\nfrom fastai.vision.all import *"
  },
  {
    "objectID": "posts/ml/2022-10-26-ml_8w_2.html#transfer-learning",
    "href": "posts/ml/2022-10-26-ml_8w_2.html#transfer-learning",
    "title": "CNN (8주차) 2",
    "section": "Transfer Learning",
    "text": "Transfer Learning\n\npath = untar_data(URLs.CIFAR)\n\n\npath.ls()\n\n(#3) [Path('/home/csy/.fastai/data/cifar10/train'),Path('/home/csy/.fastai/data/cifar10/labels.txt'),Path('/home/csy/.fastai/data/cifar10/test')]\n\n\n\n!ls '/home/csy/.fastai/data/cifar10/train'\n\nairplane  automobile  bird  cat  deer  dog  frog  horse  ship  truck\n\n\n\n수제네트워크\n\ndls\n\n\ndls = ImageDataLoaders.from_folder(path,train='train',valid='test') \n\n\n_X,_y = dls.one_batch()\n_X.shape, _y.shape\n\n(torch.Size([64, 3, 32, 32]), torch.Size([64]))\n\n\n\n!ls '/home/csy/.fastai/data/cifar10/train' # 10개의 클래스\n\nairplane  automobile  bird  cat  deer  dog  frog  horse  ship  truck\n\n\n\ndls.show_batch()\n\n\nlrnr 생성\n\n\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(3,128,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\n\nnet는 cpu에 있고 X는 gpu에 있으니 cpu로 불러오자\n\n#net1(_X.to(\"cpu\")).shape\n\n\nnet = torch.nn.Sequential(\n    net1, \n    torch.nn.Linear(25088,10)\n)\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=accuracy) \n\n\nnet.to(\"cuda:0\")\n\nSequential(\n  (0): Sequential(\n    (0): Conv2d(3, 128, kernel_size=(5, 5), stride=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n    (3): Flatten(start_dim=1, end_dim=-1)\n  )\n  (1): Linear(in_features=25088, out_features=10, bias=True)\n)\n\n\n\n학습\n\n\nX,y=dls.one_batch()\n\n\nlrnr.model(X).shape\n\ntorch.Size([64, 10])\n\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.266191\n1.226523\n0.572100\n00:05\n\n\n1\n1.128916\n1.124115\n0.609800\n00:05\n\n\n2\n1.025027\n1.076060\n0.629600\n00:05\n\n\n3\n0.956499\n1.071469\n0.636600\n00:05\n\n\n4\n0.852002\n1.033129\n0.650600\n00:05\n\n\n5\n0.811420\n1.071609\n0.641600\n00:05\n\n\n6\n0.735469\n1.074108\n0.648300\n00:04\n\n\n7\n0.703909\n1.094982\n0.648800\n00:04\n\n\n8\n0.623525\n1.132971\n0.645000\n00:05\n\n\n9\n0.589313\n1.157667\n0.637900\n00:05\n\n\n\n\n\n\n이게 생각보다 잘 안맞아요.. 70넘기 힘듬\n\n\n\n전이학습 (남이 만든 네트워크)\n\nlrnr 생성\n\n학습되어 있는 파라메터까지 같이 가져오기\n\n#collapse_output\nnet = torchvision.models.resnet18(weights=torchvision.models.resnet.ResNet18_Weights.IMAGENET1K_V1)\nnet\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n\n\n\n\\(k=1000\\) 즉 1000개의 물체를 구분하는 모형임\n\n\nnet.fc = torch.nn.Linear(in_features=512, out_features=10) \n\n\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=accuracy)\n\n\n학습\n\n\nlrnr.fit(10) \n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.813206\n0.955131\n0.677300\n00:21\n\n\n1\n0.636926\n0.719258\n0.760700\n00:21\n\n\n2\n0.538001\n0.802607\n0.765500\n00:21\n\n\n3\n0.446174\n0.591965\n0.804200\n00:20\n\n\n4\n0.339985\n0.677038\n0.786200\n00:20\n\n\n5\n0.283703\n0.664880\n0.797400\n00:21\n\n\n6\n0.221962\n0.734830\n0.787000\n00:21\n\n\n7\n0.183193\n0.720297\n0.798000\n00:21\n\n\n8\n0.160181\n0.785769\n0.790900\n00:21\n\n\n9\n0.144745\n0.745676\n0.804400\n00:21\n\n\n\n\n\n\nCIFAR10을 맞추기 위한 네트워크가 아님에도 불구하고 상당히 잘맞음\n일반인이 거의 밑바닥에서 설계하는것보다 전이학습을 이용하는 것이 효율적일 경우가 많다.\n\n\n\n전이학습 다른 구현: 순수 fastai 이용\n- 예전코드 복습\n\npath = untar_data(URLs.PETS)/'images'\n\n\nfiles= get_image_files(path)\n\n\ndef label_func(fname):\n    if fname[0].isupper():\n        return 'cat'\n    else:\n        return 'dog'\n\n\ndls = ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) \n\n\nlrnr = vision_learner(dls,resnet34,metrics=accuracy) \n\n/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\nlrnr = cnn_learner(dls,resnet34,metrics=accuracy)\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.204861\n0.011182\n0.995940\n00:32\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.056896\n0.009584\n0.996617\n00:44\n\n\n\n\n\n- 사실 위의 코드가 transfer learning 이었음.\n\n#collapse_output\nlrnr.model\n\nSequential(\n  (0): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (4): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (5): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (7): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (1): Sequential(\n    (0): AdaptiveConcatPool2d(\n      (ap): AdaptiveAvgPool2d(output_size=1)\n      (mp): AdaptiveMaxPool2d(output_size=1)\n    )\n    (1): fastai.layers.Flatten(full=False)\n    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=1024, out_features=512, bias=False)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5, inplace=False)\n    (8): Linear(in_features=512, out_features=2, bias=False)\n  )\n)\n\n\n\nXAI(설명가능한 인공지능)\n딥러닝 연구의 네가지 축 - step 1. 아키텍처 - 최근 연구 특징 : 비전문가 + 블랙박스(안 보이는 의미) - 설명가능한 딥러닝에 대한 요구 - step 2. 손실함수 - step 3. 미분계산 - step 4. 옵티마이저"
  },
  {
    "objectID": "posts/ml/2022-10-26-ml_8w_2.html#cam",
    "href": "posts/ml/2022-10-26-ml_8w_2.html#cam",
    "title": "CNN (8주차) 2",
    "section": "CAM",
    "text": "CAM\n\nCAM이란?\n\nref: http://cnnlocalization.csail.mit.edu/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf\n\n- Class Activation Mapping (CAM)은 설명가능한 인공지능모형 (eXplainable Artificial Intelligence, XAI) 중 하나로 CNN의 판단근거를 시각화하는 기술\n\n\n학습에 사용할 데이터 Load\n\npath = untar_data(URLs.PETS)/'images'\n\n\npath.ls()\n\n(#7393) [Path('/home/csy/.fastai/data/oxford-iiit-pet/images/Bombay_13.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/beagle_193.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/Ragdoll_8.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/boxer_106.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/keeshond_56.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_162.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/saint_bernard_136.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_76.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/pug_173.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_117.jpg')...]\n\n\n\nfiles= get_image_files(path)\ndef label_func(fname):\n    if fname[0].isupper():\n        return 'cat'\n    else:\n        return 'dog'\ndls = ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) \n\n\n\n구현0단계– 예비학습\n\n# 하나의 이미지 선택\n\nximg = PILImage.create('/home/csy/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_106.jpg')\nximg\n\n\n\n\n\nx = first(dls.test_dl([ximg]))[0]\nx,x.shape\n\n(TensorImage([[[[0.9059, 0.9059, 0.9098,  ..., 0.9059, 0.9059, 0.9059],\n                [0.9059, 0.9059, 0.9098,  ..., 0.9059, 0.9059, 0.9059],\n                [0.9059, 0.9059, 0.9098,  ..., 0.9059, 0.9059, 0.9059],\n                ...,\n                [0.8745, 0.8784, 0.8824,  ..., 0.8902, 0.8863, 0.8824],\n                [0.9059, 0.8980, 0.8902,  ..., 0.8824, 0.8863, 0.8824],\n                [0.8863, 0.8863, 0.8824,  ..., 0.8784, 0.8863, 0.8863]],\n \n               [[0.9137, 0.9137, 0.9176,  ..., 0.9059, 0.9059, 0.9059],\n                [0.9137, 0.9137, 0.9176,  ..., 0.9059, 0.9059, 0.9059],\n                [0.9137, 0.9137, 0.9176,  ..., 0.9059, 0.9059, 0.9059],\n                ...,\n                [0.8784, 0.8824, 0.8863,  ..., 0.8745, 0.8667, 0.8588],\n                [0.9098, 0.9020, 0.8902,  ..., 0.8745, 0.8706, 0.8627],\n                [0.8902, 0.8902, 0.8784,  ..., 0.8784, 0.8745, 0.8706]],\n \n               [[0.9098, 0.9098, 0.9137,  ..., 0.9137, 0.9137, 0.9137],\n                [0.9098, 0.9098, 0.9137,  ..., 0.9137, 0.9137, 0.9137],\n                [0.9098, 0.9098, 0.9137,  ..., 0.9137, 0.9137, 0.9137],\n                ...,\n                [0.8863, 0.8902, 0.8980,  ..., 0.8784, 0.8706, 0.8667],\n                [0.9176, 0.9137, 0.9059,  ..., 0.8745, 0.8706, 0.8667],\n                [0.8980, 0.9020, 0.8980,  ..., 0.8745, 0.8706, 0.8667]]]],\n             device='cuda:0'),\n torch.Size([1, 3, 512, 512]))\n\n\n\n\n# AP layer\n\nap = torch.nn.AdaptiveAvgPool2d(output_size=1) \n\n\nX = torch.arange(48).reshape(1,3,4,4)*1.0 \nX\n\ntensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]],\n\n         [[16., 17., 18., 19.],\n          [20., 21., 22., 23.],\n          [24., 25., 26., 27.],\n          [28., 29., 30., 31.]],\n\n         [[32., 33., 34., 35.],\n          [36., 37., 38., 39.],\n          [40., 41., 42., 43.],\n          [44., 45., 46., 47.]]]])\n\n\n\nap(X)\n\ntensor([[[[ 7.5000]],\n\n         [[23.5000]],\n\n         [[39.5000]]]])\n\n\n\nX[0,0,...].mean(),X[0,1,...].mean(),X[0,2,...].mean()\n\n(tensor(7.5000), tensor(23.5000), tensor(39.5000))\n\n\n\n\n# torch.einsum\n(예시1)\n\ntsr = torch.arange(12).reshape(4,3)\ntsr\n\ntensor([[ 0,  1,  2],\n        [ 3,  4,  5],\n        [ 6,  7,  8],\n        [ 9, 10, 11]])\n\n\n\ntorch.einsum('ij-&gt;ji',tsr)\n\ntensor([[ 0,  3,  6,  9],\n        [ 1,  4,  7, 10],\n        [ 2,  5,  8, 11]])\n\n\n(예시2)\n\ntsr1 = torch.arange(12).reshape(4,3).float()\ntsr2 = torch.arange(15).reshape(3,5).float()\n\n\ntsr1 @ tsr2\n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])\n\n\n\ntorch.einsum('ij,jk -&gt; ik',tsr1,tsr2) \n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])\n\n\n(예시3)\n\nx.to(\"cpu\").shape\n\ntorch.Size([1, 3, 512, 512])\n\n\ntorch,einsum을 사용하여 shape을 아래로 변경\n\ntorch.einsum('ocij -&gt; ijc',x.to(\"cpu\")).shape\n\ntorch.Size([512, 512, 3])\n\n\n\nplt.imshow(torch.einsum('ocij -&gt; ijc',x.to(\"cpu\")))\n\n&lt;matplotlib.image.AxesImage at 0x7fe60eea0e50&gt;\n\n\n\n\n\n\n\n\n구현1단계– 이미지분류 잘하는 네트워크 선택\n\nlrnr = vision_learner(dls,resnet34,metrics=accuracy) \n\nlrnr = cnn_learner(dls,resnet34,metrics=accuracy)\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.180252\n0.032132\n0.989851\n00:32\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.053625\n0.008279\n0.997970\n00:44\n\n\n\n\n\n\n\n구현2단계– 네트워크의 끝 부분 수정\n- 모형의 분해\n\nnet1= lrnr.model[0]\nnet2= lrnr.model[1]\n\nnet1이 2d part, net1이 1d part\n- net2를 좀더 살펴보자.\n\nnet2\n\nSequential(\n  (0): AdaptiveConcatPool2d(\n    (ap): AdaptiveAvgPool2d(output_size=1)\n    (mp): AdaptiveMaxPool2d(output_size=1)\n  )\n  (1): fastai.layers.Flatten(full=False)\n  (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (3): Dropout(p=0.25, inplace=False)\n  (4): Linear(in_features=1024, out_features=512, bias=False)\n  (5): ReLU(inplace=True)\n  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (7): Dropout(p=0.5, inplace=False)\n  (8): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\n_X, _y = dls.one_batch() \n\n\nnet1.to(\"cpu\")\nnet2.to(\"cpu\") \n_X = _X.to(\"cpu\")\n\n\nprint(net1(_X).shape)\nprint(net2[0](net1(_X)).shape)\nprint(net2[1](net2[0](net1(_X))).shape)\nprint(net2[2](net2[1](net2[0](net1(_X)))).shape)\n\ntorch.Size([64, 512, 16, 16])\ntorch.Size([64, 1024, 1, 1])\ntorch.Size([64, 1024])\ntorch.Size([64, 1024])\n\n\n- net2를 아래와 같이 수정하고 재학습하자 (왜?)\n\nnet2= torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), # (64,512,16,16) -&gt; (64,512,1,1) \n    torch.nn.Flatten(), # (64,512,1,1) -&gt; (64,512) \n    torch.nn.Linear(512,2,bias=False) # (64,512) -&gt; (64,2) \n)\n\n\nnet = torch.nn.Sequential(\n    net1,\n    net2\n)\n\n\nlrnr2= Learner(dls,net,metrics=accuracy) # loss_fn??\n\n\nlrnr2.loss_func, lrnr.loss_func ## 알아서 기존의 loss function으로 잘 들어가 있음. \n\n(FlattenedLoss of CrossEntropyLoss(), FlattenedLoss of CrossEntropyLoss())\n\n\n\nlrnr2.fine_tune(5) # net2를 수정해서 accuracy가 안좋아지긴 했는데 그래도 쓸만함 \n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.240225\n0.521585\n0.826793\n00:44\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.139931\n0.159443\n0.940460\n00:44\n\n\n1\n0.123673\n0.396028\n0.864682\n00:44\n\n\n2\n0.094375\n0.136513\n0.952639\n00:44\n\n\n3\n0.052172\n0.057100\n0.977673\n00:44\n\n\n4\n0.028230\n0.041083\n0.985792\n00:44\n\n\n\n\n\n\n\n구현3단계– 수정된 net2에서 Linear와 AP의 순서를 바꿈\n- 1개의 observation을 고정하였을 경우 출력과정 상상\n\nximg = PILImage.create('/home/csy/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_106.jpg')\nx = first(dls.test_dl([ximg]))[0]\n\n\nnet2\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\nprint(net1(x).shape)\nprint(net2[0](net1(x)).shape)\nprint(net2[1](net2[0](net1(x))).shape)\nprint(net2[2](net2[1](net2[0](net1(x)))).shape)\n\ntorch.Size([1, 512, 16, 16])\ntorch.Size([1, 512, 1, 1])\ntorch.Size([1, 512])\ntorch.Size([1, 2])\n\n\n- 최종결과 확인\n\nnet(x)\n\nTensorImage([[-6.7946,  8.0881]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n아마 모델 달라서 값이 다른 것일까..!\n\ndls.vocab\n\n['cat', 'dog']\n\n\n\nnet(x)에서 뒤쪽의 값이 클수록 ’dog’를 의미한다.\n\n- net2의 순서 바꾸기 전 전체 네트워크:\n\\[\\underset{(1,3,512,512)}{\\boldsymbol x} \\overset{net_1}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{ap}{\\to} \\underset{(1,512,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,512)}{{\\boldsymbol \\sharp}}\\overset{linear}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}}\\right) = [-9.0358,  9.0926]\\]\n- 아래와 같이 순서를 바꿔서 한번 계산해보고 싶다. (왜???..)\n\\[\\underset{(1,3,224,224)}{\\boldsymbol x} \\overset{net_1}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{linear}{\\to} \\underset{(1,2,16,16)}{{\\bf why}}\\overset{ap}{\\to} \\underset{(1,2,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}}\\right) = [−9.0358,9.0926]\\]\n\n여기에서 (1,512,16,16) -&gt; (1,2,16,16) 로 가는 선형변환을 적용하는 방법? (16,16) each pixel에 대하여 (512 \\(\\to\\) 2)로 가는 변환을 수행\n\n- 통찰: 이 경우 특이하게도 레이어의 순서를 바꿨을때 출력이 동일함 (선형변환하고 평균내거나 평균내고 선형변환하는건 같으니까)\n\n_x =torch.tensor([1,2,3.14,4]).reshape(4,1)\n_x \n\ntensor([[1.0000],\n        [2.0000],\n        [3.1400],\n        [4.0000]])\n\n\n\n_l1 = torch.nn.Linear(1,1,bias=False)\n_l1(_x).mean() # _x -&gt; 선형변환 -&gt; 평균 \n\ntensor(-0.2621, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\n_l1(_x.mean().reshape(1,1)) # _x -&gt; 평균 -&gt; 선형변환\n\ntensor([[-0.2621]], grad_fn=&lt;MmBackward0&gt;)\n\n\n- 구현해보자.\n\nnet2[2].weight.shape,net1(x).shape\n\n(torch.Size([2, 512]), torch.Size([1, 512, 16, 16]))\n\n\n\nwhy = torch.einsum('cb,abij-&gt;acij',net2[2].weight,net1(x))\nwhy.shape\n\ntorch.Size([1, 2, 16, 16])\n\n\n\nnet2[0](why)\n\nTensorImage([[[[-6.7946]],\n\n              [[ 8.0881]]]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\nnet(x)\n\nTensorImage([[-6.7946,  8.0881]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\n\n잠깐 멈추고 생각\n- 이미지\n\nximg\n\n\n\n\n- 네트워크의 결과\n\nnet2(net1(x))\n\nTensorImage([[-6.7946,  8.0881]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\n-9.0358 &lt;&lt; 9.0926 이므로 ’ximg’는 높은 확률로 개라는 뜻이다.\n\n내거에서는 9.0926이 10.2985\n- 아래의 네트워크를 관찰\n\\[\\underset{(1,2,16,16)}{{\\bf why}}\\overset{ap}{\\to} \\underset{(1,2,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}} = [-9.0358,9.0926]\\]\n\nnet2[0](why)\n\nTensorImage([[[[-6.7946]],\n\n              [[ 8.0881]]]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n더 파고들어서 분석해보자.\n\nwhy.shape\n\ntorch.Size([1, 2, 16, 16])\n\n\n\n(why[0,0,:,:]).mean(), (why[0,1,:,:]).mean()\n\n(TensorImage(-6.7946, device='cuda:0', grad_fn=&lt;AliasBackward0&gt;),\n TensorImage(8.0881, device='cuda:0', grad_fn=&lt;AliasBackward0&gt;))\n\n\nwhy[0,0,:,:]\n\n#collapse_output\n(why[0,0,:,:]).to(torch.int64)\n\nTensorImage([[   0,    0,    0,    0,    0,    0,    0,   -1,   -1,    0,    0,\n                 0,    0,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -1,   -9,  -18,  -18,   -9,   -2,\n                 0,    0,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -8,  -31,  -51,  -44,  -25,   -8,\n                 0,    0,    0,    0,    0],\n             [   0,    0,    0,    0,    0,  -16,  -50,  -82,  -73,  -45,  -14,\n                 0,    0,    0,    0,    0],\n             [   0,    0,    0,    0,   -1,  -21,  -59,  -98, -111,  -63,  -18,\n                -1,    0,    0,    0,    0],\n             [   0,    0,    0,    0,    0,  -17,  -53,  -94, -100,  -60,  -18,\n                -2,    0,    0,    0,    0],\n             [   0,    0,    0,    0,    0,  -10,  -37,  -65,  -66,  -40,  -13,\n                -2,   -1,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -6,  -25,  -43,  -34,  -16,   -4,\n                -2,   -1,   -1,    0,    0],\n             [   0,    0,    0,    0,    0,   -5,  -17,  -22,  -15,   -4,   -1,\n                -1,   -1,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -4,  -11,  -11,   -7,   -1,    0,\n                 0,    0,    0,    0,    0],\n             [   0,    0,    0,    0,   -1,   -2,   -3,   -2,    0,    0,    0,\n                 0,    1,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -1,    0,    1,    2,    1,    0,\n                 0,    0,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -3,    0,    1,    4,    3,    0,\n                -1,    0,    0,    0,    0],\n             [   0,   -1,    0,    0,   -1,   -2,   -1,    1,    3,    2,   -1,\n                -2,   -1,    0,    0,    0],\n             [  -1,   -1,    0,   -1,   -1,   -5,   -3,    0,    0,    0,   -2,\n                -2,   -2,   -1,   -1,   -1],\n             [  -1,   -1,    0,    0,   -1,   -7,   -5,    0,   -1,   -1,   -1,\n                -1,   -2,   -1,   -1,   -1]], device='cuda:0')\n\n\n\n이 값들의 평균은 -9.0358 이다. (이 값이 클수록 이 그림이 고양이라는 의미 = 이 값이 작을수록 이 그림이 고양이가 아니라는 의미)\n그런데 살펴보니 대부분의 위치에서 0에 가까운 값을 가짐. 다만 특정위치에서 엄청 큰 작은값이 있어서 -9.0358이라는 평균값이 나옴 \\(\\to\\) 특정위치에 존재하는 엄청 작은 값들은 ximg가 고양이가 아니라고 판단하는 근거가 된다.\n\nwhy[0,1,:,:]\n\n#collapse_output\n(why[0,1,:,:]).to(torch.int64)\n\nTensorImage([[  0,   0,   0,   0,   0,   0,   0,   2,   2,   1,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   1,  11,  21,  21,  11,   3,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   9,  35,  61,  53,  30,  11,   1,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,  19,  58,  95,  87,  54,  17,   1,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   1,  24,  68, 114, 132,  75,  22,   1,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   1,  20,  61, 109, 118,  72,  21,   2,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,  12,  43,  75,  77,  46,  15,   3,   1,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   7,  28,  50,  39,  18,   5,   2,   2,\n                1,   0,   0],\n             [  0,   0,   0,   0,   0,   6,  19,  26,  17,   5,   1,   1,   1,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   5,  12,  13,   9,   2,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   1,   2,   3,   3,   1,   0,   0,   0,  -1,\n                0,   0,   0],\n             [  0,   0,   0,   0,   1,   1,   1,  -1,  -2,  -1,   1,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   1,   4,   0,  -1,  -5,  -3,   0,   1,   0,\n                0,   0,   0],\n             [  0,   1,   0,   0,   1,   3,   1,  -1,  -3,  -3,   1,   2,   1,\n                0,   0,   1],\n             [  1,   1,   1,   1,   1,   6,   4,   0,   0,   0,   2,   3,   2,\n                1,   1,   1],\n             [  1,   1,   1,   1,   1,   8,   6,   1,   1,   1,   1,   1,   2,\n                1,   1,   1]], device='cuda:0')\n\n\n\n이 값들의 평균은 9.0926 이다. (이 값이 클수록 이 그림이 강아지라는 의미)\n그런데 살펴보니 대부분의 위치에서 0에 가까운 값을 가짐. 다만 특정위치에서 엄청 큰 값들이 있어서 9.0926이라는 평균값이 나옴 \\(\\to\\) 특정위치에 존재하는 엄청 큰 값들은 결국 ximg를 강아지라고 판단하는 근거가 된다.\n\n- 시각화\n\nwhy_cat = why[0,0,:,:]\nwhy_dog = why[0,1,:,:]\n\n\nfig, ax = plt.subplots(1,3,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_cat.to(\"cpu\").detach(),cmap='magma')\nax[2].imshow(why_dog.to(\"cpu\").detach(),cmap='magma')\n\n&lt;matplotlib.image.AxesImage at 0x7fe61ad76350&gt;\n\n\n\n\n\n\nmagma = 검은색 &lt; 보라색 &lt; 빨간색 &lt; 노란색\n왼쪽그림의 검은 부분은 고양이가 아니라는 근거, 오른쪽그림의 노란부분은 강아지라는 근거\n\n- why_cat, why_dog를 (16,16) \\(\\to\\) (512,512) 로 resize\n\nfig, ax = plt.subplots(1,3,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_cat.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear')\nax[2].imshow(why_dog.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear')\n\n&lt;matplotlib.image.AxesImage at 0x7fe616821f10&gt;\n\n\n\n\n\n- 겹쳐그리기\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[0].imshow(why_cat.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[1].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_dog.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\n\n&lt;matplotlib.image.AxesImage at 0x7fe5eac7af10&gt;\n\n\n\n\n\n- 하니이미지 시각화\n\n!wget https://github.com/guebin/DL2022/blob/master/_notebooks/2022-09-06-hani01.jpeg\n\n--2022-11-02 23:41:24--  https://github.com/guebin/DL2022/blob/master/_notebooks/2022-09-06-hani01.jpeg\nResolving github.com (github.com)... 20.200.245.247\nConnecting to github.com (github.com)|20.200.245.247|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [text/html]\nSaving to: ‘2022-09-06-hani01.jpeg’\n\n2022-09-06-hani01.j     [ &lt;=&gt;                ] 134.25K  --.-KB/s    in 0.02s   \n\n2022-11-02 23:41:24 (8.09 MB/s) - ‘2022-09-06-hani01.jpeg’ saved [137470]\n\n\n\n\n#\n#!wget https://github.com/guebin/DL2022/blob/master/_notebooks/2022-09-06-hani01.jpeg?raw=true\nximg= PILImage.create('2022-09-07-dogs.jpeg')\nx= first(dls.test_dl([ximg]))[0]\n\n\nwhy = torch.einsum('cb,abij-&gt;acij',net2[2].weight,net1(x))\nwhy_cat = why[0,0,:,:]\nwhy_dog = why[0,1,:,:]\n\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[0].imshow(why_cat.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[1].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_dog.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\n\n&lt;matplotlib.image.AxesImage at 0x7fe61ae94190&gt;\n\n\n\n\n\n- 하니이미지 시각화 with prob\n\nsftmax=torch.nn.Softmax(dim=1)\n\n\nsftmax(net(x))\n\nTensorImage([[1.1767e-09, 1.0000e+00]], device='cuda:0',\n            grad_fn=&lt;AliasBackward0&gt;)\n\n\n\ncatprob, dogprob = sftmax(net(x))[0,0].item(), sftmax(net(x))[0,1].item()\n\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[0].imshow(why_cat.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[0].set_title('catprob= %f' % catprob) \nax[1].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_dog.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[1].set_title('dogprob=%f' % dogprob)\n\nText(0.5, 1.0, 'dogprob=1.000000')\n\n\n\n\n\n\n\n구현4단계– CAM 시각화\n\nsftmax = torch.nn.Softmax(dim=1)\n\n\nfig, ax = plt.subplots(5,5) \nk=0 \nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -&gt; acij', net2[2].weight, net1(x))\n        why_cat = why[0,0,:,:] \n        why_dog = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob&gt;dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_cat.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"cat(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_dog.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"dog(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=25\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -&gt; acij', net2[2].weight, net1(x))\n        why_cat = why[0,0,:,:] \n        why_dog = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob&gt;dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_cat.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"cat(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_dog.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"dog(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=50\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -&gt; acij', net2[2].weight, net1(x))\n        why_cat = why[0,0,:,:] \n        why_dog = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob&gt;dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_cat.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"cat(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_dog.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"dog(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=75\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -&gt; acij', net2[2].weight, net1(x))\n        why_cat = why[0,0,:,:] \n        why_dog = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob&gt;dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_cat.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"cat(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_dog.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"dog(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/ml/2022-09-07-ml.html",
    "href": "posts/ml/2022-09-07-ml.html",
    "title": "Intro",
    "section": "",
    "text": "기계학습 특강 (1주차) 9월7일\n\n딥러닝 프레임워크\n딥러닝 슈퍼스타: 힌튼, 얀르쿤, 요수아 벤지오, 응\n요수아벤지오가 티아노를 만들었음.\n\n2010 티아노 (요수아벤지오)\n2013 caffe\n2015 체이너\n2015 텐서플로우 (구글)\n2015 케라스 (프랑소와 숄레)\n2016 파이토치 (페이스북)\n\n2017 티아노 개발 중지 선언 - 사실 개인 개발자나 대학연구팀이 구글과 메타(페이스북)을 이기는 건 불가능 - 사실상 텐서플로우와 파이토치가 양분해야하는게 맞는데? - 케라스가 안죽어..\n\n\n케라스의 시대\n케라스의 시대가 왔다 왜?? 쓰기가 쉬워요..\n누가 쓰기쉽냐\n\n비 컴퓨터공학 출신\n딥러닝의 딥도 모르는 사람\n\n–&gt; 인공지능구현을 거의 엑셀다루는 수준으로 내림..\n–&gt; 잘 모르겠지만 이렇게 이미지 넣으면 개 고양이 구분해줍니다!\n다른 언어는 어떠냐\n\n텐서플로우: 이건 진짜 못된 언어임 (높은 수준의 파이썬 숙련도가 필요, 컴공위주로 만들어졌음)\n파이토치: 프로그래밍 숙련도는 높지 않은데, 딥러닝의 알고리즘이 머리속에 있어야 함\n\n케라스가 압도..\n결말: 구글이 케라스를 삽니다.\n\n\n케라스와 파이토치의 시대\n그런데 지금은 파이토치랑 케라스(텐서플로우)가 비등비등해요,\n그런데 점점 파이토치를 쓰는 추세 왜?"
  },
  {
    "objectID": "posts/ml/2022-12-08-13wk.html",
    "href": "posts/ml/2022-12-08-13wk.html",
    "title": "RNN (13주차)",
    "section": "",
    "text": "IMDB자료의 분석 (텍스트생성과 감성분류), 잡담"
  },
  {
    "objectID": "posts/ml/2022-12-08-13wk.html#잡담1-순환신경망-텍스트마이닝-시계열분석",
    "href": "posts/ml/2022-12-08-13wk.html#잡담1-순환신경망-텍스트마이닝-시계열분석",
    "title": "RNN (13주차)",
    "section": "잡담1: 순환신경망, 텍스트마이닝, 시계열분석",
    "text": "잡담1: 순환신경망, 텍스트마이닝, 시계열분석\n- 순환신경망은 순서가 있는 (말이 좀 애매하지만 아무튼 이렇게 많이 표현해요) 자료를 분석할때 사용할 수 있다. 순서가 있는 자료는 대표적으로 시계열자료과 텍스트자료가 있다.\n- 그래서 언뜻 생각하면 텍스트마이닝이나 시계열분석과 내용이 비슷할 것 같지만 사실 그렇지 않다.\n\n텍스트마이닝의 토픽: 단어를 어떻게 숫자로 잘 만들지, 토픽모델 // 자잘하고 실용적인 느낌? 공학적임..\n\n시계열분석의 토픽: 예측(forecasting)과 신뢰구간, 변화점과 관련한 연구 (detection/test), 정상/비정상시계열모형 (ARIMA, GARCH), Cointegration Test, // 느낌이 좀 거창해.. 경제와 관련 많음.\n순환신경망의 토픽(재작년까지): 텍스트생성, 텍스트분류 + 시계열 자료의 예측, 단어의 숫자화 … 텍스트마이닝과 시계열분석의 거의 모든 토픽에 관여함\n순환신경망의 토픽(작년부터?): 딥러닝의 거의 모든 영역에 관여하기 시작함 (심지어 요즘 이미지 분석도 순환망으로 합니다)\n\n\nhttps://youtu.be/thsXGOkcGGg"
  },
  {
    "objectID": "posts/ml/2022-12-08-13wk.html#잡담2-순환신경망의-아키텍처를-얼마나-깊이-이해해야-할까",
    "href": "posts/ml/2022-12-08-13wk.html#잡담2-순환신경망의-아키텍처를-얼마나-깊이-이해해야-할까",
    "title": "RNN (13주차)",
    "section": "잡담2: 순환신경망의 아키텍처를 얼마나 깊이 이해해야 할까?",
    "text": "잡담2: 순환신경망의 아키텍처를 얼마나 깊이 이해해야 할까?\n- 과거기준(텍스트생성, 텍스트분류, 시계열자료예측 등에만 순환망이 이용되었을 때): 학부수준에서 순수 RNN만 알아도 충분했던 것 같음. LSTM이나 GRU는 석사수준?\n- 현재기준: 석사기준 LSTM 같은건 기본이고 어텐션, 트랜스포머등에 대한 개념도 잘 알고 있어야 함. (학부는 잘 모르겠네..)\n- 내 생각: 결국 아키텍처는 근데 유행이라 아키텍처는 한번 따라하면서 이해해보고 핵심 아이디어만 이해하면 된다고 생각함. 즉 LSTM 같은 특정모형의 아키텍처를 달달 외울필요는 없다, 수식써있는거 보고 이해하면 그만임. (수식정도를 이해할 능력은 필요한게.. 코드를 짤때 옵션을 이해할 수는 있어야하니까)\n- 망상: 나중에는 순환신경망이 거의 모든 딥러닝 방법의 base가 되지 않을까?"
  },
  {
    "objectID": "posts/ml/2022-12-08-13wk.html#잡담3-fastai-pytorch-lightning",
    "href": "posts/ml/2022-12-08-13wk.html#잡담3-fastai-pytorch-lightning",
    "title": "RNN (13주차)",
    "section": "잡담3: fastai, pytorch lightning",
    "text": "잡담3: fastai, pytorch lightning\n- 비 컴퓨터공학 출신이 쓰기에는 fastai가 좀 더 쓰기 편한건 사실\n- pytorch lightning은 fastai보다 쓰기 어렵지만 (진짜 약간의 클래스관련 지식이 필요함, 솔직히 별로 어렵진 않아요) 좀 더 순수 파이토치에 가깝고 따라서 코드를 뜯어보기 편리하다.\n- 과거의 생각\n\n전문가: pytorch + fastai // pytorch + pytorch lightning (컴공출신)\n비 전문가: 순수 fastai\n\n- 요즘 생각\n\n모두: pytorch + pytorch lightning\n특정한경우: 순수 fastai &lt;– 모형이 구현되어 있다면 fastai가 좋긴 좋아.. 그런데 모형의 구현속도가 못따라감"
  },
  {
    "objectID": "posts/ml/2022-12-08-13wk.html#잡담4-우린-뭘-해야-할까-학석사-레벨에서..",
    "href": "posts/ml/2022-12-08-13wk.html#잡담4-우린-뭘-해야-할까-학석사-레벨에서..",
    "title": "RNN (13주차)",
    "section": "잡담4: 우린 뭘 해야 할까 (학석사 레벨에서..)",
    "text": "잡담4: 우린 뭘 해야 할까 (학석사 레벨에서..)\n- 능력1: 코드이해력 (= 구현능력 = 코드 베끼는 능력)\n\n이미지분석? 해봤음. 텍스트자료? 해봤음. 시계열? 해봤음. 등등등등? 다 해본적 있음. 어떤 원리인지 정확하게 몰라도 다 해본적 있고 그래서 일할 수 있음!!\n돌아가는 코드 최대한 많이 모아놓으세요. torch, fastai, pytorch lightning, tensorflow, keras 등등\n\n- 능력2: 최신트렌드를 파악할 수 있는 힘 (= 논문이해력)\n\n공부, 공부, 공부… A to Z 까지 수식 다 뜯어보고 코드 다 뜯어보면서 집요하게 공부해야함. (LSTM에서 했던것 처럼!) 물론 차근차근 알려주면 수업이 있다면 좋겠지 그런데 보통은 적당히 두리뭉실하게 설명하지 detail 하게 설명하는 수업은 잘 없음. (지루하거든요)\n수식이나 코드중 하나라도 볼 줄 모르면 능력2를 얻는것 자체가 불가능."
  },
  {
    "objectID": "posts/ml/2022-11-29-13wk-2-final.html",
    "href": "posts/ml/2022-11-29-13wk-2-final.html",
    "title": "Deep Learning final example",
    "section": "",
    "text": "기말고사\nimport torch \nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/ml/2022-11-29-13wk-2-final.html#hihello-90점",
    "href": "posts/ml/2022-11-29-13wk-2-final.html#hihello-90점",
    "title": "Deep Learning final example",
    "section": "1. hi?hello!! (90점)",
    "text": "1. hi?hello!! (90점)\n아래와 같은 데이터가 있다고 하자.\n\ntxt = list('hi?hello!!')*100 \ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5], txt_y[:5]\n\n(['h', 'i', '?', 'h', 'e'], ['i', '?', 'h', 'e', 'l'])\n\n\ntxt_x와 txt_y를 이용하여 아래와 같은 순서로 다음문자를 예측하고 싶은 신경망을 설계하고 싶다.\nh \\(\\to\\) i \\(\\to\\) ? \\(\\to\\) h \\(\\to\\) e \\(\\to\\) l \\(\\to\\) l \\(\\to\\) o \\(\\to\\) ! \\(\\to\\) ! \\(\\to\\) h \\(\\to\\) i \\(\\to\\) ? \\(\\to\\) h \\(\\to\\) e \\(\\to\\) \\(\\dots\\)\n(1)-(6) 의 풀이에 공통적으로 필요한 과정 정리\n\ndef f(txt,mapping):\n    return [mapping[key] for key in txt] \nsig = torch.nn.Sigmoid()\nsoft = torch.nn.Softmax(dim=1)\ntanh = torch.nn.Tanh()\nmapping = {'!':0, '?':1,'h':2,'i':3,'e':4,'l':5,'o':6} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")\n\n(1) torch.nn.RNN()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라.\n(풀이)\n\nrnn = torch.nn.RNN(7,8).to(\"cuda:0\")\nlinr = torch.nn.Linear(8,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n_water = torch.zeros(1,8).to(\"cuda:0\")\nfor epoc in range(500):\n    ## 1\n    hidden, hT = rnn(x)\n    output = linr(hidden)\n    ## 2\n    loss = loss_fn(output,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nyhat=soft(output)    \nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);\n\n\n\n\n(2) torch.nn.RNNCell()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라.\n\ntorch.manual_seed(12345)\nrnncell = torch.nn.RNNCell(7,8).to(\"cuda:0\")\nlinr = torch.nn.Linear(8,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden = [] \n    ht = torch.zeros(8).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht = rnncell(xt,ht) \n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden)\n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\narray([[0.   , 0.005, 0.   , 0.982, 0.013, 0.   , 0.   ],\n       [0.   , 0.999, 0.   , 0.   , 0.   , 0.001, 0.   ],\n       [0.   , 0.   , 1.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.001, 0.999, 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 1.   ],\n       [1.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [1.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.   , 1.   , 0.   , 0.   , 0.   , 0.   ]], dtype=float32)\n\n\n\nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);\n\n\n\n\n(3) torch.nn.Module을 상속받은 클래스를 정의하고 (2)의 결과와 동일한 적합값이 나오는 신경망을 설계한 뒤 학습하라. (초기값을 적절하게 설정할 것)\n\nclass를 이용하지 않으면 점수없음.\ntorch.nn.RNN(), torch.nn.RNNCell() 을 이용한 네트워크를 학습시킬시 점수 없음. (초기값을 셋팅하는 용도로는 torch.nn.RNN(), torch.nn.RNNCell()을 코드에 포함시키는 것이 가능)\n\n\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(7,8)\n        self.h2h = torch.nn.Linear(8,8) \n        self.tanh = torch.nn.Tanh()\n    def forward(self,xt,ht):\n        ht = self.tanh(self.i2h(xt)+self.h2h(ht))\n        return ht\n\n\nrnncell = rNNCell().to(\"cuda:0\")\nlinr = torch.nn.Linear(8,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(linr.parameters()),lr=0.1)\n\n\n## 초기화의 설정을 위한 코드\ntorch.manual_seed(43052)\n_rnncell = torch.nn.RNNCell(7,8).to(\"cuda:0\")\n_linr = torch.nn.Linear(8,7).to(\"cuda:0\")\nrnncell.i2h.weight.data = _rnncell.weight_ih.data \nrnncell.h2h.weight.data = _rnncell.weight_hh.data \nrnncell.h2h.bias.data = _rnncell.bias_hh.data\nrnncell.i2h.bias.data = _rnncell.bias_ih.data\nlinr.weight.data = _linr.weight.data \nlinr.bias.data = _linr.bias.data \n\n\nfor epoc in range(100):\n    ## 1\n    hidden = [] \n    ht = torch.zeros(8).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht = rnncell(xt,ht)\n        # ot = linr(ht) \n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\narray([[0.   , 0.005, 0.008, 0.972, 0.014, 0.001, 0.   ],\n       [0.   , 0.997, 0.002, 0.   , 0.   , 0.001, 0.   ],\n       [0.   , 0.001, 0.999, 0.   , 0.001, 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.999, 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n       [0.   , 0.001, 0.   , 0.   , 0.   , 0.999, 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 1.   ],\n       [0.999, 0.   , 0.   , 0.   , 0.   , 0.   , 0.001],\n       [0.999, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.001, 0.998, 0.   , 0.   , 0.   , 0.   ]], dtype=float32)\n\n\n\nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);\n\n\n\n\n(4) torch.nn.LSTM()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라.\n(풀이)\n\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\nlinr = torch.nn.Linear(4,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n_water = torch.zeros(1,4).to(\"cuda:0\")\nfor epoc in range(500):\n    ## 1\n    hidden, (hT,cT) = lstm(x,(_water,_water))\n    output = linr(hidden)\n    ## 2\n    loss = loss_fn(output,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nyhat=soft(output)    \nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);\n\n\n\n\n(5) torch.nn.LSTMCell()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라.\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\")\nlinr = torch.nn.Linear(4,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstmcell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden = []\n    ht = torch.zeros(4).to(\"cuda:0\")\n    ct = torch.zeros(4).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht,ct = lstmcell(xt,(ht,ct))\n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden)\n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\narray([[0.   , 0.014, 0.084, 0.081, 0.822, 0.   , 0.   ],\n       [0.002, 0.91 , 0.   , 0.083, 0.003, 0.   , 0.001],\n       [0.001, 0.   , 0.999, 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.001, 0.005, 0.072, 0.917, 0.004, 0.   ],\n       [0.   , 0.   , 0.004, 0.   , 0.001, 0.995, 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 0.999, 0.001],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.999],\n       [0.998, 0.001, 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.99 , 0.   , 0.006, 0.001, 0.   , 0.003, 0.   ],\n       [0.007, 0.   , 0.992, 0.   , 0.   , 0.001, 0.   ]], dtype=float32)\n\n\n\nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);\n\n\n\n\n(6) (5)의 결과와 동일한 적합값을 출력하는 신경망을 직접설계한 뒤 학습시켜라. (초기값을 적절하게 설정할 것)\n\nclass를 이용하지 않아도 무방함.\ntorch.nn.LSTM(), torch.nn.LSTMCell() 을 이용한 네트워크를 학습시킬시 점수 없음. (초기값을 셋팅하는 용도로는 torch.nn.LSTM(), torch.nn.LSTMCell()을 코드에 포함시키는 것이 가능)\n\n\nclass lSTMCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(7,16)\n        self.h2h = torch.nn.Linear(4,16) \n        self.tanh = torch.nn.Tanh()\n    def forward(self,xt,past):\n        ht,ct = past \n        ifgo = self.i2h(xt) + self.h2h(ht) \n        it = sig(ifgo[0:4])\n        ft = sig(ifgo[4:8])\n        gt = tanh(ifgo[8:12])\n        ot = sig(ifgo[12:16])\n        ct = ft*ct + it*gt\n        ht = ot*self.tanh(ct) \n        return ht,ct\n\n\nlstmcell = lSTMCell().to(\"cuda:0\")\nlinr = torch.nn.Linear(4,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstmcell.parameters())+list(linr.parameters()),lr=0.1)\n\n\n# 초기값셋팅\ntorch.manual_seed(43052) \n_lstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\")\n_linr = torch.nn.Linear(4,7).to(\"cuda:0\")\nlstmcell.i2h.weight.data = _lstmcell.weight_ih.data \nlstmcell.h2h.weight.data = _lstmcell.weight_hh.data \nlstmcell.i2h.bias.data = _lstmcell.bias_ih.data\nlstmcell.h2h.bias.data = _lstmcell.bias_hh.data\nlinr.weight.data = _linr.weight.data \nlinr.bias.data = _linr.bias.data \n\n\nfor epoc in range(100):\n    ## 1\n    hidden = []     \n    ht = torch.zeros(4).to(\"cuda:0\")\n    ct = torch.zeros(4).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht,ct = lstmcell(xt,(ht,ct))\n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\narray([[0.   , 0.014, 0.084, 0.081, 0.822, 0.   , 0.   ],\n       [0.002, 0.91 , 0.   , 0.083, 0.003, 0.   , 0.001],\n       [0.001, 0.   , 0.999, 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.001, 0.005, 0.072, 0.917, 0.004, 0.   ],\n       [0.   , 0.   , 0.004, 0.   , 0.001, 0.995, 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 0.999, 0.001],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.999],\n       [0.998, 0.001, 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.99 , 0.   , 0.006, 0.001, 0.   , 0.003, 0.   ],\n       [0.007, 0.   , 0.992, 0.   , 0.   , 0.001, 0.   ]], dtype=float32)\n\n\n\nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);"
  },
  {
    "objectID": "posts/ml/2022-11-29-13wk-2-final.html#다음을-읽고-참-거짓을-판단하여라.-10점",
    "href": "posts/ml/2022-11-29-13wk-2-final.html#다음을-읽고-참-거짓을-판단하여라.-10점",
    "title": "Deep Learning final example",
    "section": "2. 다음을 읽고 참 거짓을 판단하여라. (10점)",
    "text": "2. 다음을 읽고 참 거짓을 판단하여라. (10점)\n(1) RNN은 LSTM에 비하여 장기기억에 유리하다.\n참\n(2) torch.nn.Embedding(num_embeddings=2,embedding_dim=1)와 torch.nn.Linear(in_features=1,out_features=1)의 학습가능한 파라메터수는 같다.\n참\n(3)아래와 같은 네트워크를 고려하자.\nnet = torch.nn.Linear(1,1)\n차원이 (n,1) 인 임의의 텐서에 대하여 net(x)와 net.forword(x)의 출력결과는 같다.\n참\n(4) 아래와 같이 a,b,c,d 가 반복되는 문자열이 반복되는 자료에서 다음문자열을 맞추는 과업을 수행하기 위해서는 반드시 순환신경망의 형태로 설계해야만 한다\na,b,c,d,a,b,c,d,…\n거짓\n(5) RNN 혹은 LSTM 으로 신경망을 설계할 시 손실함수는 항상 torch.nn.CrossEntropyLoss 를 사용해야 한다.\n거짓"
  },
  {
    "objectID": "posts/ml/2022-10-19-ml_7w.html",
    "href": "posts/ml/2022-10-19-ml_7w.html",
    "title": "CNN (7주차)",
    "section": "",
    "text": "기계학습 특강 (7주차) 10월19일 [딥러닝의 기초 - 드랍아웃, 이미지자료분석]"
  },
  {
    "objectID": "posts/ml/2022-10-19-ml_7w.html#imports",
    "href": "posts/ml/2022-10-19-ml_7w.html#imports",
    "title": "CNN (7주차)",
    "section": "imports",
    "text": "imports\n\nimport torch\nfrom fastai.vision.all import *\nimport matplotlib.pyplot as plt\n\nimport torchvision\n\n\nimport graphviz\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"'+s + '; }');"
  },
  {
    "objectID": "posts/ml/2022-10-19-ml_7w.html#깊은신경망-오버피팅",
    "href": "posts/ml/2022-10-19-ml_7w.html#깊은신경망-오버피팅",
    "title": "CNN (7주차)",
    "section": "깊은신경망– 오버피팅",
    "text": "깊은신경망– 오버피팅\n\n데이터\n- model: \\(y_i = (0\\times x_i) + \\epsilon_i\\)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(100,1)\ny=torch.randn(100).reshape(100,1)*0.01\nplt.plot(x,y)\n\n\n\n\n\n\n모든 데이터를 사용하여 적합 (512, relu, 1000 epochs)\n\ntorch.manual_seed(1) \nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y)\nplt.plot(x,net(x).data, '--')\n\n\n\n\n\n\n전체데이터를 8:2로 나누어서 8만을 학습\n- 데이터를 8:2로 나눈다\n\nxtr = x[:80]\nytr = y[:80] \nxtest = x[80:] \nytest = y[80:] \n\n\nx.shape, xtr.shape, xtest.shape\n\n(torch.Size([100, 1]), torch.Size([80, 1]), torch.Size([20, 1]))\n\n\n\ny.shape, ytr.shape, ytest.shape\n\n(torch.Size([100, 1]), torch.Size([80, 1]), torch.Size([20, 1]))\n\n\n\nplt.plot(xtr,ytr,'o')\nplt.plot(xtest,ytest,'o')\n\n\n\n\n- (xtr,ytr) 만 가지고 net를 학습시킨다.\n\ntorch.manual_seed(1) \nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(1000):\n    ## 1 \n    # yhat\n    ## 2 \n    loss = loss_fn(net(xtr),ytr) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(xtr,ytr,'o')\nplt.plot(xtest,ytest,'o')\nplt.plot(x,net(x).data,'--k') \n#plt.plot(xtr,net(xtr).data,'--k') \n#plt.plot(xtest,net(xtest).data,'--k') \n\n\n\n\n(서연 필기) 오차항이 너무 잘 따라가면 영향을 미칠 수 있다.\n데이터에 비해 노드 수가 많으면 오버피팅의 가능성 - 한 변수로 모든 변수 맞추는 우연을 마주한다면? - 모델에 비해 feature가 너무 클때? - 위를 예로 들면 input은 1이었는데 output은 512렸다\n차원의 저주"
  },
  {
    "objectID": "posts/ml/2022-10-19-ml_7w.html#깊은신경망-드랍아웃",
    "href": "posts/ml/2022-10-19-ml_7w.html#깊은신경망-드랍아웃",
    "title": "CNN (7주차)",
    "section": "깊은신경망– 드랍아웃",
    "text": "깊은신경망– 드랍아웃\n\n오버피팅의 해결\n- 오버피팅의 해결책: 드랍아웃\n동등한 초기값에서 시작한다고 설명 - manual_seed 정해준거\n\ntorch.manual_seed(1) \nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.8),\n    torch.nn.Linear(in_features=512,out_features=1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(1000):\n    ## 1 \n    #\n    ## 2 \n    loss = loss_fn(net(xtr),ytr) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n계속 바뀌는 plot\n\nplt.plot(xtr,ytr,'o')\nplt.plot(xtest,ytest,'o')\nplt.plot(x,net(x).data,'--k') \nplt.title(r\"network is in training mode\",fontsize=15)\n\nText(0.5, 1.0, 'network is in training mode')\n\n\n\n\n\n- 올바른 사용법\n\nnet.training\n\nTrue\n\n\nevaliation method 사용\n\nnet.eval()\nnet.training\n\nFalse\n\n\n\nplt.plot(xtr,ytr,'o')\nplt.plot(xtest,ytest,'o')\nplt.plot(x,net(x).data,'--k') \nplt.title(r\"network is in evaluation mode\",fontsize=15)\n\nText(0.5, 1.0, 'network is in evaluation mode')\n\n\n\n\n\n\n\n드랍아웃 레이어\n\n_x = torch.linspace(0,1,101) \n_x \n\ntensor([0.0000, 0.0100, 0.0200, 0.0300, 0.0400, 0.0500, 0.0600, 0.0700, 0.0800,\n        0.0900, 0.1000, 0.1100, 0.1200, 0.1300, 0.1400, 0.1500, 0.1600, 0.1700,\n        0.1800, 0.1900, 0.2000, 0.2100, 0.2200, 0.2300, 0.2400, 0.2500, 0.2600,\n        0.2700, 0.2800, 0.2900, 0.3000, 0.3100, 0.3200, 0.3300, 0.3400, 0.3500,\n        0.3600, 0.3700, 0.3800, 0.3900, 0.4000, 0.4100, 0.4200, 0.4300, 0.4400,\n        0.4500, 0.4600, 0.4700, 0.4800, 0.4900, 0.5000, 0.5100, 0.5200, 0.5300,\n        0.5400, 0.5500, 0.5600, 0.5700, 0.5800, 0.5900, 0.6000, 0.6100, 0.6200,\n        0.6300, 0.6400, 0.6500, 0.6600, 0.6700, 0.6800, 0.6900, 0.7000, 0.7100,\n        0.7200, 0.7300, 0.7400, 0.7500, 0.7600, 0.7700, 0.7800, 0.7900, 0.8000,\n        0.8100, 0.8200, 0.8300, 0.8400, 0.8500, 0.8600, 0.8700, 0.8800, 0.8900,\n        0.9000, 0.9100, 0.9200, 0.9300, 0.9400, 0.9500, 0.9600, 0.9700, 0.9800,\n        0.9900, 1.0000])\n\n\n\ndout = torch.nn.Dropout(0.9)\ndout(_x)\n\ntensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 0.0000, 0.0000, 1.3000, 0.0000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 2.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 4.1000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 5.9000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 7.1000,\n        0.0000, 0.0000, 0.0000, 0.0000, 7.6000, 7.7000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 8.9000,\n        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000])\n\n\n\n90%의 드랍아웃: 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배 만큼 값이 커진다.\n\n- 드랍아웃레이어 정리 - 구조: 입력 -&gt; 드랍아웃레이어 -&gt; 출력 - 역할: (1) 입력의 일부를 임의로 0으로 만드는 역할 (2) 0이 안된것들은 스칼라배하여 드랍아웃을 통과한 모든 숫자들의 총합이 일정하게 되도록 조정 - 효과: 오버피팅을 억제하는 효과가 있음 (왜??) - 추측일뿐! - 의미: each iteration (each epoch x) 마다 학습에 참여하는 노드가 로테이션으로 랜덤으로 결정됨. - 느낌: 모든 노드가 골고루 학습가능 + 한 두개의 특화된 능력치가 개발되기 보다 평균적인 능력치가 전반적으로 개선됨\n(서연 필기) 지배적인 예측 값들보다 비지배적인 예측값을 건들려고 하면 의미가 없음."
  },
  {
    "objectID": "posts/ml/2022-10-19-ml_7w.html#이미지자료분석-data",
    "href": "posts/ml/2022-10-19-ml_7w.html#이미지자료분석-data",
    "title": "CNN (7주차)",
    "section": "이미지자료분석– data",
    "text": "이미지자료분석– data\n- download data\n\npath = untar_data(URLs.MNIST)\n\n- training set\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1])/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n- test set\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nXX = torch.concat([X0,X1])/255\nyy = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\nX.shape,XX.shape,y.shape,yy.shape\n\n(torch.Size([12665, 1, 28, 28]),\n torch.Size([2115, 1, 28, 28]),\n torch.Size([12665, 1]),\n torch.Size([2115, 1]))"
  },
  {
    "objectID": "posts/ml/2022-10-19-ml_7w.html#이미지자료분석-cnn-예비학습",
    "href": "posts/ml/2022-10-19-ml_7w.html#이미지자료분석-cnn-예비학습",
    "title": "CNN (7주차)",
    "section": "이미지자료분석– CNN 예비학습",
    "text": "이미지자료분석– CNN 예비학습\n\n기존의 MLP 모형\n- 교재의 모형\n\n#collapse\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"x1\"\n    \"x2\"\n    \"..\"\n    \"x784\"\n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"x1\" -&gt; \"node1\"\n    \"x2\" -&gt; \"node1\"\n    \"..\" -&gt; \"node1\"\n    \n    \"x784\" -&gt; \"node1\"\n    \"x1\" -&gt; \"node2\"\n    \"x2\" -&gt; \"node2\"\n    \"..\" -&gt; \"node2\"\n    \"x784\" -&gt; \"node2\"\n    \n    \"x1\" -&gt; \"...\"\n    \"x2\" -&gt; \"...\"\n    \"..\" -&gt; \"...\"\n    \"x784\" -&gt; \"...\"\n\n    \"x1\" -&gt; \"node30\"\n    \"x2\" -&gt; \"node30\"\n    \"..\" -&gt; \"node30\"\n    \"x784\" -&gt; \"node30\"\n\n\n    label = \"Layer 1: ReLU\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -&gt; \"y\"\n    \"node2\" -&gt; \"y\"\n    \"...\" -&gt; \"y\"\n    \"node30\" -&gt; \"y\"\n    label = \"Layer 2: Sigmoid\"\n}\n''')\n\n\n\n\n- 왜 28 by 28 이미지를 784개의 벡터로 만든 다음에 모형을 돌려야 하는가?\n- 기존에 개발된 모형이 회귀분석 기반으로 되어있어서 결국 회귀분석 틀에 짜 맞추어서 이미지자료를 분석하는 느낌\n- observation의 차원은 \\(784\\)가 아니라 \\(1\\times (28\\times 28)\\)이 되어야 맞다.\n\n\n새로운 아키텍처의 제시\n- 예전\n\\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,30)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,30)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\\(l_1\\): 선형변환, feature를 뻥튀기하는 역할\n\n\\(\\sim\\) 꺾인 선이 많아진다\n\n\\(relu\\): 뻥튀기된 feature에 비선형을 추가하여 표현력 극대화\n\\(l_2\\): 선형변환, 뻥튀기된 feature를 요약 하는 역할 (=데이터를 요약하는 역할)\n\n- 새로운 아키텍처 - \\(conv\\): feature를 뻥튀기하는 역할 (2d ver \\(l_1\\) 느낌) - \\(relu\\): - \\(pooling\\): 데이터를 요약하는 역할\n\n\nCONV 레이어 (선형변환의 2D 버전)\n- 우선 연산하는 방법만 살펴보자.\n(예시1)\n\ntorch.manual_seed(43052)\n_conv = torch.nn.Conv2d(1,1,(2,2)) # 입력1, 출력1, (2,2) window size\n_conv.weight.data, _conv.bias.data\n\n(tensor([[[[-0.1733, -0.4235],\n           [ 0.1802,  0.4668]]]]),\n tensor([0.2037]))\n\n\n\n_X = torch.arange(4).reshape(1,1,2,2).float()\n_X\n\ntensor([[[[0., 1.],\n          [2., 3.]]]])\n\n\n\n(-0.1733)*0 + (-0.4235)*1 +\\\n(0.1802)*2 + (0.4668)*3 + 0.2037\n\n1.541\n\n\n\n_conv(_X)\n\ntensor([[[[1.5410]]]], grad_fn=&lt;ThnnConv2DBackward0&gt;)\n\n\n\ntorch.__version__\n\n'1.10.1'\n\n\n(예시2) 잘하면 평균도 계산하겠다?\n\n_conv.weight.data = torch.tensor([[[[1/4, 1/4],[1/4,1/4]]]])\n_conv.bias.data = torch.tensor([0.0])\n_conv.weight.data,_conv.bias.data\n\n(tensor([[[[0.2500, 0.2500],\n           [0.2500, 0.2500]]]]),\n tensor([0.]))\n\n\n\n_conv(_X) , (0+1+2+3)/4\n\n(tensor([[[[1.5000]]]], grad_fn=&lt;ThnnConv2DBackward0&gt;), 1.5)\n\n\n(예시3) 이동평균?\n\n_X = torch.arange(0,25).float().reshape(1,1,5,5) \n_X\n\ntensor([[[[ 0.,  1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.,  9.],\n          [10., 11., 12., 13., 14.],\n          [15., 16., 17., 18., 19.],\n          [20., 21., 22., 23., 24.]]]])\n\n\n\n_conv(_X)\n\ntensor([[[[ 3.,  4.,  5.,  6.],\n          [ 8.,  9., 10., 11.],\n          [13., 14., 15., 16.],\n          [18., 19., 20., 21.]]]], grad_fn=&lt;ThnnConv2DBackward0&gt;)\n\n\n(예시4) window size가 증가한다면? (2d의 이동평균느낌)\n\n_conv = torch.nn.Conv2d(1,1,(3,3)) # 입력1, 출력1, (3,3) window size\n_conv.bias.data = torch.tensor([0.0])\n_conv.weight.data = torch.tensor([[[[1/9,1/9,1/9],[1/9,1/9,1/9],[1/9,1/9,1/9]]]])\n\n(3,3)이나~ 3이나~\n\n_X,_conv(_X)\n\n(tensor([[[[ 0.,  1.,  2.,  3.,  4.],\n           [ 5.,  6.,  7.,  8.,  9.],\n           [10., 11., 12., 13., 14.],\n           [15., 16., 17., 18., 19.],\n           [20., 21., 22., 23., 24.]]]]),\n tensor([[[[ 6.0000,  7.0000,  8.0000],\n           [11.0000, 12.0000, 13.0000],\n           [16.0000, 17.0000, 18.0000]]]], grad_fn=&lt;ThnnConv2DBackward0&gt;))\n\n\n\n(1+2+3+6+7+8+11+12+13)/9\n\n7.0\n\n\n(예시5) 피처뻥튀기\n\n_X = torch.tensor([1.0,1.0,1.0,1.0]).reshape(1,1,2,2)\n_X\n\ntensor([[[[1., 1.],\n          [1., 1.]]]])\n\n\n\n_conv = torch.nn.Conv2d(1,8,(2,2))\n_conv.weight.data.shape,_conv.bias.data.shape\n\n(torch.Size([8, 1, 2, 2]), torch.Size([8]))\n\n\n\n_conv(_X).shape\n\ntorch.Size([1, 8, 1, 1])\n\n\n\n_conv(_X).reshape(-1)\n\ntensor([-0.3464,  0.2739,  0.1069,  0.6105,  0.0432,  0.8390,  0.2353,  0.2345],\n       grad_fn=&lt;ReshapeAliasBackward0&gt;)\n\n\n\ntorch.sum(_conv.weight.data[0,...])+_conv.bias.data[0],\\\ntorch.sum(_conv.weight.data[1,...])+_conv.bias.data[1]\n\n(tensor(-0.3464), tensor(0.2739))\n\n\n결국 아래를 계산한다는 의미\n\ntorch.sum(_conv.weight.data,axis=(2,3)).reshape(-1)+ _conv.bias.data\n\ntensor([-0.3464,  0.2739,  0.1069,  0.6105,  0.0432,  0.8390,  0.2353,  0.2345])\n\n\n\n_conv(_X).reshape(-1)\n\ntensor([-0.3464,  0.2739,  0.1069,  0.6105,  0.0432,  0.8390,  0.2353,  0.2345],\n       grad_fn=&lt;ReshapeAliasBackward0&gt;)\n\n\n(잔소리) axis 사용 익숙하지 않으면 아래 꼭 들으세요..\n\nhttps://guebin.github.io/IP2022/2022/04/11/(6주차)-4월11일.html , numpy공부 4단계: 축\n\n\n\nReLU (2d)\n\n_X = torch.randn(25).reshape(1,5,5)\n_X\n\ntensor([[[ 0.2656,  0.0780,  3.0465,  1.0151, -2.3908],\n         [ 0.4749,  1.6519,  1.5454,  1.0376,  0.9291],\n         [-0.7858,  0.4190,  2.6057, -0.4022,  0.2092],\n         [ 0.9594,  0.6408, -0.0411, -1.0720, -2.0659],\n         [-0.0996,  1.1351,  0.9758,  0.4952, -0.5475]]])\n\n\n\na1=torch.nn.ReLU()\n\n\na1(_X)\n\ntensor([[[0.2656, 0.0780, 3.0465, 1.0151, 0.0000],\n         [0.4749, 1.6519, 1.5454, 1.0376, 0.9291],\n         [0.0000, 0.4190, 2.6057, 0.0000, 0.2092],\n         [0.9594, 0.6408, 0.0000, 0.0000, 0.0000],\n         [0.0000, 1.1351, 0.9758, 0.4952, 0.0000]]])\n\n\n\n\nMaxpooling 레이어\n\n_maxpooling = torch.nn.MaxPool2d((2,2))\n\n\n_X = torch.arange(16).float().reshape(1,4,4) \n\n\n_X, _maxpooling(_X) \n\n(tensor([[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]]]),\n tensor([[[ 5.,  7.],\n          [13., 15.]]]))\n\n\n가장 중요한 특징만 남게 될 것이다.\n\n_X = torch.arange(25).float().reshape(1,5,5) \n\n\n_X, _maxpooling(_X) \n\n(tensor([[[ 0.,  1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.,  9.],\n          [10., 11., 12., 13., 14.],\n          [15., 16., 17., 18., 19.],\n          [20., 21., 22., 23., 24.]]]),\n tensor([[[ 6.,  8.],\n          [16., 18.]]]))\n\n\n버려지는 데이터\n\n_X = torch.arange(36).float().reshape(1,6,6) \n\n\n_X, _maxpooling(_X) \n\n(tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.],\n          [ 6.,  7.,  8.,  9., 10., 11.],\n          [12., 13., 14., 15., 16., 17.],\n          [18., 19., 20., 21., 22., 23.],\n          [24., 25., 26., 27., 28., 29.],\n          [30., 31., 32., 33., 34., 35.]]]),\n tensor([[[ 7.,  9., 11.],\n          [19., 21., 23.],\n          [31., 33., 35.]]]))"
  },
  {
    "objectID": "posts/ml/2022-10-19-ml_7w.html#이미지자료분석-cnn-구현-cpu",
    "href": "posts/ml/2022-10-19-ml_7w.html#이미지자료분석-cnn-구현-cpu",
    "title": "CNN (7주차)",
    "section": "이미지자료분석– CNN 구현 (CPU)",
    "text": "이미지자료분석– CNN 구현 (CPU)\n\nX.shape\n\ntorch.Size([12665, 1, 28, 28])\n\n\n\n(1) Conv2d\n\nc1 = torch.nn.Conv2d(1,16,(5,5))\nprint(X.shape)\nprint(c1(X).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\n\n\n\n\n(2) ReLU\n\na1 = torch.nn.ReLU()\nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\n\n\n\n\n(3) MaxPool2D\n\nm1 =  torch.nn.MaxPool2d((2,2)) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\n\n\n\n\n(4) 적당히 마무리하고 시그모이드 태우자\n- 펼치자.\n(방법1)\n\nm1(a1(c1(X))).reshape(-1,2304).shape\n\ntorch.Size([12665, 2304])\n\n\n\n16*12*12 \n\n2304\n\n\n(방법2)\n\nflttn = torch.nn.Flatten()\n\n\nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\n\n\n- 2304 \\(\\to\\) 1 로 차원축소하는 선형레이어를 설계\n\nl1 = torch.nn.Linear(in_features=2304,out_features=1) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\nprint(l1(flttn(m1(a1(c1(X))))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\ntorch.Size([12665, 1])\n\n\n- 시그모이드\n\na2 = torch.nn.Sigmoid()\n\n\nl1 = torch.nn.Linear(in_features=2304,out_features=1) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\nprint(l1(flttn(m1(a1(c1(X))))).shape)\nprint(a1(l1(flttn(m1(a1(c1(X)))))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\ntorch.Size([12665, 1])\ntorch.Size([12665, 1])\n\n\n- 네트워크 설계\n\nnet = torch.nn.Sequential(\n    c1, # 2d: 컨볼루션(선형변환), 피처 뻥튀기 \n    a1, # 2d: 렐루(비선형변환)\n    m1, # 2d: 맥스풀링: 데이터요약\n    flttn, # 2d-&gt;1d \n    l1, # 1d: 선형변환\n    a2 # 1d: 시그모이드(비선형변환) \n)\n\n\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nt1= time.time()\nfor epoc in range(100): \n    ## 1\n    yhat = net(X) \n    ## 2\n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\nt2= time.time()\nt2-t1\n\n39.31594634056091\n\n\n\nplt.plot(y)\nplt.plot(net(X).data,'.')\nplt.title('Traning Set',size=15)\n\nText(0.5, 1.0, 'Traning Set')\n\n\n\n\n\n\nplt.plot(yy)\nplt.plot(net(XX).data,'.')\nplt.title('Test Set',size=15)\n\nText(0.5, 1.0, 'Test Set')"
  },
  {
    "objectID": "posts/ml/2022-10-19-ml_7w.html#이미지자료분석-cnn-구현-gpu",
    "href": "posts/ml/2022-10-19-ml_7w.html#이미지자료분석-cnn-구현-gpu",
    "title": "CNN (7주차)",
    "section": "이미지자료분석– CNN 구현 (GPU)",
    "text": "이미지자료분석– CNN 구현 (GPU)\n\n1. dls\n\nds1=torch.utils.data.TensorDataset(X,y)\nds2=torch.utils.data.TensorDataset(XX,yy)\n\n\nX.shape\n\ntorch.Size([12665, 1, 28, 28])\n\n\n\nlen(X)/10\n\n1266.5\n\n\n\nlen(XX)\n\n2115\n\n\n\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \n\n\ndls = DataLoaders(dl1,dl2) # 이거 fastai 지원함수입니다\n\n\n\n2. lrnr 생성: 아키텍처, 손실함수, 옵티마이저\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\n\n\nlrnr = Learner(dls,net,loss_fn)\n\n\n\n3. 학습\n\nlrnr.fit(10) \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.901239\n0.605223\n00:00\n\n\n1\n0.660227\n0.370985\n00:00\n\n\n2\n0.507106\n0.213785\n00:00\n\n\n3\n0.393017\n0.113283\n00:00\n\n\n4\n0.304846\n0.065374\n00:00\n\n\n5\n0.238648\n0.042887\n00:00\n\n\n6\n0.189261\n0.031143\n00:00\n\n\n7\n0.152003\n0.024236\n00:00\n\n\n8\n0.123435\n0.019730\n00:00\n\n\n9\n0.101176\n0.016531\n00:00\n\n\n\n\n\n\nlrnr.model\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n  (5): Sigmoid()\n)\n\n\n\n\n4. 예측 및 시각화\n\nnet.to(\"cpu\") \n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n  (5): Sigmoid()\n)\n\n\n- 결과를 시각화하면 아래와 같다.\n\nplt.plot(net(X).data,'.')\nplt.title(\"Training Set\",size=15)\n\nText(0.5, 1.0, 'Training Set')\n\n\n\n\n\n\nplt.plot(net(XX).data,'.')\nplt.title(\"Test Set\",size=15)\n\nText(0.5, 1.0, 'Test Set')\n\n\n\n\n\n1/10만 사용했는데 잘 training된 것 같다\n- 빠르고 적합결과도 좋음\n\n\nLrnr 오브젝트\n\nlrnr.model\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n  (5): Sigmoid()\n)\n\n\n\nnet\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n  (5): Sigmoid()\n)\n\n\n\nid(lrnr.model), id(net)\n\n(140021490006720, 140021490006720)\n\n\n\nlrnr.model(X)\n\ntensor([[4.5555e-05],\n        [1.2910e-03],\n        [6.6828e-04],\n        ...,\n        [9.8670e-01],\n        [9.8576e-01],\n        [9.9344e-01]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nnet(X)\n\ntensor([[4.5555e-05],\n        [1.2910e-03],\n        [6.6828e-04],\n        ...,\n        [9.8670e-01],\n        [9.8576e-01],\n        [9.9344e-01]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n같은 결과\n20221026 수업\n\n\nBCEWithLogitsLoss\n- BCEWithLogitsLoss = Sigmoid + BCELoss - 왜 써요? 수치적으로 더 안정\ntorch.nn.BCEWithLogitsLoss - This loss combines a Sigmoid layer and the BCELoss in one single class. This version is more numerically stable than using a plain Sigmoid followed by a BCELoss as, by combining the operations into one layer, we take advantage of the log-sum-exp trick for numerical stability.\n- 사용방법\n\ndls 만들기\n\n\nds1=torch.utils.data.TensorDataset(X,y)\nds2=torch.utils.data.TensorDataset(XX,yy)\n\n\ntorch.utils.data.TensorDataset?\n\n\nInit signature: torch.utils.data.TensorDataset(*args, **kwds)\nDocstring:     \nDataset wrapping tensors.\nEach sample will be retrieved by indexing tensors along the first dimension.\nArgs:\n    *tensors (Tensor): tensors that have the same size of the first dimension.\nFile:           ~/anaconda3/envs/csy/lib/python3.8/site-packages/torch/utils/data/dataset.py\nType:           type\nSubclasses:     \n\n\n\n\n\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \n\n\ndls = DataLoaders(dl1,dl2) # 이거 fastai 지원함수입니다\n\n\nlrnr생성\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,1),\n    #torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCEWithLogitsLoss()\nlrnr = Learner(dls,net,loss_fn) \n\n\n학습\n\n\nlrnr.fit(10)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.956781\n0.642780\n00:00\n\n\n1\n0.709626\n0.419758\n00:00\n\n\n2\n0.554641\n0.248010\n00:00\n\n\n3\n0.431661\n0.118707\n00:00\n\n\n4\n0.331514\n0.059536\n00:00\n\n\n5\n0.256312\n0.035956\n00:00\n\n\n6\n0.200917\n0.025288\n00:00\n\n\n7\n0.159611\n0.019510\n00:00\n\n\n8\n0.128254\n0.015889\n00:00\n\n\n9\n0.104057\n0.013373\n00:00\n\n\n\n\n\n\n예측 및 시각화\n\n\nnet.to(\"cpu\")\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n)\n\n\n시각화 위해서 cpu로 옮겨주기\n\nnet(X)\n\ntensor([[-9.4061],\n        [-6.7910],\n        [-7.9819],\n        ...,\n        [ 4.3685],\n        [ 4.4061],\n        [ 5.4793]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\nsigmoid 취하기 전이지 우리는 bcewithlogiticsLoss 썼잖아, 그래서 0~1사이 아님\n\na2(torch.tensor(0))\n\ntensor(0.5000)\n\n\n\nfig,ax = plt.subplots(1,2,figsize=(8,4))\nax[0].plot(net(X).data,',',color=\"C1\")\nax[1].plot(y)\nax[1].plot(a2(net(X)).data,',')\nfig.suptitle(\"Training Set\",size=15)\n\nText(0.5, 0.98, 'Training Set')\n\n\n\n\n\n\nfig,ax = plt.subplots(1,2,figsize=(8,4))\nax[0].plot(net(XX).data,',',color=\"C1\")\nax[1].plot(yy)\nax[1].plot(a2(net(XX)).data,',')\nfig.suptitle(\"Test Set\",size=15)\n\nText(0.5, 0.98, 'Test Set')"
  },
  {
    "objectID": "posts/ml/2022-10-05-ml-HW.html",
    "href": "posts/ml/2022-10-05-ml-HW.html",
    "title": "Homework",
    "section": "",
    "text": "기계학습 특강 (6주차) 10월5일 Homework"
  },
  {
    "objectID": "posts/ml/2022-10-05-ml-HW.html#imports",
    "href": "posts/ml/2022-10-05-ml-HW.html#imports",
    "title": "Homework",
    "section": "imports",
    "text": "imports\n\nimport torch\nimport torchvision\nfrom fastai.data.all import *\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/ml/2022-10-05-ml-HW.html#숙제-해설-및-풀이는-여기참고",
    "href": "posts/ml/2022-10-05-ml-HW.html#숙제-해설-및-풀이는-여기참고",
    "title": "Homework",
    "section": "숙제 (해설 및 풀이는 여기참고)",
    "text": "숙제 (해설 및 풀이는 여기참고)\n\n숫자0과 숫자1을 구분하는 네트워크를 아래와 같은 구조로 설계하라\n\n\\[\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,64)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,64)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n위에서 \\(a_1\\)은 relu를, \\(a_2\\)는 sigmoid를 의미한다.\n\n“y=0”은 숫자0을 의미하도록 하고 “y=1”은 숫자1을 의미하도록 설정하라.\n\n\npath = untar_data(URLs.MNIST)\n\n\nzero_fnames = (path/'training/0').ls()\n\n\none_fnames = (path/'training/1').ls()\n\n\nX0 = torch.stack([torchvision.io.read_image(str(zf)) for zf in zero_fnames])\n\n\nX1 = torch.stack([torchvision.io.read_image(str(of)) for of in one_fnames])\n\n\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28).float()\n\n\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\ntorch.manual_seed(12345)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,1),\n    torch.nn.Sigmoid()\n)\n\n\n아래의 지침에 따라 200 epoch 학습을 진행하라.\n\n\n손실함수는 BECLoss를 이용할 것. torch.nn.BCELoss() 를 이용할 것.\n옵티마이저는 아담으로 설정할 것. 학습률은 lr=0.002로 설정할 것.\n\n\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.002)\n\n\nfor epoc in range(200):\n    yhat = net(X)\n    loss = loss_fn(yhat,y)\n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y)\nplt.plot(yhat.data,'.',alpha=0.4)\n\n\n\n\n\n아래의 지침에 따라 200 epoch 학습을 진행하라. 학습이 잘 되는가?\n\n\n손실함수는 BECLoss를 이용할 것. torch.nn.BCELoss()를 사용하지 않고 수식을 직접 입력할 것.\n옵티마이저는 아담으로 설정할 것. 학습률은 lr=0.002로 설정할 것.\n\n\ntorch.manual_seed(12345)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,1),\n    torch.nn.Sigmoid()\n)\n\n\noptimizr = torch.optim.Adam(net.parameters(),lr=0.002)\n\n\nfor epoc in range(200):\n    yhat = net(X)\n    loss = -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat))\n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y)\nplt.plot(yhat.data,'.',alpha=0.4)\n\n\n\n\n\nyhat.data\n\ntensor([[nan],\n        [nan],\n        [nan],\n        ...,\n        [nan],\n        [nan],\n        [nan]])\n\n\n학습이 잘 되지 않았다.\n\n아래의 지침에 따라 200 epoch 학습을 진행하라. 학습이 잘 되는가?\n\n\n이미지의 값을 0과 1사이로 규격화 하라. (Xnp = Xnp/255 를 이용하세요!)\n손실함수는 BECLoss를 이용할 것. torch.nn.BCELoss()를 사용하지 않고 수식을 직접 입력할 것.\n옵티마이저는 아담으로 설정할 것. 학습률은 lr=0.002로 설정할 것.\n\n\nX = X/255\n\n\ntorch.manual_seed(12345)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,1),\n    torch.nn.Sigmoid()\n)\n\n\noptimizr=torch.optim.Adam(net.parameters(),lr=0.002)\n\n\nfor epoc in range(200):\n    yhat = net(X)\n    loss = -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat))\n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y)\nplt.plot(yhat.data,'.',alpha=0.4)\n\n\n\n\n\n아래와 같은 수식을 이용하여 accuracy를 계산하라.\n\n\\(\\text{accuracy}=\\frac{1}{n}\\sum_{i=1}^n I(\\tilde{y}_i=y_i)\\) - \\(\\tilde{y}_i = \\begin{cases}  1 & \\hat{y}_i &gt; 0.5 \\\\  0 & \\hat{y}_i \\leq 0.5 \\end{cases}\\) - \\(I(\\tilde{y}_i=y_i) = \\begin{cases} 1 & \\tilde{y}_i=y_i \\\\ 0 & \\tilde{y}_i \\neq y_i \\end{cases}\\)\n단, \\(n\\)은 0과 1을 의미하는 이미지의 수\n\nytilde = (yhat &gt; 0.5) * 1\n\n\nytilde\n\ntensor([[0],\n        [0],\n        [0],\n        ...,\n        [1],\n        [1],\n        [1]])\n\n\n\n(ytilde == y) * 1\n\ntensor([[1],\n        [1],\n        [1],\n        ...,\n        [1],\n        [1],\n        [1]])\n\n\n\ntorch.sum((ytilde == y) * 1)\n\ntensor(12661)\n\n\n\ntorch.sum((ytilde == y) * 1)/len(y)\n\ntensor(0.9997)\n\n\n\nprint(\"accuraccy: \",torch.sum((ytilde == y) * 1)/len(y))\n\naccuraccy:  tensor(0.9997)"
  },
  {
    "objectID": "posts/ml/2022-11-02-ml_9w.html",
    "href": "posts/ml/2022-11-02-ml_9w.html",
    "title": "RNN (9주차)",
    "section": "",
    "text": "기계학습 특강 (9주차) 11월02일 [순환신경망– ab예제, embedding layer]"
  },
  {
    "objectID": "posts/ml/2022-11-02-ml_9w.html#import",
    "href": "posts/ml/2022-11-02-ml_9w.html#import",
    "title": "RNN (9주차)",
    "section": "import",
    "text": "import\n\nimport torch\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/ml/2022-11-02-ml_9w.html#define-some-funtions",
    "href": "posts/ml/2022-11-02-ml_9w.html#define-some-funtions",
    "title": "RNN (9주차)",
    "section": "Define some funtions",
    "text": "Define some funtions\n- 활성화함수들\n\nsig = torch.nn.Sigmoid()\nsoft = torch.nn.Softmax(dim=1)\ntanh = torch.nn.Tanh()\n\n\n_x = torch.linspace(-5,5,100)\nplt.plot(_x,tanh(_x))\nplt.title(\"tanh(x)\", size=15)\n\nText(0.5, 1.0, 'tanh(x)')\n\n\n\n\n\nhyperblic tangent(https://en.wikipedia.org/wiki/Hyperbolic_functions) - sigmoid(범위가0 ~ 1)와 차이점(범위가 -1 ~ 1)\n- 문자열 -&gt; 숫자로 바꾸는 함수\n\ndef f(txt,mapping):\n    return [mapping[key] for key in txt] \n\n(사용예시1)\n\ntxt = ['a','b','a']\nmapping = {'a':33,'b':-22}\nprint('변환전: %s'% txt)\nprint('변환후: %s'% f(txt,mapping))\n\n변환전: ['a', 'b', 'a']\n변환후: [33, -22, 33]\n\n\n(사용예시2)\n\ntxt = ['a','b','a']\nmapping = {'a':[1,0],'b':[0,1]}\nprint('변환전: %s'% txt)\nprint('변환후: %s'% f(txt,mapping))\n\n변환전: ['a', 'b', 'a']\n변환후: [[1, 0], [0, 1], [1, 0]]"
  },
  {
    "objectID": "posts/ml/2022-11-02-ml_9w.html#exam1-ab",
    "href": "posts/ml/2022-11-02-ml_9w.html#exam1-ab",
    "title": "RNN (9주차)",
    "section": "Exam1: ab",
    "text": "Exam1: ab\n\ndata\n\ntxt = list('ab')*100\ntxt[:10]\n\n['a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['a', 'b', 'a', 'b', 'a'], ['b', 'a', 'b', 'a', 'b'])\n\n\n\n\n선형모형을 이용한 풀이\n\n(풀이1) 1개의 파라메터 – 실패\n- 데이터정리\n\nx = torch.tensor(f(txt_x,{'a':0,'b':1})).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,{'a':0,'b':1})).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 학습 및 결과 시각화\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=False)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:5],'o')\nplt.plot(net(x).data[:5])\n\n\n\n\n\n잘 학습이 안되었다.\n\n- 학습이 잘 안된 이유\n\npd.DataFrame({'x':x[:5].reshape(-1),'y':y[:5].reshape(-1)})\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n0.0\n1.0\n\n\n1\n1.0\n0.0\n\n\n2\n0.0\n1.0\n\n\n3\n1.0\n0.0\n\n\n4\n0.0\n1.0\n\n\n\n\n\n\n\n현재 \\(\\hat{y}_i = \\hat{w}x_i\\) 꼴의 아키텍처이고 \\(y_i \\approx \\hat{w}x_i\\) 가 되는 적당한 \\(\\hat{w}\\)를 찾아야 하는 상황 - \\((x_i,y_i)=(0,1)\\) 이면 어떠한 \\(\\hat{w}\\)를 선택해도 \\(y_i \\approx \\hat{w}x_i\\)를 만드는 것이 불가능\n- \\((x_i,y_i)=(1,0)\\) 이면 \\(\\hat{w}=0\\)일 경우 \\(y_i \\approx \\hat{w}x_i\\)로 만드는 것이 가능\n상황을 종합해보니 \\(\\hat{w}=0\\)으로 학습되는 것이 그나마 최선\n0에 무엇을 곱하든 0이 되어서 학습이 안 돼\n\n\n(풀이2) 1개의 파라메터 – 성공, but 확장성이 없는 풀이\n- 0이라는 값이 문제가 되므로 인코딩방식의 변경\n\nx = torch.tensor(f(txt_x,{'a':-1,'b':1})).float().reshape(-1,1) \ny = torch.tensor(f(txt_y,{'a':-1,'b':1})).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[-1.],\n         [ 1.],\n         [-1.],\n         [ 1.],\n         [-1.]]),\n tensor([[ 1.],\n         [-1.],\n         [ 1.],\n         [-1.],\n         [ 1.]]))\n\n\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=False)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(2000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과는 성공\n\nplt.plot(y[:5],'o')\nplt.plot(net(x).data[:5])\n\n\n\n\n\n딱봐도 클래스가 3개일 경우 확장이 어려워 보인다.\n\n원핫인코딩해줘야 좋은데 그러면 마지막 무조건 softmax 그러면 loss는 BCELoss\n\n\n\n로지스틱 모형을 이용한 풀이\n\n(풀이1) 1개의 파라메터 – 실패\n- 데이터를 다시 a=0, b=1로 정리\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 학습\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=False)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 결과해석: 예상되었던 실패임 - 아키텍처는 \\(\\hat{y}_i = \\text{sig}(\\hat{w}x_i)\\) 꼴이다. - \\((x_i,y_i)=(0,1)\\) 이라면 어떠한 \\(\\hat{w}\\)을 선택해도 \\(\\hat{w}x_i=0\\) 이다. 이경우 \\(\\hat{y}_i = \\text{sig}(0) = 0.5\\) 가 된다. - \\((x_i,y_i)=(1,0)\\) 이라면 \\(\\hat{w}=-5\\)와 같은 값으로 선택하면 \\(\\text{sig}(-5) \\approx 0 = y_i\\) 와 같이 만들 수 있다. - 상황을 종합하면 net의 weight는 \\(\\text{sig}(\\hat{w}x_i) \\approx 0\\) 이 되도록 적당한 음수로 학습되는 것이 최선임을 알 수 있다.\n\nnet.weight # 적당한 음수값으로 학습되어있음을 확인\n\nParameter containing:\ntensor([[-2.8288]], requires_grad=True)\n\n\n\n\n(풀이2) 2개의 파라메터 + 좋은 초기값 – 성공\n- 동일하게 a=0, b=1로 맵핑\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 네트워크에서 bias를 넣기로 결정함\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=True)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- net의 초기값을 설정 (이것은 좋은 초기값임)\n\nnet.weight.data = torch.tensor([[-5.00]])\nnet.bias.data = torch.tensor([+2.500])\n\n\nnet(x)[:10]\n\ntensor([[ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n- 학습전 결과\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\nbias 쓰게 되면서 한쪽을 뭉개주는 효과?\n- 학습후결과\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n\n\n(풀이3) 2개의 파라메터 + 나쁜초기값 – 성공\n- a=0, b=1\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 이전과 동일하게 바이어스가 포함된 네트워크 설정\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=True)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- 초기값설정 (이 초기값은 나쁜 초기값임)\n\nnet.weight.data = torch.tensor([[+5.00]])\nnet.bias.data = torch.tensor([-2.500])\n\n\nnet(x)[:10]\n\ntensor([[-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n- 학습전상태: 반대모양으로 되어있다.\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 학습\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n\n결국 수렴하긴 할듯\n\n\n\n(풀이4) 3개의 파라메터를 쓴다면?\n- a=0, b=1로 코딩\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 3개의 파라메터를 사용하기 위해서 아래와 같은 구조를 생각하자.\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.ACTIVATION_FUNCTION(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n위와 같은 네트워크를 설정하면 3개의 파라메터를 사용할 수 있다. 적절한 ACTIVATION_FUNCTION을 골라야 하는데 실험적으로 tanh가 적절하다고 알려져있다. (\\(\\to\\) 그래서 우리도 실험적으로 이해해보자)\n\n(예비학습1) net(x)와 사실 net.forwardx(x)는 같다.\n\nnet(x)[:5] # 풀이3에서 학습한 네트워크임\n\ntensor([[-0.1584],\n        [ 0.1797],\n        [-0.1584],\n        [ 0.1797],\n        [-0.1584]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\nnet.forward(x)[:5] # 풀이3에서 학습한 네트워크임\n\ntensor([[-0.1584],\n        [ 0.1797],\n        [-0.1584],\n        [ 0.1797],\n        [-0.1584]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n그래서 net.forward를 재정의하면 net(x)의 기능을 재정의 할 수 있다.\n\nnet.forward = lambda x: 1 \n\n\n“lambda x: 1” 은 입력이 x 출력이 1인 함수를 의미 (즉 입력값에 상관없이 항상 1을 출력하는 함수)\n“net.forward = lambda x:1” 이라고 새롭게 선언하였므로 앞으론 net.forward(x), net(x) 도 입력값에 상관없이 항상 1을 출력하게 될 것임\n\n\nnet(x)\n\n1\n\n\n(예비학습2) torch.nn.Module을 상속받아서 네트워크를 만들면 (= “class XXX(torch.nn.Module):” 와 같은 방식으로 클래스를 선언하면) 약속된 아키텍처를 가진 네트워크를 찍어내는 함수를 만들 수 있다.\n(예시1)\n\nclass Mynet1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.a1 = torch.nn.Sigmoid()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\nnet = Mynet1()\n는 아래와 같은 효과를 가진다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n(예시2)\n\nclass Mynet2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.a1 = torch.nn.ReLU()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\nnet = Mynet2()\n는 아래와 같은 효과를 가진다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.RuLU(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n(예시3)\n\nclass Mynet3(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.a1 = torch.nn.Tanh()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\nnet = Mynet3()\n는 아래와 같은 효과를 가진다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n클래스에 대한 이해가 부족한 학생을 위한 암기방법\nstep1: 아래와 코드를 복사하여 틀을 만든다. (이건 무조건 고정임, XXXX 자리는 원하는 이름을 넣는다)\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        \n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return yhat\n\nnet(x)에 사용하는 x임, yhat은 net.forward(x) 함수의 리턴값임\n사실, x/yhat은 다른 변수로 써도 무방하나 (예를들면 input/output 이라든지) 설명의 편의상 x와 yhat을 고정한다.\n\nstep2: def __init__(self):에 사용할 레이어를 정의하고 이름을 붙인다. 이름은 항상 self.xxx 와 같은 식으로 정의한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Tanh()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return yhat\nstep3: def forward:에 “x –&gt; yhat” 으로 가는 과정을 묘사한 코드를 작성하고 yhat을 리턴하도록 한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Tanh()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        u = self.xxx1(x) \n        v = self.xxx2(u)\n        yhat = self.xxx3(v) \n        ## 정의 끝\n        return yhat\n예비학습 끝\n\n- 우리가 하려고 했던 것: 아래의 아키텍처에서\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.ACTIVATION_FUNCTION(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\nACTIVATION의 자리에 tanh가 왜 적절한지 직관을 얻어보자.\n- 실험결과1(Sig): Sigmoid activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet1()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_1(x):=Sigmoid(x)$\",size=20)\nfig.tight_layout()\n\n\n\n\n큰 폭 -&gt; 학습 속도가 빠르다\n- 실험결과2(ReLU): RuLU activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet2()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_2(x):=ReLU(x)$\",size=20)\nfig.tight_layout()\n\n\n\n\n- 실험결과3(Tanh): Tanh activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet3()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_2(x):=Tanh(x)$\",size=20)        \nfig.tight_layout()\n\n\n\n\n- 실험해석 - sig: 주황색선의 변동폭이 작음 + 항상 0.5근처로 머무는 적합값이 존재 - relu: 주황색선의 변동폭이 큼 + 항상 0.5근처로 머무는 적합값이 존재 - tanh: 주황색선의 변동폭이 큼 + 0.5근처로 머무는 적합값이 존재X\n- 실험해보니까 tanh가 우수한것 같다. \\(\\to\\) 앞으로는 tanh를 쓰자.\n\\(x \\to wx \\to \\tanh \\to wx \\to sig \\to y\\) - x가 양이면 wx 양수 이런 식으로 y로 가게끔 설정하면 설명의 여지가 존재(?)\n(서연 필기)sigmoid하면 0에 머무르는 값 존재해서 0.5에 머무르는 경향, 조금 사용하면 학습 능력이 떨어지기도\n\n\n\n소프트맥스로 확장\n\n(풀이1) 로지스틱모형에서 3개의 파라메터 버전을 그대로 확장\n\nmapping = {'a':[1,0],'b':[0,1]}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,2)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,2)\nx[:5],y[:5]\n\n(tensor([[1., 0.],\n         [0., 1.],\n         [1., 0.],\n         [0., 1.],\n         [1., 0.]]),\n tensor([[0., 1.],\n         [1., 0.],\n         [0., 1.],\n         [1., 0.],\n         [0., 1.]]))\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=2,bias=False)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nsoft(net(x))[:2]\n\ntensor([[0.0048, 0.9952],\n        [0.9953, 0.0047]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\ny[:5][:,1]\n\ntensor([1., 0., 1., 0., 1.])\n\n\n\nplt.plot(y[:5][:,1],'o')\nplt.plot(soft(net(x[:5]))[:,1].data,'--r')\n\n\n\n\nb,a,b,a,,,…\n\nfig,ax = plt.subplots(1,2)\nax[0].imshow(y[:5])\nax[1].imshow(soft(net(x[:5])).data)\n\n&lt;matplotlib.image.AxesImage at 0x7fe521441490&gt;\n\n\n\n\n\n비슷하게 나왔다, 학습이 잘 되었다(중간 대체과제 참고)"
  },
  {
    "objectID": "posts/ml/2022-11-02-ml_9w.html#embedding-layer",
    "href": "posts/ml/2022-11-02-ml_9w.html#embedding-layer",
    "title": "RNN (9주차)",
    "section": "Embedding Layer",
    "text": "Embedding Layer\n\nmotive\n- 결국 최종적으로는 아래와 같은 맵핑방식이 확장성이 있어보인다.\n\nmapping = {'a':[1,0,0],'b':[0,1,0],'c':[0,0,1]} # 원핫인코딩 방식 \n\n- 그런데 매번 \\(X\\)를 원핫인코딩하고 Linear 변환하는것이 번거로운데 이를 한번에 구현하는 함수가 있으면 좋겠다. \\(\\to\\) torch.nn.Embedding Layer가 그 역할을 한다.\nx dimension은 3(원핫인코딩)\n\nmapping = {'a':0,'b':1,'c':2}\nx = torch.tensor(f(list('abc')*100,mapping))\ny = torch.tensor(f(list('bca')*100,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 0, 1]), tensor([1, 2, 0, 1, 2]))\n\n\n\ntorch.manual_seed(43052)\nebdd = torch.nn.Embedding(num_embeddings=3,embedding_dim=1)\n\n\nebdd(x)[:5]\n\ntensor([[-0.8178],\n        [-0.7052],\n        [-0.5843],\n        [-0.8178],\n        [-0.7052]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n- 그런데 사실 언뜻보면 아래의 linr 함수와 역할의 차이가 없어보인다.\n\ntorch.manual_seed(43052)\nlinr = torch.nn.Linear(in_features=1,out_features=1)\n\n\nlinr(x.float().reshape(-1,1))[:5]\n\ntensor([[-0.8470],\n        [-1.1937],\n        [-1.5404],\n        [-0.8470],\n        [-1.1937]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n- 차이점: 파라메터수에 차이가 있다.\n파라메터 적게 쓰는게 비용측면에서 좋으니까\n\nebdd.weight\n\nParameter containing:\ntensor([[-0.8178],\n        [-0.7052],\n        [-0.5843]], requires_grad=True)\n\n\n\nlinr.weight, linr.bias\n\n(Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n결국 ebdd는 아래의 구조에 해당하는 파라메터들이고\n\n$=\n\\[\\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix}\\]\n\n\\[\\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\]\nnet(x)=\n\\[\\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\begin{bmatrix} -0.8178 \\\\ -0.7052 \\\\ -0.5843 \\end{bmatrix}\\]\n=\n\\[\\begin{bmatrix} -0.8178 \\\\ -0.7052 \\\\ -0.5843 \\\\ -0.8178 \\\\ -0.7052  \\end{bmatrix}\\]\n$\n\nlinr는 아래의 구조에 해당하는 파라메터이다.\n\n\\(\\text{x[:5]}= \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix} \\quad net(x)= \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix} \\times (-0.3467) + (-0.8470)=\\begin{bmatrix} -0.8470 \\\\ -1.1937 \\\\ -1.5404 \\\\ -0.8470 \\\\ -1.1937 \\end{bmatrix}\\)\n\n\n\n연습 (ab문제 소프트맥스로 확장한 것 다시 풀이)\n- 맵핑\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 0, 1, 0]), tensor([1, 0, 1, 0, 1]))\n\n\n- torch.nn.Embedding 을 넣은 네트워크\nnum_embedding이 2인 이유 a,b만 있어서\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=2,embedding_dim=1),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=2)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- 학습\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:5],'o')\nplt.plot(soft(net(x[:5]))[:,1].data,'--r')\n\n\n\n\n\nsoft(net(x[:5]))\n\ntensor([[0.0040, 0.9960],\n        [0.9960, 0.0040],\n        [0.0040, 0.9960],\n        [0.9960, 0.0040],\n        [0.0040, 0.9960]], grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nplt.imshow(soft(net(x[:5])).data)\n\n&lt;matplotlib.image.AxesImage at 0x7f1d7067ac50&gt;"
  },
  {
    "objectID": "posts/ml/2022-09-07-ml_1w.html",
    "href": "posts/ml/2022-09-07-ml_1w.html",
    "title": "DNN (1주차)",
    "section": "",
    "text": "기계학습 특강 (1주차) 9월7일 [pytorch]\n\n우리의 1차 목표: 이미지 -&gt; 개/고양이 판단하는 모형을 채용하고, 그 모형에 데이터를 넣어서 학습하고, 그 모형의 결과를 판단하고 싶다. (즉 클래시파이어를 만든다는 소리)\n\n\n우리의 2차 목표: 그 모형에 “새로운” 자료를 전달하여 이미지를 분류할 것이다. (즉 클래시파이어를 쓴다는 소리)\n\n\nimport\n\nfrom fastai.vision.all import *\n\n\n#!nvidia-smi\n\n\nURLs.PETS\n\n'https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz'\n\n\n\npath = untar_data(URLs.PETS)/'images'\n\n\npath\n\nPath('/home/csy/.fastai/data/oxford-iiit-pet/images')\n\n\n\nPILImage.create('/home/csy/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg')\n\n\n\n\n\n_lst = ['/home/csy/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg','/home/csy/.fastai/data/oxford-iiit-pet/images/Abyssinian_10.jpg']\n_lst\n\n['/home/csy/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg',\n '/home/csy/.fastai/data/oxford-iiit-pet/images/Abyssinian_10.jpg']\n\n\n\n_lst[0]\n\n'/home/csy/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg'\n\n\n\nPILImage.create(_lst[1])\n\n\n\n\n\nfilenames = get_image_files(path)\nfilenames\n\n(#7390) [Path('/home/csy/.fastai/data/oxford-iiit-pet/images/Bombay_13.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/beagle_193.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/Ragdoll_8.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/boxer_106.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/keeshond_56.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_162.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/saint_bernard_136.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_76.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/pug_173.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_117.jpg')...]\n\n\n\nfilenames[0]\n\nPath('/home/csy/.fastai/data/oxford-iiit-pet/images/Bombay_13.jpg')\n\n\n\nprint(filenames[0])\nPILImage.create(filenames[0])\n\n/home/csy/.fastai/data/oxford-iiit-pet/images/Bombay_13.jpg\n\n\n\n\n\n\nprint(filenames[1])\nPILImage.create(filenames[1])\n\n/home/csy/.fastai/data/oxford-iiit-pet/images/beagle_193.jpg\n\n\n\n\n\n\nprint(filenames[2])\nPILImage.create(filenames[2])\n\n/home/csy/.fastai/data/oxford-iiit-pet/images/Ragdoll_8.jpg\n\n\n\n\n\n\nprint(filenames[3])\nPILImage.create(filenames[3])\n\n/home/csy/.fastai/data/oxford-iiit-pet/images/boxer_106.jpg\n\n\n\n\n\n\nprint(filenames[4])\nPILImage.create(filenames[4])\n\n/home/csy/.fastai/data/oxford-iiit-pet/images/keeshond_56.jpg\n\n\n\n\n\n\nprint(filenames[5])\nPILImage.create(filenames[5])\n\n/home/csy/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_162.jpg\n\n\n\n\n\n\nprint(filenames[6])\nPILImage.create(filenames[6])\n\n/home/csy/.fastai/data/oxford-iiit-pet/images/saint_bernard_136.jpg\n\n\n\n\n\n\nprint(filenames[7])\nPILImage.create(filenames[7])\n\n/home/csy/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_76.jpg\n\n\n\n\n\n\nprint(filenames[8])\nPILImage.create(filenames[8])\n\n/home/csy/.fastai/data/oxford-iiit-pet/images/pug_173.jpg\n\n\n\n\n\n\nprint(filenames[9])\nPILImage.create(filenames[9])\n\n/home/csy/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_117.jpg\n\n\n\n\n\n\nprint(filenames[20])\nPILImage.create(filenames[20])\n\n/home/csy/.fastai/data/oxford-iiit-pet/images/Maine_Coon_266.jpg\n\n\n\n\n\nvector로 되어 있는 tensor\n\n\n'A'.isupper()\n\nTrue\n\n\n\n\ndef f(fname):\n    if fname[0].isupper():\n        return 'cat'\n    else:\n        return 'dog'\n\n\nf('dddd')\n\n'dog'\n\n\n\nfilenames[0]\n\nPath('/home/csy/.fastai/data/oxford-iiit-pet/images/Bombay_13.jpg')\n\n\n\nImageDataLoaders.from_name_func??\n\n\nSignature:\nImageDataLoaders.from_name_func(\n    path,\n    fnames,\n    label_func,\n    valid_pct=0.2,\n    seed=None,\n    item_tfms=None,\n    batch_tfms=None,\n    bs=64,\n    val_bs=None,\n    shuffle=True,\n    device=None,\n)\nSource:   \n    @classmethod\n    def from_name_func(cls, path, fnames, label_func, **kwargs):\n        \"Create from the name attrs of `fnames` in `path`s with `label_func`\"\n        if sys.platform == 'win32' and isinstance(label_func, types.LambdaType) and label_func.__name__ == '&lt;lambda&gt;':\n            # https://medium.com/@jwnx/multiprocessing-serialization-in-python-with-pickle-9844f6fa1812\n            raise ValueError(\"label_func couldn't be lambda function on Windows\")\n        f = using_attr(label_func, 'name')\n        return cls.from_path_func(path, fnames, f, **kwargs)\nFile:      ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/vision/data.py\nType:      method\n\n\n\n\ndls는 object - 동사 - 명사(method)\nsize가 다르기 때문에 dls 적용이 되지 않아 resize로 조정을 해주었다.\n\npath\n\nPath('/home/csy/.fastai/data/oxford-iiit-pet/images')\n\n\n\ndls = ImageDataLoaders.from_name_func(path,filenames,f,item_tfms=Resize(224))\n#dls\n\n\ndls.show_batch(max_n=16)\n\n\n\n\n\n\n학습\n\nobject\n\nnoun\n\n\ndata\n채용할 모델의 이름\n평가기준 metric\n\n\nverb\n\n\n학습\n판단\n\n\nysj = cnn_learner(dls,resnet34,metrics=error_rate)\n\n\nysj.fine_tune(1)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.138703\n0.014957\n0.004060\n00:10\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.061359\n0.010080\n0.002706\n00:11\n\n\n\n\n\n\n\n\n기존 데이터를 잘 맞추는지 확인\n\nfilenames[0]\n\nPath('/home/csy/.fastai/data/oxford-iiit-pet/images/Bombay_13.jpg')\n\n\n\nysj.predict(PILImage.create(filenames[0]))\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 3.5260e-07]))\n\n\n\nysj.predict(filenames[0])\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 3.5260e-07]))\n\n\n\nfilenames[1]\n\nPath('/home/csy/.fastai/data/oxford-iiit-pet/images/beagle_193.jpg')\n\n\n\nysj.predict(filenames[1])\n\n\n\n\n('dog', TensorBase(1), TensorBase([2.0373e-04, 9.9980e-01]))\n\n\n\nysj.show_results()\n\n\n\n\n\n\n\n\n\n오답분석\n\nchecker = Interpretation.from_learner(ysj)\n\n\n\n\n\nchecker.plot_top_losses(k=16)\n\n\n\n\n\n\n좋은 모델인가?\n\nPILImage.create('2022-01-13-cat.jpg')\n\n\n\n\n\nysj.predict(PILImage.create('2022-01-13-cat.jpg'))\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 3.8330e-16]))\n\n\n\nPILImage.create(requests.get('https://dimg.donga.com/ugc/CDB/SHINDONGA/Article/5e/0d/9f/01/5e0d9f011a9ad2738de6.jpg').content)\n\n\n\n\n\nimg=PILImage.create(requests.get('https://dimg.donga.com/ugc/CDB/SHINDONGA/Article/5e/0d/9f/01/5e0d9f011a9ad2738de6.jpg').content)\nysj.predict(img)\n\n\n\n\n('dog', TensorBase(1), TensorBase([2.1535e-06, 1.0000e+00]))\n\n\n\nimg=PILImage.create(requests.get('https://github.com/guebin/STML2022/blob/master/_notebooks/2022-09-06-cat1.png?raw=true').content)\nysj.predict(img)\n\n\n\n\n('cat', TensorBase(0), TensorBase([9.9982e-01, 1.8307e-04]))\n\n\n\nimg=PILImage.create(requests.get('https://github.com/guebin/STML2022/blob/master/_notebooks/2022-09-06-cat2.jpeg?raw=true').content)\nysj.predict(img)\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 2.0889e-07]))\n\n\n\nimg=PILImage.create(requests.get('https://github.com/guebin/STML2022/blob/master/_notebooks/2022-09-06-hani01.jpeg?raw=true').content)\nysj.predict(img)\n\n\n\n\n('dog', TensorBase(1), TensorBase([9.5189e-06, 9.9999e-01]))\n\n\n\nimg=PILImage.create(requests.get('https://github.com/guebin/STML2022/blob/master/_notebooks/2022-09-06-hani02.jpeg?raw=true').content)\nysj.predict(img)\n\n\n\n\n('dog', TensorBase(1), TensorBase([2.0720e-05, 9.9998e-01]))\n\n\n\nimg=PILImage.create(requests.get('https://github.com/guebin/STML2022/blob/master/_notebooks/2022-09-06-hani03.jpg?raw=true').content)\nysj.predict(img)\n\n\n\n\n('dog', TensorBase(1), TensorBase([0.0513, 0.9487]))\n\n\n\n\n\nhomework\n\n임의의 사진으로 잘 맞추는지 확인\n\n\nPILImage.create('2022-09-07-dogs.jpeg')\n\n\n\n\n\nysj.predict(PILImage.create('2022-09-07-dogs.jpeg'))\n\n\n\n\n('dog', TensorBase(1), TensorBase([2.7947e-04, 9.9972e-01]))\n\n\n\nimg2=PILImage.create('2022-09-07-dogs.jpeg')\nysj.predict(img2)\n\n\n\n\n('dog', TensorBase(1), TensorBase([2.7947e-04, 9.9972e-01]))\n\n\n\nPILImage.create(requests.get('https://media.npr.org/assets/img/2021/08/11/gettyimages-1279899488_wide-f3860ceb0ef19643c335cb34df3fa1de166e2761-s900-c85.webp').content)\n\n\n\n\n\nimg=PILImage.create(requests.get('https://media.npr.org/assets/img/2021/08/11/gettyimages-1279899488_wide-f3860ceb0ef19643c335cb34df3fa1de166e2761-s900-c85.webp').content)\nysj.predict(img)\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 2.5169e-10]))"
  },
  {
    "objectID": "posts/ap/index.html",
    "href": "posts/ap/index.html",
    "title": "Advanced Probability Theory",
    "section": "",
    "text": "Advanced Probability Theory\n마코프 체인(기본: finite한 공간에 있다.)\n\nP로 수렵\n행값이 같음"
  },
  {
    "objectID": "posts/ap/2023-06-01-14wk-1.html",
    "href": "posts/ap/2023-06-01-14wk-1.html",
    "title": "14wk-1,2: MCMC (2)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-zN7idmV8iVcOs4zV2Lg8WE\n\n\n이 강의는 14wk-1, 14wk-2 의 강의가 합쳐져 있습니다."
  },
  {
    "objectID": "posts/ap/2023-06-01-14wk-1.html#샘플추천x-이산형",
    "href": "posts/ap/2023-06-01-14wk-1.html#샘플추천x-이산형",
    "title": "14wk-1,2: MCMC (2)",
    "section": "샘플추천X & 이산형",
    "text": "샘플추천X & 이산형\n- 모티브: 위의 예제에서 전이행렬이 꼭 아래와 같을 필요는 없는것 아닌가?\n\nP\n\narray([[0.4, 0.6],\n       [0.9, 0.1]])\n\n\n- 우리의 목표: 아래와 같은 분포 \\({\\boldsymbol \\pi}\\)를 따르는 확률변수 \\(X\\)를 생성하기만 하면 되는 것 아닌가?\n\n\n\n\\(X\\)\n\\(0\\)\n\\(1\\)\n\n\n\n\n\\(\\mathbb{P}(X=k)\\)\n\\(0.6\\)\n\\(0.4\\)\n\n\n\n이러한 정상분포를 가지는 에르고딕 마코프체인의 전이행렬 \\({\\bf P}\\)를 역으로 설계해보자.\n\nP = np.array([[0.6,0.4],\n              [0.6,0.4]])\n\n\nP\n\narray([[0.6, 0.4],\n       [0.6, 0.4]])\n\n\n- DBC 체크: 아래의 detailed balance condition을 만족하기만 하면 target distribution \\({\\boldsymbol \\pi}\\)는 새롭게 설계한 \\({\\bf P}\\)를 가지는 HMC \\(\\{X_t\\}\\)의 정상분포라 주장할 수 있다.\n\\[\\forall i,j \\in E:~ \\pi_ip_{ij}=\\pi_jp_{ji}\\]\n이 예제의 경우\n\\[\\forall i,j \\in E:~ \\pi_i\\pi_{j}=\\pi_j\\pi_{i}\\]\n가 되므로 성립한다.\n- 따라서 전이행렬 \\({\\bf P}\\)를 가지는 마코프체인은 \\({\\boldsymbol \\pi}^\\top=[0.4,0.6]\\)를 정상분포로 가지는 마코프체인이다.7 이 마코프체인은 IRR 이므로 정상분포 \\({\\boldsymbol \\pi}\\)는 유일한 정상분포가 되고, 따라서 PR조건이 만족된다. 또한 AP를 만족하므로 에르고딕 마코프체인이 된다.\n\nP\n\narray([[0.6, 0.4],\n       [0.6, 0.4]])\n\n\n\ndef doctor_strange(x0):\n    xx = [x0]\n    for t in range(10500): \n        _u = np.random.rand()\n        if _u &lt; 0.4:\n            xx.append(1)\n        else:\n            xx.append(0)\n    return xx \n\n\nxx = doctor_strange(0)\n\n\nplt.hist(xx[501:],bins=100);\n\n\n\n\n- 이러한 방식은 유한차원으로 확장가능하다. (그런데 귀찮다)\n\n\n\n\\(X\\)\n\\(0\\)\n\\(1\\)\n\\(2\\)\n\n\n\n\n\\(\\mathbb{P}(X=k)\\)\n\\(0.6\\)\n\\(0.2\\)\n\\(0.2\\)\n\n\n\n\nP = np.array([[0.6,0.2,0.2],\n              [0.6,0.2,0.2],\n              [0.6,0.2,0.2]])\n\n\ndef doctor_strange(x0):\n    xx = [x0]\n    for t in range(10500): \n        _u = np.random.rand()\n        if _u &lt; 0.6:\n            xx.append(0)\n        elif _u&lt; 0.8:\n            xx.append(1)\n        else:\n            xx.append(2)        \n    return xx \n\n\nxx = doctor_strange(0)\n\n\nplt.hist(xx[501:],bins=100);"
  },
  {
    "objectID": "posts/ap/2023-06-01-14wk-1.html#샘플추천-이산형",
    "href": "posts/ap/2023-06-01-14wk-1.html#샘플추천-이산형",
    "title": "14wk-1,2: MCMC (2)",
    "section": "샘플추천 & 이산형",
    "text": "샘플추천 & 이산형\n- 아래의 분포를 고려하자.\n\nnp.random.seed(43052)\nu = np.random.rand(10)\nπ = (u/u.sum()).reshape(-1,1)\nπ.T\n\narray([[0.12977311, 0.00786117, 0.13310662, 0.09836388, 0.01944822,\n        0.01858917, 0.13959302, 0.15544153, 0.14440391, 0.15341937]])\n\n\n\nplt.stem(π)\n\n&lt;StemContainer object of 3 artists&gt;\n\n\n\n\n\n- 이러한 분포에서 샘플을 뽑는 상황을 고려하자.\n\n위의 코드로는 못하겠다.\n다른 방법은 없을까?\n\n\n그냥 저번시간처럼 하자. \\(x\\)에서 \\(x'\\)으로 가는 확률을 다 정의하지 말고, \\(x'\\)를 적당히 추천받고 옮겨탈지 말지 결정하자.\n\n- 저번시간 테크닉: \\(X(\\omega_1)=x\\)가 주어졌을때 \\(X'(\\omega_1)=x'\\)를 뽑는 방법!\n\n\\(x\\)가 주어졌다고 가정하자.\n\\(x'\\)의 후보로 \\(Y(\\omega^\\ast)=y\\)를 뽑는다. \\(Y \\sim {\\boldsymbol p}_Y:=[\\frac{1}{10},\\dots,\\frac{1}{10}]\\)\n\\(x'\\)은 \\(x\\)가 적절한지, 아니면 추천받은 \\(y\\)가 적절한지 따져보고 결정한다. 즉 아래의 확률로 \\(x'=y\\)를 선택한다.\n\n\\[\\frac{\\pi_y}{\\pi_x + \\pi_y}\\]\n- 의문: 저렇게 막 만들어도 에르고딕한지 어떻게 알지?\n\n당연히 몰라요.\n조사를 좀 해봐야 합니다.\n\n- DBC condition 체크\n\\[\\forall i,j \\in E:~ \\pi_ip_{ij}=\\pi_jp_{ji}\\]\n노테이션을 살짝 변경하면 아래와 같다.\n\\[\\forall x,x' \\in E:~ \\pi_xp_{xx'}=\\pi_{x'}p_{x'x}\\]\n여기에서 \\(p_{xx'}\\)와 \\(p_{x'x}\\)를 각각 구하면 아래와 같다.\n\\[p_{xx'} = \\frac{1}{10}\\frac{\\pi_{x'}}{\\pi_x + \\pi_{x'}}\\]\n\\[p_{x'x} = \\frac{1}{10}\\frac{\\pi_{x}}{\\pi_x + \\pi_{x'}}\\]\n따라서 DBC가 성립한다.\n- 이론전개: DBC가 만족되었으므로 \\({\\boldsymbol \\pi}\\)는 정상분포가 된다. 그리고 이 마코프체인은 IRR 이므로 정상분포는 유일해진다. 또한 IRR-HMC에서는 유일한 정상분포의 존재와 PR이 동치이므로 이 마코프체인은 PR이 된다. 또한 이 마코프체인은 AP조건을 만족한다. 따라서 이 마코프체인은 에르고딕이 된다.\n\ndef doctor_strange(x0):\n    xx = [x0]\n    for t in range(100500): \n        y = np.random.choice(range(10))\n        acceptance_prob = π[y]/(π[xx[t]]+π[y]) ## acceptance_prob 가 클수록 y가 선택\n        _u = np.random.rand()\n        if _u &lt; acceptance_prob:\n            xx.append(y)\n        else:\n            xx.append(xx[t])\n    return xx \n\n\nxx = doctor_strange(0)\n\n\nplt.stem(π*100000)\nplt.hist(xx[501:],bins=100,color='C1',alpha=0.8);\n\n\n\n\n참고\n### 비교를 위해 이전에 만들었던 코드를 확인해보자.\nT = 100000\nxx = [0.99]\nfor t in range(T):\n    y = np.random.rand()\n    thresh_prob = f(y)/(f(xx[t])+f(y)) ## thresh_prob 가 클수록 y가 선택\n    _u = np.random.rand()\n    if _u &lt; thresh_prob:\n        xx.append(y) \n    else:\n        xx.append(xx[t])"
  },
  {
    "objectID": "posts/ap/2023-06-01-14wk-1.html#샘플추천-연속형",
    "href": "posts/ap/2023-06-01-14wk-1.html#샘플추천-연속형",
    "title": "14wk-1,2: MCMC (2)",
    "section": "샘플추천 & 연속형",
    "text": "샘플추천 & 연속형\n- 아래와 같은 pdf \\(f_X(x)\\)를 가지는 확률변수를 만들고 싶다면?\n\ng = scipy.special.gamma\n\n\ndef f(x): \n    return g(2+6)/(g(2)*g(6)) * x**(2-1) * (1-x)**(6-1)\n\n\n_x = np.linspace(0,1,1000)\nplt.plot(_x, f(_x))\n\n\n\n\n- 어? 잠깐만..\n\n이전예제: \\(E= \\{0,1,2,3,4,5,6,7,8,9\\}\\)\n지금예제: \\(E= [0,1]\\)\n\n상태공간 \\(E\\) coutable 이 아니잖아? (그래도 일단 진행해보자)\n- 테크닉: \\(X(\\omega_1)=x\\)가 주어졌을때 \\(X'(\\omega_1)=x'\\)를 뽑는 방법!\n\n\\(x\\)가 주어졌다고 가정하자.\n\\(x'\\)의 후보로 \\(Y(\\omega^\\ast)=y\\)를 뽑는다. \\(Y \\sim {\\cal U}\\)\n\\(x'\\)은 \\(x\\)가 적절한지, 아니면 추천받은 \\(y\\)가 적절한지 따져보고 결정한다. 즉 아래의 확률로 \\(x'=y\\)를 선택한다.\n\n\\[\\frac{f_X(y)}{f_X(x) + f_X(y)}\\]\n- DBC condition 체크\n이전예제\n\\[\\forall x,x' \\in E:~ \\pi_xp_{xx'}=\\pi_{x'}p_{x'x}\\]\n지금예제\n\\[\\forall x,x' \\in E:~ f_X(x)p_{xx'}=f_X(x')p_{x'x}\\]\n여기에서 \\(p_{xx'}\\)와 \\(p_{x'x}\\)는 대충 아래와 같이 쓸 수 있을것 같다.\n\\[p_{xx'} = f_Y(x')\\frac{f_X(x')}{f_X(x) + f_X(x')}\\]\n\\[p_{x'x} = f_Y(x)\\frac{f_X(x)}{f_X(x) + f_X(x')}\\]\n우선 \\(f_Y(x')=f_Y(x)=1\\) 이므로 지금까지의 논의가 맞다면 DBC는 만족된다.\n- 의문1: 좀 이상한데? \\(f_X(x)\\)는 \\(\\pi_x\\)와 다르게 확률을 의미하는게 아니잖아?\n- 의문2: 애초에 HMC \\(\\{X_t\\}\\)를 coutable한 state space를 가진다고 정의하지 않았어?"
  },
  {
    "objectID": "posts/ap/2023-04-18-ap-07wk.html",
    "href": "posts/ap/2023-04-18-ap-07wk.html",
    "title": "7wk: 측도론 (3)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-yQ5IXoRW0pW0Gyd8MnRwaW"
  },
  {
    "objectID": "posts/ap/2023-04-18-ap-07wk.html#헷갈리는-표현-infty의-포함",
    "href": "posts/ap/2023-04-18-ap-07wk.html#헷갈리는-표현-infty의-포함",
    "title": "7wk: 측도론 (3)",
    "section": "헷갈리는 표현: \\(\\infty\\)의 포함",
    "text": "헷갈리는 표현: \\(\\infty\\)의 포함\n- 자연수집합 \\(\\mathbb{N}\\)은 \\(\\{\\infty\\}\\)를 포함하지 않는다. 마찬가지로 실수집합 \\(\\mathbb{R}\\) 역시 \\(\\{-\\infty\\}, \\{\\infty\\}\\)를 포함하지 않는다. 만약에 이를 포함하고 싶을 경우는 아래와 같이 표현한다.\n\n\\(\\mathbb{R} \\cup \\{-\\infty\\} \\cup \\{\\infty\\} = \\bar{\\mathbb{R}}\\)\n\\(\\mathbb{N} \\cup \\{-\\infty\\}\\)\n\n여기에서 \\(\\bar{\\mathbb{R}}\\)은 확장된 실수라고 부르는데 교재에따라 사용하기도 하고 사용하지 않기도 한다.\n- 만약에 \\(\\mathbb{N}\\)이 \\(\\{\\infty\\}\\)를 포함한다면\n\n\\(\\forall n \\in \\mathbb{N}:~ 0&lt;\\frac{1}{n} \\leq 1\\)\n\n와 같은 표현은 불가능할 것이다.\n- 구간에 대한 표현들: 구간에 대한 몇가지 표현을 정리하면 아래와 같다.\n\n\\((-\\infty, b] = \\{x: x\\leq b, ~x,b \\in \\mathbb{R}\\}\\)\n\\((-\\infty, b) = \\{x: x &lt; b,~ x,b \\in \\mathbb{R}\\}\\)\n\n- 구긴에 대한 표현 응용: 아래와 같은 표현을 고려하자. (교재의 예제 1.1.8과 비슷한 표현)\n\n\\({\\cal A} = \\{(a,b]: -\\infty \\leq a &lt; b \\leq \\infty\\}\\)\n\n\\({\\cal A}\\)의 원소의 형태는\n\n\\(\\{x: a&lt;x\\leq b,~ a,x,b \\in \\mathbb{R}\\}\\)\n\\(\\{x: a&lt;x,~ a,x \\in \\mathbb{R}\\}\\)\n\\(\\{x: x\\leq b,~ x,b \\in \\mathbb{R}\\}\\)\n\\(\\{x: x \\in \\mathbb{R}\\}\\)\n\n이다.\n\n약간 무식하게 생각하면 \\([-\\infty, b) = (-\\infty,b)\\) 로 해석하면 된다. 즉 \\(\\{-\\infty\\} \\notin [-\\infty,b)\\) 이라는 의미! 보는것 처럼 \\([-\\infty, b)\\)와 같은 표현은 엄청난 혼란을 불러오는 표현이므로 사용을 자제한다."
  },
  {
    "objectID": "posts/ap/2023-04-18-ap-07wk.html#메져의-종류와-성질",
    "href": "posts/ap/2023-04-18-ap-07wk.html#메져의-종류와-성질",
    "title": "7wk: 측도론 (3)",
    "section": "메져의 종류와 성질",
    "text": "메져의 종류와 성질\n- 메져의 종류와 성질 요약\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n분류\n\\(m(\\emptyset)=0\\)\n\\(\\sigma\\)-add\n\\(A_i\\uparrow \\Omega\\), \\(m(A_i)&lt;\\infty\\)\n\\(m(\\Omega)&lt;\\infty\\)\n\\(m(\\Omega)=1\\)\n\\(.\\)\nmonotone\n\\(\\sigma\\)-subadd\nconti-below\nconti-above\n\n\n\n\nmsr\n\\(O\\)\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(.\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(\\Delta\\)\n\n\n\\(\\sigma\\)-finite-msr\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(.\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(\\Delta\\)\n\n\nfinite-msr\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(X\\)\n\\(.\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\n\nprob-msr\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(.\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\n\n\n- 용어들\n\n\\(\\sigma\\)-additive: \\(m(\\uplus_{i=1}^{\\infty} B_i) = \\sum_{i=1}^{\\infty} m(B_i)\\)\nmonotone: \\(A\\subset B \\Rightarrow m(A) \\subset m(B)\\)\n\\(\\sigma\\)-subadditive: \\(m(\\cup_{i=1}^{\\infty} A_i) \\leq \\sum_{i=1}^{\\infty} m(A_i)\\)\ncontinuous from below: \\(A_i \\uparrow A\\) \\(\\Rightarrow\\) \\(m(\\lim_{n\\to\\infty}A_i)=\\lim_{n\\to\\infty}m(A_i)\\)\ncontinuous from above: (1) \\(A_i \\downarrow A\\) and (2) \\(m(A_1)&lt;\\infty\\) \\(\\Rightarrow\\) \\(m(\\lim_{n\\to\\infty}A_i)=\\lim_{n\\to\\infty}m(A_i)\\)\n\n- 교재의 언급 (p2. Thm 1.1.1)\n\n\n\n그림1: 메져의 성질 durret p2\n\n\n- \\(\\sigma\\)-finite msr 에 대한 동치조건: \\(m\\)이 \\((\\Omega, {\\cal F})\\)에서의 msr이라면, 아래는 동치이다. (ref: https://en.wikipedia.org/wiki/%CE%A3-finite_measure)\n언어버전\n\nThe set \\(\\Omega\\) can be covered with at most countably many measurable sets with finite measure.\nThe set \\(\\Omega\\) can be covered with at most countably many measurable disjoint sets with finite measure.\nThe set \\(\\Omega\\) can be covered with monotone sequence of measurable sets with finite measure.\n\n수식버전\n\nThere are sets \\(A_1,A_2,\\dots \\in {\\cal A}\\) with \\(m(A_i)&lt;\\infty\\) such that \\(\\cup_{i=1}^{\\infty}A_i=\\Omega\\)\nThere are sets \\(B_1,B_2,\\dots \\in {\\cal A}\\) with \\(m(B_i)&lt;\\infty\\) and \\(B_1,B_2\\dots\\) are disjoints such that \\(\\uplus_{i=1}^{\\infty}B_i=\\Omega\\)\nThere are sets \\(C_1,C_2,\\dots \\in {\\cal A}\\) with \\(m(C_i)&lt;\\infty\\) and $C_1 C_2 $ such that \\(\\cup_{i=1}^{\\infty}C_i=\\Omega\\)"
  },
  {
    "objectID": "posts/ap/2023-04-18-ap-07wk.html#복습-motivating-ex",
    "href": "posts/ap/2023-04-18-ap-07wk.html#복습-motivating-ex",
    "title": "7wk: 측도론 (3)",
    "section": "복습 & Motivating EX",
    "text": "복습 & Motivating EX\n- 귀찮아서 만든 이론2: 운이 좋다면, \\({\\cal A}\\) 에서 확률의 공리를 만족하는 적당한 함수 \\(\\tilde{P}:{\\cal A} \\to [0,1]\\)를 \\((\\Omega, \\sigma({\\cal A}))\\) 에서의 확률측도 \\(P\\)로 업그레이드 할 수 있으며 업그레이드 결과는 유일하다.\n- 이론: \\((\\Omega, \\sigma({\\cal A}), P)\\)를 확률공간이라고 하자. 여기에서 \\({\\cal A}\\)는 파이시스템이라고 가정하자. 그렇다면 확률측도 \\(P:\\sigma({\\cal A}) \\to [0,1]\\)의 값은 \\(P: {\\cal A} \\to [0,1]\\)의 값에 의하여 유일하게 결정된다.\n- 이 이론은 확률측도일 경우만 성립하고 측도일 경우는 실패했었다.\n(예제1) – 통계학과라서 행복했던 예제\n\\(\\Omega=\\{a,b\\}\\) 이라고 하고 \\({\\cal A} = \\{\\{a\\}\\}\\) 라고 하자. 가측공간 \\((\\Omega,\\sigma({\\cal A}))\\)에서 정의가능한 모든 확률측도 \\(P\\)는 \\({\\cal A}\\)에서의 값으로 유일하게 결정됨을 확인하였다. 하지만 가측공간 \\((\\Omega,\\sigma({\\cal A}))\\)에서 정의가능한 측도 \\(m\\)은 \\({\\cal A}\\)에서의 값으로 유일하게 결정되지 않는다.\n\n\n\n\n\\(m_1\\)\n\\(m_2\\)\n\n\n\n\n\\(\\{a\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{b\\}\\)\n\\(\\frac{1}{2}\\)\n\\(1\\)\n\n\n\\(\\Omega\\)\n\\(1\\)\n\\(\\frac{3}{2}\\)\n\n\n\n- 직관: 그냥 \\({\\cal A}\\)에 \\(\\Omega\\)가 있었다면 되는거 아닌가? 예를들어 아래와 같이 설정한다면?\n\n\n\n\n\\(m_1\\)\n\\(m_2\\)\n\n\n\n\n\\(\\{a\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\Omega\\)\n\\(\\frac{3}{2}\\)\n\\(\\frac{3}{2}\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{b\\}\\)\n\\(1\\)\n\\(1\\)\n\n\n\n\\(m_1(\\{b\\})=m_2(\\{b\\})=1\\) 일 수밖에 없지 않을까?\n- 혹시 아래와 같이 이론을 수정하면 되지 않을까?\n\n\\((\\Omega, \\sigma({\\cal A}))\\)을 잴 수 있는 공간이라고 하고, \\(m\\)을 이 공간에서의 메져라고 하자. 만약에 \\({\\cal A}\\)가 “전체집합을 포함하는 파이시스템” 이라면 메져 \\(m:\\sigma({\\cal A}) \\to [0,1]\\)의 값은 \\(m: {\\cal A} \\to [0,1]\\)의 값에 의하여 유일하게 결정된다. (거의 맞는데 한 조건이 빠져서 틀렸음)\n\n(예제2)\n\\(\\Omega=\\{a,b,c\\}\\) 이라고 하고 \\({\\cal A} = \\{\\{a\\},\\Omega\\}\\) 라고 하자. 여기에서 \\({\\cal A}\\)는 “\\(\\Omega\\)가 포함된 파이시스템”이다. 가측공간 \\((\\Omega,\\sigma({\\cal A}))\\)에서 정의가능한측도 \\(m\\)은 \\({\\cal A}\\)에서의 값으로 유일하게 결정될까?\n(풀이) 아래의 반례가 존재함.\n\n\n\n\n\\(m_1\\)\n\\(m_2\\)\n\n\n\n\n\\(\\{a\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\Omega\\)\n\\(\\infty\\)\n\\(\\infty\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{b\\}\\)\n\\(1\\)\n\\(\\infty\\)\n\n\n\\(\\{c\\}\\)\n\\(\\infty\\)\n\\(5\\)\n\n\n\\(\\{a,b\\}\\)\n\\(\\frac{3}{2}\\)\n\\(\\infty\\)\n\n\n\\(\\{a,c\\}\\)\n\\(\\infty\\)\n\\(\\frac{11}{2}\\)\n\n\n\\(\\{b,c\\}\\)\n\\(\\infty\\)\n\\(\\infty\\)\n\n\n\n- 이론: \\((\\Omega, \\sigma({\\cal A}))\\)을 잴 수 있는 공간이라고 하고, \\(m\\)을 이 공간에서의 유한측도라고 하자. 그리고 \\({\\cal A}\\)는 전제집합을 포함하는 파이시스템이라고 하자. 그렇다면 메져 \\(m:\\sigma({\\cal A}) \\to [0,M]\\)의 값은 \\(m: {\\cal A} \\to [0,M]\\)의 값에 의하여 유일하게 결정된다. (단, \\(M=m(\\Omega)&lt;\\infty\\))\n(예제3) – \\({\\cal A}\\)가 \\(\\Omega\\)를 포함하지 않는데, 메져가 유일하게 결정될 것 같은 예제\n\\(\\Omega = \\mathbb{Z}\\) 이라고 하자. \\(\\Omega\\)의 부분집합들로 이루어진 수열 \\(A_1,A_2,\\dots\\) 를 아래와 같이 정의하자.\n\n\\(A_{1} = [-\\frac{1}{2}, \\frac{2}{2}] \\cap \\mathbb{Z} = \\{0, 1\\}\\)\n\\(A_{2} = [-\\frac{2}{2}, \\frac{3}{2}] \\cap \\mathbb{Z} = \\{-1, 0, 1\\}\\)\n\\(A_{3} = [-\\frac{3}{2}, \\frac{4}{2}] \\cap \\mathbb{Z} = \\{-1, 0, 1, 2\\}\\)\n\\(A_{4} = [-\\frac{4}{2}, \\frac{5}{2}] \\cap \\mathbb{Z} = \\{-2, -1, 0, 1, 2\\}\\)\n\\(A_{5} = [-\\frac{5}{2}, \\frac{6}{2}] \\cap \\mathbb{Z} = \\{-2, -1, 0, 1, 2, 3\\}\\)\n\\(\\dots\\)\n\n관심있는 집합들의 모임은 \\({\\cal A}=\\{A_n:n \\in \\mathbb{N}\\}\\)로 정의하자. 가측공간 \\((\\Omega,\\sigma({\\cal A}))\\)에서 정의가능한 측도 \\(m\\)은 \\({\\cal A}\\)의 값으로 유일하게 결정될까?\n(관찰)\n풀이에 앞서서 아래의 사실을 관찰해보자.\n\n\\({\\cal A}\\)는 파이시스템이다.\n집합열 \\(A_n\\)의 극한은 \\(\\Omega\\)이다. 집합열 \\(A_n\\)은 증가하는 수열이므로 이 경우 \\(A_n \\uparrow \\Omega\\)라고 표현할 수 있다.\n모든 \\(A_n\\)이 \\({\\cal A}\\)의 멤버라고 했으나 \\(A_n\\)의 극한 \\(\\Omega\\)가 \\({\\cal A}\\)의 멤버라고 한 적은 없다. 따라서 \\({\\cal A}\\)는 전체집합을 포함하지는 않는 파이시스템이다.\n\n(풀이)\n가측공간 \\((\\Omega,\\sigma({\\cal A}))\\)에서 정의가능한 측도 \\(m\\)은 \\({\\cal A}\\)의 값으로 유일하게 결정하는 것이 가능할 것 같다. (실제로 가능해) 왜냐하면\n\n\\(m(A_1),m(A_2), m(A_3) \\dots\\) 의 값이 결정 \\(\\Rightarrow\\) \\(m(\\{0,1\\})\\), \\(m(\\{-1\\})\\), \\(m(\\{2\\})\\), \\(\\dots\\) 의 값이 결정\n\n이므로, 0과 1을 제외한 \\(\\mathbb{Z}\\)의 모든 원소의 길이가 유일하게 결정되니까.\n생각의 시간\n아래의 이론을 다시 관찰하자.\n\n이론: \\((\\Omega, \\sigma({\\cal A}))\\)을 잴 수 있는 공간이라고 하고, \\(m\\)을 이 공간에서의 유한측도라고 하자. 그리고 \\({\\cal A}\\)는 전제집합을 포함하는 파이시스템이라고 하자. 그렇다면 메져 \\(m:\\sigma({\\cal A}) \\to [0,M]\\)의 값은 \\(m: {\\cal A} \\to [0,M]\\)의 값에 의하여 유일하게 결정된다. (단, \\(M=m(\\Omega)&lt;\\infty\\))\n\n(의문1)\n\\({\\cal A}\\)가 꼭 전체집합을 포함할 필요는 없어보인다. 즉 조건 \\(\\Omega \\in {\\cal A}\\)는 굳이 필요 없어보인다. 이 조건은 더 약한 아래의 조건으로 대치가능하다.\n\n\\(\\exists A_1,A_2,\\dots \\in {\\cal A}\\) such that \\(A_i \\uparrow \\Omega\\)\n\n만약에 \\(\\Omega \\in {\\cal A}\\)인 경우는 \\(A_1=\\Omega\\)로 잡으면 위 조건이 그냥 성립한다. 따라서 위의 조건은 \\(\\Omega \\in {\\cal A}\\) 보다 약한 조건이다. 그리고 심지어 위의 조건은 다시 아래의 더 약한 조건으로 바꿀 수 있다.\n\n\\(\\exists A_1,A_2,\\dots \\in {\\cal A}\\) such that \\(\\cup_{i=1}^{\\infty} A_i = \\Omega\\)\n\n(의문2)\n심지어 \\(m(\\Omega) = \\infty\\) 이어도 상관없다.1 이 예제에서\n\n\\(m(\\{0,1\\})=2\\)\n\\(m(\\{-1\\})=1\\)\n\\(m(\\{2\\})=1\\)\n\\(\\dots\\)\n\n이라고 하면 \\(m\\)은 잴 수 있는 공간 \\((\\Omega,\\sigma({\\cal A}))\\)에서의 카운팅메져가 되고, 그 \\(m\\)은 \\(A \\in {\\cal A}\\)에서의 값으로 유일하게 결정된다. 문제가 생길만한 것은\n\n\\(m(\\{0,1\\})=2\\)\n\\(m(\\{-1\\})=1\\)\n\\(m(\\{2\\})=\\infty\\) &lt;– 이러면 곤란\n\\(\\dots\\)\n\n와 같은 경우이므로, 이 경우만 제약하면 된다. 즉 \\(m\\)이 시그마유한측도라고 제한하면 될 것 같다."
  },
  {
    "objectID": "posts/ap/2023-04-18-ap-07wk.html#state",
    "href": "posts/ap/2023-04-18-ap-07wk.html#state",
    "title": "7wk: 측도론 (3)",
    "section": "state",
    "text": "state\n- Thm: \\((\\Omega, \\sigma({\\cal A}),m)\\)을 시그마유한측도공간(\\(\\sigma\\)-finite measure space)이라고 하자. \\({\\cal A}\\)은 아래를 만족하는 파이시스템이라고 하자.\n\n\\(\\exists A_1,A_2,\\dots \\in {\\cal A}\\) such that \\(\\cup_{i=1}^{\\infty} A_i = \\Omega\\)\n\\(\\forall i \\in \\mathbb{N}:~ m(A_i) &lt;\\infty\\)\n\n그렇다면 메져 \\(m:\\sigma({\\cal A}) \\to [0,\\infty]\\)의 값은 \\(m: {\\cal A} \\to [0,\\infty]\\)의 값에 의하여 유일하게 결정된다.\n\n조건 1,2는 결국 \\(m\\)을 시그마유한측도로 만들어주는 그 집합열이 \\(\\sigma({\\cal A})-{\\cal A}\\)가 아니라 \\({\\cal A}\\)에 있어야 한다는 의미임."
  },
  {
    "objectID": "posts/ap/2023-04-18-ap-07wk.html#증명",
    "href": "posts/ap/2023-04-18-ap-07wk.html#증명",
    "title": "7wk: 측도론 (3)",
    "section": "증명",
    "text": "증명\n- 노트: supp_7wk.pdf\n- 교재의 증명: 교재의 증명은 좀 더 강한 조건에서 했음. (“\\(A_1,A_2,\\dots, {\\cal A}\\) with \\(m(A_i)&lt;\\infty\\) such that \\(A_i \\uparrow \\Omega\\)” 를 가정함.)\n\n\n\n그림2: 카라데오도리 확장정리의 유일성 part 증명, durret p457-8"
  },
  {
    "objectID": "posts/ap/2023-04-18-ap-07wk.html#state-1",
    "href": "posts/ap/2023-04-18-ap-07wk.html#state-1",
    "title": "7wk: 측도론 (3)",
    "section": "state",
    "text": "state\n- Thm: \\({\\cal A}\\)가 \\(\\Omega\\)에 대한 semiring이라고 하자. 함수 \\(\\tilde{m}: {\\cal A} \\to [0,\\infty]\\)가\n\n\\(\\tilde{m}(\\emptyset)=0\\)\n\\(\\tilde{m}(\\uplus_{i=1}^{n} B_i)=\\sum_{i=1}^{n}\\tilde{m}(B_i)\\)\n\\(\\tilde{m}(\\cup_{i=1}^{\\infty} A_i) \\leq \\sum_{i=1}^{\\infty}\\tilde{m}(A_i)\\)\n\\(\\exists A_1,A_2 \\dots \\in {\\cal A}\\) with \\(m(A_i)&lt;\\infty\\) such that \\(\\cup_{i=1}^{\\infty}A_i = \\Omega\\)\n\n를 만족한다면 \\(\\tilde{m}\\)은 \\((\\Omega,\\sigma({\\cal A})\\)에서의 측도 \\(m\\)으로 업그레이드 가능하며, 이 업그레이드 결과는 유일하다.\n\n이 결과를 ver1로 생각하자.\n\n- 교재의 state (ver2, ver3)\n\n\n\n그림3: 카라데오도리 확장저정리 ver2, durret p456\n\n\n\nver1과의 비교: \\({\\cal A}\\)가 알지브라라는 것은 세미링보다 훨씬 강한 조건이다. 또한 measure on an algebra \\({\\cal A}\\)란 것은 1,2,3 조건을 다 합친것 보다 강한 조건이다. \\(\\sigma\\)-finite이라는 조건은 \\({\\cal A}\\)의 차이를 제외하면 동일하다.\n\n\n\n\n그림4: 카라데오도리 확장정리 ver3, durret p5\n\n\n\nver1과의 비교: \\({\\cal A}\\)가 세미알지브라라는 조건은 세미링보다 강한 조건이다. (i), (ii)의 \\({\\cal A}\\)의 차이만 있을 뿐 거의 동일하다. 4의 조건도 \\({\\cal A}\\)의 차이를 제외하고는 동일하다."
  },
  {
    "objectID": "posts/ap/2023-04-18-ap-07wk.html#예제-3월28일-4wk-예제들",
    "href": "posts/ap/2023-04-18-ap-07wk.html#예제-3월28일-4wk-예제들",
    "title": "7wk: 측도론 (3)",
    "section": "예제: 3월28일 (4wk) 예제들",
    "text": "예제: 3월28일 (4wk) 예제들\n(예제1) – motivating EX\n- \\(\\Omega=\\{1,2,3,4\\}\\)이라고 하자. 내가 관심있는 집합의 모음은 아래와 같다.\n\\[{\\cal A} = \\{\\emptyset, \\{1\\},\\{2\\},\\{3,4\\},\\Omega\\}\\]\n- 소망: 그래도 그냥 \\({\\cal A}\\)에서만 확률 비슷한 함수 \\(\\tilde{P}\\)를 잘 정의하면 \\((\\Omega,\\sigma({\\cal A}))\\)에서의 확률측도로 업그레이드 가능하고 업그레이드 결과가 유일할까?\n\n\\(\\tilde{P}(\\emptyset) = 0\\)\n\\(\\tilde{P}(\\{1\\}) = 1/4\\)\n\\(\\tilde{P}(\\{2\\}) = 1/2\\)\n\\(\\tilde{P}(\\{3,4\\}) = 1/4\\)\n\\(\\tilde{P}(\\Omega) = 1\\)\n\n- 조건체크\n\n\\({\\cal A}\\)는 세미알지브라(그러므로 세미링)이다.\n\\({\\cal A}\\)는 전체집합을 포함하고 있으며 \\({\\tilde P}(\\Omega)=1\\)이다. \\(\\Rightarrow\\) 조건 (4)가 만족.\n\\({\\tilde P}\\)는 (1) \\(\\tilde{P}(\\emptyset)=0\\) 이고 (2) add 를 만족하며 (3) \\(\\sigma\\)-subadd 를 만족한다.\n\n\n참고: 이 예제의 경우 \\(|\\Omega|&lt;\\infty\\) 이므로 \\(\\sigma\\)-subadd 는 subadd 와 같은 성질이다. 그리고 add 는 subadd를 imply 하므로 사실상 (2) 만 체크하면 끝난다.2\n\n(예제2) – motivating EX (2)\n- \\(\\Omega=\\{1,2,3,4\\}\\)이라고 하고 \\({\\cal A} = \\{\\emptyset, \\{1\\},\\{2\\}, \\{3,4\\}, \\Omega\\}\\) 라고 하자. 그리고 아래와 같은 \\(\\sigma({\\cal A})\\)를 다시 상상하자.\n\\[\\sigma({\\cal A}) = \\big\\{\\emptyset, \\{1\\}, \\{2\\}, \\{1,2\\}, \\{3,4\\}, \\{1,3,4\\}, \\{2,3,4\\}, \\Omega \\big\\}\\]\n- 위의 시그마필드에서 확률을 예제1과 다른 방식으로 정의할 수 도 있다. 예를들면 아래와 같은 방식으로 정의가능하다.\n\n\n\n\n\\(P_1\\)\n\\(\\tilde{P}_1\\)\n\n\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{1\\}\\)\n\\(\\frac{1}{3}\\)\n\\(\\frac{1}{3}\\)\n\n\n\\(\\{2\\}\\)\n\\(\\frac{1}{3}\\)\n\\(\\frac{1}{3}\\)\n\n\n\\(\\{3,4\\}\\)\n\\(\\frac{1}{3}\\)\n\\(\\frac{1}{3}\\)\n\n\n\\(\\Omega\\)\n\\(1\\)\n\\(1\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\{1,2\\}\\)\n\\(\\frac{2}{3}\\)\nNone\n\n\n\\(\\{1,3,4\\}\\)\n\\(\\frac{2}{3}\\)\nNone\n\n\n\\(\\{2,3,4\\}\\)\n\\(\\frac{2}{3}\\)\nNone\n\n\n\n또한 아래와 같은 방식도 가능하다.\n\n\n\n\n\\(P_2\\)\n\\(\\tilde{P}_2\\)\n\n\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{1\\}\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{2\\}\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{3,4\\}\\)\n\\(1\\)\n\\(1\\)\n\n\n\\(\\Omega\\)\n\\(1\\)\n\\(1\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\{1,2\\}\\)\n\\(0\\)\nNone\n\n\n\\(\\{1,3,4\\}\\)\n\\(1\\)\nNone\n\n\n\\(\\{2,3,4\\}\\)\n\\(1\\)\nNone\n\n\n\n어떠한 방식으로 정의하든 \\({\\cal A}\\)에서 확률 비슷한 것 \\(\\tilde{P}_1,\\tilde{P}_2\\)를 잘 정의하기만 \\(\\sigma({\\cal A})\\)에서의 확률 \\(P\\)로 적절하게 확장할 수 있다. 심지어 이런 확장은 유일한 듯 하다.\n- 당연함. 예제1과 동일하게 \\(\\tilde{P_1}\\)과 \\(\\tilde{P_2}\\)가 add 성질만 만족한다는 사실을 체크하면 끝난다.\n(예제3) – 운이 안 좋은 경우\n- \\(\\Omega=\\{1,2,3\\}\\) 이라고 하고 \\({\\cal A} = \\{\\emptyset, \\{1,2\\},\\{2,3\\}, \\Omega\\}\\) 라고 하자.\n- 아래와 같은 확률 비슷한 함수 \\(\\tilde{P}:{\\cal A} \\to [0,1]\\)를 정의하자.\n\n\\(\\tilde{P}(\\emptyset) = 0\\)\n\\(\\tilde{P}(\\{1,2\\}) = 0\\)\n\\(\\tilde{P}(\\{2,3\\}) = 0\\)\n\\(\\tilde{P}(\\Omega) = 1\\)\n\n- 체크: 일단 \\({\\cal A}\\)는 세미링이 아니다. 따라서 확장 불가능. 세미링이 맞다고 하여도 subadd가 성립하지 않는다.\n(예제4) – 운이 안 좋은 경우\n- \\(\\Omega=\\{1,2,3,4\\}\\) 이라고 하고 \\({\\cal A} = \\{\\emptyset, \\{1,2\\},\\{2,3\\}, \\Omega\\}\\) 라고 하자.\n- 아래와 같은 확률 비슷한 함수 \\(\\tilde{P}:{\\cal A} \\to [0,1]\\)를 정의하자.\n\n\\(\\tilde{P}(\\emptyset) = 0\\)\n\\(\\tilde{P}(\\{1,2\\}) = 1/2\\)\n\\(\\tilde{P}(\\{2,3\\}) = 1/2\\)\n\\(\\tilde{P}(\\Omega) = 1\\)\n\n- 체크: \\(\\tilde{P}\\)는 괜찮게 정의되었다. (1)-(4)가 모두 성립한다. (위의 예제와는 다르게 subadd 역시 성립함!!) 하지만 \\({\\cal A}\\)가 세미링이 아니어서 탈락."
  },
  {
    "objectID": "posts/ap/2023-05-02-ap-09wk.html",
    "href": "posts/ap/2023-05-02-ap-09wk.html",
    "title": "09wk: 확률변수",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-yGgU_c-5m38ONMFujHvYLf"
  },
  {
    "objectID": "posts/ap/2023-05-02-ap-09wk.html#확률공간과-용어들",
    "href": "posts/ap/2023-05-02-ap-09wk.html#확률공간과-용어들",
    "title": "09wk: 확률변수",
    "section": "확률공간과 용어들",
    "text": "확률공간과 용어들\n- 동전예제에서의 확률공간 \\((\\Omega,{\\cal F},P)\\)를 가정하고 용어를 정리해보자.\n\noutcomes: \\(H\\),\\(T\\)\nset of “outcomes”: \\(\\Omega=\\{H,T\\}\\)\nevent: \\(\\emptyset\\), \\(\\{H\\}\\), \\(\\{T\\}\\), \\(\\{H,T\\}\\)\nset of “events”: \\({\\cal F}\\)\nprobabilites: \\(P:{\\cal F} \\to [0,1]\\)\n\n\n\n\n그림1: 확률을 위한 기본용어"
  },
  {
    "objectID": "posts/ap/2023-05-02-ap-09wk.html#확률변수의-불완전한-정의",
    "href": "posts/ap/2023-05-02-ap-09wk.html#확률변수의-불완전한-정의",
    "title": "09wk: 확률변수",
    "section": "확률변수의 불완전한 정의",
    "text": "확률변수의 불완전한 정의\n- 확률변수: \\(X:\\Omega \\to \\mathbb{R}\\)인 조금 특별한 성질을 가진 함수\n\n정의역: \\(\\Omega\\)\n공역: \\(\\mathbb{R}\\)\n\n(예제1) 동전예제\n1. outcomes1: \\(H\\),\\(T\\).\n2. sample space: \\(\\Omega = \\{H,T\\}\\)\n3. event2: \\(\\emptyset\\), \\(\\{H\\}\\), \\(\\{T\\}\\), \\(\\{H,T\\}\\).\n4. \\(\\sigma\\)-field: \\({\\cal F}=2^\\Omega\\)\n5. probability measure function: \\(P: {\\cal F} \\to [0,1]\\) such that\n\n\\(P(\\emptyset) = 0\\)\n\\(P(\\{H\\}) = \\frac{1}{2}\\)\n\\(P(\\{T\\}) = \\frac{1}{2}\\)\n\\(P(\\Omega) = 1\\)\n\n6. random variable: \\(X: \\Omega \\to \\mathbb{R}\\) such that\n\n\\(X(H)=1\\)\n\\(X(T)=0\\)\n\n만약에 편의상 \\(\\Omega=\\{H,T\\}=\\{\\omega_1,\\omega_2\\}\\)와 같이 사용한다면\n\n\\(X(\\omega_1)=1\\)\n\\(X(\\omega_2)=0\\)"
  },
  {
    "objectID": "posts/ap/2023-05-02-ap-09wk.html#헷갈려-1-star",
    "href": "posts/ap/2023-05-02-ap-09wk.html#헷갈려-1-star",
    "title": "09wk: 확률변수",
    "section": "헷갈려 (1) (\\(\\star\\))",
    "text": "헷갈려 (1) (\\(\\star\\))\n- 질문1: 아래의 표현 중 옳은 것은?3\n\n\\(X(H)=0\\)\n\\(P(\\{H\\})=\\frac{1}{2}\\)\n\\(P(\\{\\omega_1\\})=\\frac{1}{2}\\)^\n\\(P(H)=\\frac{1}{2}\\)\n\\(P(\\{H,T\\})=1\\)\n\\(P(\\omega_1)=\\frac{1}{2}\\)\n\n- 질문2: 질문1의 4번의 표현 많이 본적 있다. 예를들어서 고등학교에서 두 사건의 독립에 대해 배울때 아래와 같은 방식으로 표현했었다. // 출처: 네이버 블로그\n\n두 사건 \\(A\\), \\(B\\)에 대하여 \\(P(B|A) =P(B|A^c) =P(B)\\) 이면 두 사건이 독립이라고 한다~~\n\n그렇다면 이 표현은 틀린걸까?\n(해설)\n여기에서 사건 \\(A\\), \\(B\\)는 event을 의미하며 outcome을 의미하는게 아님. 즉 \\(A\\), \\(B\\)는 집합임.\n암기: 확률은 항상 집합을 입력으로 받아야 함!!\n- 질문3(\\(\\star\\star\\star\\)): 수리통계 시간에서 아래와 같은 표현 본 적 있다.\n\\[P(X=1)=\\frac{1}{2}\\]\n그런데 \\(P\\)의 입력으로는 집합이 들어가야하는데, \\(X=1\\)은 그냥 수식임. 그렇다면 이 표현은 틀린 표현일까??\n(해설)\n사실 \\(P(X=1)\\)의 의미는 아래와 같은 표현의 축약형이다.\n\\[P\\big(\\{\\omega: X(\\omega)=1 \\} \\big)\\]\n\\(\\{\\omega: X(\\omega)=1\\} = \\{\\omega_1\\} = \\{H\\}\\) 를 의미하므로 결국\n\\[P(X=1)=P(\\{\\omega: X(\\omega)=1\\})=P(\\{H\\})\\]\n이 된다. 따라서 옳은 표현이다."
  },
  {
    "objectID": "posts/ap/2023-05-02-ap-09wk.html#확률변수에-대한-통찰",
    "href": "posts/ap/2023-05-02-ap-09wk.html#확률변수에-대한-통찰",
    "title": "09wk: 확률변수",
    "section": "확률변수에 대한 통찰",
    "text": "확률변수에 대한 통찰\n- 아래와 같은 표현을 다시 관찰하자.\n\\[P(X=1)=P(\\{\\omega: X(\\omega)=1\\})=P(\\{H\\})\\]\n통찰1. 확률변수가 “함수”라는 사실을 떠올리고 \\(1\\)이라는 값이 확률변수의 “상(image)” 라는 사실을 떠올리면, \\(\\{\\omega: X(\\omega)=1\\}\\)은 1에 대한 “역상(inverse image)”이라고 해석할 수 있다.4\n통찰2. 확률변수의 상은 \\(\\mathbb{R}\\)에 맺히게 되고, 확률변수의 역상은 \\(\\Omega\\)의 부분집합 중 하나에 맺히게 된다.\n통찰3. 문제는 확률변수의 역상이 잴 수 있는 집합5에 맺힌다는 보장이 있냐라는 것이다… 즉 이 예제로 한정하면\n\\[\\{\\omega: X(\\omega)=1\\} \\in {\\cal F}\\]\n임을 보장해야 한다는 것이다.\n통찰4. 당연히 이러한 보장을 할 수는 없어보인다. 따라서 \\(X\\)를 단지 그냥\n\n\\(X: \\Omega \\to \\mathbb{R}\\)로 가는 함수\n\n가 아니라\n\n\\(X: \\Omega \\to \\mathbb{R}\\)로 가는 함수 & 역상이 항상 잴 수 있는 집합6이어야 함.\n\n이라는 조건이 필요하다.\n- 역상이 잴 수 있는 집합인 함수를 간단히 잴 수 있는 함수 (measurable function) 라고 한다."
  },
  {
    "objectID": "posts/ap/2023-05-02-ap-09wk.html#헷갈려-2-star-확률변수에-대한-오해",
    "href": "posts/ap/2023-05-02-ap-09wk.html#헷갈려-2-star-확률변수에-대한-오해",
    "title": "09wk: 확률변수",
    "section": "헷갈려 (2) (\\(\\star\\)) – 확률변수에 대한 오해",
    "text": "헷갈려 (2) (\\(\\star\\)) – 확률변수에 대한 오해\n오해1: 학률변수 = 값이 랜덤으로 바뀌는 변수??\n\n함수: \\(y=f(x)\\), \\(f\\): function, \\(x\\): input \\(y\\): output\n확률변수: \\(x=X(\\omega)\\), \\(X\\): function, \\(\\omega\\): outcome7, \\(x\\): realization\n확률변수는 함수이지만 보통 \\(X(\\omega)\\)와 같이 쓰지 않고 \\(X\\)라고 쓴다. \\(\\Rightarrow\\) 혼란의 이유\n\n오해2: 확률변수는 결과가 랜덤으로 변하는 함수??\n\n확률변수는 함수일 뿐임. 입력이 정해지면 출력이 고정임!\n동전예제: 입력이 \\(\\omega=H\\)이면 출력은 \\(X(\\omega)=1\\), 입력이 \\(\\omega=T\\)이면 출력은 \\(X(\\omega)=0\\)으로 고정임!\n\n오해3: 아니야.. 확률변수는 결과가 랜덤으로 바뀌는 느낌이 맞아. 아래의 예시를 봐!\n\\[X = \\begin{cases} 0 & w.p. \\frac{1}{2} \\\\ 1 & w.p. \\frac{1}{2} \\end{cases}\\]\n\n\\(X\\)는 진짜 변수처럼 보이긴함.\n심지어 변수의 값이 랜덤으로 변하는 것 같음.\n\n(해설)\n정확하게는 아래 표현이 맞다.\n\\[X(\\omega) = \\begin{cases} 0 & \\omega \\in \\{H\\} \\\\ 1 & \\omega \\in \\{T\\} \\end{cases} \\quad \\text{where } P(\\{H\\}) = P(\\{T\\}) = \\frac{1}{2}.\\]\n- 확률변수에 대한 오해2에 대한 추가설명\n\n확률변수는 결과가 랜덤으로 변하는 함수가 아님, 확률변수는 함수일 뿐임. 입력이 정해지면 출력이 고정임!\n동전예제: 입력이 \\(\\omega=H\\)이면 출력은 \\(X(\\omega)=1\\), 입력이 \\(\\omega=T\\)이면 출력은 \\(X(\\omega)=0\\)으로 고정임!\n단지 입력 outcome이 실험에 따라 랜덤으로 변할 수 있는 것임!!\n\n- 요약해보면,\n\n확률변수는 확률과 관련없다.\n간접적으로는 관련이 있다. \\(\\because\\) \\(X\\)의 역상 = \\(\\Omega\\)의 부분집합 = \\(P\\)의 정의역"
  },
  {
    "objectID": "posts/ap/2023-05-02-ap-09wk.html#확률변수의-엄밀한-정의",
    "href": "posts/ap/2023-05-02-ap-09wk.html#확률변수의-엄밀한-정의",
    "title": "09wk: 확률변수",
    "section": "확률변수의 엄밀한 정의",
    "text": "확률변수의 엄밀한 정의\n- 확률변수 (머리속): \\(X:\\Omega \\to \\mathbb{R}\\) 인 잴 수 있는 함수.\n- 확률변수 (엄밀하게): 두 개의 잴 수 있는 공간 \\((\\Omega,{\\cal F})\\)와 \\((\\mathbb{R}, {\\cal R})\\)이 있다고 하자. 확률변수 \\(X\\)는 아래를 만족하는 함수 \\(X:\\Omega \\to \\mathbb{R}\\) 이다.\n\\[\\forall B \\in {\\cal R}: X^{-1}(B) = \\{\\omega:X(\\omega)\\in B \\} \\in {\\cal F}\\]\n\nNote: \\(\\{\\omega:X(\\omega)\\in B \\} \\in {\\cal F}\\) for all \\(B \\in {\\cal R}\\) 이라 쓰기도 함. 쓰는사람 마음~"
  },
  {
    "objectID": "posts/ap/2023-05-02-ap-09wk.html#정의에-대한-비판",
    "href": "posts/ap/2023-05-02-ap-09wk.html#정의에-대한-비판",
    "title": "09wk: 확률변수",
    "section": "정의에 대한 비판",
    "text": "정의에 대한 비판\n- 왜 정의가 아래와 같지 않을까?\n\\[\\forall B \\subset \\mathbb{R}: X^{-1}(B) = \\{\\omega:X(\\omega)\\in B \\} \\in {\\cal F}\\]\n위의 질문을 위한 보충학습\n(예제) 바늘이 하나 있는 시계\n1. outcomes: \\(0,\\frac{\\pi}{2},\\pi,\\frac{3\\pi}{2},1,2,\\dots\\)\n2. sample space: \\(\\Omega = [0,2\\pi)\\)\n3. event: \\(\\emptyset\\), \\([0,\\frac{2}{\\pi})\\), \\(\\{0\\}\\), \\(\\dots\\)\n4. \\(\\sigma\\)-field: \\({\\cal F}\\)\n5. probability measure function: \\(P\\) such that\n\\[P([a,b)) = \\frac{b-a}{2\\pi}\\]\nwhere \\(0\\leq a&lt;b&lt;2\\pi\\).8\n6. random variable: \\(X: \\Omega \\to \\mathbb{R}\\) such that \\(X(\\omega)=\\omega\\)9\n\n6을 주목하자. 만약에 비탈리집합 \\(V \\subset [0,1] \\subset [0,2\\pi)\\)에 대한 inverse image는 비탈리집합 그 자체가 된다. 따라서 아래와 같이 된다.\n\n\\[P(X \\in V)=P\\big(\\{\\omega: X(\\omega) \\in V\\}\\big)=P(V)\\]\n\n그런데 집합 \\(V\\)는 르벡메져로는 잴 수 없으므로 \\(P(V)\\)와 같은 표현을 불가함.\n\n- 따라서 아래의 정의에서 \\(\\forall B \\in {\\cal R}\\) 대신에 \\(\\forall B \\subset \\mathbb{R}\\)이라고 쓸 수 없다.\n\\[\\forall B \\in {\\cal R}: X^{-1}(B) = \\{\\omega:X(\\omega)\\in B \\} \\in {\\cal F}\\]\n- 결국확률변수를 정의하기 위해서 2개의 가측공간 \\((\\Omega, {\\cal F})\\), \\((\\mathbb{R}, {\\cal R})\\)이 필요함."
  },
  {
    "objectID": "posts/ap/2023-05-02-ap-09wk.html#잴-수-있는-함수",
    "href": "posts/ap/2023-05-02-ap-09wk.html#잴-수-있는-함수",
    "title": "09wk: 확률변수",
    "section": "잴 수 있는 함수",
    "text": "잴 수 있는 함수\n- 교재의 정의1\n\n\n\n그림2: Durret에서 긁어온 확률변수의 정의\n\n\n\n“\\(X\\) is \\({\\cal F}\\)-measurable” 이라는 의미는, 모든 \\(B \\in {\\cal R}\\)에 대하여 \\(B\\)의 inverse image가 \\({\\cal F}\\)-measurable 하다는 의미.\n\\(X\\)가 랜덤변수라는 것을 기호로 간단하게 \\(X \\in {\\cal F}\\) 라고 씀.\n두개의 가측공간에 대한 언급은 매우 모호하게 되어있음.\n\n- 교재의 정의2\n\n\n\n그림3: Durret에서 긁어온 확률변수의 정의2\n\n\n\n측도의 개념을 정의하고 그 특수한 케이스로 확률측도를 정의하였듯이, 잴 수 있는 함수(measurable map)라는 개념을 정의하고 그 특수한 케이스로 확률변수(혹은 확률벡터)를 정의한다.\n두개의 가측공간이 명확하게 명시되어 있어서 좀 더 이해하기 쉽다.\n\n- 우리는 좀 더 명확한 의미전달을 위해\n\n\\(X\\)를 \\((\\Omega, {\\cal F})\\to (\\mathbb{R},{\\cal R})\\)인 확률변수라고 하자\n\\(X\\)를 \\((\\Omega, {\\cal F})\\to (S,{\\cal S})\\)인 잴 수 있는 함수 (가측함수)라고 하자\n\n와 같은 문장을 쓰겠다."
  },
  {
    "objectID": "posts/ap/2023-05-02-ap-09wk.html#확률변수의-체크",
    "href": "posts/ap/2023-05-02-ap-09wk.html#확률변수의-체크",
    "title": "09wk: 확률변수",
    "section": "확률변수의 체크",
    "text": "확률변수의 체크\n(1) 아래와 같은 measurable space를 고려하자.\n\n\\(\\Omega=\\{a,b,c,d\\}\\)\n\\({\\cal F} =\\sigma({\\cal A})\\) where \\({\\cal A} = \\{\\{a\\}\\}\\).\n\n아래와 같은 function \\(X:\\Omega \\to \\mathbb{R}\\), \\(Y:\\Omega \\to \\mathbb{R}\\)을 고려하자.\n\n\\(X(a)=1, X(b)=2, X(c)=3, X(d)=4\\)\n\\(Y(a)=1, Y(b)=2, Y(c)=2, Y(c)=2\\)\n\n아래의 물음에 답하라.\n\n\\(X\\)는 \\((\\Omega,{\\cal F})\\to (\\mathbb{R},{\\cal R})\\)인 확률변수인가?\n\\(Y\\)는 \\((\\Omega,{\\cal F})\\to (\\mathbb{R},{\\cal R})\\)인 확률변수인가?\n\n(풀이)\n\\(X\\)는 확률변수가 아님\n집합 \\(\\{2\\} \\in {\\cal R}\\)에 대하여 \\(\\{\\omega: X(\\omega) \\in \\{2\\}\\}=\\{b\\} \\not \\in \\sigma({\\cal A})\\) 이므로 \\(X\\)는 확률변수가 아님\n\\(Y\\)는 확률변수임\n\\(\\forall B \\in {\\cal R}\\)에 대하여 \\(Y^{-1}(B)\\in {\\cal F}\\)가 성립함.\n\n\\(\\{\\omega: Y(\\omega) \\in \\emptyset\\} = \\emptyset \\in \\sigma({\\cal A})\\)\n\\(\\{\\omega: Y(\\omega) \\in \\{1\\}\\} = \\{a\\} \\in \\sigma({\\cal A})\\)\n\\(\\{\\omega: Y(\\omega) \\in \\{2\\}\\} = \\{b,c,d\\} \\in \\sigma({\\cal A})\\)\n\\(\\{\\omega: Y(\\omega) \\in \\{1,2\\}\\} = \\{a,b,c,d\\} \\in \\sigma({\\cal A})\\)\n위에서 언급되지 않은 \\(B \\in {\\cal R}\\)에 대해서는 모두 \\(Y^{-1}(B)=\\emptyset \\in \\sigma({\\cal A})\\)가 성립함.\n\n(2) 두개의 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\)와 \\((S,{\\cal S})\\)를 고려하자. 단,\n\n\\(\\Omega=\\mathbb{R}\\),\n\\({\\cal F} =\\sigma({\\cal A})\\) where \\({\\cal A} = \\{\\mathbb{Q}\\}\\),\n\\(S = \\{0,1\\}\\),\n\\({\\cal S} = 2^{S}\\).\n\n아래와 같은 함수 \\(X:\\Omega \\to S\\)을 고려하라.\n\\[X(\\omega) = \\begin{cases}\n0 & \\omega \\in \\mathbb{Q}\\\\\n1 & \\omega \\in \\mathbb{R} - \\mathbb{Q}\n\\end{cases}\\]\n\\(X\\)는 \\((\\Omega,{\\cal F})\\to(S,{\\cal S})\\)인 가측함수인가?\n(풀이) 잴 수 있는 함수임.\nNote: \\(\\sigma({\\cal A})=\\{\\emptyset, \\mathbb{Q}, \\mathbb{Q}^c, \\mathbb{R} \\}, 2^S = \\{\\emptyset, \\{0\\}, \\{1\\}, \\{0,1\\}\\}\\)\n잴 수 있는 함수임을 체크하기 위해서는 \\(2^S\\)의 모든 원소 \\(B\\)에 대하여 \\(X^{-1}(B):= \\{\\omega : X(\\omega) \\in B\\} \\in {\\cal F}\\) 임을 확인하면 된다.\n\n\\(B=\\emptyset\\) 일 경우: \\(\\{\\omega: X(\\omega) \\in \\emptyset\\}=\\emptyset \\in \\sigma({\\cal A})\\)\n\\(B=\\{0\\}\\) 일 경우: \\(\\{\\omega: X(\\omega) \\in \\{0\\}\\}=\\mathbb{Q} \\in \\sigma({\\cal A})\\)\n\\(B=\\{1\\}\\) 일 경우: \\(\\{\\omega: X(\\omega) \\in \\{1\\}\\}=\\mathbb{Q}^c \\in \\sigma({\\cal A})\\)\n\\(B=\\{0,1\\}\\) 일 경우: \\(\\{\\omega: X(\\omega) \\in \\{0,1\\}\\}=\\mathbb{R} \\in \\sigma({\\cal A})\\)\n\n\n이 문제에서 \\((S,{\\cal S})\\)를 \\((\\mathbb{R}, {\\cal R})\\) 바꾸면 풀이의 약간만 수정하여 \\(X \\in {\\cal F}\\)임을 보일 수 있다.\n\n(3) 두개의 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\)와 \\((S,{\\cal S})\\)를 고려하자. 단,\n\n\\(\\Omega=\\mathbb{R}\\),\n\\({\\cal F} =\\sigma({\\cal A})\\) where \\({\\cal A} = \\{\\mathbb{Q}\\}\\),\n\\(S = \\{0,1\\}\\),\n\\({\\cal S} = 2^S\\).\n\n아래와 같은 함수 \\(X:\\Omega \\to S\\)을 고려하라.\n\\[X(\\omega) = \\begin{cases}\n0 & \\omega =0\\\\\n1 & \\omega \\neq 0\n\\end{cases}\\]\n즉 \\(X\\)는 \\((\\Omega,{\\cal F})\\to(S,{\\cal S})\\)인 가측함수인가?\n(풀이) 잴 수 있는 함수가 아님. \\(B=\\{0\\}\\) 일 경우, \\[\\{\\omega: X(\\omega) \\in B\\}=\\{0\\} \\notin \\sigma({\\cal A})\\] 이므로 잴 수 있는 함수의 정의에 만족하지 않음.\n\n이 문제에서 \\((S,{\\cal S})\\)를 \\((\\mathbb{R}, {\\cal R})\\) 바꾸면 풀이의 약간만 수정하여 \\(X \\notin {\\cal F}\\)임을 보일 수 있다."
  },
  {
    "objectID": "posts/ap/2023-03-23-4wk-1.html",
    "href": "posts/ap/2023-03-23-4wk-1.html",
    "title": "04wk-1: 측도론 intro (5)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-yTpksFFUby_Twan5kFTFdm"
  },
  {
    "objectID": "posts/ap/2023-03-23-4wk-1.html#불완전한-정의",
    "href": "posts/ap/2023-03-23-4wk-1.html#불완전한-정의",
    "title": "04wk-1: 측도론 intro (5)",
    "section": "불완전한 정의",
    "text": "불완전한 정의\n- 확률변수: \\(X:\\Omega \\to \\mathbb{R}\\)인 조금 특별한 성질을 가진 함수\n\n정의역: \\(\\Omega\\)\n치역: \\(\\mathbb{R}\\)\n\n(예제1) 동전예제\n1. outcomes31: \\(H\\),\\(T\\).\n2. sample space: \\(\\Omega = \\{H,T\\}\\)\n3. event32: \\(\\emptyset\\), \\(\\{H\\}\\), \\(\\{T\\}\\), \\(\\{H,T\\}\\).\n4. \\(\\sigma\\)-field: \\({\\cal F}=\\) \\(\\Omega\\)의 모든 부분집합의 모임\n5. probability measure function: \\(P: {\\cal F} \\to [0,1]\\) such that\n\n\\(P(\\emptyset) = 0\\)\n\\(P(\\{H\\}) = \\frac{1}{2}\\)\n\\(P(\\{T\\}) = \\frac{1}{2}\\)\n\\(P(\\Omega) = 1\\)\n\n6. random variable: \\(X: \\Omega \\to \\mathbb{R}\\) such that\n\n\\(X(H)=1\\)\n\\(X(T)=0\\)\n\n만약에 편의상 \\(\\Omega=\\{H,T\\}=\\{\\omega_1,\\omega_2\\}\\)와 같이 사용한다면\n\n\\(X(\\omega_1)=1\\)\n\\(X(\\omega_2)=0\\)"
  },
  {
    "objectID": "posts/ap/2023-03-23-4wk-1.html#헷갈려-1-starstarstar",
    "href": "posts/ap/2023-03-23-4wk-1.html#헷갈려-1-starstarstar",
    "title": "04wk-1: 측도론 intro (5)",
    "section": "헷갈려 (1) (\\(\\star\\star\\star\\))",
    "text": "헷갈려 (1) (\\(\\star\\star\\star\\))\n- 질문1: 아래의 표현 중 옳은 것은?\n\n\\(X(H)=0\\)33\n\\(P(\\{H\\})=\\frac{1}{2}\\)34\n\\(P(\\{\\omega_1\\})=\\frac{1}{2}\\)35\n\\(P(H)=\\frac{1}{2}\\)36\n\\(P(\\{H,T\\})=1\\)37\n\\(P(\\omega_1)=\\frac{1}{2}\\)38\n\n- 질문2: 질문1의 4번의 표현을 많이 본적 있다. 예를들어서 고등학교에서 두 사건의 독립에 대해 배울때 아래와 같은 방식으로 표현했었다. // 출처: 네이버 블로그\n\n두 사건 \\(A\\), \\(B\\)에 대하여 \\(P(B|A) =P(B|A^c) =P(B)\\) 이면 두 사건이 독립이라고 한다~~\n\n그렇다면 이 표현은 틀린걸까?\n(해설)\n여기에서 사건 \\(A\\), \\(B\\)는 event을 의미하며 outcome을 의미하는게 아님. 즉 \\(A\\), \\(B\\)는 집합임.\n암기: 확률은 항상 집합을 입력으로 받아야 함!!\n- 질문3(\\(\\star\\star\\star\\)): 수리통계 시간에서 아래와 같은 표현 본 적 있다.\n\\[P(X=1)=\\frac{1}{2}\\]\n그런데 \\(P\\)의 입력으로는 집합이 들어가야하는데, \\(X=1\\)은 그냥 수식임. 그렇다면 이 표현은 틀린 표현일까??\n(해설)\n사실 \\(P(X=1)\\)의 의미는 아래와 같은 표현의 축약형이다.\n\\[P\\big(\\{\\omega: X(\\omega)=1 \\} \\big)\\]\n\\(\\{\\omega: X(\\omega)=1\\} = \\{\\omega_1\\} = \\{H\\}\\) 를 의미하므로 결국\n\\[P(X=1)=P(\\{\\omega: X(\\omega)=1\\})=P(\\{H\\})\\]\n이 된다. 따라서 옳은 표현이다."
  },
  {
    "objectID": "posts/ap/2023-03-23-4wk-1.html#확률변수에-대한-통찰-1",
    "href": "posts/ap/2023-03-23-4wk-1.html#확률변수에-대한-통찰-1",
    "title": "04wk-1: 측도론 intro (5)",
    "section": "확률변수에 대한 통찰 (1)",
    "text": "확률변수에 대한 통찰 (1)\n- 아래와 같은 표현을 다시 관찰하자.\n\\[P(X=1)=P(\\{\\omega: X(\\omega)=1\\})=P(\\{H\\})\\]\n통찰1. 확률변수가 “함수”라는 사실을 떠올리고 \\(1\\)이라는 값이 확률변수의 “상(image)” 라는 사실을 떠올리면, \\(\\{\\omega: X(\\omega)=1\\}\\)은 1에 대한 “역상(inverse image)”이라고 해석할 수 있다.39\n통찰2. 확률변수의 상은 \\(\\mathbb{R}\\)에 맺히게 되고, 확률변수의 역상은 \\(\\Omega\\)의 부분집합 중 하나에 맺히게 된다.\n통찰3. 문제는 확률변수의 역상이 항상 잴 수 있는 집합에 맺힌다는 보장이 있냐라는 것이다… 즉 이 예제로 한정하면\n\\[\\{\\omega: X(\\omega)=1\\} \\in {\\cal F}\\]\n임을 보장해야 한다는 것이다.\n통찰4. 당연히 이러한 보장을 할 수는 없어보인다. 따라서 \\(X\\)를 단지 그냥\n\n\\(X: \\mathbb{\\Omega} \\to \\mathbb{R}\\)로 가는 함수\n\n가 아니라\n\n\\(X: \\mathbb{\\Omega} \\to \\mathbb{R}\\)로 가는 함수 & 역상이 항상 잴 수 있는 집합이어야 함.\n\n이라는 조건이 필요하다.\n- 역상이 잴 수 있는 집합인 함수를 간단히 잴 수 있는 함수 (measurable function) 라고 한다."
  },
  {
    "objectID": "posts/ap/2023-05-23-12wk-2.html",
    "href": "posts/ap/2023-05-23-12wk-2.html",
    "title": "12wk-2: 마코프체인 (11)",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-yZaqMvt2jojFKOeDaomqzi\n\n\n\n예비학습\n- 약어: \\(X\\)가 \\(\\mathbb{N}_0\\)에서 값을 가지는 이산형확률변수이고 \\({\\boldsymbol \\mu}^\\top\\) 가 \\(X\\)의 분포라고 하자. 이해를 위해서 아래와 같은 확률분포표를 가정한다면\n\n\n\n\\(X\\)\n\\(0\\)\n\\(1\\)\n\\(2\\)\n\n\n\n\n\\(\\mathbb{P}(X=k)\\)\n\\(0.1\\)\n\\(0.2\\)\n\\(0.7\\)\n\n\n\n\\({\\boldsymbol \\mu}^\\top = [0.1,0.2,0.7]\\) 이다. 이럴 경우 평균은\n\n\\(\\mathbb{E}(X)= 0\\times 0.1 + 1\\times 0.2 + 2 \\times 0.7\\)\n\n와 같이 표현가능한데, 이를 좀 더 명확하게 하기 위하여\n\n\\(\\mathbb{E}_{\\boldsymbol \\mu}(X)=0\\times 0.1 + 1\\times 0.2 + 2 \\times 0.7\\)\n\n라고 표현하기도 한다. 마찬가지로\n\n\\(\\mathbb{P}(X=0)=0.1\\)\n\\(\\mathbb{P}(X=1)=0.2\\)\n\\(\\mathbb{P}(X=2)=0.7\\)\n\n를 좀 더 명확하게 하기 위해서\n\n\\(\\mathbb{P}_{\\boldsymbol \\mu}(X=0)=0.1\\)\n\\(\\mathbb{P}_{\\boldsymbol \\mu}(X=1)=0.2\\)\n\\(\\mathbb{P}_{\\boldsymbol \\mu}(X=2)=0.7\\)\n\n와 같이 표현하기도 한다.\n- 예시: \\(X\\)의 분포 \\({\\boldsymbol \\mu}\\)와 \\({\\boldsymbol \\nu}\\)가 각각 아래와 같다고 하자.\n\\({\\boldsymbol \\mu}\\)의 정의\n\n\n\n\\(X\\)\n\\(1\\)\n\\(6\\)\n\n\n\n\n\\(\\mathbb{P}(X=k)\\)\n\\(0\\)\n\\(1\\)\n\n\n\n\\({\\boldsymbol \\nu}\\)의 정의\n\n\n\n\\(X\\)\n\\(1\\)\n\\(6\\)\n\n\n\n\n\\(\\mathbb{P}(X=k)\\)\n\\(1\\)\n\\(0\\)\n\n\n\n이 경우 아래의 표현들이 가능하다.\n\n\\(\\mathbb{E}_{\\boldsymbol \\mu}(X)=6\\), \\(\\mathbb{E}_{\\boldsymbol \\nu}(X)=1\\)\n\\(\\mathbb{P}_{\\boldsymbol \\mu}(X=1)=0\\), \\(\\mathbb{P}_{\\boldsymbol \\mu}(X=6)=1\\), \\(\\mathbb{P}_{\\boldsymbol \\nu}(X=1)=1\\), \\(\\mathbb{P}_{\\boldsymbol \\nu}(X=6)=0\\)\n\n- 약어: 확률변수 \\(X\\)가 \\(X=x\\)에서만 확률을 가지고 그 외에는 1이라고 할 경우 분포 \\({\\boldsymbol \\mu}\\)를 \\({\\boldsymbol \\delta}_x\\)라고 표현하기도 한다. 따라서 이 경우\n\n\\(\\mathbb{P}_{{\\boldsymbol \\delta}_x}(X=x)=1\\), \\(\\mathbb{P}_{{\\boldsymbol \\delta}_x}(X\\neq x)=0\\)\n\\(\\mathbb{E}_{{\\boldsymbol \\delta}_x}(X)=x\\)\n\n와 같은 표현들이 가능하다.\n- 예시: \\(X\\)의 분포 \\({\\boldsymbol \\mu}\\)와 \\({\\boldsymbol \\nu}\\)가 각각 아래와 같다고 하자.\n\\({\\boldsymbol \\mu}\\)의 정의\n\n\n\n\\(X\\)\n\\(1\\)\n\\(6\\)\n\n\n\n\n\\(\\mathbb{P}(X=k)\\)\n\\(0\\)\n\\(1\\)\n\n\n\n\\({\\boldsymbol \\nu}\\)의 정의\n\n\n\n\\(X\\)\n\\(1\\)\n\\(6\\)\n\n\n\n\n\\(\\mathbb{P}(X=k)\\)\n\\(1\\)\n\\(0\\)\n\n\n\n이 경우 아래의 표현들이 가능하다. (??)1\n\n\\(\\mathbb{E}_{{\\boldsymbol \\delta}_6}(X)=6\\), \\(\\mathbb{E}_{{\\boldsymbol \\delta}_1}(X)=1\\)\n\\(\\mathbb{P}_{{\\boldsymbol \\delta}_6}(X=1)=0\\), \\(\\mathbb{P}_{{\\boldsymbol \\delta}_6}(X=6)=1\\), \\(\\mathbb{P}_{{\\boldsymbol \\delta}_1}(X=1)=1\\), \\(\\mathbb{P}_{{\\boldsymbol \\delta}_1}(X=6)=0\\)\n\n- 약어: \\(\\{X_t\\}\\)가 상태공간 \\(E\\)에서 정의된 HMC 라고 하자.\n\n\\(\\mathbb{P}_{i}(X_t=k):=\\mathbb{P}_{\\boldsymbol {\\boldsymbol \\delta}_i}(X_t=k)=\\mathbb{P}(X_t=k| X_0=i)\\)2\n1의 표현에서 \\({\\boldsymbol \\delta}_x\\) 대신에 일반적인 \\({\\boldsymbol \\mu}\\)를 쓰기도 함.\n\\(\\mathbb{P}_{\\boldsymbol \\pi}(X_t=k)=\\pi_k\\)3\n\n\\(\\mathbb{P}_{i}(X_t=k)\\) 0 시점에서 델타 i에 있을떄 P의 확률\n\n\\(\\mathbb{P}_{i}\\), \\(\\mathbb{P}_{\\boldsymbol \\pi}\\) 등이 자명한 기호는 아니므로 교재마다 초반부에 정의하고 들어감헷갈리는 편임. 일반적인 기호와 충돌이 오지만 정상분포일 경우 그 의미가 같음.\n\n\n\nnature (cont)\n자연수에 0을 합친 \\(\\mathbb{N}_0\\)\n- 정의: \\(\\{X_t\\}\\)가 상태공간 \\(E\\)에서 정의된 HMC 라고 하자. \\(y \\in E\\), \\(t \\in \\mathbb{N}_0\\)에 대하여 아래와 같은 기호를 정의하자.\n\n\\(T_y = \\min\\{t: X_t=y, t\\geq 1\\}=\\min\\{t\\geq 1: X_t=y\\}\\)\n\\(P_y(T_y&lt;\\infty)\\)\n\n- 의미:\n\n나그네가 마을 \\(y\\) 에 \\(t=0\\), \\(t=2\\), \\(t=5\\), \\(t=88\\) 에 방문하였다고 하자.\n\\(\\{t: X_t=y, t\\geq 1\\}=\\{2,5,88\\}\\)\n\\(\\min\\{t: X_t=y, t\\geq 1\\}=2\\)\n\\(T_y=\\) 나그네가 마을 \\(y\\)에 처음으로 방문한 시점, 단 \\(t=0\\)인 경우는 제외함.\n\\(T_y=\\infty\\) \\(\\Leftrightarrow\\) 나그네가 마을 \\(y\\)에 갈 일이 없음\n\\(T_y&lt;\\infty\\) \\(\\Leftrightarrow\\) 나그네가 마을 \\(y\\)에 언제가는 돌아옴\n\\(\\mathbb{P}_y(T_y&lt;\\infty)=\\) 초기상태를 마을 \\(y\\)에 출발한 나그네4가 언젠가 다시 \\(y\\)로 돌아올 확률\n7의 의미는 “마을 \\(y\\)에 존재하던 나그네가 언젠가 다시 마을 \\(y\\)로 돌아올 확률”이라 해석해도 무방하다.\n\n- 정의: \\(\\{X_t\\}\\)가 상태공간 \\(E\\)에서 정의된 HMC 라고 하자. \\(T_i\\)를 상태 \\(i \\in E\\)에 대한 return time 이라고 하자. 만약에 상태 \\(i \\in E\\) 가 아래의 식을 만족한다면\n\\[\\mathbb{P}_i(T_i&lt;\\infty)=1\\]\n\\(i\\)는 recurrent 하다고 표현하고, 그렇지 않으면 \\(i\\)는 transient 하다고 표현한다. 만약에 recurrent state \\(i\\)가 아래식을 만족한다면\n\\[\\mathbb{E}_i[T_i] &lt; \\infty\\]\nstate \\(i\\)를 positive recurrent 라고 하고 그렇지 않으면 null recurrent 라고 한다.\n몇 번만에 돌아올 것이냐?\\(\\mathbb{E}\\)\n- 이론: HMC \\(\\{X_t\\}\\)가 IRR 이라면 모든 \\(i\\)는 같은 nature 를 가진다. 즉 \\(\\{X_t\\}\\)가 IRR 이면 아래중의 하나이다.\n\n모든 상태가 transient 하다.\n모든 상태가 null recurrent 하다.\n모든 상태가 positive recurrent 하다.\n\n\nHMC \\(\\{X_t\\}\\)의 모든상태가 positive recurrent 이면, positive recurrent markov chain 이라고 간단히 부른다. 나머지 역시 마찬가지\n\n- Thm(상태의분해1): \\(\\{X_t\\}\\)가 HMC라고 하고, \\(E\\)를 \\(\\{X_t\\}\\)가 정의되는 상태공간이라고 하자. 기호 \\(\\leftrightarrow\\)는 \\(E\\)에서 정의된 euivalence relation이 된다. 따라서 집합 \\(E\\)의 원소는 \\(\\leftrightarrow\\)를 기준으로 아래와 같이 나눌 수 있다.\n\\[E = \\uplus_{k=1}^{\\infty} E_k\\]\n이때\n\n\\(E_1,E_2,E_3,\\dots\\) 는 서로소\n\\(\\forall k:\\) \\(E_k\\) 는 IRR\n\n이다.\n- Thm(상태의분해2)(Durrett 2019, Thm 5.3.5): \\(\\{X_t\\}\\)가 HMC라고 하고, \\(E\\)를 \\(\\{X_t\\}\\)가 정의되는 상태공간이라고 하자. 집합 \\(E\\)는 아래와 같이 분해할 수 있다.\n\\[E = \\uplus_{k=1}^{\\infty} E_k\\]\n이때\n\n\\(E_1,E_2,E_3,\\dots\\) 는 서로소\n\\(\\forall k:\\) \\(E_k\\) 는 IRR\n\\(\\forall k:\\) \\(E_k\\) 의 모든 원소는 PR 이거나 NR 이거나 TR\n\n이다.\n- 따라서 transition matrix는 일반적으로 아래와 같이 분해하여 생각할 수 있다.\n\n\n\n그림1: 전이행렬의 분해 (Brémaud 2020, p 117)\n\n\n\n\nnature와 정상분포\n- 정의 \\(\\{X_t\\}\\)가 HMC라고 하자. 아래의 식을 만족하는\n\\[\\tilde{\\boldsymbol \\pi}^\\top {\\bf P} = \\tilde{\\boldsymbol \\pi}^\\top\\]\n\\({\\bf 0}\\)이 아닌 \\(\\tilde{\\boldsymbol \\pi}^\\top\\) 를 invariant measure 라고 한다. 만약에 \\(\\tilde{\\boldsymbol \\pi}^\\top\\) 이 분포의 정의를 만족하면 stationary measure 혹은 stationary distribution 이라고 부른다.\n- 예시: “오른쪽으로만 갈래” 예제에서는\n\\[\\tilde{\\boldsymbol \\pi}^\\top = [1,1,1,\\dots]\\]\n이 수식\n\\[\\tilde{\\boldsymbol \\pi}^\\top {\\bf P} = \\tilde{\\boldsymbol \\pi}^\\top\\]\n을 만족한다. 따라서 이 예제에서 \\(\\tilde{\\boldsymbol \\pi}^\\top = [1,1,1,\\dots]\\) 은 invariant measure 이다.\n- \\(\\{X_t\\}\\)가 HMC라고 하자. 각각에 대하여 아래가 성립한다.\n\n\n\n\n\n\n\n\n\n\nIRR\nnature\n\\(\\exists! \\tilde{\\boldsymbol \\pi}\\) up to multiplier\n\\(\\exists! {\\boldsymbol \\pi}\\)\n에르고딕정리(\\(\\approx\\)LLN)\n\n\n\n\n\\(O\\)\nPR\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\n\n\\(O\\)\nNR\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\n\n\\(O\\)\nTR\n\\(\\Delta\\)\n\\(X\\)\n\\(X\\)\n\n\n\n- 이론: \\(\\{X_t\\}\\)가 IRR-HMC5 라고 하자. \\(\\{X_t\\}\\)가 정상분포를 가진다는 조건과 유일한 정상분포를 가질 조건은 동치이다.\n\n즉 \\(\\{X_t\\}\\)가 IRR-HMC 일때, 정상분포가 존재한다는 사실만 보이면 자동으로 유일성이 보장된다.\n\n- Thm: \\(\\{X_t\\}\\)가 IRR-HMC 라고 하자. 그러면 positvite recurrent 와 \\(\\exists! {\\boldsymbol \\pi}\\) 은 동치조건이다. 즉\n\nIRR-HMC \\(\\{X_t\\}\\) 가 positive recurrent 하다면 항상 \\(\\{X_t\\}\\) 는 유일한 정상분포를 가진다.\nIRR-HMC \\(\\{X_t\\}\\) 가 정상분포를 가지면 (그 분포는 유일해지고) \\(\\{X_t\\}\\)는 항상 positive recurrent 하다.\n\n유일한 정상분포 = positive recurrent\n\n\n\n\n\n\nReferences\n\nBrémaud, Pierre. 2020. Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues. Springer Cham.\n\n\nDurrett, Rick. 2019. Probability: Theory and Examples. Vol. 49. Cambridge university press.\n\nFootnotes\n\n\n사실 이렇게 쓰는걸 본적은 없음↩︎\n\\(X_0 \\sim {\\boldsymbol \\delta}_i^\\top\\) 를 가정하고 구한 확률↩︎\n\\(X_t \\sim {\\boldsymbol \\pi}^\\top\\) 를 가정하고 구한 확률인것 처럼 보임, 하지만 사실 \\(X_0 \\sim {\\boldsymbol \\pi}^\\top\\)를 가정한 것↩︎\n\\(t=0\\) 시점에 마을 \\(y\\)에 존재하던 나그네↩︎\nirreducible 한 homogeneous markov chain↩︎"
  },
  {
    "objectID": "posts/ap/2023-06-13-fin.html",
    "href": "posts/ap/2023-06-13-fin.html",
    "title": "15wk: 기말고사",
    "section": "",
    "text": "1. 다음을 읽고 참거짓을 판단하라. (30점)\n(1) 유리수집합 \\(\\mathbb{Q}\\)는 가산집합이며 유리수집합을 르벡메져로 측정하면 그 길이가 0이다. 즉 \\(\\lambda(\\mathbb{Q})=0\\) 이다.\n\nTrue\n\nTrue\n\n\n(2) 르벡메져 \\(\\lambda\\)는 \\(\\mathbb{R}\\)의 모든 부분집합에 대하여 그 길이를 모순없이 정의가능하다. 즉 르벡메져는 \\((\\mathbb{R},2^{\\mathbb{R}})\\) 에서의 메져가 된다.\n\nFalse # 비탈리집합\n\nFalse\n\n\n(3) 르벡메져 \\(\\lambda\\)는 임의의 \\(B \\in {\\cal R}\\)의 길이를 모순없이 정의가능하다. 즉 르벡메져는 \\((\\mathbb{R},{\\cal R})\\) 에서의 메져가 된다.\n\nTrue\n\nTrue\n\n\n(4) 집합 \\(\\Omega\\)의 부분집합을 원소로 가지는 collection \\({\\cal F}\\)를 고려하자. 만약에 \\({\\cal F}\\)가 파이시스템이면서 동시에 람다시스템이라면 \\({\\cal F}\\)는 시그마필드이다.\n\nTrue\n\nTrue\n\n\n(5) 아래와 같은 함수 \\(f\\)를 고려하자.\n\\[f(x) = \\begin{cases} 1 & x \\in \\mathbb{Q}\\\\  0 & x \\in \\mathbb{R}-\\mathbb{Q}\\end{cases}\\]\n위의 함수에 대한 르벡적분값은 무한대이다. 즉 \\(\\int_{\\mathbb{R}} f d\\lambda = \\infty\\) 이다.\n\nFalse\n\nFalse\n\n\n(6) \\(X\\)가 가측공간 \\((\\Omega,{\\cal F})\\) 에서의 확률변수라는 의미는 모든 \\(B \\in {\\cal B}\\) 에 대하여 \\(\\{\\omega: X(\\omega) \\in B\\} \\in {\\cal F}\\) 를 만족한다는 의미이다.\n\nNone # 문제오류. ${\\cal B}$가 아니라 ${\\cal R}$ \n\n(7) \\(X\\)가 가측공간 \\((\\Omega,{\\cal F})\\) 에서의 확률변수라면 \\(X\\)에 대응하는 분포(distribution) \\(\\mu_X\\)가 반드시 존재하며 \\(\\mu_X:=P \\circ X^{-1}\\)로 정의가능하다.\n\nTrue\n\nTrue\n\n\n(8) \\(X\\)가 가측공간 \\((\\Omega,{\\cal F})\\) 에서의 확률변수이고, \\(X\\)에 대응하는 분포가 \\(\\mu_X\\)라고 하자. \\(\\mu_X\\)는 측도의 정의를 만족하지만 확률측도의 정의를 만족하지는 않는다.\n\nFalse # 확률측도의 정의도 만족\n\nFalse\n\n\n(9) \\(X\\)가 가측공간 \\((\\Omega,{\\cal F})\\) 에서의 확률변수이고, \\(X\\)에 대응하는 분포가 \\(\\mu_X\\)라고 하자. \\(\\mu_X\\)에 대응하는 분포함수 \\(F_X(x) = \\mu_X((-\\infty,x])\\)는 항상 존재한다.\n\nTrue\n\nTrue\n\n\n(10) \\(X\\)가 가측공간 \\((\\Omega,{\\cal F})\\) 에서의 확률변수이고 \\(F_X\\)가 \\(X\\)에 대응하는 분포함수라고 하자. 분포함수 \\(F_X\\)가 절대연속이라면 대응하는 \\(X\\)는 연속형확률변수이며 그 밀도함수 \\(f_X\\)가 존재한다.\n\nFalse\n\nFalse\n\n\n\n\n2. 확률 (40점)\n(1) \\(\\Omega=\\{1,2,3,4\\}\\) 이라고 하고 \\({\\cal A} = \\{\\emptyset, \\{1\\},\\{2\\},\\{3,4\\},\\Omega\\}\\) 이라고 하자. 함수 \\(\\tilde{P}:{\\cal A} \\to [0,1]\\)를 아래와 같이 정의하자.\n\n\\(\\tilde{P}(\\emptyset) = 0\\)\n\\(\\tilde{P}(\\{1\\}) = 1/4\\)\n\\(\\tilde{P}(\\{2\\}) = 1/2\\)\n\\(\\tilde{P}(\\{3,4\\}) = 1/4\\)\n\\(\\tilde{P}(\\Omega) = 1\\)\n\n\\({\\cal A}\\)에서 \\(\\tilde{P}\\)와 일치하는 확률메져 \\(P\\)가 가측공간 \\((\\Omega,\\sigma({\\cal A}))\\) 에서 유일하게 존재하는가?\n(풀이)\n유일하게 존재한다. \\({\\cal F}:=\\sigma({\\cal A})\\)라고 하고 아래와 같은 함수 \\(P: {\\cal F} \\to [0,1]\\)를 고려하자.\n\n\\(\\forall A \\in {\\cal A}:~ P(A)=\\tilde{P}(A)\\)\n\\(P(\\{1,2\\})=P(\\{2,3,4\\})=\\frac{3}{4}\\)\n\\(P(\\{1,3,4\\})=\\frac{1}{2}\\)\n\n\\(P\\)는 \\((\\Omega,{\\cal F})\\) 에서의 prob-msr 이며, \\({\\cal A}\\)는 파이시스템이므로 \\(P\\)의 유일성이 보장된다.\n(2) \\(\\Omega=\\{1,2,3,4\\}\\) 이라고 하고 \\({\\cal A} = \\{\\emptyset, \\{1,2\\},\\{2,3\\}, \\Omega\\}\\) 라고 하자. 함수 \\(\\tilde{P}:{\\cal A} \\to [0,1]\\)를 아래와 같이 정의하자.\n\n\\(\\tilde{P}(\\emptyset) = 0\\)\n\\(\\tilde{P}(\\{1,2\\}) = 1/2\\)\n\\(\\tilde{P}(\\{2,3\\}) = 1/2\\)\n\\(\\tilde{P}(\\Omega) = 1\\)\n\n\\({\\cal A}\\)에서 \\(\\tilde{P}\\)와 일치하는 확률메져 \\(P\\)가 가측공간 \\((\\Omega,\\sigma({\\cal A}))\\) 에서 유일하게 존재하는가?\n(풀이)\n\\({\\cal A}\\)가 파이시스템이 아니므로 유일성을 보장할 수 없다.\n반례를 위해서 \\({\\cal A}'=\\{\\emptyset, \\{1,2\\}, \\{2,3\\},\\{2\\},\\Omega\\}\\)를 고려하자. \\({\\cal A}'\\)은 세미알지브라가 되며, \\({\\cal A}'\\)에서 정의된 아래와 같은 \\(\\tilde{P}_1,\\tilde{P}_2\\)를 고려하자.\n\n\\(\\forall A \\in {\\cal A}:~\\tilde{P}_1(A)=\\tilde{P}_2(A)=\\tilde{P}(A)\\)\n\\(\\tilde{P}_1(\\{2\\})=a\\) and \\(\\tilde{P}_2(\\{2\\})=b\\), where \\(a,b \\in [0,1/2]\\) and \\(a\\neq b\\).\n\n\\(\\tilde{P}_1, \\tilde{P}_2\\)는 모두 \\({\\cal A}'\\)에서 finite msr 이고1, add를 만족하므로2 카라테오도리의 확장정리에 의하여 \\(\\tilde{P}_1\\), \\(\\tilde{P}_2\\)는 \\((\\Omega,\\sigma({\\cal A}))\\)에서의 유일한 extension \\(P_1,P_2\\)를 가진다. 이러한 그리고 이러한 \\(P_1,P_2\\)는 분명 \\(A \\in {\\cal A}\\)에서는 일치하지만 \\(P_1(\\{2\\})\\neq P_2(\\{2\\})\\) 이다.\n\n\n\n\n\n\n주의사항\n\n\n\n1. 위의 두 문제는 정답만 쓸 경우 답안으로 인정하지 않음. (1번답: 유일하게 존재함 &lt;– 이러면 0점)\n2. 유일하게 존재하는 (혹은 존재하지 않는) 이유를 설명하고, 그러한 확률측도를 예시로 제시해야함.\n3. 즉 유일하게 존재하는 경우는 아래를 만족하는 \\(P\\)를 제시하고,\n\n\\(P\\) is probability measure on \\((\\Omega,\\sigma({\\cal A}))\\)\n\\(\\forall A \\in {\\cal A}: ~ P(A) = \\tilde{P}(A)\\)\n\n유일하게 존재하지 않는 경우는 아래를 만족하는 서로 다른 2개의 측도 \\(P_1,P_2\\)를 제시해야함.\n\n\\(P_1,P_2\\) are probability measures on \\((\\Omega,\\sigma({\\cal A}))\\)\n\\(\\forall A \\in {\\cal A}: ~ P_1(A) =P_2(A) = \\tilde{P}(A)\\)\n\\(\\exists B \\in \\sigma({\\cal A}):~ P_1(B) \\neq P_2(B)\\)\n\n\n\n\n\n3. 확률변수, 밀도함수, 기대값 (30점)\n아래와 같은 확률공간 \\((\\Omega,{\\cal F},P)\\)를 고려하라.\n\n\\(\\Omega=[0,2\\pi)\\)\n\\({\\cal F} = {\\cal R}\\cap [0,2\\pi) := \\{B\\cap [0,2\\pi): B \\in {\\cal R}\\}\\)\n\\(\\forall A \\in {\\cal F}:~ P(A)=\\frac{\\lambda (A)}{2\\pi}\\)\n\n\n\n\n\n\n\n이것이 확률공간인 이유 (문제로 낼려다가..)\n\n\n\n\\((\\Omega, {\\cal F}, P)\\)가 확률공간임을 보이기 위해서는 (1) \\({\\cal F}\\)가 \\(\\sigma\\)-field 이고 (2) \\(P\\)가 prob-msr on \\((\\Omega, {\\cal F})\\)임을 보이면 된다.\n(1) \\({\\cal F}\\) is \\(\\sigma\\)-filed of \\(\\Omega\\)\n\\({\\cal F}\\)는 \\(\\pi\\)-system 이고 \\(\\lambda\\)-system 이므로 시그마필드이다. (6주차 Dynkin’s \\(\\pi-\\lambda\\) theorem 증명을 위한 준비학습 참고)3\n(2) \\(P\\) is prob-msr on \\((\\Omega, {\\cal F})\\)\n\\(\\lambda\\)가 \\({\\cal F}\\)에서의 measure이므로, \\(P:=\\frac{1}{2\\pi}\\lambda\\) 역시 \\({\\cal F}\\)에서의 measure가 된다. 이때 \\(P\\)는 \\(P(\\Omega)=1\\)을 만족하므로 prob-msr가 된다.\n\n\n(1) 함수 \\(X:\\Omega \\to \\mathbb{R}\\)을 아래와 같이 정의할때\n\\[X(\\omega) = \\begin{cases} 0 & \\omega \\in \\Omega \\cap \\mathbb{Q}^c \\\\ 1 & \\omega \\in \\Omega \\cap \\mathbb{Q} \\end{cases}\\]\n\\(X\\)가 확률변수임을 보여라.\n(풀이)\n\\(X\\)는 simple function 이므로 확률변수이다.\n(2) \\(\\mu_X &lt;&lt; \\nu\\) 를 만족하는 \\(\\sigma\\)-finite measure \\(\\nu\\) 를 가측공간 \\((\\mathbb{R}, {\\cal R})\\)에서 정의하고, \\(\\mu_X\\)의 Radon-Nikodym derivative (w.r.t. \\(\\nu\\))\n\\[f:=\\frac{d\\mu_X}{d\\nu}\\]\n를 제시하라. 단, 여기에서 \\(\\mu_X : P \\circ X^{-1}\\) 이다.\n(풀이)\n아래가 성립함을 관찰하라.\n\\[P(X=1)=P(\\{\\omega: X(\\omega) = 1\\})=P(\\Omega\\cap \\mathbb{Q}^c)=1\\]\n따라서 \\(X\\)에 대응하는 \\(\\mu_X\\)와 \\(F_x\\)는 아래와 같다.\n\n\\(\\forall B \\in {\\cal R}:~\\mu_X(B)=\\begin{cases} 1 & B =\\{0\\} \\\\ 0 & o.w \\end{cases}\\)\n\\(F_X(x)= \\begin{cases} 0 & x&lt;0 \\\\ 1 & x\\geq 0 \\end{cases}\\)\n\n따라서 \\(\\nu=\\mu_X\\) 으로 설정하면 \\(\\mu_X&lt;&lt;\\nu\\) 가 성립하며 함수\n\\[f_X(x)=\\begin{cases} 1 & x=0 \\\\ 0 & o.w \\end{cases}\\]\n는 \\(\\nu=\\delta_0\\)에 대한 \\(\\mu_X\\)의 라돈니코딤 도함수이다. 즉 모든 \\(B\\in {\\cal R}\\)에 대하여\n\\[\\mu_X(B)=\\int_B f_X(x) d\\nu\\]\n가 성립한다. (왜냐하면 \\(0\\in B\\) 인 경우 양변이 모두 1로 같으며 \\(0 \\notin B\\) 인 경우 양변이 모두 0으로 같기 때문)\n(3) \\(X\\)의 평균을 구하라. 즉 \\(\\mathbb{E}(X)\\)를 계산하라.\n(풀이)\n\\(\\mathbb{E}(X) = \\int X dP = \\int_{\\Omega \\cap \\mathbb{Q}^c} 0 dP + \\int_{\\Omega \\cap \\mathbb{Q}} 1dP =0\\)\n\n\n\n\n\nFootnotes\n\n\n그래서 \\(\\sigma\\)-finite 함↩︎\nfinite 한 케이스이므로 additivity 가 \\(\\sigma\\)-additive 를 imply함↩︎\n혹은 정석대로 시그마필드의 정의에 넣고 따져도 된다. 그런데 보통 그거보다 파이시스템과 람다시스템을 따지는게 더 편리하다.↩︎"
  },
  {
    "objectID": "posts/ap/2023-03-09-2wk-1.html",
    "href": "posts/ap/2023-03-09-2wk-1.html",
    "title": "02wk-1: 측도론 intro (1)",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-yPGeQuQgZaqhpUJujTtP4g\n\n\n\n예제1: 동전\n- \\(\\Omega =\\{H,T\\}\\): sample space\n- \\(P(\\{H\\})=P(\\{T\\})=\\frac{1}{2}\\): prob\n- 질문: \\(\\Omega\\)의 임의의(=모든) 부분 집합 \\(\\Omega^*\\)에 대하여 \\(P(\\Omega^*)\\)를 모순없이 정의할 수 있을까?\n\n당연한거 아냐?\n이게 왜 안돼?\n\n- 질문에 대한 대답\n\n\\(\\Omega\\)의 부분집합: \\(\\emptyset, \\Omega, \\{H\\},\\{T\\}\\)\n\\(P(\\{H\\})=\\frac{1}{2}\\), \\(P(\\{T\\})=\\frac{1}{2}\\), \\(P(\\Omega)=P(\\{H,T\\})=1\\), \\(P(\\emptyset)=0\\)\n\n- 모순없이의 의미?\n\n우리가 상식적으로 확률에 적용가능한 어떠한 연산들이 있음. (확률의 공리 + 기본성질) // 네이버검색\n이러한 연산을 적용해도 상식적인 수준에서 납득이 가야함\n\n(상식적인 연산 적용 예시1)\n\\(\\{H\\} \\subset \\Omega \\Rightarrow P(\\{H\\})&lt;P(\\Omega)\\)\n\n집합 \\(\\{H\\}\\)은 집합 \\(\\Omega\\)보다 작은 집합임\n상식적으로 작은집합이 일어날 확률이 큰 집합이 일어날 확률보다 클 수 없음\n동전 예제의 경우 모든 \\(A,B \\subset \\Omega\\) 에 대하여, \\(A\\subset B\\) 이라면 \\(P(A) &lt; P(B)\\) 가 성립함\n\n(상식적인 연산 적용 예시2)\n\\(\\{H\\} \\cap \\{T\\} = \\emptyset \\Rightarrow P(\\{H\\} \\cup \\{T\\})=P(\\{H\\}) + P(\\{T\\}) =1\\)\n\n우리의 상식에 따르면 \\(A,B\\)가 서로소인 사건이라면 \\(P(A)+P(B)\\)이어야 함.1\n이 예제는 실제로 그러함.\n사실 이 예제의 경우 \\(P(\\{H\\} \\cup \\{T\\})=P(\\Omega)=1\\) 와 같이 계산할 수도 있음.\n하지만 어떠한 방식으로 계산해도 모순이 없음.\n\n\n\n예제2: 바늘이 하나만 있는 시계\n- \\(\\Omega = [0,2\\pi)\\)\n\n시계바늘을 돌려서 나오는 각도를 재는일 \\(\\Leftrightarrow\\) \\([0,2\\pi)\\)사이의 숫자중에 하나를 뽑는 일\n\n- 질문: 바늘을 랜덤으로 돌렸을때 12시-6시 사이에 바늘이 있을 확률? \\(\\frac{1}{2}\\)\n\n\\(\\Omega^* = [0,\\pi)\\)\n\\(P(\\Omega^*)= \\frac{1}{2}\\)\n\n- 계산하는 방법? 아래와 같이 계산하면 가능!!\n\\[\\forall \\Omega^* \\subset \\Omega, \\quad P(\\Omega^*)=\\frac{m(\\Omega^*)}{m(\\Omega)}\\]\n단 여기에서 \\(m\\)은 구간의 길이를 재는 함수라고 하자.\n연습: \\(m\\)의 사용\n\n\\(m(\\Omega)=m\\big([0,2\\pi)\\big)=2\\pi\\)\n\\(m(\\Omega^*) = m\\big([0,\\pi)\\big)= \\pi\\)\n\n- 위와 같은 방식으로 확률을 정의하면 잘 정의될까? 이게 쉽지 않음. 왜냐하면 확률을 잘 정의하기 위해서는\n\n\\(\\Omega\\)의 모든 부분집합 \\(\\Omega^*\\)에 대하여 \\(P(\\Omega^*)\\)를 모순없이\n\n정의할 수 있어야 하는데, 이게 쉬운일이 아님.\n(질문0) 그냥 몸풀기 용 질문\n\n\\(\\Omega^*=\\emptyset\\) 일 확률이 얼마인가?\n\n(답변)\n\n0 이야2\n\n(질문1) 첫번째 도전적인 질문\n\n\\(\\Omega^* =\\{0\\}\\)일 확률이 얼마인가?\n\n(답변)\n\n즉 바늘침이 정확하게 12시를 가르킬 확률이 얼마냐는 것\n한 점으로 이루어진 집합 \\(\\{0\\}\\)은 분명히 \\(\\Omega=[0,2\\pi)\\)의 부분집합 이므로 앞서 논의한대로라면 이러한 집합에 대한 확률을 명확하게, 모순없이 정의할 수 있어야 함\n많은 사람들이 이 질문에 대한 답은 \\(0\\) 이라고 알고 있고 그 이유를 “점의 길이는 0 이니까” 라고 이해하고 있음.3\n\n답변이 사실 좀 찝찝해. 바늘침이 정확하게 12시를 가르키는 것은 우리가 분명 하루에 한번씩은 경험하는 사건임. 그런데 그 사건이 일어날 확률은 0이다?4\n(참견질문) 생각해보니까 이런게 있었잖아?\n\\[A \\subset B \\Rightarrow P(A)&lt;P(B)\\]\n그런데 \\(\\emptyset \\subset \\{0\\}\\) 인데 \\(P(\\emptyset)=P(\\{0\\})\\) 이다..?\n(답변)\n\n원래식은 이거임: \\(A \\subset B \\Rightarrow P(A)\\leq P(B)\\).\n즉 \\(A\\)가 \\(B\\)의 진 부분집합이더라도 \\(P(A)=P(B)\\)인 경우가 존재함.\n\n(질문2) 두번째 질문은 아래와 같다.\n\n그렇다면 사건 \\(\\{0,\\pi\\}\\)가 일어날 확률은 얼마인가?\n\n(답변)\n\n질문을 다시 풀어쓰면 바늘침이 정확하게 12시를 가르키거나 혹은 정확하게 6시를 가르킬 확률이 얼마냐는 것\n따라서 이 질문에 대한 대답은 \\(0+0=0\\) 이므로 \\(0\\)이라고 주장할 수 있음.\n\n(질문3) 세번째 질문은 아래와 같다.\n\n구간 \\([0,2\\pi)\\)는 무수히 많은 점들이 모여서 만들어지는 집합이다. 그런데 점 하나의 길이는 0이다. 0을 무수히 더해도 0이다. 그러므로 구간 \\([0,2\\pi)\\)의 길이도 0이 되어야 한다. 이것은 모순아닌가?\n\n(답변)\n\n까다롭다.\n\\(m([0,2\\pi))=0\\) 임을 인정하면 전체확률은 1이어야 한다는 기본상식5에 어긋나 모순이 생김.\n질문의 논리는 타당해보임. 이 논리의 약점은 딱히 없어보임. 굳이 약점이 있다면 “무한”이라는 개념?\n어쩔수없이 직관에 근거한 약간의 약속을 또 다시 해야할 것 같음. 예를들면 “점들을 유한번 합치면 그냥 많은 점들이지만 무한히 합치면 이것은 선분이 된다. 따라서 길이가 생긴다.” 와 같이.\n우리는 이 약속을 “무한번의 기적”이라고 칭하자.\n\n(질문4) 그렇다면 아래의 질문은 어떻게 대답할 수 있을까?\n\n\\([0,\\pi)\\) 에서 유리수만 뽑아낸 집합이 있다고 생각하자. 편의상 이 집합을 \\(\\mathbb{Q}\\) 라고 하자. 이 집합은 분명히 무한개의 점을 포함하고 있다. 그렇다면 이 집합도 길이가 있는가? 있다면 얼마인가?\n\n(답변)\n\n이미 점들의 길이를 무한번 더하면 길이가 생긴다고 주장한 상태이므로 (무한번의 기적) 길이가 0이라고 주장할 수 없다. 따라서 길이가 있다고 주장해야 한다.\n\\(\\pi\\)말고 딱히 떠오르는 수가 없는데 단순히 길이가 \\(\\pi\\)라고 주장한다면 바로 모순에 빠짐을 알 수 있다.6\n길이는 일단 0보다 커야하고 \\(\\pi\\)보다 작아야함은 자명하므로 그 사이에 있는 어떤 값이 길이라고 주장하자.7\n따라서 (질문4)에 대한 답은 ‘’구체적으로 얼마인지는 모르겠지만 길이가 분명 존재하고 그 길이는 0 보다 크고 \\(\\pi\\) 보다는 작은 어떠한 값 \\(a\\)이다.’’ 정도로 정리할 수 있다.\n즉 \\(m(\\mathbb{Q})=a\\), where \\(0&lt;a&lt;\\pi\\).\n\n(질문5) – 외통수\n질문4로부터 만들어지는 논리는 빌드업1-3으로 이어지는 콤보질문을 적절하게 대답하지 못한다. (질문이 좀 길어서 나누어서 설명합니다)\n(빌드업1) – 평행이동은 길이를 변화시키지 않아, 그렇지?\n\n\\(\\mathbb{Q}\\)의 모든점에 \\(\\sqrt{2}\\)를 더한다. 이 점들로 집합을 만들어 \\(\\mathbb{Q}_{\\sqrt{2}}\\)를 만든다.\n여기에서 \\(\\mathbb{Q}_{\\sqrt{2}}\\)는 \\(\\Omega\\)의 부분집합 \\(\\Rightarrow\\) \\(\\mathbb{Q}_{\\sqrt{2}}\\)는 길이를 명확하고 모순없이 정의할 수 있어야 함\n\\(\\mathbb{Q}_{\\sqrt{2}}\\)의 길이는 사실 쉽게 \\(a\\)라고 정의할 수 있음8. 즉, \\(m(\\mathbb{Q}_{\\sqrt{2}})=a\\).\n\n(빌드업2) – 겹치지 않게 평행이동 시킨다음에 길이를 더한다면?\n이제 \\(\\mathbb{Q}_{\\sqrt{2}},\\mathbb{Q}_{\\sqrt{2}/2},\\mathbb{Q}_{\\sqrt{2}/3}\\)를 생각하자. 아래의 성질을 관찰할 수 있다.\n\n\\(\\mathbb{Q}_{\\sqrt{2}},\\mathbb{Q}_{\\sqrt{2}/2},\\mathbb{Q}_{\\sqrt{2}/3}\\)는 모두 \\(\\Omega\\)의 부분집합 \\(\\Rightarrow\\) 따라서 길이를 명확하고 모순없이 정의할 수 있어야 함\n\\(\\mathbb{Q}_{\\sqrt{2}},\\mathbb{Q}_{\\sqrt{2}/2},\\mathbb{Q}_{\\sqrt{2}/3}\\)의 길이는 각각 \\(a\\)로 정의할 수 있다.9\n\\(P(\\mathbb{Q}_{\\sqrt{2}} \\cup \\mathbb{Q}_{\\sqrt{2}/2} \\cup \\mathbb{Q}_{\\sqrt{2}/3})=P(\\mathbb{Q}_{\\sqrt{2}}) + P(\\mathbb{Q}_{\\sqrt{2}/2})+ P(\\mathbb{Q}_{\\sqrt{2}/3})\\)10\n\n굳이 \\(P(\\mathbb{Q}_{\\sqrt{2}}) + P(\\mathbb{Q}_{\\sqrt{2}/2})+ P(\\mathbb{Q}_{\\sqrt{2}/3})\\)를 계산하면 아래와 같이 계산할 수 있겠다.\n\\[P(\\mathbb{Q}_{\\sqrt{2}}) + P(\\mathbb{Q}_{\\sqrt{2}/2})+ P(\\mathbb{Q}_{\\sqrt{2}/3})=\\frac{a}{2\\pi}+\\frac{a}{2\\pi}+\\frac{a}{2\\pi}=3 \\times \\frac{a}{2\\pi}\\]\n(빌드업3) – 그런데 난 겹치지않게 평행이동시킬 방법을 무한대로 알고 있는데?\n눈 여겨볼 점은 아래 식이 성립해야 한다는 것이다. (\\(\\because\\) 확률의 공리)11\n\\[P\\big(\\mathbb{Q}_{\\sqrt{2}} \\cup \\mathbb{Q}_{\\sqrt{2}/2} \\cup \\mathbb{Q}_{\\sqrt{2}/3}\\big) = 3 \\times \\frac{a}{2\\pi} \\leq 1 \\quad \\cdots (\\star)\\]\n\n그런데 \\((\\star)\\)에서 좌변의 값은 편의에 따라서 값을 임의로 키울 수 있다.\n이렇게 임의로 키워진 좌변의 값이라도 항상 그 값은 1보다 작아야 하는데 (확률의 공리), 이게 가능하려면 \\(a=0\\)인 경우 말고 없다.\n그런데 \\(a=0\\) 이 된다면 “무한번 더해서 일어나는 기적”은 허구가 되므로 질문3 의 대답에 모순이 된다.\n\n그런데 임의로 좌변의 값을 키워도 항상 그 값은 1보다 작아야 하는데 이러한 \\(a\\)는 0이외에 불가능하다.\n그런데 \\(a=0\\) 이 된다면 “무한번 더해서 일어나는 기적”은 허구가 되므로 질문3 의 대답에 모순이 된다.\n\n\n르벡메져\n- 예제2에서의 마지막 질문은 지금까지 제시한 논리로 방어가 불가능. 이처럼 논리적 모순없는 체계를 만드는 것은 매우 어려운 일임.\n- 결론적으로 말하면 길이를 재는 함수 \\(m\\)을 아래와 가정하면 위의 모든 질문에 대한 대답을 논리적 모순없이 설계할 수 있다.\n\n한 점에 대한 길이는 \\(0\\) 이다.\n\\([0,2\\pi)\\) 사이의 모든 유리수를 더한 집합은 그 길이가 \\(0\\)이다.\n\\([0,2\\pi)\\) 사이의 모든 무리수를 더한 집합은 그 길이가 \\(2\\pi\\)이다.\n\n참고로 르벡측도(Lebesgue measure)를 사용하면 위의 성질을 만족한다.12 따라서 르벡측도를 활용하여 확률을 정의하는 것이 모순을 최대한 피할 수 있다.\n\n\n\n\n\nFootnotes\n\n\n확률의 공리↩︎\n이걸 좀 더 엄밀하게 따질수도 있는데 일단 직관적으로 0이라 생각하고 넘어가자↩︎\n이해 안되면 약속이라고 생각하자.↩︎\n자연어에서는 “확률=0” 와 “불가능” 은 동일하지만 여기서는 아니다.↩︎\n심지어 이건 확률의 공리↩︎\n왜 모순에 빠지냐면 \\([0,\\pi)\\)에서 무리수만 뽑아낸 집합의 길이가 뭐냐고 물을경우 0이라고 말해야함↩︎\n구체적으로 어떤값인지는 모른다고 하자.↩︎\n평행이동은 길이를 변화시킬 수 없으니까↩︎\n평행이동은 길이를 변화시키지 않으니까↩︎\n\\(\\mathbb{Q}_{\\sqrt{2}},\\mathbb{Q}_{\\sqrt{2}/2},\\mathbb{Q}_{\\sqrt{2}/3}\\)는 모두 서로소 임을 이용↩︎\n첫 등호는 서로소인 사건에 대한 공리, 그다음 부등호는 확률의 총합은 1보다 같거나 작다라는 공리↩︎\n물론 르벡측도의 정의가 위와 같지는 않다↩︎"
  },
  {
    "objectID": "posts/ap/2023-05-25-13wk-1.html",
    "href": "posts/ap/2023-05-25-13wk-1.html",
    "title": "13wk-1: 마코프체인 (12)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-x4iyJGrSEk1pswE7dsNoke"
  },
  {
    "objectID": "posts/ap/2023-05-25-13wk-1.html#지난시간",
    "href": "posts/ap/2023-05-25-13wk-1.html#지난시간",
    "title": "13wk-1: 마코프체인 (12)",
    "section": "지난시간",
    "text": "지난시간\n- 정의 \\(\\{X_t\\}\\)가 HMC라고 하자. 아래의 식을 만족하는\n\\[\\tilde{\\boldsymbol \\pi}^\\top {\\bf P} = \\tilde{\\boldsymbol \\pi}^\\top\\]\n\\(\\tilde{\\boldsymbol \\pi}^\\top\\) 를 invariant measure 라고 한다. 만약에 \\(\\tilde{\\boldsymbol \\pi}^\\top\\) 이 분포의 정의를 만족하면 stationary measure 혹은 stationary distribution 이라고 부른다.\n- 예시: “오른쪽으로만 갈래” 예제에서는\n\\[\\tilde{\\boldsymbol \\pi}^\\top = [1,1,1,\\dots]\\]\n이 수식\n\\[\\tilde{\\boldsymbol \\pi}^\\top {\\bf P} = \\tilde{\\boldsymbol \\pi}^\\top\\]\n을 만족한다. 따라서 이 예제에서 \\(\\tilde{\\boldsymbol \\pi}^\\top = [1,1,1,\\dots]\\) 은 invariant measure 이다.\n- \\(\\{X_t\\}\\)가 HMC라고 하자. 각각에 대하여 아래가 성립한다.\n\n\n\n\n\n\n\n\n\n\nIRR\nnature\n\\(\\exists! \\tilde{\\boldsymbol \\pi}\\) up to multiplier\n\\(\\exists! {\\boldsymbol \\pi}\\)\n에르고딕정리(\\(\\approx\\)LLN)\n\n\n\n\n\\(O\\)\nPR\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\n\n\\(O\\)\nNR\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\n\n\\(O\\)\nTR\n\\(\\Delta\\)\n\\(X\\)\n\\(X\\)\n\n\n\n- 이론: \\(\\{X_t\\}\\)가 IRR-HMC1 라고 하자. \\(\\{X_t\\}\\)가 정상분포를 가진다는 조건과 유일한 정상분포를 가질 조건은 동치이다.\n\n즉 \\(\\{X_t\\}\\)가 IRR-HMC 일때, 정상분포가 존재한다는 사실만 보이면 자동으로 유일성이 보장된다.\n\n- Thm: \\(\\{X_t\\}\\)가 IRR-HMC 라고 하자. 그러면 positvite recurrent 와 \\(\\exists! {\\boldsymbol \\pi}\\) 은 동치조건이다. 즉\n\nIRR-HMC \\(\\{X_t\\}\\) 가 positive recurrent 하다면 항상 \\(\\{X_t\\}\\) 는 유일한 정상분포를 가진다.\nIRR-HMC \\(\\{X_t\\}\\) 가 정상분포를 가지면 (그 분포는 유일해지고) \\(\\{X_t\\}\\)는 항상 positive recurrent 하다.\n\n\\(\\exists! {\\boldsymbol \\pi}\\)(분포)가 존재해야 에르고딕정리(\\(\\approx\\)LLN)가 존재하지"
  },
  {
    "objectID": "posts/ap/2023-05-25-13wk-1.html#이번시간",
    "href": "posts/ap/2023-05-25-13wk-1.html#이번시간",
    "title": "13wk-1: 마코프체인 (12)",
    "section": "이번시간",
    "text": "이번시간\n- (정의) – 복습 \\(\\{X_t\\}\\)가 HMC라고 하자. 모든 \\(i \\in E\\) 는 아래의 조건중 하나를 만족하는데\n\n\\(\\mathbb{P}_i(T_i &lt;\\infty)= 1\\) and \\(\\mathbb{E}_i[T_i]&lt;\\infty\\),\n\\(\\mathbb{P}_i(T_i &lt;\\infty)= 1\\) and \\(\\mathbb{E}_i[T_i]=\\infty\\),\n\\(\\mathbb{P}_i(T_i &lt;\\infty)= 0\\).\n\n이중에서 3의 경우는 상태 \\(i\\)가 transient 하다고 표현하며, 1,2의 경우는 각각 potivite recurrent, null recurrent 하다고 표현한다.\n- 이걸 갑자기 복습하는 이유? 결국 TR, NR 모두 그 상태에 머물확률이 궁극적으로는 0이라는 느낌을 위해서! TR일 경우는 따질 필요 없이 확실하고 NR일 경우는 아래 식을 이용하여 판단할 수 있다.\n\\[\\frac{1}{\\mathbb{E}(T_i)} \\approx \\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{1}(X_t=i)\\]\n\n\\(T=100\\) 일때 21번 상태 i에 있었음.\n평균적으로 \\(\\frac{21}{100}\\approx 1/5\\) 비율로 상태 0에 있는듯\n현재 상태 0에 머물러 있다면, 평균 5번정도내로는 돌아올 듯 (그렇지 않다면 2가 성립하지 않는걸?)\n\n- 직관: 어떠한 상태가 PR이 아닌 경우는 그 상태에 머물 확률이 0이므로 당연히 정상분포를 가지지 않음.\n- Thm (에르고딕 thm): IRR-HMC \\(\\{X_t\\}\\)가 PR 조건을 만족한다고 하자. 그러면 \\(\\sum_{i\\in E}|f(i)|\\pi_i&lt;\\infty\\)를 만족하는 함수 \\(f:E \\to \\mathbb{R}\\)에 대하여 아래가 성립한다.\n\\[\\lim_{T\\to\\infty} \\frac{1}{T}\\sum_{t=0}^{T-1}f(X_t) = \\mathbb{E}_{\\boldsymbol \\pi}[f(X_0)]\\]\n여기에서 \\(\\boldsymbol \\pi\\)는 \\({\\boldsymbol \\pi}^\\top = {\\boldsymbol \\pi}^\\top{\\bf P}\\)를 만족하는 유일한 정상분포이고 \\({\\bf P}\\)는 \\(\\{X_t\\}\\)의 transition matrix 이다.\n\nFINITE 한 경우와 비교1: FINITE 조건이 PR 조건으로 바뀐느낌.\n\n\nFINITE 한 경우와 비교2: \\(\\sum_{i\\in E}|f(i)|\\pi_i&lt;\\infty\\) 이라는 조건은 없었는데 생김\n\n- 이론: (에르고딕 thm, ver2) IRR-HMC \\(\\{X_t\\}\\)가 PR이면 아래가 성립한다는 의미이다.\n\\[\\bar{\\boldsymbol \\pi} \\to {\\boldsymbol \\pi}\\]\n(증명?)\n이 이론이 성립하는 이유는 원래의 에르고딕 이론에서 \\(f\\)를 잘 해석하면 된다.\nSOME NOTES\n\nIRR 조건은 까다롭지 않다. (없다면 그냥 가정할 수 있음)\nPR 조건이 있는 이유? NR 이거나 TR 이면 애초에 수렴할 정상분포가 없는걸?\n\n- 이론: (에르고딕 thm, ver3) IRR-HMC \\(\\{X_t\\}\\)가 FINITE 이면 아래가 성립한다.\n\\[\\bar{\\boldsymbol \\pi} \\to {\\boldsymbol \\pi}\\]\n(증명?)\nIRR-HMC가 FINITE 할 경우 PR이 임플라이 되므로 자동성립\n\n에르고딕 정리는 결국 LLN의 upgrade 버전이며 (조건은 약화되었는데 결론도 강해요) “시간평균 \\(\\approx\\) 앙상블평균” 을 의미한다."
  },
  {
    "objectID": "posts/ap/2023-04-25-8wk-2.html",
    "href": "posts/ap/2023-04-25-8wk-2.html",
    "title": "08wk-2: 마코프체인 (5)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-zHbA2xrF58wfGjzkhNzxnL"
  },
  {
    "objectID": "posts/ap/2023-04-25-8wk-2.html#motivating-examples",
    "href": "posts/ap/2023-04-25-8wk-2.html#motivating-examples",
    "title": "08wk-2: 마코프체인 (5)",
    "section": "Motivating Examples",
    "text": "Motivating Examples\n\n예제1\n- 아래의 전이확률을 고려하자.\nIRR하지 않다.\n\nP =np.array([0.5, 0.5, 0.0, 0.0, \n             0.5, 0.5, 0.0, 0.0,\n             0.0, 0.0, 0.5, 0.5,\n             0.0, 0.0, 0.5, 0.5]).reshape(4,4)\nP\n\narray([[0.5, 0.5, 0. , 0. ],\n       [0.5, 0.5, 0. , 0. ],\n       [0. , 0. , 0.5, 0.5],\n       [0. , 0. , 0.5, 0.5]])\n\n\n- 특징1: \\({\\bf P}\\)는 수렴함\n\nP@P@P\n\narray([[0.5, 0.5, 0. , 0. ],\n       [0.5, 0.5, 0. , 0. ],\n       [0. , 0. , 0.5, 0.5],\n       [0. , 0. , 0.5, 0.5]])\n\n\n- 특징2: 모든 row가 같은건 아님\n- 특징3: 정상분포는 유일하게 존재하지 않음\n\nπ = np.array([1/4, 1/4, 1/4, 1/4]).reshape(4,1)\nπ\n\narray([[0.25],\n       [0.25],\n       [0.25],\n       [0.25]])\n\n\n\nπ.T @ P, π.T \n\n(array([[0.25, 0.25, 0.25, 0.25]]), array([[0.25, 0.25, 0.25, 0.25]]))\n\n\n\nπ = np.array([1/2, 1/2, 0, 0]).reshape(4,1)\nπ\n\narray([[0.5],\n       [0.5],\n       [0. ],\n       [0. ]])\n\n\n\nπ.T @ P, π.T \n\n(array([[0.5, 0.5, 0. , 0. ]]), array([[0.5, 0.5, 0. , 0. ]]))\n\n\n\nπ = np.array([1/6, 1/6, 2/6, 2/6]).reshape(4,1)\nπ\n\narray([[0.16666667],\n       [0.16666667],\n       [0.33333333],\n       [0.33333333]])\n\n\n\nπ.T @ P, π.T \n\n(array([[0.16666667, 0.16666667, 0.33333333, 0.33333333]]),\n array([[0.16666667, 0.16666667, 0.33333333, 0.33333333]]))\n\n\n- 특징4: 초기분포가 정상분포라면 정상확률과정\n- 특징5: 상태공간 \\(E\\) 에 equivalence class 가 2개 있는 느낌\n\n\n예제2\n- 아래의 전이확률을 고려하자.\nequivalent class가 두 개 있다.\n\nP =np.array([1/4, 1/4, 0.0, 1/2, \n             1/4, 1/4, 0.0, 1/2,\n             0.0, 0.0, 1.0, 0.0,\n             1/2, 1/4, 0.0, 1/4]).reshape(4,4)\nP\n\narray([[0.25, 0.25, 0.  , 0.5 ],\n       [0.25, 0.25, 0.  , 0.5 ],\n       [0.  , 0.  , 1.  , 0.  ],\n       [0.5 , 0.25, 0.  , 0.25]])\n\n\n- 특징1: \\({\\bf P}\\)는 수렴함\n\nnp.matrix(P)**500\n\nmatrix([[0.35, 0.25, 0.  , 0.4 ],\n        [0.35, 0.25, 0.  , 0.4 ],\n        [0.  , 0.  , 1.  , 0.  ],\n        [0.35, 0.25, 0.  , 0.4 ]])\n\n\n- 특징2: 모든 row가 같지는 않음\n- 특징3: 유일한 정상분포를 가지는건 아님\n\nc1 = 0.2 # 상태 0,1,3 \nc2 = 0.8 # 상태 2 \nπ = np.array([0.35*c1, 0.25*c1, 1.0*c2 ,0.4*c1]).reshape(4,1)\nπ\n\narray([[0.07],\n       [0.05],\n       [0.8 ],\n       [0.08]])\n\n\n\nπ.T @ P, π.T \n\n(array([[0.07, 0.05, 0.8 , 0.08]]), array([[0.07, 0.05, 0.8 , 0.08]]))\n\n\n- 특징4: 초기분포가 정상분포라면 정상확률과정\n- 특징5: 상태공간 \\(E\\)에 equivalence class 가 2개 있는 느낌"
  },
  {
    "objectID": "posts/ap/2023-04-25-8wk-2.html#정의-및-이론",
    "href": "posts/ap/2023-04-25-8wk-2.html#정의-및-이론",
    "title": "08wk-2: 마코프체인 (5)",
    "section": "정의 및 이론",
    "text": "정의 및 이론\n- 용어\n\nirreducible (기약) // reducible (비기약)\n(strongly) connected\n\n- 정의\n- 느낌\n\n연결되어있는 느낌. 즉 모든 \\(x,y \\in E\\)에 대하여 \\(x\\to \\cdots \\to y\\) 인 path 나 \\(y \\to \\cdots \\to x\\) 인 path 가 존재함\n겉도는 그룹이 없음 (상태공간 \\(E\\)에 단 하나의 equivalence class가 존재함)\n\n- Thm: HMC \\(\\{X_t\\}\\) 가 (1) finite state space 를 가지고 (2) irreducible 이라면 \\(\\{X_t\\}\\)의 유일한 정상분포 \\({\\boldsymbol \\pi}\\)가 존재하며 모든 state에 대한 확률은 양수이다."
  },
  {
    "objectID": "posts/ap/2023-04-25-8wk-2.html#motivating-examples-1",
    "href": "posts/ap/2023-04-25-8wk-2.html#motivating-examples-1",
    "title": "08wk-2: 마코프체인 (5)",
    "section": "Motivating Examples",
    "text": "Motivating Examples\n\n예제1\n- 아래와 같은 전이확률을 고려하자.\n\nP = np.array([0.0, 1.0, 0.0,\n              0.0, 0.0, 1.0,\n              1.0, 0.0, 0.0]).reshape(3,3)\nP\n\narray([[0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.]])\n\n\n- 다이어그램\n\n\n\n\nflowchart LR\n  0 --&gt;|1| 1\n  1 --&gt;|1| 2\n  2 --&gt;|1| 0\n\n\n\n\n\n- 특징1: \\({\\bf P}\\)는 수렴안함\n\nP@P@P\n\narray([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])\n\n\n- 특징2:\n- 특징3: 정상분포는 유일하게 존재함.\n\nπ = np.array([1/3,1/3,1/3]).reshape(3,1)\nπ\n\narray([[0.33333333],\n       [0.33333333],\n       [0.33333333]])\n\n\n\nπ.T @ P, π.T\n\n(array([[0.33333333, 0.33333333, 0.33333333]]),\n array([[0.33333333, 0.33333333, 0.33333333]]))\n\n\n- 특징4: 초기분포가 정상분포라면 정상확률과정\n- 특징5: 상태공간 \\(E\\)에 equivalence class 가 1개\n- 특징6: 주기성을 가짐 (주기는 3)\n\n관찰: 어떠한 상태 \\(x \\in E\\) 에 있더라도 반드시 3번 안에는 원래 상태로 되돌아옴.\n\n\n\n예제2\n- 아래와 같은 전이확률을 고려하자.\n\nP = np.array([0.0, 1.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 1.0,\n              0.0, 1.0, 0.0, 0.0,\n              1/3, 0.0, 2/3, 0.0]).reshape(4,4)\nP\n\narray([[0.        , 1.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 1.        ],\n       [0.        , 1.        , 0.        , 0.        ],\n       [0.33333333, 0.        , 0.66666667, 0.        ]])\n\n\n- 다이어그램\n\n\n\n\nflowchart LR\n  0 --&gt;|1| 1\n  1 --&gt;|1| 3\n  2 --&gt;|1| 1\n  3 --&gt;|1/3| 0 \n  3 --&gt;|2/3| 2\n\n\n\n\n\n- 특징1: \\({\\bf P}\\)는 수렴안함\n\nP@P@P@P\n\narray([[0.        , 1.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 1.        ],\n       [0.        , 1.        , 0.        , 0.        ],\n       [0.33333333, 0.        , 0.66666667, 0.        ]])\n\n\n- 특징2: Pass\n- 특징3: 정상분포는 유일하게 존재함.\n\nπ = (np.array([1,3,2,3])/9).reshape(4,1)\nπ\n\narray([[0.11111111],\n       [0.33333333],\n       [0.22222222],\n       [0.33333333]])\n\n\n\nπ.T @ P, π.T \n\n(array([[0.11111111, 0.33333333, 0.22222222, 0.33333333]]),\n array([[0.11111111, 0.33333333, 0.22222222, 0.33333333]]))\n\n\n어떻게 찾음?\n\neig_value, eig_vector_matrix = np.linalg.eig(P.T)\n\n\neig_value[2]\n\n(1.000000000000001+0j)\n\n\n\nπ = abs(eig_vector_matrix[:,2])\nπ = π/π.sum()\nπ\n\narray([0.11111111, 0.33333333, 0.22222222, 0.33333333])\n\n\n- 특징4: 초기분포가 정상분포라면 정상확률과정\n- 특징5: irr\n- 특징6: 주기성을 가짐 (주기는3)\n\n\n\n\nflowchart LR\n  0 --&gt;|1| 1\n  1 --&gt;|1| 3\n  2 --&gt;|1| 1\n  3 --&gt;|1/3| 0 \n  3 --&gt;|2/3| 2\n\n\n\n\n\n0에서 시작한다면?\n\n\\(0 \\to 1 \\to 3 \\to 0\\)\n\\(0 \\to 1 \\to 3 \\to 2 \\to 1 \\to 3 \\to 0\\)\n\\(0 \\to 1 \\to 3 \\to 2 \\to 1 \\to 3 \\to 2 \\to \\cdots\\)\n\n\n3번만에 되돌아오거나, 6번만에 되돌아오거나, 9번만에 되돌아오거나 … \\(\\Rightarrow\\) 주기는 3 (3,6,9의 최대공약수는 3)\n\n모든 상태에 대하여 주기가 3이면 \\(\\{x_t\\}\\)의 주기가 3\n1에서 시작한다면?\n\n\\(1 \\to 3 \\to 0 \\to 1\\)\n\\(1 \\to 3 \\to 2 \\to 1 \\to 3 \\to 0 \\to 1\\)\n\\(\\dots\\)\n\n2에서 시작한다면?\n3에서 시작한다면?\n\n꿀팁: HMC \\(\\{X_t\\}\\)가 irreducible 이라면 모든 \\(x \\in E\\) 는 같은 주기를 가진다.\n\n\n꿀팁: HMC \\(\\{X_t\\}\\)가 finite하고 irreducible 이라면 모든 \\(x \\in E\\) 는 같은 주기를 가진다."
  },
  {
    "objectID": "posts/ap/2023-04-25-ap-08wk.html",
    "href": "posts/ap/2023-04-25-ap-08wk.html",
    "title": "08wk: 측도론 (4)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-xlxvNIex1h6j7lUQALgCU1"
  },
  {
    "objectID": "posts/ap/2023-04-25-ap-08wk.html#cap_n1infty-frac1nfrac1n0",
    "href": "posts/ap/2023-04-25-ap-08wk.html#cap_n1infty-frac1nfrac1n0",
    "title": "08wk: 측도론 (4)",
    "section": "\\(\\cap_{n=1}^{\\infty}(-\\frac{1}{n},\\frac{1}{n})=\\{0\\}\\)",
    "text": "\\(\\cap_{n=1}^{\\infty}(-\\frac{1}{n},\\frac{1}{n})=\\{0\\}\\)\n- \\(\\cap_{n=1}^{\\infty}(-\\frac{1}{n},\\frac{1}{n}) =\\{0\\}\\)을 증명하라.\n(증명)\nstep1: \\(\\cap_{n=1}^{\\infty}(-\\frac{1}{n},\\frac{1}{n})\\)은 원소로 \\(0\\)을 포함한다.\n\\(\\forall n \\in \\mathbb{N}\\): \\(-\\frac{1}{n} &lt; 0 &lt; \\frac{1}{n}\\)\n\\(\\Leftrightarrow \\forall n \\in \\mathbb{N}\\): \\(0 \\in (-\\frac{1}{n},\\frac{1}{n})\\)\n\\(\\Leftrightarrow\\) \\(0 \\in (-\\frac{1}{1},\\frac{1}{1})\\) and \\(0 \\in (-\\frac{1}{2},\\frac{1}{2})\\) \\(\\dots\\)\n\\(\\Leftrightarrow\\) \\(0 \\in (-\\frac{1}{1},\\frac{1}{1}) \\cap (-\\frac{1}{2},\\frac{1}{2}) \\cap \\dots\\)\n\\(\\Leftrightarrow\\) \\(0 \\in \\cap_{n=1}^{\\infty}(-\\frac{1}{1},\\frac{1}{1})\\)\nstep2: \\(\\cap_{n=1}^{\\infty}(-\\frac{1}{n},\\frac{1}{n})\\)은 원소로 \\(0\\)보다 큰 임의의 양수를 포함하지 않는다.\n포함한다고 가정하자. 즉\n\\(\\exists \\delta &gt;0\\) such that \\(0+\\delta \\in \\cap_{n=1}^{\\infty}(-\\frac{1}{n},\\frac{1}{n})\\)\nNOTE: From \\(\\delta&gt;0\\), \\(\\exists N \\in \\mathbb{N}\\) such that \\(0&lt;\\frac{1}{N}&lt;\\delta\\)\nTHUS \\(\\delta \\notin (-\\frac{1}{N},\\frac{1}{N})\\) \\(\\Rightarrow\\) CONTRADICTION! (\\(\\because \\cap_{n=1}^{\\infty}(-\\frac{1}{n},\\frac{1}{n}) \\subset (-\\frac{1}{N},\\frac{1}{N}))\\)\nstep3: \\(\\cap_{n=1}^{\\infty}(-\\frac{1}{n},\\frac{1}{n})\\)은 원소로 \\(0\\)보다 큰 임의의 음수를 포함하지 않는다."
  },
  {
    "objectID": "posts/ap/2023-04-25-ap-08wk.html#vacuous-truth",
    "href": "posts/ap/2023-04-25-ap-08wk.html#vacuous-truth",
    "title": "08wk: 측도론 (4)",
    "section": "Vacuous truth",
    "text": "Vacuous truth\n- \\(P \\Rightarrow Q\\) 에서, \\(P\\)가 틀렸거나 \\(P\\)를 만족하는 집합이 공집합일 경우 \\(P\\Rightarrow Q\\)라는 명제는 항상 참이되고 이러한 참을 배큐어스 트루 라고 말한다.\n- 이해를 돕기 위한 예시\n\n명제1: 최규빈교수보다 나이 많은 학생은 A+를 받지 못했다.\n명제2: 최규빈교수보다 나이 많은 학생은 A+를 받았다.\n\n여기에서 명제1,명제2는 모두 참이어야 한다. 그래야 명제1,명제2의 대우는 모두 참이 되며\n\n대우1: A+를 받은 학생은 최규빈교수보다 나이가 적다.\n대우2: A+를 받지 못한 학생은 최규빈교수보다 나이가 적다.\n\n두 대우의 합성명제인 아래도 참이 된다.\n\nA+을 받거나 받지 못한 학생은 최규빈교수보다 나이가 적다."
  },
  {
    "objectID": "posts/ap/2023-04-25-ap-08wk.html#정의",
    "href": "posts/ap/2023-04-25-ap-08wk.html#정의",
    "title": "08wk: 측도론 (4)",
    "section": "정의",
    "text": "정의\n- 정의: \\(\\Omega\\)에 대한 부분집합의 모임 \\({\\cal T}\\)가 아래의 조건을 만족하면 \\({\\cal T}\\)를 \\(\\Omega\\)의 토폴로지라고 부른다.\n\n\\(\\emptyset, \\Omega \\in {\\cal T}\\)\n\\(\\forall A,B \\in {\\cal T}:~ A\\cap B \\in {\\cal T}\\) (finite intersection에 닫혀있음)\n\\(\\forall {\\cal A} \\subset {\\cal T}: ~ (\\cup_{A \\in {\\cal A}}A ) \\in {\\cal T}\\) (uncoutable union, arbitrary union에 닫혀있음)\n\n- \\((\\Omega,{\\cal T})\\)를 위상공간 (topological space) 이라고 부른다. 그리고 \\({\\cal T}\\)의 원소를 \\({\\cal T}\\)-open set이라고 부른다.\n- 모티브: 실수위에서의 열린구간 \\((a,b)\\)의 개념을 추상화하고 싶음. 즉 open interval \\(\\overset{일반화}{\\to}\\) open set 을 하고 싶음. 그리고 이러한 open set 만을 모은 collection \\({\\cal T}\\)라는 기호로 표현하고 싶음.\n\n관찰1: \\((1,3) \\cap (2,4) = (2,3)\\) // 2개의 open-interval을 교집합하니 open-interval이 나옴\n관찰2: \\(\\cap_{n=1}^{\\infty}(1-\\frac{1}{n},3+\\frac{1}{n}) =[1,3]\\) // countable many한 open-interval을 교집합하면 closed-interval이 나옴\n관찰3: \\(\\cup_{n=1}^{\\infty}(1+\\frac{1}{n},3-\\frac{1}{n})= (1,3)\\) // countable many한 open-interval을 합집합하면 open-interval이 나옴\n관찰4: \\(\\cup_{\\epsilon&gt;0}^{\\infty}(1+\\epsilon,3-\\epsilon) =(1,3)\\) // uncountalbe many한 open-interval을 합집합해도 open-interval이 나옴\n\n- 왜 open interval을 추상화하고 싶을까?\n\nopen interval은 엄청 특이한 성질이 있음. 구간 \\((a,b)\\)의 모든 점 \\(x\\)는 점 \\(x\\)를 포함하는 (아주 작은) 열린구간 \\((x-\\epsilon,x+\\epsilon)\\) 이 \\((a,b)\\)사이에 존재함.\n이 성질은 극한의 개념을 정의하기에 매우 유리하다. (따라서 연속, 끊어짐 등을 이해하기에도 좋다)\n\n- \\(\\Omega=\\mathbb{R}\\)일 경우 open-set\n\n\\((1,2)\\)\n\\((1,2)\\cup (5,6)\\)\n\\((a-\\epsilon, a+\\epsilon)\\), where \\(\\epsilon&gt;0\\) and \\(a\\in\\mathbb{R}\\)\n\\(\\dots\\)\n\n- 체크\n\n\\(\\Omega=\\mathbb{R}\\), \\({\\cal T}=\\{\\emptyset, \\Omega\\}\\)라고 하자. \\({\\cal T}\\)는 \\(\\Omega\\)에 대한 토폴로지이며 따라서 \\((\\Omega, {\\cal T})\\)는 위상공간이 된다.\n\\(\\Omega=\\mathbb{R}\\), \\({\\cal T}=2^{\\mathbb{R}}\\)라고 하자. 그렇다면 \\({\\cal T}\\)는 \\(\\Omega\\)에 대한 토폴로지이며 따라서 \\((\\Omega,{\\cal T})\\)는 위상공간이 된다.\n\n그렇지만 우린 이런걸 쓰고 싶은게 아니야 (\\(\\star\\))"
  },
  {
    "objectID": "posts/ap/2023-04-25-ap-08wk.html#짧은지식",
    "href": "posts/ap/2023-04-25-ap-08wk.html#짧은지식",
    "title": "08wk: 측도론 (4)",
    "section": "짧은지식",
    "text": "짧은지식\n- 이론: \\(\\Omega=\\mathbb{R}\\) 일때 \\({\\cal U}=\\{O:O = \\cup_{i=1}^{\\infty}(a_i, b_i),~ a_i\\leq b_i \\in \\mathbb{R}\\}\\)라고 하자. 즉 \\({\\cal U}\\)는 open interval의 countable union으로 표현가능한 집합들의 모임이다. 그렇다면 \\((\\mathbb{R}, {\\cal U})\\)는 위상공간이 된다.\n\n그리고 특별히 이러한 위상 \\({\\cal U}\\)를 \\(\\mathbb{R}\\)에서의 standard topology, Euclidean topology, 혹은 usual topology 라고 부른다. 사실 \\({\\cal U}\\)가 바로 우리가 토폴로지를 정의하는 이유이다 (매우 중요하다는 뜻이에요)\n\n\n\\({\\cal U}\\)의 원소를 원래 엄밀하게는 \\({\\cal U}\\)-open set이라고 불러야 하지만 이 경우는 \\({\\cal U}\\)를 생략하여 open set 이라고 부르기도 한다. 즉 우리가 일반적으로 말하는 “실수 \\(\\mathbb{R}\\)에서의 열린집합, 혹은 그냥 열린집합” 은 \\({\\cal U}\\)-open set을 의미한다.\n\n\n이 이론이 의미하는 바는 (1) 실수에서의 열린구간의 일반화 버전은 열린집합이며 (2) 열린집합은 열린구간의 가산합집합으로 표현가능하다 라는 뜻이다.\n\n\n\\({\\cal U}\\)를 한글로는 보통위상이라고 표현하기도 하지만 그렇게 널리 사용되지는 않는다. 하지만 따로 지칭할 용어가 마땅치 않아서 나는 그냥 보통위상이라고 부르겠다.\n\n- 이론: \\((\\mathbb{R},{\\cal U})\\)를 보통위상공간 (usual topological space) 이라고 하자. 모든 \\(O \\in {\\cal U}\\) 는 아래를 만족한다.\n\n\\(\\forall o \\in O, \\exists a,b \\in \\mathbb{R}\\) such that \\(o \\in (a,b) \\subset O \\quad \\cdots (\\star)\\)\n\n\n참고로 어떠한 집합 \\(O\\)에 대하여 \\((\\star)\\)를 만족하는 원소 \\(o\\)를 interior point of \\(O\\) 라고 부른다. 따라서 어떤 집합의 모든 원소가 그 집합의 interior point라면 그 집합은 openset이라고 해석할 수 있다.\n\n\n저는 나이테정리라고 외웠어요..\n\n- 실수에서의 \\({\\cal U}\\)-openset 을 정의하는 방법\n\n열린구간의 가산합집합\n모든원소가 interior point인 집합\n\n- 위상공간 \\((\\mathbb{R},{\\cal U})\\)를 고려하자. 여기에서 \\({\\cal U}=\\{O:O = \\cup_{i=1}^{\\infty}(a_i, b_i),~ a_i\\leq b_i \\in \\mathbb{R}\\}\\)를 의미한다. 아래의 사실들을 관찰하라.\n\n모든 열린구간은 열린집합이다.\n\\((-\\infty, a)\\)와 \\((a,\\infty)\\)는 모두 열린집합이다.\n한점의 원소 \\(\\{a\\}\\)는 닫힌집합이다. (\\(\\{a\\}\\)의 여집합이 열린집합이므로)\n\\((-\\infty, a]\\)와 \\([a,\\infty)\\)는 모두 닫힌집합이다.\n공집합과 \\(\\mathbb{R}\\)은 열린집합이다.1 따라서 공집합과 \\(\\mathbb{R}\\)은 닫힌집합이다."
  },
  {
    "objectID": "posts/ap/2023-04-25-ap-08wk.html#시그마필드-vs-토폴로지",
    "href": "posts/ap/2023-04-25-ap-08wk.html#시그마필드-vs-토폴로지",
    "title": "08wk: 측도론 (4)",
    "section": "시그마필드 vs 토폴로지",
    "text": "시그마필드 vs 토폴로지\n\n\n\n\n\n\n\n\n\n시그마필드\n토폴로지\n\n\n\n\n시작\n“길이를 잴 수 있는 집합”이란 개념을 일반화 하고 싶다\n“열린구간”의 개념을 일반화 하고 싶다\n\n\n기호\n\\({\\cal F}\\)\n\\({\\cal T}\\)\n\n\n공간\n\\((\\Omega,{\\cal F})\\)\n\\((\\Omega,{\\cal T})\\)\n\n\n원소\n\\({\\cal F}\\)-measurable set, measurable set\n\\({\\cal T}\\)-open set\n\n\n쓸모없는공간\n\\((\\mathbb{R},2^{\\mathbb R})\\)\n\\((\\mathbb{R},2^{\\mathbb R})\\)\n\n\n쓸모있는공간\n\\((\\mathbb{R},{\\cal R})\\)\n\\((\\mathbb{R},{\\cal U})\\)\n\n\n\n\n\\({\\cal R}\\)이 뭔데..?"
  },
  {
    "objectID": "posts/ap/2023-04-25-ap-08wk.html#borel-sigma-field",
    "href": "posts/ap/2023-04-25-ap-08wk.html#borel-sigma-field",
    "title": "08wk: 측도론 (4)",
    "section": "Borel \\(\\sigma\\)-field",
    "text": "Borel \\(\\sigma\\)-field\n- 정의: \\((\\mathbb{R}, {\\cal U})\\)를 보통위상공간이라고 하자. 아래와 같은 시그마필드를 Borel \\(\\sigma\\)-algebera on \\(\\mathbb{R}\\)이라고 한다.\n\\[{\\cal B}(\\mathbb{R}):=\\sigma({\\cal U})\\]\n그리고 \\({\\cal B}(\\mathbb{R})\\)의 원소를 Borel measurable sets이라고 부른다.\n- 참고: 교재에서는 \\({\\cal B}(\\mathbb{R})\\)를 \\({\\cal R}\\)로 표현하기도 한다.\n- 이론: 아래와 같은 집합을 고려하자.\n\n\\({\\cal A}_1:= \\{A\\subset \\mathbb{R}: A \\text{ is open}\\}\\)2\n\\({\\cal A}_2:= \\{(a,b): a,b \\in \\mathbb{R}, a&lt;b\\}\\)\n\\({\\cal A}_3:= \\{[a,b): a,b \\in \\mathbb{R}, a&lt;b\\}\\)\n\\({\\cal A}_4:= \\{(a,b]: a,b \\in \\mathbb{R}, a&lt;b\\}\\)\n\\({\\cal A}_5:= \\{[a,b]: a,b \\in \\mathbb{R}, a&lt;b\\}\\)\n\\({\\cal A}_6:= \\{(-\\infty,b): a,b \\in \\mathbb{R}, a&lt;b\\}\\)\n\\({\\cal A}_7:= \\{(-\\infty,b]: a,b \\in \\mathbb{R}, a&lt;b\\}\\)\n\\({\\cal A}_8:= \\{(a,\\infty): a,b \\in \\mathbb{R}, a&lt;b\\}\\)\n\\({\\cal A}_9:= \\{[a,\\infty): a,b \\in \\mathbb{R}, a&lt;b\\}\\)\n\n아래가 성립한다.\n\\[{\\cal R}:={\\cal B}(\\mathbb{R}) = \\sigma({\\cal A}_1)=\\sigma({\\cal A}_2)=\\dots=\\sigma({\\cal A}_9)\\]\n(증명??) – 증명까지는 아니고 그냥 설명..\n\n예비학습1: countable union의 countable union은 countable union이다.\n\\[\\mathbb{Q}^+ = \\cup_{m \\in \\mathbb{N}}\\big(\\cup_{n \\in \\mathbb{N}}\\{m/n\\}\\big)\\]\n예비학습2: “\\(\\sigma({\\cal A}_1)\\)의 모든원소는 \\({\\cal A}_1\\)의 원소를 재료로하여 만들수 있다” 라고 표현할 수 있으며, 여기에서 “만들 수 있다” 라는 의미는 \\({\\cal A}_1\\)의 원소에 가산합집합, 가산교집합, 여집합, 차집합등의 연산을 적용하여 \\(\\sigma({\\cal A})\\)의 원소를 만들 수 있다라는 의미이다.\n예비학습3: 아래의 연산들은 모두 시그마필드에서 닫혀있다.\n\n가산합집합의 가산합집합\n가산합집합의 가산합집합의 가산합집합\n여집합의 가산교집합의 가산합집합의 차집합\n\\(\\dots\\)\n\n즉 시그마필드는 가산합집합과, 여집합에 닫혀있고 그들의 합성연산에 닫혀있다고 해석할 수 있다.\n\n이제 아래가 성립한다고 가정해보자.\n\n\\(\\sigma({\\cal A}_1)\\)의 모든 원소는 \\({\\cal A}_1\\)의 원소를 이용하여 만들 수 있다. 즉 \\({\\cal A}_1\\)의 모든원소에 가산합집합, 여집합, 혹은 그들의 합성연산을 적용하여 \\(\\sigma({\\cal A}_1)\\)의 모든 원소를 나타낼 수 있다.\n\\({\\cal A}_1\\)의 모든 원소는 \\({\\cal A}_2\\)의 원소를 이용하여 만들 수 있다. 즉 \\({\\cal A}_1\\)의 모든원소에 가산합집합, 여집합 혹은 그들의 합성연산을 적용하여 \\({\\cal A}_2\\)의 모든 원소를 나타낼 수 있다.\n\n그렇다면 궁극적으로는 \\({\\cal A}_2\\)의 원소를 가산합집합, 여집합, 혹은 그들의 합성연산을 적용하여 \\(\\sigma({\\cal A}_1)\\)를 표현할 수 있다는 의미이고 이는 \\({\\cal R}=\\sigma({\\cal A}_1)=\\sigma({\\cal A}_2)\\)를 의미한다. \\({\\cal R}=\\sigma({\\cal A}_3)=\\sigma({\\cal A}_4)=\\dots=\\sigma({\\cal A}_9)\\) 역시 유사하게 따질 수 있다.\n- 이론: 위의 이론의 \\({\\cal A}_2,\\dots,{\\cal A}_9\\)에서 \\(\\mathbb{R}\\) 대신에 \\(\\mathbb{Q}\\)를 사용해도 성립한다.\n- NOTE: \\({\\cal A}_1,\\dots,{\\cal A}_9\\)는 모두 파이시스템이다."
  },
  {
    "objectID": "posts/ap/2023-04-25-ap-08wk.html#르벡메져",
    "href": "posts/ap/2023-04-25-ap-08wk.html#르벡메져",
    "title": "08wk: 측도론 (4)",
    "section": "르벡메져",
    "text": "르벡메져\n- Thm: \\(\\Omega=\\mathbb{R}\\) 에 대하여 아래와 같은 collection \\({\\cal A}\\)를 고려하자.\n\\[{\\cal A}=\\{(a,b]: a,b\\in \\mathbb{R}, a&lt;b\\}\\]\n그리고 아래와 같은 함수 \\(\\tilde{m}:{\\cal A} \\to [0,\\infty]\\)을 고려하자.\n\\[\\tilde{m}((a,b]) = b-a\\]\n이러한 함수 \\(\\tilde{m}\\)은 \\((\\mathbb{R},{\\cal R})\\)에서의 메져 \\(m:{\\cal R} \\to [0,\\infty]\\)로 쉽게 업그레이드 가능하며 이 업그레이드 결과는 유일하다.\n(증명)\n카라테오도리의 확장정리에 의하여\n\n\\({\\cal A}\\)가 세미링임을 체크하고\n\\(\\tilde{m}:{\\cal A}\\to[0,\\infty]\\)이 \\({\\cal A}\\)에서 (1) additive (2) \\(\\sigma\\)-subadditive (3) \\(\\sigma\\)-finite 을 만족한다는 사실을 체크하면 된다.\n\n된다. \\(\\tilde{m}\\)이 \\(\\sigma\\)-subaddtive 성질을 가진다는 것을 보이는 것이 어려운데 이는 받아들이자.\n- 정의: 위의 이론에 의하여 업그레이드 된 메져 \\(m\\)을 르벡메져라고 한다.\n- 이론: \\((\\mathbb{R},{\\cal R})\\)를 잴 수 있는 공간이라고 하고, \\(m\\)을 이 공간에서의 르벡메져라고 하자. 아래와 같은 집합들의 모임을 생각하자.\n\n\\({\\cal A}_1:= \\{A\\subset \\mathbb{R}: A \\text{ is open}\\}\\)\n\\({\\cal A}_2:= \\{(a,b): a,b \\in \\mathbb{R}, a&lt;b\\}\\)\n\\({\\cal A}_3:= \\{[a,b): a,b \\in \\mathbb{R}, a&lt;b\\}\\)\n\\({\\cal A}_4:= \\{(a,b]: a,b \\in \\mathbb{R}, a&lt;b\\}\\)\n\\({\\cal A}_5:= \\{[a,b]: a,b \\in \\mathbb{R}, a&lt;b\\}\\)\n\\({\\cal A}_6:= \\{(-\\infty,b): a,b \\in \\mathbb{R}, a&lt;b\\}\\)\n\\({\\cal A}_7:= \\{(-\\infty,b]: a,b \\in \\mathbb{R}, a&lt;b\\}\\)\n\\({\\cal A}_8:= \\{(a,\\infty): a,b \\in \\mathbb{R}, a&lt;b\\}\\)\n\\({\\cal A}_9:= \\{[a,\\infty): a,b \\in \\mathbb{R}, a&lt;b\\}\\)\n\n\\({\\cal A}_1,{\\cal A}_2,\\dots, {\\cal A}_9\\)에서의 르벡메져와 그 값이 일치하지만 \\({\\cal R} - {\\cal A}_1, \\dots, {\\cal R}-{\\cal A}_9\\) 등에서는 일치하지 않는 새로운 메져 \\(m'\\)은 존재할 수 없다. 즉 르벡메져는 \\({\\cal A}_1,\\dots,{\\cal A}_9\\)에서의 값으로 유일하게 결정된다.\n(설명)\n르벡메져는 \\(\\sigma\\)-finite한 메져이고, \\({\\cal A}_{1}\\dots{\\cal A}_{9}\\)는 모두 “7wk-파이시스템에서의 확장이론(메져버전)”에 소개된 이론의 조건 1,2를 만족하는 파이시스템이다. 따라서 르벡메져의 값은 \\({\\cal A}_1\\dots,{\\cal A}_9\\)에서의 값으로 유일하게 결정된다."
  },
  {
    "objectID": "posts/ap/2023-04-25-ap-08wk.html#생략때문에-헷갈려",
    "href": "posts/ap/2023-04-25-ap-08wk.html#생략때문에-헷갈려",
    "title": "08wk: 측도론 (4)",
    "section": "생략때문에 헷갈려",
    "text": "생략때문에 헷갈려\n- 어떠한 수학교재에서, 아무말 없이 open set 이라고만 하면 보통위상공간 (usual topological space) 으로부터 정의되는 open set을 의미한다. 즉 usual topological space \\((\\mathbb{R},{\\cal U})\\)에서 \\({\\cal U}\\)의 원소를 의미한다.\n- 어떠한 수학교재에서, 아무말 없이 measurable set 이라고 하면 르벡측도로 잴 수 있는 집합을 말한다. 즉 \\((\\mathbb{R}, {\\cal R})\\) 에서의 \\({\\cal R}\\)의 원소를 의미한다. 즉 일반적으로 정의하는 “잴 수 있는 집합”에서 “잴 수 있다”는 의미는 “르벡측도로 잴 수 있다”는 의미이다.3 일반적인 \\((\\Omega, {\\cal F})\\)에서 \\({\\cal F}\\)의 원소는 ${F}-measurable set 이라고 표현해야 옳다.\n- 하지만 때에 따라서는 \\({\\cal F}\\)의 원소를 그냥 measurable set이라고 부른다.\n예시1\n여기에서 measuralbe set은 앞에서 정의한 \\({\\cal F}\\)의 원소라는 의미이다.\n\n\n\n그림1: measurable set에 대한 교재의 언급, 눈치껏 그전의 문맥에서 정의한 \\({\\cal F}\\)-measurable set을 의미함을 알아들어야 함\n\n\n- measure, measurable 등의 의미는 눈치껏 알아먹어야 한다.\n예시2\n일반적으로 measure라는 단어가 사용되면 “르벡측도로 재다”라는 의미를 지칭하는 경우가 많음\n\n\n\n그림2: 여기에서 사용되는 “measure”의 의미는 문맥상 “르벡측도로 재다”라는 의미로 해석해야함\n\n\n예시3\n\\((\\Omega, {\\cal F})\\)를 잴 수 있는 공간이라고 할 때는 meaure의 의미가 꼭 “르벡측도로 재다” 라는 것을 의미하는 건 아님\n예시4\n비탈리집합이 nonmeasurable set이라는 의미는 르벡측도로 측정불가능한 집합이라는 것을 의미함.\n\n\n\n그림3: 여기에서 \\(N\\)은 비탈리집합을 의미하며 여기에서 “nonmeasurable” 이라는 뜻은 르벡메져로 측정불가능한 집합이라는 의미"
  },
  {
    "objectID": "posts/ap/2023-04-25-ap-08wk.html#토폴로지와-측도론의-논리전개",
    "href": "posts/ap/2023-04-25-ap-08wk.html#토폴로지와-측도론의-논리전개",
    "title": "08wk: 측도론 (4)",
    "section": "토폴로지와 측도론의 논리전개",
    "text": "토폴로지와 측도론의 논리전개\n- 토폴로지와 측도론을 공부하면서 비슷한점이 있다고 느낌\n- 비슷한점1: 모두 어떠한 속성을 가지는 집합을 “일반화” 하기 위해서 생겨났다. 예를들면, 잴 수 있는 집합이라는 것은 “수직선에서 길이를 잴 수 있는 집합”의 개념을 일반화하고 싶었어서 만들었으며, 열린집합이라는 것은 “수직선에서의 열린구간”이라는 개념을 일반화하고 싶어서 만들었다.\n- 비슷한점2: 따라서 “잴 수 있는 집합들의 모임”, “열린집합들의 모임” 이라는 집합들의 집합이라는 장치를 고안하였다. 그리고 이러한 과정에서 일반적인 “길이(length)를 잴 수 있는 집합”의 속성, “열린구간”의 속성을 모아 “잴 수 있는 집합의 모임”, “열린집합의 모임” 을 정의하는 재료로 사용하였다.\n- 비슷한점3: “잴 수 있는 집합들의 모임”, “열린집합들의 모임”의 원소를 각각 \\({\\cal F}\\)-mesurable set, \\({\\cal T}\\)-open set이라고 부르는 것도 유사하다.\n- 비슷한점4: \\(\\Omega=\\mathbb{R}\\)에 대한 시그마필드와 토폴로지가 각각 \\({\\cal R}\\)이거나 \\({\\cal U}\\)이라면 그냥 잴 수 있는 집합, 열린 집합 이라고 부르는 것도 유사하다.\n- 비슷한점5: 비슷한점4의 경우를 제외하고는 \\({\\cal F}\\)-mesurable set, \\({\\cal T}\\)-open set이라고 부르는게 원칙인데 이것도 문맥에 따라서 그냥 생략하고 쓰는 것도 유사하다. (사실 매번 언급하는게 귀찮기는 해)\n- 비슷한점6: 일반화의 과정에서 발생하는 이상한 개념의 충돌이 존재한다.\n\n잴 수 있는 집합의 모임을 \\((\\mathbb{R},2^\\mathbb{R})\\)로 설정하면 비탈리집합도 잴 수 있다. (그렇지만 \\((\\mathbb{R}, {\\cal R})\\)에서는 비탈리집합이 잴 수 없는 집합이므로 보통 책에서는 “잴 수 없는 집합”이라고 배운다)\n열린집합의 모임을 \\((\\mathbb{R},2^\\mathbb{R})\\)로 설정하면 한점만 포함하는 집합 \\(\\{x\\}\\)는 열린집합이 된다. (그렇지만 \\((\\mathbb{R},{\\cal U})\\)에서는 한점만 포함하는 집합은 닫힌집합이므로 보통 책에서는 “한점만 포함하는 집합은 닫힌집합이다” 라고 배운다.\n\n\n제 생각: 사실 이는 일반화 과정이 겪는 불가피한 문제인듯 해요. “문자, 그림, 기호 따위를 쓸 수 있는 도구” 정도로 펜슬의 의미를 확장하면 손가락도 펜슬이 되고, 발가락도 펜슬이 됩니다.\n\n- 비슷한점7: 열린집합과 토폴로지, 잴수있는 집합과 시그마필드를 정의하는 두가지 루트가 존재한다.\n\n루트1: 토폴로지를 먼저 정의하고 토폴로지의 원소가 열린집합이라고 정의한다. 혹은 시그마필드를 먼저 정의하고 시그마필드의 원소가 잴 수 있는 집합이라고 정의한다.\n루트2: 열린집합을 정의하고 (집합의 모든 원소가 interior point이면 열린집합), 열린집합의 모임으로 토폴로지를 정의한다. 혹은 잴 수 있는 집합을 정의하고, 잴 수 있는 집합의 모임으로 시그마필드를 정의한다."
  },
  {
    "objectID": "posts/ap/2023-04-20-8wk-1.html",
    "href": "posts/ap/2023-04-20-8wk-1.html",
    "title": "08wk-1: 마코프체인 (4)",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-yapWz131weSlgUlgS-0T98\n\n\n영상2는 추후 재촬영예정임\n\n\n\nimports\n\nimport numpy as np\n\n\n\nMarkovchain, Transition Matrix\n- 정의: 카운터블한 상태공간 \\(E\\)을 가지는 이산시간 확률과정 \\(\\{X_t\\}_{t\\geq 0}\\)을 고려하자. 아래가 성립한다면 확률과정 \\(\\{X_t\\}\\)을 마코프체인(Markov chain, MC)라고 한다.\n\n\\(\\forall t\\geq 0, \\forall i_0,i_1,\\dots,i_{n-1},i,j \\in E\\):\n\n\\[\\mathbb{P}(X_{t+1}=j | X_t=i, X_{t-1}=i_{t-1}, \\dots, X_0=i_0) = \\mathbb{P}(X_{t+1}=j|X_t=i)\\]\n만약에 \\(P(X_{t+1} =j | X_t=i)\\)가 모든 \\(t\\)에 대하여 일정하다면 \\(\\{X_t\\}\\)를 균질마코프체인1(homogeneous Markov chain, HMC) 라고 한다.\n- 정의: 아래의 수식을 마코프성질 (Markov property) 이라고 한다.\n\n\\(\\forall t\\geq 0, \\forall i_0,i_1,\\dots,i_{n-1},i,j \\in E\\):\n\n\\[\\mathbb{P}(X_{t+1}=j | X_t=i, X_{t-1}=i_{t-1}, \\dots, X_0=i_0) = \\mathbb{P}(X_{t+1}=j|X_t=i)\\]\n- 정의: 카운터블한 상태공간 \\(E\\)를 가지는 HMC \\(\\{X_t\\}_{t\\geq 0}\\)를 고려하자. 상태 \\(i\\)에서 상태 \\(j\\)로 바뀌는 조건부 확률\n\\[p_{ij}=\\mathbb{P}(X_{t+1}=j | X_t=0)\\]\n를 \\(\\{X_t\\}_{t\\geq 0}\\)의 전이확률(transition probability)라고 한다.\n- 전이확률의 특징: 이때 전이확률은 아래의 특징을 가진다.\n\n\\(p_{ij} \\geq 0\\)\n\n\\(\\sum_{j\\in E}p_{ij}=1\\)\n\n첫번째 식은 확률이 양수이어야 한다는 내용이고2 두번째 식은 임의의 시점에서 상태 \\(i\\)에 존재할 경우, 그 다음시점에서 상태집합 \\(V\\) 중 어딘가로는 이동해야한다는 의미이다.\n- 정의: 카운터블한 상태공간 \\(V\\)를 가지는 HMC \\(\\{X_t\\}_{t \\geq 0}\\)를 고려하자. \\(p_{ij}\\)를 \\(\\{X_t\\}_{t\\geq 0}\\)의 전이확률이라고 하자. \\((i,j)\\)-th 원소를 \\(p_{ij}\\)로 가지는 행렬 \\({\\bf P}\\)를 전이확률행렬 (transition probability matrix) 혹은 줄여서 전이행렬 (transition matrix) 이라고 한다.\n- 참고(\\(\\star\\)): 상태공간 \\(V\\)의 원소수가 무한일 수도 있으므로, 원래 \\({\\bf P}\\)를 행렬이라고 하기에는 무리가 있다. 하지만 행렬의 덧셈, 행렬의 곱셈과 같은 연산들은 일반적으로 잘 정의되므로 \\({\\bf P}\\)를 행렬로 생각할 수 있다. 이러한 \\({\\bf P}\\)는 row와 col이 무한대로 있다고 생각하면 된다.\n\n\\(|E|=\\infty\\) 인 경우 \\({\\bf P}\\)의 예시: \\({\\bf P}=\\begin{bmatrix} p_{00} & p_{01} & \\cdots \\\\ p_{10} & p_{11} & \\cdots \\\\ \\cdots & \\cdots & \\cdots \\end{bmatrix}\\)\n\n- 전이행렬의 특징: 모든 row의 합이 1이다.\n\n\\(\\sum_{j \\in E}p_{ij} = 1\\) 이어야 하므로\n\n\n\nDistribution, Distribution Function\n- 예제1: 동전예제\n선언1: \\((\\Omega, 2^{\\Omega}, \\mathbb{P})\\) 를 확률공간이라고 하자. 여기에서 확률 \\(\\mathbb{P}\\)은 아래와 같이 정의되는 set function 이다.\n\n\\(\\mathbb{P}(\\emptyset) = 0\\)\n\\(\\mathbb{P}(\\{H\\}) = 1/2\\)\n\\(\\mathbb{P}(\\{T\\}) = 1/2\\)\n\\(\\mathbb{P}(\\Omega) = 1\\)\n\n선언2: 확률변수 \\(X: (\\Omega, 2^\\Omega) \\to (E,2^E)\\)를 아래와 같이 선언하자. (단, \\(E=\\{0,1\\}\\))\n\n\\(X(H) = 0\\)\n\\(X(T) = 1\\)\n\n생각: 이제 \\(B \\in 2^V\\) 에 대하여 아래와 같은 표현들을 고려하자.\n\n표현1: \\(\\mathbb{P}(X \\in B)\\) // 고등학교 부터 쓰던 그 표현\n표현2: \\(\\mathbb{P}(\\{\\omega: X(\\omega) \\in B\\})\\) // 이번에 배운 표현, 표현1의 정확한 버전\n표현3: \\(\\mathbb{P}(X^{-1}(B))\\) // 표현2의 다른 버전, inverse image의 느낌이 확 살아 있음\n표현4: \\((\\mathbb{P} \\circ X^{-1})(B)\\) // 생각해보니까 이것도 가능함. \\(\\mathbb{P}\\), \\(X\\) 모두 함수였잖아?\n\n새로운 함수 \\(\\mu:= \\mathbb{P}\\circ X^{-1}\\)는 이 경우 어떻게 정의할 수 있을까?\n\n\\(\\mu(\\emptyset) = 0\\)\n\\(\\mu(\\{0\\}) = \\frac{1}{2}\\)\n\\(\\mu(\\{1\\}) = \\frac{1}{2}\\)\n\\(\\mu(\\{0,1\\}) = 1\\)\n\n표현1과 4만 모아서 살펴보면 아래와 같다.\n\n\\(\\mu(\\emptyset) = 0\\) \\(\\Leftrightarrow\\) \\(\\mathbb{P}(X \\notin \\{0,1\\})=0\\)\n\\(\\mu(\\{0\\}) = \\frac{1}{2}\\) \\(\\Leftrightarrow\\) \\(\\mathbb{P}(X=0)\\)\n\n\\(\\mu(\\{1\\}) = \\frac{1}{2}\\) \\(\\Leftrightarrow\\) \\(\\mathbb{P}(X=1\\})\\)\n\\(\\mu(\\{0,1\\}) = \\frac{1}{2}\\) \\(\\Leftrightarrow\\) \\(\\mathbb{P}(X\\in \\{0,1\\})\\) \\(\\Leftrightarrow\\) \\(\\mathbb{P}(X\\leq 1)\\)\n\n\\(\\mu\\)를 적당히 바꿔서 cdf로 나타낼 수 있다.\n- 예제2: 동전예제(2)\n\\((E,2^E)\\) 대신에 \\((\\mathbb{R},{\\cal R})\\) 으로 바꾸어도 위의 동전예제는 잘 정의된다.\n선언1: \\((\\Omega, 2^{\\Omega}, \\mathbb{P})\\) 를 확률공간이라고 하자. 여기에서 확률 \\(\\mathbb{P}\\)은 아래와 같이 정의되는 set function 이다.\n\n\\(\\mathbb{P}(\\emptyset) = 0\\)\n\\(\\mathbb{P}(\\{H\\}) = 1/2\\)\n\\(\\mathbb{P}(\\{T\\}) = 1/2\\)\n\\(\\mathbb{P}(\\Omega) = 1\\)\n\n선언2: 확률변수 \\(X: (\\Omega, 2^\\Omega) \\to (\\mathbb{R},{\\cal R})\\)를 아래와 같이 선언하자.\n\n\\(X(H) = 0\\)\n\\(X(T) = 1\\)\n\n생각: 이제 \\(B \\in {\\cal R}\\) 에 대한 표현들. 편의상 \\(B=\\{b: b\\leq 0.5\\}\\) 라고 가정하자.\n\n표현1: \\(\\mathbb{P}(X \\in B)=\\mathbb{P}(X\\leq 0.5)=\\mathbb{P}(X=0)=\\frac{1}{2}\\)\n표현2: 생략\n표현3: 생략\n표현4: \\((\\mathbb{P} \\circ X^{-1})((-\\infty,0.5])\\)\n\n표현1과 4만 모아서 살펴보면 아래와 같다.\n\n\\(\\mu((-\\infty,x])\\) \\(\\Leftrightarrow\\) \\(\\mathbb{P}(X \\leq x)\\)\n\\(\\mu(A)\\) \\(\\Leftrightarrow\\) \\(\\mathbb{P}(X\\in A)\\)\n\n\\(X\\)에 포함될 확률\n- 생각의 시간\n\\((\\Omega,{\\cal F}, \\mathbb{P})\\)가 확률공간이고 \\(X \\to \\mathbb{R}\\)이 확률변수라면, \\(\\mu\\)는 언제나 잘 정의된다.\n\n모든 \\(B \\in {\\cal R}\\)에 대하여 \\(X^{-1}(B)\\)가 시그마필드의 원소가 아닐 수 없다. (만약 그렇다면 \\(X\\)는 확률변수가 아닌걸?)\n모든 \\(B \\in {\\cal R}\\)에 대하여 \\(\\mathbb{P}(X^{-1}(B))\\)의 값을 모순되게 정의할 수 없다. (만약 그렇다면 \\((\\Omega, {\\cal F}, \\mathbb{P})\\)는 확률공간이 아닌걸?)\n\n결론: \\(\\mu\\)는 안전해!\n확률공간, 확률변수를 잘 선언한다는 가정하에\n- \\(\\mu\\)도 메져의 조건을 만족한다.\n\n정의역이 시그마필드임\n\\(\\forall B \\in {\\cal R}:~ \\mu(B)\\geq 0\\).\n\\(\\forall B_1,B_2,\\dots \\in {\\cal R}\\) such that \\(B_1,B_2 \\dots\\) are disjoint: \\(\\sum_{i=1}^{n}\\mu(B_i) = \\mu(\\uplus_{i=1}^{\\infty}B_i)\\)\n\n- \\(\\mu\\)를 부르는 용어 (\\(\\star\\star\\star\\)): \\(X\\)를 확률공간 \\((\\Omega, {\\cal F}, \\mathbb{P})\\)에서 정의된 확률변수라고 하자. 이때 \\(X^{-1}\\circ \\mathbb{P}\\)로 정의가능한 함수 \\(\\mu: {\\cal R} \\to [0,1]\\) 를 \\(X\\)의 distribution 이라고 부른다.\n- \\(F(x)\\)의 정의: \\(X\\)를 확률공간 \\((\\Omega, {\\cal F}, \\mathbb{P})\\)에서 정의된 확률변수라고 하자. \\(F: \\mathbb{R} \\to [0,1]\\) 인 함수를 아래와 같이 정의하자.\n\\[F(x) = \\mu((-\\infty, x])\\]\n이러한 함수 \\(F\\)는 아래와 같이 표현할 수 있다.\n\\[F(x) = \\mathbb{P}(X \\leq x)\\]\n함수 \\(F\\)를 확률변수 \\(X\\)의 distribution function 이라고 한다.\n- 참고사항 (그냥 교양임, 시험에 안냄):\n\n\\(\\mu\\)가 언제나 잘 정의되므로 \\(F(x)\\)도 언제나 잘 정의된다.\n\\(F(x)\\)는 어떠한 성질들을 가진다. (비감소함수, 오른쪽연속 등..)\n\\(F(x)\\)는 \\(F(x)= F_c(x) + F_s(x) + F_d(x)\\) 와 같이 분해가능하다.\n\\(F(x)=F_c(x)\\)라면 \\(F(x)\\)는 연속형확률변수의 cdf가 된다. \\(F(x)=F_d(x)\\)라면, \\(F(x)\\)는 이산형확률변수의 cdf가 된다.\n\\(F(x)=F_c(x)+F_d(X)\\)라면 혼합형확률변수의 cdf가 된다.\n\\(F(x)=F_s(x)\\)인 경우는 pdf, pmf가 존재하지 않는다.\n\n- Borel sets (어떤 학생이 헷갈려해서.. 제가 헷갈리게 설명해서..)\n\n\\(\\Omega=\\mathbb{R}\\) 일때 \\(2^{\\mathbb{R}}\\) 역시 시그마필드임.\n따라서 적당한 메져가 존재하여 \\(2^\\mathbb{R}\\)의 모든 집합을 잴 수 있음. (모든 원소를 0으로 측정하는 메져라든가..)\n하지만 르벡메져는 \\(2^{\\mathbb{R}}\\)의 모든 원소를 잴 수 없음. 따라서 \\(2^{\\mathbb{R}}\\)의 모든 원소에서 확률을 정의하는 것이 불가능함.\n그러나 \\(\\Omega=\\mathbb{R}\\)일때 \\({\\cal R}\\)이라는 시그마필드는 모든 원소에서 확률을 정의할 수 있음.\n\\({\\cal R}\\)을 Borel sets 이라고 부름.\n\n르벡 메져가 잘 정의되는 공간 = 보렐 셋\n- \\(\\mathbb{R}\\)을 포함하는 Borel sets 은 \\({\\cal B}(\\mathbb{R})\\)로 표현하기도 함. 즉 \\({\\cal R} = {\\cal B}(\\mathbb{R})\\) 이다.\n\n\nThe Stationary Distribution of an HMC\n- 정의: stationary distribution (정확한 버전)\n\\((E,{\\cal B}(E))\\)를 잴 수 있는 공간이라고 하고 \\(\\mu\\)를 \\((E,{\\cal B}(E))\\)에서의 distribution 이라고 하자. 만약에 아래식을 만족하면 \\(\\mu\\) 를 stationary distribution 이라고 한다.\n\\[\\mu p = \\mu\\]\n여기에서 \\(\\mu p(\\{x\\}):= \\sum_{y \\in E} \\mu(\\{y\\})p_{yx}\\) 를 의미한다.\n상태집합 \\(E\\), 상태집합을 포함하는 보렐 셋\\(\\cal{B}\\)\\((E)\\)\n- 정의: stationary distribution (쉬운버전)\n아래식을 만족하는 distribution \\({\\boldsymbol \\mu}\\) 를 stationary distribution 이라고 한다.\n\\[{\\boldsymbol \\mu}^\\top{\\bf P} = {\\boldsymbol \\mu}^\\top\\]\n- 예시1: 아래와 같은 transition matrix를 고려하자.\n\nP = np.array([[0.2,0.8],\n              [0.3,0.7]])\nP\n\narray([[0.2, 0.8],\n       [0.3, 0.7]])\n\n\n수렴할까?\n\nnp.linalg.matrix_power(P,50)\n\narray([[0.27272727, 0.72727273],\n       [0.27272727, 0.72727273]])\n\n\n결과분석\n\n특징1: \\({\\bf P}^{\\star}\\)로 수렴한다.\n특징2: 수렴한 매트릭스를 세로로 읽으면 값이 같다. \\(\\Rightarrow\\) … \\(\\Rightarrow\\) \\({\\bf P}^{\\star}\\)의 아무 row나 가져오면 정상분포가 된다.\n특징3: \\({\\boldsymbol \\pi}^\\top {\\bf P} = {\\boldsymbol \\pi}^\\top\\) \\(\\Leftarrow\\) \\(({\\boldsymbol \\mu}^\\top{\\bf P}^\\star) {\\bf P} ={\\boldsymbol \\pi}^\\top\\)\n특징4: 초기분포에 \\({\\boldsymbol \\pi}^\\top\\)을 대입하면 \\(\\{X_t\\}\\)는 동일한 분포를 가진다.\n\n- 예시2: 아래와 같은 transition matrix를 고려하자.\n\nP = np.array([[0.4,0.6],\n              [0.9,0.1]])\nP\n\narray([[0.4, 0.6],\n       [0.9, 0.1]])\n\n\n수렴할까?\n\nnp.linalg.matrix_power(P,50)\n\narray([[0.6, 0.4],\n       [0.6, 0.4]])\n\n\n결과분석\n\n특징1: \\({\\bf P}^{\\star}\\)로 수렴한다.\n특징2: 수렴한 매트릭스를 세로로 읽으면 값이 같다. \\(\\Rightarrow\\) … \\(\\Rightarrow\\) \\({\\bf P}^{\\star}\\)의 아무 row나 가져오면 정상분포가 된다.\n특징3: \\({\\boldsymbol \\pi}^\\top {\\bf P} = {\\boldsymbol \\pi}^\\top\\) \\(\\Leftarrow\\) \\(({\\boldsymbol \\mu}^\\top{\\bf P}^\\star) {\\bf P} ={\\boldsymbol \\pi}^\\top\\)\n특징4: 초기분포에 \\({\\boldsymbol \\pi}^\\top\\)을 대입하면 \\(\\{X_t\\}\\)는 동일한 분포를 가진다.\n\n- 예시3: 어지간하면 다 수렴할 것 같으니까 아래와 같이 특이한 transition matrix를 고려하자.\n\nP = np.array([[1.0, 0.0],\n              [0.05,0.95]])\nP\n\narray([[1.  , 0.  ],\n       [0.05, 0.95]])\n\n\n\nnp.linalg.matrix_power(P,50)\n\narray([[1.        , 0.        ],\n       [0.92305502, 0.07694498]])\n\n\n수렴안하나?\n\nnp.linalg.matrix_power(P,100)\n\narray([[1.        , 0.        ],\n       [0.99407947, 0.00592053]])\n\n\n\nnp.linalg.matrix_power(P,500)\n\narray([[1.00000000e+00, 0.00000000e+00],\n       [1.00000000e+00, 7.27449156e-12]])\n\n\n결국에는 한다.\n결과분석\n\n특징1: \\({\\bf P}^{\\star}\\)로 수렴한다.\n특징2: 수렴한 매트릭스를 세로로 읽으면 값이 같다. \\(\\Rightarrow\\) … \\(\\Rightarrow\\) \\({\\bf P}^{\\star}\\)의 아무 row나 가져오면 정상분포가 된다.\n특징3: \\({\\boldsymbol \\pi}^\\top {\\bf P} = {\\boldsymbol \\pi}^\\top\\) \\(\\Leftarrow\\) \\(({\\boldsymbol \\mu}^\\top{\\bf P}^\\star) {\\bf P} ={\\boldsymbol \\pi}^\\top\\)\n특징4: 초기분포에 \\({\\boldsymbol \\pi}^\\top\\)을 대입하면 \\(\\{X_t\\}\\)는 동일한 분포를 가진다.\n\n- 공식 (쓸모없는): transition matrix 가 아래와 같은 (2,2)-matrix이라고 하자.\n\n\\({\\bf P} = \\begin{bmatrix} 1-a & a \\\\ b & 1-b \\end{bmatrix}\\)\n\n그러면 대응하는 정상확률분포는 아래와 같다.\n\n\\(\\pi_0= \\frac{b}{a+b}\\)\n\\(\\pi_1= \\frac{a}{a+b}\\)\n\n예시1의 경우를 이 공식에 넣으면\n\n0.3/(0.8+0.3),0.8/(0.8+0.3)\n\n(0.2727272727272727, 0.7272727272727273)\n\n\n예시2의 경우를 이 공식에 넣으면\n\n0.9/(0.6+0.9), 0.6/(0.6+0.9)\n\n(0.6, 0.39999999999999997)\n\n\n예시3의 경우를 이 공식에 넣으면\n\n0.05/(0+0.05) , 0/(0+0.05)\n\n(1.0, 0.0)\n\n\n- 예시4: \\(a+b=0\\) 이라면?\n\nP = np.array([[1.0, 0.0],\n              [0.0, 1.0]])\nP\n\narray([[1., 0.],\n       [0., 1.]])\n\n\n수렴은 할텐데..\n결과분석\n\n특징1: \\({\\bf P}^{\\star}\\)로 수렴한다.\n특징2: 수렴한 매트릭스를 세로로 읽으면 값이 다르다?\n특징3: 어?\n특징4: 어????? (이건 그냥 되는데?)\n\n특징3: 정상분포\n일단 모든 \\({\\boldsymbol \\mu}\\)에 대하여 아래가 성립하긴한다.\n\\[{\\boldsymbol \\mu}^\\top {\\bf P} =  {\\boldsymbol \\mu}^\\top\\]\n따라서 이 경우 모든 확률측도 \\({\\boldsymbol \\mu}\\)는 정상분포가 된다. 유일한 정상분포를 가지지 않는다!!\n특징4: 정상확률과정\n\\({\\bf P}= {\\bf I}\\) 이므로 당연히 \\(\\{X_t\\}\\)는 모든 \\(t\\geq 0\\)에 대하여 동일한 분포를 가진다.\n- 예시5 (\\(\\star\\star\\star\\))\n\nP = np.array([[0.0, 1.0],\n              [1.0, 0.0]])\nP\n\narray([[0., 1.],\n       [1., 0.]])\n\n\n\nP@P\n\narray([[1., 0.],\n       [0., 1.]])\n\n\n\nP@P@P\n\narray([[0., 1.],\n       [1., 0.]])\n\n\n게속 바뀌고 있다.\n결과분석\n\n특징1: 수렴을 안하는데?\n특징2:\n특징3:\n특징4:\n\n특징3: 정상분포\n만약에 \\({\\boldsymbol \\pi}=\\begin{bmatrix} 1/2 \\\\ 1/2 \\end{bmatrix}\\) 로 설정한다면 아래가 성립한다.\n\\[{\\boldsymbol \\pi}^\\top {\\bf P} =  {\\boldsymbol \\pi}^\\top\\]\n따라서 \\({\\boldsymbol \\pi}\\)는 정상분포가 된다.\n특징4: 정상확률과정\n만약에 \\({\\boldsymbol \\pi}=\\begin{bmatrix} 1/2 \\\\ 1/2 \\end{bmatrix}\\) 로 설정한다면 \\(\\{X_t\\}\\)는 모든 \\(t\\geq 0\\)에 대하여 동일한 분포를 가진다.\n- 생각의 시간\n\n\n\n\n특징1(수렴)\n특징2(동일row)\n특징3(정상분포)\n특징4(정상과정)\n\n\n\n\n예시1(나이스)\nO\nO\n존재O, 유일O\nO\n\n\n예시2(나이스)\nO\nO\n존재O, 유일O\nO\n\n\n예시3(흡수)\nO\nO\n존재O, 유일O\nO\n\n\n예시4(단위행렬)\nO\nX\n존재O, 유일X\nO\n\n\n예시5(주기)\nX\nNA\n존재O, 유일O\nO\n\n\n\n예시4(단위행렬)\n특징3에서 정상분포가 존재하면 특징4는 그냥 성립한다. 지금까지 살펴본 예제에서는 모두 정상분포가 존재했다. 혹시 정상분포가 존재하지 않을 수도 있을까?\n- Thm: finite state를 가지는 HMC는 정상분포가 최소한 1개는 존재한다.\n동질마코프체인\n\n\n\n\n\nFootnotes\n\n\n진짜 억지로 변형한것, 마땅한 한글용어가 없음↩︎\n쓸모없는 내용↩︎"
  },
  {
    "objectID": "posts/ap/2023-03-07-ap_1wk.html",
    "href": "posts/ap/2023-03-07-ap_1wk.html",
    "title": "1주차: 측도론",
    "section": "",
    "text": "측도론\n\n교재\n\n1,2,3 장 진도나갈 예정!\n\n교수님 lecture note\n\n확률의 공리, 확률이라면 지켜져야 할, 위배되서는 안 될,\n확률의 공리 3개\n\n\\(P(\\Omega) = 1\\)\n\n\n어떤 실험의 결과는 표본공간 \\(\\Omega\\)에서 항상 일어난다.\n\n\n사건 \\(A \\in \\Omega\\)에 대해, \\(0 \\le P(A) \\le 1\\)\n\n\n어느 사건도 확률이 음수가 될 수 없고 1보다 클 수도 없다.\n\n\n서로 배반인 사건 \\(A\\)와 \\(B\\)에 대해, \\(P(A \\cup B) = P(A) + P(B)\\)\n\n\n서로 배반인 두 사건 \\(A\\)와 \\(B\\)에 대해 합사건의 확률은 각각의 확률의 합과 같다.\n\n\n확률로서 가능한 정의\n\n경우의 수\n면적/길이의 개념\n\n\n\n예제1: 동전\n- \\(\\Omega =\\{H,T\\}\\): sample space\n- \\(P(\\{H\\})=P(\\{T\\})=\\frac{1}{2}\\): prob\n- 질문: \\(\\Omega\\)의 임의의(=모든) 부분 집합 \\(\\Omega^*\\)에 대하여 \\(P(\\Omega^*)\\)를 모순없이 정의할 수 있을까?\n\n당연한거 아냐?\n이게 왜 안돼?\n\n- 질문에 대한 대답\n\n\\(\\Omega\\)의 부분집합: \\(\\emptyset, \\Omega, \\{H\\},\\{T\\}\\)\n\\(P(\\{H\\})=\\frac{1}{2}\\), \\(P(\\{T\\})=\\frac{1}{2}\\), \\(P(\\Omega)=P(\\{H,T\\})=1\\), \\(P(\\emptyset)=0\\)\n\n- 모순없이의 의미?\n\n우리가 상식적으로 확률에 적용가능한 어떠한 연산들이 있음. (확률의 공리 + 기본성질) // 네이버검색\n이러한 연산을 적용해도 상식적인 수준에서 납득이 가야함\n\n(상식적인 연산 적용 예시1)\n\\(\\{H\\} \\subset \\Omega \\Rightarrow P(\\{H\\})&lt;P(\\Omega)\\)\n\n집합 \\(\\{H\\}\\)은 집합 \\(\\Omega\\)보다 작은 집합임\n상식적으로 작은집합이 일어날 확률이 큰 집합이 일어날 확률보다 클 수 없음\n동전 예제의 경우 모든 \\(A,B \\subset \\Omega\\) 에 대하여, \\(A\\subset B\\) 이라면 \\(P(A) &lt; P(B)\\) 가 성립함\n\n(상식적인 연산 적용 예시2)\n\\(\\{H\\} \\cap \\{T\\} = \\emptyset \\Rightarrow P(\\{H\\} \\cup \\{T\\})=P(\\{H\\}) + P(\\{T\\}) =1\\)\n\n우리의 상식에 따르면 \\(A,B\\)가 서로소인 사건이라면 \\(P(A)+P(B)\\)이어야 함.1\n이 예제는 실제로 그러함.\n사실 이 예제의 경우 \\(P(\\{H\\} \\cup \\{T\\})=P(\\Omega)=1\\) 와 같이 계산할 수도 있음.\n하지만 어떠한 방식으로 계산해도 모순이 없음.\n\n\n\n예제2: 바늘이 하나만 있는 시계\n- \\(\\Omega = [0,2\\pi)\\)\n\n시계바늘을 돌려서 나오는 각도를 재는일 \\(\\Leftrightarrow\\) \\([0,2\\pi)\\)사이의 숫자중에 하나를 뽑는 일\n\n- 질문: 바늘을 랜덤으로 돌렸을때 12시-6시 사이에 바늘이 있을 확률? \\(\\frac{1}{2}\\)\n\n\\(\\Omega^* = [0,\\pi)\\)\n\\(P(\\Omega^*)= \\frac{1}{2}\\)\n\n- 계산하는 방법? 아래와 같이 계산하면 가능!!\n\\[\\forall \\Omega^* \\subset \\Omega, \\quad P(\\Omega^*)=\\frac{m(\\Omega^*)}{m(\\Omega)}\\]\n단 여기에서 \\(m\\)은 구간의 길이를 재는 함수라고 하자.\n연습: \\(m\\)의 사용\n\n\\(m(\\Omega)=m\\big([0,2\\pi)\\big)=2\\pi\\)\n\\(m(\\Omega^*) = m\\big([0,\\pi)\\big)= \\pi\\)\n\n- 위와 같은 방식으로 확률을 정의하면 잘 정의될까? 이게 쉽지 않음. 왜냐하면 확률을 잘 정의하기 위해서는\n\n\\(\\Omega\\)의 모든 부분집합 \\(\\Omega^*\\)에 대하여 \\(P(\\Omega^*)\\)를 모순없이\n\n정의할 수 있어야 하는데, 이게 쉬운일이 아님.\n(질문0) 그냥 몸풀기 용 질문\n\n\\(\\Omega^*=\\emptyset\\) 일 확률이 얼마인가?\n\n(답변)\n\n0 이야2\n\n(질문1) 첫번째 도전적인 질문\n\n\\(\\Omega^* =\\{0\\}\\)일 확률이 얼마인가?\n\n(답변)\n\n즉 바늘침이 정확하게 12시를 가르킬 확률이 얼마냐는 것\n한 점으로 이루어진 집합 \\(\\{0\\}\\)은 분명히 \\(\\Omega=[0,2\\pi)\\)의 부분집합 이므로 앞서 논의한대로라면 이러한 집합에 대한 확률을 명확하게, 모순없이 정의할 수 있어야 함\n많은 사람들이 이 질문에 대한 답은 \\(0\\) 이라고 알고 있고 그 이유를 “점의 길이는 0 이니까” 라고 이해하고 있음.3\n\n답변이 사실 좀 찝찝해. 바늘침이 정확하게 12시를 가르키는 것은 우리가 분명 하루에 한번씩은 경험하는 사건임. 그런데 그 사건이 일어날 확률은 0이다?4\n(참견질문) 생각해보니까 이런게 있었잖아?\n\\[A \\subset B \\Rightarrow P(A)&lt;P(B)\\]\n그런데 \\(\\emptyset \\subset \\{0\\}\\) 인데 \\(P(\\emptyset)=P(\\{0\\})\\) 이다..?\n(답변)\n\n원래식 \\(A \\subset B \\Rightarrow P(A)\\leq P(B)\\) 이 성립함\n즉 \\(A\\)가 \\(B\\)의 진 부분집합이더라도 \\(P(A)=P(B)\\)인 경우가 존재함.\n\n(질문2) 두번째 질문은 아래와 같다.\n\n그렇다면 사건 \\(\\{0,\\pi\\}\\)가 일어날 확률은 얼마인가?\n\n(답변)\n\n질문을 다시 풀어쓰면 바늘침이 정확하게 12시를 가르키거나 혹은 정확하게 6시를 가르킬 확률이 얼마냐는 것\n따라서 이 질문에 대한 대답은 \\(0+0=0\\) 이므로 \\(0\\)이라고 주장할 수 있음.\n\n(질문3) 세번째 질문은 아래와 같다.\n\n구간 \\([0,2\\pi)\\)는 무수히 많은 점들이 모여서 만들어지는 집합이다. 그런데 점 하나의 길이는 0이다. 0을 무수히 더해도 0이다. 그러므로 구간 \\([0,2\\pi)\\)의 길이도 0이 되어야 한다. 이것은 모순아닌가?\n\n(답변)\n\n까다롭다.\n\\(m([0,2\\pi))=0\\) 임을 인정하면 전체확률은 1이어야 한다는 기본상식5에 어긋나 모순이 생김.\n질문의 논리는 타당해보임. 이 논리의 약점은 딱히 없어보임. 굳이 약점이 있다면 “무한”이라는 개념?\n어쩔수없이 직관에 근거한 약간의 약속을 또 다시 해야할 것 같음. 예를들면 “점들을 유한번 합치면 그냥 많은 점들이지만 무한히 합치면 이것은 선분이 된다. 따라서 길이가 생긴다.” 와 같이.\n우리는 이 약속을 “무한번의 기적”이라고 칭하자.\n\n(질문4) 그렇다면 아래의 질문은 어떻게 대답할 수 있을까?\n\n\\([0,\\pi)\\) 에서 유리수만 뽑아낸 집합이 있다고 생각하자. 편의상 이 집합을 \\(\\mathbb{Q}\\) 라고 하자. 이 집합은 분명히 무한개의 점을 포함하고 있다. 그렇다면 이 집합도 길이가 있는가? 있다면 얼마인가?\n\n(답변)\n\n이미 점들의 길이를 무한번 더하면 길이가 생긴다고 주장한 상태이므로 (무한번의 기적) 길이가 0이라고 주장할 수 없다. 따라서 길이가 있다고 주장해야 한다.\n\\(\\pi\\)말고 딱히 떠오르는 수가 없는데 단순히 길이가 \\(\\pi\\)라고 주장한다면 바로 모순에 빠짐을 알 수 있다.6\n길이는 일단 0보다 커야하고 \\(\\pi\\)보다 작아야함은 자명하므로 그 사이에 있는 어떤 값이 길이라고 주장하자.7\n따라서 (질문4)에 대한 답은 ‘’구체적으로 얼마인지는 모르겠지만 길이가 분명 존재하고 그 길이는 0 보다 크고 \\(\\pi\\) 보다는 작은 어떠한 값 \\(a\\)이다.’’ 정도로 정리할 수 있다.\n즉 \\(m(\\mathbb{Q})=a\\).\n\n\\([0,\\pi] = [0,\\pi) \\cup \\{ \\pi \\}\\)\n둘이 서로소니까\n(질문5) – 외통수\n질문4로부터 만들어지는 논리는 빌드업1-3으로 이어지는 콤보질문을 적절하게 대답하지 못한다. (질문이 좀 길어서 나누어서 설명합니다)\n(빌드업1) – 평행이동은 길이를 변화시키지 않아, 그렇지?\n\n\\(\\mathbb{Q}\\)의 모든점에 \\(\\sqrt{2}\\)를 더한다. 이 점들로 집합을 만들어 \\(\\mathbb{Q}_{\\sqrt{2}}\\)를 만든다.\n여기에서 \\(\\mathbb{Q}_{\\sqrt{2}}\\)는 \\(\\Omega\\)의 부분집합 \\(\\Rightarrow\\) \\(\\mathbb{Q}_{\\sqrt{2}}\\)는 길이를 명확하고 모순없이 정의할 수 있어야 함\n\\(\\mathbb{Q}_{\\sqrt{2}}\\)의 길이는 사실 쉽게 \\(a\\)라고 정의할 수 있음8. 즉, \\(m(\\mathbb{Q}_{\\sqrt{2}})=a\\).\n\n(빌드업2) – 겹치지 않게 평행이동 시킨다음에 길이를 더한다면?\n이제 \\(\\mathbb{Q}_{\\sqrt{2}},\\mathbb{Q}_{\\sqrt{2}/2},\\mathbb{Q}_{\\sqrt{2}/3}\\)를 생각하자. 아래의 성질을 관찰할 수 있다.\n\n\\(\\mathbb{Q}_{\\sqrt{2}},\\mathbb{Q}_{\\sqrt{2}/2},\\mathbb{Q}_{\\sqrt{2}/3}\\)는 모두 \\(\\Omega\\)의 부분집합 \\(\\Rightarrow\\) 따라서 길이를 명확하고 모순없이 정의할 수 있어야 함\n\\(\\mathbb{Q}_{\\sqrt{2}},\\mathbb{Q}_{\\sqrt{2}/2},\\mathbb{Q}_{\\sqrt{2}/3}\\)의 길이는 각각 \\(a\\)로 정의할 수 있다.9\n\\(P(\\mathbb{Q}_{\\sqrt{2}} \\cup \\mathbb{Q}_{\\sqrt{2}/2} \\cup \\mathbb{Q}_{\\sqrt{2}/3})=P(\\mathbb{Q}_{\\sqrt{2}}) + P(\\mathbb{Q}_{\\sqrt{2}/2})+ P(\\mathbb{Q}_{\\sqrt{2}/3})\\)10\n\n굳이 \\(P(\\mathbb{Q}_{\\sqrt{2}}) + P(\\mathbb{Q}_{\\sqrt{2}/2})+ P(\\mathbb{Q}_{\\sqrt{2}/3})\\)를 계산하면 아래와 같이 계산할 수 있겠다.\n\\[P(\\mathbb{Q}_{\\sqrt{2}}) + P(\\mathbb{Q}_{\\sqrt{2}/2})+ P(\\mathbb{Q}_{\\sqrt{2}/3})=\\frac{a}{2\\pi}+\\frac{a}{2\\pi}+\\frac{a}{2\\pi}=3 \\times \\frac{a}{2\\pi}\\]\n(빌드업3) – 그런데 난 겹치지않게 평행이동시킬 방법을 무한대로 알고 있는데?\n눈 여겨볼 점은 아래 식이 성립해야 한다는 것이다. (\\(\\because\\) 확률의 공리)11\n\\[P\\big(\\mathbb{Q}_{\\sqrt{2}} \\cup \\mathbb{Q}_{\\sqrt{2}/2} \\cup \\mathbb{Q}_{\\sqrt{2}/3}\\big) = 3 \\times \\frac{a}{2\\pi} \\leq 1 \\quad \\cdots (\\star)\\]\n\n그런데 \\((\\star)\\)에서 좌변의 값은 편의에 따라서 값을 임의로 키울 수 있다.\n이렇게 임의로 키워진 좌변의 값이라도 항상 그 값은 1보다 작아야 하는데 (확률의 공리), 이게 가능하려면 \\(\\alpha=0\\)인 경우 말고 없다.\n그런데 \\(\\alpha=0\\) 이 된다면 “무한번 더해서 일어나는 기적”은 허구가 되므로 질문3 의 대답에 모순이 된다.\n\n그런데 임의로 좌변의 값을 키워도 항상 그 값은 1보다 작아야 하는데 이러한 \\(\\alpha\\)는 0이외에 불가능하다.\n그런데 \\(\\alpha=0\\) 이 된다면 “무한번 더해서 일어나는 기적”은 허구가 되므로 질문3 의 대답에 모순이 된다.\n모순을 막기 위한 부등호 \\(&lt;\\) \\(\\le\\)\n\n\n르벡메져\n르벡메져\n- 예제2에서의 마지막 질문은 지금까지 제시한 논리로 방어가 불가능. 이처럼 논리적인 모순없는 체계를 만드는 것은 매우 어려운 일임.\n- 결론적으로 말하면 길이를 재는 함수 \\(m\\)을 아래와 가정하면 위의 모든 질문에 대한 대답을 논리적 모순없이 설계할 수 있다.\n\n한 점에 대한 길이는 \\(0\\) 이다.\n\\([0,2\\pi)\\) 사이의 모든 유리수를 더한 집합은 그 길이가 \\(0\\)이다.\n\\([0,2\\pi)\\) 사이의 모든 무리수를 더한 집합은 그 길이가 \\(2\\pi\\)이다.\n\n참고로 르벡측도(Lebesgue measure)를 사용하면 위의 성질을 만족한다.12 따라서 르벡측도를 활용하여 확률을 정의하는 것이 모순을 최대한 피할 수 있다.\n\n\n\n\n\nFootnotes\n\n\n확률의 공리↩︎\n이걸 좀 더 엄밀하게 따질수도 있는데 일단 직관적으로 0이라 생각하고 넘어가자↩︎\n이해 안되면 약속이라고 생각하자.↩︎\n자연어에서는 “확률=0” 와 “불가능” 은 동일하지만 여기서는 아니다.↩︎\n심지어 이건 확률의 공리↩︎\n왜 모순에 빠지냐면 \\([0,\\pi)\\)에서 무리수만 뽑아낸 집합의 길이가 뭐냐고 물을경우 0이라고 말해야함↩︎\n구체적으로 어떤값인지는 모른다고 하자.↩︎\n평행이동은 길이를 변화시킬 수 없으니까↩︎\n평행이동은 길이를 변화시키지 않으니까↩︎\n\\(\\mathbb{Q}_{\\sqrt{2}},\\mathbb{Q}_{\\sqrt{2}/2},\\mathbb{Q}_{\\sqrt{2}/3}\\)는 모두 서로소 임을 이용↩︎\n첫 등호는 서로소인 사건에 대한 공리, 그다음 부등호는 확률의 총합은 1보다 같거나 작다라는 공리↩︎\n물론 르벡측도의 정의가 위와 같지는 않다↩︎"
  },
  {
    "objectID": "posts/ap/2023-03-14-2wk-2.html",
    "href": "posts/ap/2023-03-14-2wk-2.html",
    "title": "02wk-2: 측도론 intro (2)",
    "section": "",
    "text": "강의영상\n\nhttps://youtube.com/playlist?list=PLQqh36zP38-zQoiFje77DtmGx03QS339J\n\n\n\n예비개념1: 귀류법\n- 귀류법: 니 논리 대로면… &lt;- 인터넷 댓글에 많음..\n님 논리대로면..\n- XXX가 문제 없으면 서울 전체가 문제가 없고 (애초에 서울은 문제도 아니라는데 왜 이소리는 하고 계신지 모르겠지만)\n- 수도권 모 대학이 문제가 없으면 전체가 문제가 없겠네요?\n- 지방도 1개 대학이 문제가 없으니 전체가 문제 없겠네요?\n와우! 모든 문제가 해결되었습니다! 출산율 감소로 인한 한국대학의 위기가 해결되었.. 아니 애초에 위기가 없었군요!.\n어휴.. ㅠㅠ\n\nref: 하이브레인넷\n\n\n\n예비개념2: 일반화\n- 연필의 정의: 필기도구의 하나. 흑연과 점토의 혼합물을 구워 만든 가느다란 심을 속에 넣고, 겉은 나무로 둘러싸서 만든다. 1565년에 영국에서 처음으로 만들었다.\n- 질문: 아래는 연필인가?\n\n\n\n애플펜슬!\n\n\n\n\ncardinality\n\nref: https://en.wikipedia.org/wiki/Cardinality\n\n- \\(A=\\{2,4,6\\}\\) \\(\\Rightarrow\\) \\(|A|=3\\), \\(A\\) has a cardinality of 3.\n- \\(A=\\{1,2,3,4,\\dots\\}=\\mathbb{N}\\) \\(\\Rightarrow\\) \\(|A|=?\\)\n\nCardinal number: 유한집합에서의 “갯수”라는 개념을 좀 더 일반화 하여 무한집합으로 적용하고 싶다.\n유한집합: 우리가 친숙한 size 와 그 뜻이 같음\n무한집합: 무한집합의 경우는 그 동작원리가 조금 더 복잡함\n\n- 질문: \\(|\\mathbb{Q}| &lt; |\\mathbb{Q}^c|\\) ??\nBijection, injection and surjection (예비학습)\n\nref: https://en.wikipedia.org/wiki/Bijection,_injection_and_surjection\n\n\n- 용어 정리\n\nsurjective = onto = 전사 = 위로의 함수\ninjective = one-to-one = 단사 = 일대일 함수\nbijective = one-to-one and onto, one-to-one correspondence = 전단사 = 일대일 대응\n\n- 따지는 방법:\n\n단사: 함수 \\(f\\)는 \\(X\\)에서 \\(Y\\)로 향하는 단사함수이다. \\(\\Leftrightarrow\\) \\(\\forall x_1,x_2 \\in X\\): \\(x_1\\neq x_2 \\Rightarrow f(x_1)\\neq f(x_2)\\)\n전사: 함수 \\(f\\)는 \\(X\\)에서 \\(Y\\)로 향하는 전사함수이다. \\(\\Leftrightarrow\\) \\(\\forall y \\in Y ~\\exists x \\in X\\) such that \\(f(x)=y\\).\n\n- 성질1: 어떤함수가 전사함수 & 단사함수 \\(\\Rightarrow\\) 전단사함수\n- 성질2:\n\n집합 \\(X\\)에서 집합 \\(Y\\)로 가는 단사함수 \\(f\\)가 존재한다. \\(\\Rightarrow\\) \\(|X| \\leq |Y|\\)\n집합 \\(X\\)에서 집합 \\(Y\\)로 가는 전사함수 \\(f\\)가 존재한다. \\(\\Rightarrow\\) \\(|X| \\geq |Y|\\)\n\n(예비학습 끝)\n- 성질1~2로 유추하면 아래와 같은 사실을 주장 할 수 있지 않을까?\n\n집합 \\(X\\)에서 집합 \\(Y\\)로 향하는 전단사함수가 존재한다 \\(\\Rightarrow\\) \\(|X|=|Y|\\)\n\n- 그렇다면 우리가 주장하고 싶은 것은 아래와 같이 된다.\n\n유리수집합의 무리수집합의 cardinality는 다르다.\n유리수집합과 무리수집합사이의 전단사함수는 존재할 수 없다.\n\n\n\n유리수집합의 카디널리티\n- 우리가 궁극적으로 궁금한 것\n\n유리수집합과 무리수집합의 카디널리티는 다를까?\n\n- 그냥 궁금한 것\n\n자연수의 집합, 비음인 정수의 집합, 음의 정수의 집합, 정수의 집합, 짝수의 집합, 홀수의 집합의 카디널리티는 어떠할까?\n\n- (예제1)\n집합 \\(X=\\{1,2,3\\}\\), \\(Y=\\{2,4,6\\}\\)을 생각하자. 적당한 함수 \\(f\\)를 아래와 같이 정의하자.\n\n\\(f(1)=2\\)\n\\(f(2)=4\\)\n\\(f(3)=6\\)\n\n아래의 질문에 대답해보자.\n\n(단사) \\(\\forall x_1,x_2 \\in X\\), \\(x_1\\neq x_2\\) \\(\\Rightarrow\\) \\(f(x_1)\\neq f(x_2)\\)?\n(전사) \\(\\forall y \\in Y~ \\exists x \\in X\\) such that \\(f(x)=y\\)?\n\n1의 질문과 2의 질문이 모두 맞으므로 함수 \\(f\\)는 전단사 함수이다. 집합 \\(X\\)에서 집합 \\(Y\\)로 가는 전단사 함수가 존재하므로 집합 \\(X\\)와 집합 \\(Y\\)의 카디널리티는 동일하다.\n- (예제2)\n집합 \\(X=\\{1,2,3,\\dots \\}\\), \\(Y=\\{2,4,6,\\dots \\}\\)을 생각하자. 적당한 함수 \\(f\\)를 아래와 같이 정의하자.\n\n\\(f(1)=2\\)\n\\(f(2)=4\\)\n\\(f(3)=6\\)\n\\(\\dots\\)\n\n아래의 질문에 대답해보자.\n\n(단사) \\(\\forall x_1,x_2 \\in X\\), \\(x_1\\neq x_2\\) \\(\\Rightarrow\\) \\(f(x_1)\\neq f(x_2)\\)?\n(전사) \\(\\forall y \\in Y~ \\exists x \\in X\\) such that \\(f(x)=y\\)?\n\n1의 질문과 2의 질문이 모두 맞으므로 함수 \\(f\\)는 전단사함수이다. 집합 \\(X\\)에서 집합 \\(Y\\)로 가는 전단사 함수가 존재하므로 집합 \\(X\\)와 집합 \\(Y\\)의 카디널리티는 동일하다.\n- \\(\\aleph_0\\) (알레프 널, 혹은 알레프 제로라고 읽음)\n\n자연수집합 \\(\\mathbb{N}\\)의 카디널리티는 \\(\\aleph_0\\)이다. 즉 \\(|\\mathbb{N}|=\\aleph_0\\).\n짝수인 자연수 집합의 카디널리티는 \\(\\aleph_0\\)이고, 홀수인 자연수 집합의 카디널리티는 \\(\\aleph_0\\)이다.\n정수집합 \\(\\mathbb{Z}\\)의 카디널리티는 \\(\\aleph_0\\)이다. 즉 \\(|\\mathbb{Z}|=\\aleph_0\\).\n\n- 느낌: \\(\\aleph_0\\)를 2배,3배,4배 하여도 \\(\\aleph_0\\)이다.\n\n즉 무한집합의 경우, 본인과 카디널넘버가 같은 진 부분집합이 존재할 수 있다. (유한집합에서는 불가능하겠지)\n무한집합의 정의: 집합 \\(A\\)가 무한집합이다. \\(\\Leftrightarrow\\) \\(A\\)와 동일한 카디널리티를 가지는 \\(A\\)의 진 부분집합이 존재한다.\n\n- (예제3)\n원소의 수가 \\(n\\)인 임의의 유한집합 \\(A\\)에 대하여 \\(|A|=n\\) 이다.\n- (예제4)\n유리수집합의 카디널리티는 얼마인가? (ref: https://en.wikipedia.org/wiki/Rational_number)\n집합 \\(X\\)를 자연수의 집합이라고 하자. 집합 \\(Y\\)를 아래그림에 있는 숫자들의 집합이라고 하자.1\n\n예를들어 집합 \\(X\\)와 집합 \\(Y\\)를 앞의 몇개만 써보면\n\n\\(X=\\{1,2,3,4,5,6,\\dots\\}\\)\n\\(Y=\\{1,\\frac{2}{1},\\frac{1}{2},\\frac{3}{1},\\frac{2}{2},\\frac{1}{3},\\dots \\}\\)\n\n함수 \\(f\\)를 아래와 같이 정의하자.\n\n\\(f(1)=1\\)\n\\(f(2)=2/1\\)\n\\(f(3)=1/2\\)\n\\(f(4)=3/1\\)\n\\(f(5)=2/2\\)\n\\(f(6)=1/3\\)\n\\(\\dots\\)\n\n함수 \\(f\\)는 \\(X\\)에서 \\(Y\\)로 향하는 전단사함수이다. \\(\\Rightarrow\\) \\(|X|=\\aleph_0=|Y|\\)\n(관찰) 임의의 양의 유리수의 집합 \\(\\mathbb{Q}^+\\)는 모두 \\(Y\\)에 포함되어 있다. \\(\\Rightarrow\\) \\(X \\subset \\mathbb{Q}^+ \\subset Y\\) \\(\\Rightarrow\\) \\(|\\mathbb{Q}^+|=\\aleph_0\\)\n(생각) 그럼 음의 유리수의 집합 \\(\\mathbb{Q}^-\\)의 카디널넘버 역시 \\(\\aleph_0\\)이다. 즉 \\(|\\mathbb{Q}^-|=\\aleph_0\\).\n(결론) 그럼 유리수의 카디널넘버는 \\(\\aleph_0\\)이다.2 좀 더 자극적으로 말하면 “자연수의 갯수와 유리수의 갯수는 같다” 라고 말할 수 있다.\n- 조금 무식하게 쓰면 아래와 같이 쓸 수 있다.\n\n\\(\\aleph_0 + 1 = \\aleph_0\\)\n\\(\\aleph_0 \\times 2 = \\aleph_0\\)\n\\(\\aleph_0 \\times \\aleph_0 = \\aleph_0^2 = \\aleph_0\\)\n\n\n\n\n\n\nFootnotes\n\n\n그래서 일단 집합 \\(Y\\)는 양의 유리수의 집합을 포함한다↩︎\n\\(\\mathbb{Q} = \\mathbb{Q}^+ \\cup \\{0\\} \\cup \\mathbb{Q}^-\\)↩︎"
  },
  {
    "objectID": "posts/ap/2023-05-16-11wk-2.html",
    "href": "posts/ap/2023-05-16-11wk-2.html",
    "title": "11wk-2: 마코프체인 (9)",
    "section": "",
    "text": "- 수업시간 중 잘못 설명한 부분이 있어서 정정하고 촬영하였습니다. (두번째 영상이 재촬영한 부분임)\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-wygptXg6WEfudbDb-ZjvRm"
  },
  {
    "objectID": "posts/ap/2023-05-16-11wk-2.html#intro",
    "href": "posts/ap/2023-05-16-11wk-2.html#intro",
    "title": "11wk-2: 마코프체인 (9)",
    "section": "intro",
    "text": "intro\n- 같다(=) 라는 개념의 추상화\n- 예시1: 아래의 리스트에서 같은 원소끼리 묶어라.\n\n[1,1,2,2,3,3,3]\n\n[1, 1, 2, 2, 3, 3, 3]\n\n\n\n[[1,1], [2,2], [3,3,3]]\n\n[[1, 1], [2, 2], [3, 3, 3]]\n\n\n\n같은 원소들의 모임을 동치류 (equivalence class) 라고 한다. 이 예제에서는 3개의 동치류가 있는 셈.\n\n- 예시2: 아래의 리스트에서 같은 원소끼리 묶어라.\n\nlst = [1, 1.0, 2, 2, 3, 3, 3]\nlst \n\n[1, 1.0, 2, 2, 3, 3, 3]\n\n\n\n어떻게 할까? (수학적으로 볼까? 프로그래밍적으로 볼까?)\n같다라는건 뭐지?"
  },
  {
    "objectID": "posts/ap/2023-05-16-11wk-2.html#같다의-개념을-추상화",
    "href": "posts/ap/2023-05-16-11wk-2.html#같다의-개념을-추상화",
    "title": "11wk-2: 마코프체인 (9)",
    "section": "“같다”의 개념을 추상화",
    "text": "“같다”의 개념을 추상화\n- “같다”라는 개념을 좀 일반화 해보자.\n\n같다라는 것은 “어떠한 기준으로 판단하였을 경우” 그 결과가 같은 집합으로 묶인다는 것을 의미\n\n- 아래의 예시를 다시 관찰하자.\n\nlst = [1, 1.0, 2, 2, 3, 3, 3]\nlst \n\n[1, 1.0, 2, 2, 3, 3, 3]\n\n\n(경우1)\n판단기준을 “수학적인 값이 같음”으로 설정한다면 lst[0]과 lst[1]은 같다.\n\nlst[0] == lst[1]\n\nTrue\n\n\n따라서 아래와 같은 분류가 합리적이다.\n\n[[1, 1.0], [2,2], [3,3,3]]\n\n[[1, 1.0], [2, 2], [3, 3, 3]]\n\n\n(경우2)\n판단기준을 “수학적인 값이 같음 & 파이썬에서의 자료형이 일치” 로 설정한다면 lst[0]과 lst[1]은 다르다.\n\ntype(lst[0]) == type(lst[1])\n\nFalse\n\n\n따라서 아래와 같은 분류가 합리적이다.\n\n[[1], [1.0], [2,2], [3,3,3]]\n\n[[1], [1.0], [2, 2], [3, 3, 3]]\n\n\n(경우3)\n판단기준을 “파이썬에서의 자료형이 일치” 로 설정한다면? 아래와 같은 분류도 합리적이다.\n\n[[1,2,2,3,3,3], [1.0]]\n\n[[1, 2, 2, 3, 3, 3], [1.0]]\n\n\n이것도 어떠한 의미에서는 같은원소들을 모아놓은 것임\n\n“같다”라는 것을 올바르게 지칭하려면 “어떠한 의미에서 같다”라는 것인지 명확하게 설명할 필요가 있다.\n\n- 예시2: \\(a\\)와 \\(b\\)가 “어떠한 의미에서 같다”라는 것을 기호로 \\(a \\sim b\\)라고 하자. ~의 의미를\n\n\\(a \\sim b\\) \\(\\overset{def}{\\Leftrightarrow}\\) a == b\n\n로 해석한다면, 아래와 같이 원소를 묶을 수 있다.\n\n[[1, 1.0], [2,2], [3,3,3]]\n\n[[1, 1.0], [2, 2], [3, 3, 3]]\n\n\n만약에 ~의 의미를\n\n\\(a \\sim b\\) \\(\\overset{def}{\\Leftrightarrow}\\) (a == b) & (type(a)==type(b))\n\n로 해석한다면, 아래와 같이 원소를 묶을 수 있다.\n\n[[1], [1.0], [2,2], [3,3,3]]\n\n[[1], [1.0], [2, 2], [3, 3, 3]]\n\n\n만약에 ~의 의미를\n\n\\(a \\sim b\\) \\(\\overset{def}{\\Leftrightarrow}\\) (type(a)==type(b))\n\n로 해석한다면, 아래와 같이 원소를 묶을 수 있다.\n\n[[1,2,2,3,3,3], [1.0]]\n\n[[1, 2, 2, 3, 3, 3], [1.0]]\n\n\n- “같음(=)”이라는 기호가 가지는 당연한 성질\n\n\\(a=a\\)\n\\(a=b \\Rightarrow b=a\\)\n\\(a=b, b=c \\Rightarrow a=c\\)\n\n성질 1,2,3은 원래 =라는 기호가 “두 원소의 같음”을 의미할때 가지는 당연한 성질이다.\n- 역으로 생각해보면 어떠한 기호 \\(\\sim\\)이 성질 1,2,3을 가진다면 기호 \\(\\sim\\)를 같음을 의미하는 기호로 “해석”할 수 있다.\n\n예시1: 합동\n예시2: 닮음\n\n- 정의: 어떠한 집합 \\(\\Omega\\)의 임의의 원소 \\(a,b,c\\) 에 대하여 \\(\\sim\\)이 아래와 같은 성질이 성립한다면 \\(\\sim\\)를 equivalence relation 이라고 부른다.\n\n\\(a\\sim~a\\)\n\\(a \\sim b \\Rightarrow b\\sim a\\)\n\\(a \\sim b, b \\sim c \\Rightarrow a \\sim c\\)\n\n여기에서 \\(\\sim\\)은 “같음”을 의미하는 기호 \\(=\\)의 일반화된 버전이다.\n- 정의: 어떠한 집합 \\(\\Omega\\)가 equivalence relation \\(\\sim\\)를 가진다면 그 집합은 \\(\\sim\\)를 기준으로 나눌 수 있다.\n(예시1) 아래와 같이 5명의 학생이 있다고 치자.\n\n23학번: 20살, 20살, 20살\n22학번: 21살, 21살\n\n구성원들의 나이나 학번이 같으면 반말을 한다고 치자. (그렇지 않으면 존대말을 한다고 가정하자) 이제 아래와 같은 기호를 정의하자.\n\n\\(a \\sim b\\) \\(\\overset{def}{\\Leftrightarrow}\\) \\(a\\)가 \\(b\\)에게 반말함\n\n그렇다면 \\(\\sim\\) equivalence relation 이다. 따라서 학생들을 \\(\\sim\\)를 기준으로 두개의 그룹으로 나눌 수 있다.\n(예시2) 아래와 같이 5명의 학생이 있다고 치자.\n\n23학번: 20살, 20살, 21살\n20학번: 23살, 23살\n\n여전히 \\(\\sim\\)는 equivalence relation 이다. 따라서 학생들을 \\(\\sim\\)를 기준으로 두개의 그룹으로 나눌 수 있다.\n(예시3) 아래와 같이 5명의 학생이 있다고 치자.\n\n23학번: 20살, 20살, 21살\n22학번: 21살, 21살\n\n이제 \\(\\sim\\)는 equivalence relation 이 아니다. 따라서 학생들을 \\(\\sim\\)를 기준으로 나눌 수 없다."
  },
  {
    "objectID": "posts/ap/2023-05-16-11wk-2.html#intro-1",
    "href": "posts/ap/2023-05-16-11wk-2.html#intro-1",
    "title": "11wk-2: 마코프체인 (9)",
    "section": "intro",
    "text": "intro\n- 질문: “오른쪽으로만 갈래요” 예제는 IRR HMC 인가?\n- 가짜정의: 어떠한 HMC \\(\\{X_t\\}\\)가 IRR이라는 것은 모든 상태공간이 “연결”되어있다는 의미이다.\n- 가짜정의의 보충설명 (1)\n\n여기에서 모든 상태공간이 연결되어있다는 의미는 상태공간 \\(E\\)에서 임의의 두 상태 \\(i,j\\)를 뽑았을때 \\(i \\to j\\) 이고, \\(j \\to i\\) 라는 의미이다.\n여기에서 \\(i\\to j\\) 라는 의미는 언젠가는 상태 \\(i\\)에서 출발한 체인이 상태 \\(j\\)에 도달할 수 있다는 의미이다.\n\n- 의문: 언젠가는에 대한 의미??\n\n\n\n\nflowchart LR\n  0 --&gt; 1\n  1 --&gt; 2\n  2 --&gt; 1 \n  2 --&gt; 3 \n  3 --&gt; 1\n  3 --&gt; 2 \n\n\n\n\n\n상태0에서 시작하면 3회 이후에는 상태3에 갈 확률이 있다. (3회시점에 꼭 상태3에 있겠다는 의미는 아님) 따라서 이 경우\n\\[0 \\to 3\\]\n이라고 쓸 수 있다. 이 예제의 경우\n\n\\(0 \\to 1\\), \\(0 \\to 2\\), \\(0 \\to 3\\), \\(0 \\to 4\\), \\(0\\to 0\\)1\n\\(1 \\to 1\\), \\(1 \\to 2\\), \\(1 \\to 3\\)\n\\(2 \\to 1\\), \\(2 \\to 2\\), \\(2 \\to 3\\)\n\\(3 \\to 1\\), \\(3 \\to 2\\), \\(3 \\to 3\\)\n\n와 같다.\n\n여기서 제가 설명잘못했는데요, 0회도 포함시킨다고 하면 \\(0 \\to 0\\) 입니다.\n\n- 다시 가짜정의의 보충설명 (2) – (1)을 이어서\n\n여기에서 모든 상태공간이 연결되어있다는 의미는 상태공간 \\(E\\)에서 임의의 두 상태 \\(i,j\\)를 뽑았을때 \\(i \\to j\\) 이고, \\(j \\to i\\) 라는 의미이다.\n여기에서 \\(i\\to j\\) 라는 의미는 언젠가는 상태 \\(i\\)에서 출발한 체인이 상태 \\(j\\)에 도달할 수 있다는 의미이다.\n즉 \\(i \\to j\\)라는 의미는 “(\\(i\\)에서 출발한다면 \\(T_0\\) 이후에 \\(j\\)에 도달해 있을 확률) &gt; \\(0\\)” 이라는 뜻이다.\n\n- 다시의문: \\(i\\)에서 출발했다고 가정할때 \\(T_0\\)이후에 \\(j\\)에 도달해 있을 확률을 어떻게 구체적으로 쓰지?\n- (예시)\n\n\n\n\nflowchart LR\n  0 --&gt; |1.0| 1\n  1 --&gt; |0.5| 1\n  1 --&gt; |0.5| 2\n  2 --&gt; |1.0| 1 \n\n\n\n\n\n질문: \\(p_{ij}^{(T_0)}\\)를 “\\(i\\)에서 출발했다고 가정할때 \\(T_0\\)이후에 \\(j\\)에 도달해 있을 확률이라고 하자.” \\(T_0=2\\)일 경우 아래를 구하라.\n\n\\(p_{00}^{(2)}=0\\)\n\\(p_{01}^{(2)}=0.5\\)\n\\(p_{02}^{(2)}=0.5\\)\n\\(p_{10}^{(2)}=0\\)\n\\(p_{11}^{(2)}=?\\)\n\\(p_{12}^{(2)}=?\\)\n\\(p_{20}^{(2)}=0\\)\n\\(p_{21}^{(2)}=0.5\\)\n\\(p_{22}^{(2)}=0.5\\)\n\n\nP = np.array([[0,1,0],\n              [0,1/2,1/2],\n              [0,1,0]])\nP@P\n\narray([[0.  , 0.5 , 0.5 ],\n       [0.  , 0.75, 0.25],\n       [0.  , 0.5 , 0.5 ]])\n\n\n- 다시 가짜정의의 보충설명 (3) – (2)를 이어서\n\n여기에서 모든 상태공간이 연결되어있다는 의미는 상태공간 \\(E\\)에서 임의의 두 상태 \\(i,j\\)를 뽑았을때 \\(i \\to j\\) 이고, \\(j \\to i\\) 라는 의미이다.\n여기에서 \\(i\\to j\\) 라는 의미는 언젠가는 상태 \\(i\\)에서 출발한 체인이 상태 \\(j\\)에 도달할 수 있다는 의미이다.\n즉 \\(i \\to j\\)라는 의미는 “(\\(i\\)에서 출발한다면 \\(T_0\\) 이후에 \\(j\\)에 도달해 있을 확률) &gt; \\(0\\)” 이라는 뜻이다.\n\n즉 \\(i \\to j\\)라는 의미는 “\\(\\exists T_0 \\in \\mathbb{N}_0\\) such that \\(p_{ij}^{(T_0)}&gt;0\\)” 이라는 뜻이다.\n\n\n이 부분도 제가 설명을 잘못했는데 여기에서 \\(T_0=0\\) 인 경우는 \\({\\bf P}^{0}={\\bf I}\\) 와 같이 해석합니다. 따라서 모든 \\(\\forall x \\in E:~ x\\leftrightarrow x\\) 입니다."
  },
  {
    "objectID": "posts/ap/2023-05-16-11wk-2.html#정의-irreducible-irr",
    "href": "posts/ap/2023-05-16-11wk-2.html#정의-irreducible-irr",
    "title": "11wk-2: 마코프체인 (9)",
    "section": "정의: irreducible (IRR)",
    "text": "정의: irreducible (IRR)\n- 정의: \\(\\{X_t\\}\\)를 상태공간 \\(E\\)에 정의된 HMC라고 하고 \\({\\bf P}\\)를 \\(\\{X_t\\}\\)의 transition matrix (혹은 그 비슷한 것) 라고 하자. 임의의 \\(i,j \\in S\\)에 대하여 상태 \\(i\\)에서 상태 \\(j\\)로 도달가능(accessible)하다는 의미는\n\n\\(\\exists T_0 \\in \\mathbb{N}_0\\) such that \\(p_{ij}^{(T_0)}&gt;0\\)\n\n를 의미하며 이를 기호로는 \\(i\\to j\\)와 같이 표현한다. 참고로 여기에서 \\(p_{ij}^{(T_0)}\\)는 \\({\\bf P}^{T_0}\\)의 \\((i,j)\\)-th element이다.\n- 따라서 아래는 모두 같은 의미임\n\n\\(\\exists T_0 \\in \\mathbb{N}_0 \\textsf{ such that } p_{ij}^{(T_0)}&gt;0\\)\n\\(i \\to j\\)\n\\(j\\) is accessible from \\(i\\)\n\n- 정의: \\(\\{X_t\\}\\)를 상태공간 \\(E\\)에 정의된 HMC라고 하고 \\({\\bf P}\\)를 \\(\\{X_t\\}\\)의 transition matrix (혹은 그 비슷한 것) 라고 하자. 임의의 \\(i,j \\in S\\)에 대하여 상태 \\(i,j\\)가 상호도달가능 (communicate) 하다는 의미는\n\n\\(i \\to j\\) and \\(j \\to i\\)\n\n임을 의미한다. \\(i,j\\)가 상호도달할 경우 기호로는 \\(i \\leftrightarrow j\\) 와 같이 표현한다.\n- 이론: 아래가 성립한다. (굳이 증명할 필요없음. 결과만 기억해도 OK)\n\n\\(i \\leftrightarrow i\\)\n\\(i \\leftrightarrow j\\) \\(\\Rightarrow\\) \\(j \\leftrightarrow i\\)\n\\(i \\leftrightarrow j\\), \\(j \\leftrightarrow k\\) \\(\\Rightarrow\\) \\(i \\leftrightarrow k\\)\n\n따라서 \\(\\leftrightarrow\\) 는 equivalence relation 이다. 따라서 상태공간 \\(E\\)는 \\(\\leftrightarrow\\)를 기준으로 “나눌 수” 있다.\n- 정의: \\(\\{X_t\\}\\)를 상태공간 \\(E\\)에 정의된 HMC라고 하자. 상태공간 \\(E\\)는 equivalence relation \\(\\leftrightarrow\\)를 기준으로\n\\[E = E_1 \\uplus E_2 \\uplus \\dots\\]\n와 같이 “나눌 수” 있는데 이때 나누어진 집합 \\(E_1,E_2,\\dots\\) 를 communication class라고 부른다.\n- 예시1: 상태공간을 \\(\\{0\\}\\)와 \\(\\{1,2\\}\\)로 나눌 수 있다. 따라서 \\(E\\)는 2개의 communication class 를 가진다.\n\n\n\n\nflowchart LR\n  0 --&gt; |1.0| 1\n  1 --&gt; |0.5| 1\n  1 --&gt; |0.5| 2\n  2 --&gt; |1.0| 1 \n\n\n\n\n\n- 예시2: 아래와 같은 transition matrix를 가지는 마코프체인의 경우\n\nP = np.array([[1,0],\n              [0,1]])\nP\n\narray([[1, 0],\n       [0, 1]])\n\n\n상태공간을 \\(\\{0\\},\\{1\\}\\)로 나눌 수 있다. 따라서 \\(E\\)는 2개의 communication class 를 가진다.\n- 정의 \\(\\{X_t\\}\\)를 상태공간 \\(E\\)에 정의된 HMC라고 하고 \\({\\bf P}\\)를 \\(\\{X_t\\}\\)의 transition matrix (혹은 그 비슷한 것) 라고 하자. 상태공간 \\(E\\)가 오직 하나의 communication class를 가지는 경우 아래와 같이 말한다.\n\n\\(\\{X_t\\}\\) 가 irreducible 한 마코프체인이다.\n\\({\\bf P}\\) 가 irreducible 한 transition matrix 이다."
  },
  {
    "objectID": "posts/ap/2023-03-29-5wk-2-hw1.html",
    "href": "posts/ap/2023-03-29-5wk-2-hw1.html",
    "title": "05wk-2: HW1",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-xsTHLqiyPTgay2jwnssbnC\n\n\n\n배점\n\n\n\n문항\n점수\n\n\n\n\n1-(1)\n15\n\n\n1-(2)\n15\n\n\n2-(1)\n5\n\n\n2-(2)\n5\n\n\n2-(3)\n10\n\n\n2-(4)\n10\n\n\n3-(1)\n20\n\n\n3-(2)\n20\n\n\n\n\n\n1. Cardinality\n(1) \\(\\mathbb{Q}\\)의 cardinality가 \\(\\aleph_0\\)임을 증명하라.\n(풀이) 생략\n(2) \\(\\mathbb{R}\\)의 cardinality가 \\(\\aleph_0\\)이 아님을 보여라.\n(풀이) 생략\n\n\n2. \\(\\sigma\\)-field\n(1) \\(\\Omega=\\{H,T\\}\\)일 때, 다음 중 시그마필드의 정의를 만족하는 집합을 모두 골라라.\n\n\\({\\cal F}=\\{\\emptyset\\}\\)\n\\({\\cal F}=\\{\\Omega\\}\\)\n\\({\\cal F}=\\{\\emptyset, \\Omega\\}\\)\n\\({\\cal F}=\\{\\{H\\}\\}\\)\n\\({\\cal F}=\\{\\{H\\}, \\{T\\}\\}\\)\n\\({\\cal F}=\\{\\emptyset, \\{H\\}, \\Omega\\}\\)\n\\({\\cal F}=\\{\\emptyset, \\{T\\}, \\Omega\\}\\)\n\\({\\cal F}=\\{\\emptyset, \\{H\\}, \\{T\\}, \\Omega\\}\\)\n\n(풀이) 3,8 이 시그마필드이다. // 시그마필드가 아닌이유를 서술할 필요없음. 답만 쓰면 인정함.\n(2) \\(\\Omega=\\{1,2,3,4\\}\\) 일 때,\n\\[{\\cal A}=\\{ \\{1\\}, \\{1,2\\}\\}\\]\n이라고 하자. \\(\\sigma({\\cal A})\\)를 구하여라.\n(풀이) // 이 문제역시 답만 써도 인정\n\\(\\sigma({\\cal A}) = \\{\\emptyset, \\{1\\},\\{2\\},\\{3,4\\}, \\{1,2\\},\\{1,3,4\\}, \\{2,3,4\\}, \\Omega\\}\\)\n\n요령: \\(\\{3,4\\}\\)를 한세트로 보면 편리하다. 즉 전체사건을 \\(\\{1\\},\\{2\\},\\{3,4\\}\\)로 쪼갠뒤에 3개의 원소만 있다고 생각하고 모든 부분집합을 쓰면 된다.\n\n(3) \\(\\Omega=\\{1,2,3,4,\\dots,100\\}\\) 일 때,\n\\[{\\cal A}=\\{ \\{1\\}, \\{1,2\\}, \\{1,2,3\\},\\{1,2,3,4\\}\\}\\]\n이라고 하자. 아래의 물음에 답하여라.\n\n\\(\\{2\\} \\in \\sigma({\\cal A})\\) 인가?\n\\(\\{2,3,4\\} \\in \\sigma({\\cal A})\\) 인가?\n\\(\\{3,4,5\\} \\in \\sigma({\\cal A})\\) 인가?\n\\(\\Omega - \\{1,2,3\\} \\in \\sigma({\\cal A})\\) 인가?\n\n(풀이) // 답만쓰면 인정하지 않음.\n시그마필드의 정의는 아래와 같다.\n\n시그마필드 \\({\\cal F} \\subset 2^\\Omega\\) 는 1. 전체집합을 포함하고, 2. 여집합에 닫혀있고 3. 가산합집합에 닫혀있는 collection 이다.\n\n먼저 강의노트를 참고하여 아래의 사실을 보이자.\n\n\\(A,B \\in {\\cal F} \\Rightarrow A \\cap B \\in {\\cal F}\\)\n\\(A,B \\in {\\cal F} \\Rightarrow A - B \\in {\\cal F}\\)\n\n이제 풀어보자.\n1번\n\n\\(\\{1,2\\} \\in \\sigma({\\cal A})\\), \\(\\{1\\} \\in \\sigma({\\cal A})\\)\n\\(\\Rightarrow\\) \\(\\{1,2\\} - \\{1\\} = \\{2\\} \\in \\sigma({\\cal A})\\) (\\(\\because\\) (b))\n\n2번\n\n\\(\\{1,2\\}-\\{1\\} = \\{2\\} \\in \\sigma({\\cal A})\\), \\(\\{1,2,3\\} - \\{1,2\\} = \\{3\\} \\in \\sigma({\\cal A})\\), \\(\\{1,2,3,4\\} - \\{1,2,3\\} = \\{4\\} \\in \\sigma({\\cal A})\\).\n\\(\\Rightarrow\\) \\(\\{2\\}\\cup \\{3\\} \\cup \\{4\\} = \\{2,3,4\\} \\in \\sigma({\\cal A})\\)\n\n3번\n\n\\(\\{3,4,5\\} \\not \\in \\sigma({\\cal A})\\)\n\n4번\n\n\\(\\{1,2,3\\}\\in \\sigma({\\cal A})\\)\n\\(\\Rightarrow \\{1,2,3\\}^c \\in \\sigma({\\cal A})\\)\n\n(4) \\(\\Omega=[0,2\\pi)\\) 일 때,\n\\[{\\cal A}=\\{ [a,b): 0\\leq a&lt; b\\leq 2\\pi\\}\\]\n이라고 하자. 아래의 물음에 답하여라.\n\n\\([\\frac{\\pi}{2},\\pi) \\in \\sigma({\\cal A})\\) 인가?\n\\(\\{\\pi\\} \\in \\sigma({\\cal A})\\) 인가?\n\\(\\{0,\\frac{\\pi}{2},\\pi,\\frac{3\\pi}{2}\\} \\in \\sigma({\\cal A})\\) 인가?\n\\((\\frac{\\pi}{2},\\pi) \\in \\sigma({\\cal A})\\) 인가?\n\n\n수업시간에 2번문제 잘못해설했어요. (문제도 잘못냈어요, 너무 어렵게 냈어요. )\n\n(풀이)\n\n\\(a=\\frac{\\pi}{2}\\), \\(b=\\pi\\)\n\\([0,\\pi)~ \\bigcup ~\\cup_{i=1}^{\\infty}[\\pi+\\frac{1}{n}, 2\\pi) = [0,\\pi) \\cup (\\pi,2\\pi)\\) \\(\\Rightarrow\\) \\(\\Omega - \\big([0,\\pi) \\cup (\\pi,2\\pi) \\big) = \\{\\pi\\} \\in \\sigma({\\cal A})\\)\n\n\n\\([\\pi+\\frac{1}{n}, 2\\pi)\\)는 각각 잴 수 있는 집합이므로 \\(\\cup_{i=1}^{\\infty}[\\pi+\\frac{1}{n}, 2\\pi)\\) 역시 잴 수 있는 집합이다.\n여기에서 \\(\\cup_{i=1}^{\\infty}[\\pi+\\frac{1}{n}, 2\\pi)=(\\pi,2\\pi)\\) 로 볼 수 있는데, 그 이유는 \\(\\cup_{i=1}^{\\infty}[\\pi+\\frac{1}{n}, 2\\pi)\\)는 \\(\\pi\\)보다 큰 모든수를 포함하지만 \\(\\pi\\)는 포함할 수 없기 때문이다.\n\\([0, \\pi)\\)도 당연히 잴 수 있는 집합이다.\n잴 수 있는 집합의 교집합은 잴 수 있으므로 \\([0,\\pi)~ \\cup ~(\\pi,2\\pi)\\) 역시 잴 수 있는 집합이다.\n따라서 \\([0,2\\pi) - \\big([0,\\pi) \\cup (\\pi,2\\pi) \\big)\\) 역시 잴 수 있다.\n\n\n\\(\\{\\pi\\}\\)를 잴수 있다는 것과 동일한 논리전개로 \\(\\{0\\},\\{\\frac{\\pi}{2}\\}, \\{\\frac{3\\pi}{2}\\}\\) 모두 잴 수 있는 집합이고, 따라서 이들의 합집합도 잴 수 있다.\n\\([\\frac{\\pi}{2}, \\pi)\\)를 잴 수 있고 \\(\\{\\frac{\\pi}{2}\\}\\)를 잴 수 있으므로 \\([\\frac{\\pi}{2}, \\pi) - \\{\\frac{\\pi}{2}\\}\\) 역시 잴 수 있다.\n\n\n\n3. 확률과 확률변수\n(1) 아래와 같은 measurable space \\((\\Omega, {\\cal F})\\)를 고려하자.\n\n\\(\\Omega=\\{a,b,c,d\\}\\)\n\\({\\cal F}=2^\\Omega\\)\n\n아래와 같은 확률변수 \\(X: \\Omega \\to \\{1,2,3,4\\}\\) 를 고려하자. 다음중 올바른 표현은?\n\n\\(X(a)\\)\n\\(X(\\{a\\})\\)\n\\(P(a)\\)\n\\(P(\\{a\\})\\)\n\\(P(X=1)\\)\n\\(X = \\begin{cases} 1 & w.p.~\\frac{1}{2} \\\\ 2 & w.p. ~\\frac{1}{6} \\\\ 3 & w.p. ~\\frac{1}{6} \\\\ 4 & w.p. ~\\frac{1}{6} \\end{cases}\\)\n\n(풀이) 생략 (이 문제는 그대로 낼거라서요, 풀이 생략합니다. 스스로 해보세요. 시험에서는 답만쓰면 정답으로 인정합니다)\n(2) 아래와 같은 measurable space를 고려하자.\n\n\\(\\Omega=\\{a,b,c,d\\}\\)\n\\({\\cal F} =\\sigma({\\cal A})\\) where \\({\\cal A} = \\{\\{a\\}\\}\\).\n\n아래와 같은 function \\(X:\\Omega \\to A:=\\{1,2,3,4\\}\\), \\(Y:\\Omega \\to B:=\\{1,2\\}\\)을 고려하자.\n\n\\(X(a)=1, X(b)=2, X(c)=3, X(d)=4\\)\n\\(Y(a)=1, Y(b)=2, Y(c)=2, Y(c)=2\\)\n\n아래의 물음에 답하라.\n\n\\(X\\)는 \\((\\Omega,{\\cal F}) \\to (A,2^{A})\\) 인가? 즉 \\(X\\)는 \\((\\Omega,{\\cal F})\\) 에서의 확률변수인가?\n\\(Y\\)는 \\((\\Omega,{\\cal F}) \\to (B,2^{B})\\) 인가? 즉 \\(Y\\)는 \\((\\Omega,{\\cal F})\\) 에서의 확률변수인가?\n\n(풀이)\n\\(X\\)는 확률변수가 아님\n집합 \\(\\{2\\} \\subset 2^A\\)에 대하여 \\(\\{\\omega: X(\\omega) \\in \\{2\\}\\}=\\{b\\} \\not \\in \\sigma({\\cal A})\\) 이므로 \\(X\\)는 확률변수가 아님\n\\(Y\\)는 확률변수임\n\\(2^B = \\{\\emptyset,\\{1\\},\\{2\\},B\\}\\) 의 모든 부분집합 \\(B^\\ast\\)에 대하여 \\(\\{\\omega: X(\\omega) \\in B^\\ast\\} \\in \\sigma({\\cal A})\\) 이 성립함.\n\n\\(\\{\\omega: X(\\omega) \\in \\emptyset\\} = \\emptyset \\in \\sigma({\\cal A})\\)\n\\(\\{\\omega: X(\\omega) \\in \\{1\\}\\} = \\{a\\} \\in \\sigma({\\cal A})\\)\n\\(\\{\\omega: X(\\omega) \\in \\{2\\}\\} = \\{b,c,d\\} \\in \\sigma({\\cal A})\\)\n\\(\\{\\omega: X(\\omega) \\in B\\} = \\{a,b,c,d\\} \\in \\sigma({\\cal A})\\)"
  },
  {
    "objectID": "posts/ap/2023-04-27-9wk-1.html",
    "href": "posts/ap/2023-04-27-9wk-1.html",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-xbWjXgaQNqqqZDzuV1QsgL"
  },
  {
    "objectID": "posts/ap/2023-04-27-9wk-1.html#motivating-examples-cont",
    "href": "posts/ap/2023-04-27-9wk-1.html#motivating-examples-cont",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "Motivating Examples (cont)",
    "text": "Motivating Examples (cont)\n반복되는 느낌이 있으면 periodic\n\n예제3\n- 아래의 전이확률을 고려하자.\n\nP =np.array([0.0, 1.0, 0.0, 0.0, \n             1/2, 0.0, 1/2, 0.0,\n             0.0, 0.0, 0.0, 1.0,\n             0.0, 1.0, 0.0, 0.0]).reshape(4,4)\nP\n\narray([[0. , 1. , 0. , 0. ],\n       [0.5, 0. , 0.5, 0. ],\n       [0. , 0. , 0. , 1. ],\n       [0. , 1. , 0. , 0. ]])\n\n\n- 다이어그램\n\n\n\n\nflowchart LR\n  0 --&gt;|1| 1\n  1 --&gt;|1/2| 0\n  1 --&gt;|1/2| 2\n  2 --&gt;|1| 3\n  3 --&gt;|1| 1\n\n\n\n\n\n- 특징1,2:\n\nnp.matrix(P)**500\n\nmatrix([[0.2, 0.4, 0.2, 0.2],\n        [0.2, 0.4, 0.2, 0.2],\n        [0.2, 0.4, 0.2, 0.2],\n        [0.2, 0.4, 0.2, 0.2]])\n\n\n- 특징3: 정상분포를 가짐\n- 특징4: 초기분포가 정상분포라면 정상확률과정\n- 특징5: irr\n- 특징6: 주기가 없음\n\n\n\n\nflowchart LR\n  0 --&gt;|1| 1\n  1 --&gt;|1/2| 0\n  1 --&gt;|1/2| 2\n  2 --&gt;|1| 3\n  3 --&gt;|1| 1\n\n\n\n\n\n1에서 시작한다면?\n\n\\(1 \\to 0 \\to 1\\), 2번만에 리턴\n\\(1 \\to 2 \\to 3 \\to 1\\), 3번만에 리턴\n\n이 경우 2와 3의 최대공약수는 1이므로 주기는 1이다. 그리고 finite state space를 가지는 HMC는 모든 state가 항상 같은 주기를 가지므로 이 마코프체인의 모든 주기는 1이다.\n\n주기가 1인 경우는 aperiodic 하다고 표현한다. (언제 올지 몰라)\n\n\n꿀팁: 자기자신으로 1턴만에 되돌아올 확률이 있다면 항상 aperiodic 하다."
  },
  {
    "objectID": "posts/ap/2023-04-27-9wk-1.html#정의-및-이론",
    "href": "posts/ap/2023-04-27-9wk-1.html#정의-및-이론",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "정의 및 이론",
    "text": "정의 및 이론\n- 정의:\n- 느낌: 상태 \\(i\\)에서 \\(i\\)로 되돌아오는 횟수들의 최대공약수를 HMC \\(\\{X_t\\}\\)의 period라고 하고, period=1인 경우를 aperiodic 이라고 한다.\n- 이론: HMC \\(\\{X_t\\}\\)이 IRR이면, 모든 상태가 항상 같은 주기를 가진다."
  },
  {
    "objectID": "posts/ap/2023-04-27-9wk-1.html#정의-및-이론-1",
    "href": "posts/ap/2023-04-27-9wk-1.html#정의-및-이론-1",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "정의 및 이론",
    "text": "정의 및 이론\n- Thm: HMC \\(\\{X_t\\}\\)가 (1) finite state space를 가지고 (2) irreduciable 하고 (3) aperiodic 이라면, \\({\\bf P}\\)가 수렴하고 수렴한 matrix의 모든 row는 같다. 따라서 임의의 초기분포 \\({\\boldsymbol \\mu}\\) 에 대하여\n\\[\\lim_{t\\to \\infty}{\\boldsymbol \\mu}^\\top{\\bf P}^t = {\\boldsymbol \\pi}^\\top \\]\n이 성립한다. 여기에서 \\({\\boldsymbol \\pi}\\)는 \\(\\{X_t\\}\\)의 정상분포이다.\n- 정의: 아래의 식을 만족하는 HMC \\(\\{X_t\\}\\)을 에르고딕하다고 말한다.\n\\[\\lim_{t\\to \\infty}{\\boldsymbol \\mu}^\\top{\\bf P}^t = {\\boldsymbol \\pi}^\\top \\]\n(1)이 성립하면 정상분포가 하나 이상 존재한다는 뜻, (2)가 성립하면 unique한 stationary한 distribution이 존재 (3)이 성립하면 에르고딕하다고 함"
  },
  {
    "objectID": "posts/ap/2023-04-27-9wk-1.html#intro",
    "href": "posts/ap/2023-04-27-9wk-1.html#intro",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "intro",
    "text": "intro\n- Google\n\nGoogle은 사용자의 검색어와 일치하는 검색 결과를 제공\nGoogle은 웹사이트들 사이에서 “더 나은” 또는 “더 중요한” 웹사이트가 검색 결과 상위에 나타나도록 순위를 유지\n이 순위는 전체 문제를 한 번에 해결하는 것이 아니라 먼저 전체적으로 수립되고(검색어와는 독립적으로), 그 후에 검색어와 일치하는 웹사이트들만 해당 순위에 따라 정렬된다고 함\n\n- 이 강의에서는 순위 매기기에 초점을 맞추어 생각해보자. (이는 마코프체인과 관련이 있음)\n\nref: https://en.wikipedia.org/wiki/PageRank\n\n- 페이지랭크\n\n페이지랭크(PageRank)는 구글 검색에서 웹 페이지의 순위를 결정하는 알고리즘으로 이는 “웹 페이지”와 구글 공동 창업자인 라리 페이지(Larry Page)의 이름을 따서 지어졌음\n페이지랭크는 웹사이트 페이지의 중요성을 측정하는 방법이며 기본적으로 더 중요한 웹사이일수록 다른 웹사이트에서 더 많은 링크를 받을 가능성이 높다는 점에 착안함\n페이지랭크는 구글이 검색 결과를 정렬하는 데 사용하는 유일한 알고리즘이 아니지만, 구글에서 사용한 최초의 알고리즘이며, 가장 잘 알려진 알고리즘임"
  },
  {
    "objectID": "posts/ap/2023-04-27-9wk-1.html#toy-example",
    "href": "posts/ap/2023-04-27-9wk-1.html#toy-example",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "toy example",
    "text": "toy example\n- 아래는 7개의 website에 대한 web graph이다.\n\n\n\n\nflowchart LR\n  0 --&gt;|1/2| 1\n  1 --&gt;|1/2| 0\n  0 --&gt;|1/2| 2\n  1 --&gt;|1/2| 2\n  2 --&gt;|1| 3 \n  4 --&gt;|1| 3\n  3 --&gt;|1| 5 \n  6 --&gt;|1| 5\n\n\n\n\n\n- 여기에서 가장 중요한 웹사이트는 무엇일까?\n\n구글의 아이디어는 기본적으로 더 많은 화살표를 받는 쪽이 더 중요한 웹사이트이다 라는 것이었다.\n이 논리대로라면 노드 2,3,5가 똑같이 중요해보인다.\n좀 더 생각해보니까 노드2보다 노드3과 노드5가 더 중요해보인다. 왜냐하면 노드2는 확률 1/2 짜리 화살표 2개이지만 노드3과 노드5는 확률 1짜리 화살표가 2개임\n그렇지만 또 노드3보다는 노드5가 더 중요해보인다. 왜냐하면 노드3을 방문한 사람은 결국은 노드5로 갈테니까 노드3보다 노드5가 더 중요한 사이트라고 볼 수 있다.\n그럼 노드3의 중요도가 1일때 노드5의 중요도는 얼마정도 될까?\n\n- 구글의 아이디어: random surfer\n\n무작위로 웹사이트를 방문하는 가상의 유저를 만들자.\n그리고 이 유저가 많이 방문하게 되는 웹사이트를 기록하자.\n\n- 구글의 아이디어는 결국 위의 다이어그램을 토대로 transition matrix \\({\\bf P}\\)를 만들고 임의의 초기상태 \\({\\boldsymbol \\mu}\\)에 대하여\n\\[\\lim_{t\\to\\infty}{\\boldsymbol \\mu}^\\top{\\bf P}^{t}\\]\n를 계산하겠다는 의미이다.\n- 문제점1: 이 상황은 transition matrix를 만들 수 없는걸?\n\nP = np.array([0.0, 1/2, 1/2, 0.0, 0.0, 0.0, 0.0,\n              1/2, 0.0, 1/2, 0.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ### 이 부분은 다 0이다. \n              0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]).reshape(7,7)\nP\n\narray([[0. , 0.5, 0.5, 0. , 0. , 0. , 0. ],\n       [0.5, 0. , 0.5, 0. , 0. , 0. , 0. ],\n       [0. , 0. , 0. , 1. , 0. , 0. , 0. ],\n       [0. , 0. , 0. , 0. , 0. , 1. , 0. ],\n       [0. , 0. , 0. , 1. , 0. , 0. , 0. ],\n       [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n       [0. , 0. , 0. , 0. , 0. , 1. , 0. ]])\n\n\n- 문제점1의 해결: 이러한 경우 상태5에서 다른상태로 갈 확률은 랜덤으로 다시 뿌린다.\n\nP = np.array([0.0, 1/2, 1/2, 0.0, 0.0, 0.0, 0.0,\n              1/2, 0.0, 1/2, 0.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n              1/7, 1/7, 1/7, 1/7, 1/7, 1/7, 1/7, ### 이렇게 고쳐버리자~\n              0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]).reshape(7,7)\nP\n\narray([[0.        , 0.5       , 0.5       , 0.        , 0.        ,\n        0.        , 0.        ],\n       [0.5       , 0.        , 0.5       , 0.        , 0.        ,\n        0.        , 0.        ],\n       [0.        , 0.        , 0.        , 1.        , 0.        ,\n        0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        1.        , 0.        ],\n       [0.        , 0.        , 0.        , 1.        , 0.        ,\n        0.        , 0.        ],\n       [0.14285714, 0.14285714, 0.14285714, 0.14285714, 0.14285714,\n        0.14285714, 0.14285714],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        1.        , 0.        ]])\n\n\n- 문제점2: \\(\\lim_{t\\to\\infty}{\\boldsymbol \\mu}^\\top{\\bf P}^{t}\\)이게 수렴한다는 보장이 어디있지?"
  },
  {
    "objectID": "posts/ap/2023-04-27-9wk-1.html#수렴의-트릭",
    "href": "posts/ap/2023-04-27-9wk-1.html#수렴의-트릭",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "수렴의 트릭",
    "text": "수렴의 트릭\n- 생각: HMC \\(\\{X_t\\}\\)가 에르고딕이려면 (1) finite state space를 가지고 (2) irreducible (3) aperiodic 해야한다.\n- 그런데 (N,N) 차원을 가지는 임의의 transition matrix \\({\\bf P}\\)를 아래와 같이 \\(\\tilde{\\bf P}\\)로 변형한다면 이 transition matrix는 aperiodic하고 irreducible하게 된다.\n\\[\\tilde{\\bf P} = 0.99 \\cdot {\\bf P} + 0.01 \\cdot \\frac{1}{N}{\\bf J}\\]\n여기에서 \\({\\bf J}\\)는 \\({\\bf P}\\)와 차원이 같고 모든 원소가 1인 매트릭스이다. 즉\n\\[{\\bf J} = \\begin{bmatrix} 1 & 1 & \\dots & 1 \\\\ 1 & 1 & \\dots & 1 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ 1 & 1 & \\dots & 1 \\end{bmatrix}\\]\n이다.\n- 위의 수식에서 \\(\\tilde{\\bf P}\\)는 \\({\\bf P}\\)와 매우 비슷하지만 에르고딕한 마코프체인이다.\n- 이러한 \\(\\tilde{\\bf P}\\)를 구글매트릭스라고 부르자. 위의 식을 좀 더 간결하게 쓰면\n\\[{\\bf GoogleMatrix}:= \\alpha\\cdot {\\bf P} + (1-\\alpha)\\cdot\\frac{1}{N}{\\bf J}\\]\n와 같이 된다. 여기에서 \\(\\alpha \\in (0,1)\\) 이다.\n- 여기에서 \\(\\alpha\\)는 수렴의 속도를 결정한다.\n\n\\({\\bf P}\\)가 원래 수렴안하는 조건이었다면 \\(\\alpha \\approx 1\\) 일수록 구글매트릭스는 매우 느리게 수렴할 것이다.\n\\(\\alpha=0\\) 이라면 구글매트릭스는 이미 수렴되어 있다."
  },
  {
    "objectID": "posts/ap/2023-04-27-9wk-1.html#구현",
    "href": "posts/ap/2023-04-27-9wk-1.html#구현",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "구현",
    "text": "구현\n\nP = np.array([0.0, 1/2, 1/2, 0.0, 0.0, 0.0, 0.0,\n              1/2, 0.0, 1/2, 0.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n              1/7, 1/7, 1/7, 1/7, 1/7, 1/7, 1/7,\n              0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]).reshape(7,7)\nP\n\narray([[0.        , 0.5       , 0.5       , 0.        , 0.        ,\n        0.        , 0.        ],\n       [0.5       , 0.        , 0.5       , 0.        , 0.        ,\n        0.        , 0.        ],\n       [0.        , 0.        , 0.        , 1.        , 0.        ,\n        0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        1.        , 0.        ],\n       [0.        , 0.        , 0.        , 1.        , 0.        ,\n        0.        , 0.        ],\n       [0.14285714, 0.14285714, 0.14285714, 0.14285714, 0.14285714,\n        0.14285714, 0.14285714],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        1.        , 0.        ]])\n\n\n\nalpha= 0.85 \nJ = np.ones(49).reshape(7,7)\nGoogleMatrix = alpha*P + (1-alpha)/7 \n\nalph가 1에 가까울수록 P랑 비슷해지고, 0에 가까워질수록 수렴한다.\n\nnp.linalg.matrix_power(GoogleMatrix,100)[0].round(3).tolist()\n\n[0.102, 0.102, 0.145, 0.231, 0.058, 0.304, 0.058]\n\n\n\nimport pandas as pd \npd.DataFrame({'website':['state'+i for i in '0123456'], \n             'pagerank': np.linalg.matrix_power(GoogleMatrix,100)[0].round(3).tolist()})\n\n\n\n\n\n\n\n\nwebsite\npagerank\n\n\n\n\n0\nstate0\n0.102\n\n\n1\nstate1\n0.102\n\n\n2\nstate2\n0.145\n\n\n3\nstate3\n0.231\n\n\n4\nstate4\n0.058\n\n\n5\nstate5\n0.304\n\n\n6\nstate6\n0.058"
  },
  {
    "objectID": "posts/ap/2023-04-27-9wk-1.html#다른풀이",
    "href": "posts/ap/2023-04-27-9wk-1.html#다른풀이",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "다른풀이",
    "text": "다른풀이\n\n_, eigen_vector_matrix = np.linalg.eig(GoogleMatrix.T)\n\n고유값 1이 나오는 값을 찾아주자\n\nabs(eigen_vector_matrix[:,0])/ abs(eigen_vector_matrix[:,0]).sum()\n\narray([0.10154862, 0.10154862, 0.14470678, 0.2310231 , 0.05839045,\n       0.30439198, 0.05839045])"
  },
  {
    "objectID": "posts/ap/2023-04-27-9wk-1.html#페이지랭크의-약점",
    "href": "posts/ap/2023-04-27-9wk-1.html#페이지랭크의-약점",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "페이지랭크의 약점",
    "text": "페이지랭크의 약점\n- 아래와 같은 상황을 고려하자.\n\n\n\n\nflowchart LR\n  0 --&gt;|1/2| 1\n  1 --&gt;|1/2| 0\n  0 --&gt;|1/2| 2\n  1 --&gt;|1/2| 2\n  2 --&gt;|1| 3 \n  4 --&gt;|1| 3\n\n\n\n\n\n여기서는 어차피 3번으로 갈테니까 3번이 중요\n\nP = np.arrfffq([1/5, 1/5,\n              0.0, 0.0, 0.0, 1.0, 0.0]).reshape(5,5)\nP\n\narray([[0. , 0.5, 0.5, 0. , 0. ],\n       [0.5, 0. , 0.5, 0. , 0. ],\n       [0. , 0. , 0. , 1. , 0. ],\n       [0.2, 0.2, 0.2, 0.2, 0.2],\n       [0. , 0. , 0. , 1. , 0. ]])\n\n\n\nGoogleMatrix = P*0.85 + 0.15/5 \n\n\nnp.linalg.matrix_power(GoogleMatrix,100)\n\narray([[0.15936255, 0.15936255, 0.22709163, 0.3625498 , 0.09163347],\n       [0.15936255, 0.15936255, 0.22709163, 0.3625498 , 0.09163347],\n       [0.15936255, 0.15936255, 0.22709163, 0.3625498 , 0.09163347],\n       [0.15936255, 0.15936255, 0.22709163, 0.3625498 , 0.09163347],\n       [0.15936255, 0.15936255, 0.22709163, 0.3625498 , 0.09163347]])\n\n\n- 우리는 여기에서 1번네트워크의 page rank를 올리고 싶다고 가정하자. (현재는 5개중 0.15936255)\n\n\n\n\nflowchart LR\n  0 --&gt;|1/2| 1\n  1 --&gt;|1/2| 0\n  0 --&gt;|1/2| 2\n  1 --&gt;|1/2| 2\n  2 --&gt;|1| 3 \n  4 --&gt;|1| 3\n\n\n\n\n\nStep1: 먼저 1번에서 다른쪽으로 가는 모든 링크를 끊는다. (다른 웹사이트의 page rank를 올려줄 이유가 없음)\n\n\n\n\nflowchart LR\n  0 --&gt;|1/2| 1\n  0 --&gt;|1/2| 2\n  2 --&gt;|1| 3 \n  4 --&gt;|1| 3\n\n\n\n\n\n\nP = np.array([0.0, 1/2, 1/2, 0.0, 0.0,\n              1/5, 1/5, 1/5, 1/5, 1/5,\n              0.0, 0.0, 0.0, 1.0, 0.0,\n              1/5, 1/5, 1/5, 1/5, 1/5,\n              0.0, 0.0, 0.0, 1.0, 0.0]).reshape(5,5)\n\n\nGoogleMatrix = P*0.85 + 0.15/5 \nnp.linalg.matrix_power(GoogleMatrix,100)\n\narray([[0.12640228, 0.18012324, 0.18012324, 0.38694897, 0.12640228],\n       [0.12640228, 0.18012324, 0.18012324, 0.38694897, 0.12640228],\n       [0.12640228, 0.18012324, 0.18012324, 0.38694897, 0.12640228],\n       [0.12640228, 0.18012324, 0.18012324, 0.38694897, 0.12640228],\n       [0.12640228, 0.18012324, 0.18012324, 0.38694897, 0.12640228]])\n\n\nStep2: 3개의 더미사이트 5,6,7을 만들어서 1번네트워크와 서로 연결시킨다.\n\n\n\n\nflowchart LR\n  0 --&gt;|1/2| 1\n  0 --&gt;|1/2| 2\n  2 --&gt;|1| 3 \n  4 --&gt;|1| 3\n  1 --&gt;|1/3| 5\n  5 --&gt;|1| 1\n  1 --&gt;|1/3| 6\n  6 --&gt;|1| 1\n  1 --&gt;|1/3| 7 \n  7 --&gt;|1| 1 \n\n\n\n\n\n\nP = np.array([0.0, 1/2, 1/2, 0.0, 0.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 0.0, 0.0, 1/3, 1/3, 1/3,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n              1/8, 1/8, 1/8, 1/8, 1/8, 1/8, 1/8, 1/8,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n              0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n              0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n              0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]).reshape(8,8)\n\n\nGoogleMatrix = P*0.85 + 0.15/8\npagerank =np.linalg.matrix_power(GoogleMatrix,100)[0]\npagerank\n\narray([0.02778839, 0.39804992, 0.03959846, 0.08506721, 0.02778839,\n       0.14056921, 0.14056921, 0.14056921])\n\n\n\nwebsite = ['state'+i for i in '01234567']\nwebsite\n\n['state0',\n 'state1',\n 'state2',\n 'state3',\n 'state4',\n 'state5',\n 'state6',\n 'state7']\n\n\n\npd.DataFrame({'pagerank':pagerank,'website':website})\n\n\n\n\n\n\n\n\npagerank\nwebsite\n\n\n\n\n0\n0.027788\nstate0\n\n\n1\n0.398050\nstate1\n\n\n2\n0.039598\nstate2\n\n\n3\n0.085067\nstate3\n\n\n4\n0.027788\nstate4\n\n\n5\n0.140569\nstate5\n\n\n6\n0.140569\nstate6\n\n\n7\n0.140569\nstate7\n\n\n\n\n\n\n\n- 약점을 극복한 구글의 아이디어: 저도 몰라용.."
  },
  {
    "objectID": "posts/ap/2023-03-28-ap-04wk.html",
    "href": "posts/ap/2023-03-28-ap-04wk.html",
    "title": "04wk: 측도론 intro (4)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-ysaKaydM8V9RauAwOaUhSN"
  },
  {
    "objectID": "posts/ap/2023-03-28-ap-04wk.html#상황1-시그마필드-구하기-귀찮아",
    "href": "posts/ap/2023-03-28-ap-04wk.html#상황1-시그마필드-구하기-귀찮아",
    "title": "04wk: 측도론 intro (4)",
    "section": "상황1: 시그마필드 구하기 귀찮아",
    "text": "상황1: 시그마필드 구하기 귀찮아\n(예제1)\n- \\(\\Omega=\\{1,2,3,4\\}\\)이라고 하자. 내가 관심있는 event의 모음은 아래와 같다.\n\\[{\\cal A} = \\{\\{1\\},\\{2\\}\\}\\]\n- 당연히 이러한 이벤트에 대해서만 적절한 확률을 정의하면 좋겠는데, 이는 불가능 하다. 왜냐하면 \\({\\cal A}\\)는 시그마필드가 아니기 때문이다.\n- 따라서 할 수 없이 아래와 같은 방식으로 시그마필드를 구해야 했다.\n\\[{\\cal F} = \\big\\{\\emptyset, \\{1\\}, \\{2\\}, \\{1,2\\}, \\{3,4\\}, \\{1,3,4\\}, \\{2,3,4\\}, \\Omega \\big\\}\\]\n- 이러한 \\({\\cal F}\\)를 구하기는 것은 귀찮은 일인데, 이를 편리하게 해결하기 위해서 \\(\\sigma({\\cal A})\\)라는 기호를 도입하고 이를 “\\(\\{1\\}\\), \\(\\{2\\}\\)를 원소로 가지는 최소한의 \\({\\cal F}\\)” 라고 생각 하기로 하였다. 즉 앞으로는\n\\[\\sigma({\\cal A})\\]\n라고만 써도 위에서 명시한 \\({\\cal F}\\)를 의미한다고 알아서 생각하면 된다는 것이다.\n걱정: 문제는 이러한 논리전개가 항상 가능하냐는 것이다.\n\n귀찮아서 만든 이론1: 걱정할 필요 없다. 언제나 \\(\\sigma({\\cal A})\\)라는 표현은 가능하다. 즉 \\(\\Omega\\)의 임의의 부분집합에 대하여 우리가 관심있는 집합만 모은 것을 \\({\\cal A}\\)라고 할때, \\({\\cal A}\\)의 모든 원소를 포함하고 시그마필드의 정의를 만족하는 최소한의 시그마필드 \\(\\sigma({\\cal A})\\)는 항상 존재한다.\n\n(예제2)\n\\(\\Omega = \\mathbb{R}\\) 이라고 하자. 이중에서 우리가 관심있는 집합들은 르벡메져로 길이를 명확하게 잴 수 있는 아래와 같은 형태이다.\n\\[[a,b]\\]\n여기에서 \\(a,b \\in \\mathbb{R}\\), \\(a&lt;b\\) 이라고 하자. 따라서 이 경우 \\({\\cal A}\\)를 아래와 같이 설정할 수 있다.\n\\[{\\cal A} = \\big\\{[a,b]: a,b \\in \\mathbb{R}, a&lt;b \\big\\}\\]\n이제 \\(\\sigma({\\cal A})\\)를 상상하자. 이는 \\(\\Omega=\\mathbb{R}\\)에서 잴 수 있는 집합들의 모임이다. 편의상 \\(\\sigma({\\cal A}):={\\cal R}\\)로 정의하자. 여기에서 \\({\\cal R}\\) 상당히 많은 케이스를 포함하는 집합이다. 예를들면 아래와 같은 집합들은 모두 \\({\\cal R}\\)의 원소이다. (즉 아래의 집합은 \\([a,b]\\)를 잴 수 있다고 할때, 당연히 잴 수 있다고 여겨지는 집합들이다.)\n\n\\([0,2)\\)\n\\(\\{2\\}\\)\n\\((0,2)\\)\n\\([0,\\infty)\\), \\((0,\\infty)\\)\n\\((-\\infty,0)\\), \\((-\\infty,0]\\)\n\\([1,2] \\cup [3,4]\\)\n\\((1,2] \\cup [3,4)\\)\n\\(\\mathbb{N}\\), \\(\\mathbb{Z}\\), \\(\\mathbb{Q}\\)\n\\([0,2] \\cap \\mathbb{Q}\\)\n\n\n사실상 \\({\\cal R}=\\sigma({\\cal A})\\)와 같은 기호가 없다면 \\(\\mathbb{R}\\)에서 잴 수 있는 집합들의 모임은 명시적으로 쓰는 것 자체가 불가능함."
  },
  {
    "objectID": "posts/ap/2023-03-28-ap-04wk.html#상황2-확률-정의하기-귀찮아",
    "href": "posts/ap/2023-03-28-ap-04wk.html#상황2-확률-정의하기-귀찮아",
    "title": "04wk: 측도론 intro (4)",
    "section": "상황2: 확률 정의하기 귀찮아",
    "text": "상황2: 확률 정의하기 귀찮아\n(예제1) – motivating EX\n- \\(\\Omega=\\{1,2,3,4\\}\\)이라고 하자. 내가 관심있는 집합의 모음은 아래와 같다.\n\\[{\\cal A} = \\{\\emptyset, \\{1\\},\\{2\\},\\{3,4\\},\\Omega\\}\\]\n- 여기에서 \\({\\cal A}\\)는 시그마필드가 아니다. 따라서 \\({\\cal A}\\)에서는 확률을 정의할 수 없다. 확률을 정의하려면 \\(\\sigma({\\cal A})\\)에서 정의해야 한다.\n- 소망: 그래도 그냥 \\({\\cal A}\\)에서만 확률 비슷한걸5 잘 정의하면 안될까?\n- 희망: 이게 될 것 같다. 예를들면 함수 \\(\\tilde{P}:{\\cal A} \\to [0,1]\\)를 아래와 같이 정의하자.\n\n\\(\\tilde{P}(\\emptyset) = 0\\)\n\\(\\tilde{P}(\\{1\\}) = 1/4\\)\n\\(\\tilde{P}(\\{2\\}) = 1/2\\)\n\\(\\tilde{P}(\\{3,4\\}) = 1/4\\)\n\\(\\tilde{P}(\\Omega) = 1\\)\n\n이 정도만 정의해보자. \\(\\tilde{P}\\)는 정의역이 시그마필드가 아니라는 점만 제외하면 확률의 공리 1,2,3을 따른다. 이렇게 함수 \\(\\tilde{P}\\)를 정의하게 되면\n\\[\\sigma({\\cal A}) = \\big\\{\\emptyset, \\{1\\}, \\{2\\}, \\{1,2\\}, \\{3,4\\}, \\{1,3,4\\}, \\{2,3,4\\}, \\Omega \\big\\}\\]\n에서의 확률 \\(P:\\sigma({\\cal A}) \\to [0,1]\\)는 확률 비슷한 함수 \\(\\tilde{P}\\)를 “알아서, 잘, 센스있게” 확장하여 정의할 수 있다. 구체적으로는 아래와 같이 된다.\n\n\n\n\n\\(P\\)\n\\(\\tilde{P}\\)\n\n\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{1\\}\\)\n\\(\\frac{1}{4}\\)\n\\(\\frac{1}{4}\\)\n\n\n\\(\\{2\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{3,4\\}\\)\n\\(\\frac{1}{4}\\)\n\\(\\frac{1}{4}\\)\n\n\n\\(\\Omega\\)\n\\(1\\)\n\\(1\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\{1,2\\}\\)\n\\(\\frac{3}{4}\\)\nNone\n\n\n\\(\\{1,3,4\\}\\)\n\\(\\frac{1}{2}\\)\nNone\n\n\n\\(\\{2,3,4\\}\\)\n\\(\\frac{3}{4}\\)\nNone\n\n\n\n(예제2) – motivating EX (2)\n- \\(\\Omega=\\{1,2,3,4\\}\\)이라고 하고 \\({\\cal A} = \\{\\emptyset, \\{1\\},\\{2\\}, \\{3,4\\}, \\Omega\\}\\) 라고 하자. 그리고 아래와 같은 \\(\\sigma({\\cal A})\\)를 다시 상상하자.\n\\[\\sigma({\\cal A}) = \\big\\{\\emptyset, \\{1\\}, \\{2\\}, \\{1,2\\}, \\{3,4\\}, \\{1,3,4\\}, \\{2,3,4\\}, \\Omega \\big\\}\\]\n- 위의 시그마필드에서 확률을 예제1과 다른 방식으로 정의할 수 도 있다. 예를들면 아래와 같은 방식으로 정의가능하다.\n\n\n\n\n\\(P_1\\)\n\\(\\tilde{P}_1\\)\n\n\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{1\\}\\)\n\\(\\frac{1}{3}\\)\n\\(\\frac{1}{3}\\)\n\n\n\\(\\{2\\}\\)\n\\(\\frac{1}{3}\\)\n\\(\\frac{1}{3}\\)\n\n\n\\(\\{3,4\\}\\)\n\\(\\frac{1}{3}\\)\n\\(\\frac{1}{3}\\)\n\n\n\\(\\Omega\\)\n\\(1\\)\n\\(1\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\{1,2\\}\\)\n\\(\\frac{2}{3}\\)\nNone\n\n\n\\(\\{1,3,4\\}\\)\n\\(\\frac{2}{3}\\)\nNone\n\n\n\\(\\{2,3,4\\}\\)\n\\(\\frac{2}{3}\\)\nNone\n\n\n\n또한 아래와 같은 방식도 가능하다.\n\n\n\n\n\\(P_2\\)\n\\(\\tilde{P}_2\\)\n\n\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{1\\}\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{2\\}\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{3,4\\}\\)\n\\(1\\)\n\\(1\\)\n\n\n\\(\\Omega\\)\n\\(1\\)\n\\(1\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\{1,2\\}\\)\n\\(0\\)\nNone\n\n\n\\(\\{1,3,4\\}\\)\n\\(1\\)\nNone\n\n\n\\(\\{2,3,4\\}\\)\n\\(1\\)\nNone\n\n\n\n- 어떠한 방식으로 정의하든 \\({\\cal A}\\)에서 확률 비슷한 것 \\(\\tilde{P}_1,\\tilde{P}_2\\)를 잘 정의하기만 \\(\\sigma({\\cal A})\\)에서의 확률 \\(P\\)로 적절하게 확장할 수 있다. 심지어 이런 확장은 유일한 듯 하다.\n\n귀찮아서 만든 이론2: 운이 좋다면, \\({\\cal A}\\) 에서 확률의 공리를 만족하는 적당한 함수 \\(\\tilde{P}:{\\cal A} \\to [0,1]\\)를 \\((\\Omega, \\sigma({\\cal A}))\\) 에서의 확률측도 \\(P\\)로 업그레이드 할 수 있으며 업그레이드 결과는 유일하다.\n\n(예제3) – 운이 안 좋은 경우\n- \\(\\Omega=\\{1,2,3\\}\\) 이라고 하고 \\({\\cal A} = \\{\\emptyset, \\{1,2\\},\\{2,3\\}, \\Omega\\}\\) 라고 하자.\n- 아래와 같은 확률 비슷한 함수 \\(\\tilde{P}:{\\cal A} \\to [0,1]\\)를 정의하자.\n\n\\(\\tilde{P}(\\emptyset) = 0\\)\n\\(\\tilde{P}(\\{1,2\\}) = 0\\)\n\\(\\tilde{P}(\\{2,3\\}) = 0\\)\n\\(\\tilde{P}(\\Omega) = 1\\)\n\n- \\(\\tilde{P}\\)는 분명히 \\({\\cal A}\\)에서 확률의 공리1-3을 만족한다.\n- 하지만 \\(\\sigma({\\cal A})\\)로의 확장은 불가능하다.\n(예제4) – 운이 안 좋은 경우\n- \\(\\Omega=\\{1,2,3,4\\}\\) 이라고 하고 \\({\\cal A} = \\{\\emptyset, \\{1,2\\},\\{2,3\\}, \\Omega\\}\\) 라고 하자.\n- 아래와 같은 확률 비슷한 함수 \\(\\tilde{P}:{\\cal A} \\to [0,1]\\)를 정의하자.\n\n\\(\\tilde{P}(\\emptyset) = 0\\)\n\\(\\tilde{P}(\\{1,2\\}) = 1/2\\)\n\\(\\tilde{P}(\\{2,3\\}) = 1/2\\)\n\\(\\tilde{P}(\\Omega) = 1\\)\n\n- \\(\\tilde{P}\\)는 분명히 \\({\\cal A}\\)에서 확률의 공리1-3을 만족한다.\n- \\(\\sigma({\\cal A})\\)로의 확장도 가능하다. 하지만 유일한 확장을 보장하지 않는다.\n\n\n\n\n\\(P_1\\)\n\\(P_2\\)\n\\(\\tilde{P}\\)\n\n\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{1,2\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{2,3\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\Omega\\)\n\\(1\\)\n\\(1\\)\n\\(1\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\{1\\}\\)\n\\(0\\)\n\\(\\frac{1}{2}\\)\nNone\n\n\n\\(\\{2\\}\\)\n\\(\\frac{1}{2}\\)\n\\(0\\)\nNone\n\n\n\\(\\{3\\}\\)\n\\(0\\)\n\\(\\frac{1}{2}\\)\nNone\n\n\n\\(\\{4\\}\\)\n\\(\\frac{1}{2}\\)\n\\(0\\)\nNone\n\n\n\\(\\{1,3\\}\\)\n\\(0\\)\n\\(1\\)\nNone\n\n\n\\(\\{1,4\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\nNone\n\n\n\\(\\{2,4\\}\\)\n\\(1\\)\n\\(0\\)\nNone\n\n\n\\(\\{3,4\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\nNone\n\n\n\\(\\{2,3,4\\}\\)\n\\(1\\)\n\\(\\frac{1}{2}\\)\nNone\n\n\n\\(\\{1,3,4\\}\\)\n\\(\\frac{1}{2}\\)\n\\(1\\)\nNone\n\n\n\\(\\{1,2,4\\}\\)\n\\(1\\)\n\\(\\frac{1}{2}\\)\nNone\n\n\n\\(\\{1,2,3\\}\\)\n\\(\\frac{1}{2}\\)\n\\(1\\)\nNone\n\n\n\n(예제5) – 혹시…\n- \\(\\Omega=\\mathbb{R}\\), \\({\\cal A}=\\big\\{[a,b]: a,b \\in \\mathbb{R}, a&lt;b \\big\\}\\) 라고 하자.\n- \\({\\cal A}\\)에서만 측도비슷한 함수 \\(\\tilde{m}([a,b])=b-a\\)를 잘 정의한다면 그것이 \\(\\sigma({\\cal A})\\)에서의 측도 \\(m\\)으로 업그레이드 가능하며, 그 업그레이드 결과는 유일할까?"
  },
  {
    "objectID": "posts/ap/2023-05-30-13wk-2.html",
    "href": "posts/ap/2023-05-30-13wk-2.html",
    "title": "13wk-2: MCMC (1)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-zyk8psVKy2OaZs3zV4ExWn"
  },
  {
    "objectID": "posts/ap/2023-05-30-13wk-2.html#균등분포",
    "href": "posts/ap/2023-05-30-13wk-2.html#균등분포",
    "title": "13wk-2: MCMC (1)",
    "section": "균등분포",
    "text": "균등분포\n- 가정: 균등분포에서는 뽑을 수 있다고 가정한다. (제가 사실 여기는 잘 몰라요)\n\n\n\n그림1: 균등분포를 생성하는 원리에 대하여 chatGPT에게 물어봄\n\n\n- 균등분포 이외의 난수는 어떻게?… (어려워요)"
  },
  {
    "objectID": "posts/ap/2023-05-30-13wk-2.html#베르누이-이항분포-포아송-지수분포",
    "href": "posts/ap/2023-05-30-13wk-2.html#베르누이-이항분포-포아송-지수분포",
    "title": "13wk-2: MCMC (1)",
    "section": "베르누이, 이항분포, 포아송, 지수분포",
    "text": "베르누이, 이항분포, 포아송, 지수분포\n- 베르누이\n\nx = np.random.rand(1000)\nplt.hist(x);\n\n\n\n\n\nfig, ax = plt.subplots(1,2)\nax[0].hist((x &gt; 0.5)*1.0,color='C0');\nax[1].hist(np.random.binomial(1,0.5,size=1000),color='C1');\n\n\n\n\n\n\\(X \\sim Ber(p)\\), \\(p=0.5\\)\n\n- 이항분포: 베르누이의 합으로!\n\nx = np.random.rand(10*100000).reshape(10,100000)\nfig, ax = plt.subplots(1,2)\nax[0].hist((x&gt;0.5).sum(axis=0),bins=9);\nax[1].hist(np.random.binomial(10,0.5,size=100000),color='C1',bins=9);\n\n\n\n\n- 포아송: 이항분포의 근사로\n\nref: https://guebin.github.io/SC2022/0324.html\n\n- 지수분포: 포아송 프로세스를 이용하여!\n\nref: https://guebin.github.io/SC2022/0324.html"
  },
  {
    "objectID": "posts/ap/2023-05-30-13wk-2.html#inverse-cdf-박스뮬러변환",
    "href": "posts/ap/2023-05-30-13wk-2.html#inverse-cdf-박스뮬러변환",
    "title": "13wk-2: MCMC (1)",
    "section": "inverse cdf, 박스뮬러변환",
    "text": "inverse cdf, 박스뮬러변환\n- inverse cdf: 지수분포를 뽑는 또 다른 테크닉: (지수분포가 아니더라도 CDF를 알면 뽑을 수 있음)\n\nref: https://guebin.github.io/SC2022/0329.html\n\n- 박스뮬러변환: 지수분포 + uniform으로 정규분포를 뽑는 테크닉\n\nref: https://guebin.github.io/SC2022/0329.html\n\n- 카이제곱분포, 감마분포: 지수분포를 이용하면 샘플링가능\n\nref: https://guebin.github.io/SC2022/0419.html"
  },
  {
    "objectID": "posts/ap/2023-05-30-13wk-2.html#pdf-정의",
    "href": "posts/ap/2023-05-30-13wk-2.html#pdf-정의",
    "title": "13wk-2: MCMC (1)",
    "section": "pdf 정의",
    "text": "pdf 정의\n- 모티브: 그냥 pdf를 입력하면 알아서 샘플링되도록 할 수 없나?\n- 예비학습: 감마함수\n\nscipy.special.gamma(5)\n\n24.0\n\n\n(n-1)! 이라고 생각(혹은 근사), 소수점 넣어도 가능\n\ng = scipy.special.gamma\n\n- 베타분포의 pdf\n\\[f_X(x) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}x^{\\alpha-1}(1-x)^{\\beta-1}\\]\n\ndef f(x): \n    return g(2+6)/(g(2)*g(6)) * x**(2-1) * (1-x)**(6-1)\n\n\n_x = np.linspace(0,1,10000)\nplt.plot(_x,f(_x))"
  },
  {
    "objectID": "posts/ap/2023-05-30-13wk-2.html#시도1-망했음",
    "href": "posts/ap/2023-05-30-13wk-2.html#시도1-망했음",
    "title": "13wk-2: MCMC (1)",
    "section": "시도1: 망했음",
    "text": "시도1: 망했음\n\nstep1: 초기화\n- 베타분포에서 10만개의 샘플을 뽑아보자.\n- 일단 \\({\\bf xx}=(x_0,x_1,\\dots,x_{T-1})\\)를 초기화를 하자.\n\nxx=[0.99]\nxx\n\n[0.99]\n\n\n\n현재의 \\(x_i\\)값은 \\(x_0=0.99\\) 만 있지만 궁극적으로는 \\({\\cal B}(2,6)\\)에서 생성된 샘플로 채우고 싶다.\n\n\n\nstep2: 후보 샘플링\n- 하나의 \\(y\\) 을 균등분포에서 샘플링한다.\n\nnp.random.seed(1)\ny = np.random.rand()\ny\n\n0.417022004702574\n\n\n\n\nstep3: 비교\n- \\(xx[0]\\) vs \\(y\\)\n\nplt.plot(_x,f(_x))\nplt.scatter(xx[0],0,color='C0')\nplt.scatter(xx[0],f(xx[0]),color='C0')\nplt.scatter(y,0,color='C1')\nplt.scatter(y,f(y),color='C1')\n\n&lt;matplotlib.collections.PathCollection at 0x7ff3eca2eb50&gt;\n\n\n\n\n\n\n\nstep4: 선택\n- 비교결과: \\(xx[0]\\) 보다 \\(y\\)가 나은것 같다\n- 선택: \\(xx[1]=y\\) 로 하자\n\n만약에 \\(xx[0]\\)이 \\(y\\)보다 나은것 같다면? 그냥 \\(xx[1]=xx[0]\\)으로 선택\n\n\n\nstep 1~4 반복: 망했음\n\nT = 100000\nxx = [0.99]\nfor t in range(T):\n    y = np.random.rand()\n    if f(xx[t]) &lt; f(y):\n        xx.append(y) \n    else:\n        xx.append(xx[t])\n\n\nplt.hist(xx,bins=50);"
  },
  {
    "objectID": "posts/ap/2023-05-30-13wk-2.html#시도2-성공",
    "href": "posts/ap/2023-05-30-13wk-2.html#시도2-성공",
    "title": "13wk-2: MCMC (1)",
    "section": "시도2: 성공",
    "text": "시도2: 성공\n\nstep1: 초기화\n- 베타분포에서 10만개의 샘플을 뽑아보자.\n- 일단 \\({\\bf xx}=(x_0,x_1,\\dots,x_{T-1})\\)를 초기화를 하자.\n\nxx=[0.99]\nxx\n\n[0.99]\n\n\n\n현재의 \\(x_i\\)값은 \\(x_0=0.99\\) 만 있지만 궁극적으로는 \\({\\cal B}(2,6)\\)에서 생성된 샘플로 채우고 싶다.\n\n\n\nstep2: 후보 샘플링\n- 하나의 \\(y\\) 을 균등분포에서 샘플링한다.\n\nnp.random.seed(1)\ny = np.random.rand()\ny\n\n0.417022004702574\n\n\n\n\nstep3: 비교\n- \\(xx[0]\\) vs \\(y\\)\n\nplt.plot(_x,f(_x))\nplt.scatter(xx[0],0,color='C0')\nplt.scatter(xx[0],f(xx[0]),color='C0')\nplt.scatter(y,0,color='C1')\nplt.scatter(y,f(y),color='C1')\n\n&lt;matplotlib.collections.PathCollection at 0x7ff85ef61b20&gt;\n\n\n\n\n\n\n\nstep4: 선택\n- 비교결과: \\(xx[0]\\) 보다 \\(y\\)가 나은것 같다\n- 선택: 그렇지만 무조건 \\(xx[1]=y\\) 로 선택하면 큰일나겠음.. 아래의 확률로 선택하자!\n\n확률 \\(\\frac{f(xx[0])}{f(xx[0])+f(y)}\\) 로 \\(xx[1]=xx[0]\\)을 선택!\n확률 \\(\\frac{f(y)}{f(xx[0])+f(y)}\\) 로 \\(y\\)를 선택!\n\n\n\nstep 1~4 반복: 이게 된다고?\n\nT = 100000\nxx = [0.99]\nfor t in range(T):\n    y = np.random.rand()\n    thresh_prob = f(y)/(f(xx[t])+f(y)) ## thresh_prob 가 클수록 y가 선택\n    _u = np.random.rand()\n    if _u &lt; thresh_prob:\n        xx.append(y) \n    else:\n        xx.append(xx[t])\n\n\nplt.hist(xx,bins=50);\n\n\n\n\n\nplt.hist(np.random.beta(2,6,size=100000),bins=50);"
  },
  {
    "objectID": "posts/ap/2023-03-21-3wk-2.html",
    "href": "posts/ap/2023-03-21-3wk-2.html",
    "title": "03wk-2: 측도론 intro (4)",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-yaBxW0S3fsO1d-kYIqZa62\n\n\n\n시그마필드 motivation (1)\n(예제1) – 잴 수 있는 집합의 모임\n\\(\\Omega=\\{H,T\\}\\)라고 하자. 아래집합들은 모두 확률을 정의할 수 있는 집합들이다.\n\\[\\emptyset, \\{H\\}, \\{T\\}, \\Omega\\]\n따라서 \\({\\cal F}\\)을 아래와 같이 정의한다면 묶음 \\({\\cal F}\\)가 합리적일 것이다.\n\\[{\\cal F}=\\big\\{\\emptyset, \\{H\\}, \\{T\\}, \\Omega\\big\\}\\]\n\n이때 \\({\\cal F}\\)는 집합들의 집합인데, 이러한 집합을 collection 이라고 한다.\n\n(예제2) – 집합 \\(A\\)를 잴 수 있다면, 집합 \\(A^c\\)도 잴 수 있어~\n\\(\\Omega=\\{H,T\\}\\)라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다면 묶음 \\({\\cal F}\\)는 합리적이지 않다.\n\\[{\\cal F}=\\big\\{\\emptyset, \\{H\\}, \\Omega\\big\\}\\]\n(해설1)\n이러한 묶음이 의미하는건 “앞면이 나올 확률은 모순없이 정의할 수 있지만, 뒷면이 나오는 확률은 모순없이 정의하는게 불가능해~” 라는 뜻이다. 그런데 뒷면이 나올 확률은 “1-앞면이 나올 확률” 로 모순없이 정의할 수 있으므로 “앞면이 나올 확률이 모순없이 정의되면서” 동시에 “뒷면이 나올 확률이 모순없이 정의되지 않는” 상황은 없다.\n(해설2)\n\\(\\Omega\\)의 어떠한 부분집합 \\(A\\)에 확률이 모순없이 정의된다면 그 집합의 여집합인 \\(A^c\\)에 대하여서도 확률이 모순없이 정의되어야 한다.\n\\(\\Leftrightarrow\\) \\(\\forall A \\subset {\\Omega}: ~ A \\in {\\cal F} \\Rightarrow A^c \\in {\\cal F}\\)\n(예제3) – 전체집합이 잴 수 있는 집합이니까 공집합도 잴 수 있는 집합이야\n\\(\\Omega=\\{H,T\\}\\)라고 하자. \\({\\cal F}\\)를 아래와 같이 정의한다면 묶음 \\({\\cal F}\\)는 합리적이지 않다.\n\\[{\\cal F}=\\big\\{ \\{H\\}, \\{T\\}, \\Omega\\big\\}\\]\n(해설)\n전체집합의 확률은 \\(P(\\Omega)=1\\)로 정의할 수 있다. 그런데 전체집합의 여집합인 공집합의 확률을 정의할 수 없는건 말이 안되므로 공집합은 \\(\\cal F\\)에 포함되어야 한다.\n(예제4) – 원소의 수가 유한한 경우 \\({\\cal F}=2^\\Omega\\)은 잴 수 있는 집합의 모임이야.\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\)이라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다고 하자. 이러한 묶음은 \\({\\cal F}\\)은 합리적이다.\n\\[{\\cal F}=\\text{all subset of $\\Omega$}= 2^\\Omega = \\big\\{ \\emptyset, \\{1\\}, \\{2\\}, \\dots, \\{6\\}, \\dots, \\{1,2,3,4,5\\} \\dots \\Omega\\big\\}\\]\n(해설)\n\\(\\Omega\\)의 모든 부분집합에 대하여 확률을 모순없이 정의할 수 있다. 예를들면\n\n\\(P(\\Omega)=1\\), \\(P(\\emptyset)=0\\)\n\\(P(\\{1\\})=\\frac{1}{6}\\)\n\\(P(\\{1,2,4\\})=\\frac{3}{6}\\)\n\\(P(\\{2,3,4,5,6\\})=\\frac{5}{6}\\)\n\\(\\dots\\)\n\n이런식으로 정의할 수 있다.\n(예제5) – 동일한 \\(\\Omega\\)에 대하여 잴 수 있는 집합의 모임 \\({\\cal F}\\)는 유니크하지 않음.\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\)이라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다고 하자. 이러한 묶음 \\({\\cal F}\\)는 합리적이다.\n\\[{\\cal F}=\\big\\{\\emptyset, \\{6\\}, \\{1,2,3,4,5\\},\\Omega \\big\\}\\]\n(해설)\n어떠한 특수한 상황을 가정하자. 주사위를 던져야하는데 6이 나오면 살수 있고 6이 나오지 않으면 죽는다고 하자. 따라서 던지는 사람 입장에서는 주사위를 던져서 6이 나오는지 안나오는지만 관심있을 것이다. 이 사람의 머리속에서 순간적으로 떠오르는 확률들은 아래와 같다.1\n\n살수있다 =&gt; 1/6\n죽는다 =&gt; 5/6\n살거나 죽는다 =&gt; 1\n살지도 죽지도 않는다 =&gt; 0\n\n이러한 확률은 합리적이다. 즉 아래의 집합들만 확률을 정의한다고 해도, 확률을 잘 정의할 수 있을 것 같다.\n\\[\\emptyset, \\{6\\}, \\{1,2,3,4,5\\}, \\Omega\\]\n(예제6) – \\(\\Omega\\)를 어떠한 사건의 집합으로 보느냐에 따라서 \\({\\cal F}\\)를 달리 구성할 수 있다.\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\)이라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다고 하자. 이러한 묶음 \\({\\cal F}\\)는 합리적이다.\n\\[{\\cal F}=\\big\\{\\emptyset, \\{1,3,5\\}, \\{2,4,6\\},\\Omega \\big\\}\\]\n(해설)\n전체사건을 “주사위를 던져서 짝이 나오는 사건”, “주사위를 던져서 홀이 나오는 사건” 정도만 구분하겠다는 의미\n(예제7) – \\(A\\in {\\cal F} \\Rightarrow A^c \\in {\\cal F}\\)\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\)이라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다고 하자. 이러한 묶음 \\({\\cal F}\\)는 합리적이지 않다.\n\\[{\\cal F}=\\big\\{\\emptyset, \\{1,3,5\\}, \\Omega \\big\\}\\]\n(해설)\n“주사위를 던져서 홀수가 나올 사건”에 대한 확률을 정의할 수 있는데, 짝수가 나올 사건에 대한 확률을 정의할 수 없다는건 말이 안되는 소리임.\n(예제8) – trivial \\(\\sigma\\)-field\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\)이라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다고 하자. 이러한 묶음 \\({\\cal F}\\)는 합리적이다.\n\\[{\\cal F}=\\{\\emptyset, \\Omega \\}\\]\n(해설)\n아예 이렇게 잡으면 모순이 일어나진 않음. (쓸모가 없겠지)\n(예제9) – 서로소인 두 집합의 합, 포함관계에 있는 집합의 차\n\\(\\Omega=\\{1,2,3,4\\}\\)이라고 하자. 어떠한 필요에 따라서 1이 나올 확률과 2가 나올 확률에만 관심이 있고 나머지는 별로 관심이 없다고 하자. 그래서 \\({\\cal F}\\)을 아래와 같이 정의했다고 하자. 이러한 묶음 \\({\\cal F}\\)는 합리적이지 않다.\n\\[{\\cal F}=\\{\\emptyset, \\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\Omega \\}\\]\n(해설1)\n\\({\\cal F}\\)은 전체집합과 공집합을 포함하고 여집합에 닫혀있으므로 언뜻 생각해보면 합리적인듯 보이지만 그렇지 않다. 왜냐하면 \\(\\{1,2\\}\\)이 빠졌기 때문이다. 1이 나올 확률 \\(P(\\{1\\})\\)와 2가 나올 확률 \\(P(\\{2\\})\\)를 각각 정의할 수 있는데, 1 또는 2가 나올 확률 \\(P(\\{1,2\\})\\)을 정의할 때 모순이 발생한다는 것은 합리적이지 못하다. 왜냐하면 \\(\\{1\\} \\cap \\{2\\} = \\emptyset\\) 이므로\n\\[P(\\{1\\} \\cup \\{2\\})=P(\\{1\\}) + P(\\{2\\})\\]\n와 같이 정의가능하기 때문이다. 따라서 집합이 아래와 같이 수정되어야 한다.\n\\[{\\cal F}=\\{\\emptyset, \\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\Omega, \\{1,2\\}, \\{3,4\\} \\}\\]\n(해설2)\n생각해보니까 \\(\\{2\\}\\)는 \\(\\{2,3,4\\}\\)의 부분집합이다. 그런데 \\(P(\\{2\\})\\)와 \\(P(\\{2,3,4\\})\\)를 각각 정의할 수 있는데\n\\[P(\\{2,3,4\\} - \\{2\\}) = P(\\{3,4\\})\\]\n를 정의할 수 없는건 말이 안된다. 따라서 \\({\\cal F}\\)를 아래와 같이 수정해야 한다.\n\\[{\\cal F}=\\{\\emptyset, \\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\Omega, \\{3,4\\}, \\{1,2\\} \\}\\]\n(해설3)\n\\(\\Omega\\)의 어떠한 두 부분집합 \\(A\\), \\(B\\)가 서로소라고 상상하자. 집합 \\(A\\), \\(B\\)에 대한 확률이 각각 무모순으로 정의된다면, 집합 \\(A\\cup B\\)에 대한 확률도 무모순으로 정의되어야 한다.\n\\(\\Leftrightarrow\\) \\(\\forall A,B \\subset \\Omega\\) such that \\(A \\cap B =\\emptyset\\): \\(A,B \\in {\\cal F} \\Rightarrow A \\cup B \\in {\\cal F}\\)\n또한 \\(\\Omega\\)의 임의의 두 부분집합이 \\(A \\subset B\\)와 같은 포함관계가 성립할때, 집합 \\(A\\), \\(B\\)에 대한 확률이 각각 무모순으로 정의된다면, 집합 \\(B-A\\)에 대한 확률로 무모순으로 정의되어야 한다.\n\\(\\Leftrightarrow\\) \\(\\forall A,B \\subset \\Omega\\) such that \\(A \\subset B\\): \\(A,B \\in {\\cal F} \\Rightarrow B-A \\in {\\cal F}\\)\n(예제10) – \\({\\cal A}=\\{\\{1\\},\\{2\\}\\}\\) 일때, \\(\\sigma({\\cal A})\\) 를 구하는 문제\n\\(\\Omega=\\{1,2,3,4\\}\\)이라고 하자. 내가 관심이 있는 확률은 \\(P(\\{1\\})\\), \\(P(\\{2\\})\\) 밖에 없다고 하자. 이러한 확률들이 무모순으로 정의되기 위한 최소한의 \\({\\cal F}\\)를 정의하라.\n(해설) – 좀 귀찮네..?\n0차수정: \\({\\cal A} = \\big\\{\\{1\\}, \\{2\\}\\big\\}\\)\n1차수정: \\(\\big\\{\\emptyset, \\{1\\}, \\{2\\}, \\Omega \\big\\}\\)\n2차수정: \\(\\big\\{\\emptyset, \\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\Omega \\big\\}\\)\n3차수정: \\(\\big\\{\\emptyset, \\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\Omega, \\{1,2\\}, \\{3,4\\} \\big\\}\\)\n\n사실 우리가 관심 있는건 \\({\\cal A} = \\{ \\{1\\}, \\{2\\} \\}\\) 뿐 이었음. 그런데 뭔가 \\(P(\\{1\\})\\)와 \\(P(\\{2\\})\\)를 합리적으로 정의하기 위해서 필연적으로 발생하는 어떠한 집합들을 모두 생각하는건 매우 피곤하고 귀찮은 일임. 그래서 “아 모르겠고, \\(\\{1\\}\\) 와 \\(\\{2\\}\\)를 포함하고 확률의 뜻에 모순되지 않게 만드는 최소한의 \\({\\cal F}\\)가 있을텐데, 거기서만 확률을 정의할래!” 라고 쉽게 생각하고 싶은 사람들이 생김. 그러한 공간을 \\(\\sigma({\\cal A})\\)라는 기호로 약속하고 smallest \\(\\sigma\\)-field containing \\({\\cal A}\\) 라는 용어로 부름.\n\n\n\n\n\n\nFootnotes\n\n\n공평한 주사위라고 하자..↩︎"
  },
  {
    "objectID": "posts/ap/2023-03-28-4wk-2.html",
    "href": "posts/ap/2023-03-28-4wk-2.html",
    "title": "04wk-2: 측도론 intro (6)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-x7Z5LJZOG4At6NWHs757XG"
  },
  {
    "objectID": "posts/ap/2023-03-28-4wk-2.html#셀-수-있는",
    "href": "posts/ap/2023-03-28-4wk-2.html#셀-수-있는",
    "title": "04wk-2: 측도론 intro (6)",
    "section": "셀 수 있는",
    "text": "셀 수 있는\n- 셀 수 있는 집합과 셀 수 없는 집합.\n\ncountable: finite, countable many\nuncountable: uncountable many\n\n- 예시1: countable set, uncountable set\n\n\\(\\{1,2,3,4,5\\}\\)는 셀 수 있는 집합이다.\n\\(\\mathbb{N}\\)은 셀 수 있는 집합이다.\n\\(\\mathbb{Z}\\)는 셀 수 있는 집합이다.\n\\(\\mathbb{Q}\\)는 셀 수 있는 집합이다.\n\\(\\mathbb{R}\\)은 셀 수 없는 집합이다.\n\n- 예시2: countable sum: 아래는 모두 countable sum을 의미한다.\n\n\\(\\sum_{i=1}^{n}a_i\\).\n\\(\\sum_{i \\in I} a_i\\), where \\(I=\\{1,2,3,\\dots,10\\}\\).\n\\(\\sum_{i=1}^{\\infty} a_i\\), \\(\\sum_{i=0}^{\\infty} a_i\\).\n\\(\\sum_{i \\in \\mathbb{N}}a_i\\).\n\\(\\sum_{x \\in \\mathbb{Q}}m(\\{x\\})\\), where \\(m\\) is Lebesgue measure\n\n- 예시3: countable union: 아래는 countalbe union을 의미한다.\n\n\\(\\cup_{i=1}^n A_i\\)\n\\(\\cup_{i=1}^{\\infty} A_i\\)\n\\(\\cup_{x \\in \\mathbb{Q}} \\{x\\}\\)\n\n- 예시4: 아래는 uncountable sum을 의미한다.\n\n\\(\\sum_{x \\in [0,1]}m(\\{x\\})\\), where \\(m\\) is Lebesgue measure\n\n- 예시5: 아래는 uncountable union을 의미한다.\n\n\\(\\cup_{x \\in [0,1]} \\{x\\}\\)"
  },
  {
    "objectID": "posts/ap/2023-03-28-4wk-2.html#여러가지-집합",
    "href": "posts/ap/2023-03-28-4wk-2.html#여러가지-집합",
    "title": "04wk-2: 측도론 intro (6)",
    "section": "여러가지 집합",
    "text": "여러가지 집합\n\n\n\n집합 (\\(\\mathbb{R}\\)의 부분집합)\n카디널리티\n분류\n르벡메져\n\n\n\n\n\\(\\{1,2,3\\}\\)\n3\n가산집합\n0\n\n\n\\(\\mathbb{N}\\)\n\\(\\aleph_0\\)\n가산집합\n0\n\n\n\\(\\mathbb{Z}\\)\n\\(\\aleph_0\\)\n가산집합\n0\n\n\n\\(\\mathbb{Q}\\)\n\\(\\aleph_0\\)\n가산집합\n0\n\n\n\\([0,1]\\)\n\\(2^{\\aleph_0}\\)\n비가산집합\n1\n\n\n\\([0,1]\\cap \\mathbb{Q}\\)\n\\(\\aleph_0\\)\n가산집합\n0\n\n\n\\([0,1]\\cup \\mathbb{Q}\\)\n\\(2^{\\aleph_0}\\)\n비가산집합\n1\n\n\n\\([0,1]\\cap \\mathbb{Q}^c\\)\n\\(2^{\\aleph_0}\\)\n비가산집합\n1\n\n\n\\([0,\\infty)\\)\n\\(2^{\\aleph_0}\\)\n비가산집합\n\\(\\infty\\)\n\n\n비탈리집합\n\\(2^{\\aleph_0}\\)\n비가산집합\nNA\n\n\n칸토어집합\n\\(2^{\\aleph_0}\\)\n비가산집합\n0"
  },
  {
    "objectID": "posts/ap/2023-03-28-4wk-2.html#확률변수의-엄밀한-정의",
    "href": "posts/ap/2023-03-28-4wk-2.html#확률변수의-엄밀한-정의",
    "title": "04wk-2: 측도론 intro (6)",
    "section": "확률변수의 엄밀한 정의",
    "text": "확률변수의 엄밀한 정의\n- 확률변수 (머리속): \\(X:\\Omega \\to \\mathbb{R}\\) 인 잴 수 있는 함수.\n- 확률변수 (엄밀하게): 두 개의 잴 수 있는 공간 \\((\\Omega,{\\cal F})\\)와 \\((\\mathbb{R}, {\\cal R})\\)이 있다고 하자. 확률변수 \\(X\\)는 아래를 만족하는 함수 \\(X:\\Omega \\to \\mathbb{R}\\) 이다.\n\\[\\forall B \\in {\\cal R}: X^{-1}(B) = \\{\\omega:X(\\omega)\\in B \\} \\in {\\cal F}\\]\n\nNote1: \\(\\{\\omega:X(\\omega)\\in B \\} \\in {\\cal F}\\) for all \\(B \\in {\\cal R}\\) 이라 쓰기도 함. 쓰는사람 마음~\n\n\nNote2: \\({\\cal R}\\)은 Borel sets라고 부른다. 의미는 \\(\\mathbb{R}\\)의 부분집합중 잴 수 있는 부분집합의 모임이라는 뜻이다. (즉 \\({\\cal F}\\)의 의미와 같다) \\({\\cal B}\\)의 원소는 Borel set이라고 부른다.\n\n- 왜 정의가 아래와 같지 않을까?\n\\[\\forall B \\subset \\mathbb{R}: X^{-1}(B) = \\{\\omega:X(\\omega)\\in B \\} \\in {\\cal F}\\]\n\n위의 질문을 위한 보충학습\n(예제) 바늘이 하나 있는 시계\n1. outcomes: \\(0,1,\\frac{\\pi}{3},\\frac{2\\pi}{5},\\pi\\dots\\)\n2. sample space: \\(\\Omega = (0,2\\pi]\\)\n3. event: \\(\\emptyset\\), \\([0,\\frac{2}{\\pi})\\), \\(\\{2\\pi\\}\\), \\(\\dots\\)\n4. \\(\\sigma\\)-field: \\({\\cal F}\\). \\(\\Omega\\)의 부분집합 중 잴 수 있는 집합의 모임.\n5. probability measure function: \\(P: \\Omega \\to [0,1]\\) such that\n\n\\(P(\\emptyset) = 0\\)\n\\(P([0,\\frac{2}{\\pi}) = \\frac{1}{4}\\)\n\\(P(\\{2\\pi\\}) = 0\\)\n\\(P(\\Omega) = 1\\)\n\n6. random variable: \\(X: \\Omega \\to \\mathbb{R}\\) such that \\(X(\\omega)=\\omega\\). // 사실 \\(X: (0,2\\pi] \\to (0,2\\pi]\\)\n6을 주목하자. 만약에 비탈리집합 \\(V \\subset \\mathbb{R}\\)에 대한 inverse image는 비탈리집합 그 자체가 된다. 따라서 아래와 같이 된다.\n\\[P(X \\in V)=P\\big(\\{\\omega: X(\\omega) \\in V\\}\\big)=P(V)\\]\n\\(V\\)는 잴 수 없는 집합이므로 \\(P(V)\\)와 같은 표현을 불가함.\n결론: 확률변수 \\(X\\)를 고려할때 정의역의 치역 양쪽의 measurable space를 고려해야함.\n\n- 교재의 정의1\n\n\n\n그림1: Durret에서 긁어온 확률변수의 정의\n\n\n- 교재의 정의2\n\n\n\n그림2: Durret에서 긁어온 확률변수의 정의2\n\n\n- \\(X\\)가 랜덤변수라는 것을 기호로 간단하게 \\(X \\in {\\cal F}\\) 혹은 \\(X : (\\Omega, {\\cal F}) \\to (\\mathbb{R},{\\cal R})\\)라고 쓴다.\n\n사실 \\(X: (\\Omega,{\\cal F}) \\to (\\mathbb{R}, {\\cal R})\\)은 \\(X\\)가 잴 수 있는 함수 (measurable function, measurable map) 임을 나타내는 기호이다.\n\n- “\\(X\\)를 확률변수라고 하자.” 라는 의미? 지금 까지 해온 모든 논의가 압축된 표현…\n\n확률이라는건 원래 모든 \\(\\Omega\\)에서는 잘 정의되지 않음.\n그래도 \\(\\Omega\\)의 부분집합중 잴 수 있는 집합이라는 것이 있는데 그게 \\({\\cal F}\\)야.\n이 두개를 세트로 묶어서 \\((\\Omega,{\\cal F})\\) 이라고 하고 이를 잴 수 있는 공간이라고 하자.\n이 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\) 에서는 이제 확률 \\(P\\)를 정의 할 수 있어.\n한편 \\(\\Omega\\)의 원소는 숫자로 되어있지 않으니까 이를 숫자화시키는 어떠한 함수가 필요한데 이것을 우리는 \\(X\\)라고 할 것임.\n그런데 \\(P(X=1)\\)와 같은 표현이 가능하려면 \\(X\\)의 inverse image가 \\({\\cal F}\\)의 원소이어야 하는데 이게 항상 가능한 것은 아니므로 \\(X\\)를 잴 수 있는 함수라고 추가가정 해야 함.\n\n\n“\\(X\\)를 확률변수라고 하자” 라고 선언하는 것은 아래의 효과를 가진다. (1) \\(\\Omega\\)에 대응하는 \\({\\cal F}\\)가 잘 정의되어 있다고 하자. (2) \\(P\\) 역시 잘 정의되어 있다고 하자. (3) \\(\\mathbb{R}\\)와 \\({\\cal R}\\)이 잘 정의되어 있다고 하자. (4) \\(X: (\\Omega,{\\cal F}) \\to (\\mathbb{R},{\\cal R})\\) 이 잘 정의되어 있다고 하자."
  },
  {
    "objectID": "posts/ap/2023-03-28-4wk-2.html#헷갈려-2-starstarstar",
    "href": "posts/ap/2023-03-28-4wk-2.html#헷갈려-2-starstarstar",
    "title": "04wk-2: 측도론 intro (6)",
    "section": "헷갈려 (2) (\\(\\star\\star\\star\\))",
    "text": "헷갈려 (2) (\\(\\star\\star\\star\\))\n- 확률변수에 대한 오해1: 학률변수 = 값이 랜덤으로 바뀌는 변수??\n\n함수: \\(y=f(x)\\), \\(f\\): function, \\(x\\): input \\(y\\): output\n확률변수: \\(x=X(\\omega)\\), \\(X\\): function, \\(\\omega\\): outcome1, \\(x\\): realization\n확률변수는 함수이지만 보통 \\(X(\\omega)\\)와 같이 쓰지 않고 \\(X\\)라고 쓴다. \\(\\Rightarrow\\) 혼란의 이유\n\n- 확률변수에 대한 오해2: 확률변수는 결과가 랜덤으로 변한다??\n\n확률변수는 함수일 뿐임. 입력이 정해지면 출력이 고정임!\n동전예제: 입력이 \\(\\omega=H\\)이면 출력은 \\(X(\\omega)=1\\), 입력이 \\(\\omega=T\\)이면 출력은 \\(X(\\omega)=0\\)으로 고정임!\n\n- 확률변수에 대한 오해3: 아니야.. 확률변수는 결과가 랜덤으로 바뀌는 느낌이 맞아. 아래의 예시를 봐!\n\\[X = \\begin{cases} 0 & w.p. \\frac{1}{2} \\\\ 1 & w.p. \\frac{1}{2} \\end{cases}\\]\n\n\\(X\\)는 진짜 변수처럼 보이긴함.\n심지어 변수의 값이 랜덤으로 변하는 것 같음.\n\n(해설)\n정확하게는 아래 표현이 맞다.\n\\[X(\\omega) = \\begin{cases} 0 & \\omega \\in \\{H\\} \\\\ 1 & \\omega \\in \\{T\\} \\end{cases} \\quad \\text{where } P(\\{H\\}) = P(\\{T\\}) = \\frac{1}{2}.\\]\n- 확률변수에 대한 오해2에 대한 추가설명\n\n확률변수는 결과가 랜덤으로 변하는 함수가 아님, 확률변수는 함수일 뿐임. 입력이 정해지면 출력이 고정임!\n동전예제: 입력이 \\(\\omega=H\\)이면 출력은 \\(X(\\omega)=1\\), 입력이 \\(\\omega=T\\)이면 출력은 \\(X(\\omega)=0\\)으로 고정임!\n단지 입력 outcome이 실험에 따라 랜덤으로 변할 수 있는 것임!!\n\n- 요약해보면,\n\n확률변수는 확률과 관련없다.\n간접적으로는 관련이 있다. \\(\\because\\) X의 역상 = \\(\\Omega\\)의 부분집합 = \\(P\\)의 정의역\n\n- 표현연습: \\(P(X=1), P(X \\in \\{0,1\\}),\\dots ...\\)"
  },
  {
    "objectID": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html",
    "href": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html",
    "title": "STBDA2023 09wk-1: 중간고사_sy",
    "section": "",
    "text": "import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom plotnine import * \n#---#\nimport PIL\nimport io \nimport requests\nimport cv2"
  },
  {
    "objectID": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#에너지-사용-추세-10점",
    "href": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#에너지-사용-추세-10점",
    "title": "STBDA2023 09wk-1: 중간고사_sy",
    "section": "(1) 에너지 사용 추세 – 10점",
    "text": "(1) 에너지 사용 추세 – 10점\n2018년부터 2021년까지 에너지사용량을 dot-connected plot으로 시각화 하라.\n시각화 예시\n\n세부지침\n1. plotnine으로 생성된 fig[1]에 .draw()메소드를 사용하여 matplotlib.figure.Figure 자료형으로 변환할것\n[1] type이 plotnine.ggplot.ggplot 인 오브젝트\n\nplt.plot(result_df.Year, result_df.Elec, label='Year')"
  },
  {
    "objectID": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#에너지-종류별-사용-추세-10점",
    "href": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#에너지-종류별-사용-추세-10점",
    "title": "STBDA2023 09wk-1: 중간고사_sy",
    "section": "(2) 에너지 종류별 사용 추세 – 10점",
    "text": "(2) 에너지 종류별 사용 추세 – 10점\n2018년부터 2021년까지 에너지사용량을 dot-connected plot으로 시각화 하라. 에너지의 유형은 색상으로 구분하라.\n시각화 예시\n\n세부지침\n1 geom_point의 color와 shape을 EneryType으로 설정할 것.\n2 geom_line의 color와 linetype을 EneryType으로 설정할 것"
  },
  {
    "objectID": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#년-대비-2021년의-전기에너지-사용량-증가-20점",
    "href": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#년-대비-2021년의-전기에너지-사용량-증가-20점",
    "title": "STBDA2023 09wk-1: 중간고사_sy",
    "section": "(3) 2020년 대비 2021년의 전기에너지 사용량 증가 – 20점",
    "text": "(3) 2020년 대비 2021년의 전기에너지 사용량 증가 – 20점\n2020년 대비 2021년의 전기에너지 사용량이 증가한 상위 5개의 지역을 아래와 같이 시각화하라.\n시각화 예시\n\n세부지침\n1. 2020년 대비 2021년의 전기에너지 사용 증가량은 아래와 같이 구한다.\n\\[\\text{서울의 전기에너지 사용 증가량} = \\frac{\\text{2021년 서울 전기에너지 사용량}-\\text{2020년 서울 전기에너지 사용량}}{\\text{2020년 서울 전기에너지 사용량}}\\]\n\n\\(\\text{서울의 2021년 전기에너지 사용 증가량}= \\text{2021년 강남구의 전기에너지 사용량} + \\dots + \\text{2021년 중랑구의 전기에너지 사용량}\\)\n\\(\\text{서울의 2020년 전기에너지 사용 증가량}= \\text{2020년 강남구의 전기에너지 사용량} + \\dots + \\text{2020년 중랑구의 전기에너지 사용량}\\)\n\n2. 전기에너지의 사용량이 증가한 상위5개의 지역 중 가장 많이 증가한 2개의 지역은 색깔과 투명도로 하이라이팅 한다. (구체적 코드는 hint를 참고할 것)\n힌트\n- 정리된 자료의 형태는 아래와 같아야 한다.\n\n- 그림안에 text를 넣기위해서 geom_text를 시용한다. 위의 데이터가 정리되었다는 전제하에 구체적인 시각화 코드는 아래와 같다.\nfig = ggplot(tidydata.query('Rank&lt;5'))\ncol = geom_col(aes(x='Rank',y='ElecUseInc',fill='Top2',alpha='Top2'))\ntext = geom_text(aes(x='Rank',y='ElecUseInc',label='Prov'))\nfig + col + text + scale_alpha_manual(values={True: 1, False: 0.2})"
  },
  {
    "objectID": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#건물당-에너지-소비량-연도별-상위-15구-비교-20점",
    "href": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#건물당-에너지-소비량-연도별-상위-15구-비교-20점",
    "title": "STBDA2023 09wk-1: 중간고사_sy",
    "section": "(4) 건물당 에너지 소비량: 연도별 상위 15구 비교 – 20점",
    "text": "(4) 건물당 에너지 소비량: 연도별 상위 15구 비교 – 20점\n건물당 에너지소비량이 가장 큰 15개의 구를 연도별로 시각화하라.\n시각화 예시\n\n세부지침\n1. 건물당 에너지 사용량(=EUB)을 아래와 같은 방식으로 구할 것\n\\[\\text{EUB}_{강남구,2018}=\\frac{\\text{강남구의 2018년도 전기에너지 사용량}+ \\text{강남구의 2018년도 도시가스 사용량} +\\text{강남구의 2018년도 지역난방 사용량}}{\\text{강남구의 2018년도 건물동수}}\\]\n2. 연도별로 EUB가 높은 15개의 구를 정렬할 것. (따라서 매년도마다 순위가 다를수 있음)"
  },
  {
    "objectID": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#수도권과-비수도권의-전기-에너지-사용량-및-사용-비율-20점",
    "href": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#수도권과-비수도권의-전기-에너지-사용량-및-사용-비율-20점",
    "title": "STBDA2023 09wk-1: 중간고사_sy",
    "section": "(5) 수도권과 비수도권의 전기 에너지 사용량 및 사용 비율 – 20점",
    "text": "(5) 수도권과 비수도권의 전기 에너지 사용량 및 사용 비율 – 20점\n수도권과 비수도권의 전기에너지 사용량 및 사용비율을 계산하고 시각화 하라.\n시각화예시\n\n세부지침\n1. ['Seoul','Gyeonggi-do','Incheon']은 수도권으로 그 외의 지역은 비수도권으로 분리한다.\n2. 수도권의 전기에너지 사용비율은 아래와 같이 구한다.\n\\[\\text{2018년 수도권의 전기에너지 사용비율} = \\frac{\\text{2018년 수도권의 전기 사용량}}{\\text{2018년 수도권의 전기 사용량}+\\text{2018년 수도권의 도시가스 사용량}+\\text{2018년 수도권의 지역난방 사용량}}\\]\n3. facet_wrap 사용시 scales='free' 옵션을 사용할 것"
  },
  {
    "objectID": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#나이와-포지션에-따른-선수-가치-및-급여-분석-10점",
    "href": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#나이와-포지션에-따른-선수-가치-및-급여-분석-10점",
    "title": "STBDA2023 09wk-1: 중간고사_sy",
    "section": "(1) 나이와 포지션에 따른 선수 가치 및 급여 분석 – 10점",
    "text": "(1) 나이와 포지션에 따른 선수 가치 및 급여 분석 – 10점\n나이에 따른 선수가치(Value)와 급여(Wage)의 산점도를 포지션별로 시각화 하고 추세선을 그려라.\n시각화 예시\n\n세부지침\n1. Value와 Wage는 log값을 취하여 시각화 하라.\n2. geom_point를 사용할 시alpha=0.2, size=0.1, position='jitter'로 설정하라.\n3. SUB와 RES 포지션은 제외하고 시각화 할 것"
  },
  {
    "objectID": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#골키퍼-능력치별-로그급여-추세-10점",
    "href": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#골키퍼-능력치별-로그급여-추세-10점",
    "title": "STBDA2023 09wk-1: 중간고사_sy",
    "section": "(2) 골키퍼 능력치별 로그급여 추세 – 10점",
    "text": "(2) 골키퍼 능력치별 로그급여 추세 – 10점\n아래의 리스트는 골키퍼와 관련된 능력치이다.\n\ngkstats = ['GKDiving','GKHandling', 'GKKicking', 'GKPositioning', 'GKReflexes']\ngkstats\n\ngkstats 에 해당하는 능력치와 로그급여(logWage)를 산점도로 시각화하고 추세선을 추가하라.\n시각화예시\n\n세부지침\n1. 포지션이 “골키퍼”인 선수에 한정하여 시각화 할 것\n2. geom_point를 사용할 시 alpha=0.5,size=0.5,position='jitter' 를 설정하라."
  },
  {
    "objectID": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#gkability에-따른-골키퍼의-overall-예측-20점",
    "href": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#gkability에-따른-골키퍼의-overall-예측-20점",
    "title": "STBDA2023 09wk-1: 중간고사_sy",
    "section": "(3) “GKAbility”에 따른 골키퍼의 Overall 예측 – 20점",
    "text": "(3) “GKAbility”에 따른 골키퍼의 Overall 예측 – 20점\n아래의 리스트는 골키퍼와 관련된 능력치이다.\n\ngkstats = ['GKDiving','GKHandling', 'GKKicking', 'GKPositioning', 'GKReflexes']\ngkstats\n\ngkstats 에 해당하는 능력치의 평균을 계산하고 GKAbility라는 변수에 저장하라. 골키퍼 포지션과 공격수 포지션을 가지는 선수들에 한정하여 GKAbility와 OveraAll(=선수의 전반적 능력치)의 관계를 산점도로 시각화하라.\n시각화 예시\n\n세부지침\n1. ID=212198인 선수 Bruno Fernandes의 경우 GKAbility를 아래와 같이 계산할 수 있다.\n\\[\\text{Bruno Fernandes의 GKAbility} = \\frac{\\text{Bruno Fernandes의 GKDiving} + \\dots + \\text{Bruno Fernandes의 GKReflexes}}{5}\\]\n2. 시각화를 위한 세부옵션은 아래의 코드를 참고하라.\nfig = ggplot(tidydata)\npoint = geom_point(aes(x='GKAbility',y='Overall',size='logWage',alpha='logWage',color='Position'),position='jitter')\nsmooth = geom_smooth(aes(x='GKAbility',y='Overall'),linetype='dashed')\nfacet = facet_wrap('Position',scales='free')\nfig + point + smooth + facet"
  },
  {
    "objectID": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#포워드와-수비수의-기술별-가치-평가-25점",
    "href": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#포워드와-수비수의-기술별-가치-평가-25점",
    "title": "STBDA2023 09wk-1: 중간고사_sy",
    "section": "(4) 포워드와 수비수의 기술별 가치 평가 – 25점",
    "text": "(4) 포워드와 수비수의 기술별 가치 평가 – 25점\n아래는 축구선수의 능력치와 관련이 있는 column들의 리스트이다. (골키퍼 관련 능력치는 제외하였음)\n\nabilities_list = ['Crossing', 'Finishing', 'HeadingAccuracy', 'ShortPassing', 'Volleys', 'Dribbling', 'Curve', 'FKAccuracy', 'LongPassing', 'BallControl', 'Acceleration', 'SprintSpeed', 'Agility', 'Reactions', 'Balance', 'ShotPower', 'Jumping', 'Stamina', 'Strength', 'LongShots', 'Aggression', 'Interceptions', 'Positioning', 'Vision', 'Penalties', 'Composure', 'StandingTackle', 'SlidingTackle']\n\n아래는 위의 abilities_list을 적당한 카테고리로 묶은 것이다.\n\nabilities_categories = {\n    \"FinishingSkills\": ['Finishing', 'HeadingAccuracy', 'Volleys', 'LongShots', 'Positioning', 'Vision', 'Penalties', 'ShotPower', 'Jumping'],\n    \"BallControl_Passing\": ['Dribbling', 'Curve', 'Crossing','ShortPassing', 'LongPassing', 'BallControl','FKAccuracy'],\n    \"Speed_Stamina\": ['Acceleration', 'SprintSpeed', 'Agility', 'Stamina'],\n    \"Reactions_PhysicalAttributes\": ['Reactions', 'Balance', 'Strength', 'Composure'],\n    \"DefensiveSkills\": ['Aggression', 'Interceptions', 'StandingTackle', 'SlidingTackle']\n}\n\n선수들의 여러 능력치를 abilities_categories에 따라 통합하고 각 스킬 카테고리별로 선수의 능력치의 평균을 구하여 SkillValueCategories값에 저장하라. 정리된 자료의 예시는 아래와 같다.\n\n위의 자료를 바탕으로 SkillValueCategories와 logValue의 산점도를 포지션별로 시각화 하라.\n시각화 예시\n\n힌트\n- 아래의 데이터프레임에서\n\n마지막 row의 SkillValueCategories의 값은 아래와 같이 구하였다.\n\\[14.250 = \\frac{\\text{259646선수의 Aggression}+\\dots+\\text{259646선수의 SlidingTackle}}{4}=\\frac{24+6+14+13}{4} \\]\n\n(24+6+14+13)/4\n\n- 시각화를 위해 아래의 코드를 참고하라.\nfig = ggplot(tidydata.query(\"Position=='FORWARD' or Position=='DEFENDER'\"))\npoint = geom_point(aes(x='SkillValueCategories',y='logValue',color='Position'),alpha=0.05,size=0.05)\nsmooth = geom_smooth(aes(x='SkillValueCategories',y='logValue',color='Position'))\nfacet = facet_wrap('SkillTypeCategories')\nfig = (fig + point + smooth + facet).draw()\nfig.set_dpi(150)\nfig.set_size_inches(8,5)\nfig"
  },
  {
    "objectID": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#스킬-카테고리별-선수의-로그-연봉-분석-25점",
    "href": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#스킬-카테고리별-선수의-로그-연봉-분석-25점",
    "title": "STBDA2023 09wk-1: 중간고사_sy",
    "section": "(5) 스킬 카테고리별 선수의 로그 연봉 분석 – 25점",
    "text": "(5) 스킬 카테고리별 선수의 로그 연봉 분석 – 25점\n공격수 포지션을 가진 선수들의 특정 능력치가 그들의 Value에 얼마나 영향을 주는지 알아보고자 한다. 선수들의 logValue를 10개의 구간으로 나눈 후, 각 구간별로 [‘FinishingSkills’,…,‘DefensiveSkills’]의 통합능력치 평균을 바 플롯(bar plot)으로 시각화하라.\n시각화 예시\n\n세부지침\n1. logValue는 pd.qcut을 이용하여 분할하고 이때 q=10으로 설정하라.\n2. 시각화를 위해 아래의 코드를 사용하라.\nfig = ggplot(tidydata.query(\"Position=='FORWARD'\")) \ncol = geom_col(aes(x='logValueCut',y='SkillValueCategories',fill='logValueCut'),position='dodge')\nfacet = facet_wrap('SkillTypeCategories')\nfig = (fig + col + facet + theme(axis_text_x=element_blank(), axis_ticks=element_blank())).draw()\nfig.set_dpi(150)\nfig.set_size_inches(8,5)\nfig"
  },
  {
    "objectID": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#심슨의-역설-10점",
    "href": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#심슨의-역설-10점",
    "title": "STBDA2023 09wk-1: 중간고사_sy",
    "section": "(1) 심슨의 역설 – 10점",
    "text": "(1) 심슨의 역설 – 10점\n다음은 농구선수 A,B 의 시즌별 자유투 성공률이다.\n\ndf = pd.DataFrame({\n    'Player': ['A','A','A','A','B','B','B','B'], \n    'Season': [1,1,2,2]*2,\n    'Status': ['Success','Failure']*4,\n    'Count': [7,3,None,None,None,None,4,0]\n})\ndf\n\n적절한 값을 채워 시즌 1,2 모두 B선수의 자유투 성공률이 높지만 시즌1-2를 전체 합치면 A선수의 자유투 성공률이 더 높도록 하라. (즉 적절한 값을 채워 심슨의 역설을 설명하기 위한 자료를 구성하라.) 만들어진 자료를 바탕으로 심슨의 역설을 시각화하라. (즉 시즌별 자유투 성공률과 전체 자유투 성공률을 barplot으로 시각화하라)"
  },
  {
    "objectID": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#histogram-equalization-5점",
    "href": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#histogram-equalization-5점",
    "title": "STBDA2023 09wk-1: 중간고사_sy",
    "section": "(2) Histogram Equalization – 5점",
    "text": "(2) Histogram Equalization – 5점\n\nurl = 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/Unequalized_Hawkes_Bay_NZ.jpg/300px-Unequalized_Hawkes_Bay_NZ.jpg'\nimg_before = np.array(PIL.Image.open(io.BytesIO(requests.get(url).content)))\nimg_after = cv2.equalizeHist(img_before)\nfig,ax = plt.subplots(2,2)\nax[0,0].imshow(img_before,cmap='gray',vmax=255,vmin=0); ax[0,0].set_title(\"(a) before: image\")\nax[0,1].imshow(img_after,cmap='gray',vmax=255,vmin=0); ax[0,1].set_title(\"(b) after: image\")\nax[1,0].hist(img_before.reshape(-1), bins=255); ax[1,0].set_title(\"(c) before: histogram\")\nax[1,1].hist(img_after.reshape(-1), bins=255); ax[1,1].set_title(\"(d) after: histogram\")\nfig.tight_layout()\n\n\n\n\n위의 그림을 올바르게 해석한 사람을 모두 고르라. (모두 맞출 경우만 정답으로 인정)\n\n유진: (a) 이미지의 값들은 (b) 이미지의 값들 보다 분산이 작을 것이다.\n레이: (a) 이미지의 값은 대부분 130~150근처에 모여있어서 회색으로 보인다.\n원영: 130~150 사이의 값들은 (b) 이미지 보다 (a) 이미지에서 훨씬 많은 빈도로 나타난다.\n리즈: (a) 이미지를 (b) 이미지로 바꾸는 기법을 histogram equalization 이라고 하며, 그 원리는 (c)와 같은 히스토그램을 (d)와 같은 히스토그램으로 바꾸는 것이다."
  },
  {
    "objectID": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#엔스콤의-플랏-5점",
    "href": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#엔스콤의-플랏-5점",
    "title": "STBDA2023 09wk-1: 중간고사_sy",
    "section": "(3) 엔스콤의 플랏 – 5점",
    "text": "(3) 엔스콤의 플랏 – 5점\n\nx = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]\ny1 = [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68]\ny2 = [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74]\ny3 = [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73]\nx4 = [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8]\ny4 = [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]\nfig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2)\nax1.plot(x,y1,'.') \nax1.set_title(\"(a)\")\nax2.plot(x,y2,'.') \nax2.set_title(\"(b)\")\nax3.plot(x,y3,'.'); ax3.plot(x[2],y3[2],'o',color='C1') \nax3.set_title(\"(c)\")\nax4.plot(x4,y4,'.'); ax4.plot(x4[-4],y4[-4],'o',color='C1')\nax4.set_title(\"(d)\")\nfig.suptitle(\"Anscombe's quartet\",size=15)\nplt.tight_layout()\n\n\n\n\n위의 그림을 올바르게 해석한 사람을 모두 고르라. (모두 맞출경우만 정답으로 인정)\n\n유진: (a)-(d) 모두 양의 상관계수를 가진다.\n레이: 이 중 상관계수값의 해석이 가장 적절한 자료는 (a)이다.\n원영: (b)가 적절하지 않은 이유는 선형성이 가정되어 있지 않기 때문이며, (c)가 적절하지 않은 이유는 주황색점으로 표시된 점이 계수값을 크게 바꾸기 때문이다.\n리즈: (d)의 경우 주황색점의 값 \\((x,y)\\)을 \\((-x,y)\\)로 바꾸게 된다면 상관계수의 부호가 음수가 될 것이다."
  },
  {
    "objectID": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#아이스크림을-많이-먹으면-걸리는-병-5점",
    "href": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#아이스크림을-많이-먹으면-걸리는-병-5점",
    "title": "STBDA2023 09wk-1: 중간고사_sy",
    "section": "(4) 아이스크림을 많이 먹으면 걸리는 병 – 5점",
    "text": "(4) 아이스크림을 많이 먹으면 걸리는 병 – 5점\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/icecream.csv')\nggplot(data=df.assign(temp=pd.cut(df.temp,[-np.inf,0,5,10,15,20,25,30,np.inf])))\\\n+geom_point(aes(x='icecream',y='disease',color='temp'))\\\n+geom_smooth(aes(x='icecream',y='disease',color='temp'))\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/plotnine/stats/smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/plotnine/stats/smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/plotnine/stats/smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/plotnine/stats/smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/plotnine/stats/smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/plotnine/stats/smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/plotnine/stats/smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\n\n\n\n\n\n아래의 그림을 보고 올바르게 해석한 사람을 모두 고르라. (모두 맞출경우만 정답으로 인정)\n\n그림에 대한 배경설명은 강의노트 “아이스크림을 많이 먹으면 걸리는 병”을 참고\n\n\n원영: (아이스크림 판매량, 소아마비 반응수치)의 상관계수값은 양수이다.\n가을: 온도를 통제하였을 경우 (아이스크림 판매량, 소아마비 반응수치)의 상관계수값은, 온도를 통제하지 않았을 경우 (아이스크림 판매량, 소아마비 반응수치)의 상관계수 값보다 작다.\n이서: (온도, 소아마비 반응수치)의 상관계수 값은 양수이다.\n레이: (온도, 아이스크림 판매량)의 상관계수 값은 양수이다.\n유진: 온도가 유일한 은닉변수라면, 아이스크림 판매량과 소아마비 반응수치 사이에는 인과성이 없다고 볼 수 있다."
  },
  {
    "objectID": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#산점도의-해석들-5점",
    "href": "posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html#산점도의-해석들-5점",
    "title": "STBDA2023 09wk-1: 중간고사_sy",
    "section": "(5) 산점도의 해석들 – 5점",
    "text": "(5) 산점도의 해석들 – 5점\n아래는 문제 4에 제시된 산점도와 그 해석들이다. 옳은 해석을 모두 골라라.\n\n답: 해석1, 해석2, 해석3\n\n\n해석4가 틀린이유: 상관계수가 0근처라면 FinishingSkill의 붉은 추세선이 x축과 거의 평행해야 한다.\n\n4-(1)\n\n\n\n4-(1)의 그림\n\n\n해석1: 모든 포지션에 대하여, (Age,logValue)는 음의 상관계수값을 가지며 (Age,logWage)는 양의 상관계수값을 가진다.\n4-(2)\n\n\n\n4-(2)의 그림\n\n\n해석2: [GKDiving,…,GKReflexes]는 모두 logWage와 양의 상관계수값을 가진다.\n4-(3)\n\n\n\n4-(3)의 그림\n\n\n해석3: GOALKEEPER 포지션의 경우 GKAbility를 이용하여 Overall을 추정하는 것이 합리적이지만 FORWARD 포지션의 경우 GKAbility를 이용하여 Overall을 추정하는 것은 합리적이지 않다.\n4-(4)\n\n\n\n4-(4)의 그림\n\n\n해석4: 수비수 포지션의 경우 FinishingSkills 과 logValue 사이의 상관계수 값은 거의 0에 가깝다."
  },
  {
    "objectID": "posts/anything/2023-06-01-Survival_R.html",
    "href": "posts/anything/2023-06-01-Survival_R.html",
    "title": "Survival Analysis Tutorial with R",
    "section": "",
    "text": "library(survival)\nlibrary(survminer)\nlibrary(epitools)\n\nlibrary(tidyverse)\nlibrary(ggplot2)"
  },
  {
    "objectID": "posts/anything/2023-06-01-Survival_R.html#import",
    "href": "posts/anything/2023-06-01-Survival_R.html#import",
    "title": "Survival Analysis Tutorial with R",
    "section": "",
    "text": "library(survival)\nlibrary(survminer)\nlibrary(epitools)\n\nlibrary(tidyverse)\nlibrary(ggplot2)"
  },
  {
    "objectID": "posts/anything/2023-06-01-Survival_R.html#독립변수가-범주형변수일때",
    "href": "posts/anything/2023-06-01-Survival_R.html#독립변수가-범주형변수일때",
    "title": "Survival Analysis Tutorial with R",
    "section": "독립변수가 범주형변수일때",
    "text": "독립변수가 범주형변수일때\nref : (odds ratio](https://en.wikipedia.org/wiki/Odds_ratio)\nA의 성공 확률 = \\(\\frac{P(A)}{1-P(A)}\\)\nB의 성공 확률 = \\(\\frac{P(B)}{1-P(B)}\\)\nOdds Ratio = A의 성공 확률 / B의 성공 확률\n= \\(\\frac{\\frac{P(A)}{1-P(A)}}{\\frac{P(B)}{1-P(B)}}\\)\n해석\n\n1보다 클 경우\n\nA집단의 성공할 확률이 B 집단이 성공할 확률보다 높다.\n\n1보다 작을 경우\n\nA집단의 성공할 확률이 B 집단이 성공할 확률보다 낮다.\n\n1일 경우\n\nA집단의 성공할 확률이 B 집단이 성공할 확률보다 같다.\n\n\n\n\n\n\n\n\nTip\n\n\n\n어떤 확률을 기준으로 하느냐에 따라 해석은 달라진다.\nex) 어떤 검사 값이 정상이 나올 확률\n\n1보다 클 경우\n\nA집단의 정상일 확률이 B 집단이 정상일 확률보다 높다.\n\n1보다 작을 경우\n\nA집단의 정상일 확률이 B 집단이 정상일 확률보다 낮다.\n\n1일 경우\n\nA집단의 정상일 확률이 B 집단이 정상일 확률보다 같다.\n\n\n\n\n\ntmp &lt;- lung %&gt;% mutate(tmp = ifelse(ph.karno &lt; 70, 1, 0));head(tmp)\n\n\nA data.frame: 6 × 12\n\n\n\ninst\ntime\nstatus\nage\nsex\nph.ecog\nph.karno\npat.karno\nmeal.cal\nwt.loss\ntemp\ntmp\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n3\n306\n2\n74\n1\n1\n90\n100\n1175\nNA\n1\n0\n\n\n2\n3\n455\n2\n68\n1\n0\n90\n90\n1225\n15\n1\n0\n\n\n3\n3\n1010\n1\n56\n1\n0\n90\n90\nNA\n15\n1\n0\n\n\n4\n5\n210\n2\n57\n1\n1\n90\n60\n1150\n11\n1\n0\n\n\n5\n1\n883\n2\n60\n1\n0\n100\n90\nNA\n0\n1\n0\n\n\n6\n12\n1022\n1\n74\n1\n1\n50\n80\n513\n0\n1\n1\n\n\n\n\n\n\ntmp %&gt;% select(sex, tmp) %&gt;% table()\n\n   tmp\nsex   0   1\n  1 122  15\n  2  80  10\n\n\n위의 표에서 tmp 가 0인 것이 성공, 1인 것이 실패로 보고, A집단이 성별 = 1, B집단이 성별 = 2로 본다면 오즈비는 아래와 같이 계산된다.\n\n# A의 성공 확률\n(122/137)/(15/137)\n# = (122/137)/((137-122)/137)\n\n8.13333333333333\n\n\n\n# B의 성공 확률\n(80/90)/(10/90)\n# = (80/90)/((80-10)/90)\n\n8\n\n\n\n# 오즈비\n((122/137)/(15/137))/((80/90)/(10/90))\n\n1.01666666666667\n\n\n\nrst &lt;- oddsratio.wald(tmp %&gt;% select(sex, tmp) %&gt;% table())\nrst\n\n\n    $data\n        \n\nA matrix: 3 × 3 of type int\n\n\n\n0\n1\nTotal\n\n\n\n\n1\n122\n15\n137\n\n\n2\n80\n10\n90\n\n\nTotal\n202\n25\n227\n\n\n\n$measure\n\nA matrix: 2 × 3 of type dbl\n\n\n\nestimate\nlower\nupper\n\n\n\n\n1\n1.000000\nNA\nNA\n\n\n2\n1.016667\n0.435243\n2.374791\n\n\n\n$p.value\n\nA matrix: 2 × 3 of type dbl\n\n\n\nmidp.exact\nfisher.exact\nchi.square\n\n\n\n\n1\nNA\nNA\nNA\n\n\n2\n0.9614893\n1\n0.9695386\n\n\n\n\n\n    $correction\n        FALSE\n\n\n\n\nrst$data\n\n\nA matrix: 3 × 3 of type int\n\n\n\n0\n1\nTotal\n\n\n\n\n1\n122\n15\n137\n\n\n2\n80\n10\n90\n\n\nTotal\n202\n25\n227\n\n\n\n\n\n\nrst$measure # Odds Ratio\n\n\nA matrix: 2 × 3 of type dbl\n\n\n\nestimate\nlower\nupper\n\n\n\n\n1\n1.000000\nNA\nNA\n\n\n2\n1.016667\n0.435243\n2.374791\n\n\n\n\n\n1보다 크게 나왔으니까 sex=1인 집단이 성공할 활률이 sex=2인 집단이 성공할 확률보다 높다.\n\nrst$p.value # fisher or chi-square test result\n\n\nA matrix: 2 × 3 of type dbl\n\n\n\nmidp.exact\nfisher.exact\nchi.square\n\n\n\n\n1\nNA\nNA\nNA\n\n\n2\n0.9614893\n1\n0.9695386\n\n\n\n\n\np값이 0.05보다 높게 나와 오즈비가 유의하지 않다는 것을 알 수 있다.\n\nrst$correction # correction \n\nFALSE"
  },
  {
    "objectID": "posts/anything/2023-06-01-Survival_R.html#독립변수가-연속형변수일때",
    "href": "posts/anything/2023-06-01-Survival_R.html#독립변수가-연속형변수일때",
    "title": "Survival Analysis Tutorial with R",
    "section": "독립변수가 연속형변수일때",
    "text": "독립변수가 연속형변수일때\n독립변수를 연속형 변수로, 종속변수를 이산형(0 또는 1)binomial으로 지정한 일반화 선형 모형을 사용할 것이다.\n\n\n\n\n\n\nTip\n\n\n\n물론 아래 방식은 독립변수가 범주형 변수일때도 사용 가능하다.\n하지만 독립변수가 연속형 변수일때 독립변수가 범주형일때 사용한 방법으로는 사용이 불가능하다.\n\n\n\nmodel &lt;- glm(tmp ~ wt.loss, data = tmp, family = binomial)\nsummary(model)\n\n\nCall:\nglm(formula = tmp ~ wt.loss, family = binomial, data = tmp)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.5488  -0.4825  -0.4708  -0.4651   2.1864  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.169588   0.279940  -7.750 9.18e-15 ***\nwt.loss      0.005184   0.016325   0.318    0.751    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 146.04  on 213  degrees of freedom\nResidual deviance: 145.94  on 212  degrees of freedom\n  (14 observations deleted due to missingness)\nAIC: 149.94\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nodds_ratio &lt;- exp(coef(model))[[2]] # 오즈비\nci_lower &lt;- exp(confint(model))[2,][1] # 95% 신뢰구간 하한\nci_upper &lt;- exp(confint(model))[2,][2] # 95% 신뢰구간 상한\nlist(odds_ratio=odds_ratio,ci_lower=ci_lower,ci_upper=ci_upper)\n\nWaiting for profiling to be done...\n\nWaiting for profiling to be done...\n\n\n\n\n    $odds_ratio\n        1.00519779379364\n    $ci_lower\n        2.5 %: 0.971395088673715\n    $ci_upper\n        97.5 %: 1.03624397215135"
  },
  {
    "objectID": "posts/anything/2023-06-01-Survival_R.html#odds-ratio-plot",
    "href": "posts/anything/2023-06-01-Survival_R.html#odds-ratio-plot",
    "title": "Survival Analysis Tutorial with R",
    "section": "Odds Ratio Plot",
    "text": "Odds Ratio Plot\nData Ref: stackoverflow\nand Odds plot code made by me\n\nboxLabels = c(\"Package recommendation\", \"Breeder’s recommendations\", \"Vet’s \nrecommendation\", \"Measuring cup\", \"Weigh on scales\", \"Certain number of \ncans\", \"Ad lib feeding\", \"Adjusted for body weight\")\n\n\ndf &lt;- data.frame(yAxis = length(boxLabels):1, \n                 boxOdds = log(c(0.9410685, \n                                 0.6121181, 1.1232907, 1.2222137, 0.4712629, 0.9376822, 1.0010816, \n                                 0.7121452)), \n                 boxCILow = c(-0.1789719, -0.8468693,-0.00109809, 0.09021224,\n                              -1.0183040, -0.2014975, -0.1001832,-0.4695449), \n                 boxCIHigh = c(0.05633076, -0.1566818, 0.2326694, 0.3104405, \n                               -0.4999281, 0.07093752, 0.1018351, -0.2113544))\n\n\nggplot(data = df,\n       mapping = aes(y = forcats::fct_rev(f = forcats::fct_inorder(f = boxLabels)))) +\n  geom_point(aes(x = boxOdds),size = 1.5, color = \"black\")+\n  geom_errorbarh(aes(xmax = boxCIHigh, xmin = boxCILow), size = .5, height = .2, color = \"gray50\") +\n  theme_classic()+\n  geom_vline(xintercept = 1) + # 오즈비는 1을 기준으로 보기 때문에 1의 수직선을 그려줘야 한다.\n  theme(panel.grid.minor = element_blank()) +\n  labs(x = \"\",  y = \"\", title = \"Odds ratio plot\") + \n  scale_y_discrete(labels = boxLabels)\n\n\n\n\n# the method of save ggplot file\n# You can allocate path\nggsave(file= paste0(path,\"name.png\", sep=''), width=15, height=8, units = c(\"cm\"))"
  },
  {
    "objectID": "posts/anything/2023-06-01-Survival_R.html#hazard-ratio-plot",
    "href": "posts/anything/2023-06-01-Survival_R.html#hazard-ratio-plot",
    "title": "Survival Analysis Tutorial with R",
    "section": "Hazard Ratio Plot",
    "text": "Hazard Ratio Plot\n\ndf &lt;- data.frame(yAxis = length(cova):1, # 그래프에 그려지는 변수의 순서를 지정해주기 위함\n                 boxhz = tab$HR,\n                 boxCILow = tab$lower,\n                 boxCIHigh = tab$upper)\n\n\nggplot(data = df,\n       mapping = aes(y = forcats::fct_rev(f = forcats::fct_inorder(f = cova)))) +\n  geom_point(aes(x = boxhz), size = 1.5, color = \"black\")+\n  geom_errorbarh(aes(xmax = boxCIHigh, xmin = boxCILow), size = .5, height = .2, color = \"gray50\") +\n  theme_classic()+\n  geom_vline(xintercept = 1) +\n  theme(panel.grid.minor = element_blank()) +\n  labs(x = \"\",  y = \"\", title = \"Hazard ratio plot\")  +\n  scale_y_discrete(labels = rev(c('residual disease present (1=no,2=yes)',\n                                  'treatment group',\n                                  'in years')))"
  },
  {
    "objectID": "posts/anything/2023-06-01-Survival_R.html#log-rank-test",
    "href": "posts/anything/2023-06-01-Survival_R.html#log-rank-test",
    "title": "Survival Analysis Tutorial with R",
    "section": "Log-Rank Test",
    "text": "Log-Rank Test\n\n카플란-마이어 생존분석에서 나온 생존 함수가 유의하게 다른지 검정하는 방법\n서로 다른 두 집단의 생존률(사건 발생률)을 비교하는 비모수적 가설 검정법\nsurvdiff는 집단 간의 생존함수를 비교하기 위해 사용\np값이 0.05보다 작을 경우 생존 곡선 간에 차이가 있는 것으로 본다.\n\n\nsurvdiff(Surv(time = time, event = status) ~ sex, data=lung) # lung 데이터에서 성별에 따른 생존곡선 차이 비교\n\nCall:\nsurvdiff(formula = Surv(time = time, event = status) ~ sex, data = lung)\n\n        N Observed Expected (O-E)^2/E (O-E)^2/V\nsex=1 138      112     91.6      4.55      10.3\nsex=2  90       53     73.4      5.68      10.3\n\n Chisq= 10.3  on 1 degrees of freedom, p= 0.001 \n\n\np 값이 0.0001로 나와 생존 곡선 간에 차이가 있다는 것을 알 수 있다."
  },
  {
    "objectID": "posts/anything/2023-06-01-Survival_R.html#survival-plot",
    "href": "posts/anything/2023-06-01-Survival_R.html#survival-plot",
    "title": "Survival Analysis Tutorial with R",
    "section": "Survival plot",
    "text": "Survival plot\nRef : ggkm\n\nggkm &lt;- function(sfit, returns = FALSE,\nxlabs = \"Time\", ylabs = \"survival probability\",\nystratalabs = NULL, ystrataname = NULL,\ntimeby = 100, main = \"Kaplan-Meier Plot\",\npval = TRUE, ...) {\nrequire(plyr)\nrequire(ggplot2)\nrequire(survival)\nrequire(gridExtra)\nif(is.null(ystratalabs)) {\n   ystratalabs &lt;- as.character(levels(summary(sfit)$strata))\n}\nm &lt;- max(nchar(ystratalabs))\nif(is.null(ystrataname)) ystrataname &lt;- \"Strata\"\ntimes &lt;- seq(0, max(sfit$time), by = timeby)\n.df &lt;- data.frame(time = sfit$time, n.risk = sfit$n.risk,\n    n.event = sfit$n.event, surv = sfit$surv, strata = summary(sfit, censored = T)$strata,\n    upper = sfit$upper, lower = sfit$lower)\nlevels(.df$strata) &lt;- ystratalabs\nzeros &lt;- data.frame(time = 0, surv = 1, strata = factor(ystratalabs, levels=levels(.df$strata)),\n    upper = 1, lower = 1)\n.df &lt;- rbind.fill(zeros, .df)\nd &lt;- length(levels(.df$strata))\np &lt;- ggplot(.df, aes(time, surv, group = strata)) +\n    geom_step(aes(linetype = strata), size = 0.7) +\n    theme_bw() +\n    theme(axis.title.x = element_text(vjust = 0.5)) +\n    scale_x_continuous(xlabs, breaks = times, limits = c(0, max(sfit$time))) +\n    scale_y_continuous(ylabs, limits = c(0, 1)) +\n    theme(panel.grid.minor = element_blank()) +\n    theme(legend.position = c(ifelse(m &lt; 10, .28, .35), ifelse(d &lt; 4, .25, .35))) +\n    theme(legend.key = element_rect(colour = NA)) +\n    labs(linetype = ystrataname) +\n    theme(plot.margin = unit(c(0, 1, .5, ifelse(m &lt; 10, 1.5, 2.5)), \"lines\")) +\n    ggtitle(main)\n \nif(pval) {\n    sdiff &lt;- survdiff(eval(sfit$call$formula), data = eval(sfit$call$data))\n    pval &lt;- pchisq(sdiff$chisq, length(sdiff$n)-1, lower.tail = FALSE)\n    pvaltxt &lt;- ifelse(pval &lt; 0.0001, \"p &lt; 0.0001\", paste(\"p =\", sprintf(\"%.4f\", pval) ))\n    p &lt;- p + annotate(\"text\", x = 0.6 * max(sfit$time), y = 0.1, label = pvaltxt)\n}\n## Plotting the graphs\n    print(p)\n    if(returns) return(p)\n   \n}\n\n사용법\n\nlabs=paste(\"성별\",c(\"Male\",\"Female\"))  # legend 항목 지정 test-ref 순\nstrataname=paste(\"Sex\") # legend 명 지정\n\n\nlung$temp=ifelse(lung$sex==2,0,1) # Ref 지정, Ref=0, Test-Ref 순으로 그래프가 그려짐\n# 여기서는 여성(sex=2)를 ref로 지정해주었다.\n\n\n\n\n\n\n\nNote\n\n\n\n변수에 ref가 지정되지 않으면 결과 해석에 혼동이 있을 수 있으니 ref 지정이 필요\n\n\n\nfit=survfit(Surv(time = time, event = status)~temp ,data=lung)\n\nfit\n\nCall: survfit(formula = Surv(time = time, event = status) ~ temp, data = lung)\n\n         n events median 0.95LCL 0.95UCL\ntemp=0  90     53    426     348     550\ntemp=1 138    112    270     212     310\n\n\n\nggkm(fit,timeby=500,ystratalabs=labs,ystrataname=strataname, main = 'Survival', ylab='Event')\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\n여러개 그룹에 대하여 생존 분석을 시행하고자 할때 log rank test 해석에 주의하여야 한다.\n해당 결과에 대한 대립가설은 그룹 중 하나라도 다른 생존곡선이 존재한다라는 의미가 되기 때문에 각 집단별로 비교해보고 차이가 유의한 그룹들을 찾는 것이 낫다.\n\n\n참고로, 아래와 같이 summary 해주면 단변량의 항목별로 시간별로 볼 수 있다.\n또한, 가장 마지막 값 저장하기 위해 아래 코드 사용 가능\nsink('summary.txt')\nsummary(fit) \nsink()\n\nsummary(fit)\n\nCall: survfit(formula = Surv(time = time, event = status) ~ temp, data = lung)\n\n                temp=0 \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    5     90       1   0.9889  0.0110       0.9675        1.000\n   60     89       1   0.9778  0.0155       0.9478        1.000\n   61     88       1   0.9667  0.0189       0.9303        1.000\n   62     87       1   0.9556  0.0217       0.9139        0.999\n   79     86       1   0.9444  0.0241       0.8983        0.993\n   81     85       1   0.9333  0.0263       0.8832        0.986\n   95     83       1   0.9221  0.0283       0.8683        0.979\n  107     81       1   0.9107  0.0301       0.8535        0.972\n  122     80       1   0.8993  0.0318       0.8390        0.964\n  145     79       2   0.8766  0.0349       0.8108        0.948\n  153     77       1   0.8652  0.0362       0.7970        0.939\n  166     76       1   0.8538  0.0375       0.7834        0.931\n  167     75       1   0.8424  0.0387       0.7699        0.922\n  182     71       1   0.8305  0.0399       0.7559        0.913\n  186     70       1   0.8187  0.0411       0.7420        0.903\n  194     68       1   0.8066  0.0422       0.7280        0.894\n  199     67       1   0.7946  0.0432       0.7142        0.884\n  201     66       2   0.7705  0.0452       0.6869        0.864\n  208     62       1   0.7581  0.0461       0.6729        0.854\n  226     59       1   0.7452  0.0471       0.6584        0.843\n  239     57       1   0.7322  0.0480       0.6438        0.833\n  245     54       1   0.7186  0.0490       0.6287        0.821\n  268     51       1   0.7045  0.0501       0.6129        0.810\n  285     47       1   0.6895  0.0512       0.5962        0.798\n  293     45       1   0.6742  0.0523       0.5791        0.785\n  305     43       1   0.6585  0.0534       0.5618        0.772\n  310     42       1   0.6428  0.0544       0.5447        0.759\n  340     39       1   0.6264  0.0554       0.5267        0.745\n  345     38       1   0.6099  0.0563       0.5089        0.731\n  348     37       1   0.5934  0.0572       0.4913        0.717\n  350     36       1   0.5769  0.0579       0.4739        0.702\n  351     35       1   0.5604  0.0586       0.4566        0.688\n  361     33       1   0.5434  0.0592       0.4390        0.673\n  363     32       1   0.5265  0.0597       0.4215        0.658\n  371     30       1   0.5089  0.0603       0.4035        0.642\n  426     26       1   0.4893  0.0610       0.3832        0.625\n  433     25       1   0.4698  0.0617       0.3632        0.608\n  444     24       1   0.4502  0.0621       0.3435        0.590\n  450     23       1   0.4306  0.0624       0.3241        0.572\n  473     22       1   0.4110  0.0626       0.3050        0.554\n  520     19       1   0.3894  0.0629       0.2837        0.534\n  524     18       1   0.3678  0.0630       0.2628        0.515\n  550     15       1   0.3433  0.0634       0.2390        0.493\n  641     11       1   0.3121  0.0649       0.2076        0.469\n  654     10       1   0.2808  0.0655       0.1778        0.443\n  687      9       1   0.2496  0.0652       0.1496        0.417\n  705      8       1   0.2184  0.0641       0.1229        0.388\n  728      7       1   0.1872  0.0621       0.0978        0.359\n  731      6       1   0.1560  0.0590       0.0743        0.328\n  735      5       1   0.1248  0.0549       0.0527        0.295\n  765      3       1   0.0832  0.0499       0.0257        0.270\n\n                temp=1 \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n   11    138       3   0.9783  0.0124       0.9542        1.000\n   12    135       1   0.9710  0.0143       0.9434        0.999\n   13    134       2   0.9565  0.0174       0.9231        0.991\n   15    132       1   0.9493  0.0187       0.9134        0.987\n   26    131       1   0.9420  0.0199       0.9038        0.982\n   30    130       1   0.9348  0.0210       0.8945        0.977\n   31    129       1   0.9275  0.0221       0.8853        0.972\n   53    128       2   0.9130  0.0240       0.8672        0.961\n   54    126       1   0.9058  0.0249       0.8583        0.956\n   59    125       1   0.8986  0.0257       0.8496        0.950\n   60    124       1   0.8913  0.0265       0.8409        0.945\n   65    123       2   0.8768  0.0280       0.8237        0.933\n   71    121       1   0.8696  0.0287       0.8152        0.928\n   81    120       1   0.8623  0.0293       0.8067        0.922\n   88    119       2   0.8478  0.0306       0.7900        0.910\n   92    117       1   0.8406  0.0312       0.7817        0.904\n   93    116       1   0.8333  0.0317       0.7734        0.898\n   95    115       1   0.8261  0.0323       0.7652        0.892\n  105    114       1   0.8188  0.0328       0.7570        0.886\n  107    113       1   0.8116  0.0333       0.7489        0.880\n  110    112       1   0.8043  0.0338       0.7408        0.873\n  116    111       1   0.7971  0.0342       0.7328        0.867\n  118    110       1   0.7899  0.0347       0.7247        0.861\n  131    109       1   0.7826  0.0351       0.7167        0.855\n  132    108       2   0.7681  0.0359       0.7008        0.842\n  135    106       1   0.7609  0.0363       0.6929        0.835\n  142    105       1   0.7536  0.0367       0.6851        0.829\n  144    104       1   0.7464  0.0370       0.6772        0.823\n  147    103       1   0.7391  0.0374       0.6694        0.816\n  156    102       2   0.7246  0.0380       0.6538        0.803\n  163    100       3   0.7029  0.0389       0.6306        0.783\n  166     97       1   0.6957  0.0392       0.6230        0.777\n  170     96       1   0.6884  0.0394       0.6153        0.770\n  175     94       1   0.6811  0.0397       0.6076        0.763\n  176     93       1   0.6738  0.0399       0.5999        0.757\n  177     92       1   0.6664  0.0402       0.5922        0.750\n  179     91       2   0.6518  0.0406       0.5769        0.736\n  180     89       1   0.6445  0.0408       0.5693        0.730\n  181     88       2   0.6298  0.0412       0.5541        0.716\n  183     86       1   0.6225  0.0413       0.5466        0.709\n  189     83       1   0.6150  0.0415       0.5388        0.702\n  197     80       1   0.6073  0.0417       0.5309        0.695\n  202     78       1   0.5995  0.0419       0.5228        0.687\n  207     77       1   0.5917  0.0420       0.5148        0.680\n  210     76       1   0.5839  0.0422       0.5068        0.673\n  212     75       1   0.5762  0.0424       0.4988        0.665\n  218     74       1   0.5684  0.0425       0.4909        0.658\n  222     72       1   0.5605  0.0426       0.4829        0.651\n  223     70       1   0.5525  0.0428       0.4747        0.643\n  229     67       1   0.5442  0.0429       0.4663        0.635\n  230     66       1   0.5360  0.0431       0.4579        0.627\n  239     64       1   0.5276  0.0432       0.4494        0.619\n  246     63       1   0.5192  0.0433       0.4409        0.611\n  267     61       1   0.5107  0.0434       0.4323        0.603\n  269     60       1   0.5022  0.0435       0.4238        0.595\n  270     59       1   0.4937  0.0436       0.4152        0.587\n  283     57       1   0.4850  0.0437       0.4065        0.579\n  284     56       1   0.4764  0.0438       0.3979        0.570\n  285     54       1   0.4676  0.0438       0.3891        0.562\n  286     53       1   0.4587  0.0439       0.3803        0.553\n  288     52       1   0.4499  0.0439       0.3716        0.545\n  291     51       1   0.4411  0.0439       0.3629        0.536\n  301     48       1   0.4319  0.0440       0.3538        0.527\n  303     46       1   0.4225  0.0440       0.3445        0.518\n  306     44       1   0.4129  0.0440       0.3350        0.509\n  310     43       1   0.4033  0.0441       0.3256        0.500\n  320     42       1   0.3937  0.0440       0.3162        0.490\n  329     41       1   0.3841  0.0440       0.3069        0.481\n  337     40       1   0.3745  0.0439       0.2976        0.471\n  353     39       2   0.3553  0.0437       0.2791        0.452\n  363     37       1   0.3457  0.0436       0.2700        0.443\n  364     36       1   0.3361  0.0434       0.2609        0.433\n  371     35       1   0.3265  0.0432       0.2519        0.423\n  387     34       1   0.3169  0.0430       0.2429        0.413\n  390     33       1   0.3073  0.0428       0.2339        0.404\n  394     32       1   0.2977  0.0425       0.2250        0.394\n  428     29       1   0.2874  0.0423       0.2155        0.383\n  429     28       1   0.2771  0.0420       0.2060        0.373\n  442     27       1   0.2669  0.0417       0.1965        0.362\n  455     25       1   0.2562  0.0413       0.1868        0.351\n  457     24       1   0.2455  0.0410       0.1770        0.341\n  460     22       1   0.2344  0.0406       0.1669        0.329\n  477     21       1   0.2232  0.0402       0.1569        0.318\n  519     20       1   0.2121  0.0397       0.1469        0.306\n  524     19       1   0.2009  0.0391       0.1371        0.294\n  533     18       1   0.1897  0.0385       0.1275        0.282\n  558     17       1   0.1786  0.0378       0.1179        0.270\n  567     16       1   0.1674  0.0371       0.1085        0.258\n  574     15       1   0.1562  0.0362       0.0992        0.246\n  583     14       1   0.1451  0.0353       0.0900        0.234\n  613     13       1   0.1339  0.0343       0.0810        0.221\n  624     12       1   0.1228  0.0332       0.0722        0.209\n  643     11       1   0.1116  0.0320       0.0636        0.196\n  655     10       1   0.1004  0.0307       0.0552        0.183\n  689      9       1   0.0893  0.0293       0.0470        0.170\n  707      8       1   0.0781  0.0276       0.0390        0.156\n  791      7       1   0.0670  0.0259       0.0314        0.143\n  814      5       1   0.0536  0.0239       0.0223        0.128\n  883      3       1   0.0357  0.0216       0.0109        0.117"
  },
  {
    "objectID": "posts/anything/A2.out.html",
    "href": "posts/anything/A2.out.html",
    "title": "A2: 강화학습 (2) – 4x4 grid",
    "section": "",
    "text": "내 메모는 녹색\n\n강의영상\nhttps://www.youtube.com/watch?v=Z4D70gCZwVU&list=PLQqh36zP38-zHvVuJ92xfdypwHwDFgg8k&index=1\n\n\nGame2: 4x4 grid\n- 문제설명: 4x4 그리드월드에서 상하좌우로 움직이는 에이전트가 목표점에 도달하도록 학습하는 방법\n\n\nimports\n\nimport gymnasium as gym\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nimport IPython\n\n\n\n예비학습: 시각화\n\ndef show(states):\n    fig = plt.Figure()\n    ax = fig.subplots()\n    ax.matshow(np.zeros([4,4]), cmap='bwr',alpha=0.0)\n    sc = ax.scatter(0, 0, color='red', s=500)  \n    ax.text(0, 0, 'start', ha='center', va='center')\n    ax.text(3, 3, 'end', ha='center', va='center')\n    # Adding grid lines to the plot\n    ax.set_xticks(np.arange(-.5, 4, 1), minor=True)\n    ax.set_yticks(np.arange(-.5, 4, 1), minor=True)\n    ax.grid(which='minor', color='black', linestyle='-', linewidth=2)\n    def update(t):\n        sc.set_offsets(states[t])\n    ani = FuncAnimation(fig,update,frames=len(states))\n    display(IPython.display.HTML(ani.to_jshtml()))\n\n\nshow([[0,0],[0,1],[1,1],[1,2],[1,3],[1,2],[1,3],[1,2],[1,3],[1,2],[1,3]])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nEnv 클래스 구현\n- GridWorld: 강화학습에서 많이 예시로 사용되는 기본적인 시뮬레이션 환경\n\nState: 각 격자 셀이 하나의 상태이며, 에이전트는 이러한 상태 중 하나에 있을 수 있음.\nAction: 에이전트는 현재상태에서 다음상태로 이동하기 위해 상,하,좌,우 중 하나의 행동을 취할 수 있음.\nReward: 에이전트가 현재상태에서 특정 action을 하면 얻어지는 보상\nTerminated: 하나의 에피소드가 종료되었음을 나타내는 상태\n\n\naction = 3\ncurrent_state = np.array([1,1])\n\n\naction_to_direction = { \n            0 : np.array([1, 0]), # x+ \n            1 : np.array([0, 1]), # y+ \n            2 : np.array([-1 ,0]), # x- \n            3 : np.array([0, -1]) # y- \n        }\n\n\nnext_state = current_state + action_to_direction[action]\nnext_state\n\narray([1, 0])\n\n\n\nclass GridWorld:\n    def __init__(self):\n        self.reset()\n        self.state_space = gym.spaces.MultiDiscrete([4,4])\n        self.action_space = gym.spaces.Discrete(4) \n        self._action_to_direction = { \n            0 : np.array([1, 0]), # x+ \n            1 : np.array([0, 1]), # y+ \n            2 : np.array([-1 ,0]), # x- \n            3 : np.array([0, -1]) # y- \n        }\n    def reset(self):\n        self.agent_action = None \n        self.agent_state = np.array([0,0])        \n        return self.agent_state \n    def step(self,action):\n        direction = self._action_to_direction[action]\n        self.agent_state = self.agent_state + direction\n        if self.agent_state not in env.state_space: # 4x4 그리드 밖에 있는 경우\n            reward = -10 \n            terminated = True\n            self.agent_state = self.agent_state -1/2 * direction\n        elif np.array_equal(env.agent_state, np.array([3,3])): # 목표지점에 도달할 경우 \n            reward = 100 \n            terminated = True\n        else: \n            reward = -1 \n            terminated = False         \n        return self.agent_state, reward, terminated\n\ngrid를 벗어나는 경우를 reward가 -10이 되게 함\n\nenv = GridWorld()\n\n\nstates = [] \nstate = env.reset()\nstates.append(state) \nfor t in range(50):\n    action = env.action_space.sample() \n    state,reward,terminated = env.step(action)\n    states.append(state) \n    if terminated: break \n\n에이전트가 무지한 경우\n\nstates\n\n[array([0, 0]),\n array([0, 1]),\n array([0, 0]),\n array([1, 0]),\n array([2, 0]),\n array([ 2. , -0.5])]\n\n\n\nshow(states)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nAgent1 클래스 구현 + Run\n- 우리가 구현하고 싶은 기능\n\n.act(): 액션을 결정 –&gt; 여기서는 그냥 랜덤액션\n.save_experience(): 데이터를 저장 –&gt; 여기에 일단 초점을 맞추자\n.learn(): 데이터로에서 학습 –&gt; 패스\n\n- 첫번째 시도\n\nclass Agent1:\n    def __init__(self,env):\n        self.action_space = env.action_space\n        self.state_spcae = env.state_space \n        self.n_experiences = 0 \n        self.n_episodes = 0 \n        self.score = 0 \n        \n        # episode-wise info \n        self.scores = [] \n        self.playtimes = []\n\n        # time-wise info\n        self.current_state = None \n        self.action = None \n        self.reward = None \n        self.next_state = None         \n        self.terminated = None \n\n        # replay_buffer \n        self.actions = []\n        self.current_states = [] \n        self.rewards = []\n        self.next_states = [] \n        self.terminations = [] \n\n    def act(self):\n        self.action = self.action_space.sample() \n\n    def save_experience(self):\n        self.actions.append(self.action) \n        self.current_states.append(self.current_state)\n        self.rewards.append(self.reward)\n        self.next_states.append(self.next_state)\n        self.terminations.append(self.terminated) \n        self.n_experiences += 1 \n        self.score = self.score + self.reward \n        \n    def learn(self):\n        pass \n\n일단 랜덤으로 acition 선택\n에피소드의 개념은 몇번째 게임중이냐!\n\nenv = GridWorld() \nagent = Agent1(env) \nfor _ in range(20):\n    ## 본질적인 코드 \n    agent.current_state = env.reset()\n    agent.terminated = False \n    agent.score = 0 \n    for t in range(50):\n        # step1: agent &gt;&gt; env \n        agent.act() \n        env.agent_action = agent.action  \n        # step2: agent &lt;&lt; env \n        agent.next_state, agent.reward, agent.terminated = env.step(env.agent_action)\n        agent.save_experience() \n        # step3: learn \n        # agent.learn()\n        # step4: state update \n        agent.current_state = agent.next_state \n        # step5: \n        if agent.terminated: break \n    agent.scores.append(agent.score) \n    agent.playtimes.append(t+1)\n    agent.n_episodes = agent.n_episodes + 1 \n    ## 덜 본질적인 코드 \n    print(\n        f\"Epsiode: {agent.n_episodes} \\t\"\n        f\"Score: {agent.scores[-1]} \\t\"\n        f\"Playtime: {agent.playtimes[-1]}\"\n    )   \n\nEpsiode: 1  Score: -10  Playtime: 1\nEpsiode: 2  Score: -10  Playtime: 1\nEpsiode: 3  Score: -10  Playtime: 1\nEpsiode: 4  Score: -17  Playtime: 8\nEpsiode: 5  Score: -10  Playtime: 1\nEpsiode: 6  Score: -11  Playtime: 2\nEpsiode: 7  Score: -22  Playtime: 13\nEpsiode: 8  Score: -10  Playtime: 1\nEpsiode: 9  Score: -21  Playtime: 12\nEpsiode: 10     Score: -10  Playtime: 1\nEpsiode: 11     Score: -18  Playtime: 9\nEpsiode: 12     Score: -11  Playtime: 2\nEpsiode: 13     Score: -11  Playtime: 2\nEpsiode: 14     Score: -10  Playtime: 1\nEpsiode: 15     Score: -10  Playtime: 1\nEpsiode: 16     Score: -12  Playtime: 3\nEpsiode: 17     Score: 91   Playtime: 10\nEpsiode: 18     Score: -10  Playtime: 1\nEpsiode: 19     Score: -12  Playtime: 3\nEpsiode: 20     Score: -12  Playtime: 3\n\n\nif agent.terminated: break True이면 멈추라는 뜻 \n\nsum(agent.playtimes[:7])\n\n27\n\n\n\nsum(agent.playtimes[:8])\n\n28\n\n\n위에서 맞춘 거만 가져와봄(48 = Playtime의 누적 합)\n\nstates = [np.array([0,0])] + agent.next_states[48:60]\nshow(states)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n우연히 잘맞춘 케이스\n\n\n\n환경의 이해 (1차원적 이해)\n- 무작위로 10000판을 진행해보자.\n\nenv = GridWorld() \nagent = Agent1(env) \nfor _ in range(10000):\n    ## 본질적인 코드 \n    agent.current_state = env.reset()\n    agent.terminated = False \n    agent.score = 0 \n    for t in range(50):\n        # step1: agent &gt;&gt; env \n        agent.act() \n        env.agent_action = agent.action  \n        # step2: agent &lt;&lt; env \n        agent.next_state, agent.reward, agent.terminated = env.step(env.agent_action)\n        agent.save_experience() \n        # step3: learn \n        # agent.learn()\n        # step4: state update \n        agent.current_state = agent.next_state \n        # step5: \n        if agent.terminated: break \n    agent.scores.append(agent.score) \n    agent.playtimes.append(t+1)\n    agent.n_episodes = agent.n_episodes + 1 \n\n\nagent.n_experiences\n\n32858\n\n\n- 데이터관찰\n\nagent.current_states[0], agent.actions[0], agent.rewards[0], agent.next_states[0]\n\n(array([0, 0]), 3, -10, array([ 0. , -0.5]))\n\n\n\nagent.current_states[1], agent.actions[1], agent.rewards[1], agent.next_states[1]\n\n(array([0, 0]), 3, -10, array([ 0. , -0.5]))\n\n\n\nagent.current_states[2], agent.actions[2], agent.rewards[2], agent.next_states[2]\n\n(array([0, 0]), 0, -1, array([1, 0]))\n\n\n\nagent.current_states[3], agent.actions[3], agent.rewards[3], agent.next_states[3]\n\n(array([1, 0]), 3, -10, array([ 1. , -0.5]))\n\n\n\nagent.current_states[4], agent.actions[4], agent.rewards[4], agent.next_states[4]\n\n(array([0, 0]), 0, -1, array([1, 0]))\n\n\n- 환경을 이해하기 위한 기록 (1)\nq = x,y,a\nx,y - 축 생각하면 될 듯 \n\nq = np.zeros([4,4,4])\ncount = np.zeros([4,4,4])\nfor i in range(agent.n_experiences):\n    x,y = agent.current_states[i] \n    a = agent.actions[i] \n    q[x,y,a] = q[x,y,a] + agent.rewards[i] \n    count[x,y,a] = count[x,y,a] + 1 \n\nq의 x,y,a 차원에 rewards를 더하자\ncount를 기록해야 한다는 단점\n\ncount[count == 0] = 0.01 \nq = q/count\n\n\nq[:,:,3]\n\narray([[-10.,  -1.,  -1.,  -1.],\n       [-10.,  -1.,  -1.,  -1.],\n       [-10.,  -1.,  -1.,  -1.],\n       [-10.,  -1.,  -1.,   0.]])\n\n\n\nfor a in range(4):\n    print(\n        f\"action = {a}\\n\" \n        f\"action-value function = \\n {q[:,:,a]}\\n\" \n)\n\naction = 0\naction-value function = \n [[ -1.  -1.  -1.  -1.]\n [ -1.  -1.  -1.  -1.]\n [ -1.  -1.  -1. 100.]\n [-10. -10. -10.   0.]]\n\naction = 1\naction-value function = \n [[ -1.  -1.  -1. -10.]\n [ -1.  -1.  -1. -10.]\n [ -1.  -1.  -1. -10.]\n [ -1.  -1. 100.   0.]]\n\naction = 2\naction-value function = \n [[-10. -10. -10. -10.]\n [ -1.  -1.  -1.  -1.]\n [ -1.  -1.  -1.  -1.]\n [ -1.  -1.  -1.   0.]]\n\naction = 3\naction-value function = \n [[-10.  -1.  -1.  -1.]\n [-10.  -1.  -1.  -1.]\n [-10.  -1.  -1.  -1.]\n [-10.  -1.  -1.   0.]]\n\n\n\n- 환경을 이해하기 위한 기록 (2)\nreal 과 estimate의 차이를 이용하여 update\n\nq = np.zeros([4,4,4])\nfor i in range(agent.n_experiences):\n    x,y = agent.current_states[i]\n    a = agent.actions[i]\n    q_estimated = q[x,y,a] # 우리가 환경을 이해하고 있는 값, 우리가 풀어낸 답 \n    q_realistic = agent.rewards[i] # 실제 답 \n    diff = q_realistic - q_estimated # 실제답과 풀이한값의 차이 = 오차피드백값 \n    q[x,y,a] = q_estimated + 0.05 * diff ## 새로운답 = 원래답 + 오차피드백값 \n\n오차를 5 %만 반영하자\n\nfor a in range(4):\n    print(\n        f\"action = {a}\\n\" \n        f\"action-value function = \\n {q[:,:,a]}\\n\" \n)\n\naction = 0\naction-value function = \n [[-1.         -1.         -1.         -0.99879276]\n [-1.         -1.         -0.99999999 -0.99923914]\n [-1.         -1.         -0.99999572 99.15219633]\n [-9.99277183 -9.99788945 -9.9626859   0.        ]]\n\naction = 1\naction-value function = \n [[-1.         -1.         -1.         -9.98910469]\n [-1.         -1.         -0.99999997 -9.99411261]\n [-1.         -1.         -0.99999418 -9.88466698]\n [-0.99981905 -0.99974088 99.40794708  0.        ]]\n\naction = 2\naction-value function = \n [[-10.         -10.          -9.99999978  -9.9923914 ]\n [ -1.          -1.          -0.99999999  -0.99934766]\n [ -0.99999998  -0.99999998  -0.99997791  -0.98722072]\n [ -0.9990167   -0.99960942  -0.98584013   0.        ]]\n\naction = 3\naction-value function = \n [[-10.          -1.          -1.          -0.99764828]\n [-10.          -1.          -0.99999996  -0.99818028]\n [ -9.99999999  -0.99999999  -0.99999716  -0.99645516]\n [ -9.98357707  -0.99988595  -0.99645516   0.        ]]\n\n\n\n\n\n환경의 깊은 이해 (좀 더 고차원적인 이해)\n- action=1 일때 각 state의 가치 (=기대보상)\n\nq[:,:,1]\n\narray([[-1.        , -1.        , -1.        , -9.98910469],\n       [-1.        , -1.        , -0.99999997, -9.99411261],\n       [-1.        , -1.        , -0.99999418, -9.88466698],\n       [-0.99981905, -0.99974088, 99.40794708,  0.        ]])\n\n\n- 분석1\n\nq[3,2,1]\n\n99.40794707796658\n\n\n\n상태 (3,2)에서 행동 1을 하게되면 100의 보상을 얻으므로 기대보상값은 100근처 –&gt; 합리적임\n\n- 분석2\n\nq[3,1,1]\n\n-0.9997408802884766\n\n\n\n상태 (3,1)에서 행동 1을 하게되면 -1 의 보상을 얻으므로 기대보상값은 -1 근처 –&gt; 합리적일까??\n\n- 비판: 분석2는 합리적인것 처럼 보이지만 data를 분석한 뒤에는 그다지 합리적이지 못함\n- 상황상상\n\n빈 종이를 줌\n빈 종이에는 0 또는 1을 쓸 수 있음 (action = 0 혹은 1)\n0을 쓸때와 1을 쓸때 보상이 다름\n무수히 많은 데이터를 분석해보니, 0을 쓰면 0원을 주고 1을 쓰면 10만원을 보상을 준다는 것을 “알게 되었음”\n이때 빈 종이의 가치는 5만원인가? 10만원인가? –&gt; 10만원아니야?\n\n- 직관: 생각해보니 현재 \\(s=(3,1)\\) \\(a=1\\)에서 추정된(esitated) 값은 q[3,1,1]= -0.9997128867462345 이지만[1], 현실적으로는 “실제보상(-1)과 잠재적보상(100)”을 동시에 고려해야 하는게 합리적임\n[1] 즉 next_state가 가지는 잠재적값어치는 고려되어있지 않음\n\nq_estimated = q[3,1,1]\nq_estimated\n\n-0.9997408802884766\n\n\n\nq_realistic = (-1) + 0.99 * 100 \nq_realistic\n\n98.0\n\n\n0.01은 약간의 패널티..\n\n여기에서 0.99는 “미래에 받을 보상이 현재에 비해 얼마나 중요한지를 결정하는 가중치” 이다.\n1에 가까울수록 미래에 받을 보상을 매우 중시한다는 의미 (즉 빈종이= 십만원 으로 생각한다는 의미)\n\n- 즉 \\(q(s,a)\\)는 모든 \\(s\\), \\(a\\)에 대하여\n\\[q(s,a) \\approx \\text{reward}(s,a) + 0.99 \\times \\max_{a}q(s',a)\\]\n가 성립한다면 \\(q(s,a)\\)는 타당하게 추정된 것이라 볼 수 있다. 물론 수식을 좀 더 엄밀하게 쓰면 아래와 같다.\n\\[q(s,a) \\approx \\begin{cases} \\text{reward}(s,a) & \\text{terminated} \\\\  \\text{reward}(s,a) + 0.99 \\times \\max_{a}q(s',a) & \\text{not terminated}\\end{cases}\\]\ns는 상태 a는 action\n\\(q(s,a) \\approx \\text{reward}(s,a) + 0.99 \\times \\max_{a}q(s',a)\\) 여기서 \\(\\text{reward}(s,a)\\)이거는 바로 받는 거 $ _{a}q(s’,a)$ 이거는 내각 가질 수 있는 최대 리워드\n\nq = np.zeros([4,4,4])\nfor i in range(agent.n_experiences):\n    x,y = agent.current_states[i]\n    xx,yy = agent.next_states[i]\n    a = agent.actions[i]\n    q_estimated = q[x,y,a] \n    if agent.terminations[i]:\n        q_realistic = agent.rewards[i]\n    else:\n        q_future = q[xx,yy,:].max()\n        q_realistic = agent.rewards[i] + 0.99 * q_future\n    diff = q_realistic - q_estimated \n    q[x,y,a] = q_estimated + 0.05 * diff \n\n\nfor a in range(4):\n    print(\n        f\"action = {a}\\n\" \n        f\"action-value function = \\n {q[:,:,a]}\\n\" \n)\n\naction = 0\naction-value function = \n [[88.53307362 90.49709464 92.36408758 88.68673925]\n [90.28856398 92.49369954 94.61842445 95.49617968]\n [90.91491115 94.21657181 96.89901308 99.15219633]\n [-9.99277183 -9.99788945 -9.9626859   0.        ]]\n\naction = 1\naction-value function = \n [[88.55960706 90.3131511  83.87809217 -9.98910469]\n [90.472853   92.49913938 92.55929104 -9.99411261]\n [92.35065011 94.61963597 96.65724194 -9.88466698]\n [93.42457258 96.5945232  99.40794708  0.        ]]\n\naction = 2\naction-value function = \n [[-10.         -10.          -9.99999978  -9.9923914 ]\n [ 86.56190669  88.46124563  89.96848094  80.18849597]\n [ 88.03732538  90.28026548  91.62827094  84.50628885]\n [ 87.41906298  91.06145181  87.82431486   0.        ]]\n\naction = 3\naction-value function = \n [[-10.          86.5658665   88.21628148  86.74874619]\n [-10.          88.40364698  90.19865977  90.75947241]\n [ -9.99999999  89.90158238  91.81108837  92.72733049]\n [ -9.98357707  88.02167685  91.41860035   0.        ]]\n\n\n\n\n\n행동 전략 수립\n- 상태 (0,0)에 있다고 가정해보자.\n\nq[0,0,:]\n\narray([ 88.53307362,  88.55960706, -10.        , -10.        ])\n\n\n\n행동 0 혹은 행동 1을 하는게 유리하다. // 행동 2,3을 하면 망한다.\n\n- 상태 (2,3)에 있다고 가정해보자.\n\nq[2,3,:]\n\narray([99.15219633, -9.88466698, 84.50628885, 92.72733049])\n\n\n\n행동 0을 하는게 유리함.\n\n- 상태 (3,2)에 있다고 가정해보자.\n\nq[3,2,:]\n\narray([-9.9626859 , 99.40794708, 87.82431486, 91.41860035])\n\n\n\n행동1을 하는게 유리함\n\n- 각 상태에서 최적은 action은 아래와 같다.\n\nq[0,0,:].argmax()\n\n1\n\n\n\nq[2,3,:].argmax()\n\n0\n\n\n\nq[3,2,:].argmax()\n\n1\n\n\n- 전략(=정책)을 정리해보자.\n\npolicy = np.array(['?????']*16).reshape(4,4)\npolicy\n\narray([['?????', '?????', '?????', '?????'],\n       ['?????', '?????', '?????', '?????'],\n       ['?????', '?????', '?????', '?????'],\n       ['?????', '?????', '?????', '?????']], dtype='&lt;U5')\n\n\n\ndirections = {0:'down', 1: 'right', 2:'up', 3:'left'} \n\n\nfor x in range(4):\n    for y in range(4):\n        policy[x,y] = directions[q[x,y,:].argmax()]\npolicy\n\narray([['right', 'down', 'down', 'down'],\n       ['right', 'right', 'down', 'down'],\n       ['right', 'right', 'down', 'down'],\n       ['right', 'right', 'right', 'down']], dtype='&lt;U5')\n\n\n\nq.max(axis=-1)\n\narray([[88.55960706, 90.49709464, 92.36408758, 88.68673925],\n       [90.472853  , 92.49913938, 94.61842445, 95.49617968],\n       [92.35065011, 94.61963597, 96.89901308, 99.15219633],\n       [93.42457258, 96.5945232 , 99.40794708,  0.        ]])\n\n\n\n\nAgent2 클래스 구현 + Run\n\nclass Agent2(Agent1):\n    def __init__(self,env):\n        super().__init__(env)\n        self.q = np.zeros([4,4,4]) \n    def learn(self):\n        x,y = self.current_state\n        xx,yy = self.next_state\n        a = self.action \n        q_estimated = self.q[x,y,a] \n        if self.terminated:\n            q_realistic = self.reward\n        else:\n            q_future = q[xx,yy,:].max()\n            q_realistic = self.reward + 0.99 * q_future\n        diff = q_realistic - q_estimated \n        self.q[x,y,a] = q_estimated + 0.05 * diff \n    def act(self):\n        if self.n_experiences &lt; 3000: \n            self.action = self.action_space.sample() \n        else:\n            x,y = self.current_state \n            self.action = self.q[x,y,:].argmax()\n\nexperiences 쌓일 때마다 업데이트 하기\n\nenv = GridWorld() \nagent = Agent2(env) \nfor _ in range(2000):\n    ## 본질적인 코드 \n    agent.current_state = env.reset()\n    agent.terminated = False \n    agent.score = 0 \n    for t in range(50):\n        # step1: agent &gt;&gt; env \n        agent.act() \n        env.agent_action = agent.action  \n        # step2: agent &lt;&lt; env \n        agent.next_state, agent.reward, agent.terminated = env.step(env.agent_action)\n        agent.save_experience() \n        # step3: learn \n        agent.learn()\n        # step4: state update \n        agent.current_state = agent.next_state \n        # step5: \n        if agent.terminated: break \n    agent.scores.append(agent.score) \n    agent.playtimes.append(t+1)\n    agent.n_episodes = agent.n_episodes + 1 \n    ## 덜 본질적인 코드 \n    if (agent.n_episodes % 100) ==0:\n        print(\n            f\"Epsiode: {agent.n_episodes} \\t\"\n            f\"Score: {np.mean(agent.scores[-100:])} \\t\"\n            f\"Playtime: {np.mean(agent.playtimes[-100:])}\"\n        )   \n\nEpsiode: 100    Score: -11.76   Playtime: 2.76\nEpsiode: 200    Score: -9.53    Playtime: 3.83\nEpsiode: 300    Score: -9.0     Playtime: 3.3\nEpsiode: 400    Score: -12.1    Playtime: 3.1\nEpsiode: 500    Score: -10.38   Playtime: 3.58\nEpsiode: 600    Score: -8.94    Playtime: 3.24\nEpsiode: 700    Score: -12.16   Playtime: 3.16\nEpsiode: 800    Score: -8.94    Playtime: 3.24\nEpsiode: 900    Score: -10.02   Playtime: 5.78\nEpsiode: 1000   Score: -50.0    Playtime: 50.0\nEpsiode: 1100   Score: -50.0    Playtime: 50.0\nEpsiode: 1200   Score: -50.0    Playtime: 50.0\nEpsiode: 1300   Score: -50.0    Playtime: 50.0\nEpsiode: 1400   Score: -50.0    Playtime: 50.0\nEpsiode: 1500   Score: -50.0    Playtime: 50.0\nEpsiode: 1600   Score: -50.0    Playtime: 50.0\nEpsiode: 1700   Score: -50.0    Playtime: 50.0\nEpsiode: 1800   Score: -50.0    Playtime: 50.0\nEpsiode: 1900   Score: -50.0    Playtime: 50.0\nEpsiode: 2000   Score: -50.0    Playtime: 50.0\n\n\nagent.n_episodes % 100 –&gt; 100의 배수\n\nstates = [np.array([0,0])] + agent.next_states[-agent.playtimes[-1]:] \nshow(states)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\nagent.q.max(-1).T\n\narray([[88.59212369, 90.00967758, 80.87907551, 57.04075186],\n       [90.44044671, 89.98145875, 79.93920263, 60.65439373],\n       [88.59212369, 82.69209965, 67.47304639, 43.63362743],\n       [47.92350641, 55.86149947, 40.12630608,  0.        ]])\n\n\n갇혀서 업데이트가 되지 않는 상황\nmax로만 가지 말고 랜덤으로 다른 action 취해보고 좋으면 거기로 가자\n\n\nAgnet3 클래스 구현 + Run\n\nclass Agent3(Agent2):\n    def __init__(self,env):\n        super().__init__(env)\n        self.eps = 0 \n    def act(self):\n        if np.random.rand() &lt; self.eps:\n            self.action = self.action_space.sample() \n        else:\n            x,y = self.current_state \n            self.action = self.q[x,y,:].argmax()\n\n\nenv = GridWorld() \nagent = Agent3(env) \nagent.eps = 1\nfor _ in range(5000):\n    ## 본질적인 코드 \n    agent.current_state = env.reset()\n    agent.terminated = False \n    agent.score = 0 \n    for t in range(50):\n        # step1: agent &gt;&gt; env \n        agent.act() \n        env.agent_action = agent.action  \n        # step2: agent &lt;&lt; env \n        agent.next_state, agent.reward, agent.terminated = env.step(env.agent_action)\n        agent.save_experience() \n        # step3: learn \n        agent.learn()\n        # step4: state update \n        agent.current_state = agent.next_state \n        # step5: \n        if agent.terminated: break \n    agent.scores.append(agent.score) \n    agent.playtimes.append(t+1)\n    agent.n_episodes = agent.n_episodes + 1\n    agent.eps = agent.eps * 0.999\n    ## 덜 본질적인 코드 \n    if (agent.n_episodes % 200) ==0:\n        print(\n            f\"Epsiode: {agent.n_episodes} \\t\"\n            f\"Score: {np.mean(agent.scores[-100:])} \\t\"\n            f\"Playtime: {np.mean(agent.playtimes[-100:])}\\t\"\n            f\"Epsilon: {agent.eps : .2f}\"\n        )   \n\nEpsiode: 200    Score: -12.82   Playtime: 3.82  Epsilon:  0.82\nEpsiode: 400    Score: -13.66   Playtime: 4.66  Epsilon:  0.67\nEpsiode: 600    Score: -11.49   Playtime: 6.89  Epsilon:  0.55\nEpsiode: 800    Score: -13.44   Playtime: 12.68 Epsilon:  0.45\nEpsiode: 1000   Score: -14.79   Playtime: 15.04 Epsilon:  0.37\nEpsiode: 1200   Score: -12.01   Playtime: 15.29 Epsilon:  0.30\nEpsiode: 1400   Score: 28.38    Playtime: 12.57 Epsilon:  0.25\nEpsiode: 1600   Score: 72.7     Playtime: 6.3   Epsilon:  0.20\nEpsiode: 1800   Score: 73.92    Playtime: 6.18  Epsilon:  0.17\nEpsiode: 2000   Score: 82.54    Playtime: 6.36  Epsilon:  0.14\nEpsiode: 2200   Score: 82.56    Playtime: 6.34  Epsilon:  0.11\nEpsiode: 2400   Score: 77.03    Playtime: 6.37  Epsilon:  0.09\nEpsiode: 2600   Score: 81.36    Playtime: 6.53  Epsilon:  0.07\nEpsiode: 2800   Score: 88.94    Playtime: 6.56  Epsilon:  0.06\nEpsiode: 3000   Score: 83.42    Playtime: 6.76  Epsilon:  0.05\nEpsiode: 3200   Score: 93.8     Playtime: 6.1   Epsilon:  0.04\nEpsiode: 3400   Score: 91.67    Playtime: 6.03  Epsilon:  0.03\nEpsiode: 3600   Score: 89.19    Playtime: 6.4   Epsilon:  0.03\nEpsiode: 3800   Score: 91.32    Playtime: 6.38  Epsilon:  0.02\nEpsiode: 4000   Score: 93.71    Playtime: 6.19  Epsilon:  0.02\nEpsiode: 4200   Score: 93.89    Playtime: 6.01  Epsilon:  0.01\nEpsiode: 4400   Score: 92.45    Playtime: 6.44  Epsilon:  0.01\nEpsiode: 4600   Score: 94.94    Playtime: 6.06  Epsilon:  0.01\nEpsiode: 4800   Score: 90.08    Playtime: 6.61  Epsilon:  0.01\nEpsiode: 5000   Score: 93.91    Playtime: 5.99  Epsilon:  0.01\n\n\n\nstates = [np.array([0,0])] + agent.next_states[-agent.playtimes[-1]:] \nshow(states)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/anything/A1.out.html",
    "href": "posts/anything/A1.out.html",
    "title": "A1: 강화학습 (1) – bandit",
    "section": "",
    "text": "내 메모는 녹색\n\n강의영상\nhttps://youtu.be/playlist?list=PLQqh36zP38-zoOHd7w3N5q9Jc5P34Ux8X&si=MdJTHM3a27MCAssp\n\n\n환경셋팅\n- 설치 (코랩)\n!pip install -q swig\n!pip install gymnasium\n!pip install gymnasium[box2d]\n\n\nimports\n\nimport gymnasium as gym\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nref: https://gymnasium.farama.org/index.html\n\n\n\nintro\n- 강화학습(대충설명): 어떠한 “(게임)환경”이 있을때 거기서 “뭘 할지”를 학습하는 과업\n- 딥마인드: breakout \\(\\to\\) 알파고\n\nhttps://www.youtube.com/watch?v=TmPfTpjtdgg\n\n- 강화학습 미래? (이거 잘하면 먹고 살 수 있을까?)\n- 선행 (강화학습)\n\n프로그래밍 지식: 파이썬, 클래스에 대한 이해 // https://guebin.github.io/PP2023/ 10wk-2 이후\n딥러닝 기본지식: DNN // https://guebin.github.io/DL2022/ 3wk-02 ~ 4wk-02\n수학적인 지식: 마코프과정\n\n\n\nGame1: bandit\n- 문제설명: 두 개의 버튼이 있다. 버튼0을 누르면 1의 보상을, 버튼1을 누르면 100의 보상을 준다고 가정\n- 처음에 어떤 행동을 해야 하는가? —&gt; ??? 처음에는 아는게 없음 —&gt; 일단 “아무거나” 눌러보자.\n- 버튼을 아무거나 누르는 함수를 구현해보자.\n\naction_space = ['button0', 'button1'] \naction = np.random.choice(action_space)\naction\n\n'button1'\n\n\n- 보상을 주는 함수를 구현해보자.\n\nif action == 'button0': # button0을 눌렀다면 \n    reward = 1 \nelse: # button1을 눌렀다면 \n    reward = 100 \n\n\nreward\n\n100\n\n\n- 아무버튼이나 10번정도 눌러보면서 데이터를 쌓아보자.\n\nfor _ in range(10):\n    action = np.random.choice(action_space)\n    if action == 'button0': \n        reward = 1 \n    else: \n        reward = 100     \n    print(action,reward) \n\nbutton0 1\nbutton0 1\nbutton0 1\nbutton0 1\nbutton0 1\nbutton1 100\nbutton0 1\nbutton0 1\nbutton1 100\nbutton0 1\n\n\n- 깨달았음: button0을 누르면 1점을 받고, button1을 누르면 100점을 받는 “환경”이구나? \\(\\to\\) button1을 누르는 “동작”을 해야하는 상황이구나?\n\n여기에서 \\(\\to\\)의 과정을 체계화 시킨 학문이 강화학습\n\n\nfor _ in range(10):\n    action = action_space[1]\n    if action == 'button0': \n        reward = 1 \n    else: \n        reward = 100     \n    print(action,reward) \n\nbutton1 100\nbutton1 100\nbutton1 100\nbutton1 100\nbutton1 100\nbutton1 100\nbutton1 100\nbutton1 100\nbutton1 100\nbutton1 100\n\n\n\n게임 클리어\n\n- 강화학습: 환경을 이해 \\(\\to\\) 행동을 결정\n위의 과정이 잘 되었다는 의미로 사용하는 문장들\n\n강화학습이 성공적으로 잘 되었다.\n에이전트가 환경의 과제를 완료했다.\n에이전트가 환경에서 성공적으로 학습했다.\n에이전트가 올바른 행동을 학습했다.\n게임 클리어 (비공식)\n\n- 게임이 클리어 되었다는 것을 의미하는 지표를 정하고 싶다.\n\n첫 생각: button1을 누르는 순간 게임클리어로 보면 되지 않나?\n두번째 생각: 아니지? 우연히 누를수도 있잖아?\n게임클리어조건: 최근 20번의 보상이 1900점 이상이면 게임이 클리어 되었다고 생각하자.[1]\n\n- 무지한자 – 게임을 클리어할 수 없다.\n[1] button1을 눌러야 하는건 맞지만 20번에 한번정도의 실수는 눈감아 주는 조건\n\naction_space = [0,1]\nrewards = [] \nfor t in range(50): # 10000번을 해도 못깸 \n    action = np.random.choice(action_space) # 무지한자의 행동 (찍어) \n    if action == 0: \n        reward = 1 \n        rewards.append(reward)\n    else: \n        reward = 100\n        rewards.append(reward)\n    print(\n        f\"n_try = {t+1}\\t\"\n        f\"action= {action}\\t\"\n        f\"reward= {reward}\\t\"\n        f\"reward20= {sum(rewards[-20:])}\\t\"\n    )\n    if np.sum(rewards[-20:])&gt;=1900:\n        break \n\nn_try = 1   action= 0   reward= 1   reward20= 1 \nn_try = 2   action= 0   reward= 1   reward20= 2 \nn_try = 3   action= 1   reward= 100 reward20= 102   \nn_try = 4   action= 1   reward= 100 reward20= 202   \nn_try = 5   action= 1   reward= 100 reward20= 302   \nn_try = 6   action= 1   reward= 100 reward20= 402   \nn_try = 7   action= 1   reward= 100 reward20= 502   \nn_try = 8   action= 0   reward= 1   reward20= 503   \nn_try = 9   action= 1   reward= 100 reward20= 603   \nn_try = 10  action= 0   reward= 1   reward20= 604   \nn_try = 11  action= 0   reward= 1   reward20= 605   \nn_try = 12  action= 0   reward= 1   reward20= 606   \nn_try = 13  action= 0   reward= 1   reward20= 607   \nn_try = 14  action= 0   reward= 1   reward20= 608   \nn_try = 15  action= 1   reward= 100 reward20= 708   \nn_try = 16  action= 0   reward= 1   reward20= 709   \nn_try = 17  action= 0   reward= 1   reward20= 710   \nn_try = 18  action= 0   reward= 1   reward20= 711   \nn_try = 19  action= 0   reward= 1   reward20= 712   \nn_try = 20  action= 0   reward= 1   reward20= 713   \nn_try = 21  action= 1   reward= 100 reward20= 812   \nn_try = 22  action= 0   reward= 1   reward20= 812   \nn_try = 23  action= 0   reward= 1   reward20= 713   \nn_try = 24  action= 1   reward= 100 reward20= 713   \nn_try = 25  action= 1   reward= 100 reward20= 713   \nn_try = 26  action= 0   reward= 1   reward20= 614   \nn_try = 27  action= 1   reward= 100 reward20= 614   \nn_try = 28  action= 1   reward= 100 reward20= 713   \nn_try = 29  action= 1   reward= 100 reward20= 713   \nn_try = 30  action= 0   reward= 1   reward20= 713   \nn_try = 31  action= 1   reward= 100 reward20= 812   \nn_try = 32  action= 0   reward= 1   reward20= 812   \nn_try = 33  action= 1   reward= 100 reward20= 911   \nn_try = 34  action= 1   reward= 100 reward20= 1010  \nn_try = 35  action= 1   reward= 100 reward20= 1010  \nn_try = 36  action= 0   reward= 1   reward20= 1010  \nn_try = 37  action= 1   reward= 100 reward20= 1109  \nn_try = 38  action= 0   reward= 1   reward20= 1109  \nn_try = 39  action= 0   reward= 1   reward20= 1109  \nn_try = 40  action= 1   reward= 100 reward20= 1208  \nn_try = 41  action= 1   reward= 100 reward20= 1208  \nn_try = 42  action= 0   reward= 1   reward20= 1208  \nn_try = 43  action= 1   reward= 100 reward20= 1307  \nn_try = 44  action= 1   reward= 100 reward20= 1307  \nn_try = 45  action= 0   reward= 1   reward20= 1208  \nn_try = 46  action= 1   reward= 100 reward20= 1307  \nn_try = 47  action= 1   reward= 100 reward20= 1307  \nn_try = 48  action= 1   reward= 100 reward20= 1307  \nn_try = 49  action= 0   reward= 1   reward20= 1208  \nn_try = 50  action= 1   reward= 100 reward20= 1307  \n\n\n- 깨달은자 – 게임클리어\n\naction_space = [0,1]\nrewards = [] \nfor t in range(50): # 10000번을 해도 못깸 \n    #action = np.random.choice(action_space) # 무지한자의 행동 (찍어) \n    action = 1\n    if action == 0: \n        reward = 1 \n        rewards.append(reward)\n    else: \n        reward = 100\n        rewards.append(reward)\n    print(\n        f\"n_try = {t+1}\\t\"\n        f\"action= {action}\\t\"\n        f\"reward= {reward}\\t\"\n        f\"reward20= {sum(rewards[-20:])}\\t\"\n    )\n    if np.sum(rewards[-20:])&gt;=1900:\n        break \n\nn_try = 1   action= 1   reward= 100 reward20= 100   \nn_try = 2   action= 1   reward= 100 reward20= 200   \nn_try = 3   action= 1   reward= 100 reward20= 300   \nn_try = 4   action= 1   reward= 100 reward20= 400   \nn_try = 5   action= 1   reward= 100 reward20= 500   \nn_try = 6   action= 1   reward= 100 reward20= 600   \nn_try = 7   action= 1   reward= 100 reward20= 700   \nn_try = 8   action= 1   reward= 100 reward20= 800   \nn_try = 9   action= 1   reward= 100 reward20= 900   \nn_try = 10  action= 1   reward= 100 reward20= 1000  \nn_try = 11  action= 1   reward= 100 reward20= 1100  \nn_try = 12  action= 1   reward= 100 reward20= 1200  \nn_try = 13  action= 1   reward= 100 reward20= 1300  \nn_try = 14  action= 1   reward= 100 reward20= 1400  \nn_try = 15  action= 1   reward= 100 reward20= 1500  \nn_try = 16  action= 1   reward= 100 reward20= 1600  \nn_try = 17  action= 1   reward= 100 reward20= 1700  \nn_try = 18  action= 1   reward= 100 reward20= 1800  \nn_try = 19  action= 1   reward= 100 reward20= 1900  \n\n\n\n\n수정1: action_space의 수정\n\naction_space = gym.spaces.Discrete(2)\naction_space\n\nDiscrete(2)\n\n\n\ntype(action_space)\n\ngymnasium.spaces.discrete.Discrete\n\n\n위에서 우리가 지정한 것은 type 이 list\n- 좋은점1: sample\n\nfor _ in range(10):\n    print(action_space.sample())\n\n0\n1\n1\n1\n0\n1\n1\n0\n1\n0\n\n\n자체적 sampling 가능!\n- 좋은점2: in\n\n0 in action_space # 유효한 액션을 검사 -- 0은 유효한 액션\n\nTrue\n\n\n\n1 in action_space # 유효한 액션을 검사 -- 1은 유효한 액션 \n\nTrue\n\n\n\n2 in action_space # 유효한 액션을 검사 -- 2는 유효하지 않은 액션 \n\nFalse\n\n\nTrue의 뜻은 유효한 action이라는 뜻\n- 코드 1차수정\n\naction_space = gym.spaces.Discrete(2) \nrewards = [] \nfor t in range(50): \n    action = action_space.sample()\n    #action = 1\n    if action == 0: \n        reward = 1 \n        rewards.append(reward)\n    else: \n        reward = 100\n        rewards.append(reward)\n    print(\n        f\"n_try = {t+1}\\t\"\n        f\"action= {action}\\t\"\n        f\"reward= {reward}\\t\"\n        f\"reward20= {sum(rewards[-20:])}\\t\"\n    )\n    if np.sum(rewards[-20:])&gt;=1900:\n        break \n\nn_try = 1   action= 0   reward= 1   reward20= 1 \nn_try = 2   action= 0   reward= 1   reward20= 2 \nn_try = 3   action= 1   reward= 100 reward20= 102   \nn_try = 4   action= 0   reward= 1   reward20= 103   \nn_try = 5   action= 1   reward= 100 reward20= 203   \nn_try = 6   action= 1   reward= 100 reward20= 303   \nn_try = 7   action= 0   reward= 1   reward20= 304   \nn_try = 8   action= 1   reward= 100 reward20= 404   \nn_try = 9   action= 0   reward= 1   reward20= 405   \nn_try = 10  action= 1   reward= 100 reward20= 505   \nn_try = 11  action= 1   reward= 100 reward20= 605   \nn_try = 12  action= 0   reward= 1   reward20= 606   \nn_try = 13  action= 0   reward= 1   reward20= 607   \nn_try = 14  action= 1   reward= 100 reward20= 707   \nn_try = 15  action= 1   reward= 100 reward20= 807   \nn_try = 16  action= 1   reward= 100 reward20= 907   \nn_try = 17  action= 0   reward= 1   reward20= 908   \nn_try = 18  action= 1   reward= 100 reward20= 1008  \nn_try = 19  action= 0   reward= 1   reward20= 1009  \nn_try = 20  action= 1   reward= 100 reward20= 1109  \nn_try = 21  action= 0   reward= 1   reward20= 1109  \nn_try = 22  action= 1   reward= 100 reward20= 1208  \nn_try = 23  action= 1   reward= 100 reward20= 1208  \nn_try = 24  action= 1   reward= 100 reward20= 1307  \nn_try = 25  action= 1   reward= 100 reward20= 1307  \nn_try = 26  action= 1   reward= 100 reward20= 1307  \nn_try = 27  action= 1   reward= 100 reward20= 1406  \nn_try = 28  action= 0   reward= 1   reward20= 1307  \nn_try = 29  action= 1   reward= 100 reward20= 1406  \nn_try = 30  action= 0   reward= 1   reward20= 1307  \nn_try = 31  action= 0   reward= 1   reward20= 1208  \nn_try = 32  action= 0   reward= 1   reward20= 1208  \nn_try = 33  action= 0   reward= 1   reward20= 1208  \nn_try = 34  action= 0   reward= 1   reward20= 1109  \nn_try = 35  action= 1   reward= 100 reward20= 1109  \nn_try = 36  action= 0   reward= 1   reward20= 1010  \nn_try = 37  action= 1   reward= 100 reward20= 1109  \nn_try = 38  action= 1   reward= 100 reward20= 1109  \nn_try = 39  action= 1   reward= 100 reward20= 1208  \nn_try = 40  action= 0   reward= 1   reward20= 1109  \nn_try = 41  action= 1   reward= 100 reward20= 1208  \nn_try = 42  action= 1   reward= 100 reward20= 1208  \nn_try = 43  action= 1   reward= 100 reward20= 1208  \nn_try = 44  action= 1   reward= 100 reward20= 1208  \nn_try = 45  action= 1   reward= 100 reward20= 1208  \nn_try = 46  action= 0   reward= 1   reward20= 1109  \nn_try = 47  action= 0   reward= 1   reward20= 1010  \nn_try = 48  action= 1   reward= 100 reward20= 1109  \nn_try = 49  action= 1   reward= 100 reward20= 1109  \nn_try = 50  action= 0   reward= 1   reward20= 1109  \n\n\n\n\n수정2: Env 클래스\n- env 클래스 선언\n\nclass Bandit: \n    def step(self, action):\n        if action == 0:\n            return 1 \n        else: \n            return 100 \n\n\naction_space = gym.spaces.Discrete(2) \nenv = Bandit()\nrewards = []\nfor t in range(50): \n    #action = action_space.sample()\n    action = 1\n    reward = env.step(action)\n    rewards.append(reward)\n    print(\n        f\"n_try = {t+1}\\t\"\n        f\"action= {action}\\t\"\n        f\"reward= {reward}\\t\"\n        f\"reward20= {sum(rewards[-20:])}\\t\"\n    )\n    if np.sum(rewards[-20:])&gt;=1900:\n        break \n\nn_try = 1   action= 1   reward= 100 reward20= 100   \nn_try = 2   action= 1   reward= 100 reward20= 200   \nn_try = 3   action= 1   reward= 100 reward20= 300   \nn_try = 4   action= 1   reward= 100 reward20= 400   \nn_try = 5   action= 1   reward= 100 reward20= 500   \nn_try = 6   action= 1   reward= 100 reward20= 600   \nn_try = 7   action= 1   reward= 100 reward20= 700   \nn_try = 8   action= 1   reward= 100 reward20= 800   \nn_try = 9   action= 1   reward= 100 reward20= 900   \nn_try = 10  action= 1   reward= 100 reward20= 1000  \nn_try = 11  action= 1   reward= 100 reward20= 1100  \nn_try = 12  action= 1   reward= 100 reward20= 1200  \nn_try = 13  action= 1   reward= 100 reward20= 1300  \nn_try = 14  action= 1   reward= 100 reward20= 1400  \nn_try = 15  action= 1   reward= 100 reward20= 1500  \nn_try = 16  action= 1   reward= 100 reward20= 1600  \nn_try = 17  action= 1   reward= 100 reward20= 1700  \nn_try = 18  action= 1   reward= 100 reward20= 1800  \nn_try = 19  action= 1   reward= 100 reward20= 1900  \n\n\n\n\n수정3: Agnet 클래스\n- Agent 클래스를 만들자. (액션을 하고, 환경에서 받은 reward를 간직)\n\nclass Agent1:\n    def __init__(self):\n        self.action_space = gym.spaces.Discrete(2) \n        self.action = None \n        self.reward = None \n        self.actions = [] \n        self.rewards = []\n    def act(self):\n        self.action = self.action_space.sample() # 무지한자 \n        #self.action = 1 # 깨달은 자\n    def save_experience(self):\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n\n— 대충 아래와 같은 느낌으로 코드가 돌아가요 —\n시점0: init\n\nenv = Bandit()\nagent = Agent1() \n\n\nagent.action, agent.reward\n\n(None, None)\n\n\n시점1: agent &gt;&gt; env\nact는 sample과 비슷한 역할을 한다.\n\nagent.act()\n\n\nagent.action, agent.reward\n\n(1, None)\n\n\n\nenv.agent_action = agent.action\n\n시점2: agent &lt;&lt; env\n\nagent.reward = env.step(env.agent_action)\n\n\nagent.action, agent.reward, env.agent_action\n\n(1, 100, 1)\n\n\n\nagent.actions,agent.rewards\n\n([], [])\n\n\n\nagent.save_experience()\n\n\nagent.actions,agent.rewards\n\n([1], [100])\n\n\n– 전체코드 –\n\nenv = Bandit() \nagent = Agent1()\nfor t in range(50): \n    ## 1. main 코드 \n    # step1: agent &gt;&gt; env \n    agent.act() \n    env.agent_action = agent.action\n    # step2: agent &lt;&lt; env \n    agent.reward = env.step(env.agent_action)\n    agent.save_experience() \n\n    ## 2. 비본질적 코드 \n    print(\n        f\"n_try = {t+1}\\t\"\n        f\"action= {agent.action}\\t\"\n        f\"reward= {agent.reward}\\t\"\n        f\"reward20= {sum(agent.rewards[-20:])}\\t\"\n    )\n    if np.sum(agent.rewards[-20:])&gt;=1900:\n        break \n\nn_try = 1   action= 0   reward= 1   reward20= 1 \nn_try = 2   action= 1   reward= 100 reward20= 101   \nn_try = 3   action= 1   reward= 100 reward20= 201   \nn_try = 4   action= 0   reward= 1   reward20= 202   \nn_try = 5   action= 1   reward= 100 reward20= 302   \nn_try = 6   action= 0   reward= 1   reward20= 303   \nn_try = 7   action= 0   reward= 1   reward20= 304   \nn_try = 8   action= 1   reward= 100 reward20= 404   \nn_try = 9   action= 0   reward= 1   reward20= 405   \nn_try = 10  action= 0   reward= 1   reward20= 406   \nn_try = 11  action= 1   reward= 100 reward20= 506   \nn_try = 12  action= 0   reward= 1   reward20= 507   \nn_try = 13  action= 1   reward= 100 reward20= 607   \nn_try = 14  action= 1   reward= 100 reward20= 707   \nn_try = 15  action= 1   reward= 100 reward20= 807   \nn_try = 16  action= 1   reward= 100 reward20= 907   \nn_try = 17  action= 1   reward= 100 reward20= 1007  \nn_try = 18  action= 1   reward= 100 reward20= 1107  \nn_try = 19  action= 0   reward= 1   reward20= 1108  \nn_try = 20  action= 1   reward= 100 reward20= 1208  \nn_try = 21  action= 0   reward= 1   reward20= 1208  \nn_try = 22  action= 0   reward= 1   reward20= 1109  \nn_try = 23  action= 0   reward= 1   reward20= 1010  \nn_try = 24  action= 1   reward= 100 reward20= 1109  \nn_try = 25  action= 0   reward= 1   reward20= 1010  \nn_try = 26  action= 0   reward= 1   reward20= 1010  \nn_try = 27  action= 1   reward= 100 reward20= 1109  \nn_try = 28  action= 0   reward= 1   reward20= 1010  \nn_try = 29  action= 0   reward= 1   reward20= 1010  \nn_try = 30  action= 1   reward= 100 reward20= 1109  \nn_try = 31  action= 1   reward= 100 reward20= 1109  \nn_try = 32  action= 1   reward= 100 reward20= 1208  \nn_try = 33  action= 1   reward= 100 reward20= 1208  \nn_try = 34  action= 1   reward= 100 reward20= 1208  \nn_try = 35  action= 0   reward= 1   reward20= 1109  \nn_try = 36  action= 0   reward= 1   reward20= 1010  \nn_try = 37  action= 1   reward= 100 reward20= 1010  \nn_try = 38  action= 1   reward= 100 reward20= 1010  \nn_try = 39  action= 0   reward= 1   reward20= 1010  \nn_try = 40  action= 1   reward= 100 reward20= 1010  \nn_try = 41  action= 0   reward= 1   reward20= 1010  \nn_try = 42  action= 0   reward= 1   reward20= 1010  \nn_try = 43  action= 1   reward= 100 reward20= 1109  \nn_try = 44  action= 1   reward= 100 reward20= 1109  \nn_try = 45  action= 0   reward= 1   reward20= 1109  \nn_try = 46  action= 0   reward= 1   reward20= 1109  \nn_try = 47  action= 1   reward= 100 reward20= 1109  \nn_try = 48  action= 0   reward= 1   reward20= 1109  \nn_try = 49  action= 0   reward= 1   reward20= 1109  \nn_try = 50  action= 1   reward= 100 reward20= 1109  \n\n\n\n\n수정4: 학습과정을 포함\n- Game1에 대한 생각:\n\n사실 강화학습은 “환경을 이해 \\(\\to\\) 행동을 결정” 의 과정에서 \\(\\to\\)의 과정을 수식화 한 것이다.\n그런데 지금까지 했던 코드는 환경(env)를 이해하는 순간 에이전트가 최적의 행동(action)[1]을 직관적으로 결정하였으므로 기계가 스스로 학습을 했다고 볼 수 없다.\n\n- 지금까지의 코드 복습\n\n클래스를 선언하는 부분\n\nEnv 클래스의 선언\nAgent 클래스의 선언\n\n환경과 에이전트를 인스턴스화 (초기화)\nfor loop를 반복하여 게임을 진행\n\n메인코드: (1) agent \\(\\to\\) env (2) agent \\(\\leftarrow\\) env\n비본질적코드: 학습과정을 display, 학습의 종료조건체크\n\n\n- 앞으로 구성할 코드의 형태: 에이전트가 데이터를 보고 스스로 button1을 눌러야 한다는 생각을 했으면 좋겠음.\n\n클래스를 선언하는 부분\n\nEnv 클래스의 선언\nAgent 클래스의 선언 // &lt;—- 학습의 과정이 포함되어야 한다, act함수의 수정, learn함수의 추가\n\n환경과 에이전트를 인스턴스화 (초기화)\nfor loop를 반복하여 게임을 진행\n\n메인코드 (1) agent \\(\\to\\) env (2) agent \\(\\leftarrow\\) env // &lt;—- agent가 데이터를 분석하고 학습하는 과정이 추가\n비본질적코드: 학습과정을 display, 학습의 종료조건체크\n\n\n- 에이전트가 학습을 어떻게 하는가? 아래와 같이 버튼을 누르도록 한다면\n\n버튼0을 누를 확률: \\(\\frac{q_0}{q_0+q_1}\\)\n버튼1을 누를 확률: \\(\\frac{q_1}{q_0+q_1}\\)\n\n시간이 지날수록 버튼1을 주로 누를 것이다.\n- 걱정: \\(t=0\\) 이면 어쩌지? \\(t=1\\)이면 어쩌지?… \\(\\to\\) 해결책: 일정시간동안 랜덤액션을 하면서 데이터를 쌓고 그 뒤에 \\(q_0,q_1\\)을 계산\n- 쌓은 데이터를 바탕으로 환경을 이해하고 action을 뽑는 코드\n[1] button1을 누른다\n\nagent.actions = [0,1,1,0,1,0,0] \nagent.rewards = [1,101,102,1,99,1,1.2] \nactions = np.array(agent.actions)\nrewards = np.array(agent.rewards)\n\n\nq0 = rewards[actions == 0].mean()\nq1 = rewards[actions == 1].mean()\n\n\nagent.q = np.array([q0,q1]) \nagent.q\n\narray([  1.05      , 100.66666667])\n\n\n\nprob = agent.q / agent.q.sum()\nprob \n\narray([0.01032279, 0.98967721])\n\n\n\naction = np.random.choice([0,1], p= agent.q / agent.q.sum())\naction\n\n1\n\n\n- 최종코드정리\n\nclass Bandit: \n    def step(self, action):\n        if action == 0:\n            return 1 \n        else: \n            return 100 \nclass Agent:\n    def __init__(self):\n        self.action_space = gym.spaces.Discrete(2) \n        self.action = None \n        self.reward = None \n        self.actions = [] \n        self.rewards = []\n        self.q = np.array([0,0]) \n        self.n_experience = 0 \n    def act(self):\n        if self.n_experience&lt;30: \n            self.action = self.action_space.sample() \n        else: \n            self.action = np.random.choice([0,1], p= self.q / self.q.sum())\n    def save_experience(self):\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n        self.n_experience += 1 \n    def learn(self):\n        if self.n_experience&lt;30: \n            pass \n        else: \n            actions = np.array(self.actions)\n            rewards = np.array(self.rewards)\n            q0 = rewards[actions == 0].mean()\n            q1 = rewards[actions == 1].mean()\n            self.q = np.array([q0,q1]) \n\n\nenv = Bandit() \nagent = Agent()\nfor t in range(50): \n    ## 1. main 코드 \n    # step1: agent &gt;&gt; env \n    agent.act() \n    env.agent_action = agent.action\n    # step2: agent &lt;&lt; env \n    agent.reward = env.step(env.agent_action)\n    agent.save_experience() \n    # step3: learn \n    agent.learn()\n    ## 2. 비본질적 코드 \n    print(\n        f\"n_try = {t+1}\\t\"\n        f\"action= {agent.action}\\t\"\n        f\"reward= {agent.reward}\\t\"\n        f\"reward20= {sum(agent.rewards[-20:])}\\t\"\n        f\"q = {agent.q}\"\n    )\n    if np.sum(agent.rewards[-20:])&gt;=1900:\n        break \n\nn_try = 1   action= 1   reward= 100 reward20= 100   q = [0 0]\nn_try = 2   action= 1   reward= 100 reward20= 200   q = [0 0]\nn_try = 3   action= 0   reward= 1   reward20= 201   q = [0 0]\nn_try = 4   action= 1   reward= 100 reward20= 301   q = [0 0]\nn_try = 5   action= 1   reward= 100 reward20= 401   q = [0 0]\nn_try = 6   action= 1   reward= 100 reward20= 501   q = [0 0]\nn_try = 7   action= 1   reward= 100 reward20= 601   q = [0 0]\nn_try = 8   action= 0   reward= 1   reward20= 602   q = [0 0]\nn_try = 9   action= 1   reward= 100 reward20= 702   q = [0 0]\nn_try = 10  action= 0   reward= 1   reward20= 703   q = [0 0]\nn_try = 11  action= 0   reward= 1   reward20= 704   q = [0 0]\nn_try = 12  action= 0   reward= 1   reward20= 705   q = [0 0]\nn_try = 13  action= 0   reward= 1   reward20= 706   q = [0 0]\nn_try = 14  action= 1   reward= 100 reward20= 806   q = [0 0]\nn_try = 15  action= 0   reward= 1   reward20= 807   q = [0 0]\nn_try = 16  action= 1   reward= 100 reward20= 907   q = [0 0]\nn_try = 17  action= 0   reward= 1   reward20= 908   q = [0 0]\nn_try = 18  action= 0   reward= 1   reward20= 909   q = [0 0]\nn_try = 19  action= 0   reward= 1   reward20= 910   q = [0 0]\nn_try = 20  action= 0   reward= 1   reward20= 911   q = [0 0]\nn_try = 21  action= 1   reward= 100 reward20= 911   q = [0 0]\nn_try = 22  action= 1   reward= 100 reward20= 911   q = [0 0]\nn_try = 23  action= 0   reward= 1   reward20= 911   q = [0 0]\nn_try = 24  action= 0   reward= 1   reward20= 812   q = [0 0]\nn_try = 25  action= 0   reward= 1   reward20= 713   q = [0 0]\nn_try = 26  action= 1   reward= 100 reward20= 713   q = [0 0]\nn_try = 27  action= 1   reward= 100 reward20= 713   q = [0 0]\nn_try = 28  action= 0   reward= 1   reward20= 713   q = [0 0]\nn_try = 29  action= 1   reward= 100 reward20= 713   q = [0 0]\nn_try = 30  action= 0   reward= 1   reward20= 713   q = [  1. 100.]\nn_try = 31  action= 1   reward= 100 reward20= 812   q = [  1. 100.]\nn_try = 32  action= 1   reward= 100 reward20= 911   q = [  1. 100.]\nn_try = 33  action= 1   reward= 100 reward20= 1010  q = [  1. 100.]\nn_try = 34  action= 1   reward= 100 reward20= 1010  q = [  1. 100.]\nn_try = 35  action= 1   reward= 100 reward20= 1109  q = [  1. 100.]\nn_try = 36  action= 1   reward= 100 reward20= 1109  q = [  1. 100.]\nn_try = 37  action= 1   reward= 100 reward20= 1208  q = [  1. 100.]\nn_try = 38  action= 1   reward= 100 reward20= 1307  q = [  1. 100.]\nn_try = 39  action= 1   reward= 100 reward20= 1406  q = [  1. 100.]\nn_try = 40  action= 1   reward= 100 reward20= 1505  q = [  1. 100.]\nn_try = 41  action= 1   reward= 100 reward20= 1505  q = [  1. 100.]\nn_try = 42  action= 1   reward= 100 reward20= 1505  q = [  1. 100.]\nn_try = 43  action= 1   reward= 100 reward20= 1604  q = [  1. 100.]\nn_try = 44  action= 1   reward= 100 reward20= 1703  q = [  1. 100.]\nn_try = 45  action= 1   reward= 100 reward20= 1802  q = [  1. 100.]\nn_try = 46  action= 1   reward= 100 reward20= 1802  q = [  1. 100.]\nn_try = 47  action= 1   reward= 100 reward20= 1802  q = [  1. 100.]\nn_try = 48  action= 1   reward= 100 reward20= 1901  q = [  1. 100.]"
  },
  {
    "objectID": "posts/anything/2023-04-17-Survival_Analysis.html",
    "href": "posts/anything/2023-04-17-Survival_Analysis.html",
    "title": "Survival Analysis",
    "section": "",
    "text": "Survival Analysis\n\n생존분석(Survival Analysis)은 시간에 따른 사건(event) 발생을 다루는 통계적 분석 방법입니다.\n기본적으로 생존분석은 다음과 같은 개념을 사용합니다.\n\n생존시간(survival time) : 어떤 사건이 발생하기까지 걸리는 시간\n생존함수(survival function) : 어떤 시점까지 생존할 확률을 나타내는 함수\n위험함수(hazard function) : 어떤 시점에서 사건이 발생할 위험성을 나타내는 함수\n\n생존분석에서는 위의 개념을 사용하여 시간에 따라 생존함수와 위험함수를 추정합니다. 이를 통해 어떤 사건이 발생하기까지 걸리는 시간과 그 시간에 따른 생존확률을 예측할 수 있습니다.\n생존분석에는 여러 가지 방법이 있지만, 가장 대표적인 방법은 코크스-매키스(Cox-Meier) 생존분석입니다. 이 방법은 다음과 같은 절차를 따릅니다.\n\n데이터 수집 : 연구 대상이 되는 그룹의 데이터를 수집합니다.\n데이터 전처리 : 수집한 데이터를 정리하고 필요한 변수를 선택합니다.\n생존함수 추정 : 적합한 생존모형을 선택하여 생존함수와 위험함수를 추정합니다.\n생존분석 결과 해석 : 추정된 생존함수와 위험함수를 시각화하고, 예측된 생존시간 등을 분석합니다.\n\n생존분석은 데이터의 특성에 따라 다양한 모델을 사용할 수 있습니다.\n일반적으로는 코크스-매키스 생존분석 외에도 침입(입원)한 경우를 대상으로 하는 Kaplan-Meier 생존분석 등이 사용됩니다.\n이들 생존분석 방법은 시간에 따른 사건 발생률, 생존확률 등을 예측하는 데 유용합니다.\nlibrary(survival) # 생존분석 패키지\nsurvfit 함수는 생존분석에서 Kaplan-Meier 생존곡선을 추정하는 함수입니다.\n이 함수는 생존시간 데이터와 이벤트 발생 여부 데이터를 이용해 생존곡선을 추정하고, 추정된 생존곡선을 시각화할 수 있습니다.\nsurvfit 함수를 사용하기 위해서는 먼저 생존시간과 이벤트 발생 여부 데이터를 Surv 함수를 이용해 생성해야 합니다.\nSurv 함수는 생존분석에서 사용되는 시간과 상태(이벤트 발생 여부) 데이터를 담은 객체를 생성합니다. Surv 함수는 다음과 같은 형태로 사용됩니다.\nSurv(time, event)\n여기서 formula는 Surv 객체를 포함한 모형을 지정하는데 사용되는 공식을 나타내며, data는 데이터 프레임을 나타냅니다.\n예를 들어, lung 데이터셋에서 생존시간과 이벤트 발생 여부 데이터를 추출하고, 이를 Surv 함수에 입력하여 생존곡선을 추정하려면 다음과 같이 작성할 수 있습니다.\n예시 및 사용법\nlibrary(survival) # 생존분석 패키지 불러오기\ndata(lung) # R 내장 데이터셋인 lung 데이터 불러오기\n\nsurv_obj &lt;- Surv(time = lung$time, event = lung$status) # 생존시간과 이벤트 발생 여부 데이터 추출\n\nsurvfit_obj &lt;- survfit(surv_obj ~ 1) # Kaplan-Meier 생존곡선 추정\nsurvfit_obj &lt;- survfit(surv_obj ~ 1) # Kaplan-Meier 생존곡선 추정\n\nsummary(survfit_obj)\n\nCall: 사용한 함수 및 입력 정보를 보여줍니다.\ntime n: 생존시간 데이터의 총 관측 수를 보여줍니다.\nevents n: 이벤트 발생 여부 데이터 중 이벤트가 발생한 수를 보여줍니다.\nmedian: 생존곡선에서의 중위 생존시간을 보여줍니다.\n0.95LCL, 0.95UCL: 생존곡선의 95% 신뢰구간을 보여줍니다.\nCall: 생존곡선 상태표를 출력합니다. 상태표는 생존시간의 범위와 이벤트 발생 여부에 따라 생존곡선의 상태를 표시합니다.\nn events: 이벤트 발생 여부 데이터 중 이벤트가 발생한 수를 보여줍니다.\nlog-rank: 로그 랭크 검정에 대한 결과를 보여줍니다. 로그 랭크 검정은 생존곡선 간 차이의 유의성을 검정하는 검정 방법 중 하나입니다.\n\nlibrary(survminer) # 생존분석 결과 시각화 패키지\nsurvminer 패키지는 생존 분석 결과를 시각화하기 위한 패키지로, 생존 함수, 생존 곡선, 누적 발생율 함수 등을 그래프로 그릴 수 있습니다. 이 패키지는 ggplot2 패키지를 기반으로 하여 만들어졌으며, ggplot2의 그래프 작성 방법과 유사합니다.\nsurvminer 패키지에서 제공하는 함수와 예시를 설명하겠습니다.\n\nggsurvplot 함수 ggsurvplot 함수는 생존 곡선을 그리기 위한 함수입니다. 예를 들어, 다음과 같이 생존 분석 결과를 이용하여 생존 곡선을 그릴 수 있습니다.\n\nlibrary(survival)\nlibrary(survminer)\n\ndata(lung)\nfit &lt;- survfit(Surv(time, status) ~ sex, data = lung)\n\nggsurvplot(fit, data = lung, risk.table = TRUE)\n위 코드에서는 lung 데이터셋에서 time과 status 변수를 이용하여 생존 분석을 수행한 뒤, 성별에 따른 생존 곡선을 그리도록 하였습니다. ggsurvplot 함수의 risk.table 인자를 TRUE로 설정하면, 위 그래프와 함께 위험표(risk table)도 함께 출력됩니다.\n\nggcoxzph 함수 ggcoxzph 함수는 Cox 비례위험 모형 가정을 검정하기 위한 그래프를 그리기 위한 함수입니다. 예를 들어, 다음과 같이 Cox 비례위험 모형 가정을 검정하기 위한 그래프를 그릴 수 있습니다.\n\nlibrary(survival)\nlibrary(survminer)\n\ndata(lung)\nfit &lt;- coxph(Surv(time, status) ~ age + sex, data = lung)\n\nggcoxzph(fit, linear.predictions = TRUE)\n위 코드에서는 lung 데이터셋에서 age와 sex 변수를 이용하여 Cox 비례위험 모형을 적합한 뒤, 모형 가정을 검정하기 위한 그래프를 그리도록 하였습니다. ggcoxzph 함수의 linear.predictions 인자를 TRUE로 설정하면, 선형 예측값과 함께 그래프가 출력됩니다.\n\nggforest 함수 ggforest 함수는 Cox 모형에서 변수의 효과를 비교하기 위한 그래프를 그리기 위한 함수입니다. 예를 들어, 다음과 같이 Cox 모형에서 변수의 효과를 비교하는 그래프를 그릴 수 있습니다.\n\nlibrary(survival)\nlibrary(survminer)\n\ndata(lung)\nfit &lt;- coxph(Surv(time, status) ~ age + sex + ph.ecog, data = lung)\n\nggforest(fit, data = lung)\n\nggcoxdiagnostics 함수 ggcoxdiagnostics 함수는 Cox 모형의 가정을 검정하기 위한 그래프를 그리기 위한 함수입니다. 예를 들어, 다음과 같이 Cox 모형의 가정을 검정하는 그래프를 그릴 수 있습니다.\n\nlibrary(survival)\nlibrary(survminer)\n\ndata(lung)\nfit &lt;- coxph(Surv(time, status) ~ age + sex + ph.ecog, data = lung)\n\nggcoxdiagnostics(fit, type = \"deviance\")\n위 코드에서는 lung 데이터셋에서 age, sex, ph.ecog 변수를 이용하여 Cox 모형을 적합한 뒤, 모형 가정을 검정하는 그래프를 그리도록 하였습니다. ggcoxdiagnostics 함수의 type 인자를 “deviance”로 설정하면, 잔차 그래프와 로그(-로그) 생존 함수 그래프가 출력됩니다.\n\nggdag 함수 ggdag 함수는 DAG(Directed Acyclic Graph)를 그리기 위한 함수입니다. 예를 들어, 다음과 같이 DAG를 그릴 수 있습니다.\n\nlibrary(survminer)\n\nggdag(igraph::make_empty_graph(3) +\n  igraph::make_edges(c(1,2,2,3))\n)\n위 코드에서는 igraph 패키지를 이용하여 빈 그래프를 만든 뒤, 간선을 추가하여 DAG를 그리도록 하였습니다. ggdag 함수는 igraph 객체를 입력으로 받으며, 그래프를 그릴 때는 ggplot2의 기능을 이용합니다."
  },
  {
    "objectID": "posts/anything/A3.out.html",
    "href": "posts/anything/A3.out.html",
    "title": "A3: 강화학습 (3) – LunarLander",
    "section": "",
    "text": "내 메모는 녹색\n\n강의영상\nhttps://www.youtube.com/watch?v=Y55g-okEsjI&list=PLQqh36zP38-zBEizLbjgRE8qMfsJML6Ua&index=1\n\n\nimports\n\nimport gymnasium as gym\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nimport torch\nimport collections\nimport IPython\n\n\n\n예비학습\n- collections.deque 의 기능\n\na = collections.deque([1,2,3], maxlen = 5 )\na\n\ndeque([1, 2, 3])\n\n\n\na.append(4)\na\n\ndeque([1, 2, 3, 4])\n\n\n\na.append(5)\na\n\ndeque([1, 2, 3, 4, 5])\n\n\n\na.append(6)\na\n\ndeque([2, 3, 4, 5, 6])\n\n\n- 단점? numpy array 보다는 list 느낌임 (연산에 특화된건 아님)\n\na + 1\n\nTypeError: can only concatenate deque (not \"int\") to deque\n\n\n- 그렇지만 필요하다면 np.array 화 시킬 수 있음.\n\nnp.array(a) + 1\n\n- collection.deque 는 리플레이 버퍼를 구현할때 유용한 자료구조이다.\n\n(우리가 했던) 기존방식: 모든 데이터를 저장하며 하나의 경험씩 학습함\n리플레이버퍼: 최근 \\(N\\)개의 데이터를 저장하여 여러경험을 샘플링하여 학습하는 방식\n리플레이버퍼의 장점: 메모리를 아낄 수 있다, 다양한 종류의 경험을 저장하고 무작위로 재사용하여 학습이 안정적으로 된다, “저장 -&gt; 학습 -&gt; 저장” 순으로 반드시 실시간으로 학습할 필요가 없어서 병렬처리에 용이하다, 강화학습에서 연속된 경험은 상관관계가 있을 수 있는데 무작위 샘플로 이러한 상관관계를 제거할 수 있음\n\n\n\nGame3: LunarLander\n- 환경생성\n\nenv = gym.make('LunarLander-v2', render_mode = 'rgb_array') \nenv \n\n&lt;TimeLimit&lt;OrderEnforcing&lt;PassiveEnvChecker&lt;LunarLander&lt;LunarLander-v2&gt;&gt;&gt;&gt;&gt;\n\n\n- state_space\n\nenv.observation_space\n\nBox([-1.5       -1.5       -5.        -5.        -3.1415927 -5.\n -0.        -0.       ], [1.5       1.5       5.        5.        3.1415927 5.        1.\n 1.       ], (8,), float32)\n\n\n\nenv.observation_space.sample()\n\narray([ 0.26299486, -0.8300088 ,  3.0305617 , -1.0865942 ,  1.9163206 ,\n       -0.2580665 ,  0.5529532 ,  0.64002186], dtype=float32)\n\n\n- action_space\n\nenv.action_space\n\nDiscrete(4)\n\n\n\nenv.action_space.sample()\n\n1\n\n\n- env.reset()\n\ntype(env.reset())\n\ntuple\n\n\n\nenv.reset()[0]\n\narray([-0.00568256,  1.4154928 , -0.57559764,  0.203213  ,  0.00659147,\n        0.1303815 ,  0.        ,  0.        ], dtype=float32)\n\n\n\nenv.reset()[1]\n\n{}\n\n\nreset된 초기 상태, 시작점?\n\nstate, _ = env.reset()\nstate \n\narray([ 0.00335846,  1.4095061 ,  0.3401579 , -0.06285264, -0.00388481,\n       -0.07705088,  0.        ,  0.        ], dtype=float32)\n\n\n- env.render()\n\nenv.render().shape\n\n(400, 600, 3)\n\n\n\nplt.imshow(env.render())\n\n&lt;matplotlib.image.AxesImage at 0x7f0e26c19a60&gt;\n\n\n\n\n\n- env.step\nenv.step(0)의 입력은 action\n\nnext_state, reward, terminated, _, _ = env.step(0)\nnext_state, reward, terminated\n\n(array([ 0.00671701,  1.4075147 ,  0.3396984 , -0.08852121, -0.00769225,\n        -0.07615532,  0.        ,  0.        ], dtype=float32),\n -0.6954854601109162,\n False)\n\n\nterminated =&gt; 끝났는지 안 끝났는지~\n- play\n\nenv.reset()\nplt.imshow(env.render())\n\n&lt;matplotlib.image.AxesImage at 0x7f0e1f684f10&gt;\n\n\n\n\n\n\nfor _ in range(7):\n    env.step(3)\n    env.step(2)\nplt.imshow(env.render())\n\n&lt;matplotlib.image.AxesImage at 0x7f0e1f48d5e0&gt;\n\n\n\n\n\n자유낙하\n\nfor _ in range(7):\n    env.step(0)\nplt.imshow(env.render())\n\n&lt;matplotlib.image.AxesImage at 0x7f0e1f40d670&gt;\n\n\n\n\n\n왼쪽\n\nfor _ in range(7):\n    env.step(1)\nplt.imshow(env.render())\n\n&lt;matplotlib.image.AxesImage at 0x7f0e1f38a490&gt;\n\n\n\n\n\n위\n\nfor _ in range(7):\n    env.step(2)\nplt.imshow(env.render())\n\n&lt;matplotlib.image.AxesImage at 0x7f0e1f306370&gt;\n\n\n\n\n\n오른쪽\n\nfor _ in range(7):\n    env.step(3)\nplt.imshow(env.render())\n\n&lt;matplotlib.image.AxesImage at 0x7f0e1f27e7c0&gt;\n\n\n\n\n\n\n0 : 아무행동도 하지 않음\n1 : 왼쪽\n2 : 위\n3 : 오른쪽\n\n\n\n시각화\njump가 10인 것은 이미지 생략한 것일 뿐임\n\ndef show(ims,jump=10):\n    ims = ims[::jump]\n    fig = plt.Figure()\n    ax = fig.subplots()\n    def update(i):\n       ax.imshow(ims[i])\n    ani = FuncAnimation(fig,update,frames=len(ims))\n    display(IPython.display.HTML(ani.to_jshtml()))\n\n\ncurrent_state, _ = env.reset()\nims = [] \nfor t in range(500): \n    action = env.action_space.sample()\n    next_state, reward, terminated, _, _ = env.step(action)\n    im = env.render()\n    ims.append(im) \n    current_state = next_state \n    if terminated: break \n\n\nshow(ims) \n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nq_net\n- 원래는 agent.q 에 해당하는 것인데, 이전에서는 agent.q를 (4,4,4) shape의 numpy array 를 사용했는데 여기서는 불가능\n\n4x4 grid: 상태공간의 차원은 2차원이며 가질수 있는 값은 16개, 각 상태공간에서 할수 있는 행동이 4개 -&gt; 총 16*4의 경우의 수에 대한 reward만 조사하면 되었음\nLunarLander: 상태공간의 차원은 8차원이지만 가질수 있는 값의 범위는 무한대 -&gt; 무수히 많은 경우에 대한 reward 값을 조사하는건 현실적으로 불가능\n\n- 데이터를 모아보자.\n\ncurrent_states = collections.deque(maxlen=50) \nactions = collections.deque(maxlen=50) \nnext_states = collections.deque(maxlen=50) \nrewards = collections.deque(maxlen=50) \nterminations = collections.deque(maxlen=50) \n\ncurrent_state, _ = env.reset()\nfor t in range(500): \n    ## step1: agent &gt;&gt; env \n    action = env.action_space.sample()\n    ## step2:agent &lt;&lt; env \n    next_state, reward, terminated, _, _ = env.step(action)\n    current_states.append(current_state)\n    actions.append(action)\n    next_states.append(next_state)\n    rewards.append(reward)\n    terminations.append(terminated) \n    ## step3: learn \n    ## step4: update state     \n    current_state = next_state \n    ## step5: 종료조건체크 \n    if terminated: break \n\n- 이전코드에서 아래에 대응하는 부분을 구현하면 된다.\n## 1. q[x,y,a]를 초기화: q(s)를 넣으면 action에 대한 q값을 알려주는 기능 \nagent.q = np.zeros([4,4,4]) \n\n## 2. q_estimated 를 계산 \nx,y = agent.current_state\nxx,yy = agent.next_state\na = agent.action \nq_estimated = agent.q[x,y,a] \n\n## 3. q_realistic = agent.reward + 0.99 * q_future 를 수행하는 과정 \nif agent.terminated:\n    q_realistic = agent.reward\nelse:\n    q_future = q[xx,yy,:].max()\n    q_realistic = agent.reward + 0.99 * q_future\n\n## 4. q_estimated 를 점점 q_realistic 와 비슷하게 만드는 과정 \ndiff = q_realistic - q_estimated \nagent.q[x,y,a] = q_estimated + 0.05 * diff \n1. agent.q 에 대응하는 과정\n\nq_net = torch.nn.Sequential(\n    torch.nn.Linear(8,128),\n    torch.nn.ReLU(),\n    torch.nn.Linear(128,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,4)\n)\n\n\nq_net # &lt;- 8개의 숫자가 입력으로 오면 4개의 숫자를 리턴하는 함수 \n\nSequential(\n  (0): Linear(in_features=8, out_features=128, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=128, out_features=64, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=64, out_features=32, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=32, out_features=4, bias=True)\n)\n\n\n\nq_net(torch.tensor(current_state))\n\ntensor([ 0.2089,  0.0208, -0.0194,  0.1119], grad_fn=&lt;AddBackward0&gt;)\n\n\n\nq_net은 8개의 숫자가 입력으로 오면 4개의 숫자가 리턴되는 함수이다.\n해석을 하면 8개의 숫자는 state를 나타내는 숫자로 이해할 수 있고 4개의 숫자는 각 action에 대한 q값으로 해석할 수 있다.\n하지만 이 숫자가 합리적인건 아님 (아무숫자임)\nq_net의 특징: 고정된 함수가 아니고 데이터를 이용하여 점점 더 그럴듯한 숫자를 뱉어내도록 학습할 수 있는 함수이다. (뉴럴네트워크)\n\n1. agent.q 에 대응하는 과정 (배치버전)\n– get batch –\n\nbatch_size = 4 \nidx = np.random.randint(0,50,size=batch_size)\n\ncurrent_states_batch = torch.tensor(np.array(current_states))[idx].float()\nactions_batch = torch.tensor(np.array(actions))[idx].reshape(batch_size,-1) \nrewards_batch = torch.tensor(np.array(rewards))[idx].reshape(batch_size,-1).float()\nnext_states_batch = torch.tensor(np.array(next_states))[idx].float()\nterminations_batch = torch.tensor(np.array(terminations))[idx].reshape(batch_size,-1)\n\n자료형 float64를 float 32로 바꿔주자, 64가 더 자세히 표현 가능함\n– q_net –\n\ncurrent_states_batch\n\ntensor([[ 0.0460,  1.1553,  0.2655, -0.7388, -0.1076, -0.1409,  0.0000,  0.0000],\n        [ 0.1101,  0.7167,  0.3612, -1.0887, -0.2963, -0.2328,  0.0000,  0.0000],\n        [ 0.1986,  0.0916,  0.4388, -1.4444, -0.4664, -0.0699,  0.0000,  0.0000],\n        [ 0.1560,  0.3964,  0.4360, -1.2567, -0.4123, -0.1800,  0.0000,  0.0000]])\n\n\n\nq_net(current_states_batch)\n\ntensor([[ 0.1819, -0.0285,  0.0155,  0.0395],\n        [ 0.1837, -0.0370,  0.0174,  0.0401],\n        [ 0.1934, -0.0340,  0.0255,  0.0449],\n        [ 0.1874, -0.0365,  0.0215,  0.0408]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n2. q_estimated\n\nq_net(current_states_batch), actions_batch\n\n(tensor([[ 0.1819, -0.0285,  0.0155,  0.0395],\n         [ 0.1837, -0.0370,  0.0174,  0.0401],\n         [ 0.1934, -0.0340,  0.0255,  0.0449],\n         [ 0.1874, -0.0365,  0.0215,  0.0408]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[0],\n         [1],\n         [1],\n         [1]]))\n\n\n\nq_net(current_states_batch).gather(1,actions_batch)\n\ntensor([[ 0.1819],\n        [-0.0370],\n        [-0.0340],\n        [-0.0365]], grad_fn=&lt;GatherBackward0&gt;)\n\n\naction에 맞는 거 뽑아주는 기능 gather\n3. q_realistic = agent.reward + 0.99 * q_future\n– q_future –\n\nq_future = q_net(next_states_batch).max(axis=1)[0].reshape(batch_size,1)\nq_future\n\ntensor([[0.1820],\n        [0.1842],\n        [0.1942],\n        [0.1883]], grad_fn=&lt;ReshapeAliasBackward0&gt;)\n\n\n\nq_realistic = rewards_batch + 0.99 * q_future * (~terminations_batch)\n\n~~terminations_batch 1-를 뒤집는 역할\n4. q_estimated 를 점점 q_realistic 와 비슷하게 만드는 과정\n## 여기는.. 딥러닝과 파이토치를 좀 알아야.. 모른다면 일단 패스해야합니다.. \noptimizer = torch.optim.Adam(q_net.parameters(),lr=0.0001) \nfor _ in range(2000):\n    ~~~\n    ~~~\n    q_estimated = ~~~ \n    q_realistic = ~~~ \n    loss = torch.nn.functional.mse_loss(q_estimated,q_realistic)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n\npolicy\n\neps = 0.5 \nif np.random.rand() &lt; eps:\n    action = env.action_space.sample() \nelse:\n    action = q_net(torch.tensor(current_state)).argmax().item()\n\ntensor에서 수만 나오게 하는 item()\n\naction\n\n0\n\n\n\n\nAgent 클래스 + run\n\nclass Agent():\n    def __init__(self,env):\n        self.eps = 0\n        self.n_experiences = 0\n        self.n_episode = 0\n        self.score = 0\n        self.scores = []\n        self.playtimes = []\n        self.batch_size = 64\n        self.buffer_size = 5000 \n        self.action_space = env.action_space\n        #self.state_space = env.observation_space\n\n        # Q-Network\n        self.q_net = torch.nn.Sequential(\n            torch.nn.Linear(8,128), \n            torch.nn.ReLU(),\n            torch.nn.Linear(128,64),\n            torch.nn.ReLU(),\n            torch.nn.Linear(64,32),\n            torch.nn.ReLU(),\n            torch.nn.Linear(32,4)\n        ) \n        self.optimizer = torch.optim.Adam(self.q_net.parameters(), lr=0.0001)\n\n        # ReplayBuffer\n        self.current_states = collections.deque(maxlen=self.buffer_size)\n        self.actions = collections.deque(maxlen=self.buffer_size)\n        self.rewards = collections.deque(maxlen=self.buffer_size)\n        self.next_states = collections.deque(maxlen=self.buffer_size)\n        self.terminations = collections.deque(maxlen=self.buffer_size)\n       \n    def save_experience(self):\n        \"\"\"Add a new experience to memory.\"\"\"\n        self.current_states.append(self.current_state)\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n        self.next_states.append(self.next_state)\n        self.terminations.append(self.terminated) \n        self.n_experiences = self.n_experiences+1\n        self.score += self.reward\n    \n    def act(self):\n        if np.random.rand() &lt; self.eps:\n            self.action = self.action_space.sample()\n        else:\n            self.action = self.q_net(torch.tensor(self.current_state)).argmax().item()\n            \n    def get_batch(self):\n        idx = np.random.randint(0,self.buffer_size,size=self.batch_size) \n        self.current_states_batch = torch.tensor(np.array(self.current_states))[idx].float()\n        self.actions_batch = torch.tensor(np.array(self.actions))[idx].reshape(self.batch_size,1)\n        self.rewards_batch = torch.tensor(np.array(self.rewards))[idx].reshape(self.batch_size,-1).float()\n        self.next_states_batch = torch.tensor(np.array(self.next_states))[idx].float()\n        self.terminations_batch = torch.tensor(np.array(self.terminations))[idx].reshape(self.batch_size,-1) \n    \n    def learn(self):\n        if self.n_experiences &lt; self.buffer_size:\n            pass\n        else: \n            self.get_batch()\n            q_estimated = self.q_net(self.current_states_batch).gather(1, self.actions_batch)\n            q_future = self.q_net(self.next_states_batch).detach().max(1)[0].reshape(self.batch_size,1)\n            q_realistic = self.rewards_batch + 0.99 * q_future * (~self.terminations_batch)\n\n            loss = torch.nn.functional.mse_loss(q_estimated, q_realistic)\n            loss.backward()\n            self.optimizer.step()\n            self.optimizer.zero_grad()\n\n\nenv = gym.make('LunarLander-v2',render_mode='rgb_array')\nagent = Agent(env)\nagent.eps = 1.0 \nfor _ in range(2000):\n    ### 1. 본질적인 코드\n    agent.current_state, _  = env.reset() \n    agent.terminated = False\n    agent.score = 0 \n    for t in range(500):\n        # step1: agent &gt;&gt; env \n        agent.act() \n        env.agent_action = agent.action  \n        # step2: agent &lt;&lt; env \n        agent.next_state, agent.reward, agent.terminated, _,_ = env.step(env.agent_action)\n        agent.save_experience() \n        # step3: learn \"\n        agent.learn()\n        # step4: state update \n        agent.current_state = agent.next_state \n        # step5: \n        if agent.terminated: break \n    agent.scores.append(agent.score) \n    agent.playtimes.append(t+1)\n    agent.n_episode = agent.n_episode + 1 \n    agent.eps = agent.eps*0.995\n    ## 2. 비본질적 코드\n    if (agent.n_episode % 10) == 0:\n        print(\n            f'Episode {agent.n_episode}\\t'\n            f'Score: {np.mean(agent.scores[-100:]) : .2f}\\t'\n            f'Playtime: {np.mean(agent.playtimes[-100:]) : .2f}\\t'\n            f'n_eps: {agent.eps}\\t'\n            f'n_experiences: {agent.n_experiences}\\t'\n        )\n    if np.mean(agent.scores[-100:])&gt;=200.0:\n        break\n\nEpisode 10  Score: -172.47  Playtime:  96.90    n_eps: 0.9511101304657719   n_experiences: 969  \nEpisode 20  Score: -169.88  Playtime:  100.10   n_eps: 0.9046104802746175   n_experiences: 2002 \nEpisode 30  Score: -183.41  Playtime:  98.43    n_eps: 0.8603841919146962   n_experiences: 2953 \nEpisode 40  Score: -206.50  Playtime:  101.62   n_eps: 0.8183201210226743   n_experiences: 4065 \nEpisode 50  Score: -219.56  Playtime:  103.06   n_eps: 0.778312557068642    n_experiences: 5153 \nEpisode 60  Score: -222.80  Playtime:  101.28   n_eps: 0.7402609576967045   n_experiences: 6077 \nEpisode 70  Score: -218.37  Playtime:  100.14   n_eps: 0.7040696960536299   n_experiences: 7010 \nEpisode 80  Score: -215.56  Playtime:  98.80    n_eps: 0.6696478204705644   n_experiences: 7904 \nEpisode 90  Score: -209.10  Playtime:  97.70    n_eps: 0.6369088258938781   n_experiences: 8793 \nEpisode 100 Score: -205.01  Playtime:  97.46    n_eps: 0.6057704364907278   n_experiences: 9746 \nEpisode 110 Score: -201.82  Playtime:  100.77   n_eps: 0.5761543988830038   n_experiences: 11046    \nEpisode 120 Score: -213.35  Playtime:  107.39   n_eps: 0.547986285490042    n_experiences: 12741    \nEpisode 130 Score: -211.61  Playtime:  110.09   n_eps: 0.5211953074858876   n_experiences: 13962    \nEpisode 140 Score: -196.57  Playtime:  114.99   n_eps: 0.49571413690105054  n_experiences: 15564    \nEpisode 150 Score: -180.50  Playtime:  117.85   n_eps: 0.47147873742168567  n_experiences: 16938    \nEpisode 160 Score: -189.93  Playtime:  126.25   n_eps: 0.4484282034609769   n_experiences: 18702    \n\n\n- 시각화를 위한코드\n\nagent2 = Agent(env) \nagent2.q_net = agent.q_net\n\nagent2.current_state, _ = env.reset()\nagent2.terminated = False \nims = [] \nims.append(env.render())\nfor t in range(500):\n    agent2.act() \n    agent2.next_state, agent2.reward, agent2.terminated, _, _  = env.step(agent2.action)\n    im = env.render()\n    ims.append(im)\n    agent2.current_state = agent2.next_state\n    if agent2.terminated: break \n\n\nshow(ims)"
  },
  {
    "objectID": "posts/as/index.html",
    "href": "posts/as/index.html",
    "title": "Special Topics in Applied Statistics",
    "section": "",
    "text": "Let’s study Special Topics in Applied Statistics."
  },
  {
    "objectID": "posts/ct/2023-01-30-Coding_Test_Q3.html",
    "href": "posts/ct/2023-01-30-Coding_Test_Q3.html",
    "title": "코딩 테스트 공부(Done)",
    "section": "",
    "text": "2022:KAKAO TECH INTERNSHIP\n\n문제 설명 [본 문제는 정확성과 효율성 테스트 각각 점수가 있는 문제입니다.]\n당신은 코딩 테스트를 준비하기 위해 공부하려고 합니다. 코딩 테스트 문제를 풀기 위해서는 알고리즘에 대한 지식과 코드를 구현하는 능력이 필요합니다.\n알고리즘에 대한 지식은 알고력, 코드를 구현하는 능력은 코딩력이라고 표현합니다. 알고력과 코딩력은 0 이상의 정수로 표현됩니다.\n문제를 풀기 위해서는 문제가 요구하는 일정 이상의 알고력과 코딩력이 필요합니다.\n예를 들어, 당신의 현재 알고력이 15, 코딩력이 10이라고 가정해보겠습니다.\nA라는 문제가 알고력 10, 코딩력 10을 요구한다면 A 문제를 풀 수 있습니다.\nB라는 문제가 알고력 10, 코딩력 20을 요구한다면 코딩력이 부족하기 때문에 B 문제를 풀 수 없습니다.\n풀 수 없는 문제를 해결하기 위해서는 알고력과 코딩력을 높여야 합니다. 알고력과 코딩력을 높이기 위한 다음과 같은 방법들이 있습니다.\n알고력을 높이기 위해 알고리즘 공부를 합니다. 알고력 1을 높이기 위해서 1의 시간이 필요합니다.\n코딩력을 높이기 위해 코딩 공부를 합니다. 코딩력 1을 높이기 위해서 1의 시간이 필요합니다.\n현재 풀 수 있는 문제 중 하나를 풀어 알고력과 코딩력을 높입니다. 각 문제마다 문제를 풀면 올라가는 알고력과 코딩력이 정해져 있습니다.\n문제를 하나 푸는 데는 문제가 요구하는 시간이 필요하며 같은 문제를 여러 번 푸는 것이 가능합니다.\n당신은 주어진 모든 문제들을 풀 수 있는 알고력과 코딩력을 얻는 최단시간을 구하려 합니다.\n초기의 알고력과 코딩력을 담은 정수 alp와 cop, 문제의 정보를 담은 2차원 정수 배열 problems가 매개변수로 주어졌을 때, 모든 문제들을 풀 수 있는 알고력과 코딩력을 얻는 최단시간을 return 하도록 solution 함수를 작성해주세요.\n모든 문제들을 1번 이상씩 풀 필요는 없습니다. 입출력 예 설명을 참고해주세요.\n제한사항\n초기의 알고력을 나타내는 alp와 초기의 코딩력을 나타내는 cop가 입력으로 주어집니다.\n\\(0 ≤ alp,cop ≤ 150\\), \\(1 ≤ problems의 길이 ≤ 100\\)\nproblems의 원소는 [alp_req, cop_req, alp_rwd, cop_rwd, cost]의 형태로 이루어져 있습니다.\nalp_req는 문제를 푸는데 필요한 알고력입니다.\n\\(0 ≤ alp_req ≤ 150\\)\ncop_req는 문제를 푸는데 필요한 코딩력입니다.\n\\(0 ≤ cop_req ≤ 150\\)\nalp_rwd는 문제를 풀었을 때 증가하는 알고력입니다.\n\\(0 ≤ alp_rwd ≤ 30\\)\ncop_rwd는 문제를 풀었을 때 증가하는 코딩력입니다.\n\\(0 ≤ cop_rwd ≤ 30\\)\ncost는 문제를 푸는데 드는 시간입니다.\n\\(1 ≤ cost ≤ 100\\)\n정확성 테스트 케이스 제한사항\n\\(0 ≤ alp,cop ≤ 20\\)\n\\(1 ≤ problems의 길이 ≤ 6\\)\n\\(0 ≤ alp_req,cop_req ≤ 20\\)\n\\(0 ≤ alp_rwd,cop_rwd ≤ 5\\)\n\\(1 ≤ cost ≤ 10\\)\n효율성 테스트 케이스 제한사항\n주어진 조건 외 추가 제한사항 없습니다.\n입출력 예\n\n\n\nalp\ncop\nproblems\nresult\n\n\n\n\n10\n10\n[[10,15,2,1,2],[20,20,3,3,4]]\n15\n\n\n0\n0\n[[0,0,2,1,2],[4,5,3,1,2],[4,11,4,0,2],[10,4,0,4,2]]\n13\n\n\n\n입출력 예 설명\n입출력 예 #1\n코딩력 5를 늘립니다. 알고력 10, 코딩력 15가 되며 시간이 5만큼 소요됩니다.\n1번 문제를 5번 풉니다. 알고력 20, 코딩력 20이 되며 시간이 10만큼 소요됩니다. 15의 시간을 소요하여 모든 문제를 풀 수 있는 알고력과 코딩력을 가질 수 있습니다.\n입출력 예 #2\n1번 문제를 2번 풉니다. 알고력 4, 코딩력 2가 되며 시간이 4만큼 소요됩니다.\n코딩력 3을 늘립니다. 알고력 4, 코딩력 5가 되며 시간이 3만큼 소요됩니다.\n2번 문제를 2번 풉니다. 알고력 10, 코딩력 7이 되며 시간이 4만큼 소요됩니다.\n4번 문제를 1번 풉니다. 알고력 10, 코딩력 11이 되며 시간이 2만큼 소요됩니다. 13의 시간을 소요하여 모든 문제를 풀 수 있는 알고력과 코딩력을 가질 수 있습니다.\n제한시간 안내\n정확성 테스트 : 10초\n효율성 테스트 : 언어별로 작성된 정답 코드의 실행 시간의 적정 배수\n\n동적 계획법(Dynamic Programming)\n이미 계산을 했지만, 그 출력 결과를 바탕으로 다시 계산이 됨.(ex. 피보나치 수열)\n\ntop-down\ndown-top\n\n두 가지 방식이 존재한다.\n\ndef solution(alp, cop, problems):\n    max_alp = 0\n    max_cop = 0\n    for alp_req, cop_req, alp_rwd, cop_rwd, cost in problems:\n        max_alp = max(max_alp,alp_req)\n        max_cop = max(max_cop,cop_req)\n    \n    dp = [[float('inf')] * (max_cop + 1) for _ in range(max_alp +1)]\n    \n    alp = min(alp,max_alp)\n    cop = min(cop,max_cop)\n    \n    dp[alp][cop] = 0\n    \n    for i in range(alp, max_alp + 1):\n        for j in range(cop,max_cop +1):\n            if i &lt; max_alp:\n                dp[i+1][j] = min(dp[i+1][j],dp[i][j]+1)\n            if j &lt; max_cop:\n                dp[i][j+1] = min(dp[i][j+1],dp[i][j]+1)\n            for alp_req, cop_req, alp_rwd, cop_rwd, cost in problems:\n                if i &gt;= alp_req and j &gt;= cop_req:\n                    alp_n = min(i + alp_rwd, max_alp)\n                    cop_n = min(j + cop_rwd, max_cop)\n                    dp[alp_n][cop_n] = min(dp[alp_n][cop_n],dp[i][j] + cost)\n                    \n    return dp[max_alp][max_cop]\n\n\nmax_alp = 0\nmax_cop = 0\n\n\nproblems = [[0,0,2,1,2],[4,5,3,1,2],[4,11,4,0,2],[10,4,0,4,2]]\n\n\nalp = 0\ncop = 0\n\n\nfor alp_req, cop_req, alp_rwd, cop_rwd, cost in problems:\n    max_alp = max(max_alp,alp_req)\n    max_cop = max(max_cop,cop_req)\n\n\nmax_alp,max_cop\n\n(10, 11)\n\n\n\ndp = [[float('inf')] * (max_cop + 1) for _ in range(max_alp +1)]\ndp\n\n[[inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]]\n\n\n\nalp = min(alp,max_alp)\ncop = min(cop,max_cop)\n\n\nalp,cop\n\n(0, 0)\n\n\n\ndp[alp][cop] = 0\n\n\ndp\n\n[[0, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]]\n\n\n\nfor i in range(alp, max_alp + 1):\n    for j in range(cop,max_cop +1):\n        if i &lt; max_alp:\n            dp[i+1][j] = min(dp[i+1][j],dp[i][j]+1)\n        if j &lt; max_cop:\n            dp[i][j+1] = min(dp[i][j+1],dp[i][j]+1)\n        for alp_req, cop_req, alp_rwd, cop_rwd, cost in problems:\n            if i &gt;= alp_req and j &gt;= cop_req:\n                alp_n = min(i + alp_rwd, max_alp)\n                cop_n = min(j + cop_rwd, max_cop)\n                dp[alp_n][cop_n] = min(dp[alp_n][cop_n],dp[i][j] + cost)\nreturn dp[max_alp][max_cop]"
  },
  {
    "objectID": "posts/ct/index.html",
    "href": "posts/ct/index.html",
    "title": "Coding Test",
    "section": "",
    "text": "Let’s prepare the coding test."
  },
  {
    "objectID": "posts/ct/2023-03-05-Coding_Test_Stack.html",
    "href": "posts/ct/2023-03-05-Coding_Test_Stack.html",
    "title": "Stack",
    "section": "",
    "text": "Stack"
  },
  {
    "objectID": "posts/ct/2023-03-05-Coding_Test_Stack.html#stack을-통해-사용하는-기능",
    "href": "posts/ct/2023-03-05-Coding_Test_Stack.html#stack을-통해-사용하는-기능",
    "title": "Stack",
    "section": "Stack을 통해 사용하는 기능",
    "text": "Stack을 통해 사용하는 기능\n\npush: 데이터를 스택에 추가한다.(스택의 하단부터 상단으로 차곡차곡 쌓는다.\npop: 스택의 최상단 데이터를 삭제한다.\ntop: 스택에 데이터가 몇 개 들어있는지 확인한다.\nsize: 스택에 데이터가 몇 개 들어있는지 확인한다.\nempty: 스택이 비어 있는지 확인한다.(데이터가 없는지 확인)"
  },
  {
    "objectID": "posts/ct/2023-03-05-Coding_Test_Stack.html#쇠막대기",
    "href": "posts/ct/2023-03-05-Coding_Test_Stack.html#쇠막대기",
    "title": "Stack",
    "section": "쇠막대기",
    "text": "쇠막대기\n여러 개의 쇠막대기를 레이저로 절단하려고 한다. 효율적인 작업을 위해서 쇠막대기를 아래에서 위로 겹쳐 놓고, 레이저를 위에서 수직으로 발사하여 쇠막대기들을 자른다. 쇠막대기와 레이저의 배치는 다음 조건을 만족한다.\n\n쇠막대기는 자신보다 긴 쇠막대기 위에만 놓일 수 있다.\n\n쇠막대기를 다른 쇠막대기 위에 놓는 경우 완전히 포함되도록 놓되, 끝점은 겹치지 않도록 놓는다.\n\n각 쇠막대기를 자르는 레이저는 적어도 하나 존재한다.\n레이저는 어떤 쇠막대기릐 양 끝점과도 겹치지 않는다.\n\n아래 그림은 위 조건을 만족하는 예를 보여준다. 수평으로 그려진 굵은 실선은 쇠막대기이고, 점은 레이저의 위치, 수직으로 그려진 점선 화살표는 레이저의 발사 방향이다.\n\n\n\nimage.png\n\n\n이러한 레이저와 쇠막대기의 배치는 다음과 같이 괄호를 이용하여 왼쪽부터 순서대로 표현할 수 있다.\n레이저는 여는 괄호와 닫는 괄호의 인접한 쌍 ‘( )’ 으로 표현된다. 또한, 모든 ‘( ) ’는 반드시 레이저를 표현한다. 쇠막대기의 왼쪽 끝은 여는 괄호 ‘ (’ 로, 오른쪽 끝은 닫힌 괄호 ‘)’ 로 표현된다. 위 예의 괄호 표현은 그림 위에 주어져 있다.\n쇠막대기는 레이저에 의해 몇 개의 조각으로 잘려지는데, 위 예에서 가장 위에 있는 두 개의 쇠막대기는 각각 3개와 2개의 조각으로 잘려지고, 이와 같은 방식으로 주어진 쇠막대기들은 총 17개의 조각으로 잘려진다.\n쇠막대기와 레이저의 배치를 나타내는 괄호 표현이 주어졌을때, 잘려진 쇠막대기 조각의 총 개수를 구하는 프로그램을 작성하시오."
  },
  {
    "objectID": "posts/ct/2023-03-05-Coding_Test_Stack.html#크게-만들기",
    "href": "posts/ct/2023-03-05-Coding_Test_Stack.html#크게-만들기",
    "title": "Stack",
    "section": "크게 만들기",
    "text": "크게 만들기\nN 자리 숫자가 주어졌을때, 여기서 숫자 K개를 얻을 수 있는 가장 큰 수를 구하는 프로그램을 작성하시오.\n- 맨 왼쪽에 있는 수가 가장 큰 수를 선택했을때 결과도 크겠지?\n- array보다는 stack으로 시간복잡도를 줄일 수 있다.\n\nn, k = map(int, input().split())\nnumber = list(input())\n\nanswer = []\ncnt = k\nfor num in number: \n    while answer and cnt&gt;0 and answer[-1] &lt;num: \n        # 만약 answer에 값이 있고 지울 수 있는 수 k가 남아있고, answer의 마지막 값이 num보다 작다면?\n        del answer[-1]\n        # answer 마지막 값 삭제하고\n        cnt-=1\n        # 지울 수 있는 k 수도 줄인다.\n    answer.append(num)\n    \nprint(''.join(answer[:n-k]))\n\n 4 2\n 1924\n\n\n94"
  },
  {
    "objectID": "posts/ct/2023-01-21-Coding_Test_Q1.html",
    "href": "posts/ct/2023-01-21-Coding_Test_Q1.html",
    "title": "성격 유형 검사하기(Done)",
    "section": "",
    "text": "2022:KAKAO TECH INTERNSHIP\n\n\n문제 설명\n나만의 카카오 성격 유형 검사지를 만들려고 합니다.\n성격 유형 검사는 다음과 같은 4개 지표로 성격 유형을 구분합니다. 성격은 각 지표에서 두 유형 중 하나로 결정됩니다.\n\n\n\n지표 번호\n성격 유형\n\n\n\n\n1번 지표\n라이언형(R), 튜브형(T)\n\n\n2번 지표\n콘형(C), 프로도형(F)\n\n\n3번 지표\n제이지형(J), 무지형(M)\n\n\n4번 지표\n어피치형(A), 네오형(N)\n\n\n\n4개의 지표가 있으므로 성격 유형은 총 16(=2 x 2 x 2 x 2)가지가 나올 수 있습니다. 예를 들어, “RFMN”이나 “TCMA”와 같은 성격 유형이 있습니다.\n검사지에는 총 n개의 질문이 있고, 각 질문에는 아래와 같은 7개의 선택지가 있습니다.\n\n\n\n매우 비동의\n\n\n\n\n비동의\n\n\n약간 비동의\n\n\n모르겠음\n\n\n약간 동의\n\n\n동의\n\n\n매우 동의\n\n\n\n각 질문은 1가지 지표로 성격 유형 점수를 판단합니다.\n예를 들어, 어떤 한 질문에서 4번 지표로 아래 표처럼 점수를 매길 수 있습니다.\n\n\n\n선택지\n성격 유형 점수\n\n\n\n\n매우 비동의\n네오형 3점\n\n\n비동의\n네오형 2점\n\n\n약간 비동의\n네오형 1점\n\n\n모르겠음\n어떤 성격 유형도 점수를 얻지 않습니다\n\n\n약간 동의\n어피치형 1점\n\n\n동의\n어피치형 2점\n\n\n매우 동의\n어피치형 3점\n\n\n\n이때 검사자가 질문에서 약간 동의 선택지를 선택할 경우 어피치형(A) 성격 유형 1점을 받게 됩니다. 만약 검사자가 매우 비동의 선택지를 선택할 경우 네오형(N) 성격 유형 3점을 받게 됩니다.\n위 예시처럼 네오형이 비동의, 어피치형이 동의인 경우만 주어지지 않고, 질문에 따라 네오형이 동의, 어피치형이 비동의인 경우도 주어질 수 있습니다.\n하지만 각 선택지는 고정적인 크기의 점수를 가지고 있습니다.\n\n매우 동의나 매우 비동의 선택지를 선택하면 3점을 얻습니다.\n동의나 비동의 선택지를 선택하면 2점을 얻습니다.\n약간 동의나 약간 비동의 선택지를 선택하면 1점을 얻습니다.\n모르겠음 선택지를 선택하면 점수를 얻지 않습니다.\n\n검사 결과는 모든 질문의 성격 유형 점수를 더하여 각 지표에서 더 높은 점수를 받은 성격 유형이 검사자의 성격 유형이라고 판단합니다. 단, 하나의 지표에서 각 성격 유형 점수가 같으면, 두 성격 유형 중 사전 순으로 빠른 성격 유형을 검사자의 성격 유형이라고 판단합니다.\n질문마다 판단하는 지표를 담은 1차원 문자열 배열 survey와 검사자가 각 질문마다 선택한 선택지를 담은 1차원 정수 배열 choices가 매개변수로 주어집니다. 이때, 검사자의 성격 유형 검사 결과를 지표 번호 순서대로 return 하도록 solution 함수를 완성해주세요.\n제한사항\n\n1 ≤ survey의 길이 ( = n) ≤ 1,000\nsurvey의 원소는 “RT”, “TR”, “FC”, “CF”, “MJ”, “JM”, “AN”, “NA” 중 하나입니다.\nsurvey[i]의 첫 번째 캐릭터는 i+1번 질문의 비동의 관련 선택지를 선택하면 받는 성격 유형을 의미합니다.\nsurvey[i]의 두 번째 캐릭터는 i+1번 질문의 동의 관련 선택지를 선택하면 받는 성격 유형을 의미합니다.\nchoices의 길이 = survey의 길이\n\nchoices[i]는 검사자가 선택한 i+1번째 질문의 선택지를 의미합니다.\n\n1 ≤ choices의 원소 ≤ 7\n\n\n\n\nchoices\n뜻\n\n\n\n\n1\n매우 비동의\n\n\n2\n비동의\n\n\n3\n약간 비동의\n\n\n4\n모르겠음\n\n\n5\n약간 동의\n\n\n6\n동의\n\n\n7\n매우 동의\n\n\n\n입출력 예\n\n\n\nsurvey\nchoices\nresult\n\n\n\n\n[“AN”, “CF”, “MJ”, “RT”, “NA”]\n[5, 3, 2, 7, 5]\n“TCMA”\n\n\n[“TR”, “RT”, “TR”]\n[7, 1, 3]\n“RCJA”\n\n\n\nanswer\n\ndef solution(survey, choices):\n    answer = ''\n    a = {'R':0,'T':0,'F':0,'C':0,'M':0,'J':0,'N':0,'A':0}\n    \n    for i in range(len(survey)):\n        if choices[i] &lt; 4:\n            if choices[i] == 1:\n                a[survey[i][0]] = a[survey[i][0]] + 3\n            elif choices[i] == 2:\n                a[survey[i][0]] = a[survey[i][0]] + 2\n            elif choices[i] == 3:\n                a[survey[i][0]] = a[survey[i][0]] + 1\n        if choices[i] &gt; 4:\n            if choices[i] == 5:\n                a[survey[i][1]] = a[survey[i][1]] + 1\n            elif choices[i] == 6:\n                a[survey[i][1]] = a[survey[i][1]] + 2\n            elif choices[i] == 7:\n                a[survey[i][1]] = a[survey[i][1]] + 3\n                \n    # for i in range(len(choices)):\n    #     if choices[i] &gt; 4:\n    #         choices[i] = choices[i] - 4\n\n    if a['T']&gt;a['R']:\n        answer += 'T'\n    else: answer += 'R'\n        \n    if a['F']&gt;a['C']:\n        answer += 'F'\n    else: answer += 'C'\n        \n    if a['M']&gt;a['J']:\n        answer += 'M'\n    else: answer += 'J'\n        \n    if a['N']&gt;a['A']:\n        answer += 'N'\n    else: answer += 'A'\n    \n    return answer\n\n\nsolution([\"AN\", \"CF\", \"MJ\", \"RT\", \"NA\"],[5, 3, 2, 7, 5])\n\n'TCMA'\n\n\n\nsolution([\"TR\", \"RT\", \"TR\"],[7,1,3])\n\n'RCJA'"
  },
  {
    "objectID": "posts/ct/2023-01-15-Coding_Test_interfunction.html",
    "href": "posts/ct/2023-01-15-Coding_Test_interfunction.html",
    "title": "내장함수",
    "section": "",
    "text": "주요 라이브러리 문법"
  },
  {
    "objectID": "posts/ct/2023-01-15-Coding_Test_interfunction.html#sum",
    "href": "posts/ct/2023-01-15-Coding_Test_interfunction.html#sum",
    "title": "내장함수",
    "section": "sum",
    "text": "sum\n\nsum([1,2])\n\n3"
  },
  {
    "objectID": "posts/ct/2023-01-15-Coding_Test_interfunction.html#min",
    "href": "posts/ct/2023-01-15-Coding_Test_interfunction.html#min",
    "title": "내장함수",
    "section": "min",
    "text": "min\n\nmin([14,5,6,0,3])\n\n0"
  },
  {
    "objectID": "posts/ct/2023-01-15-Coding_Test_interfunction.html#max",
    "href": "posts/ct/2023-01-15-Coding_Test_interfunction.html#max",
    "title": "내장함수",
    "section": "max",
    "text": "max\n\nmax(1,3,6,3,33)\n\n33"
  },
  {
    "objectID": "posts/ct/2023-01-15-Coding_Test_interfunction.html#eval",
    "href": "posts/ct/2023-01-15-Coding_Test_interfunction.html#eval",
    "title": "내장함수",
    "section": "eval",
    "text": "eval\n수학 수식이 문자열 형식으로 들어오면 해당 수식을 계산한 결과를 반환\n\neval(\"3+4\")\n\n7\n\n\n\neval(\"3*4\")\n\n12"
  },
  {
    "objectID": "posts/ct/2023-01-15-Coding_Test_interfunction.html#sorted",
    "href": "posts/ct/2023-01-15-Coding_Test_interfunction.html#sorted",
    "title": "내장함수",
    "section": "sorted",
    "text": "sorted\n\nsorted([1,2,3,2,3])\n\n[1, 2, 2, 3, 3]\n\n\n\nsorted([1,2,3,2,3],reverse=True)\n\n[3, 3, 2, 2, 1]\n\n\n\\(\\star\\) List 형식이어야 함\n\nsorted(1,2,3,2,3)\n\nTypeError: sorted expected 1 argument, got 5\n\n\ngroup 가능\n\nsorted([('a',3),('b',4)],reverse=True)\n\n[('b', 4), ('a', 3)]\n\n\n사실 list 는 iterable 객체라 기본으로 sort()함수 가지고 있음\n\na = [4,1,3,4]\na.sort()\nprint(a)\n\n[1, 3, 4, 4]"
  },
  {
    "objectID": "posts/ct/2023-01-15-Coding_Test_interfunction.html#itertools",
    "href": "posts/ct/2023-01-15-Coding_Test_interfunction.html#itertools",
    "title": "내장함수",
    "section": "itertools",
    "text": "itertools\n\npermutations 순열(중복 허용하지 않음)\n\nfrom itertools import permutations\n\ndata = [1,3,5]\n\nresult = list(permutations(data,3))\n\nprint(result)\n\n[(1, 3, 5), (1, 5, 3), (3, 1, 5), (3, 5, 1), (5, 1, 3), (5, 3, 1)]\n\n\n\n\ncombinations 조합(중복 허용하지 않음)\n\nfrom itertools import combinations\n\ndata = ['a','r','t','e']\nresult = list(combinations(data,2))\n\nprint(result)\n\n[('a', 'r'), ('a', 't'), ('a', 'e'), ('r', 't'), ('r', 'e'), ('t', 'e')]\n\n\n\n\nproduct 순열(중복 허용)\n\nfrom itertools import product\n\ndata = [1,3,5]\n\nresult = list(product(data,repeat=3))\n\nprint(result)\n\n[(1, 1, 1), (1, 1, 3), (1, 1, 5), (1, 3, 1), (1, 3, 3), (1, 3, 5), (1, 5, 1), (1, 5, 3), (1, 5, 5), (3, 1, 1), (3, 1, 3), (3, 1, 5), (3, 3, 1), (3, 3, 3), (3, 3, 5), (3, 5, 1), (3, 5, 3), (3, 5, 5), (5, 1, 1), (5, 1, 3), (5, 1, 5), (5, 3, 1), (5, 3, 3), (5, 3, 5), (5, 5, 1), (5, 5, 3), (5, 5, 5)]\n\n\n\n\ncombinations_with_replacement(중복 허용)\n\nfrom itertools import combinations_with_replacement\n\ndata = ['a','r','t','e']\nresult = list(combinations_with_replacement(data,2))\n\nprint(result)\n\n[('a', 'a'), ('a', 'r'), ('a', 't'), ('a', 'e'), ('r', 'r'), ('r', 't'), ('r', 'e'), ('t', 't'), ('t', 'e'), ('e', 'e')]"
  },
  {
    "objectID": "posts/ct/2023-01-15-Coding_Test_interfunction.html#heapq",
    "href": "posts/ct/2023-01-15-Coding_Test_interfunction.html#heapq",
    "title": "내장함수",
    "section": "heapq",
    "text": "heapq\n다익스트라 최단 경로 알고리즘을 포함해 다양한 알고리즘에서 우선순위 큐 기능을 구현하고자 할 때 사용\n\nimport heapq\n\ndef heapsort(iterable):\n    h = []\n    result = []\n    for value in iterable:\n        heapq.heappush(h,value)\n    for _ in range(len(h)):\n        result.append(heapq.heappop(h))\n    return result\n    \nresult = heapsort([1,4,5,6,2,2,77,3,25])\nprint(result)\n\n[1, 2, 2, 3, 4, 5, 6, 25, 77]\n\n\n\na = []\nheapq.heappush(a,5)\n\n\na\n\n[5]\n\n\n\nheapq.heappush(a,3)\na\n\n[3, 5]\n\n\n\nheapq.heappush(a,2)\na\n\n[2, 5, 3]\n\n\n\nheapq.heappop(a)\n\n2\n\n\n\nmax heap\n\nimport heapq\n\ndef heapsort(iterable):\n    h = []\n    result = []\n    for value in iterable:\n        heapq.heappush(h,-value)\n    for _ in range(len(h)):\n        result.append(-heapq.heappop(h))\n    return result\n    \nresult = heapsort([1,4,5,6,2,2,77,3,25])\nprint(result)\n\n[77, 25, 6, 5, 4, 3, 2, 2, 1]\n\n\n\na = []\nheapq.heappush(a,-5)\n\n\na\n\n[-5]\n\n\n\nheapq.heappush(a,-3)\na\n\n[-5, -3]\n\n\n\nheapq.heappush(a,-2)\na\n\n[-5, -3, -2]\n\n\n\n-heapq.heappop(a)\n\n5"
  },
  {
    "objectID": "posts/ct/2023-01-15-Coding_Test_interfunction.html#bisect",
    "href": "posts/ct/2023-01-15-Coding_Test_interfunction.html#bisect",
    "title": "내장함수",
    "section": "bisect",
    "text": "bisect\n이진 탐색 구현\n\n정렬된 상태여야 함\n\n\nbisect_left(a,x)\n정렬된 순서를 유지하면서 리스트 a에 데이터 x를 삽입할 가장 왼쪽 인덱스를 찾는 메서드\n\n\nbisect_right(a,x)\n정렬된 순서를 유지하면서 리스트 a에 데이터 x를 삽입할 가장 오른쪽 인덱스를 찾는 메서드\n\nfrom bisect import bisect_left, bisect_right\n\na = [1,2,5,6,33,3]\nx = 3\nb = sorted(a)\nprint(b)\nprint(bisect_left(b,x))\nprint(bisect_right(b,x))\n\n[1, 2, 3, 5, 6, 33]\n2\n3\n\n\n\nfrom bisect import bisect_left, bisect_right\n\ndef count_by_range(a,left_value,right_value):\n    right_index = bisect_right(a,right_value)\n    left_index = bisect_left(a,left_value)\n    return right_index - left_index\n\na = [1,4,5,7,5,3,6,7,9,99,2,22]\nb = sorted(a)\n\nprint(count_by_range(b,5,5))\n\nprint(count_by_range(b,-1,3))\n\n2\n3"
  },
  {
    "objectID": "posts/ct/2023-01-15-Coding_Test_interfunction.html#collections",
    "href": "posts/ct/2023-01-15-Coding_Test_interfunction.html#collections",
    "title": "내장함수",
    "section": "collections",
    "text": "collections\n\ndeque\n\nfrom collections import deque\n\ndata = deque([2,5,4,6,3])\ndata.appendleft(3)\ndata.append(1)\n\nprint(data)\n\nprint(list(data))\n\ndeque([3, 2, 5, 4, 6, 3, 1])\n[3, 2, 5, 4, 6, 3, 1]\n\n\n\ndata.pop()\n\n1\n\n\n\ndata\n\ndeque([3, 2, 5, 4, 6, 3])\n\n\n\ndata.popleft()\n\n3\n\n\n\ndata\n\ndeque([2, 5, 4, 6, 3])\n\n\n\n\nCounter\n등장 횟수 세는 기능\n\nfrom collections import Counter\n\ncounter = Counter(['d','d','d','a','e','q','d'])\n\nprint(counter['d'])\nprint(counter['a'])\nprint(dict(counter),\"\\n사전자료형으로 반환\")\n\n4\n1\n{'d': 4, 'a': 1, 'e': 1, 'q': 1} \n사전자료형으로 반환\n\n\n\ncounter\n\nCounter({'d': 4, 'a': 1, 'e': 1, 'q': 1})"
  },
  {
    "objectID": "posts/ct/2023-01-15-Coding_Test_interfunction.html#math",
    "href": "posts/ct/2023-01-15-Coding_Test_interfunction.html#math",
    "title": "내장함수",
    "section": "math",
    "text": "math\n\nimport math\nprint(math.factorial(4))\n\n24\n\n\n\n4*3*2*1\n\n24\n\n\n\nimport math\nprint(math.sqrt(25))\n\n5.0\n\n\n최대 공약수\n\nimport math\nprint(math.gcd(30,25))\n\n5\n\n\n\nimport math\nprint(math.pi)\nprint(math.e)\n\n3.141592653589793\n2.718281828459045"
  },
  {
    "objectID": "posts/ct/2023-02-12-Coding_Test.html",
    "href": "posts/ct/2023-02-12-Coding_Test.html",
    "title": "ArrayList & LinkedList",
    "section": "",
    "text": "ArrayList & LinkedList"
  },
  {
    "objectID": "posts/ct/2023-02-12-Coding_Test.html#max-min",
    "href": "posts/ct/2023-02-12-Coding_Test.html#max-min",
    "title": "ArrayList & LinkedList",
    "section": "max & min",
    "text": "max & min\n\nn = input(list())\n\n[] \n\n\n\narray_list = list(map(int,input().split()))\n\n 20 10 35 30 7\n\n\n\nmax_num = array_list[0]\nmin_num = array_list[0]\n\n\nfor num in array_list:\n    if num &gt; max_num:\n        max_num = num\n    if num &lt; min_num:\n        min_num = num\n\n\nprint(min_num,max_num)\n\n7 35"
  },
  {
    "objectID": "posts/ct/2023-02-12-Coding_Test.html#dimension-arraylist",
    "href": "posts/ct/2023-02-12-Coding_Test.html#dimension-arraylist",
    "title": "ArrayList & LinkedList",
    "section": "2 dimension arraylist",
    "text": "2 dimension arraylist\n\nhuman = [list(map(int,input().split())) for _ in range(5)]\n\n 5 4 4 5\n 5 4 4 4 \n 5 5 4 4 \n 5 5 5 4\n 4 4 4 5\n\n\n\nhumanscore = [0]*5\n\n\nscore = 0\n\n\nfor i in range(5):\n    sum = 0\n    for j in range(4):\n        sum += human[i][j]\n    humanscore[i] = sum\n    score = max(score,sum)\n\n\nhumanscore\n\n[18, 17, 18, 19, 17]\n\n\n\nscore\n\n19\n\n\n\nfor i in range(5):\n    if humanscore[i] == score:\n        print(i+1,score)\n        break\n\n4 19\n\n\n\\(\\star\\) 0 부터 시작하니까 1 더해주기"
  },
  {
    "objectID": "posts/ct/2023-02-12-Coding_Test.html#add-delete",
    "href": "posts/ct/2023-02-12-Coding_Test.html#add-delete",
    "title": "ArrayList & LinkedList",
    "section": "add & delete",
    "text": "add & delete\n삽입과 삭제가 많은 문제를 접랬을때는 ArrayList 사용하게 되면 시간복잡도가 높아진다.\n따라서 스택을 이용하는 게 적절하다. 다른 장에 추가 서술 예정"
  },
  {
    "objectID": "posts/ts/index.html",
    "href": "posts/ts/index.html",
    "title": "Theoritical Statistics",
    "section": "",
    "text": "Those are posts of Theoritical Statistics.\n[참고(https://seoyeonc.github.io/chch/theoritical%20statistics/2022/04/17/ts-3%EC%9E%A5%EA%B3%BC%EC%A0%9C.html)"
  },
  {
    "objectID": "posts/ts/2022-12-31-ts_1.html",
    "href": "posts/ts/2022-12-31-ts_1.html",
    "title": "확률변수와 확률분포",
    "section": "",
    "text": "확률변수와 확률분포"
  },
  {
    "objectID": "posts/ts/2022-12-31-ts_1.html#확률",
    "href": "posts/ts/2022-12-31-ts_1.html#확률",
    "title": "확률변수와 확률분포",
    "section": "확률",
    "text": "확률\n\n표본공간; 모든 관찰 가능한 조합\n사건; 표본 공간의 부분 집합\n확률의 공리적 정의\n\n\\(P(S) = 1\\), 사건이 일어날 확률은 1\n\\(0&lt;P(A)&lt;1\\), 표본공간 안에서 사건 A의 확률은 0과 1 사이\n\\(A_1,A_2, \\dots\\)사건들 중 임의의 두 사건을 뽑았을 때, 공집합 이어야 함 \\(\\to\\) 상호배반\n\n\\(P(A_i \\cap A_j) = \\varnothing\\)\n\\(P(\\sum A) = \\sum P(A)\\)\n\n\n\nExample\n\n동전 3회 던지는 실험\n\n\\(S\\{ (H,H), (H,T), (T,H), (T,T) \\}\\) \\(\\to\\) 배반사건\n\n\\(P((H,H)) = \\frac{1}{9}\\)\n\\(P((H,T)) = \\frac{2}{9}\\)\n\\(P((T,H)) = \\frac{2}{9}\\)\n\\(P((T,T)) = \\frac{4}{9}\\)\n\n\\(P(S) = 1\\)\n\\(P(\\sum A_i) = \\sum P(A_i)\\)\n\n어떤 기계의 수명시간 측정"
  },
  {
    "objectID": "posts/ts/2022-12-31-ts_1.html#확률변수",
    "href": "posts/ts/2022-12-31-ts_1.html#확률변수",
    "title": "확률변수와 확률분포",
    "section": "확률변수",
    "text": "확률변수\n확률변수 : 표본공간 S에 정의된 실수값을 가지는 합수(real-valued function), X 영문 대문자\n\n사건을 수치화, 실험 결과에 따라 변하는 변수\n사건의 가능성을 확률적으로 결정\n확률밀도함수 = 확률질량함수\n\\(P(X = x)\\)라는 사건을 가징 확률 \\(P(X=x)\\)는 \\(f(x)\\)에 속해 있다.\n\n이산형\n\n\\(f(1) = P(X = 1)\\)\n\n연속형\n\n\\(f(1)\\) 이렇게 나타낼 수는 없지만, 넓이로 표현; 사건을 구간으로 표현\n\n\\(\\star\\) 확률변수는 대문자로, 관측값은 소문자로 표현"
  },
  {
    "objectID": "posts/ts/2022-12-31-ts_1.html#확률밀도함수-및-확률분포함수",
    "href": "posts/ts/2022-12-31-ts_1.html#확률밀도함수-및-확률분포함수",
    "title": "확률변수와 확률분포",
    "section": "확률밀도함수 및 확률분포함수",
    "text": "확률밀도함수 및 확률분포함수\n확률밀도함수(probablity density function) - \\(f(x)\\)\n확률분포함수(probablity distribution function) - \\(F(x)\\)\n확률변수의 분포형태를 나타내는 데 사용\n이산형 확률변수의 확률밀도함수\n다음 조건 만족\n\n모든 실수 \\(x\\)애 대하여 \\(f(x) \\ge 0\\)\n확률변수가 가질 수 있는 값 \\(x_1, x_2, \\dots\\)에 대하여\n\n\\(f(x_i) &gt; 0, \\sum_{all x_i} f(x_i) = 1\\)\n\n확률질량함수(probablity mass function)으로 부르기도 함\n\\(f(x) = P(X = x)\\)\n\n연속형 확률변수의 확률밀도함수\n\n셀 수 없이 무한히 많은 가능한 값 하나하나에 확률을 부여하지 않고 구간에 확률 부여, 즉 \\(P(X=x)=0\\)\n\n다음 조건 만족\n\n모든 실수 \\(x\\)에 대하여 \\(f(x) \\ge 0\\)\n\\(\\int_{-\\inf}^\\inf f(x) dx = 1\\)\n\n\\(P(a \\le X \\le b) = \\int_a^b f(x) dx\\)\n\\[P(X \\in A) = \\begin{cases} \\sum_{x_i \\in A} f(x_i) & \\text{discrete  } X \\\\ \\int_A f(x) dx & \\text{continuous  } X \\end{cases}\\]\nExample\n구간 (0,3)에서 정의된 함수\n\n\\(f(x) = \\frac{x^2}{9}\\)\n\n\\(\\frac{x^2}{9} \\ge 0\\)\n\\(\\int_0^3 \\frac{x^2}{9} dx = \\frac{1}{9} \\begin{bmatrix} \\frac{x^2}{3} \\end{bmatrix}^3_0 = 1\\)\n\n\n\\(\\therefore\\) 확률밀도함수가 맞다.\n(누적)분포함수(cumulative distribution function): 확률변수 \\(X\\)가 주어진 점 \\(x\\) 이하인 값을 가질 확률 \\[F(x) = P(X \\le x)\\]\n참고\n\n\\(X \\sim f(x)\\) : 확률변수 \\(X\\)가 확률밀도함수 \\(f(x)\\)를 가짐\n\\(X \\sim F(x)\\) : 확률변수 \\(X\\)가 확률분포함수 \\(F(x)\\)를 가짐\n\n\\[F(x) = \\begin{cases} \\sum_{x_i \\le x} f(x_i) & \\text{discrete  } X \\\\ \\int_{-\\inf}^x f(t)dt & \\text{continuous  } X \\end{cases}\\]\n확률뷴포함수의 성질\n함수 \\(F(x)\\)가 어떤 확률변수 \\(X\\)의 누적분포함수가 되는 필요충분조건\n\n\\(lim_{x \\to -\\inf} F(x) = 0\\)\n\\(lim_{x \\to \\inf} F(x) = 1\\)\n\\(lim_{h \\to 0+} F(x+h) = F(x)\\)\n\\(a &lt; b\\)이면 \\(F(a) \\le F(b)\\)\n\n\\[P(a &lt; X \\le b) = F(b) - F(a)\\]\n\\(\\star\\) 연속형이라면? 각 점에서 확률이 0이니까\n\n\\(P(a \\le X \\le b) = P(a \\le X &lt; b) = P(a&lt; X \\le b) = P(a&lt; X &lt; b)\\)\n\n\\(\\star\\) 이산형이라면?\n\nprobability density function 미분하면 step function 을 가지는 probability distribution function\n\nExample\n앞면 나올 확률이 \\(\\frac{1}{2}\\)인 동전 3회 던지는 실험에서 관심있는 변수 \\(X\\) = 앞면의 수일때 \\(f(x)\\)와 \\(F(x)\\)는?\n\n각각 독립이다.\n\\(f(3) = P(X = 3) = P(A)P(B)P(C) = \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{8}\\)\n\\(f(2) = P(X = 2) = P(A)P(B)P(C) = \\frac{1}{8} \\times 3\\)\n\\(f(1) = P(X = 1) = P(A)P(B)P(C) = \\frac{1}{8} \\times 3\\)\n\\(f(0) = P(X = 0) = P(A)P(B)P(C) = \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{8}\\)\n\\(f(3) + f(2) + f(1) + f(0) = 1\\)"
  },
  {
    "objectID": "posts/ts/2023-03-03-graduation_test.html",
    "href": "posts/ts/2023-03-03-graduation_test.html",
    "title": "Theoritical Statistics GT",
    "section": "",
    "text": "GT"
  },
  {
    "objectID": "posts/ts/2023-03-03-graduation_test.html#a",
    "href": "posts/ts/2023-03-03-graduation_test.html#a",
    "title": "Theoritical Statistics GT",
    "section": "(a)",
    "text": "(a)\n이 랜덤표본의 결합확률밀도함수를 기술하시오."
  },
  {
    "objectID": "posts/ts/2023-03-03-graduation_test.html#b",
    "href": "posts/ts/2023-03-03-graduation_test.html#b",
    "title": "Theoritical Statistics GT",
    "section": "(b)",
    "text": "(b)\n\\(p(1-p)\\)에 대한 최대가능도추정량을 구하시오."
  },
  {
    "objectID": "posts/ts/2023-03-03-graduation_test.html#c",
    "href": "posts/ts/2023-03-03-graduation_test.html#c",
    "title": "Theoritical Statistics GT",
    "section": "(c)",
    "text": "(c)\n\\(X_1(1-X_2)\\)의 기댓값을 구하시오."
  },
  {
    "objectID": "posts/ts/2023-03-03-graduation_test.html#d",
    "href": "posts/ts/2023-03-03-graduation_test.html#d",
    "title": "Theoritical Statistics GT",
    "section": "(d)",
    "text": "(d)\n\\(E[X_1(1-X_2)|\\sum^n_{i=1} X_i = t]\\)을 구하시오."
  },
  {
    "objectID": "posts/ts/2023-03-03-graduation_test.html#e",
    "href": "posts/ts/2023-03-03-graduation_test.html#e",
    "title": "Theoritical Statistics GT",
    "section": "(e)",
    "text": "(e)\n\\(p=\\frac{1}{2}\\)일 때의 점근분포를 구체적으로 제시하라."
  },
  {
    "objectID": "posts/ts/2023-03-03-graduation_test.html#f",
    "href": "posts/ts/2023-03-03-graduation_test.html#f",
    "title": "Theoritical Statistics GT",
    "section": "(f)",
    "text": "(f)\n가설 \\(H_0 : p = \\frac{1}{2}\\) vs \\(H_1 : p \\neq \\frac{1}{2}\\) 일때, 일반화 가능도비를 이용하여 기각 영역을 제시하라."
  },
  {
    "objectID": "posts/ts/2023-01-14-ts_Mid term.html",
    "href": "posts/ts/2023-01-14-ts_Mid term.html",
    "title": "Theoritical Statistics Mid term",
    "section": "",
    "text": "중간고사"
  },
  {
    "objectID": "posts/ts/2023-01-14-ts_Mid term.html#a",
    "href": "posts/ts/2023-01-14-ts_Mid term.html#a",
    "title": "Theoritical Statistics Mid term",
    "section": "(a)",
    "text": "(a)\n\\(T_1(X)\\)과 \\(T_2(X)\\)의 기댓값을 각각 구하시오.\nanswer\n- \\(E(T_1(X))\\)\n\\(= E(\\frac{1}{n}\\sum^n_{i=1}(X_i - \\mu)^2) = \\frac{E((X-\\mu)^2)}{n} = \\frac{n\\sigma^2}{n} = \\sigma^2\\)\n- \\(E(T_2(X))\\)\n\\(= E(\\frac{1}{n-1}\\sum^n_{i=1}(X_i - \\bar{X})^2)\\)\n\\(\\star\\)\n\\(\\sum(X-\\mu)^2 = \\sum(X - \\bar{X} + \\bar{X} - \\mu)^2\\)\n\\(= \\sum((X-\\bar{X})^2 + (\\bar{X} - \\mu)^2 + 2(X-\\bar{X})(\\bar{X}-\\mu))\\)\n\\(= \\sum(X - \\bar{X})^2.+ n(\\bar{X} - \\mu)^2\\)\n\\(\\star\\)\n\\(= E(\\frac{\\sum(X-\\mu)^2 - n(\\bar{X}-\\mu)}{n-1}^2) = \\frac{1}{n-1}[n\\sigma^2 - n\\frac{\\sigma^2}{n}] = \\frac{(n-1)\\sigma^2}{n-1} = \\sigma^2\\)"
  },
  {
    "objectID": "posts/ts/2023-01-14-ts_Mid term.html#b",
    "href": "posts/ts/2023-01-14-ts_Mid term.html#b",
    "title": "Theoritical Statistics Mid term",
    "section": "(b)",
    "text": "(b)\n\\(T_1(X)\\)과 \\(T_2(X)\\)의 분산을 각각 구하시오.\nanswer\n- \\(Var(T_1(X))\\)\n\\(= Var(\\frac{\\sigma^2}{n} \\frac{1}{\\sigma^2}\\sum^n_{i=1}(X_i - \\mu)^2)\\)\n\\(= \\frac{\\sigma^4}{n^2}2n\\)\n\\(= (\\frac{2\\sigma^4}{n})\\)\n\\(\\star\\)\n\\(V = \\sum(\\frac{X_i - \\mu}{\\sigma})^2 \\sim chi^2(n)\\)\n\\(\\star\\)\n- \\(Var(T_2(X))\\)\n\\(= Var(\\frac{1}{n-1}\\sum^n_{i=1}(X_i - \\bar{X})^2)\\)\n\\(\\star\\)\n\\(S_n^2 = \\sum^n_{i=1}\\frac{(X_i - \\bar{X}_n)^2}{n-1}\\)\n\\(\\frac{(n-1)S_n^2}{\\sigma^2} = \\frac{\\sum^n_{i=1}(X_i - \\bar{X})^2}{\\sigma^2} \\sim \\chi^2_{n-1}\\)\n\\(\\star\\)\n\\(= Var(\\frac{\\sigma^2}{n-1} \\times \\frac{(n-1)S^2}{\\sigma^2})\\)\n\\(\\frac{\\sigma^4}{(n-1)^2} \\times 2(n-1)\\)\n\\(= \\frac{2\\sigma^4}{n-1}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-14-ts_Mid term.html#a-1",
    "href": "posts/ts/2023-01-14-ts_Mid term.html#a-1",
    "title": "Theoritical Statistics Mid term",
    "section": "(a)",
    "text": "(a)\n\\(\\sqrt{n}(\\bar{X}^2_n - \\lambda^2)\\)의 극한 분포를 구하시오.\nanswer\nDelta Method\n\\(\\sqrt{n}(\\bar{X}^2_n - \\mu^2) \\xrightarrow[]{d} N(0,4\\mu^2\\sigma^2)\\) 단, \\(\\mu \\neq 0\\)\n\\(\\mu = \\lambda\\), \\(\\sigma^2 = \\lambda\\)\n\\(\\sqrt{n}(\\bar{X}^2_n - \\lambda^2) \\xrightarrow[]{d} N(0,4\\lambda^4)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-14-ts_Mid term.html#b-1",
    "href": "posts/ts/2023-01-14-ts_Mid term.html#b-1",
    "title": "Theoritical Statistics Mid term",
    "section": "(b)",
    "text": "(b)\n\\(E(\\sum^n_{i=1}a_i X_i) = \\lambda\\)가 되기 위한 \\(a_i\\)의 조건은 무엇인가?\nanswer\n\\(E(\\sum^n_{i=1}a_iX_i) = \\lambda\\)\n\\(= E(a_1X_1 + a_2X_2 + \\dots a_nX_n) = a_1E(X_1) + a_2E(X_2) + \\dots + a_nE(X_n)\\)\n\\(= a_1\\lambda + a_2\\lambda + \\dots + a_n\\lambda = \\sum^n_{i=1}a_i \\lambda\\)\n\\(\\therefore \\sum^n_{i=1} a_i= 1\\)이어야 한다."
  },
  {
    "objectID": "posts/ts/2023-01-14-ts_Mid term.html#c",
    "href": "posts/ts/2023-01-14-ts_Mid term.html#c",
    "title": "Theoritical Statistics Mid term",
    "section": "(c)",
    "text": "(c)\n\\(\\sum^n_{i=1}a_iX_i\\)의 분산을 구하시오.\nanswer\n\\(Var(\\sum^n_{i=1}a_iX_i) = Var(a_1X_1 + a_2X_2 + \\dots + a_n X_n)\\)\n\\(= a_1^2\\lambda + a_2^2\\lambda + \\dots + a_n^2\\lambda = \\sum^n_{i=1} a_i^2 \\lambda\\)"
  },
  {
    "objectID": "posts/ts/2023-01-14-ts_Mid term.html#a-2",
    "href": "posts/ts/2023-01-14-ts_Mid term.html#a-2",
    "title": "Theoritical Statistics Mid term",
    "section": "(a)",
    "text": "(a)\n이 랜덤표본의 결합확률밀도함수를 기술하시오.\nanswer\n\\(f(X_1)f(X_2)f(X_3)f(X_4)\\)\n\\(= (1-p)^{1-X_1}p^{X_1}(1-p)^{1-X_2}p^{X_2}(1-p)^{1-X_3}p^{X_3}(1-p)^{1-X_4}p^{X_4}\\)\n\\(= (1-p)^{4-X_1-X_2-X_3-X_4} p^{X_1+X_2+X_3+X_4}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-14-ts_Mid term.html#b-2",
    "href": "posts/ts/2023-01-14-ts_Mid term.html#b-2",
    "title": "Theoritical Statistics Mid term",
    "section": "(b)",
    "text": "(b)\n\\(X_1(1-X_2)\\)의 기댓값을 구하시오.\nanswer\n\\(E(X_1(1-X_2))\\)\n\\(= E(X_1 - X_1X_2) = E(X_1) - E(X_1)E(X_2)\\)\n\\(= p - p^2 = p(1-p)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-14-ts_Mid term.html#c-1",
    "href": "posts/ts/2023-01-14-ts_Mid term.html#c-1",
    "title": "Theoritical Statistics Mid term",
    "section": "(c)",
    "text": "(c)\n\\(E[X_1(1-X_2)|\\sum^4_{i=1}X_i = t]\\)을 구하시오.\nanswer\n\\(\\frac{p(1-p)}{4p} = \\frac{1-p}{4}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-14-ts_Mid term.html#d",
    "href": "posts/ts/2023-01-14-ts_Mid term.html#d",
    "title": "Theoritical Statistics Mid term",
    "section": "(d)",
    "text": "(d)\n\\(E[(\\frac{d}{dp}log p^X (1-p)^{1-p})^2]\\)을 구하시오.\nanswer\n\\(E[(\\frac{d}{dp} log p^x (1-p)^{1-X})^2]\\)\n\\(= E((\\frac{d}{dp}(X log p - (1-X) log(1-p)))^2)\\)\n\\(= E((\\frac{X}{p} - \\frac{1-X}{1-p})^2)\\)\n\\(= E((\\frac{X-Xp - p + pX}{p(1-p)})^2)\\)\n\\(= E((\\frac{X-p}{p(1-p)})^2)\\)\n\\(= \\frac{1}{p^2(1-p)^2}(E(X^2)-p^2)\\)\n\\(= \\frac{p-p^2+p^2+p^2}{p^2(1-p)^2} = \\frac{p(1-p)}{p^2(1-p)^2} = \\frac{1}{p(1-p)}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW1.html",
    "href": "posts/ts/2023-01-05-ts_HW1.html",
    "title": "Theoritical Statistics HW1",
    "section": "",
    "text": "확률변수와 확률분포"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW1.html#a-x의-주변분포를-구하시오.",
    "href": "posts/ts/2023-01-05-ts_HW1.html#a-x의-주변분포를-구하시오.",
    "title": "Theoritical Statistics HW1",
    "section": "(a) \\(X\\)의 주변분포를 구하시오.",
    "text": "(a) \\(X\\)의 주변분포를 구하시오.\nAnswer\n\\(F_X(X)\\)\n\n\\(P(X=0) = \\frac{1}{9} + \\frac{1}{9} = \\frac{2}{9}\\)\n\\(P(X=1) = \\frac{1}{6} + \\frac{1}{6} =\\frac{2}{6} = \\frac{1}{3}\\)\n\\(P(X=2) = \\frac{2}{9} + \\frac{2}{9} = \\frac{4}{9}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW1.html#b-y의-주변분포를-구하시오.",
    "href": "posts/ts/2023-01-05-ts_HW1.html#b-y의-주변분포를-구하시오.",
    "title": "Theoritical Statistics HW1",
    "section": "(b) \\(Y\\)의 주변분포를 구하시오.",
    "text": "(b) \\(Y\\)의 주변분포를 구하시오.\nAnswer\n\\(F_Y(Y)\\)\n\n\\(P(Y=10) = \\frac{1}{9} + \\frac{1}{6} = \\frac{15}{54} = \\frac{5}{18}\\)\n\\(P(Y=20) = \\frac{1}{9} + \\frac{2}{9} =\\frac{3}{9} = \\frac{1}{3}\\)\n\\(P(Y=30) = \\frac{1}{6} + \\frac{2}{9} = \\frac{21}{54} = \\frac{7}{18}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW1.html#c-y10-일-때-x의-조건부분포를-구하시오",
    "href": "posts/ts/2023-01-05-ts_HW1.html#c-y10-일-때-x의-조건부분포를-구하시오",
    "title": "Theoritical Statistics HW1",
    "section": "(c) \\(Y=10\\) 일 때 \\(X\\)의 조건부분포를 구하시오",
    "text": "(c) \\(Y=10\\) 일 때 \\(X\\)의 조건부분포를 구하시오\nAnswer\n\\(F_X(Y=10|X=0) = \\frac{1/9}{5/18} = \\frac{2}{5}\\)\n\\(F_X(Y=10|X=1) = \\frac{1/6}{5/18} = \\frac{3}{5}\\)\n\\(F_X(Y = 10|X = 2) = \\frac{0}{5/18} = 0\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html",
    "href": "posts/ts/2023-01-25-ts-final term.html",
    "title": "Theoritical Statistics Final term",
    "section": "",
    "text": "Final term"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#a",
    "href": "posts/ts/2023-01-25-ts-final term.html#a",
    "title": "Theoritical Statistics Final term",
    "section": "(a)",
    "text": "(a)\n\\(\\hat{\\theta}_{a_1,a_2}\\)이 비편향추정량이 될 \\(a_1\\)과 \\(a_2\\)의 조건을 구하시오\nanswer\n비편향 추정량 \\(\\theta_1\\), \\(\\theta_2\\), \\(E(\\hat{\\theta}_1) = \\bar{\\theta}\\), \\(E(\\hat{\\theta}_2) = \\bar{\\theta}\\)\n\\(E(\\hat{\\theta}_{a_1,a_2}) = E(a_1\\hat{\\theta}_1 + a_2\\hat{\\theta}_2) = a_1E(\\hat{\\theta}_1) + a_2E(\\hat{\\theta}_2) = a_1\\bar{\\theta} + a_2\\bar{\\theta} = \\bar{\\theta}(a_1 + a_2)\\)\n\\(\\bar{\\theta} = \\bar{\\theta}(a_1 + a_2)\\), 즉, \\(a_1 + a_2 = 1\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#b",
    "href": "posts/ts/2023-01-25-ts-final term.html#b",
    "title": "Theoritical Statistics Final term",
    "section": "(b)",
    "text": "(b)\n비편향추정량인 \\(\\hat{\\theta}_{a_1,a_2}\\) 중에서 가장 작은 분산을 가지는 추정량을 구하시오.\nanswer\n\\(Var(\\hat{\\theta}_1) = \\sigma^2_1\\), \\(Var(\\hat{\\theta}_2) = \\sigma^2_2\\)\n\\(Var(\\hat{\\theta}_{a_1,a_2}) = Var((a_1 + a_2)\\bar{\\theta}) = (a_1 + a_2)^2 Var(\\hat{\\theta})\\)\n\\((a_1 + a_2)^2\\)이 최소이면서 \\(a_1 + a_2=1\\)일 때, 즉 \\(a_1 = 0.5, a_2 = 0.5\\)일 때 가장 작은 분산을 가진다."
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#a-1",
    "href": "posts/ts/2023-01-25-ts-final term.html#a-1",
    "title": "Theoritical Statistics Final term",
    "section": "(a)",
    "text": "(a)\n\\(p(1-p)\\)에 대한 비편향추정량의 크래머-라오 하한값을 구하시오.\nanswer\nbias = \\(E(\\hat{p}(1-\\hat{p})) - p(1-p) = 0\\)\n\\(E(\\bar{X}) = np\\), \\(Var(\\bar{X}) = np(1-p)\\)\n\\(E(\\hat{p}(1-\\hat{p})) = E(\\frac{\\bar{X}}{n}(1-\\frac{\\bar{X}}{n})) = E(\\frac{\\bar{X}}{n} - (\\frac{\\bar{X}}{n})^2) = p - p^2\\)\n\\(f(x) = p^x(1-p)^{1-x}\\)\n\\(logf(x) = xlogp + (1-x)log(1-p)\\)\n\\(\\frac{\\partial log f(x)}{\\partial p} = \\frac{x}{p} - \\frac{1-x}{1-p}\\)\n\\(\\frac{\\partial^2 log f(x)}{\\partial^2 p} = -\\frac{x}{p^2} - \\frac{1-x}{(1-p)^2}\\)\n\\(\\star I(\\theta) = E[(\\frac{\\partial}{\\partial \\theta} log f(C; \\theta))^2)]\\)\n\\(I(p) = -E(-\\frac{x}{p^2}-\\frac{1-x}{(1-p)^2}) = \\frac{1}{p} + \\frac{1}{1-p} = \\frac{1}{p(1-p)}\\)\n\\(CRLB = \\frac{g'(p)^2}{nI(p)} = \\frac{(1-2p)^2p(1-p)}{n}\\)\n\\(\\star g(p) = p(1-p)\\), \\(g'(p) = 1-2p\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#b-1",
    "href": "posts/ts/2023-01-25-ts-final term.html#b-1",
    "title": "Theoritical Statistics Final term",
    "section": "(b)",
    "text": "(b)\n\\(X_1(1-X_2)\\)의 기댓값을 구하시오.\nanswer\n\\(E(X_1(1-X_2)) = E(X_1 - X_1X_2) = E(X_1) - E(X_1X_2) = E(X_1) - E(X_1)E(X_2) = p - p^2 = p(1- p)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#c",
    "href": "posts/ts/2023-01-25-ts-final term.html#c",
    "title": "Theoritical Statistics Final term",
    "section": "(c)",
    "text": "(c)\n\\(p(1-p)\\)에 대한 최소분산 비편향 추정량을 구하시오.\nanswer\n\\(E(\\bar{X}_n(1 - \\bar{X}_n)) = \\frac{(n-1)p(1-p)}{n}\\)\n\\(p(1-p) = \\frac{n\\bar{X}_n(1-\\bar{X}_n)}{n-1}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#d",
    "href": "posts/ts/2023-01-25-ts-final term.html#d",
    "title": "Theoritical Statistics Final term",
    "section": "(d)",
    "text": "(d)\n\\(p(1-p)\\)에 대한 적률추정량을 구하시오.\nanswer\n\\(M_1 = E(\\bar{X}) = p\\)\n\\(M_2 = Var(\\bar{X}) + E(\\bar{X})^2 = p(1-p) + p^2 = p\\)\n\\(p(1-p)\\)의 적률추정량 \\((p(1-p))^{MME} = M_2 - M^2_1 = p - p^2 = p(1-p)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#e",
    "href": "posts/ts/2023-01-25-ts-final term.html#e",
    "title": "Theoritical Statistics Final term",
    "section": "(e)",
    "text": "(e)\n\\(p(1-p)\\)에 대한 최대가능도추정량을 구하시오.\nanswer\n\\(f(x) = p^x(1-p)^{1-x}, x=0,1, 0&lt;p&lt;1\\)\n\\(L(p) = f(x_1|p)\\dots f(x_n|p) = p^{x_1}(1-p)^{1-x_1}\\dots p^{x_n}(1-p)^{1-x_n} = p^{\\sum x_i}(1-p)^{n-\\sum x_i}\\)\n\\(l(p) = \\sum x_i log p + (n-\\sum x_i) log (1-p)\\)\n\\(l'(p) = \\frac{\\sum x_i}{p} - \\frac{n-\\sum x_i}{1-p} = 0\\)\n\\(\\hat{p} = \\frac{\\sum x_i}{n} = \\bar{X}\\)\n\\((\\hat{p}(1-\\hat{p}))^{MLE} = \\bar{X}(1-\\bar{X})\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#a-2",
    "href": "posts/ts/2023-01-25-ts-final term.html#a-2",
    "title": "Theoritical Statistics Final term",
    "section": "(a)",
    "text": "(a)\n\\(\\theta\\)에 대한 적절한 추축변량을 구하고, 해당 추축변량의 분포를 명시하시오.\nanswer\n\\(X_i \\sim exp(\\frac{1}{\\theta})\\)\n\\(2X_i \\theta \\sim exp(2)\\)\n\\(2n\\bar{X}\\theta \\sim \\chi^2 (2n)\\)\n참고"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#b-2",
    "href": "posts/ts/2023-01-25-ts-final term.html#b-2",
    "title": "Theoritical Statistics Final term",
    "section": "(b)",
    "text": "(b)\n\\(\\theta\\)에 대한 95%신뢰구간을 구하시오.\nanswer\n\\((\\chi^2_{0.025} (2n) \\le 2n \\bar{X} \\theta \\le \\chi^2_{0.975} (2n)) = 0.95\\)\n\\(\\theta_{0.95} \\to (\\frac{\\chi^2_{0.025}(2n)}{2n\\bar{X}} , \\frac{\\chi^2_{0.975}(2n)}{2n\\bar{X}})\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#c-1",
    "href": "posts/ts/2023-01-25-ts-final term.html#c-1",
    "title": "Theoritical Statistics Final term",
    "section": "(c)",
    "text": "(c)\n\\(P(X&gt;1)\\)에 대한 95% 신뢰구간을 구하시오.\nanswer\n\\(P(X&gt;1) = \\int^{\\infty}_1 \\theta e^{-x\\theta} dx = [ e^{x\\theta}]^{\\infty}_1 = e^{-\\theta}\\)\n\\(P(X&gt;1)\\) \\(95\\)% CI : \\((exp(\\frac{\\chi^2_{0.9755}(2n)}{2n\\bar{X}} , exp(\\frac{\\chi^2_{0.025}(2n)}{2n\\bar{X}}))\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#d-1",
    "href": "posts/ts/2023-01-25-ts-final term.html#d-1",
    "title": "Theoritical Statistics Final term",
    "section": "(d)",
    "text": "(d)\n가설에서 고려하고 있는 \\(\\theta\\)의 전체 모수공간 \\(\\Omega\\)와 귀무가설 하에서의 모수공간 \\(\\Omega_0\\)을 구하시오.\nanswer\n\\(\\Omega = \\{ \\theta : \\theta &gt; 0 \\}\\)\n\\(\\Omega_0 = \\{ \\theta: \\theta = 2\\}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#e-1",
    "href": "posts/ts/2023-01-25-ts-final term.html#e-1",
    "title": "Theoritical Statistics Final term",
    "section": "(e)",
    "text": "(e)\n\\(\\theta\\)의 가능도 함수를 기술하시오.\nanswer\n\\(L(\\theta) = \\theta^n e^{-\\theta n \\bar{X}}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#f",
    "href": "posts/ts/2023-01-25-ts-final term.html#f",
    "title": "Theoritical Statistics Final term",
    "section": "(f)",
    "text": "(f)\n\\(\\theta\\)의 \\(\\Omega\\)에서의 최대가능도 추정량과 \\(\\Omega_0\\)에서의 최대가능도 추정량을 구하시오.\nanswer\n\\(\\hat{\\theta}^{\\Omega} = \\frac{1}{\\bar{X}}\\)\n\\(\\hat{\\theta}^{\\Omega_0} = 2\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#g",
    "href": "posts/ts/2023-01-25-ts-final term.html#g",
    "title": "Theoritical Statistics Final term",
    "section": "(g)",
    "text": "(g)\n일반화 가능도 비 \\(\\Lambda\\)을 구하시오.\nanswer\n\\(\\frac{L(\\hat{\\theta}^{\\Omega_0})}{L(\\hat{\\theta}^{\\Omega})} = \\frac{\\hat{\\theta}^{n,\\Omega_0} e^{-\\hat{\\theta} n \\bar{X}}}{\\hat{\\theta}^{n,\\Omega} e^{-\\hat{\\theta} n \\bar{X}}} = (\\frac{2}{n})^2 e^{n\\bar{x}(\\theta-2)}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#h",
    "href": "posts/ts/2023-01-25-ts-final term.html#h",
    "title": "Theoritical Statistics Final term",
    "section": "(h)",
    "text": "(h)\n유의수준 \\(\\alpha\\)인 가능도비 검정법의 기각역을 \\(\\chi^2\\)분포의 분위수를 사용하여 표현하시오.\nanswer\n7장 예제 7.2.3. 참고\n\\(2(l(\\hat{\\theta}^{\\Omega}) - l(\\hat{\\theta}^{\\Omega_0})) = 2n(\\bar{x}\\theta_0 - 1 -log(\\bar{X}\\theta_0))\\)\n최대가능도비 검정의 기각역 형태 \\(2n(\\bar{x}\\theta_0 - 1 -log(\\bar{X}\\theta_0))\\ge c\\)\n기각역\n\\(\\begin{cases} \\bar{x}\\theta_0 \\le c_1 \\text{ 또는 } \\bar{x}\\theta_0\\ge c_2 \\\\ c_1 log c_1 = c_2 - log c_2\\end{cases}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#a-3",
    "href": "posts/ts/2023-01-25-ts-final term.html#a-3",
    "title": "Theoritical Statistics Final term",
    "section": "(a)",
    "text": "(a)\n가설 \\(H_0:\\sigma^2 = 4\\) vs \\(H_1: \\sigma^2 = 9\\)에 대한 최강력 검정의 기각역은\n\\[C = \\{ (x_1,\\dots,x_n):\\sum^n_{i=1}x_i^2 \\ge c\\}\\]\n의 꼴로 주어짐을 보이시오.\nanswer\n\\(L(\\sigma^2) = \\Pi^n_{i=1} f(x_2 : \\sigma^2) = \\Pi^n_{i=1} \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{x_i^2}{2\\sigma^2}} * \\mu=0\\)\n\\(= (\\frac{1}{2\\pi\\sigma^2})^{\\frac{n}{2}} e^{-\\frac{\\sum^n_{i=1}x_i^2}{2\\sigma^2}}\\)\n네이만 피어슨 정의에 의하면, \\(LR = \\frac{L(H_0)}{L(H_1)} = \\frac{L(4)}{L(9)} \\le k\\)\n\\(LR = \\frac{L(4)}{L(9)} = \\frac{(\\frac{1}{2\\pi 4})^{\\frac{n}{2}} e^{-\\frac{\\sum^n_{i=1} x_i^2}{2 \\times 4}}}{(\\frac{1}{2\\pi 9})^{\\frac{n}{2}} e^{-\\frac{\\sum^n_{i=1} x_i^2}{2 \\times 9}}}\\)\n\\(= (\\frac{9}{4})^{\\frac{n}{2}}e^{-\\sum^n_{i=1}x^2_i(\\frac{1}{8}-\\frac{1}{18})}\\)\n\\(= (\\frac{9}{4})^{\\frac{n}{2}}e^{-\\frac{5}{72}\\sum^n_{i=1}x^2_i} \\le k\\)\n\\(\\to e^{-\\frac{5}{72}\\sum^n_{i=1}x^2_i} \\le k\\)\n\\(\\to -\\frac{5}{72}\\sum^n_{i=1}x^2_i \\le k\\)\n\\(\\to \\sum^n_{i=1}x^2_i \\ge k\\)\n기각역: \\(\\therefore c = \\{ (x_1, \\dots ,x_n) : \\sum^n_{i=1} x^2_i \\ge c)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#b-3",
    "href": "posts/ts/2023-01-25-ts-final term.html#b-3",
    "title": "Theoritical Statistics Final term",
    "section": "(b)",
    "text": "(b)\n표본의 크기가 \\(n=20\\)일 때 유의수준이 \\(\\alpha=0.05\\)이기 위한 상수 \\(c\\)의 값을 \\(\\chi^2\\)분포의 분위수를 사용하여 표현하시오.\nanswer\n\\(\\alpha = P(\\text{Reject } H_0 | H_0 \\text{True})\\)\n\\(= P(\\sum^n_{i=1}x^2_i \\ge k | \\sigma^2 = 4)\\)\n\\(= P(\\sum^n_{i=1}\\frac{\\chi^2_i}{\\sigma^2} \\ge \\frac{k}{\\sigma^2}|\\sigma^2 = 4)\\)\n\\(= P(\\sum^{20}_{i=1} \\frac{\\chi^2_i}{4} \\ge \\frac{k}{4} | \\sigma^2 = 4)\\)\n\n\n\nimage.png\n\n\n\\(\\frac{k}{4} = \\chi^2_{0.05(20)}\\)\n\nqchisq(0.95,20)\n\n31.4104328442309\n\n\n\nround(4*qchisq(0.95,20),2)\n\n125.64\n\n\n\\(k = 4\\chi^2_{0.05(20)} = 125.64\\)\n\\(c = \\{(x_1,\\dots,x_n) : \\sum^n_{i=1}\\ge 125.64\\}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#c-2",
    "href": "posts/ts/2023-01-25-ts-final term.html#c-2",
    "title": "Theoritical Statistics Final term",
    "section": "(c)",
    "text": "(c)\n표본의 크기가 \\(n=20\\)일 때 (b)에서 찾은 기각역에 대한 제2종오류를 범할 확률을 구하시오.\nanswer\n\\(\\beta = P(\\text{Not Reject } H_0 | H_1 \\text{True})\\)\n\\(= P(\\sum^n_{i=1}x^2_i \\le k | \\sigma^2 = 9)\\)\n\\(\\star\\)\n모집단 분포 \\(X_i \\sim N(0,\\sigma^2)\\)\n표준화 \\(\\frac{X_i}{\\sigma} \\sim N(0,1)\\)\n표분화 제곱 분포는 카이제곱 \\((\\frac{X_i^2}{\\sigma})^2 \\sim \\chi^2_1, i=1,2,\\dots, n\\)\n카이제곱의 합의 자유도 합 \\(\\sum^n_{i=1}(\\frac{X_i}{\\sigma})^2 \\sim \\chi^2_{(n)}\\)\n\\(\\star\\)\n\\(= P(\\sum^n_{i=1}\\frac{\\chi^2_i}{\\sigma^2} \\le \\frac{k}{\\sigma^2}|\\sigma^2 = 9)\\)\n\\(= P(\\sum^{20}_{i=1} \\frac{\\chi^2_i}{9} \\le \\frac{k}{9} | \\sigma^2 = 9)\\)\n\\(\\frac{k}{9} = \\chi^2_{0.05(20)}\\)\n\nqchisq(0.95,20)\n\n31.4104328442309\n\n\n\nround(9*qchisq(0.95,20),2)\n\n282.69\n\n\n\\(k = 9\\chi^2_{0.05(20)} = 282.69\\)\n\\(c = \\{(x_1,\\dots,x_n) : \\sum^n_{i=1}\\le 282.69\\}\\)\n랜덤표본\\(X_1,X_2,\\dots,X_n\\)의 분포가 확률밀도함수 \\(f(x;\\theta), \\theta\\in\\Omega\\)를 따른다고 하자. 이때 표본과 모수 \\(\\theta\\)의 함수인 확률변량 \\(T(X_1,X_2,\\dots, X_n;\\theta)\\)의 분포가 모수 \\(\\theta\\)에 의존하지 않으면 이를 추축변량이라 한다."
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#a-4",
    "href": "posts/ts/2023-01-25-ts-final term.html#a-4",
    "title": "Theoritical Statistics Final term",
    "section": "(a)",
    "text": "(a)\n적절한 추축변량을 이용하여 \\(\\sigma^2\\)에 대한 \\(100(1-\\alpha)%\\) 신뢰구간을 구하시오.\nanswer\n\\(\\frac{\\sum(X_i - \\bar{X})2}{\\sigma^2} = \\frac{(n-1)S^2}{\\sigma^2} \\sim \\chi_{(n-1)}^2\\)\n\\(P[\\chi_L \\le \\frac{(n-1)S^2}{\\sigma^2} \\le \\chi_U] = 1-\\alpha\\)\n\\(P[\\chi_{\\alpha/2} \\le \\frac{(n-1)S^2}{\\sigma^2} \\le \\chi_{1-\\alpha/2}] = 1-\\alpha\\)\n\\(P[\\frac{(n-1)S^2}{\\chi^2_{1-\\alpha/2}} \\le \\sigma^2 \\le \\frac{(n-1)S^2}{\\chi^2_{\\alpha/2}}] = 1-\\alpha\\)\n\\(\\therefore (\\frac{(n-1)S^2}{\\chi^2_{\\alpha/2}},\\frac{(n-1)S^2}{\\chi^2_{1-\\alpha/2}})\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#b-4",
    "href": "posts/ts/2023-01-25-ts-final term.html#b-4",
    "title": "Theoritical Statistics Final term",
    "section": "(b)",
    "text": "(b)\n유의수준 \\(\\alpha\\)인 일반화 가능도비 검정 기각역을 구하시오.\nanswer\n모평균 \\(\\mu\\)의 최대가능도 추정량은 가설에 관계없이 언제나 \\(\\bar{X}\\)\n모분산 \\(\\sigma^2\\)의 최대가능도 추정량은 귀무가설 하에서는 \\(4\\)이며, 전체 모수공간\\(\\Omega\\)내에서는 \\(\\hat{\\sigma}^2 = \\frac{\\sum^n_{i=1}(X - \\bar{X})^2}{n}\\)\n일반화 가능도비 \\(\\Lambda(X_1,X_2,\\dots,X_n) = (\\frac{\\sum^n_{i=1} (X_i - \\bar{X}_n)^2}{4n})^{n/2} \\times exp[-\\frac{1}{2} \\{ \\frac{\\sum^n_{i=1}\\{(X_i - \\bar{X}_i)}{4} \\}^2 + \\frac{n}{2}]\\)\n\\(= (\\frac{\\hat{\\sigma}^2}{4})^{n/2} exp\\{ -(\\frac{n}{2})(\\frac{\\hat{\\sigma^2}}{4}) + \\frac{n}{2} \\}\\)\n\\(\\Lambda = \\frac{\\hat{\\sigma}^2}{4}^{n/2} exp(-\\frac{n}{2}\\frac{\\hat{\\sigma}^2}{4} + \\frac{n}{2})\\)\n\\(\\frac{\\hat{\\sigma}^2}{4} exp(-\\frac{\\hat{\\sigma}^2}{4}) \\le (\\lambda^*)^{2/n} exp(-1) = c^*\\)\n\\(\\frac{\\hat{\\sigma}^2}{4}&lt;1\\)일 때는 단조증가, \\(\\frac{\\hat{\\sigma}^2}{4}&gt;1\\)일 때는 단조감소\n기각영역 ; \\(C = \\{ (x_1,x_2,\\dots,x_n):(\\frac{\\hat{\\sigma}^2}{4} \\le a\\) 또는 \\(\\frac{\\hat{\\sigma}^2}{4} \\ge b \\}\\)\n\\(n\\frac{\\hat{\\sigma}^2}{4} = \\frac{\\sum^n_{i=1}(X_i - \\bar{X}_n)^2}{4} \\sim \\chi^2(n-1)\\)\n\\(P[\\frac{\\sum^n_{i=1}(X_i - \\bar{X}_n)^2}{4} \\le \\chi^2_{1-\\alpha/2}(n-1)|H_0]\\)\n\\(= P[\\frac{\\sum^n_{i=1}(X_i - \\bar{X}_n)^2}{4} \\ge \\chi^2_{\\alpha/2}(n-1)|H_0]\\)\n\\(= \\frac{\\alpha}{2}\\)\n그러므로 카이제곱분포의 양쪽꼬리에서 \\(\\alpha/2\\)씩 고려한 일반화 가능도비 검정법의 근사꼴로서 기각영역은\n\\(\\frac{\\sum^n_{i=1}(X_i - \\bar{X}_n)^2}{4} \\le \\chi^2_{1-\\alpha/2}(n-1)\\)\n또는 \\(\\frac{\\sum^n_{i=1}(X_i - \\bar{X}_n)^2}{4} \\ge \\chi^2_{\\alpha/2}(n-1)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-25-ts-final term.html#c-3",
    "href": "posts/ts/2023-01-25-ts-final term.html#c-3",
    "title": "Theoritical Statistics Final term",
    "section": "(c)",
    "text": "(c)\n\\(n=10\\)이고 표본분산 \\(S^2\\)의 관측값은 \\(6\\)이라고 한다. (b)의 일반화 가능도비 검정법으로 유의확률 (\\(p-value\\))을 구하시오.\nanswer\n\n1-pchisq(6/4*9,9)\n\n0.14125582649328"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW2.html",
    "href": "posts/ts/2023-01-05-ts_HW2.html",
    "title": "Theoritical Statistics HW2",
    "section": "",
    "text": "기댓값"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW2.html#section-3",
    "href": "posts/ts/2023-01-05-ts_HW2.html#section-3",
    "title": "Theoritical Statistics HW2",
    "section": "(1)",
    "text": "(1)\n\\(x\\)에 대한 \\(Y\\)의 조건부 기댓값 \\(E(Y|x)\\)를 구하라.\nAnswer\n\\(E(Y|x) = \\int^\\infty_{-\\infty} y f_{Y|X} (y) dy = \\int^\\infty_{-\\infty} y \\frac{f(X,y)}{f_X(X)}dy\\)\n\\(\\star\\)\n\\(f_X(X) = \\int f(x,y) dy = \\int^\\infty_{-\\infty} 4I(0&lt;x&lt;1,1&lt;y&lt;2x)dy\\)\n\\(= 4I(0&lt;x&lt;1)\\int_{-\\infty &lt; y &lt; \\infty , 1&lt;y&lt;2x} I(1&lt;y&lt;2x)dy\\)\n\\(= 4I(0&lt;x&lt;1)\\int^{2x}_1 a dy = 4I(0&lt;x&lt;1)[y]^{2x}_1\\)\n\\(= 4(2x-1)I(0&lt;x&lt;1)\\)\n\\(\\star\\)\n\\(= \\int^\\infty_{-\\infty} y \\frac{4I(0&lt;x&lt;1,1&lt;y&lt;2x)}{4(2x-1)I(0&lt;x&lt;1)} dy\\)\n\\(= \\int_{-\\infty &lt; y&lt; \\infty, 1&lt;y&lt;2x} y \\frac{I(0&lt;x&lt;1)}{2x-1} dy = \\frac{I(0&lt;x&lt;1)}{2x-1} \\int^{2x}_1 y dy\\)\n\\(= \\frac{I(0,x&lt;1)}{2x-1} [\\frac{1}{2} y^2]^{2x}_1\\)\n\\(= \\frac{I(0&lt;x&lt;1)}{2x-1}(\\frac{1}{2}(4x^2-1))\\)\n\\(\\star 4x^2 - 1 = (2x+1)(2x-1)\\)\n\\(= \\frac{2x+1}{2}I(0&lt;x&lt;1)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW2.html#section-4",
    "href": "posts/ts/2023-01-05-ts_HW2.html#section-4",
    "title": "Theoritical Statistics HW2",
    "section": "(2)",
    "text": "(2)\n\\(y\\)에 대한 \\(X\\)의 조건부 기댓값 \\(E(X|y)\\)를 구하라.\nAnswer\n\\(E(X|Y=y) = \\int^\\infty_{-\\infty} x f_{X|Y}(x|y) dx = \\int^\\infty_{-\\infty} x\\frac{f(x,y}{f(y)} dx\\)\n\\(\\star\\)\n\\(f_Y(Y) = \\int^\\infty_{-\\infty} f(x,y) dy = \\int^\\infty_{-\\infty} 4I(0&lt;x&lt;1,1&lt;y&lt;2x) dx\\)\n\\(= 4\\int_{-\\infty &lt;x&lt;\\infty, 0&lt;x&lt;1, 1&lt;y&lt;2x} 1 dx = \\int^1_{\\frac{y}{2}} 4I(1&lt;y&lt;2) dx [4x]^1_{\\frac{y}{2}}\\)\n\\(= (4-2y)I(1&lt;y&lt;2)\\)\n\\(\\star\\)\n\\(= \\int^\\infty_{-\\infty} x \\frac{4I(0&lt;x&lt;1,1&lt;y&lt;2x)}{(4-2y)I(1&lt;y&lt;2)} dx\\)\n\\(= \\frac{4}{4-2y} \\int_{-\\infty x&lt;\\infty, 0&lt;x&lt;1,1&lt;y&lt;2x,1&lt;y&lt;2} x dx = \\frac{4}{4-2y} \\int^1_{\\frac{y}{2}} xI(1&lt;y&lt;2) dx\\)\n\\(= \\frac{4}{4-2y}[\\frac{1}{2}x^2]^1_{\\frac{y}{2}} = \\frac{4}{4-2y} (\\frac{1}{2} - \\frac{y^2}{8})\\)\n\\(= \\frac{4}{2(2-y)}(\\frac{4-y^2}{8})\\)\n\\(\\star 4-y^2 = (2+y)(2-y)\\)\n\\(= 4(2+y)I(1&lt;y&lt;2)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW2.html#section-5",
    "href": "posts/ts/2023-01-05-ts_HW2.html#section-5",
    "title": "Theoritical Statistics HW2",
    "section": "(3)",
    "text": "(3)\n\\(x\\)에 관한 \\(Y\\)의 조건부 분산 \\(E[Y - E(Y|x)|x]^2\\)을 구하라.\nAnswer\n\\(E[(Y - E(Y|X=x))^2|X=x] = E(Y^2|X=x) - \\{ E(Y|X=x) \\}^2\\)\n\\(\\star\\)\n\\(E(Y^2|X=x) = \\int Y^2 f_{Y|X}(y) dy = \\int^\\infty_{-\\infty} y^2 \\frac{f(x,y)}{f_X(X)}dy\\)\n\\(= \\int^\\infty_{-\\infty} y^2 \\frac{4I(0&lt;x&lt;1,1&lt;y&lt;2x)}{4(2x-1)I(0&lt;x&lt;1)} dy\\)\n\\(= \\frac{1}{2x-1} I(0&lt;x&lt;0 \\int_{-\\infty &lt; y&lt;\\infty, 1&lt;y&lt;2x} y^2 dy\\)\n\\(= \\frac{1}{2x-1} I(0&lt;x&lt;1)\\int^{2x}_1 y^2 dy\\)\n\\(= \\frac{1}{2x-1}I(0&lt;x&lt;1) [\\frac{1}{3} y^2]^{2x}_1\\)\n\\(= \\frac{1}{2x-1} I (0&lt;x&lt;1)\\frac{1}{3}(8x^3-1)\\)\n\\(= \\frac{4x^2 + 2x+1}{3} I(0&lt;x&lt;1)\\)\n\\(\\star\\)\n\\(= (\\frac{4x^2 + 2x + 1}{3} - \\frac{(2x+ 1)^2}{2^2}) I(0&lt;x&lt;1)\\)\n\\(\\frac{(2x-1)^2}{12}I(0&lt;x&lt;1)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW2.html#section-9",
    "href": "posts/ts/2023-01-05-ts_HW2.html#section-9",
    "title": "Theoritical Statistics HW2",
    "section": "(1)",
    "text": "(1)\n확률변수들 \\(X_i\\)의 적률생성함수를 구하라.\nAnswer\n\\(M_X(t) = E(e^{tx})\\)\n\\(\\sum^1_{x=0}e^{tx}f(x) = e^0 f(0) + e^tf(1) = 1-p+e^tp\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW2.html#section-10",
    "href": "posts/ts/2023-01-05-ts_HW2.html#section-10",
    "title": "Theoritical Statistics HW2",
    "section": "(2)",
    "text": "(2)\n(1)의 결과를 이용하여 확률변수 \\(X_i\\)의 분산을 구하라.\nAnswer\n\\(M_X^{'} (t) = e^tp \\to M_X^{'}(0) = p\\)\n\\(M_X^{''} (t) = e^tp \\to M_X^{''}(0) = p\\)\n\\(var(X_i) = E(X^2) - (E(X))^2\\)\n\\(= M_X^{''}(0) - \\{ M_X^{'}(0)\\}^2\\)\n\\(= p - p^2\\)\n\\(= p(1-p)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW2.html#section-11",
    "href": "posts/ts/2023-01-05-ts_HW2.html#section-11",
    "title": "Theoritical Statistics HW2",
    "section": "(3)",
    "text": "(3)\n(1)의 결과를 이용하여 확률변수 \\(\\sum^n_{i=1} X_i\\)의 적률생성함수를 구하라.\nAnswer\n\\(M_{\\sum^n_{i=1} X_i}(t) = E(e^{t\\sum^n_{i=1} X_i})\\)\n\\(= E(e^{tX_1 + tX_2 + \\dots + tX_n})\\)\n\\(= E(e^{tX_1} e^{tX_2} \\dots e^{tX_n})\\)\n\\(= E(e^{tx})E(e^{tX_2})\\dots E(e^{tX_n})\\)\n\\(= M_{X_1}(t) M_{X_2}(t) \\dots M_{X_n}(t)\\)\n\\(= (1-p+pe^t)^n \\to\\) 이항분포의 적률생성함수"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW2.html#section-13",
    "href": "posts/ts/2023-01-05-ts_HW2.html#section-13",
    "title": "Theoritical Statistics HW2",
    "section": "(1)",
    "text": "(1)\n\\(P(X = 3)\\)을 계산하라.\nAnswer\n\\(P(X=1) = \\frac{1}{9}\\)\n\\(P(X=3) = \\frac{3}{9}\\)\n\\(P(X=5) = \\frac{5}{9}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW2.html#section-14",
    "href": "posts/ts/2023-01-05-ts_HW2.html#section-14",
    "title": "Theoritical Statistics HW2",
    "section": "(2)",
    "text": "(2)\n\\(X\\)의 확륢밀도함수를 구하라.\nAnswer\n\\(M_X(t) = E(e^{tx}) = \\sum^n_{i=1} e^{tx} f(x) = \\frac{1}{9}e^t + \\frac{3}{9} e^{3t} + \\frac{5}{9} e^{5t}\\)\n\\(\\therefore f(x) = \\frac{x}{9}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW3.html",
    "href": "posts/ts/2023-01-05-ts_HW3.html",
    "title": "Theoritical Statistics HW3",
    "section": "",
    "text": "자주 사용되는 확률분포"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW3.html#수업-과제-1.",
    "href": "posts/ts/2023-01-05-ts_HW3.html#수업-과제-1.",
    "title": "Theoritical Statistics HW3",
    "section": "수업 과제 1.",
    "text": "수업 과제 1.\n기하분포: \\(X \\sim Geometric(p)\\)\n\\(X=\\)서로 독립인 베르누이 시행을 반복할 때 첫번째 성공이 나올 때까지 시행횟수\n\\[f(x) = (1-p)^{x-1}p, x=1,2,\\dots\\]\n\n\\(\\sum^{\\infty}_{x=1}(1-p)^{x-1}p = 1\\)\n아래 증명\n\\(M(t) = \\frac{pe^t}{1-qe^t} \\text{ for } t&lt; - ln q\\)\n\\(E(X) = \\frac{1}{p}, Var(X) = \\frac{q}{p^2}\\)\n\nanswer\n\\(M(t) = E(e^{tx}) = \\sum^{\\infty}_{x=1} e^{tx} (1-p)^{x-1}p\\)\n\\(= \\frac{p}{1-p}\\sum^{\\infty}_{x=1}\\{e^t(1-p)\\}^x\\)\n\\(= \\frac{p}{1-p}\\frac{e^t - pe^t}{1-e^t + pe^t}\\)\n\\(= \\frac{pe^t}{1-e^t+pe^t}\\)\n\\(M^{'}_X(t) = \\frac{pe^t(1-e^t + pe^t) - pe^t(-e^t + pe^t)}{(1-e^t + pe^t)^2} = \\frac{pe^t}{(1-e^t+pe^t)^2}\\)\n\\(M^{'}_X(0) = E(X) = \\frac{1}{p}\\)\n\\(M^{''}_X(t) = pe^t(1-e^t+pe^t)^{-2}+pe^t(-2)(1-e^t+pe^t)^{-3}(-e^t+pe^t)\\)\n\\(= pe^t(1-e^t+pe^t)^{-3}(1-e^t+pe^t-2(-e^t+pe^t))\\)\n\\(= pe^t(1-e^t+pe^t)^{-3}(1+e^t-pe^t)\\)\n\\(M^{''}_X(0) = E(X^2)=p(1-1+p)^{-3}(1+1-p)=\\frac{2-p}{p^2} = \\frac{1+q}{p^2}\\)\n\\(var(X) = E(X^2) - (E(X))^2 = \\frac{1+q}{p^2} - \\frac{1}{p^2} = \\frac{q}{p^2}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW3.html#수업과제-2.",
    "href": "posts/ts/2023-01-05-ts_HW3.html#수업과제-2.",
    "title": "Theoritical Statistics HW3",
    "section": "수업과제 2.",
    "text": "수업과제 2.\n\\(\\Gamma(\\frac{1}{2}) = \\sqrt{\\pi}\\) 증명\n\\(\\Gamma(k) = \\int^{\\infty}_{0} t^{k-1} e^{-t} dt\\)\nanswer\n\\(\\Gamma(\\frac{1}{2}) = \\int^{\\infty}_{0} x^{\\frac{1}{2} - 1} e^{-x} dx\\)\n변수 변환 \\(y = x^{\\frac{1}{2}}\\), \\(x = y^2\\), \\(dx = 2y dy\\), \\(y&gt;0\\)\n\\(= \\int^{\\infty}_0 \\frac{1}{y} e^{-y^2} 2y dy = 2 \\int^{\\infty}_0 e^{-y^2} dy\\)\n변수 변환 \\(u = r\\cos \\theta\\), \\(v=r \\sin \\theta\\), \\(J = \\begin{bmatrix} \\cos \\theta & r \\sin \\theta \\\\ \\sin \\theta & r \\cos \\theta \\end{bmatrix} = r\\),\n\\(0&lt;u&lt;\\infty \\to 0&lt;r&lt;\\infty\\),\n\\(0&lt;v&lt;\\infty \\to 0&lt; \\theta &lt; \\frac{\\pi}{2}\\)\n\\(\\Gamma \\{ (\\frac{1}{2}) \\}^2 = 4\\int^{\\infty}_0 e^{-u^2} du \\int^{\\infty}_0 e^{-v^2} dv = 4\\int^{\\infty}_0 \\int^{\\infty}_0 e^{-(u^2 + v^2)} du dv\\)\n\\(= 4\\int^{\\infty}_0 \\int^{\\frac{\\pi}{2}}_0 e^{-r^2} r d \\theta dr\\)\n\\(= 4 \\frac{\\pi}{2} \\int^{\\infty}_0 e^{-r^2} r dr = 2\\pi \\frac{1}{2} e^{-r^2} |^{\\infty}_0 = \\pi\\)\n\\(\\to \\Gamma(\\frac{1}{2}) = \\sqrt{\\pi}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW3.html#수업-과제-3.",
    "href": "posts/ts/2023-01-05-ts_HW3.html#수업-과제-3.",
    "title": "Theoritical Statistics HW3",
    "section": "수업 과제 3.",
    "text": "수업 과제 3.\n\\(P(X \\le t) = 1-P(X&gt;t) = 1-P(n\\text{번째 사건이 발생하는 시간}&gt;t) = 1-P([0,t) \\text{사이에 발생하는 사건의 수} \\le n-1)\\)\nanswer\ncdf : \\(= 1-\\sum^{n-1}_{y=0} \\frac{e^{-\\lambda t}(\\lambda t)^y} {y!}\\)\n\\(f(x) = \\frac{1}{\\lambda} exp(-\\frac{x}{\\lambda})\\)\npdf : \\(=(1-\\sum^{n-1}_{y=0}\\frac{e^{-\\lambda t} (\\lambda t)^y}{y!} )\\frac{d}{dy}\\)\n\\(= \\frac{d}{dy}(1-e^{-\\lambda t} -\\sum^{n-1}_{y=1} \\frac{e^{-\\lambda t}(\\lambda t)^y}{y!})\\)\n\\(= \\lambda e^{-\\lambda t} - \\sum^{n-1}_{y=1} \\frac{1}{y!} (t(\\lambda t)^{y-1} \\lambda e^{-\\lambda t} - \\lambda (\\lambda t)^y e^{-\\lambda t})\\)\n\\(= \\lambda e^{-\\lambda t} - \\lambda e^{-\\lambda t} \\sum^{n-1}_{y=1} \\frac{1}{y!} (y (\\lambda t)^{y-1} - (\\lambda t)^y)\\)\n\\(= \\lambda e^{-\\lambda t} + \\lambda e^{-\\lambda t} \\sum^{n-1}_{y=1} (\\frac{(\\lambda t)^{y-1}}{(y-1)!} - \\frac{(\\lambda t)^{y-1}}{(y-1)!})\\)\n\\(= \\lambda e^{-\\lambda t} + \\lambda e^{-\\lambda t} (\\lambda t - 1 + \\frac{\\lambda t^2}{2!} - \\lambda t + \\dots \\frac{\\lambda t^2}{3!} - \\frac{\\lambda t^2}{2!} + \\dots + \\frac{(\\lambda t)^{y-1}}{(y-1)!} - \\frac{(\\lambda t)^{n-2}}{(y-2)!}\\)\n\\(= \\lambda e^{-\\lambda t} - \\lambda e^{-\\lambda t}(\\frac{(\\lambda t)^{y-1}}{(y-1)!} - 1)\\)\n\\(= \\frac{\\lambda}{\\Gamma(y)}(\\lambda t)^{y-1} e^{-\\lambda t} \\dots\\)\n\\(\\star \\Gamma(t) = (y-1)!\\)\n\\(= \\frac{t^{y-1} e^{-\\lambda t}}{\\lambda^{-y} \\Gamma(y)}\\)\n\\(y\\)에 \\(\\alpha\\)를 놓으면\n\\(\\therefore f(x) = \\frac{t^{\\alpha -1}e^{-\\lambda t}}{\\lambda^{-\\alpha}\\Gamma(\\alpha)}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW3.html#수업과제-4.",
    "href": "posts/ts/2023-01-05-ts_HW3.html#수업과제-4.",
    "title": "Theoritical Statistics HW3",
    "section": "수업과제 4.",
    "text": "수업과제 4.\n\\(E(S^2) = \\sigma^2\\) 증명\nanswer\n표본분산 \\(S^2 = \\frac{1}{n-1}\\sum^n_{i=1} (X_i - \\bar{X})^2\\)\n\\(E(S^2) = E(\\frac{1}{n-1} \\sum^n_{i=1}(X_i - \\bar{X})^2)\\)\n\\(= \\frac{1}{n-1} E(\\sum^n_{i=1}(X_i - \\bar{X})^2)\\)\n\\(\\star\\)\n\\(\\sum^n_{i=1}(X_i - \\mu)^2 = \\sum^n_{i=1}(X_i - \\bar{X}_n + \\bar{X}_n -\\mu)^2\\)\n\\(\\sum^n_{i=1}[(X_i - \\bar{X}_n)^2 + 2(X_i - \\bar{X}_n)(\\bar{X}_n - \\mu) + (\\bar{X}_n - \\mu)^2]\\)\n\\(\\sum^n_{i=1}(X_i - \\bar{X}_n)^2 + n(\\bar{X}_n - \\mu)^2\\)\n\\(\\star\\)\n\\(= \\frac{1}{n-1} E(\\sum^n_{i=1}(X_i - \\mu)^2 - n(\\bar{X}_n - \\mu)^2)\\)\n\\(= \\frac{1}{n-1}(\\sum^n_{i=1} E(X_i-\\mu)^2 - nE(\\bar{X}_n - \\mu)^2)\\)\n\\(= \\frac{1}{n-1}(n \\sigma^2 - n \\frac{\\sigma^2}{n})\\)\n\\(= \\sigma^2\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW3.html#section",
    "href": "posts/ts/2023-01-05-ts_HW3.html#section",
    "title": "Theoritical Statistics HW3",
    "section": "19.",
    "text": "19.\n확률변수 \\(X\\)의 확률밀도함수가 \\(f_X(x) = 2x,0&lt;x&lt;1\\)일 때\n\n(1)\n\\(Y = 3X+2\\)의 확률밀도함수를 구하라.\nanswer\n\\(g(X) = 3X+2\\)\n\\(g^{-1}(Y) = \\frac{Y-2}{3}\\)\n\\(f_Y(y) = f_X(g^{-1}(y))|\\frac{dg^{-1}(y)}{dy}| = f_X(\\frac{x-2}{3}) |\\frac{1}{3}|\\)\n\\(= \\frac{2}{3}\\times \\frac{y-2}{3} = \\frac{2y-4}{9}, 2&lt;y&lt;5\\)\n\n\n(2)\n\\(Y = X^2\\)의 확률밀도함수를 구하라.\nanswer\n\\(g(X) = X^2\\)\nas \\(x\\) is greater than 0, \\(g^{-1}(Y) = \\sqrt{y}\\)\n\\(= f_Y(y) = f_X(g^{-1}(y))\\frac{dg^{-1}(y)}{dy}\\)\n\\(= f_X(\\sqrt{y})\\frac{1}{2\\sqrt{y}}\\)\n\\(= 2\\sqrt{y}\\frac{1}{2\\sqrt{y}}\\)\n\\(= I(0&lt;y&lt;1)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW3.html#section-3",
    "href": "posts/ts/2023-01-05-ts_HW3.html#section-3",
    "title": "Theoritical Statistics HW3",
    "section": "20.",
    "text": "20.\n확률변수 \\(X\\)의 확률밀도함수가 \\(f_X(x) = 3e^{-3x},x&gt;0\\)일 때\n\n(1)\n\\(Y = 2X+5\\)의 확률밀도함수와 확률분포함수를 구하라.\nanswer\n\\(F_Y(y) = P(Y \\le y) = P(X \\le \\frac{y-5}{2}) = F_X(\\frac{y-5}{2})\\)\n\\(f_Y(y) = \\frac{d}{dy} F_y(y) = \\frac{1}{2}f_X(\\frac{y-5}{2}) = \\frac{3}{2}exp(-\\frac{3y-15}{2})I(y&gt;5)\\)\n\n\n(2)\n\\(Y = \\frac{1}{X}\\)의 확률밀도함수와 확률분포함수를 구하라.\nanswer\n\\(F_Y(y) = P(Y \\le y) = P(X \\le \\frac{1}{y}) = F_X(\\frac{1}{y})\\)\n\\(f_y(y) = \\frac{d}{dy}F_y(y) = \\frac{1}{y^2}f_X(\\frac{1}{y}) = \\frac{3}{y^2}exp(-\\frac{3}{y})I(y&gt;0)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW3.html#section-6",
    "href": "posts/ts/2023-01-05-ts_HW3.html#section-6",
    "title": "Theoritical Statistics HW3",
    "section": "42.",
    "text": "42.\n\\(X=B(n,p)\\)일 때 \\(Y = n-X\\)의 분포를 구하라.\nanswer\n\\(M_X(t) = E(e^{tx})=(1-p+pe^t)^n\\)\n\\(M_Y(t) = E(e^{ty}) = E(e^{(n-x)t}) = \\sum^n_{x=0}e^{(n-x)t}\\begin{pmatrix} n \\\\ n-x \\end{pmatrix} p^{n-x}(1-p)^x\\)\n\\(= \\sum^n_{x=0} e^{nt}\\begin{pmatrix} n \\\\ n-x \\end{pmatrix}(pe^{-t})^x(1-p)^x\\)\n\\(= e^{nt}(1-p+pe^{-t})^n \\to\\) mgf of \\(B(n,1-p)\\)\n\\(\\therefore n-x \\sim B(n,1-p)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW3.html#section-7",
    "href": "posts/ts/2023-01-05-ts_HW3.html#section-7",
    "title": "Theoritical Statistics HW3",
    "section": "46.",
    "text": "46.\n\\(X \\sim POI(\\lambda)\\)일 때 \\(E(1+X)^2\\)을 계산하라.\nanswer\n\\(E(X) = \\lambda\\)\n\\(var(X) = \\lambda = E(X^2) - \\{E(X)\\}^2\\)\n\\(E(X^2) = var(X) + \\{E(X)\\}^2 = \\lambda + \\lambda^2\\)\n\\(f(x) = \\frac{\\lambda^x e^{-\\lambda}}{X!}\\)\n\\(E(1+X) = 1+E(X) = 1+\\lambda\\)\n\\(E(1+X)^2 = E(1+2X + X^2) = 1+2E(X) + E(X^2) = 1+2\\lambda + \\lambda + \\lambda^2 = 1+ 3\\lambda + \\lambda^2\\)\n\\(E(1+X)^2 = \\sum^{\\infty}_{x=0}(1+2x+ x^2)\\frac{e^{-\\lambda}\\lambda^x}{x!}\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW3.html#section-8",
    "href": "posts/ts/2023-01-05-ts_HW3.html#section-8",
    "title": "Theoritical Statistics HW3",
    "section": "52.",
    "text": "52.\n어느 전자제품의 수명이 확률변수 \\(X \\sim EXP(100)\\)라고 할 때,\n\\(\\lambda = \\frac{1}{100}\\)\n\\(E(X) = 100\\)\n\\(var(X) = 100^2\\)\n\n(1)\n\\(P(X&gt;30)\\)을 구하라.\nanswer\n\\(P(X&gt;30) = \\int^{\\infty}_{-\\infty} \\lambda e^{-\\lambda x} dx = \\int^{\\infty}_{30} \\frac{1}{100}e^{-\\frac{x}{100}}dx = [-e^{-\\frac{\\lambda}{100}}]^{\\infty}_{30} = e^{-0.3}\\)\n\n\n(2)\n\\(P(X&gt;110)\\)을 구하라.\nanswer\n\\(P(X&gt;110) = \\int^{\\infty}_{110} \\frac{1}{100} e^{-\\frac{x}{100}}dx = [-e^{-\\frac{\\lambda}{100}}]^{\\infty}_{110} = e^{-1.1}\\)\n\n\n(3)\n\\(P(X&gt;110|X&gt;80)\\)을 구하고 (1)의 결과와 비교하라.\nanswer\n\\(P(X&gt;110|X&gt;80) = \\frac{P(X&gt;110)}{P(X&gt;80)} = \\frac{e^{-1.1}}{e^{-0.8}} = e^{-1.1+0.8} = e^{-0.3}\\)\n(1)의 결과와 (3)의 결과가 같다."
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW3.html#section-12",
    "href": "posts/ts/2023-01-05-ts_HW3.html#section-12",
    "title": "Theoritical Statistics HW3",
    "section": "54.",
    "text": "54.\n\\(X \\sim N(\\mu, \\sigma^2)\\)일 때,\n\\(f(x) = \\frac{1}{\\sqrt{2\\pi} \\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\)\n\n(1)\n\\(Y = |X-\\mu|\\)의 확률밀도함수를 구하라.\nanswer\n\\(F_Y(y) = P(Y \\le y) = P(|X-\\mu| \\le y) = P(\\mu-y \\le X \\le \\mu+y) = F_X(\\mu + y) - F_X(\\mu - y)\\)\n\\(f_y(y) = \\frac{d}{dy}\\{F_X(\\mu + y) - F_X(\\mu - y) \\} = f_X (\\mu + y) + f_X(\\mu - y) = \\frac{2}{\\sqrt{2\\pi}\\sigma} exp(-\\frac{y^2}{2\\sigma^2}) I(y&gt;0)\\)\n\n\n(2)\n\\(Y = exp(X)\\)의 확률밀도함수를 구하라.(이를 로그 정규확률밀도함수라고 한다.)\nanswer\n\\(Y = e^X\\)\n\\(g(y) = e^X\\)\n\\(g^{-1}(y) = ln(y)\\)\n\\((g^{-1}(y))^{' }= \\frac{1}{y}\\)\n\\(f_y(y) = f_X(g^{-1}(y))(\\frac{d g^{-1}(y) }{dy} ) I(y&gt;0) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(lny - \\mu)^2}{2\\sigma^2}} \\times \\frac{1}{y}\\)\n\\(= \\frac{1}{y\\sigma\\sqrt{2\\pi}}exp(-\\frac{(lny - \\mu)^2}{2\\sigma^2})I(y&gt;0)\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW3.html#section-15",
    "href": "posts/ts/2023-01-05-ts_HW3.html#section-15",
    "title": "Theoritical Statistics HW3",
    "section": "65.",
    "text": "65.\n확률변수들 \\(X_i(i=1,2,\\dots,k)\\)는 서로 독립이며 \\(B(n,p)\\)분포를 따른다고 하자,\n이떄 \\(\\sum^k_{i=1}X_i\\)의 적률생성함수를 구하고 그의 분포가 \\(B(nk,p)\\)임을 보여라.\nanswer\n\\(M_X(t) = E(e^{tx}) = (e^t + q)^n\\)\n\\(M_{\\sum^k_{i=1}X_i}(t) = E(e^{tX_1 + tX_2 + \\dots+tX_k}) = E(e^{tX_1}e^{tX_2}\\dots e^{tX_k})\\)\nBecause those are independent, \\(= E(e^{tX_1})E(e^{tX_2})\\dots E(e^{tX_k})\\)\n\\(= (pe^{tx} + q)^n(pe^t+q)^n \\dots (pe^t+q)^n = (pe^{tx} + q)^{kn}\\)\n\\(M_{\\sum^k_{i=1}X_i}^{'}(t) = kn(pe^{tx}+q)^{kn-1}pe^{tx}\\)\n\\(M_{\\sum^k_{i=1}X_i}^{'}(0) = kn(p+q)^{kn-1}p = knp = E(\\sum^k_{i=1}X_i)\\)\n\\(M_{\\sum^k_{i=1}X_i}^{''}(t) = kn(kn-1)(pe^{tx}+q)^{kn-2}p^2e^{2tx} + kn(pe^{tx} + 1)^{kn-1}pe^{tx}\\)\n\\(M_{\\sum^k_{i=1}X_i}^{''}(0) = kn(kn-1)p^2 + knp = k^2n^2p^2 - knp^2 + knp\\)\n\\(var(\\sum^k_{i=1}X_i) = k^2n^2p^2 - knp^2 + knp - k^2n^2p^2 = knp(1-p) = knpq\\)"
  },
  {
    "objectID": "posts/ts/2023-01-05-ts_HW3.html#section-16",
    "href": "posts/ts/2023-01-05-ts_HW3.html#section-16",
    "title": "Theoritical Statistics HW3",
    "section": "68.",
    "text": "68.\n확률변수 \\(X\\)가 \\(GAM(k,\\theta)\\)를 따르면 임의의 상수 \\(c\\)에 대해 \\(cX\\)는 \\(GAM(k,c\\theta)\\)를 따름을 보여라.\nanswer\n\\(E(X) = k \\theta\\), \\(var(X) = k \\theta^2\\), \\(f(x;k,\\theta) = \\frac{1}{\\theta^2 \\Gamma(k)} x^{k-1} e^{-\\frac{x}{\\theta}}\\)\n\\(E(cX) = ck\\theta\\), \\(var(cX) = c^2 var(X) = c^2k\\theta^2\\)\n\\(g(y) = \\frac{Y}{c}\\)\n\\(f_Y(y) = f_X(x) |\\frac{dx}{dy}|I(x&gt;0)\\)\n\\(= f_X(g^{-1}(y)|\\frac{dg^{-1}(y)}{dy}|I(g^{-1}(y) &gt;0)\\)\n\\(= \\frac{1}{\\theta^k \\Gamma(k)} (\\frac{y}{c})^{k-1} e^{-\\frac{x}{c\\theta}}\\frac{1}{c}\\)\n\\(= \\frac{1}{c^k\\theta^k \\Gamma(k)} y^{k-1}e^{-\\frac{x}{c\\theta}} \\sim GAM(k,c\\theta)\\)"
  }
]