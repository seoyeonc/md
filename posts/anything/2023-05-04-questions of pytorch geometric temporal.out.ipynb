{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Questions of PyTorch Geometric Temporal\n",
        "\n",
        "SEOYEON CHOI  \n",
        "2023-05-04\n",
        "\n",
        "> PyTorch Geometric Temporal\n",
        "\n",
        "# PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models\n",
        "\n",
        "Reference: [Paper](https://arxiv.org/pdf/2104.07788.pdf),\n",
        "[Website](https://pytorch-geometric-temporal.readthedocs.io/en/latest/notes/introduction.html?highlight=web#web-traffic-prediction)\n",
        "\n",
        "## Applications\n",
        "\n",
        "### Epidemiological Forecasting"
      ],
      "id": "ddf8c8d7-dc0b-4cf4-ba91-2d85f6f316d7"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n",
        "from torch_geometric_temporal.signal import temporal_signal_split\n",
        "\n",
        "loader = ChickenpoxDatasetLoader()\n",
        "\n",
        "dataset = loader.get_dataset()\n",
        "\n",
        "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)"
      ],
      "id": "04f5f8c4-a40e-4ea3-b32a-6be14cf2977a"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric_temporal.nn.recurrent import DCRNN\n",
        "\n",
        "class RecurrentGCN(torch.nn.Module):\n",
        "    def __init__(self, node_features):\n",
        "        super(RecurrentGCN, self).__init__()\n",
        "        self.recurrent = DCRNN(node_features, 32, 1)\n",
        "        self.linear = torch.nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        h = self.recurrent(x, edge_index, edge_weight)\n",
        "        h = F.relu(h)\n",
        "        h = self.linear(h)\n",
        "        return h"
      ],
      "id": "8c4319ad-e582-4ca8-82eb-ac7a8df40b54"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:40<00:00,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 1]) torch.Size([20]) torch.Size([20, 20])"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "model = RecurrentGCN(node_features = 4)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in tqdm(range(200)):\n",
        "    cost = 0\n",
        "    for time, snapshot in enumerate(train_dataset):\n",
        "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
        "        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
        "    cost = cost / (time+1)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    \n",
        "###########################################################\n",
        "# I added this to check the shape.\n",
        "print(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)"
      ],
      "id": "4f9e7cc9-b274-4d6b-a33a-2e5dbedd6acf"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 1.0247"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "cost = 0\n",
        "for time, snapshot in enumerate(test_dataset):\n",
        "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
        "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
        "cost = cost / (time+1)\n",
        "cost = cost.item()\n",
        "print(\"MSE: {:.4f}\".format(cost))\n",
        "# >>> MSE: 1.0232"
      ],
      "id": "cdc34f29-43d7-4061-8621-54f5be838023"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "#### Shape Check (1)"
      ],
      "id": "3a7642f9-eb84-40d3-8c50-f712aa3885fb"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.randn(20, 1)"
      ],
      "id": "970bbf64-954b-4e4b-8920-11ca7e8f1abb"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "b = torch.randn(20)"
      ],
      "id": "294eb463-e8f9-4b71-9049-ab272bc5893c"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "c = a-b"
      ],
      "id": "6cae59b0-7e12-4ad6-bd87-0300787487e6"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 1]) torch.Size([20]) torch.Size([20, 20])"
          ]
        }
      ],
      "source": [
        "print(a.size(),b.size(),c.size())"
      ],
      "id": "48ff2abd-20da-4748-8618-12965f836ce7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "#### Doesn’t it have to ‘y_hat’ be the same shape as snapshot.y?\n",
        "\n",
        "-   If we want to compare the y_hat from the model with the values y,\n",
        "    the same shape is appropriate to evaluate."
      ],
      "id": "e63183f4-0c6f-4301-86dc-50594cc4be9d"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [01:27<00:00,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20]) torch.Size([20]) torch.Size([20])"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "model = RecurrentGCN(node_features = 4)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in tqdm(range(200)):\n",
        "    cost = 0\n",
        "    for time, snapshot in enumerate(train_dataset):\n",
        "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n",
        "        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
        "    cost = cost / (time+1)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    \n",
        "###########################################################\n",
        "# I added this to check the shape.\n",
        "print(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)"
      ],
      "id": "33bcb01d-f53e-4199-9d73-6be82b0976f5"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 1.2844"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "cost = 0\n",
        "for time, snapshot in enumerate(test_dataset):\n",
        "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
        "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
        "cost = cost / (time+1)\n",
        "cost = cost.item()\n",
        "print(\"MSE: {:.4f}\".format(cost))\n",
        "# >>> MSE: 1.0232"
      ],
      "id": "46a83329-72b1-4dfc-aa20-8409309f361c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "#### Shape Check (2)"
      ],
      "id": "a56754a6-54d9-4007-b97c-d75edf8170e2"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.randn(20, 1).reshape(-1)"
      ],
      "id": "abcdcf5b-189b-4c40-a0d6-d312ac1f793c"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "b = torch.randn(20)"
      ],
      "id": "5eb322db-0e51-4485-ab8c-24bf78efb697"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "c = a-b"
      ],
      "id": "ad4dd87c-2ce5-4c17-b82a-ddfdd5353f7d"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20]) torch.Size([20]) torch.Size([20])"
          ]
        }
      ],
      "source": [
        "print(a.size(),b.size(),c.size())"
      ],
      "id": "40b68896-40aa-435f-89e0-f4b06e05bf6d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "## Web Traffic Prediction"
      ],
      "id": "78800ed0-50b3-4d58-9447-3f2eaf324abd"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch_geometric_temporal.dataset import WikiMathsDatasetLoader\n",
        "from torch_geometric_temporal.signal import temporal_signal_split\n",
        "\n",
        "loader = WikiMathsDatasetLoader()\n",
        "\n",
        "dataset = loader.get_dataset(lags=14)\n",
        "\n",
        "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)"
      ],
      "id": "05df3cdc-96fe-457b-8008-939ae497250f"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
        "\n",
        "class RecurrentGCN(torch.nn.Module):\n",
        "    def __init__(self, node_features, filters):\n",
        "        super(RecurrentGCN, self).__init__()\n",
        "        self.recurrent = GConvGRU(node_features, filters, 2)\n",
        "        self.linear = torch.nn.Linear(filters, 1)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        h = self.recurrent(x, edge_index, edge_weight)\n",
        "        h = F.relu(h)\n",
        "        h = self.linear(h)\n",
        "        return h"
      ],
      "id": "71f96616-a8f3-442f-9618-408ee0740aec"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [31:26<00:00, 37.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1068, 1]) torch.Size([1068]) torch.Size([1068, 1068])"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "model = RecurrentGCN(node_features=14, filters=32)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in tqdm(range(50)):\n",
        "    for time, snapshot in enumerate(train_dataset):\n",
        "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
        "        cost = torch.mean((y_hat-snapshot.y)**2)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "    \n",
        "###########################################################\n",
        "# I added this to check the shape.\n",
        "print(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)"
      ],
      "id": "8650d45b-bb2d-4a6d-9771-597508f3cdd4"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.7939"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "cost = 0\n",
        "for time, snapshot in enumerate(test_dataset):\n",
        "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
        "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
        "cost = cost / (time+1)\n",
        "cost = cost.item()\n",
        "print(\"MSE: {:.4f}\".format(cost))\n",
        "# >>> MSE: 0.7760"
      ],
      "id": "8ce8a3d4-7b1c-4227-8d4a-912d593e4bf5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "#### Shape Check (1)"
      ],
      "id": "4b0237e3-6573-4a0c-b3cf-b69f2a49ee4e"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.randn(1068, 1)"
      ],
      "id": "ac0fa59f-69b3-48ce-b8ba-75c34817106f"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "b = torch.randn(1068)"
      ],
      "id": "97a6129f-d58a-4d58-b6f5-8a645d202e9e"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "c = a-b"
      ],
      "id": "9bd73bab-5a5d-4271-98fc-06d1fccb8c2d"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1068, 1]) torch.Size([1068]) torch.Size([1068, 1068])"
          ]
        }
      ],
      "source": [
        "print(a.size(),b.size(),c.size())"
      ],
      "id": "f0937567-4b63-49a9-b841-5b80be652626"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "#### If the code changes the shape of y_hat?"
      ],
      "id": "5c4f10da-32d9-49be-a8e7-038965480f83"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [36:39<00:00, 43.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1068, 1]) torch.Size([1068]) torch.Size([1068, 1068])"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "model = RecurrentGCN(node_features=14, filters=32)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in tqdm(range(50)):\n",
        "    for time, snapshot in enumerate(train_dataset):\n",
        "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
        "        cost = torch.mean((y_hat-snapshot.y)**2)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "    \n",
        "###########################################################\n",
        "# I added this to check the shape.\n",
        "print(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)"
      ],
      "id": "e29b15f1-1541-4105-9ed6-24beced59329"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.7807"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "cost = 0\n",
        "for time, snapshot in enumerate(test_dataset):\n",
        "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
        "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
        "cost = cost / (time+1)\n",
        "cost = cost.item()\n",
        "print(\"MSE: {:.4f}\".format(cost))\n",
        "# >>> MSE: 0.7760"
      ],
      "id": "3a306878-cd75-41f7-8482-3d3174d93990"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "#### Shape Check (2)"
      ],
      "id": "24e8b9e7-b032-449b-b200-cb83bb1f5f7f"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.randn(1068, 1).reshape(-1)"
      ],
      "id": "275aab3f-716f-4094-aa60-79dbb6d598a7"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "b = torch.randn(1068)"
      ],
      "id": "d45a21f5-ec06-4863-8229-a05d067f43dc"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "c = a-b"
      ],
      "id": "a5deb374-2b07-40f4-958d-8e80fba72502"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1068]) torch.Size([1068]) torch.Size([1068])"
          ]
        }
      ],
      "source": [
        "print(a.size(),b.size(),c.size())"
      ],
      "id": "d5835ab0-5f8e-4d22-9714-c1d4908316d0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "### References\n",
        "\n",
        "@inproceedings{rozemberczki2021pytorch, author = {Benedek Rozemberczki\n",
        "and Paul Scherer and Yixuan He and George Panagopoulos and Alexander\n",
        "Riedel and Maria Astefanoaei and Oliver Kiss and Ferenc Beres and and\n",
        "Guzman Lopez and Nicolas Collignon and Rik Sarkar}, title = {{PyTorch\n",
        "Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine\n",
        "Learning Models}}, year = {2021}, booktitle={Proceedings of the 30th ACM\n",
        "International Conference on Information and Knowledge Management}, pages\n",
        "= {4564–4573}, }"
      ],
      "id": "8c44119a-04ae-4db7-9eb6-b5aa9de33434"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  }
}