{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b256b519-dd17-4b39-89eb-81e78575cf30",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"Questions of PyTorch Geometric Temporal\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-05-04\"\n",
    "categories:\n",
    "  - PyTorch Geometric Temporal\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3427ff5c-43cf-4aa8-85fc-aad67c7464ce",
   "metadata": {},
   "source": [
    "> PyTorch Geometric Temporal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448eca93-4d69-410d-afd1-f259eba32597",
   "metadata": {},
   "source": [
    "# PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50493a97-0844-4e72-b27b-4b25d9fa9918",
   "metadata": {},
   "source": [
    "Reference: [Paper](https://arxiv.org/pdf/2104.07788.pdf), [Website](https://pytorch-geometric-temporal.readthedocs.io/en/latest/notes/introduction.html?highlight=web#web-traffic-prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032e3958-4ec4-4330-af2b-831c5a2b1209",
   "metadata": {},
   "source": [
    "## Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65fbc2-71b9-4e02-b09f-608ab2fd354a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Epidemiological Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f5f8c4-a40e-4ea3-b32a-6be14cf2977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "\n",
    "loader = ChickenpoxDatasetLoader()\n",
    "\n",
    "dataset = loader.get_dataset()\n",
    "\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4319ad-e582-4ca8-82eb-ac7a8df40b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = DCRNN(node_features, 32, 1)\n",
    "        self.linear = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f9e7cc9-b274-4d6b-a33a-2e5dbedd6acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:40<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1]) torch.Size([20]) torch.Size([20, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = RecurrentGCN(node_features = 4)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(200)):\n",
    "    cost = 0\n",
    "    for time, snapshot in enumerate(train_dataset):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "    cost = cost / (time+1)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "###########################################################\n",
    "# I added this to check the shape.\n",
    "print(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdc34f29-43d7-4061-8621-54f5be838023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.0247\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "cost = 0\n",
    "for time, snapshot in enumerate(test_dataset):\n",
    "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "cost = cost / (time+1)\n",
    "cost = cost.item()\n",
    "print(\"MSE: {:.4f}\".format(cost))\n",
    "# >>> MSE: 1.0232"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ce12c-25a7-4fc8-a2db-b55998539055",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3301f067-9e48-47c2-a6cc-e6a4c12a78d9",
   "metadata": {},
   "source": [
    "#### Shape Check (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "970bbf64-954b-4e4b-8920-11ca7e8f1abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "294eb463-e8f9-4b71-9049-ab272bc5893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cae59b0-7e12-4ad6-bd87-0300787487e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48ff2abd-20da-4748-8618-12965f836ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1]) torch.Size([20]) torch.Size([20, 20])\n"
     ]
    }
   ],
   "source": [
    "print(a.size(),b.size(),c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb9c5d-0745-4a5c-a095-374b7de599d7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609f8ba-cda7-4174-9ec8-dd9efd9159da",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Doesn't it have to 'y_hat' be the same shape as snapshot.y?\n",
    "\n",
    "- If we want to compare the y_hat from the model with the values y, the same shape is appropriate to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33bcb01d-f53e-4199-9d73-6be82b0976f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:27<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20]) torch.Size([20]) torch.Size([20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = RecurrentGCN(node_features = 4)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(200)):\n",
    "    cost = 0\n",
    "    for time, snapshot in enumerate(train_dataset):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr).reshape(-1)\n",
    "        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "    cost = cost / (time+1)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "###########################################################\n",
    "# I added this to check the shape.\n",
    "print(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46a83329-72b1-4dfc-aa20-8409309f361c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.2844\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "cost = 0\n",
    "for time, snapshot in enumerate(test_dataset):\n",
    "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "cost = cost / (time+1)\n",
    "cost = cost.item()\n",
    "print(\"MSE: {:.4f}\".format(cost))\n",
    "# >>> MSE: 1.0232"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e087555-eac1-408f-9fba-63d3ed97dbd7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61def45-41ed-41bb-9683-e43173f0ac14",
   "metadata": {},
   "source": [
    "#### Shape Check (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abcdcf5b-189b-4c40-a0d6-d312ac1f793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(20, 1).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5eb322db-0e51-4485-ab8c-24bf78efb697",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad4dd87c-2ce5-4c17-b82a-ddfdd5353f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40b68896-40aa-435f-89e0-f4b06e05bf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20]) torch.Size([20]) torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "print(a.size(),b.size(),c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c2130a-fad7-4cfd-9d40-a01d9e69aa81",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd96a0cd-c7a3-4bd0-bec6-1e0c91dc03a8",
   "metadata": {},
   "source": [
    "## Web Traffic Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05df3cdc-96fe-457b-8008-939ae497250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.dataset import WikiMathsDatasetLoader\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "\n",
    "loader = WikiMathsDatasetLoader()\n",
    "\n",
    "dataset = loader.get_dataset(lags=14)\n",
    "\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71f96616-a8f3-442f-9618-408ee0740aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, filters):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = GConvGRU(node_features, filters, 2)\n",
    "        self.linear = torch.nn.Linear(filters, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8650d45b-bb2d-4a6d-9771-597508f3cdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [31:26<00:00, 37.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1068, 1]) torch.Size([1068]) torch.Size([1068, 1068])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = RecurrentGCN(node_features=14, filters=32)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(50)):\n",
    "    for time, snapshot in enumerate(train_dataset):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        cost = torch.mean((y_hat-snapshot.y)**2)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "###########################################################\n",
    "# I added this to check the shape.\n",
    "print(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ce8a3d4-7b1c-4227-8d4a-912d593e4bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.7939\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "cost = 0\n",
    "for time, snapshot in enumerate(test_dataset):\n",
    "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "cost = cost / (time+1)\n",
    "cost = cost.item()\n",
    "print(\"MSE: {:.4f}\".format(cost))\n",
    "# >>> MSE: 0.7760"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f125ed5b-7415-4505-a1bd-066a06689148",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319fd323-d1f8-46ac-96d7-3e613db22af3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Shape Check (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac0fa59f-69b3-48ce-b8ba-75c34817106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1068, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97a6129f-d58a-4d58-b6f5-8a645d202e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(1068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bd73bab-5a5d-4271-98fc-06d1fccb8c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0937567-4b63-49a9-b841-5b80be652626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1068, 1]) torch.Size([1068]) torch.Size([1068, 1068])\n"
     ]
    }
   ],
   "source": [
    "print(a.size(),b.size(),c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea4d2d6-e83e-47fe-96de-5d39cbee8b5b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f3ca6-f8f4-4439-9d91-10582694e170",
   "metadata": {},
   "source": [
    "####  If the code changes the shape of y_hat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e29b15f1-1541-4105-9ed6-24beced59329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [36:39<00:00, 43.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1068, 1]) torch.Size([1068]) torch.Size([1068, 1068])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = RecurrentGCN(node_features=14, filters=32)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(50)):\n",
    "    for time, snapshot in enumerate(train_dataset):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        cost = torch.mean((y_hat-snapshot.y)**2)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "###########################################################\n",
    "# I added this to check the shape.\n",
    "print(y_hat.shape,snapshot.y.shape,(y_hat-snapshot.y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a306878-cd75-41f7-8482-3d3174d93990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.7807\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "cost = 0\n",
    "for time, snapshot in enumerate(test_dataset):\n",
    "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "cost = cost / (time+1)\n",
    "cost = cost.item()\n",
    "print(\"MSE: {:.4f}\".format(cost))\n",
    "# >>> MSE: 0.7760"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd09ef-1c66-4da8-9c10-b1e1a3af3a13",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e3db8-46ea-4bb9-a187-fb523f727e6e",
   "metadata": {},
   "source": [
    "#### Shape Check (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "275aab3f-716f-4094-aa60-79dbb6d598a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1068, 1).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d45a21f5-ec06-4863-8229-a05d067f43dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(1068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5deb374-2b07-40f4-958d-8e80fba72502",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5835ab0-5f8e-4d22-9714-c1d4908316d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1068]) torch.Size([1068]) torch.Size([1068])\n"
     ]
    }
   ],
   "source": [
    "print(a.size(),b.size(),c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a0ae1a-23f4-49d7-ac15-12d86518915d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a92357b-97af-4dc5-b78f-db6c1ca66e36",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "::: {#refs}\n",
    "@inproceedings{rozemberczki2021pytorch,\n",
    "                author = {Benedek Rozemberczki and Paul Scherer and Yixuan He and George Panagopoulos and Alexander Riedel and Maria Astefanoaei and Oliver Kiss and Ferenc Beres and and Guzman Lopez and Nicolas Collignon and Rik Sarkar},\n",
    "                title = {{PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models}},\n",
    "                year = {2021},\n",
    "                booktitle={Proceedings of the 30th ACM International Conference on Information and Knowledge Management},\n",
    "                pages = {4564–4573},\n",
    "}\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd57eb-12ab-4850-a2b7-fb3a9165b054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
