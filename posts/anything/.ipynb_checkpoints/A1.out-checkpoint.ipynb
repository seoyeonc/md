{
 "cells": [
  {
   "cell_type": "raw",
   "id": "797e8d95-d6a1-49d7-b2c3-9408d17ba638",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"A1: 강화학습 (1) – bandit\"\n",
    "author: \"최규빈\"\n",
    "date: \"2023-08-29\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec013ed-a572-48b2-93eb-1ffe0a33a9a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 강의영상\n",
    "\n",
    "<https://youtu.be/playlist?list=PLQqh36zP38-zoOHd7w3N5q9Jc5P34Ux8X&si=MdJTHM3a27MCAssp>\n",
    "\n",
    "# 환경셋팅\n",
    "\n",
    "`-` 설치 (코랩)\n",
    "\n",
    "``` python\n",
    "!pip install -q swig\n",
    "!pip install gymnasium\n",
    "!pip install gymnasium[box2d]\n",
    "```\n",
    "\n",
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd03e1-fba4-4aaa-8416-b0459d792cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium\n",
      "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cloudpickle>=1.2.0\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q swig\n",
    "!pip install gymnasium\n",
    "!pip install gymnasium[box2d]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a08935c-5215-44cb-8c5c-c0b0beb3afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a0cc54-2123-434d-a3c5-aac34a4c3630",
   "metadata": {},
   "source": [
    "-   ref: <https://gymnasium.farama.org/index.html>\n",
    "\n",
    "# intro\n",
    "\n",
    "`-` 강화학습(대충설명): 어떠한 “(게임)환경”이 있을때 거기서 “뭘 할지”를\n",
    "학습하는 과업\n",
    "\n",
    "`-` 딥마인드: breakout $\\to$ 알파고\n",
    "\n",
    "-   <https://www.youtube.com/watch?v=TmPfTpjtdgg>\n",
    "\n",
    "`-` 강화학습 미래? (이거 잘하면 먹고 살 수 있을까?)\n",
    "\n",
    "`-` 선행 (강화학습)\n",
    "\n",
    "-   프로그래밍 지식: 파이썬, 클래스에 대한 이해 //\n",
    "    <https://guebin.github.io/PP2023/> 10wk-2 이후\n",
    "-   딥러닝 기본지식: DNN // <https://guebin.github.io/DL2022/> 3wk-02 ~\n",
    "    4wk-02\n",
    "-   수학적인 지식: 마코프과정\n",
    "\n",
    "# Game1: bandit\n",
    "\n",
    "`-` 문제설명: 두 개의 버튼이 있다. 버튼0을 누르면 1의 보상을, 버튼1을\n",
    "누르면 100의 보상을 준다고 가정\n",
    "\n",
    "`-` 처음에 어떤 행동을 해야 하는가? —\\> ??? 처음에는 아는게 없음 —\\>\n",
    "일단 “아무거나” 눌러보자.\n",
    "\n",
    "`-` 버튼을 아무거나 누르는 함수를 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a70d3d83-5d1f-4e95-aa37-b8c62ab0c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = ['button0', 'button1'] \n",
    "action = np.random.choice(action_space)\n",
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cdf7d0-caa7-41a9-9323-2892308ac95c",
   "metadata": {},
   "source": [
    "`-` 보상을 주는 함수를 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9904638b-4f7d-4297-afca-099343661519",
   "metadata": {},
   "outputs": [],
   "source": [
    "if action == 'button0': # button0을 눌렀다면 \n",
    "    reward = 1 \n",
    "else: # button1을 눌렀다면 \n",
    "    reward = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0fbba1-3a4b-4463-ad8a-8d7ab5923208",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b6290d-e876-4766-b727-2d5ffd05dca3",
   "metadata": {},
   "source": [
    "`-` 아무버튼이나 10번정도 눌러보면서 데이터를 쌓아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "190e8df9-2421-45cf-a557-b81f096a7ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button0 1\n",
      "button1 100\n",
      "button1 100\n",
      "button0 1"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    action = np.random.choice(action_space)\n",
    "    if action == 'button0': \n",
    "        reward = 1 \n",
    "    else: \n",
    "        reward = 100     \n",
    "    print(action,reward) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97467bc-a8fc-4242-9c31-ae23dc8ded44",
   "metadata": {},
   "source": [
    "`-` 깨달았음: `button0`을 누르면 1점을 받고, `button1`을 누르면 100점을\n",
    "받는 “환경”이구나? $\\to$ `button1`을 누르는 “동작”을 해야하는\n",
    "상황이구나?\n",
    "\n",
    "-   여기에서 $\\to$의 과정을 체계화 시킨 학문이 강화학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3095c3b3-ea5b-4fb9-b262-b370f61a83dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    action = action_space[1]\n",
    "    if action == 'button0': \n",
    "        reward = 1 \n",
    "    else: \n",
    "        reward = 100     \n",
    "    print(action,reward) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3912d53-0261-4f55-8cf7-57df407c8201",
   "metadata": {},
   "source": [
    "-   게임 클리어\n",
    "\n",
    "`-` 강화학습: 환경을 이해 $\\to$ 행동을 결정\n",
    "\n",
    "***위의 과정이 잘 되었다는 의미로 사용하는 문장들***\n",
    "\n",
    "-   강화학습이 성공적으로 잘 되었다.\n",
    "-   에이전트가 환경의 과제를 완료했다.\n",
    "-   에이전트가 환경에서 성공적으로 학습했다.\n",
    "-   에이전트가 올바른 행동을 학습했다.\n",
    "-   게임 클리어 (비공식)\n",
    "\n",
    "`-` 게임이 클리어 되었다는 것을 의미하는 지표를 정하고 싶다.\n",
    "\n",
    "-   첫 생각: `button1`을 누르는 순간 게임클리어로 보면 되지 않나?\n",
    "-   두번째 생각: 아니지? 우연히 누를수도 있잖아?\n",
    "-   게임클리어조건: 최근 20번의 보상이 1900점 이상이면 게임이 클리어\n",
    "    되었다고 생각하자.[1]\n",
    "\n",
    "`-` 무지한자 – 게임을 클리어할 수 없다.\n",
    "\n",
    "[1] `button1`을 눌러야 하는건 맞지만 20번에 한번정도의 실수는 눈감아\n",
    "주는 조건"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdd0f72b-5433-42e4-b504-e19b1b4ad1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1   action= 1   reward= 100 reward20= 100   \n",
      "n_try = 2   action= 0   reward= 1   reward20= 101   \n",
      "n_try = 3   action= 0   reward= 1   reward20= 102   \n",
      "n_try = 4   action= 0   reward= 1   reward20= 103   \n",
      "n_try = 5   action= 1   reward= 100 reward20= 203   \n",
      "n_try = 6   action= 1   reward= 100 reward20= 303   \n",
      "n_try = 7   action= 1   reward= 100 reward20= 403   \n",
      "n_try = 8   action= 0   reward= 1   reward20= 404   \n",
      "n_try = 9   action= 1   reward= 100 reward20= 504   \n",
      "n_try = 10  action= 1   reward= 100 reward20= 604   \n",
      "n_try = 11  action= 0   reward= 1   reward20= 605   \n",
      "n_try = 12  action= 0   reward= 1   reward20= 606   \n",
      "n_try = 13  action= 1   reward= 100 reward20= 706   \n",
      "n_try = 14  action= 0   reward= 1   reward20= 707   \n",
      "n_try = 15  action= 0   reward= 1   reward20= 708   \n",
      "n_try = 16  action= 0   reward= 1   reward20= 709   \n",
      "n_try = 17  action= 1   reward= 100 reward20= 809   \n",
      "n_try = 18  action= 1   reward= 100 reward20= 909   \n",
      "n_try = 19  action= 0   reward= 1   reward20= 910   \n",
      "n_try = 20  action= 1   reward= 100 reward20= 1010  \n",
      "n_try = 21  action= 1   reward= 100 reward20= 1010  \n",
      "n_try = 22  action= 0   reward= 1   reward20= 1010  \n",
      "n_try = 23  action= 0   reward= 1   reward20= 1010  \n",
      "n_try = 24  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 25  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 26  action= 0   reward= 1   reward20= 1010  \n",
      "n_try = 27  action= 1   reward= 100 reward20= 1010  \n",
      "n_try = 28  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 29  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 30  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 31  action= 0   reward= 1   reward20= 1109  \n",
      "n_try = 32  action= 0   reward= 1   reward20= 1109  \n",
      "n_try = 33  action= 0   reward= 1   reward20= 1010  \n",
      "n_try = 34  action= 0   reward= 1   reward20= 1010  \n",
      "n_try = 35  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 36  action= 0   reward= 1   reward20= 1109  \n",
      "n_try = 37  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 38  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 39  action= 0   reward= 1   reward20= 1109  \n",
      "n_try = 40  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 41  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 42  action= 1   reward= 100 reward20= 1208  \n",
      "n_try = 43  action= 1   reward= 100 reward20= 1307  \n",
      "n_try = 44  action= 1   reward= 100 reward20= 1307  \n",
      "n_try = 45  action= 1   reward= 100 reward20= 1307  \n",
      "n_try = 46  action= 1   reward= 100 reward20= 1406  \n",
      "n_try = 47  action= 1   reward= 100 reward20= 1406  \n",
      "n_try = 48  action= 1   reward= 100 reward20= 1406  \n",
      "n_try = 49  action= 1   reward= 100 reward20= 1406  \n",
      "n_try = 50  action= 1   reward= 100 reward20= 1406  "
     ]
    }
   ],
   "source": [
    "action_space = [0,1]\n",
    "rewards = [] \n",
    "for t in range(50): # 10000번을 해도 못깸 \n",
    "    action = np.random.choice(action_space) # 무지한자의 행동 (찍어) \n",
    "    if action == 0: \n",
    "        reward = 1 \n",
    "        rewards.append(reward)\n",
    "    else: \n",
    "        reward = 100\n",
    "        rewards.append(reward)\n",
    "    print(\n",
    "        f\"n_try = {t+1}\\t\"\n",
    "        f\"action= {action}\\t\"\n",
    "        f\"reward= {reward}\\t\"\n",
    "        f\"reward20= {sum(rewards[-20:])}\\t\"\n",
    "    )\n",
    "    if np.sum(rewards[-20:])>=1900:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f734d6-c248-4697-8cf4-af6074782b12",
   "metadata": {},
   "source": [
    "`-` 깨달은자 – 게임클리어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eed38ded-287b-455a-ac78-00648ccda990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1   action= 1   reward= 100 reward20= 100   \n",
      "n_try = 2   action= 1   reward= 100 reward20= 200   \n",
      "n_try = 3   action= 1   reward= 100 reward20= 300   \n",
      "n_try = 4   action= 1   reward= 100 reward20= 400   \n",
      "n_try = 5   action= 1   reward= 100 reward20= 500   \n",
      "n_try = 6   action= 1   reward= 100 reward20= 600   \n",
      "n_try = 7   action= 1   reward= 100 reward20= 700   \n",
      "n_try = 8   action= 1   reward= 100 reward20= 800   \n",
      "n_try = 9   action= 1   reward= 100 reward20= 900   \n",
      "n_try = 10  action= 1   reward= 100 reward20= 1000  \n",
      "n_try = 11  action= 1   reward= 100 reward20= 1100  \n",
      "n_try = 12  action= 1   reward= 100 reward20= 1200  \n",
      "n_try = 13  action= 1   reward= 100 reward20= 1300  \n",
      "n_try = 14  action= 1   reward= 100 reward20= 1400  \n",
      "n_try = 15  action= 1   reward= 100 reward20= 1500  \n",
      "n_try = 16  action= 1   reward= 100 reward20= 1600  \n",
      "n_try = 17  action= 1   reward= 100 reward20= 1700  \n",
      "n_try = 18  action= 1   reward= 100 reward20= 1800  \n",
      "n_try = 19  action= 1   reward= 100 reward20= 1900  "
     ]
    }
   ],
   "source": [
    "action_space = [0,1]\n",
    "rewards = [] \n",
    "for t in range(50): # 10000번을 해도 못깸 \n",
    "    #action = np.random.choice(action_space) # 무지한자의 행동 (찍어) \n",
    "    action = 1\n",
    "    if action == 0: \n",
    "        reward = 1 \n",
    "        rewards.append(reward)\n",
    "    else: \n",
    "        reward = 100\n",
    "        rewards.append(reward)\n",
    "    print(\n",
    "        f\"n_try = {t+1}\\t\"\n",
    "        f\"action= {action}\\t\"\n",
    "        f\"reward= {reward}\\t\"\n",
    "        f\"reward20= {sum(rewards[-20:])}\\t\"\n",
    "    )\n",
    "    if np.sum(rewards[-20:])>=1900:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8489e00-9728-4e7b-a827-b14a0c00af82",
   "metadata": {},
   "source": [
    "# 수정1: `action_space`의 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c397a13-6784-42fc-91e8-75ebbc051b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = gym.spaces.Discrete(2)\n",
    "action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f8d622-cb9e-4186-b118-ec489de05092",
   "metadata": {},
   "source": [
    "`-` 좋은점1: sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f522c24a-7947-4f4f-b19d-b51f1224cfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e82a9c6-5159-4c80-8c43-7cdb4b20e4fa",
   "metadata": {},
   "source": [
    "`-` 좋은점2: in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13c5c948-755a-409b-aa4a-cc9b76c05a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "0 in action_space # 유효한 액션을 검사 -- 0은 유효한 액션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8c12ef4-d45c-4015-948e-e2aa63b42d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 in action_space # 유효한 액션을 검사 -- 1은 유효한 액션 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ed458e5-ddb4-4bf6-989b-2ed34cb039d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 in action_space # 유효한 액션을 검사 -- 2는 유효하지 않은 액션 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650abde7-eed8-4ce2-ac52-e52eaa112428",
   "metadata": {},
   "source": [
    "`-` 코드 1차수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e50169bd-4db0-4e18-aa76-d2ee35790e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1   action= 0   reward= 1   reward20= 1 \n",
      "n_try = 2   action= 0   reward= 1   reward20= 2 \n",
      "n_try = 3   action= 1   reward= 100 reward20= 102   \n",
      "n_try = 4   action= 1   reward= 100 reward20= 202   \n",
      "n_try = 5   action= 1   reward= 100 reward20= 302   \n",
      "n_try = 6   action= 0   reward= 1   reward20= 303   \n",
      "n_try = 7   action= 0   reward= 1   reward20= 304   \n",
      "n_try = 8   action= 0   reward= 1   reward20= 305   \n",
      "n_try = 9   action= 0   reward= 1   reward20= 306   \n",
      "n_try = 10  action= 1   reward= 100 reward20= 406   \n",
      "n_try = 11  action= 0   reward= 1   reward20= 407   \n",
      "n_try = 12  action= 0   reward= 1   reward20= 408   \n",
      "n_try = 13  action= 0   reward= 1   reward20= 409   \n",
      "n_try = 14  action= 1   reward= 100 reward20= 509   \n",
      "n_try = 15  action= 1   reward= 100 reward20= 609   \n",
      "n_try = 16  action= 0   reward= 1   reward20= 610   \n",
      "n_try = 17  action= 1   reward= 100 reward20= 710   \n",
      "n_try = 18  action= 0   reward= 1   reward20= 711   \n",
      "n_try = 19  action= 0   reward= 1   reward20= 712   \n",
      "n_try = 20  action= 1   reward= 100 reward20= 812   \n",
      "n_try = 21  action= 1   reward= 100 reward20= 911   \n",
      "n_try = 22  action= 0   reward= 1   reward20= 911   \n",
      "n_try = 23  action= 0   reward= 1   reward20= 812   \n",
      "n_try = 24  action= 0   reward= 1   reward20= 713   \n",
      "n_try = 25  action= 0   reward= 1   reward20= 614   \n",
      "n_try = 26  action= 0   reward= 1   reward20= 614   \n",
      "n_try = 27  action= 0   reward= 1   reward20= 614   \n",
      "n_try = 28  action= 0   reward= 1   reward20= 614   \n",
      "n_try = 29  action= 0   reward= 1   reward20= 614   \n",
      "n_try = 30  action= 0   reward= 1   reward20= 515   \n",
      "n_try = 31  action= 1   reward= 100 reward20= 614   \n",
      "n_try = 32  action= 1   reward= 100 reward20= 713   \n",
      "n_try = 33  action= 0   reward= 1   reward20= 713   \n",
      "n_try = 34  action= 1   reward= 100 reward20= 713   \n",
      "n_try = 35  action= 1   reward= 100 reward20= 713   \n",
      "n_try = 36  action= 0   reward= 1   reward20= 713   \n",
      "n_try = 37  action= 1   reward= 100 reward20= 713   \n",
      "n_try = 38  action= 0   reward= 1   reward20= 713   \n",
      "n_try = 39  action= 1   reward= 100 reward20= 812   \n",
      "n_try = 40  action= 0   reward= 1   reward20= 713   \n",
      "n_try = 41  action= 1   reward= 100 reward20= 713   \n",
      "n_try = 42  action= 0   reward= 1   reward20= 713   \n",
      "n_try = 43  action= 1   reward= 100 reward20= 812   \n",
      "n_try = 44  action= 1   reward= 100 reward20= 911   \n",
      "n_try = 45  action= 1   reward= 100 reward20= 1010  \n",
      "n_try = 46  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 47  action= 1   reward= 100 reward20= 1208  \n",
      "n_try = 48  action= 0   reward= 1   reward20= 1208  \n",
      "n_try = 49  action= 0   reward= 1   reward20= 1208  \n",
      "n_try = 50  action= 0   reward= 1   reward20= 1208  "
     ]
    }
   ],
   "source": [
    "action_space = gym.spaces.Discrete(2) \n",
    "rewards = [] \n",
    "for t in range(50): \n",
    "    action = action_space.sample()\n",
    "    #action = 1\n",
    "    if action == 0: \n",
    "        reward = 1 \n",
    "        rewards.append(reward)\n",
    "    else: \n",
    "        reward = 100\n",
    "        rewards.append(reward)\n",
    "    print(\n",
    "        f\"n_try = {t+1}\\t\"\n",
    "        f\"action= {action}\\t\"\n",
    "        f\"reward= {reward}\\t\"\n",
    "        f\"reward20= {sum(rewards[-20:])}\\t\"\n",
    "    )\n",
    "    if np.sum(rewards[-20:])>=1900:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08df7392-eb22-4bbc-bf18-e9c303afe80e",
   "metadata": {},
   "source": [
    "# 수정2: Env 클래스\n",
    "\n",
    "`-` env 클래스 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c0c0620-e9f5-4b2d-a464-21d462974a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandit: \n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            return 1 \n",
    "        else: \n",
    "            return 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "188ec458-5a17-48c4-ba7b-eb6362cf2fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1   action= 1   reward= 100 reward20= 100   \n",
      "n_try = 2   action= 1   reward= 100 reward20= 200   \n",
      "n_try = 3   action= 1   reward= 100 reward20= 300   \n",
      "n_try = 4   action= 1   reward= 100 reward20= 400   \n",
      "n_try = 5   action= 1   reward= 100 reward20= 500   \n",
      "n_try = 6   action= 1   reward= 100 reward20= 600   \n",
      "n_try = 7   action= 1   reward= 100 reward20= 700   \n",
      "n_try = 8   action= 1   reward= 100 reward20= 800   \n",
      "n_try = 9   action= 1   reward= 100 reward20= 900   \n",
      "n_try = 10  action= 1   reward= 100 reward20= 1000  \n",
      "n_try = 11  action= 1   reward= 100 reward20= 1100  \n",
      "n_try = 12  action= 1   reward= 100 reward20= 1200  \n",
      "n_try = 13  action= 1   reward= 100 reward20= 1300  \n",
      "n_try = 14  action= 1   reward= 100 reward20= 1400  \n",
      "n_try = 15  action= 1   reward= 100 reward20= 1500  \n",
      "n_try = 16  action= 1   reward= 100 reward20= 1600  \n",
      "n_try = 17  action= 1   reward= 100 reward20= 1700  \n",
      "n_try = 18  action= 1   reward= 100 reward20= 1800  \n",
      "n_try = 19  action= 1   reward= 100 reward20= 1900  "
     ]
    }
   ],
   "source": [
    "action_space = gym.spaces.Discrete(2) \n",
    "env = Bandit()\n",
    "rewards = []\n",
    "for t in range(50): \n",
    "    #action = action_space.sample()\n",
    "    action = 1\n",
    "    reward = env.step(action)\n",
    "    rewards.append(reward)\n",
    "    print(\n",
    "        f\"n_try = {t+1}\\t\"\n",
    "        f\"action= {action}\\t\"\n",
    "        f\"reward= {reward}\\t\"\n",
    "        f\"reward20= {sum(rewards[-20:])}\\t\"\n",
    "    )\n",
    "    if np.sum(rewards[-20:])>=1900:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0ff80-377d-45a1-8144-402af23facc5",
   "metadata": {},
   "source": [
    "# 수정3: Agnet 클래스\n",
    "\n",
    "`-` Agent 클래스를 만들자. (액션을 하고, 환경에서 받은 reward를 간직)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dec4bbb-05aa-441e-88b1-5ee2a28f2a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent1:\n",
    "    def __init__(self):\n",
    "        self.action_space = gym.spaces.Discrete(2) \n",
    "        self.action = None \n",
    "        self.reward = None \n",
    "        self.actions = [] \n",
    "        self.rewards = []\n",
    "    def act(self):\n",
    "        self.action = self.action_space.sample() # 무지한자 \n",
    "        #self.action = 1 # 깨달은 자\n",
    "    def save_experience(self):\n",
    "        self.actions.append(self.action)\n",
    "        self.rewards.append(self.reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ffc7df-0cb5-46c9-a765-0181b100088e",
   "metadata": {},
   "source": [
    "— 대충 아래와 같은 느낌으로 코드가 돌아가요 —\n",
    "\n",
    "**시점0**: init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc6800c5-1150-45bb-a92d-7353102a6bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Bandit()\n",
    "agent = Agent1() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a4ed1ca-2d30-424c-bb61-0e88f9568023",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.action, agent.reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0584ebf0-e818-4b90-a90b-528cdaba3862",
   "metadata": {},
   "source": [
    "**시점1**: agent \\>\\> env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b3031b7-dd5f-4794-a5f4-ca3efa4530c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.act()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82edf659-c379-45f2-86b5-777740919145",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.action, agent.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44281576-2b8e-45fb-9864-c0b2ebcc8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.agent_action = agent.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b874ee2e-d31a-4e4c-804f-853bb4378b13",
   "metadata": {},
   "source": [
    "**시점2**: agent \\<\\< env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eada8cbf-4634-485d-a1b8-a2b6a1b45871",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.reward = env.step(env.agent_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "563f8f89-0306-473d-9160-7bcf1588adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.action, agent.reward, env.agent_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69a4d505-421c-404b-80aa-592f44c8b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.actions,agent.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b60a437-83eb-4acc-9c23-aeb0c140f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save_experience()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cac5485-34be-4d46-b630-37d8bfd5a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.actions,agent.rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4c305a-f5e4-4649-a71c-1dab7e7dd23d",
   "metadata": {},
   "source": [
    "– 전체코드 –"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f788df4-f84e-4e6e-8a21-ec3490e27674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1   action= 0   reward= 1   reward20= 1 \n",
      "n_try = 2   action= 1   reward= 100 reward20= 101   \n",
      "n_try = 3   action= 1   reward= 100 reward20= 201   \n",
      "n_try = 4   action= 0   reward= 1   reward20= 202   \n",
      "n_try = 5   action= 1   reward= 100 reward20= 302   \n",
      "n_try = 6   action= 0   reward= 1   reward20= 303   \n",
      "n_try = 7   action= 0   reward= 1   reward20= 304   \n",
      "n_try = 8   action= 1   reward= 100 reward20= 404   \n",
      "n_try = 9   action= 0   reward= 1   reward20= 405   \n",
      "n_try = 10  action= 0   reward= 1   reward20= 406   \n",
      "n_try = 11  action= 1   reward= 100 reward20= 506   \n",
      "n_try = 12  action= 0   reward= 1   reward20= 507   \n",
      "n_try = 13  action= 1   reward= 100 reward20= 607   \n",
      "n_try = 14  action= 1   reward= 100 reward20= 707   \n",
      "n_try = 15  action= 1   reward= 100 reward20= 807   \n",
      "n_try = 16  action= 1   reward= 100 reward20= 907   \n",
      "n_try = 17  action= 1   reward= 100 reward20= 1007  \n",
      "n_try = 18  action= 1   reward= 100 reward20= 1107  \n",
      "n_try = 19  action= 0   reward= 1   reward20= 1108  \n",
      "n_try = 20  action= 1   reward= 100 reward20= 1208  \n",
      "n_try = 21  action= 0   reward= 1   reward20= 1208  \n",
      "n_try = 22  action= 0   reward= 1   reward20= 1109  \n",
      "n_try = 23  action= 0   reward= 1   reward20= 1010  \n",
      "n_try = 24  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 25  action= 0   reward= 1   reward20= 1010  \n",
      "n_try = 26  action= 0   reward= 1   reward20= 1010  \n",
      "n_try = 27  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 28  action= 0   reward= 1   reward20= 1010  \n",
      "n_try = 29  action= 0   reward= 1   reward20= 1010  \n",
      "n_try = 30  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 31  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 32  action= 1   reward= 100 reward20= 1208  \n",
      "n_try = 33  action= 1   reward= 100 reward20= 1208  \n",
      "n_try = 34  action= 1   reward= 100 reward20= 1208  \n",
      "n_try = 35  action= 0   reward= 1   reward20= 1109  \n",
      "n_try = 36  action= 0   reward= 1   reward20= 1010  \n",
      "n_try = 37  action= 1   reward= 100 reward20= 1010  \n",
      "n_try = 38  action= 1   reward= 100 reward20= 1010  \n",
      "n_try = 39  action= 0   reward= 1   reward20= 1010  \n",
      "n_try = 40  action= 1   reward= 100 reward20= 1010  \n",
      "n_try = 41  action= 0   reward= 1   reward20= 1010  \n",
      "n_try = 42  action= 0   reward= 1   reward20= 1010  \n",
      "n_try = 43  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 44  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 45  action= 0   reward= 1   reward20= 1109  \n",
      "n_try = 46  action= 0   reward= 1   reward20= 1109  \n",
      "n_try = 47  action= 1   reward= 100 reward20= 1109  \n",
      "n_try = 48  action= 0   reward= 1   reward20= 1109  \n",
      "n_try = 49  action= 0   reward= 1   reward20= 1109  \n",
      "n_try = 50  action= 1   reward= 100 reward20= 1109  "
     ]
    }
   ],
   "source": [
    "env = Bandit() \n",
    "agent = Agent1()\n",
    "for t in range(50): \n",
    "    ## 1. main 코드 \n",
    "    # step1: agent >> env \n",
    "    agent.act() \n",
    "    env.agent_action = agent.action\n",
    "    # step2: agent << env \n",
    "    agent.reward = env.step(env.agent_action)\n",
    "    agent.save_experience() \n",
    "\n",
    "    ## 2. 비본질적 코드 \n",
    "    print(\n",
    "        f\"n_try = {t+1}\\t\"\n",
    "        f\"action= {agent.action}\\t\"\n",
    "        f\"reward= {agent.reward}\\t\"\n",
    "        f\"reward20= {sum(agent.rewards[-20:])}\\t\"\n",
    "    )\n",
    "    if np.sum(agent.rewards[-20:])>=1900:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9524637-2440-4d0b-ad18-2f24764cc30d",
   "metadata": {},
   "source": [
    "# 수정4: 학습과정을 포함\n",
    "\n",
    "`-` Game1에 대한 생각:\n",
    "\n",
    "-   사실 강화학습은 “환경을 이해 $\\to$ 행동을 결정” 의 과정에서 $\\to$의\n",
    "    과정을 수식화 한 것이다.\n",
    "-   그런데 지금까지 했던 코드는 환경(env)를 이해하는 순간 에이전트가\n",
    "    최적의 행동(action)[1]을 직관적으로 결정하였으므로 기계가 스스로\n",
    "    학습을 했다고 볼 수 없다.\n",
    "\n",
    "`-` 지금까지의 코드 복습\n",
    "\n",
    "1.  클래스를 선언하는 부분\n",
    "    -   Env 클래스의 선언\n",
    "    -   Agent 클래스의 선언\n",
    "2.  환경과 에이전트를 인스턴스화 (초기화)\n",
    "3.  for loop를 반복하여 게임을 진행\n",
    "    -   메인코드: (1) agent $\\to$ env (2) agent $\\leftarrow$ env\n",
    "    -   비본질적코드: 학습과정을 display, 학습의 종료조건체크\n",
    "\n",
    "`-` 앞으로 구성할 코드의 형태: 에이전트가 데이터를 보고 스스로\n",
    "`button1`을 눌러야 한다는 생각을 했으면 좋겠음.\n",
    "\n",
    "1.  클래스를 선언하는 부분\n",
    "    -   Env 클래스의 선언\n",
    "    -   **Agent 클래스의 선언** // \\<—- `학습의 과정이 포함되어야 한다`,\n",
    "        `act함수의 수정`, `learn함수의 추가`\n",
    "2.  환경과 에이전트를 인스턴스화 (초기화)\n",
    "3.  for loop를 반복하여 게임을 진행\n",
    "    -   **메인코드** (1) agent $\\to$ env (2) agent $\\leftarrow$ env //\n",
    "        \\<—- `agent가 데이터를 분석하고 학습하는 과정이 추가`\n",
    "    -   비본질적코드: 학습과정을 display, 학습의 종료조건체크\n",
    "\n",
    "`-` 에이전트가 학습을 어떻게 하는가? 아래와 같이 버튼을 누르도록 한다면\n",
    "\n",
    "-   버튼0을 누를 확률: $\\frac{q_0}{q_0+q_1}$\n",
    "-   버튼1을 누를 확률: $\\frac{q_1}{q_0+q_1}$\n",
    "\n",
    "시간이 지날수록 버튼1을 주로 누를 것이다.\n",
    "\n",
    "`-` 걱정: $t=0$ 이면 어쩌지? $t=1$이면 어쩌지?… $\\to$ 해결책:\n",
    "일정시간동안 랜덤액션을 하면서 데이터를 쌓고 그 뒤에 $q_0,q_1$을 계산\n",
    "\n",
    "`-` 쌓은 데이터를 바탕으로 환경을 이해하고 action을 뽑는 코드\n",
    "\n",
    "[1] `button1`을 누른다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17846ed9-1a22-4fab-978f-dbce2a7f8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.actions = [0,1,1,0,1,0,0] \n",
    "agent.rewards = [1,101,102,1,99,1,1.2] \n",
    "actions = np.array(agent.actions)\n",
    "rewards = np.array(agent.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e1a9c75-12d6-4f06-a9ad-f40b2b01b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 = rewards[actions == 0].mean()\n",
    "q1 = rewards[actions == 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "450b3144-2b92-4b4b-b77e-0d44ad3a3e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.q = np.array([q0,q1]) \n",
    "agent.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "549734b0-8ccf-44d3-bafd-2f669ef6a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = agent.q / agent.q.sum()\n",
    "prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a899fc5-975e-4e60-898d-2545f4bfd283",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = np.random.choice([0,1], p= agent.q / agent.q.sum())\n",
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137b6d1e-791f-4f45-b22a-424cb7db06d9",
   "metadata": {},
   "source": [
    "`-` 최종코드정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c02f44fe-91c9-4ac7-a715-6d965889a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandit: \n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            return 1 \n",
    "        else: \n",
    "            return 100 \n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.action_space = gym.spaces.Discrete(2) \n",
    "        self.action = None \n",
    "        self.reward = None \n",
    "        self.actions = [] \n",
    "        self.rewards = []\n",
    "        self.q = np.array([0,0]) \n",
    "        self.n_experience = 0 \n",
    "    def act(self):\n",
    "        if self.n_experience<30: \n",
    "            self.action = self.action_space.sample() \n",
    "        else: \n",
    "            self.action = np.random.choice([0,1], p= self.q / self.q.sum())\n",
    "    def save_experience(self):\n",
    "        self.actions.append(self.action)\n",
    "        self.rewards.append(self.reward)\n",
    "        self.n_experience += 1 \n",
    "    def learn(self):\n",
    "        if self.n_experience<30: \n",
    "            pass \n",
    "        else: \n",
    "            actions = np.array(self.actions)\n",
    "            rewards = np.array(self.rewards)\n",
    "            q0 = rewards[actions == 0].mean()\n",
    "            q1 = rewards[actions == 1].mean()\n",
    "            self.q = np.array([q0,q1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "16591779-af01-412a-ab5a-798c9141b63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1   action= 0   reward= 1   reward20= 1 q = [0 0]\n",
      "n_try = 2   action= 0   reward= 1   reward20= 2 q = [0 0]\n",
      "n_try = 3   action= 1   reward= 100 reward20= 102   q = [0 0]\n",
      "n_try = 4   action= 0   reward= 1   reward20= 103   q = [0 0]\n",
      "n_try = 5   action= 0   reward= 1   reward20= 104   q = [0 0]\n",
      "n_try = 6   action= 0   reward= 1   reward20= 105   q = [0 0]\n",
      "n_try = 7   action= 0   reward= 1   reward20= 106   q = [0 0]\n",
      "n_try = 8   action= 0   reward= 1   reward20= 107   q = [0 0]\n",
      "n_try = 9   action= 1   reward= 100 reward20= 207   q = [0 0]\n",
      "n_try = 10  action= 0   reward= 1   reward20= 208   q = [0 0]\n",
      "n_try = 11  action= 1   reward= 100 reward20= 308   q = [0 0]\n",
      "n_try = 12  action= 1   reward= 100 reward20= 408   q = [0 0]\n",
      "n_try = 13  action= 1   reward= 100 reward20= 508   q = [0 0]\n",
      "n_try = 14  action= 0   reward= 1   reward20= 509   q = [0 0]\n",
      "n_try = 15  action= 1   reward= 100 reward20= 609   q = [0 0]\n",
      "n_try = 16  action= 0   reward= 1   reward20= 610   q = [0 0]\n",
      "n_try = 17  action= 0   reward= 1   reward20= 611   q = [0 0]\n",
      "n_try = 18  action= 0   reward= 1   reward20= 612   q = [0 0]\n",
      "n_try = 19  action= 1   reward= 100 reward20= 712   q = [0 0]\n",
      "n_try = 20  action= 1   reward= 100 reward20= 812   q = [0 0]\n",
      "n_try = 21  action= 0   reward= 1   reward20= 812   q = [0 0]\n",
      "n_try = 22  action= 1   reward= 100 reward20= 911   q = [0 0]\n",
      "n_try = 23  action= 0   reward= 1   reward20= 812   q = [0 0]\n",
      "n_try = 24  action= 1   reward= 100 reward20= 911   q = [0 0]\n",
      "n_try = 25  action= 1   reward= 100 reward20= 1010  q = [0 0]\n",
      "n_try = 26  action= 1   reward= 100 reward20= 1109  q = [0 0]\n",
      "n_try = 27  action= 1   reward= 100 reward20= 1208  q = [0 0]\n",
      "n_try = 28  action= 1   reward= 100 reward20= 1307  q = [0 0]\n",
      "n_try = 29  action= 1   reward= 100 reward20= 1307  q = [0 0]\n",
      "n_try = 30  action= 1   reward= 100 reward20= 1406  q = [  1. 100.]\n",
      "n_try = 31  action= 1   reward= 100 reward20= 1406  q = [  1. 100.]\n",
      "n_try = 32  action= 1   reward= 100 reward20= 1406  q = [  1. 100.]\n",
      "n_try = 33  action= 1   reward= 100 reward20= 1406  q = [  1. 100.]\n",
      "n_try = 34  action= 1   reward= 100 reward20= 1505  q = [  1. 100.]\n",
      "n_try = 35  action= 1   reward= 100 reward20= 1505  q = [  1. 100.]\n",
      "n_try = 36  action= 1   reward= 100 reward20= 1604  q = [  1. 100.]\n",
      "n_try = 37  action= 1   reward= 100 reward20= 1703  q = [  1. 100.]\n",
      "n_try = 38  action= 1   reward= 100 reward20= 1802  q = [  1. 100.]\n",
      "n_try = 39  action= 1   reward= 100 reward20= 1802  q = [  1. 100.]\n",
      "n_try = 40  action= 1   reward= 100 reward20= 1802  q = [  1. 100.]\n",
      "n_try = 41  action= 1   reward= 100 reward20= 1901  q = [  1. 100.]"
     ]
    }
   ],
   "source": [
    "env = Bandit() \n",
    "agent = Agent()\n",
    "for t in range(50): \n",
    "    ## 1. main 코드 \n",
    "    # step1: agent >> env \n",
    "    agent.act() \n",
    "    env.agent_action = agent.action\n",
    "    # step2: agent << env \n",
    "    agent.reward = env.step(env.agent_action)\n",
    "    agent.save_experience() \n",
    "    # step3: learn \n",
    "    agent.learn()\n",
    "    ## 2. 비본질적 코드 \n",
    "    print(\n",
    "        f\"n_try = {t+1}\\t\"\n",
    "        f\"action= {agent.action}\\t\"\n",
    "        f\"reward= {agent.reward}\\t\"\n",
    "        f\"reward20= {sum(agent.rewards[-20:])}\\t\"\n",
    "        f\"q = {agent.q}\"\n",
    "    )\n",
    "    if np.sum(agent.rewards[-20:])>=1900:\n",
    "        break "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
