<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="SEOYEON CHOI">
<meta name="dcterms.date" content="2022-11-21">

<title>Seoyeon’s Blog for classes - RNN (11주차)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Seoyeon’s Blog for classes</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../about.html" aria-current="page">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/seoyeonc/md/"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">RNN (11주차)</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title d-none d-lg-block">RNN (11주차)</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Special Topics in Machine Learning</div>
                <div class="quarto-category">순환신경망</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>SEOYEON CHOI </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 21, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../about.html" class="sidebar-item-text sidebar-link">About</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Posts</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ap/index.html" class="sidebar-item-text sidebar-link">Advanced Probability Theory</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-07-ap_1wk.html" class="sidebar-item-text sidebar-link">1주차: 측도론</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-14-ap-2wk.html" class="sidebar-item-text sidebar-link">2주차: 측도론</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-21-ap-3wk.html" class="sidebar-item-text sidebar-link">3주차: 측도론</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-28-ap-4wk.html" class="sidebar-item-text sidebar-link">4주차: 측도론</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/rl/index.html" class="sidebar-item-text sidebar-link">Advanced Regression Analysis</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2023-02-23-rl-final_term.html" class="sidebar-item-text sidebar-link">Advanced Regression Analysis Final Term</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2023-03-02-graduation_test.html" class="sidebar-item-text sidebar-link">Advanced Regression Analysis GT</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2023-02-22-rl-mid_term.html" class="sidebar-item-text sidebar-link">Advanced Regression Analysis Mid Term</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-09-21-rl_HW1.html" class="sidebar-item-text sidebar-link">Regression HW 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-10-23-rl-HW2.html" class="sidebar-item-text sidebar-link">Regression HW 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-21-rl-HW3.html" class="sidebar-item-text sidebar-link">Regression HW 3</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-12-08-rl-HW4.html" class="sidebar-item-text sidebar-link">Regression HW 4</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-12-11-rl-Ch10.html" class="sidebar-item-text sidebar-link">고급회귀분석 CH10</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-09-21-rl_CH03, CH04.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH03, CH04</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-14-rl_CH06, CH07.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH06, CH07</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-23-rl-CH10.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH10</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-12-05-rl-CH11.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH11</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-28-rl-CH13.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH13</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ct/index.html" class="sidebar-item-text sidebar-link">Coding Test</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-15-Coding_Test_Algorithm.html" class="sidebar-item-text sidebar-link">Algorithm</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-02-12-Coding_Test.html" class="sidebar-item-text sidebar-link">ArrayList &amp; LinkedList</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-01-Coding_Test_Greedy.html" class="sidebar-item-text sidebar-link">Chapter 03 Greedy</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/Untitled.html" class="sidebar-item-text sidebar-link">Map</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-03-12-Coding_Test_Queue.html" class="sidebar-item-text sidebar-link">Queue</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-03-05-Coding_Test_Stack.html" class="sidebar-item-text sidebar-link">Stack</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-03-22-Coding_Test_Tree.html" class="sidebar-item-text sidebar-link">Tree</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-15-Coding_Test_interfunction.html" class="sidebar-item-text sidebar-link">내장함수</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-23-Coding_Test_Q2.html" class="sidebar-item-text sidebar-link">두 큐 합 같게 만들기(Done)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-21-Coding_Test_Q1.html" class="sidebar-item-text sidebar-link">성격 유형 검사하기(Done)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-30-Coding_Test_Q3.html" class="sidebar-item-text sidebar-link">코딩 테스트 공부(Done)</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ml_basic/index.html" class="sidebar-item-text sidebar-link">Machine Learning basic</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-29-Lasso and Ridge.html" class="sidebar-item-text sidebar-link">Lasso and Ridge</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-28-Linear Regression, Logistic Regression.html" class="sidebar-item-text sidebar-link">Linear Regression, Logistic Regression</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-28-Principal Component Analysis.html" class="sidebar-item-text sidebar-link">Principal Component Analysis</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-23-Support Vector Machine.html" class="sidebar-item-text sidebar-link">Support Vector Machine</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ml/index.html" class="sidebar-item-text sidebar-link">Special Topics in Machine Learning</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-07-13wk.html" class="sidebar-item-text sidebar-link">A1: 깊은복사와 얕은복사 (12주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-19-Assignment-1-Copy1.html" class="sidebar-item-text sidebar-link">Assignment 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-19-ml_7w.html" class="sidebar-item-text sidebar-link">CNN (7주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-26-ml_8w_1.html" class="sidebar-item-text sidebar-link">CNN (8주차) 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-26-ml_8w_2.html" class="sidebar-item-text sidebar-link">CNN (8주차) 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-29-13wk-2-final.html" class="sidebar-item-text sidebar-link">Deep Learning final example</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-07-ml_1w.html" class="sidebar-item-text sidebar-link">DNN (1주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-14-ml_2w.html" class="sidebar-item-text sidebar-link">DNN (2주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-21-ml_3w.html" class="sidebar-item-text sidebar-link">DNN (3주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-29-ml_4w.html" class="sidebar-item-text sidebar-link">DNN (4주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-05-ml-5w.html" class="sidebar-item-text sidebar-link">DNN (5주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-12-ml-6w.html" class="sidebar-item-text sidebar-link">DNN (6주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-21-Extra-1.html" class="sidebar-item-text sidebar-link">Extra-1: 추천시스템</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-21-Extra-2.html" class="sidebar-item-text sidebar-link">Extra-2: 생성모형(GAN)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-23-Extra-3.html" class="sidebar-item-text sidebar-link">Extra-3: 딥러닝의 기초 (5)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-13-final_seoyeon.html" class="sidebar-item-text sidebar-link">Finalterm</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-05-ml-HW.html" class="sidebar-item-text sidebar-link">Homework</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-07-ml.html" class="sidebar-item-text sidebar-link">Intro</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-02-ml-midterm.html" class="sidebar-item-text sidebar-link">Midterm</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-09-ml-10w.html" class="sidebar-item-text sidebar-link">RNN (10주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-21-ml-11w.html" class="sidebar-item-text sidebar-link active">RNN (11주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-30-12wk.html" class="sidebar-item-text sidebar-link">RNN (12주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-08-13wk.html" class="sidebar-item-text sidebar-link">RNN (13주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-02-ml_9w.html" class="sidebar-item-text sidebar-link">RNN (9주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-14-study.html" class="sidebar-item-text sidebar-link">study</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ts/index.html" class="sidebar-item-text sidebar-link">Theoritical Statistics</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-25-ts-final term.html" class="sidebar-item-text sidebar-link">Theoritical Statistics Final term</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-03-03-ts-final_qanda.html" class="sidebar-item-text sidebar-link">Theoritical Statistics Final term 6 Explanation</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-03-03-graduation_test.html" class="sidebar-item-text sidebar-link">Theoritical Statistics GT</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-05-ts_HW1.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-05-ts_HW2.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-05-ts_HW3.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW3</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-09-ts_HW4.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW4</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-12-ts_HW5.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW5</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-14-ts_HW6.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW6</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-18-ts_HW7.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW7</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-18-ts-HW8.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW8</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-21-ts-HW9.html" class="sidebar-item-text sidebar-link">Theoritical Statistics HW9</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-14-ts_Mid term.html" class="sidebar-item-text sidebar-link">Theoritical Statistics Mid term</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2022-12-31-ts_1.html" class="sidebar-item-text sidebar-link">확률변수와 확률분포</a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#import" id="toc-import" class="nav-link active" data-scroll-target="#import">import</a></li>
  <li><a href="#define-some-funtions" id="toc-define-some-funtions" class="nav-link" data-scroll-target="#define-some-funtions">Define some funtions</a></li>
  <li><a href="#exam4-abacad-2" id="toc-exam4-abacad-2" class="nav-link" data-scroll-target="#exam4-abacad-2">Exam4: AbAcAd (2)</a>
  <ul class="collapse">
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data">data</a></li>
  <li><a href="#순환신경망-구현1-손으로-직접구현-리뷰" id="toc-순환신경망-구현1-손으로-직접구현-리뷰" class="nav-link" data-scroll-target="#순환신경망-구현1-손으로-직접구현-리뷰">순환신경망 구현1 (손으로 직접구현) – 리뷰</a></li>
  <li><a href="#순환신경망-구현2-with-rnncell-hidden-node-2" id="toc-순환신경망-구현2-with-rnncell-hidden-node-2" class="nav-link" data-scroll-target="#순환신경망-구현2-with-rnncell-hidden-node-2">순환신경망 구현2 (with RNNCell, hidden node 2)</a></li>
  <li><a href="#순환신경망-구현3-with-rnn-hidden-node-2-성공" id="toc-순환신경망-구현3-with-rnn-hidden-node-2-성공" class="nav-link" data-scroll-target="#순환신경망-구현3-with-rnn-hidden-node-2-성공">순환신경망 구현3 (with RNN, hidden node 2) – 성공</a></li>
  <li><a href="#순환신경망-구현4-with-rnn-hidden-node-3-성공" id="toc-순환신경망-구현4-with-rnn-hidden-node-3-성공" class="nav-link" data-scroll-target="#순환신경망-구현4-with-rnn-hidden-node-3-성공">순환신경망 구현4 (with RNN, hidden node 3) – 성공</a></li>
  </ul></li>
  <li><a href="#gpu-실험" id="toc-gpu-실험" class="nav-link" data-scroll-target="#gpu-실험">GPU 실험</a>
  <ul class="collapse">
  <li><a href="#len-20-hidden-nodes" id="toc-len-20-hidden-nodes" class="nav-link" data-scroll-target="#len-20-hidden-nodes">20000 len + 20 hidden nodes</a></li>
  <li><a href="#len-20-hidden-nodes-역전파주석처리" id="toc-len-20-hidden-nodes-역전파주석처리" class="nav-link" data-scroll-target="#len-20-hidden-nodes-역전파주석처리">20000 len + 20 hidden nodes + 역전파주석처리</a></li>
  <li><a href="#len-20-hidden-nodes-1" id="toc-len-20-hidden-nodes-1" class="nav-link" data-scroll-target="#len-20-hidden-nodes-1">2000 len + 20 hidden nodes</a></li>
  <li><a href="#len-20-hidden-nodes-역전파주석처리-1" id="toc-len-20-hidden-nodes-역전파주석처리-1" class="nav-link" data-scroll-target="#len-20-hidden-nodes-역전파주석처리-1">2000 len + 20 hidden nodes + 역전파주석처리</a></li>
  <li><a href="#len-5000-hidden-nodes" id="toc-len-5000-hidden-nodes" class="nav-link" data-scroll-target="#len-5000-hidden-nodes">2000 len + 5000 hidden nodes</a></li>
  <li><a href="#len-5000-hidden-nodes-역전파주석처리" id="toc-len-5000-hidden-nodes-역전파주석처리" class="nav-link" data-scroll-target="#len-5000-hidden-nodes-역전파주석처리">2000 len + 5000 hidden nodes + 역전파주석처리</a></li>
  <li><a href="#실험결과-요약" id="toc-실험결과-요약" class="nav-link" data-scroll-target="#실험결과-요약">실험결과 요약</a></li>
  </ul></li>
  <li><a href="#exam5-abcabc" id="toc-exam5-abcabc" class="nav-link" data-scroll-target="#exam5-abcabc">Exam5: abcabC</a>
  <ul class="collapse">
  <li><a href="#data-1" id="toc-data-1" class="nav-link" data-scroll-target="#data-1">data</a></li>
  <li><a href="#rnn" id="toc-rnn" class="nav-link" data-scroll-target="#rnn">RNN</a></li>
  <li><a href="#lstm" id="toc-lstm" class="nav-link" data-scroll-target="#lstm">LSTM</a></li>
  <li><a href="#rnn-vs-lstm-성능비교실험" id="toc-rnn-vs-lstm-성능비교실험" class="nav-link" data-scroll-target="#rnn-vs-lstm-성능비교실험">RNN vs LSTM 성능비교실험</a></li>
  </ul></li>
  <li><a href="#exam6-abcdabcd" id="toc-exam6-abcdabcd" class="nav-link" data-scroll-target="#exam6-abcdabcd">Exam6: abcdabcD</a>
  <ul class="collapse">
  <li><a href="#data-2" id="toc-data-2" class="nav-link" data-scroll-target="#data-2">data</a></li>
  <li><a href="#rnn-vs-lstm-성능비교실험-1" id="toc-rnn-vs-lstm-성능비교실험-1" class="nav-link" data-scroll-target="#rnn-vs-lstm-성능비교실험-1">RNN vs LSTM 성능비교실험</a></li>
  </ul></li>
  <li><a href="#lstm의-계산과정" id="toc-lstm의-계산과정" class="nav-link" data-scroll-target="#lstm의-계산과정">LSTM의 계산과정</a>
  <ul class="collapse">
  <li><a href="#data-abab" id="toc-data-abab" class="nav-link" data-scroll-target="#data-abab">data: abaB</a></li>
  <li><a href="#epoch-ver1-with-torch.nn.lstmcell" id="toc-epoch-ver1-with-torch.nn.lstmcell" class="nav-link" data-scroll-target="#epoch-ver1-with-torch.nn.lstmcell">1 epoch ver1 (with torch.nn.LSTMCell)</a></li>
  <li><a href="#epoch-ver2-완전-손으로-구현" id="toc-epoch-ver2-완전-손으로-구현" class="nav-link" data-scroll-target="#epoch-ver2-완전-손으로-구현">1 epoch ver2 (완전 손으로 구현)</a></li>
  <li><a href="#epoch-ver3-with-torch.nn.lstm" id="toc-epoch-ver3-with-torch.nn.lstm" class="nav-link" data-scroll-target="#epoch-ver3-with-torch.nn.lstm">1 epoch ver3 (with torch.nn.LSTM)</a></li>
  </ul></li>
  <li><a href="#lstm은-왜-강한가" id="toc-lstm은-왜-강한가" class="nav-link" data-scroll-target="#lstm은-왜-강한가">LSTM은 왜 강한가?</a>
  <ul class="collapse">
  <li><a href="#data-abab-1" id="toc-data-abab-1" class="nav-link" data-scroll-target="#data-abab-1">data: abaB</a></li>
  <li><a href="#epoch" id="toc-epoch" class="nav-link" data-scroll-target="#epoch">1000 epoch</a></li>
  <li><a href="#시각화" id="toc-시각화" class="nav-link" data-scroll-target="#시각화">시각화</a></li>
  <li><a href="#시각화의-해석i" id="toc-시각화의-해석i" class="nav-link" data-scroll-target="#시각화의-해석i">시각화의 해석I</a></li>
  <li><a href="#시각화의-해석ii" id="toc-시각화의-해석ii" class="nav-link" data-scroll-target="#시각화의-해석ii">시각화의 해석II</a></li>
  <li><a href="#lstm의-알고리즘-리뷰-i-수식위주" id="toc-lstm의-알고리즘-리뷰-i-수식위주" class="nav-link" data-scroll-target="#lstm의-알고리즘-리뷰-i-수식위주">LSTM의 알고리즘 리뷰 I (수식위주)</a></li>
  <li><a href="#lstm의-알고리즘-리뷰-ii-느낌위주" id="toc-lstm의-알고리즘-리뷰-ii-느낌위주" class="nav-link" data-scroll-target="#lstm의-알고리즘-리뷰-ii-느낌위주">LSTM의 알고리즘 리뷰 II (느낌위주)</a></li>
  <li><a href="#lstm이-강한이유" id="toc-lstm이-강한이유" class="nav-link" data-scroll-target="#lstm이-강한이유">LSTM이 강한이유</a></li>
  </ul></li>
  <li><a href="#참고자료들" id="toc-참고자료들" class="nav-link" data-scroll-target="#참고자료들">참고자료들</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>기계학습 특강 (11주차) 11월16일 [순환신경망– abc예제, abdc예제, abcde예제, AbAcAd예제]</p>
<section id="import" class="level2">
<h2 class="anchored" data-anchor-id="import">import</h2>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code></pre></div>
</div>
</section>
<section id="define-some-funtions" class="level2">
<h2 class="anchored" data-anchor-id="define-some-funtions">Define some funtions</h2>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(txt,mapping):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [mapping[key] <span class="cf">for</span> key <span class="kw">in</span> txt] </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>soft <span class="op">=</span> torch.nn.Softmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>tanh <span class="op">=</span> torch.nn.Tanh()</span></code></pre></div>
</div>
</section>
<section id="exam4-abacad-2" class="level2">
<h2 class="anchored" data-anchor-id="exam4-abacad-2">Exam4: AbAcAd (2)</h2>
<section id="data" class="level3">
<h3 class="anchored" data-anchor-id="data">data</h3>
<p><code>-</code> 기존의 정리방식</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'AbAcAd'</span>)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>txt[:<span class="dv">10</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>txt_x <span class="op">=</span> txt[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>txt_y <span class="op">=</span> txt[<span class="dv">1</span>:]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>txt_x[:<span class="dv">5</span>],txt_y[:<span class="dv">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_x,{<span class="st">'A'</span>:<span class="dv">0</span>,<span class="st">'b'</span>:<span class="dv">1</span>,<span class="st">'c'</span>:<span class="dv">2</span>,<span class="st">'d'</span>:<span class="dv">3</span>}))).<span class="bu">float</span>()</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_y,{<span class="st">'A'</span>:<span class="dv">0</span>,<span class="st">'b'</span>:<span class="dv">1</span>,<span class="st">'c'</span>:<span class="dv">2</span>,<span class="st">'d'</span>:<span class="dv">3</span>}))).<span class="bu">float</span>()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>x,y</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>(tensor([[1., 0., 0., 0.],
         [0., 1., 0., 0.],
         [1., 0., 0., 0.],
         ...,
         [1., 0., 0., 0.],
         [0., 0., 1., 0.],
         [1., 0., 0., 0.]]),
 tensor([[0., 1., 0., 0.],
         [1., 0., 0., 0.],
         [0., 0., 1., 0.],
         ...,
         [0., 0., 1., 0.],
         [1., 0., 0., 0.],
         [0., 0., 0., 1.]]))</code></pre>
</div>
</div>
</section>
<section id="순환신경망-구현1-손으로-직접구현-리뷰" class="level3">
<h3 class="anchored" data-anchor-id="순환신경망-구현1-손으로-직접구현-리뷰">순환신경망 구현1 (손으로 직접구현) – 리뷰</h3>
<p><code>(1)</code> 숙성담당 네트워크</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> rNNCell(torch.nn.Module):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.i2h <span class="op">=</span> torch.nn.Linear(<span class="dv">4</span>,<span class="dv">2</span>) </span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.h2h <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">2</span>) </span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tanh <span class="op">=</span> torch.nn.Tanh()</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,x,hidden):</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        hidden <span class="op">=</span> <span class="va">self</span>.tanh(<span class="va">self</span>.i2h(x)<span class="op">+</span><span class="va">self</span>.h2h(hidden))</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> hidden</span></code></pre></div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>rnncell <span class="op">=</span> rNNCell() <span class="co"># 숙성담당 네트워크 </span></span></code></pre></div>
</div>
<p><code>(2)</code> 조리담당 네트워크</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>cook <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">4</span>) </span></code></pre></div>
</div>
<p><code>(3)</code> 손실함수, 옵티마이저 설계</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() </span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnncell.parameters())<span class="op">+</span><span class="bu">list</span>(cook.parameters()))</span></code></pre></div>
</div>
<p><code>(4)</code> 학습 (6분정도 걸림)</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>x[[<span class="dv">2</span>]].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>torch.Size([1, 4])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="bu">len</span>(x) </span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>): </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1~2</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    ht <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>) </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>        xt,yt <span class="op">=</span> x[[t]], y[[t]]</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        ht <span class="op">=</span> rnncell(xt,ht) </span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>        ot <span class="op">=</span> cook(ht) </span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss <span class="op">+</span> loss_fn(ot,yt) </span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<p><code>(5)</code> 시각화</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="bu">len</span>(x) </span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>hidden <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>) <span class="co"># 599년치 h를 담을 변수 </span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>) <span class="co"># 맹물 </span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>hidden[[<span class="dv">0</span>]] <span class="op">=</span> rnncell(x[[<span class="dv">0</span>]],_water) </span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,T):</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    hidden[[t]] <span class="op">=</span> rnncell(x[[t]],hidden[[t<span class="op">-</span><span class="dv">1</span>]]) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(cook(hidden))</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>yhat</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>tensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],
        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],
        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],
        ...,
        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],
        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],
        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],
       grad_fn=&lt;SoftmaxBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(yhat.data[<span class="op">-</span><span class="dv">15</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="113">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f1160dcaa50&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-17-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="순환신경망-구현2-with-rnncell-hidden-node-2" class="level3">
<h3 class="anchored" data-anchor-id="순환신경망-구현2-with-rnncell-hidden-node-2">순환신경망 구현2 (with RNNCell, hidden node 2)</h3>
<p>ref: <a href="https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html" class="uri">https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html</a></p>
<section id="구현1과-같은-초기값-확인용" class="level4">
<h4 class="anchored" data-anchor-id="구현1과-같은-초기값-확인용">구현1과 같은 초기값 (확인용)</h4>
<p><code>(1)</code> 숙성네트워크</p>
<div class="cell" data-execution_count="114">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>_rnncell <span class="op">=</span> rNNCell() <span class="co"># 숙성담당 네트워크 </span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="115">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>rnncell <span class="op">=</span> torch.nn.RNNCell(<span class="dv">4</span>,<span class="dv">2</span>)</span></code></pre></div>
</div>
<ul>
<li>input_size = 4</li>
<li>hindden_size = 2</li>
</ul>
<p><code>rNNCell()</code> 는 사실 <code>torch.nn.RNNCell()</code>와 같은 동작을 하도록 설계를 하였음.</p>
<p>같은동작을 하는지 확인하기 위해서 동일한 초기상태에서 <code>rNNCell()</code>에 의하여 학습된 결과와 <code>torch.nn.RNNCell()</code>에 의하여 학습된 결과를 비교해보자.</p>
<div class="cell" data-execution_count="116">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>rnncell.weight_ih.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="116">
<pre><code>torch.Size([2, 4])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="117">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>rnncell.bias_ih.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="117">
<pre><code>torch.Size([2])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="118">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>rnncell.weight_hh.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="118">
<pre><code>torch.Size([2, 2])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="119">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>rnncell.bias_hh.shape </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="119">
<pre><code>torch.Size([2])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="120">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>rnncell.weight_ih.data <span class="op">=</span> _rnncell.i2h.weight.data</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>rnncell.bias_ih.data <span class="op">=</span> _rnncell.i2h.bias.data</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>rnncell.weight_hh.data <span class="op">=</span> _rnncell.h2h.weight.data</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>rnncell.bias_hh.data <span class="op">=</span> _rnncell.h2h.bias.data</span></code></pre></div>
</div>
<p>_rnncell 초기값을 rnncell에 넣어주기</p>
<p><code>(2)</code> 조리네트워크</p>
<div class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>cook <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">4</span>) <span class="co"># 숙성된 2차원의 단어를 다시 4차원으로 바꿔줘야지 나중에 softmax취할 수 있음</span></span></code></pre></div>
</div>
<p><code>(3)</code> 손실함수와 옵티마이저</p>
<div class="cell" data-execution_count="122">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnncell.parameters())<span class="op">+</span><span class="bu">list</span>(cook.parameters()))</span></code></pre></div>
</div>
<p><code>(4)</code> 학습</p>
<div class="cell" data-execution_count="123">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="bu">len</span>(x) </span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>):</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1~2</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    ht <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>) </span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>        xt,yt <span class="op">=</span> x[[t]], y[[t]]</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>        ht <span class="op">=</span> rnncell(xt,ht)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>        ot <span class="op">=</span> cook(ht)</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss <span class="op">+</span> loss_fn(ot,yt) </span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<p><code>(5)</code> 시각화</p>
<div class="cell" data-execution_count="124">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>hidden <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="125">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># t=0 </span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>hidden[[<span class="dv">0</span>]] <span class="op">=</span> rnncell(x[[<span class="dv">0</span>]],_water)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co"># t=1~T </span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,T):</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>    hidden[[t]] <span class="op">=</span> rnncell(x[[t]],hidden[[t<span class="op">-</span><span class="dv">1</span>]])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="126">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(cook(hidden))</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>yhat</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="126">
<pre><code>tensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],
        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],
        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],
        ...,
        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],
        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],
        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],
       grad_fn=&lt;SoftmaxBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="127">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(yhat[:<span class="dv">15</span>].data,cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="127">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f1123dd2650&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-31-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="128">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(yhat[<span class="op">-</span><span class="dv">15</span>:].data,cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="128">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f11237d65d0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-32-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>뒷부분갈수록 잘 맞음</p>
</section>
<section id="새로운-초기값" class="level4">
<h4 class="anchored" data-anchor-id="새로운-초기값">새로운 초기값</h4>
<p><code>(1)</code> 숙성네트워크</p>
<div class="cell" data-execution_count="129">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>torch.nn.RNNCell(<span class="dv">4</span>,<span class="dv">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="129">
<pre><code>RNNCell(4, 2)</code></pre>
</div>
</div>
<p>앞 부분은 잘 맞지 않고 뒷부분은 잘 맞을 것!</p>
<p><code>(2)</code> 조리네트워크</p>
<div class="cell" data-execution_count="130">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>cook <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">4</span>) <span class="co"># 숙성된 2차원의 단어를 다시 4차원으로 바꿔줘야지 나중에 softmax취할 수 있음</span></span></code></pre></div>
</div>
<p><code>(3)</code> 손실함수와 옵티마이저</p>
<div class="cell" data-execution_count="131">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnncell.parameters())<span class="op">+</span><span class="bu">list</span>(cook.parameters()))</span></code></pre></div>
</div>
<p><code>(4)</code> 학습</p>
<div class="cell" data-execution_count="132">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="bu">len</span>(x) </span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>):</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1~2</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>    ht <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>) </span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>        xt,yt <span class="op">=</span> x[[t]], y[[t]]</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>        ht <span class="op">=</span> rnncell(xt,ht)</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>        ot <span class="op">=</span> cook(ht)</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss <span class="op">+</span> loss_fn(ot,yt) </span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<p><code>(5)</code> 시각화</p>
<p>x -&gt; h -&gt; o -&gt; yhat(softmax(o))</p>
<p>네트워크만 학습된 상태, 따라서 hiddenlayer를 재구성해줘야 한다.</p>
</section>
</section>
<section id="순환신경망-구현3-with-rnn-hidden-node-2-성공" class="level3">
<h3 class="anchored" data-anchor-id="순환신경망-구현3-with-rnn-hidden-node-2-성공">순환신경망 구현3 (with RNN, hidden node 2) – 성공</h3>
<p>(예비학습)</p>
<p><code>-</code> 네트워크학습이후 yhat을 구하려면 번거로웠음</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>hidden <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>) </span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>hidden[[<span class="dv">0</span>]] <span class="op">=</span> rnncell(x[[<span class="dv">0</span>]],_water)</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,T):</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>    hidden[[t]] <span class="op">=</span> rnncell(x[[t]],hidden[[t<span class="op">-</span><span class="dv">1</span>]])</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(cook(hidden))</span></code></pre></div>
<p><code>-</code> 이렇게 하면 쉽게(?) 구할 수 있음</p>
<div class="cell" data-execution_count="133">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">2</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="134">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>rnn.weight_hh_l0.data <span class="op">=</span> rnncell.weight_hh.data </span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>rnn.weight_ih_l0.data <span class="op">=</span> rnncell.weight_ih.data</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>rnn.bias_hh_l0.data <span class="op">=</span> rnncell.bias_hh.data</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>rnn.bias_ih_l0.data <span class="op">=</span> rnncell.bias_ih.data</span></code></pre></div>
</div>
<p><code>-</code> rnn(x,_water)의 결과는 (1) 599년치 간장 (2) 599번째 간장 이다</p>
<div class="cell" data-execution_count="135">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>rnn(x,_water), hidden</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="135">
<pre><code>((tensor([[-0.1271,  0.9965],
          [-1.0000, -0.9987],
          [ 0.9962,  1.0000],
          ...,
          [ 0.9962,  1.0000],
          [-1.0000, -0.9897],
          [ 0.9959,  1.0000]], grad_fn=&lt;SqueezeBackward1&gt;),
  tensor([[0.9959, 1.0000]], grad_fn=&lt;SqueezeBackward1&gt;)),
 tensor([[-0.2232,  0.9769],
         [-0.9999, -0.9742],
         [ 0.9154,  0.9992],
         ...,
         [ 0.9200,  0.9992],
         [-0.9978, -0.0823],
         [-0.9154,  0.9965]], grad_fn=&lt;IndexPutBackward0&gt;))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="136">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>soft(cook(rnn(x,_water)[<span class="dv">0</span>]))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="136">
<pre><code>tensor([[6.0688e-02, 4.2958e-01, 2.9885e-01, 2.1088e-01],
        [9.9700e-01, 8.2096e-04, 1.3663e-03, 8.1039e-04],
        [2.2782e-03, 3.3203e-01, 3.3260e-01, 3.3309e-01],
        ...,
        [2.2779e-03, 3.3203e-01, 3.3260e-01, 3.3309e-01],
        [9.9692e-01, 8.4633e-04, 1.4012e-03, 8.3072e-04],
        [2.2803e-03, 3.3206e-01, 3.3260e-01, 3.3306e-01]],
       grad_fn=&lt;SoftmaxBackward0&gt;)</code></pre>
</div>
</div>
<p><strong><em>(예비학습결론) torch.nn.RNN(4,2)는 torch.nn.RNNCell(4,2)의 batch 버전이다. (for문이 포함된 버전이다)</em></strong></p>
<hr>
<p>torch.nn.RNN(4,2)를 이용하여 구현하자.</p>
<p><code>(1)</code> 숙성네트워크</p>
<p>선언</p>
<div class="cell" data-execution_count="137">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">2</span>)</span></code></pre></div>
</div>
<p>가중치초기화</p>
<div class="cell" data-execution_count="138">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>_rnncell <span class="op">=</span> torch.nn.RNNCell(<span class="dv">4</span>,<span class="dv">2</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="139">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>rnn.weight_hh_l0.data <span class="op">=</span> _rnncell.weight_hh.data </span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>rnn.weight_ih_l0.data <span class="op">=</span> _rnncell.weight_ih.data</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>rnn.bias_hh_l0.data <span class="op">=</span> _rnncell.bias_hh.data</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>rnn.bias_ih_l0.data <span class="op">=</span> _rnncell.bias_ih.data</span></code></pre></div>
</div>
<p><code>(2)</code> 조리네트워크</p>
<div class="cell" data-execution_count="140">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>cook <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">4</span>) </span></code></pre></div>
</div>
<p><code>(3)</code> 손실함수와 옵티마이저</p>
<div class="cell" data-execution_count="141">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(cook.parameters()))</span></code></pre></div>
</div>
<p><code>(4)</code> 학습</p>
<div class="cell" data-execution_count="142">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>) </span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>):</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>    hidden,hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> cook(hidden) </span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y)</span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<p>결과는 같을 것</p>
<p><code>(5)</code> 시각화1: yhat</p>
<div class="cell" data-execution_count="143">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="144">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(yhat.data[:<span class="dv">15</span>],cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="144">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f1123908710&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-48-output-2.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>처음은 좀 틀렸음 ㅎㅎ</li>
</ul>
<div class="cell" data-execution_count="145">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(yhat.data[<span class="op">-</span><span class="dv">15</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="145">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f11238cac90&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-49-output-2.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>뒤에는 잘맞음</li>
</ul>
<p><strong>실전팁: <code>_water</code> 대신에 <code>hT</code>를 대입 (사실 큰 차이는 없음)</strong></p>
<p>hT는 이미 값이 저장되어 있잖아</p>
<div class="cell" data-execution_count="146">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>rnn(x[:<span class="dv">6</span>],_water),rnn(x[:<span class="dv">6</span>],hT)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="146">
<pre><code>((tensor([[-0.9912, -0.9117],
          [ 0.0698, -1.0000],
          [-0.9927, -0.9682],
          [ 0.5761, -1.0000],
          [-0.9960, -0.0173],
          [ 0.9960, -1.0000]], grad_fn=&lt;SqueezeBackward1&gt;),
  tensor([[ 0.9960, -1.0000]], grad_fn=&lt;SqueezeBackward1&gt;)),
 (tensor([[-0.9713, -1.0000],
          [ 0.0535, -1.0000],
          [-0.9925, -0.9720],
          [ 0.5759, -1.0000],
          [-0.9960, -0.0180],
          [ 0.9960, -1.0000]], grad_fn=&lt;SqueezeBackward1&gt;),
  tensor([[ 0.9960, -1.0000]], grad_fn=&lt;SqueezeBackward1&gt;)))</code></pre>
</div>
</div>
<p><code>(6)</code> 시각화2: hidden, yhat</p>
<div class="cell" data-execution_count="147">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>combinded <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="148">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">15</span>:].data,cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="148">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f1123881510&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-52-output-2.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>히든노드의 해석이 어려움.</li>
</ul>
<p>hidden layer-&gt;layer 더 있음 좋겠다</p>
</section>
<section id="순환신경망-구현4-with-rnn-hidden-node-3-성공" class="level3">
<h3 class="anchored" data-anchor-id="순환신경망-구현4-with-rnn-hidden-node-3-성공">순환신경망 구현4 (with RNN, hidden node 3) – 성공</h3>
<p><code>(1)</code> 숙성네트워크~ <code>(2)</code> 조리네트워크</p>
<div class="cell" data-execution_count="149">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">2</span>) <span class="co">#1 </span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">3</span>) </span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>cook <span class="op">=</span> torch.nn.Linear(<span class="dv">3</span>,<span class="dv">4</span>) </span></code></pre></div>
</div>
<p><code>(3)</code> 손실함수와 옵티마이저</p>
<div class="cell" data-execution_count="150">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(cook.parameters()))</span></code></pre></div>
</div>
<p><code>(4)</code> 학습</p>
<div class="cell" data-execution_count="151">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>) </span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>):</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1</span></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>    hidden,hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> cook(hidden) </span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<p><code>(5)</code> 시각화1: yhat</p>
<div class="cell" data-execution_count="152">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="153">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(yhat[<span class="op">-</span><span class="dv">15</span>:].data,cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="153">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f1123e41f10&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-57-output-2.png" class="img-fluid"></p>
</div>
</div>
<p><code>(6)</code> 시각화2: hidden, yhat</p>
<div class="cell" data-execution_count="154">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>combinded <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="155">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">15</span>:].data,cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="155">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f1123a3fd10&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-59-output-2.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>세번째 히든노드 = 대소문자(a/A)를 구분</li>
<li>1,2 히든노드 = bcd를 구분</li>
</ul>
</section>
</section>
<section id="gpu-실험" class="level2">
<h2 class="anchored" data-anchor-id="gpu-실험">GPU 실험</h2>
<section id="len-20-hidden-nodes" class="level3">
<h3 class="anchored" data-anchor-id="len-20-hidden-nodes">20000 len + 20 hidden nodes</h3>
<p><strong><em>cpu</em></strong></p>
<div class="cell" data-execution_count="164">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span></code></pre></div>
</div>
<div class="cell" data-execution_count="161">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">20000</span>,<span class="dv">4</span>]) </span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">20000</span>,<span class="dv">4</span>]) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="162">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">20</span>) </span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">4</span>) </span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div class="cell" data-execution_count="165">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>)</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a>    loss.backward() </span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb85-13"><a href="#cb85-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb85-14"><a href="#cb85-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb85-15"><a href="#cb85-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="165">
<pre><code>228.14399337768555</code></pre>
</div>
</div>
<p>왕 느려</p>
<p><strong><em>gpu</em></strong></p>
<div class="cell" data-execution_count="166">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">20000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">20000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="167">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div class="cell" data-execution_count="168">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a>    loss.backward() </span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb89-12"><a href="#cb89-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb89-13"><a href="#cb89-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb89-14"><a href="#cb89-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb89-15"><a href="#cb89-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="168">
<pre><code>6.0587098598480225</code></pre>
</div>
</div>
<ul>
<li>왜 빠른지?</li>
</ul>
</section>
<section id="len-20-hidden-nodes-역전파주석처리" class="level3">
<h3 class="anchored" data-anchor-id="len-20-hidden-nodes-역전파주석처리">20000 len + 20 hidden nodes + 역전파주석처리</h3>
<p><strong><em>cpu</em></strong></p>
<div class="cell" data-execution_count="169">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">20000</span>,<span class="dv">4</span>]) </span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">20000</span>,<span class="dv">4</span>]) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="170">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">20</span>) </span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">4</span>) </span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div class="cell" data-execution_count="171">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>)</span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#loss.backward() </span></span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb93-12"><a href="#cb93-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb93-13"><a href="#cb93-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb93-14"><a href="#cb93-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb93-15"><a href="#cb93-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="171">
<pre><code>28.451032400131226</code></pre>
</div>
</div>
<p>loss 미분할 때 시간 많이 잡음ㅁ</p>
<p><strong><em>gpu</em></strong></p>
<div class="cell" data-execution_count="172">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">20000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">20000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="173">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div class="cell" data-execution_count="174">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb97-6"><a href="#cb97-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb97-7"><a href="#cb97-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb97-8"><a href="#cb97-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb97-9"><a href="#cb97-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb97-10"><a href="#cb97-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#loss.backward() </span></span>
<span id="cb97-11"><a href="#cb97-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb97-12"><a href="#cb97-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb97-13"><a href="#cb97-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb97-14"><a href="#cb97-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb97-15"><a href="#cb97-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="174">
<pre><code>1.6839873790740967</code></pre>
</div>
</div>
</section>
<section id="len-20-hidden-nodes-1" class="level3">
<h3 class="anchored" data-anchor-id="len-20-hidden-nodes-1">2000 len + 20 hidden nodes</h3>
<p><strong><em>cpu</em></strong></p>
<div class="cell" data-execution_count="175">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]) </span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="176">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">20</span>) </span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">4</span>) </span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div class="cell" data-execution_count="177">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>)</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb101-8"><a href="#cb101-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb101-9"><a href="#cb101-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb101-10"><a href="#cb101-10" aria-hidden="true" tabindex="-1"></a>    loss.backward() </span>
<span id="cb101-11"><a href="#cb101-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb101-12"><a href="#cb101-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb101-13"><a href="#cb101-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb101-14"><a href="#cb101-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb101-15"><a href="#cb101-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="177">
<pre><code>10.069071292877197</code></pre>
</div>
</div>
<p><strong><em>gpu</em></strong></p>
<div class="cell" data-execution_count="178">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="179">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div class="cell" data-execution_count="180">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb105-9"><a href="#cb105-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb105-10"><a href="#cb105-10" aria-hidden="true" tabindex="-1"></a>    loss.backward() </span>
<span id="cb105-11"><a href="#cb105-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb105-12"><a href="#cb105-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb105-13"><a href="#cb105-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb105-14"><a href="#cb105-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb105-15"><a href="#cb105-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="180">
<pre><code>1.7792012691497803</code></pre>
</div>
</div>
</section>
<section id="len-20-hidden-nodes-역전파주석처리-1" class="level3">
<h3 class="anchored" data-anchor-id="len-20-hidden-nodes-역전파주석처리-1">2000 len + 20 hidden nodes + 역전파주석처리</h3>
<p><strong><em>cpu</em></strong></p>
<div class="cell" data-execution_count="181">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]) </span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="182">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">20</span>) </span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">4</span>) </span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div class="cell" data-execution_count="183">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>)</span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb109-7"><a href="#cb109-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb109-8"><a href="#cb109-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb109-9"><a href="#cb109-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb109-10"><a href="#cb109-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#loss.backward() </span></span>
<span id="cb109-11"><a href="#cb109-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb109-12"><a href="#cb109-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb109-13"><a href="#cb109-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb109-14"><a href="#cb109-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb109-15"><a href="#cb109-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="183">
<pre><code>2.7720658779144287</code></pre>
</div>
</div>
<p><strong><em>gpu</em></strong></p>
<div class="cell" data-execution_count="184">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="185">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div class="cell" data-execution_count="186">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb113-5"><a href="#cb113-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb113-6"><a href="#cb113-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb113-7"><a href="#cb113-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb113-8"><a href="#cb113-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb113-9"><a href="#cb113-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb113-10"><a href="#cb113-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#loss.backward() </span></span>
<span id="cb113-11"><a href="#cb113-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb113-12"><a href="#cb113-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb113-13"><a href="#cb113-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb113-14"><a href="#cb113-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb113-15"><a href="#cb113-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="186">
<pre><code>0.2116107940673828</code></pre>
</div>
</div>
</section>
<section id="len-5000-hidden-nodes" class="level3">
<h3 class="anchored" data-anchor-id="len-5000-hidden-nodes">2000 len + 5000 hidden nodes</h3>
<p><strong><em>cpu</em></strong></p>
<div class="cell" data-execution_count="187">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]) </span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="188">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">1000</span>) </span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">1000</span>,<span class="dv">4</span>) </span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div class="cell" data-execution_count="189">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">1000</span>)</span>
<span id="cb117-5"><a href="#cb117-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb117-6"><a href="#cb117-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb117-7"><a href="#cb117-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb117-8"><a href="#cb117-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb117-9"><a href="#cb117-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb117-10"><a href="#cb117-10" aria-hidden="true" tabindex="-1"></a>    loss.backward() </span>
<span id="cb117-11"><a href="#cb117-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb117-12"><a href="#cb117-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb117-13"><a href="#cb117-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb117-14"><a href="#cb117-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb117-15"><a href="#cb117-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="189">
<pre><code>34.20541262626648</code></pre>
</div>
</div>
<p><strong><em>gpu</em></strong></p>
<div class="cell" data-execution_count="190">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="191">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">1000</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">1000</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div class="cell" data-execution_count="192">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">1000</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb121-6"><a href="#cb121-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb121-7"><a href="#cb121-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb121-8"><a href="#cb121-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb121-9"><a href="#cb121-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb121-10"><a href="#cb121-10" aria-hidden="true" tabindex="-1"></a>    loss.backward() </span>
<span id="cb121-11"><a href="#cb121-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb121-12"><a href="#cb121-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb121-13"><a href="#cb121-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb121-14"><a href="#cb121-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb121-15"><a href="#cb121-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="192">
<pre><code>4.586683511734009</code></pre>
</div>
</div>
</section>
<section id="len-5000-hidden-nodes-역전파주석처리" class="level3">
<h3 class="anchored" data-anchor-id="len-5000-hidden-nodes-역전파주석처리">2000 len + 5000 hidden nodes + 역전파주석처리</h3>
<p><strong><em>cpu</em></strong></p>
<div class="cell" data-execution_count="193">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]) </span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="194">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">1000</span>) </span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">1000</span>,<span class="dv">4</span>) </span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div class="cell" data-execution_count="195">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb125-4"><a href="#cb125-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">1000</span>)</span>
<span id="cb125-5"><a href="#cb125-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb125-6"><a href="#cb125-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb125-7"><a href="#cb125-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb125-8"><a href="#cb125-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb125-9"><a href="#cb125-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb125-10"><a href="#cb125-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#loss.backward() </span></span>
<span id="cb125-11"><a href="#cb125-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb125-12"><a href="#cb125-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb125-13"><a href="#cb125-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb125-14"><a href="#cb125-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb125-15"><a href="#cb125-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="195">
<pre><code>8.695780992507935</code></pre>
</div>
</div>
<p><strong><em>gpu</em></strong></p>
<div class="cell" data-execution_count="196">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="197">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">1000</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">1000</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb128-3"><a href="#cb128-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb128-4"><a href="#cb128-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div class="cell" data-execution_count="198">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb129-4"><a href="#cb129-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">1000</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb129-5"><a href="#cb129-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb129-6"><a href="#cb129-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb129-7"><a href="#cb129-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb129-8"><a href="#cb129-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb129-9"><a href="#cb129-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb129-10"><a href="#cb129-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#loss.backward() </span></span>
<span id="cb129-11"><a href="#cb129-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb129-12"><a href="#cb129-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb129-13"><a href="#cb129-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb129-14"><a href="#cb129-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb129-15"><a href="#cb129-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="198">
<pre><code>2.3646719455718994</code></pre>
</div>
</div>
</section>
<section id="실험결과-요약" class="level3">
<h3 class="anchored" data-anchor-id="실험결과-요약">실험결과 요약</h3>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">len</th>
<th style="text-align: center;"># of hidden nodes</th>
<th style="text-align: center;">backward</th>
<th style="text-align: center;">cpu</th>
<th style="text-align: center;">gpu</th>
<th style="text-align: center;">ratio</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">20000</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">O</td>
<td style="text-align: center;">93.02</td>
<td style="text-align: center;">3.26</td>
<td style="text-align: center;">28.53</td>
</tr>
<tr class="even">
<td style="text-align: center;">20000</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">X</td>
<td style="text-align: center;">18.85</td>
<td style="text-align: center;">1.29</td>
<td style="text-align: center;">14.61</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2000</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">O</td>
<td style="text-align: center;">6.53</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">8.70</td>
</tr>
<tr class="even">
<td style="text-align: center;">2000</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">X</td>
<td style="text-align: center;">1.25</td>
<td style="text-align: center;">0.14</td>
<td style="text-align: center;">8.93</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2000</td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">O</td>
<td style="text-align: center;">58.99</td>
<td style="text-align: center;">4.75</td>
<td style="text-align: center;">12.41</td>
</tr>
<tr class="even">
<td style="text-align: center;">2000</td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">X</td>
<td style="text-align: center;">13.16</td>
<td style="text-align: center;">2.29</td>
<td style="text-align: center;">5.74</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="exam5-abcabc" class="level2">
<h2 class="anchored" data-anchor-id="exam5-abcabc">Exam5: abcabC</h2>
<section id="data-1" class="level3">
<h3 class="anchored" data-anchor-id="data-1">data</h3>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'abcabC'</span>)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a>txt[:<span class="dv">8</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>['a', 'b', 'c', 'a', 'b', 'C', 'a', 'b']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>txt_x <span class="op">=</span> txt[:<span class="op">-</span><span class="dv">1</span>] </span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>txt_y <span class="op">=</span> txt[<span class="dv">1</span>:]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>mapping <span class="op">=</span> {<span class="st">'a'</span>:<span class="dv">0</span>,<span class="st">'b'</span>:<span class="dv">1</span>,<span class="st">'c'</span>:<span class="dv">2</span>,<span class="st">'C'</span>:<span class="dv">3</span>} </span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).<span class="bu">float</span>()</span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).<span class="bu">float</span>()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.to(<span class="st">"cuda:0"</span>)</span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y.to(<span class="st">"cuda:0"</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>x.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>torch.Size([599, 4])</code></pre>
</div>
</div>
</section>
<section id="rnn" class="level3">
<h3 class="anchored" data-anchor-id="rnn">RNN</h3>
<ul>
<li>bc</li>
<li>bC</li>
<li>b의 수준이 2개</li>
<li>abc</li>
<li>amC</li>
<li>문맥 고려해서 <span class="math inline">\(\to\)</span> hiddenlayer = 3</li>
</ul>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">3</span>) </span>
<span id="cb138-3"><a href="#cb138-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">3</span>,<span class="dv">4</span>) </span>
<span id="cb138-4"><a href="#cb138-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb138-5"><a href="#cb138-5" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span> <span class="bu">list</span>(linr.parameters()))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>rnn.to(<span class="st">"cuda:0"</span>) </span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>linr.to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>Linear(in_features=3, out_features=4, bias=True)</code></pre>
</div>
</div>
<p><code>-</code> 3000 epochs</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb141-2"><a href="#cb141-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb141-3"><a href="#cb141-3" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb141-4"><a href="#cb141-4" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb141-5"><a href="#cb141-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb141-6"><a href="#cb141-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb141-7"><a href="#cb141-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb141-8"><a href="#cb141-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb141-9"><a href="#cb141-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb141-10"><a href="#cb141-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb141-11"><a href="#cb141-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb141-12"><a href="#cb141-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>combinded  <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>).data.to(<span class="st">"cpu"</span>)</span></code></pre></div>
</div>
<ul>
<li>어차피 시각화하려면 cpu에 있어야해</li>
<li>나중 기억!</li>
</ul>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f116f95fd10&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-106-output-2.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 6000 epochs</p>
<ul>
<li>3: a일 확률</li>
<li>4: b일 확률</li>
<li>5: c일 확률</li>
<li>6: C일 확률</li>
</ul>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb145-2"><a href="#cb145-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb145-3"><a href="#cb145-3" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb145-4"><a href="#cb145-4" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb145-5"><a href="#cb145-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb145-6"><a href="#cb145-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb145-7"><a href="#cb145-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb145-8"><a href="#cb145-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb145-9"><a href="#cb145-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb145-10"><a href="#cb145-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb145-11"><a href="#cb145-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb145-12"><a href="#cb145-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a>combinded  <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>).data.to(<span class="st">"cpu"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f1162b1ad10&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-109-output-2.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 9000 epochs</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb149-3"><a href="#cb149-3" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb149-4"><a href="#cb149-4" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb149-5"><a href="#cb149-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb149-6"><a href="#cb149-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb149-7"><a href="#cb149-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb149-8"><a href="#cb149-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb149-9"><a href="#cb149-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb149-10"><a href="#cb149-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb149-11"><a href="#cb149-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb149-12"><a href="#cb149-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a>combinded  <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>).data.to(<span class="st">"cpu"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f11627385d0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-112-output-2.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 12000 epochs</p>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb153-2"><a href="#cb153-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb153-3"><a href="#cb153-3" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb153-4"><a href="#cb153-4" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb153-5"><a href="#cb153-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb153-6"><a href="#cb153-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb153-7"><a href="#cb153-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb153-8"><a href="#cb153-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb153-9"><a href="#cb153-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb153-10"><a href="#cb153-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb153-11"><a href="#cb153-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb153-12"><a href="#cb153-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a>combinded  <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>).data.to(<span class="st">"cpu"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f11626b9950&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-115-output-2.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 15000 epochs</p>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb157-3"><a href="#cb157-3" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb157-4"><a href="#cb157-4" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb157-5"><a href="#cb157-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb157-6"><a href="#cb157-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb157-7"><a href="#cb157-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb157-8"><a href="#cb157-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb157-9"><a href="#cb157-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb157-10"><a href="#cb157-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb157-11"><a href="#cb157-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb157-12"><a href="#cb157-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span>
<span id="cb158-2"><a href="#cb158-2" aria-hidden="true" tabindex="-1"></a>combinded  <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>).data.to(<span class="st">"cpu"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">12</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f11624ce950&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-118-output-2.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>15,000번 정도 하니 c와 C를 구분하는 모습</li>
<li>hidden layer(0,1,2)의 색 순서에 따라 문맥상 다른 것을 알 수 있고 학습도 되는 모습을 볼 수 있다.</li>
</ul>
</section>
<section id="lstm" class="level3">
<h3 class="anchored" data-anchor-id="lstm">LSTM</h3>
<p><code>-</code> LSTM</p>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb161"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb161-2"><a href="#cb161-2" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">4</span>,<span class="dv">3</span>) </span>
<span id="cb161-3"><a href="#cb161-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">3</span>,<span class="dv">4</span>) </span>
<span id="cb161-4"><a href="#cb161-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb161-5"><a href="#cb161-5" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters())<span class="op">+</span> <span class="bu">list</span>(linr.parameters()))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb162"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a>lstm.to(<span class="st">"cuda:0"</span>) </span>
<span id="cb162-2"><a href="#cb162-2" aria-hidden="true" tabindex="-1"></a>linr.to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>Linear(in_features=3, out_features=4, bias=True)</code></pre>
</div>
</div>
<p><code>-</code> 3000 epochs</p>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb164"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb164-2"><a href="#cb164-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb164-3"><a href="#cb164-3" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb164-4"><a href="#cb164-4" aria-hidden="true" tabindex="-1"></a>    hidden, (hT,cT) <span class="op">=</span> lstm(x,(_water,_water))</span>
<span id="cb164-5"><a href="#cb164-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb164-6"><a href="#cb164-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb164-7"><a href="#cb164-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb164-8"><a href="#cb164-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb164-9"><a href="#cb164-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb164-10"><a href="#cb164-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb164-11"><a href="#cb164-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb164-12"><a href="#cb164-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span>
<span id="cb165-2"><a href="#cb165-2" aria-hidden="true" tabindex="-1"></a>combinded  <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>).data.to(<span class="st">"cpu"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb166"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f116245a750&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-123-output-2.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>하얀부분이 0 파란 부분이 -1 빨간 부분이 +1</li>
</ul>
<p><code>-</code> 6000 epochs</p>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb168"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb168-2"><a href="#cb168-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb168-3"><a href="#cb168-3" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb168-4"><a href="#cb168-4" aria-hidden="true" tabindex="-1"></a>    hidden, (hT,cT) <span class="op">=</span> lstm(x,(_water,_water))</span>
<span id="cb168-5"><a href="#cb168-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb168-6"><a href="#cb168-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb168-7"><a href="#cb168-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb168-8"><a href="#cb168-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb168-9"><a href="#cb168-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb168-10"><a href="#cb168-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb168-11"><a href="#cb168-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb168-12"><a href="#cb168-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span>
<span id="cb169-2"><a href="#cb169-2" aria-hidden="true" tabindex="-1"></a>combinded  <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>).data.to(<span class="st">"cpu"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb170"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f11623e0a90&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-126-output-2.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>rnn에 비해 lstm은 조금 돌려도 어느정도 비교 잘 해낸다</li>
</ul>
</section>
<section id="rnn-vs-lstm-성능비교실험" class="level3">
<h3 class="anchored" data-anchor-id="rnn-vs-lstm-성능비교실험">RNN vs LSTM 성능비교실험</h3>
<p><code>-</code> RNN</p>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb172-2"><a href="#cb172-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb172-3"><a href="#cb172-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb172-4"><a href="#cb172-4" aria-hidden="true" tabindex="-1"></a>        rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb172-5"><a href="#cb172-5" aria-hidden="true" tabindex="-1"></a>        linr <span class="op">=</span> torch.nn.Linear(<span class="dv">3</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb172-6"><a href="#cb172-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb172-7"><a href="#cb172-7" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb172-8"><a href="#cb172-8" aria-hidden="true" tabindex="-1"></a>        _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb172-9"><a href="#cb172-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb172-10"><a href="#cb172-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1</span></span>
<span id="cb172-11"><a href="#cb172-11" aria-hidden="true" tabindex="-1"></a>            hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb172-12"><a href="#cb172-12" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> linr(hidden)</span>
<span id="cb172-13"><a href="#cb172-13" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2</span></span>
<span id="cb172-14"><a href="#cb172-14" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(output,y)</span>
<span id="cb172-15"><a href="#cb172-15" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3</span></span>
<span id="cb172-16"><a href="#cb172-16" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb172-17"><a href="#cb172-17" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb172-18"><a href="#cb172-18" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb172-19"><a href="#cb172-19" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb172-20"><a href="#cb172-20" aria-hidden="true" tabindex="-1"></a>        yhat<span class="op">=</span>soft(output)    </span>
<span id="cb172-21"><a href="#cb172-21" aria-hidden="true" tabindex="-1"></a>        combind <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb172-22"><a href="#cb172-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(combind.to(<span class="st">"cpu"</span>).data[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb172-23"><a href="#cb172-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="vs">r"$RNN$"</span>,size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb172-24"><a href="#cb172-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-127-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> LSTM</p>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb173"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb173-2"><a href="#cb173-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb173-3"><a href="#cb173-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb173-4"><a href="#cb173-4" aria-hidden="true" tabindex="-1"></a>        lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">4</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb173-5"><a href="#cb173-5" aria-hidden="true" tabindex="-1"></a>        linr <span class="op">=</span> torch.nn.Linear(<span class="dv">3</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb173-6"><a href="#cb173-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb173-7"><a href="#cb173-7" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb173-8"><a href="#cb173-8" aria-hidden="true" tabindex="-1"></a>        _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb173-9"><a href="#cb173-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb173-10"><a href="#cb173-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1</span></span>
<span id="cb173-11"><a href="#cb173-11" aria-hidden="true" tabindex="-1"></a>            hidden, (hT,cT) <span class="op">=</span> lstm(x,(_water,_water))</span>
<span id="cb173-12"><a href="#cb173-12" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> linr(hidden)</span>
<span id="cb173-13"><a href="#cb173-13" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2</span></span>
<span id="cb173-14"><a href="#cb173-14" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(output,y)</span>
<span id="cb173-15"><a href="#cb173-15" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3</span></span>
<span id="cb173-16"><a href="#cb173-16" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb173-17"><a href="#cb173-17" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb173-18"><a href="#cb173-18" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb173-19"><a href="#cb173-19" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb173-20"><a href="#cb173-20" aria-hidden="true" tabindex="-1"></a>        yhat<span class="op">=</span>soft(output)    </span>
<span id="cb173-21"><a href="#cb173-21" aria-hidden="true" tabindex="-1"></a>        combind <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb173-22"><a href="#cb173-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(combind.to(<span class="st">"cpu"</span>).data[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb173-23"><a href="#cb173-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="vs">r"$LSTM$"</span>,size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb173-24"><a href="#cb173-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-128-output-1.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>lstm이 rnn보다 이런 상황에서는 더 잘 학습해낸다.</li>
<li>linear 의 hiddenlayer로 구분되어 있다.</li>
</ul>
</section>
</section>
<section id="exam6-abcdabcd" class="level2">
<h2 class="anchored" data-anchor-id="exam6-abcdabcd">Exam6: abcdabcD</h2>
<section id="data-2" class="level3">
<h3 class="anchored" data-anchor-id="data-2">data</h3>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb174"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb174-1"><a href="#cb174-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'abcdabcD'</span>)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb174-2"><a href="#cb174-2" aria-hidden="true" tabindex="-1"></a>txt[:<span class="dv">8</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>['a', 'b', 'c', 'd', 'a', 'b', 'c', 'D']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb176"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb176-1"><a href="#cb176-1" aria-hidden="true" tabindex="-1"></a>txt_x <span class="op">=</span> txt[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb176-2"><a href="#cb176-2" aria-hidden="true" tabindex="-1"></a>txt_y <span class="op">=</span> txt[<span class="dv">1</span>:]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>mapping <span class="op">=</span> {<span class="st">'a'</span>:<span class="dv">0</span>, <span class="st">'b'</span>:<span class="dv">1</span>, <span class="st">'c'</span>:<span class="dv">2</span>, <span class="st">'d'</span>:<span class="dv">3</span>, <span class="st">'D'</span>:<span class="dv">4</span>}</span>
<span id="cb177-2"><a href="#cb177-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).<span class="bu">float</span>()</span>
<span id="cb177-3"><a href="#cb177-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).<span class="bu">float</span>()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb178"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>x.to(<span class="st">"cuda:0"</span>)</span>
<span id="cb178-2"><a href="#cb178-2" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>y.to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
</section>
<section id="rnn-vs-lstm-성능비교실험-1" class="level3">
<h3 class="anchored" data-anchor-id="rnn-vs-lstm-성능비교실험-1">RNN vs LSTM 성능비교실험</h3>
<p><code>-</code> RNN</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb179"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb179-2"><a href="#cb179-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb179-3"><a href="#cb179-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb179-4"><a href="#cb179-4" aria-hidden="true" tabindex="-1"></a>        rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">5</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb179-5"><a href="#cb179-5" aria-hidden="true" tabindex="-1"></a>        linr <span class="op">=</span> torch.nn.Linear(<span class="dv">4</span>,<span class="dv">5</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb179-6"><a href="#cb179-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb179-7"><a href="#cb179-7" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb179-8"><a href="#cb179-8" aria-hidden="true" tabindex="-1"></a>        _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb179-9"><a href="#cb179-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb179-10"><a href="#cb179-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1</span></span>
<span id="cb179-11"><a href="#cb179-11" aria-hidden="true" tabindex="-1"></a>            hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb179-12"><a href="#cb179-12" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> linr(hidden)</span>
<span id="cb179-13"><a href="#cb179-13" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2</span></span>
<span id="cb179-14"><a href="#cb179-14" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(output,y)</span>
<span id="cb179-15"><a href="#cb179-15" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3</span></span>
<span id="cb179-16"><a href="#cb179-16" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb179-17"><a href="#cb179-17" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb179-18"><a href="#cb179-18" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb179-19"><a href="#cb179-19" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb179-20"><a href="#cb179-20" aria-hidden="true" tabindex="-1"></a>        yhat<span class="op">=</span>soft(output)    </span>
<span id="cb179-21"><a href="#cb179-21" aria-hidden="true" tabindex="-1"></a>        combind <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb179-22"><a href="#cb179-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(combind.to(<span class="st">"cpu"</span>).data[<span class="op">-</span><span class="dv">8</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb179-23"><a href="#cb179-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="vs">r"$RNN$"</span>,size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb179-24"><a href="#cb179-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-133-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> LSTM</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb180"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb180-1"><a href="#cb180-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb180-2"><a href="#cb180-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb180-3"><a href="#cb180-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb180-4"><a href="#cb180-4" aria-hidden="true" tabindex="-1"></a>        lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">5</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb180-5"><a href="#cb180-5" aria-hidden="true" tabindex="-1"></a>        linr <span class="op">=</span> torch.nn.Linear(<span class="dv">4</span>,<span class="dv">5</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb180-6"><a href="#cb180-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb180-7"><a href="#cb180-7" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb180-8"><a href="#cb180-8" aria-hidden="true" tabindex="-1"></a>        _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb180-9"><a href="#cb180-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb180-10"><a href="#cb180-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1</span></span>
<span id="cb180-11"><a href="#cb180-11" aria-hidden="true" tabindex="-1"></a>            hidden, (hT,cT) <span class="op">=</span> lstm(x,(_water,_water))</span>
<span id="cb180-12"><a href="#cb180-12" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> linr(hidden)</span>
<span id="cb180-13"><a href="#cb180-13" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2</span></span>
<span id="cb180-14"><a href="#cb180-14" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(output,y)</span>
<span id="cb180-15"><a href="#cb180-15" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3</span></span>
<span id="cb180-16"><a href="#cb180-16" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb180-17"><a href="#cb180-17" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb180-18"><a href="#cb180-18" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb180-19"><a href="#cb180-19" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb180-20"><a href="#cb180-20" aria-hidden="true" tabindex="-1"></a>        yhat<span class="op">=</span>soft(output)    </span>
<span id="cb180-21"><a href="#cb180-21" aria-hidden="true" tabindex="-1"></a>        combind <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb180-22"><a href="#cb180-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(combind.to(<span class="st">"cpu"</span>).data[<span class="op">-</span><span class="dv">8</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb180-23"><a href="#cb180-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="vs">r"$LSTM$"</span>,size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb180-24"><a href="#cb180-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-134-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 관찰1: LSTM이 확실히 장기기억에 강하다.</p>
<p><code>-</code> 관찰2: LSTM은 hidden에 0이 잘 나온다.</p>
<ul>
<li>사실 확실히 구분되는 특징을 판별할때는 -1,1 로 히든레이어 값들이 설정되면 명확하다.</li>
<li>히든레이어에 -1~1사이의 값이 나온다면 애매한 판단이 내려지게 된다.</li>
<li>그런데 이 애매한 판단이 어떻게 보면 문맥의 뉘앙스를 이해하는데 더 잘 맞다.</li>
<li>그런데 RNN은 -1,1로 셋팅된 상황에서 -1~1로의 변화가 더디다는 것이 문제임.</li>
</ul>
</section>
</section>
<section id="lstm의-계산과정" class="level2">
<h2 class="anchored" data-anchor-id="lstm의-계산과정">LSTM의 계산과정</h2>
<section id="data-abab" class="level3">
<h3 class="anchored" data-anchor-id="data-abab">data: abaB</h3>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb181"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'abaB'</span>)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb181-2"><a href="#cb181-2" aria-hidden="true" tabindex="-1"></a>txt[:<span class="dv">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>['a', 'b', 'a', 'B', 'a']</code></pre>
</div>
</div>
<ul>
<li>ab</li>
<li>aB</li>
<li>로서 a의 수준이 2개로 나뉨 <span class="math inline">\(\to\)</span> hidden node = 2</li>
</ul>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb183"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a>txt_x <span class="op">=</span> txt[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb183-2"><a href="#cb183-2" aria-hidden="true" tabindex="-1"></a>txt_y <span class="op">=</span> txt[<span class="dv">1</span>:]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb184"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb184-1"><a href="#cb184-1" aria-hidden="true" tabindex="-1"></a>mapping <span class="op">=</span> {<span class="st">'a'</span>:<span class="dv">0</span>, <span class="st">'b'</span>:<span class="dv">1</span>, <span class="st">'B'</span>:<span class="dv">2</span>}</span>
<span id="cb184-2"><a href="#cb184-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).<span class="bu">float</span>()</span>
<span id="cb184-3"><a href="#cb184-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).<span class="bu">float</span>()</span></code></pre></div>
</div>
</section>
<section id="epoch-ver1-with-torch.nn.lstmcell" class="level3">
<h3 class="anchored" data-anchor-id="epoch-ver1-with-torch.nn.lstmcell">1 epoch ver1 (with torch.nn.LSTMCell)</h3>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb185"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb185-1"><a href="#cb185-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb185-2"><a href="#cb185-2" aria-hidden="true" tabindex="-1"></a>lstm_cell <span class="op">=</span> torch.nn.LSTMCell(<span class="dv">3</span>,<span class="dv">2</span>) </span>
<span id="cb185-3"><a href="#cb185-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb185-4"><a href="#cb185-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() </span>
<span id="cb185-5"><a href="#cb185-5" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm_cell.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb186"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="bu">len</span>(x) </span>
<span id="cb186-2"><a href="#cb186-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>):</span>
<span id="cb186-3"><a href="#cb186-3" aria-hidden="true" tabindex="-1"></a>    ht <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb186-4"><a href="#cb186-4" aria-hidden="true" tabindex="-1"></a>    ct <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb186-5"><a href="#cb186-5" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb186-6"><a href="#cb186-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1~2</span></span>
<span id="cb186-7"><a href="#cb186-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb186-8"><a href="#cb186-8" aria-hidden="true" tabindex="-1"></a>        xt,yt <span class="op">=</span> x[[t]], y[[t]]</span>
<span id="cb186-9"><a href="#cb186-9" aria-hidden="true" tabindex="-1"></a>        ht,ct <span class="op">=</span> lstm_cell(xt,(ht,ct))</span>
<span id="cb186-10"><a href="#cb186-10" aria-hidden="true" tabindex="-1"></a>        ot <span class="op">=</span> linr(ht) </span>
<span id="cb186-11"><a href="#cb186-11" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss <span class="op">+</span> loss_fn(ot,yt)</span>
<span id="cb186-12"><a href="#cb186-12" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss <span class="op">/</span> T</span>
<span id="cb186-13"><a href="#cb186-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb186-14"><a href="#cb186-14" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb186-15"><a href="#cb186-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb186-16"><a href="#cb186-16" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb186-17"><a href="#cb186-17" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<ul>
<li>데이터 적으니까 cpu로 할 것임</li>
</ul>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb187"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a>ht,ct </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>(tensor([[-0.0406,  0.2505]], grad_fn=&lt;MulBackward0&gt;),
 tensor([[-0.0975,  0.7134]], grad_fn=&lt;AddBackward0&gt;))</code></pre>
</div>
</div>
<ul>
<li>hidden node가 많고 len 이 클수록 GPU가 효율이 좋다</li>
</ul>
</section>
<section id="epoch-ver2-완전-손으로-구현" class="level3">
<h3 class="anchored" data-anchor-id="epoch-ver2-완전-손으로-구현">1 epoch ver2 (완전 손으로 구현)</h3>
<section id="t0-to-t1" class="level4">
<h4 class="anchored" data-anchor-id="t0-to-t1"><strong><em>t=0 <span class="math inline">\(\to\)</span> t=1</em></strong></h4>
<p><code>-</code> lstm_cell 을 이용한 계산 (결과비교용)</p>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb189"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb189-2"><a href="#cb189-2" aria-hidden="true" tabindex="-1"></a>lstm_cell <span class="op">=</span> torch.nn.LSTMCell(<span class="dv">3</span>,<span class="dv">2</span>) </span>
<span id="cb189-3"><a href="#cb189-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb189-4"><a href="#cb189-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() </span>
<span id="cb189-5"><a href="#cb189-5" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm_cell.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb190"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb190-1"><a href="#cb190-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="bu">len</span>(x) </span>
<span id="cb190-2"><a href="#cb190-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>):</span>
<span id="cb190-3"><a href="#cb190-3" aria-hidden="true" tabindex="-1"></a>    ht <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb190-4"><a href="#cb190-4" aria-hidden="true" tabindex="-1"></a>    ct <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb190-5"><a href="#cb190-5" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb190-6"><a href="#cb190-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1~2</span></span>
<span id="cb190-7"><a href="#cb190-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>):</span>
<span id="cb190-8"><a href="#cb190-8" aria-hidden="true" tabindex="-1"></a>        xt,yt <span class="op">=</span> x[[t]], y[[t]]</span>
<span id="cb190-9"><a href="#cb190-9" aria-hidden="true" tabindex="-1"></a>        ht,ct <span class="op">=</span> lstm_cell(xt,(ht,ct))</span>
<span id="cb190-10"><a href="#cb190-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     ot = linr(ht) </span></span>
<span id="cb190-11"><a href="#cb190-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     loss = loss + loss_fn(ot,yt)</span></span>
<span id="cb190-12"><a href="#cb190-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loss = loss / T</span></span>
<span id="cb190-13"><a href="#cb190-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ## 3 </span></span>
<span id="cb190-14"><a href="#cb190-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loss.backward()</span></span>
<span id="cb190-15"><a href="#cb190-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ## 4 </span></span>
<span id="cb190-16"><a href="#cb190-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># optimizr.step()</span></span>
<span id="cb190-17"><a href="#cb190-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># optimizr.zero_grad()</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb191"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb191-1"><a href="#cb191-1" aria-hidden="true" tabindex="-1"></a>ht,ct </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>(tensor([[-0.0541,  0.0892]], grad_fn=&lt;MulBackward0&gt;),
 tensor([[-0.1347,  0.2339]], grad_fn=&lt;AddBackward0&gt;))</code></pre>
</div>
</div>
<ul>
<li>이런결과를 어떻게 만드는걸까?</li>
<li><a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html" class="uri">https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html</a></li>
</ul>
<p><span class="math inline">\(i_t = \sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi})\)</span></p>
<p><span class="math inline">\(f_t = \sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf})\)</span></p>
<p><span class="math inline">\(g_t = \tanh (W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg})\)</span></p>
<p><span class="math inline">\(o_t = \sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{hg})\)</span></p>
<p><span class="math inline">\(o_t = \sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho})\)</span></p>
<p><span class="math inline">\(c_t = f_t \odot c_{t-1} + i_t \odot g_t\)</span></p>
<p><span class="math inline">\(h_t = o_t \odot \tanh (c_t)\)</span></p>
<p><span class="math inline">\(\sigma = \text{ Sigmoid }\)</span></p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ }\circ \text{ }\underrightarrow{sig} \text{ }i_t\)</span></p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ }\square \text{ } \underrightarrow{sig} \text{ }f_t\)</span></p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ }\star \text{ } \underrightarrow{tanh} \text{ }g_t\)</span></p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ } \triangleleft \text{ }\underrightarrow{sig} \text{ }o_t\)</span></p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ }\circ \text{ , } \square \text{, } \star \text{, } \triangleleft \text{ } \to \sigma(circ) \text{, }\sigma(\square) \text{ , }\tanh(\star)\text{ , } \sigma(\triangleleft) \sim i_t, f_t, g_t, o_t\)</span></p>
<ul>
<li>위에 나온 W가 어떻게 계산되나</li>
</ul>
<p>weight_ih_l[k] – the learnable input-hidden weights of the <span class="math inline">\(\text{k}^{th}\)</span> layer <span class="math inline">\((W_ii|W_if|W_ig|W_io)\)</span>, of shape (4<em>hidden_size, input_size) for <span class="math inline">\(k = 0\)</span>. Otherwise, the shape is (4</em>hidden_size, num_directions * hidden_size). If proj_size &gt; 0 was specified, the shape will be (4<em>hidden_size, num_directions </em> proj_size) for <span class="math inline">\(k &gt; 0\)</span></p>
<p>weight_hh_l[k] – the learnable hidden-hidden weights of the <span class="math inline">\(\text{k}^{th}\)</span>layer <span class="math inline">\((W_hi|W_hf|W_hg|W_ho)\)</span>, of shape (4<em>hidden_size, hidden_size). If proj_size &gt; 0 was specified, the shape will be (4</em>hidden_size, proj_size).</p>
<p><code>-</code> 직접계산</p>
<ul>
<li><span class="math inline">\(o_t\)</span> = output_gate</li>
<li><span class="math inline">\(f_t\)</span> = forget_gate</li>
<li><span class="math inline">\(i_t\)</span> = input_gate</li>
</ul>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb193"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb193-1"><a href="#cb193-1" aria-hidden="true" tabindex="-1"></a>ht <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb193-2"><a href="#cb193-2" aria-hidden="true" tabindex="-1"></a>ct <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb194"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb194-1"><a href="#cb194-1" aria-hidden="true" tabindex="-1"></a>_ifgo <span class="op">=</span> xt <span class="op">@</span> lstm_cell.weight_ih.T <span class="op">+</span> ht <span class="op">@</span> lstm_cell.weight_hh.T <span class="op">+</span> lstm_cell.bias_ih <span class="op">+</span> lstm_cell.bias_hh</span>
<span id="cb194-2"><a href="#cb194-2" aria-hidden="true" tabindex="-1"></a>_ifgo</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>tensor([[ 0.0137,  0.1495,  0.0879,  0.6436, -0.2615,  0.3974, -0.3506, -0.4550]],
       grad_fn=&lt;AddBackward0&gt;)</code></pre>
</div>
</div>
<p><span class="math inline">\(\circ \text{ , } \square \text{, } \star \text{, } \triangleleft\)</span>각 두 개씩</p>
<div class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb196"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb196-1"><a href="#cb196-1" aria-hidden="true" tabindex="-1"></a>input_gate <span class="op">=</span> sig(_ifgo[:,<span class="dv">0</span>:<span class="dv">2</span>])</span>
<span id="cb196-2"><a href="#cb196-2" aria-hidden="true" tabindex="-1"></a>forget_gate <span class="op">=</span> sig(_ifgo[:,<span class="dv">2</span>:<span class="dv">4</span>])</span>
<span id="cb196-3"><a href="#cb196-3" aria-hidden="true" tabindex="-1"></a>gt <span class="op">=</span> tanh(_ifgo[:,<span class="dv">4</span>:<span class="dv">6</span>])</span>
<span id="cb196-4"><a href="#cb196-4" aria-hidden="true" tabindex="-1"></a>output_gate <span class="op">=</span> sig(_ifgo[:,<span class="dv">6</span>:<span class="dv">8</span>])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb197"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a>ct <span class="op">=</span> forget_gate <span class="op">*</span> ct <span class="op">+</span> input_gate <span class="op">*</span> gt</span>
<span id="cb197-2"><a href="#cb197-2" aria-hidden="true" tabindex="-1"></a>ht <span class="op">=</span> output_gate <span class="op">*</span> tanh(ct)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb198"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb198-1"><a href="#cb198-1" aria-hidden="true" tabindex="-1"></a>ht,ct</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>(tensor([[-0.0812,  0.1327]], grad_fn=&lt;MulBackward0&gt;),
 tensor([[-0.1991,  0.3563]], grad_fn=&lt;AddBackward0&gt;))</code></pre>
</div>
</div>
</section>
<section id="t0-to-tt" class="level4">
<h4 class="anchored" data-anchor-id="t0-to-tt"><strong><em>t=0 <span class="math inline">\(\to\)</span> t=T</em></strong></h4>
<div class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb200"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb200-1"><a href="#cb200-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb200-2"><a href="#cb200-2" aria-hidden="true" tabindex="-1"></a>lstm_cell <span class="op">=</span> torch.nn.LSTMCell(<span class="dv">3</span>,<span class="dv">2</span>) </span>
<span id="cb200-3"><a href="#cb200-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb200-4"><a href="#cb200-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() </span>
<span id="cb200-5"><a href="#cb200-5" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm_cell.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb201"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="bu">len</span>(x) </span>
<span id="cb201-2"><a href="#cb201-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>):</span>
<span id="cb201-3"><a href="#cb201-3" aria-hidden="true" tabindex="-1"></a>    ht <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb201-4"><a href="#cb201-4" aria-hidden="true" tabindex="-1"></a>    ct <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb201-5"><a href="#cb201-5" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb201-6"><a href="#cb201-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1~2</span></span>
<span id="cb201-7"><a href="#cb201-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb201-8"><a href="#cb201-8" aria-hidden="true" tabindex="-1"></a>        xt,yt <span class="op">=</span> x[[t]], y[[t]]</span>
<span id="cb201-9"><a href="#cb201-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb201-10"><a href="#cb201-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">## lstm_cell step1: calculate _ifgo </span></span>
<span id="cb201-11"><a href="#cb201-11" aria-hidden="true" tabindex="-1"></a>        _ifgo <span class="op">=</span> xt <span class="op">@</span> lstm_cell.weight_ih.T <span class="op">+</span> ht <span class="op">@</span> lstm_cell.weight_hh.T <span class="op">+</span> lstm_cell.bias_ih <span class="op">+</span> lstm_cell.bias_hh</span>
<span id="cb201-12"><a href="#cb201-12" aria-hidden="true" tabindex="-1"></a>        <span class="co">## lstm_cell step2: decompose _ifgo </span></span>
<span id="cb201-13"><a href="#cb201-13" aria-hidden="true" tabindex="-1"></a>        input_gate <span class="op">=</span> sig(_ifgo[:,<span class="dv">0</span>:<span class="dv">2</span>])</span>
<span id="cb201-14"><a href="#cb201-14" aria-hidden="true" tabindex="-1"></a>        forget_gate <span class="op">=</span> sig(_ifgo[:,<span class="dv">2</span>:<span class="dv">4</span>])</span>
<span id="cb201-15"><a href="#cb201-15" aria-hidden="true" tabindex="-1"></a>        gt <span class="op">=</span> tanh(_ifgo[:,<span class="dv">4</span>:<span class="dv">6</span>])</span>
<span id="cb201-16"><a href="#cb201-16" aria-hidden="true" tabindex="-1"></a>        output_gate <span class="op">=</span> sig(_ifgo[:,<span class="dv">6</span>:<span class="dv">8</span>])</span>
<span id="cb201-17"><a href="#cb201-17" aria-hidden="true" tabindex="-1"></a>        <span class="co">## lstm_cell step3: calculate ht,ct </span></span>
<span id="cb201-18"><a href="#cb201-18" aria-hidden="true" tabindex="-1"></a>        ct <span class="op">=</span> forget_gate <span class="op">*</span> ct <span class="op">+</span> input_gate <span class="op">*</span> gt</span>
<span id="cb201-19"><a href="#cb201-19" aria-hidden="true" tabindex="-1"></a>        ht <span class="op">=</span> output_gate <span class="op">*</span> tanh(ct)</span>
<span id="cb201-20"><a href="#cb201-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb201-21"><a href="#cb201-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     ot = linr(ht) </span></span>
<span id="cb201-22"><a href="#cb201-22" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     loss = loss + loss_fn(ot,yt)</span></span>
<span id="cb201-23"><a href="#cb201-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loss = loss / T</span></span>
<span id="cb201-24"><a href="#cb201-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ## 3 </span></span>
<span id="cb201-25"><a href="#cb201-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loss.backward()</span></span>
<span id="cb201-26"><a href="#cb201-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ## 4 </span></span>
<span id="cb201-27"><a href="#cb201-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># optimizr.step()</span></span>
<span id="cb201-28"><a href="#cb201-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># optimizr.zero_grad()</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb202"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb202-1"><a href="#cb202-1" aria-hidden="true" tabindex="-1"></a>ht,ct</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="72">
<pre><code>(tensor([[-0.0406,  0.2505]], grad_fn=&lt;MulBackward0&gt;),
 tensor([[-0.0975,  0.7134]], grad_fn=&lt;AddBackward0&gt;))</code></pre>
</div>
</div>
</section>
</section>
<section id="epoch-ver3-with-torch.nn.lstm" class="level3">
<h3 class="anchored" data-anchor-id="epoch-ver3-with-torch.nn.lstm">1 epoch ver3 (with torch.nn.LSTM)</h3>
<div class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb204"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb204-1"><a href="#cb204-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb204-2"><a href="#cb204-2" aria-hidden="true" tabindex="-1"></a>lstm_cell <span class="op">=</span> torch.nn.LSTMCell(<span class="dv">3</span>,<span class="dv">2</span>)</span>
<span id="cb204-3"><a href="#cb204-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">3</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb205"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb205-1"><a href="#cb205-1" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">3</span>,<span class="dv">2</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb206"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb206-1"><a href="#cb206-1" aria-hidden="true" tabindex="-1"></a>lstm.weight_hh_l0.data <span class="op">=</span> lstm_cell.weight_hh.data </span>
<span id="cb206-2"><a href="#cb206-2" aria-hidden="true" tabindex="-1"></a>lstm.bias_hh_l0.data <span class="op">=</span> lstm_cell.bias_hh.data </span>
<span id="cb206-3"><a href="#cb206-3" aria-hidden="true" tabindex="-1"></a>lstm.weight_ih_l0.data <span class="op">=</span> lstm_cell.weight_ih.data </span>
<span id="cb206-4"><a href="#cb206-4" aria-hidden="true" tabindex="-1"></a>lstm.bias_ih_l0.data <span class="op">=</span> lstm_cell.bias_ih.data </span></code></pre></div>
</div>
<ul>
<li>초기화된 가중치값들로 덮어씌우기</li>
</ul>
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb207"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb207-1"><a href="#cb207-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb207-2"><a href="#cb207-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters()) <span class="op">+</span> <span class="bu">list</span>(linr.parameters()), lr<span class="op">=</span><span class="fl">0.1</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb208"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb208-1"><a href="#cb208-1" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>) </span>
<span id="cb208-2"><a href="#cb208-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>): </span>
<span id="cb208-3"><a href="#cb208-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## step1 </span></span>
<span id="cb208-4"><a href="#cb208-4" aria-hidden="true" tabindex="-1"></a>    hidden, (ht,ct) <span class="op">=</span> lstm(x,(_water,_water))</span>
<span id="cb208-5"><a href="#cb208-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden)</span>
<span id="cb208-6"><a href="#cb208-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ## step2</span></span>
<span id="cb208-7"><a href="#cb208-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loss = loss_fn(output,y) </span></span>
<span id="cb208-8"><a href="#cb208-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ## step3</span></span>
<span id="cb208-9"><a href="#cb208-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loss.backward()</span></span>
<span id="cb208-10"><a href="#cb208-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ## step4 </span></span>
<span id="cb208-11"><a href="#cb208-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># optimizr.step()</span></span>
<span id="cb208-12"><a href="#cb208-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># optimizr.zero_grad() </span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb209"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a>ht,ct</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>(tensor([[-0.0406,  0.2505]], grad_fn=&lt;SqueezeBackward1&gt;),
 tensor([[-0.0975,  0.7134]], grad_fn=&lt;SqueezeBackward1&gt;))</code></pre>
</div>
</div>
</section>
</section>
<section id="lstm은-왜-강한가" class="level2">
<h2 class="anchored" data-anchor-id="lstm은-왜-강한가">LSTM은 왜 강한가?</h2>
<section id="data-abab-1" class="level3">
<h3 class="anchored" data-anchor-id="data-abab-1">data: abaB</h3>
<div class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb211"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb211-1"><a href="#cb211-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'abaB'</span>)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb211-2"><a href="#cb211-2" aria-hidden="true" tabindex="-1"></a>txt[:<span class="dv">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="79">
<pre><code>['a', 'b', 'a', 'B', 'a']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb213"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb213-1"><a href="#cb213-1" aria-hidden="true" tabindex="-1"></a>n_words <span class="op">=</span> <span class="dv">3</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb214"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb214-1"><a href="#cb214-1" aria-hidden="true" tabindex="-1"></a>mapping <span class="op">=</span> {<span class="st">'a'</span>:<span class="dv">0</span>, <span class="st">'b'</span>:<span class="dv">1</span>, <span class="st">'B'</span>:<span class="dv">2</span>}</span></code></pre></div>
</div>
<div class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb215"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb215-1"><a href="#cb215-1" aria-hidden="true" tabindex="-1"></a>txt_x <span class="op">=</span> txt[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb215-2"><a href="#cb215-2" aria-hidden="true" tabindex="-1"></a>txt_y <span class="op">=</span> txt[<span class="dv">1</span>:]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb216"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb216-1"><a href="#cb216-1" aria-hidden="true" tabindex="-1"></a>txt_x[:<span class="dv">10</span>],txt_y[:<span class="dv">10</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="83">
<pre><code>(['a', 'b', 'a', 'B', 'a', 'b', 'a', 'B', 'a', 'b'],
 ['b', 'a', 'B', 'a', 'b', 'a', 'B', 'a', 'b', 'a'])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb218"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb218-1"><a href="#cb218-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).<span class="bu">float</span>()</span>
<span id="cb218-2"><a href="#cb218-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).<span class="bu">float</span>()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb219"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb219-1"><a href="#cb219-1" aria-hidden="true" tabindex="-1"></a>x,y</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<pre><code>(tensor([[1., 0., 0.],
         [0., 1., 0.],
         [1., 0., 0.],
         ...,
         [1., 0., 0.],
         [0., 1., 0.],
         [1., 0., 0.]]),
 tensor([[0., 1., 0.],
         [1., 0., 0.],
         [0., 0., 1.],
         ...,
         [0., 1., 0.],
         [1., 0., 0.],
         [0., 0., 1.]]))</code></pre>
</div>
</div>
</section>
<section id="epoch" class="level3">
<h3 class="anchored" data-anchor-id="epoch">1000 epoch</h3>
<div class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb221"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb221-1"><a href="#cb221-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb221-2"><a href="#cb221-2" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">3</span>,<span class="dv">2</span>) </span>
<span id="cb221-3"><a href="#cb221-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">3</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb222"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb222-1"><a href="#cb222-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() </span>
<span id="cb222-2"><a href="#cb222-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters())<span class="op">+</span> <span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb223"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb223-1"><a href="#cb223-1" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>) </span>
<span id="cb223-2"><a href="#cb223-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>): </span>
<span id="cb223-3"><a href="#cb223-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## step1 </span></span>
<span id="cb223-4"><a href="#cb223-4" aria-hidden="true" tabindex="-1"></a>    hidden, (ht,ct) <span class="op">=</span> lstm(x,(_water,_water))</span>
<span id="cb223-5"><a href="#cb223-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden)</span>
<span id="cb223-6"><a href="#cb223-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## step2</span></span>
<span id="cb223-7"><a href="#cb223-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb223-8"><a href="#cb223-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## step3</span></span>
<span id="cb223-9"><a href="#cb223-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb223-10"><a href="#cb223-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## step4 </span></span>
<span id="cb223-11"><a href="#cb223-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb223-12"><a href="#cb223-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad() </span></code></pre></div>
</div>
</section>
<section id="시각화" class="level3">
<h3 class="anchored" data-anchor-id="시각화">시각화</h3>
<div class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb224"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb224-1"><a href="#cb224-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb224-2"><a href="#cb224-2" aria-hidden="true" tabindex="-1"></a>input_gate <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>)</span>
<span id="cb224-3"><a href="#cb224-3" aria-hidden="true" tabindex="-1"></a>forget_gate <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>)</span>
<span id="cb224-4"><a href="#cb224-4" aria-hidden="true" tabindex="-1"></a>output_gate <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>)</span>
<span id="cb224-5"><a href="#cb224-5" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>)</span>
<span id="cb224-6"><a href="#cb224-6" aria-hidden="true" tabindex="-1"></a>cell <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>)</span>
<span id="cb224-7"><a href="#cb224-7" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>) </span></code></pre></div>
</div>
<ul>
<li>변수를 담을 빈 셋 설정</li>
</ul>
<div class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb225"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb225-1"><a href="#cb225-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T): </span>
<span id="cb225-2"><a href="#cb225-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1: calculate _ifgo </span></span>
<span id="cb225-3"><a href="#cb225-3" aria-hidden="true" tabindex="-1"></a>    _ifgo <span class="op">=</span> x[[t]] <span class="op">@</span> lstm.weight_ih_l0.T <span class="op">+</span> h[[t]] <span class="op">@</span> lstm.weight_hh_l0.T <span class="op">+</span> lstm.bias_ih_l0 <span class="op">+</span> lstm.bias_hh_l0 </span>
<span id="cb225-4"><a href="#cb225-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2: decompose _ifgo </span></span>
<span id="cb225-5"><a href="#cb225-5" aria-hidden="true" tabindex="-1"></a>    input_gate[[t]] <span class="op">=</span> sig(_ifgo[:,<span class="dv">0</span>:<span class="dv">2</span>])</span>
<span id="cb225-6"><a href="#cb225-6" aria-hidden="true" tabindex="-1"></a>    forget_gate[[t]] <span class="op">=</span> sig(_ifgo[:,<span class="dv">2</span>:<span class="dv">4</span>])</span>
<span id="cb225-7"><a href="#cb225-7" aria-hidden="true" tabindex="-1"></a>    g[[t]] <span class="op">=</span> tanh(_ifgo[:,<span class="dv">4</span>:<span class="dv">6</span>])</span>
<span id="cb225-8"><a href="#cb225-8" aria-hidden="true" tabindex="-1"></a>    output_gate[[t]] <span class="op">=</span> sig(_ifgo[:,<span class="dv">6</span>:<span class="dv">8</span>])</span>
<span id="cb225-9"><a href="#cb225-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3: calculate ht,ct </span></span>
<span id="cb225-10"><a href="#cb225-10" aria-hidden="true" tabindex="-1"></a>    cell[[t]] <span class="op">=</span> forget_gate[[t]] <span class="op">*</span> cell[[t]] <span class="op">+</span> input_gate[[t]] <span class="op">*</span> g[[t]]</span>
<span id="cb225-11"><a href="#cb225-11" aria-hidden="true" tabindex="-1"></a>    h[[t]] <span class="op">=</span> output_gate[[t]] <span class="op">*</span> tanh(cell[[t]])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="91">
<div class="sourceCode cell-code" id="cb226"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb226-1"><a href="#cb226-1" aria-hidden="true" tabindex="-1"></a>combinded1 <span class="op">=</span> torch.concat([input_gate,forget_gate,output_gate],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb226-2"><a href="#cb226-2" aria-hidden="true" tabindex="-1"></a>combinded2 <span class="op">=</span> torch.concat([g,cell,h,soft(output)],axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb227"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb227-1"><a href="#cb227-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded1[<span class="op">-</span><span class="dv">8</span>:].data,cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)<span class="op">;</span></span>
<span id="cb227-2"><a href="#cb227-2" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(combinded1.shape[<span class="op">-</span><span class="dv">1</span>]),labels<span class="op">=</span>[<span class="st">'i'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'f'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'o'</span>]<span class="op">*</span><span class="dv">2</span>)<span class="op">;</span></span>
<span id="cb227-3"><a href="#cb227-3" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded2[<span class="op">-</span><span class="dv">8</span>:].data,cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb227-4"><a href="#cb227-4" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(combinded2.shape[<span class="op">-</span><span class="dv">1</span>]),labels<span class="op">=</span>[<span class="st">'g'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'c'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'h'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'yhat'</span>]<span class="op">*</span><span class="dv">3</span>)<span class="op">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-171-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-171-output-2.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>상단그림은 게이트의 값들만 시각화, 하단그림은 게이트 이외의 값들을 시각화</li>
</ul>
</section>
<section id="시각화의-해석i" class="level3">
<h3 class="anchored" data-anchor-id="시각화의-해석i">시각화의 해석I</h3>
<div class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb228"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb228-1"><a href="#cb228-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded1[<span class="op">-</span><span class="dv">8</span>:].data,cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)<span class="op">;</span></span>
<span id="cb228-2"><a href="#cb228-2" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(combinded1.shape[<span class="op">-</span><span class="dv">1</span>]),labels<span class="op">=</span>[<span class="st">'i'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'f'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'o'</span>]<span class="op">*</span><span class="dv">2</span>)<span class="op">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-172-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> input_gate, forget_gate, output_gate는 모두 0~1 사이의 값을 가진다.</p>
<p><code>-</code> 이 값들은 각각 모두 <span class="math inline">\({\boldsymbol g}_t, {\boldsymbol c}_{t-1}, \tanh({\boldsymbol c}_t)\)</span>에 곱해진다. 따라서 input_gate, forget_gate, output_gate 는 gate의 역할로 비유가능하다. (1이면 통과, 0이면 차단)</p>
<ul>
<li>input_gate: <span class="math inline">\({\boldsymbol g}_t\)</span>의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정</li>
<li>forget_gate: <span class="math inline">\({\boldsymbol c}_{t-1}\)</span>의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정</li>
<li>output_gate: <span class="math inline">\(\tanh({\boldsymbol c}_t)\)</span>의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정</li>
</ul>
<p>(서연 필기)</p>
<ul>
<li>값들이 0과 1사이의 값을 가진다</li>
<li>파 -1 흰 0 빨 1</li>
<li>0 곱하면 어떤 값이든 0이 되니까 차단한다 표현</li>
</ul>
</section>
<section id="시각화의-해석ii" class="level3">
<h3 class="anchored" data-anchor-id="시각화의-해석ii">시각화의 해석II</h3>
<div class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb229"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb229-1"><a href="#cb229-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded2[<span class="op">-</span><span class="dv">8</span>:].data,cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb229-2"><a href="#cb229-2" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(combinded2.shape[<span class="op">-</span><span class="dv">1</span>]),labels<span class="op">=</span>[<span class="st">'g'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'c'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'h'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'yhat'</span>]<span class="op">*</span><span class="dv">3</span>)<span class="op">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-173-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 결국 <span class="math inline">\({\boldsymbol g}_t\to {\boldsymbol c}_t \to {\boldsymbol h}_t \to \hat{\boldsymbol y}\)</span> 의 느낌이다. (<span class="math inline">\({\boldsymbol h}_t\)</span>를 계산하기 위해서는 <span class="math inline">\({\boldsymbol c}_t\)</span>가 필요했고 <span class="math inline">\({\boldsymbol c}_t\)</span>를 계산하기 위해서는 <span class="math inline">\({\boldsymbol c}_{t-1}\)</span>과 <span class="math inline">\({\boldsymbol g}_t\)</span>가 필요했음)</p>
<ul>
<li><span class="math inline">\({\boldsymbol h}_t= \tanh({\boldsymbol c}_t) \odot {\boldsymbol o}_t\)</span></li>
<li><span class="math inline">\({\boldsymbol c}_t ={\boldsymbol c}_{t-1} \odot {\boldsymbol f}_t + {\boldsymbol g}_{t} \odot {\boldsymbol i}_t\)</span></li>
</ul>
<p><code>-</code> <span class="math inline">\({\boldsymbol g}_t,{\boldsymbol c}_t,{\boldsymbol h}_t\)</span> 모두 <span class="math inline">\({\boldsymbol x}_t\)</span>의 정보를 숙성시켜 가지고 있는 느낌이 든다.</p>
<p><code>-</code> <span class="math inline">\({\boldsymbol g}_t\)</span> 특징: 보통 -1,1 중 하나의 값을 가지도록 학습되어 있다. (마치 RNN의 hidden node처럼!)</p>
<ul>
<li><span class="math inline">\(\boldsymbol{g}_t = \tanh({\boldsymbol x}_t {\bf W}_{ig} + {\boldsymbol h}_{t-1} {\bf W}_{hg}+ {\boldsymbol b}_{ig}+{\boldsymbol b}_{hg})\)</span></li>
</ul>
<p><code>-</code> <span class="math inline">\({\boldsymbol c}_t\)</span> 특징: <span class="math inline">\({\boldsymbol g}_t\)</span>와 매우 비슷하지만 약간 다른값을 가진다. 그래서 <span class="math inline">\({\boldsymbol g}_t\)</span>와는 달리 -1,1 이외의 값도 종종 등장.</p>
<div class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb230"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb230-1"><a href="#cb230-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"first row: gt=</span><span class="sc">{}</span><span class="st">, ct=</span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(g[<span class="op">-</span><span class="dv">8</span>].data, cell[<span class="op">-</span><span class="dv">8</span>].data))</span>
<span id="cb230-2"><a href="#cb230-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"second row: gt=</span><span class="sc">{}</span><span class="st">, ct=</span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(g[<span class="op">-</span><span class="dv">7</span>].data, cell[<span class="op">-</span><span class="dv">7</span>].data))</span>
<span id="cb230-3"><a href="#cb230-3" aria-hidden="true" tabindex="-1"></a><span class="co">#g[-7], cell[-7]</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>first row: gt=tensor([ 0.9999, -0.9999]), ct=tensor([ 0.9647, -0.9984])
second row: gt=tensor([ 0.9970, -0.9554]), ct=tensor([ 0.3592, -0.9373])</code></pre>
</div>
</div>
<p><code>-</code> <span class="math inline">\({\boldsymbol h}_t\)</span> 특징: (1) <span class="math inline">\({\boldsymbol c}_t\)</span>의 느낌이 있음 하지만 약간의 변형이 있음. (2) -1~1 사이에의 값을 훨씬 다양하게 가진다. (tanh때문)</p>
<p>(서연 필기)</p>
<ul>
<li>comparison of g,c part
<ul>
<li>보니까 빨간 색은 1에 가까운 값, 파란색은 -1에 가까운 값들을 띄었다.</li>
<li>그리고 연한 빨간색인 부분은 0.3592로 낮았고, g부분과 c부분이 열별로 보았을 때 달랐다</li>
</ul></li>
</ul>
<div class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb232"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb232-1"><a href="#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"first row: gt=</span><span class="sc">{}</span><span class="st">, ct=</span><span class="sc">{}</span><span class="st">, ht=</span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(g[<span class="op">-</span><span class="dv">8</span>].data, cell[<span class="op">-</span><span class="dv">8</span>].data,h[<span class="op">-</span><span class="dv">8</span>].data))</span>
<span id="cb232-2"><a href="#cb232-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"second row: gt=</span><span class="sc">{}</span><span class="st">, ct=</span><span class="sc">{}</span><span class="st">, ht=</span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(g[<span class="op">-</span><span class="dv">7</span>].data, cell[<span class="op">-</span><span class="dv">7</span>].data,h[<span class="op">-</span><span class="dv">7</span>].data))</span>
<span id="cb232-3"><a href="#cb232-3" aria-hidden="true" tabindex="-1"></a><span class="co">#g[-7], cell[-7]</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>first row: gt=tensor([ 0.9999, -0.9999]), ct=tensor([ 0.9647, -0.9984]), ht=tensor([ 0.7370, -0.3323])
second row: gt=tensor([ 0.9970, -0.9554]), ct=tensor([ 0.3592, -0.9373]), ht=tensor([ 0.0604, -0.6951])</code></pre>
</div>
</div>
<p>(서연 필기)</p>
<ul>
<li>comparison of c,h part
<ul>
<li>h는 c와 무관해보이지 않는다.</li>
<li>단지 어떤 변형이 있는 것 같다.</li>
</ul></li>
</ul>
<p><code>-</code> 예전의문 해결</p>
<ul>
<li>실험적으로 살펴보니 LSTM이 RNN보다 장기기억에 유리했음.</li>
<li>그 이유: RRN은 <span class="math inline">\({\boldsymbol h}_t\)</span>의 값이 -1 혹은 1로 결정되는 경우가 많았음. 그러나 경우에 따라서는 <span class="math inline">\({\boldsymbol h}_t\)</span>이 -1~1의 값을 가지는 것이 문맥적 뉘앙스를 포착하기에는 유리한데 LSTM이 이러한 방식으로 학습되는 경우가 많았음.</li>
<li>왜 LSTM의 <span class="math inline">\({\boldsymbol h}_t\)</span>은 -1,1 이외의 값을 쉽게 가질 수 있는가? (1) gate들의 역할 (2) 마지막에 취해지는 tanh 때문</li>
</ul>
</section>
<section id="lstm의-알고리즘-리뷰-i-수식위주" class="level3">
<h3 class="anchored" data-anchor-id="lstm의-알고리즘-리뷰-i-수식위주">LSTM의 알고리즘 리뷰 I (수식위주)</h3>
<p><strong>(step1)</strong> calculate <span class="math inline">\({\tt ifgo}\)</span></p>
<p><span class="math inline">\({\tt ifgo} = {\boldsymbol x}_t \big[{\bf W}_{ii} | {\bf W}_{if}| {\bf W}_{ig} |{\bf W}_{io}\big] + {\boldsymbol h}_{t-1} \big[ {\bf W}_{hi}|{\bf W}_{hf} |{\bf W}_{hg} | {\bf W}_{ho} \big] + bias\)</span></p>
<p><span class="math inline">\(=\big[{\boldsymbol x}_t{\bf W}_{ii} + {\boldsymbol h}_{t-1}{\bf W}_{hi} ~\big|~ {\boldsymbol x}_t{\bf W}_{if}+ {\boldsymbol h}_{t-1}{\bf W}_{hf}~ \big|~ {\boldsymbol x}_t{\bf W}_{ig} + {\boldsymbol h}_{t-1}{\bf W}_{hg} ~\big|~ {\boldsymbol x}_t{\bf W}_{io} + {\boldsymbol h}_{t-1}{\bf W}_{ho} \big] + bias\)</span></p>
<p>참고: 위의 수식은 아래코드에 해당하는 부분</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb234-1"><a href="#cb234-1" aria-hidden="true" tabindex="-1"></a>ifgo <span class="op">=</span> xt <span class="op">@</span> lstm_cell.weight_ih.T <span class="op">+</span> ht <span class="op">@</span> lstm_cell.weight_hh.T <span class="op">+</span> lstm_cell.bias_ih <span class="op">+</span> lstm_cell.bias_hh</span></code></pre></div>
<p><strong>(step2)</strong> decompose <span class="math inline">\({\tt ifgo}\)</span> and get <span class="math inline">\({\boldsymbol i}_t\)</span>, <span class="math inline">\({\boldsymbol f}_t\)</span>, <span class="math inline">\({\boldsymbol g}_t\)</span>, <span class="math inline">\({\boldsymbol o}_t\)</span></p>
<p><span class="math inline">\({\boldsymbol i}_t = \sigma({\boldsymbol x}_t {\bf W}_{ii} + {\boldsymbol h}_{t-1} {\bf W}_{hi} +bias )\)</span></p>
<p><span class="math inline">\({\boldsymbol f}_t = \sigma({\boldsymbol x}_t {\bf W}_{if} + {\boldsymbol h}_{t-1} {\bf W}_{hf} +bias )\)</span></p>
<p><span class="math inline">\({\boldsymbol g}_t = \tanh({\boldsymbol x}_t {\bf W}_{ig} + {\boldsymbol h}_{t-1} {\bf W}_{hg} +bias )\)</span></p>
<p><span class="math inline">\({\boldsymbol o}_t = \sigma({\boldsymbol x}_t {\bf W}_{io} + {\boldsymbol h}_{t-1} {\bf W}_{ho} +bias )\)</span></p>
<p><strong>(step3)</strong> calculate <span class="math inline">\({\boldsymbol c}_t\)</span> and <span class="math inline">\({\boldsymbol h}_t\)</span></p>
<p><span class="math inline">\({\boldsymbol c}_t = {\boldsymbol i}_t \odot {\boldsymbol g}_t+ {\boldsymbol f}_t \odot {\boldsymbol c}_{t-1}\)</span></p>
<p><span class="math inline">\({\boldsymbol h}_t = \tanh({\boldsymbol o}_t \odot {\boldsymbol c}_t)\)</span></p>
</section>
<section id="lstm의-알고리즘-리뷰-ii-느낌위주" class="level3">
<h3 class="anchored" data-anchor-id="lstm의-알고리즘-리뷰-ii-느낌위주">LSTM의 알고리즘 리뷰 II (느낌위주)</h3>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ } \triangleleft \text{ }\underrightarrow{sig} \text{ }o_t\)</span></p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ }\circ \text{ , } \square \text{, } \star \text{, } \triangleleft \text{ } \to \sigma(circ) \text{, }\sigma(\square) \text{ , }\tanh(\star)\text{ , } \sigma(\triangleleft) \sim i_t, f_t, g_t, o_t\)</span></p>
<ul>
<li>이해 및 암기를 돕기위해서 비유적으로 설명한 챕터입니다..</li>
</ul>
<p><code>-</code> 느낌1: RNN이 콩물에서 간장을 한번에 숙성시키는 방법이라면 LSTM은 콩물에서 간장을 3차로 나누어 숙성하는 느낌이다.</p>
<ul>
<li>콩물: <span class="math inline">\({\boldsymbol x}_t\)</span></li>
<li>1차숙성: <span class="math inline">\({\boldsymbol g}_t\)</span></li>
<li>2차숙성: <span class="math inline">\({\boldsymbol c}_t\)</span></li>
<li>3차숙성: <span class="math inline">\({\boldsymbol h}_t\)</span></li>
</ul>
<p><code>-</code> 느낌2: <span class="math inline">\({\boldsymbol g}_t\)</span>에 대하여</p>
<ul>
<li>계산방법: <span class="math inline">\({\boldsymbol x}_t\)</span>와 <span class="math inline">\({\boldsymbol h}_{t-1}\)</span>를 <span class="math inline">\({\bf W}_{ig}, {\bf W}_{hg}\)</span>를 이용해 선형결합하고 <span class="math inline">\(\tanh\)</span>를 취한 결과</li>
<li>RNN에서 간장을 만들던 그 수식에서 <span class="math inline">\(h_t\)</span>를 <span class="math inline">\(g_t\)</span>로 바꾼것</li>
<li>크게 2가지의 의미를 가진다 (1) 과거와 현재의 결합 (2) 활성화함수 <span class="math inline">\(\tanh\)</span>를 적용</li>
</ul>
<p>(서연 필기)</p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ }\circ \text{ }\underrightarrow{sig} \text{ }i_t\)</span></p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ }\square \text{ } \underrightarrow{sig} \text{ }f_t\)</span></p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ }\star \text{ } \underrightarrow{tanh} \text{ }g_t\)</span></p>
<p>를 풀어서 쓰면</p>
<p><span class="math inline">\(\tanh(x_t W_{ig} + h_{t-1} W_{hg} + bias)\)</span></p>
<p>RNN: <span class="math inline">\(h_t = \tanh(x_t W + h_{t-1} W + bias)\)</span></p>
<p>LSTM: <span class="math inline">\(g_t = \tanh(x_t W + h_{t-1} W + bias)\)</span> - 과거<span class="math inline">\(h_{t-1}\)</span>와 현재<span class="math inline">\(x_t\)</span>의 결합</p>
<p><code>-</code> 느낌3: <span class="math inline">\({\boldsymbol c}_t\)</span>에 대하여 (1)</p>
<ul>
<li>계산방법: <span class="math inline">\({\boldsymbol g}_{t}\)</span>와 <span class="math inline">\({\boldsymbol c}_{t-1}\)</span>를 요소별로 선택하고 더하는 과정</li>
<li><span class="math inline">\(g_t\)</span>는 (1) 과거와 현재의 결합 (2) 활성화함수 tanh를 적용으로 나누어지는데 이중에서 (1) 과거와 현재의 정보를 결합하는 과정만 해당한다. 차이점은 요소별 선택 후 덧셈
<ul>
<li><span class="math inline">\(g_t\)</span>는 선형 결합</li>
</ul></li>
<li>이러한 결합을 쓰는 이유? 게이트를 이용하여 과거와 현재의 정보를 제어 (일반적인 설명, 솔직히 내가 좋아하는 설명은 아님)</li>
</ul>
<p>(서연 필기)</p>
<p><span class="math inline">\(c_t = g_t \odot Input + c_{t-1} \odot Forget\)</span></p>
<p><code>-</code> 느낌4: <span class="math inline">\({\boldsymbol c}_t\)</span>에 대하여 (2) // <span class="math inline">\({\boldsymbol c}_t\)</span>는 왜 과거와 현재의 정보를 제어한다고 볼 수 있는가?</p>
<p><span class="math inline">\(t=1\)</span> 시점 계산과정관찰</p>
<div class="cell" data-execution_count="98">
<div class="sourceCode cell-code" id="cb235"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb235-1"><a href="#cb235-1" aria-hidden="true" tabindex="-1"></a>input_gate[<span class="dv">1</span>],g[<span class="dv">1</span>],forget_gate[<span class="dv">1</span>],cell[<span class="dv">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="98">
<pre><code>(tensor([0.9065, 0.9999], grad_fn=&lt;SelectBackward0&gt;),
 tensor([0.9931, 0.9999], grad_fn=&lt;SelectBackward0&gt;),
 tensor([0.9931, 0.0014], grad_fn=&lt;SelectBackward0&gt;),
 tensor([ 0.3592, -0.9373], grad_fn=&lt;SelectBackward0&gt;))</code></pre>
</div>
</div>
<p><span class="math inline">\([0.9,1.0] \odot {\boldsymbol g}_t + [1.0,0.0] \odot {\boldsymbol c}_{t-1}\)</span></p>
<p>(서연 필기)</p>
<p>여기서 곱은 element별 곱 - <span class="math inline">\([0.9,1.0] \odot g_t = [0.9,1.0]\odot [g_1,g_2] = [0.9g_1(현재)_,1.0g_2(과거)]\)</span> - 여기서 0이 현재에 곱해지면 현재를 기억하지 않고 과거에 0이 곱해지면 과거를 기억하지 않도록 조정할 수 있음</p>
<p><span class="math inline">\(\star\)</span> gate없으면 조정 못 하나??<span class="math inline">\(\to\)</span> no, weigjht로도 조정할 수 있지 않을까?</p>
<ul>
<li>forget_gate는 <span class="math inline">\(c_{t-1}\)</span>의 첫번째 원소는 기억하고, 두번째 원소는 잊으라고 말하고 있음 // forget_gate는 과거(<span class="math inline">\(c_{t-1}\)</span>)의 정보를 얼마나 잊을지 (= 얼마나 기억할지) 를 결정한다고 해석할 수 있다.</li>
<li>input_gate는 <span class="math inline">\(g_{t}\)</span>의 첫번째 원소와 두번째 원소를 모두 기억하되 두번째 원소를 좀 더 중요하게 기억하라고 말하고 있음 // input_gate는 현재(<span class="math inline">\(g_{t}\)</span>)의 정보를 얼만큼 강하게 반영할지 결정한다.</li>
<li>이 둘을 조합하면 <span class="math inline">\({\boldsymbol c}_t\)</span>가 현재와 과거의 정보중 어떠한 정보를 더 중시하면서 기억할지 결정한다고 볼 수 있다.</li>
</ul>
<blockquote class="blockquote">
<p>이 설명은 제가 좀 싫어해요, 싫어하는 이유는 (1) “기억의 정도를 조절한다”와 “망각의 정도를 조절한다”는 사실 같은말임. 그래서 forget_gate의 용어가 모호함. (2) 기억과 망각을 조정하는 방식으로 꼭 gate의 개념을 사용해야 하는건 아님</p>
</blockquote>
<p><code>-</code> 느낌5: <span class="math inline">\({\boldsymbol c}_t\)</span>에 대하여 (3)</p>
<ul>
<li>사실상 LSTM 알고리즘의 꽃이라 할 수 있음.</li>
<li>LSTM은 long short term memory의 약자임. 기존의 RNN은 장기기억을 활용함에 약점이 있는데 LSTM은 단기기억/장기기억 모두 잘 활용함.</li>
<li>LSTM이 장기기억을 잘 활용하는 비법은 바로 <span class="math inline">\({\boldsymbol c}_t\)</span>에 있다.</li>
</ul>
<p>(서연필기) <span class="math inline">\(c_t\)</span>로 과거, 현재 기억 조절할 수 있기 때문에</p>
<p><code>-</code> 느낌6: <span class="math inline">\({\boldsymbol h}_t\)</span>에 대하여 - 계산방법: <span class="math inline">\(\tanh({\boldsymbol c}_t)\)</span>를 요소별로 선택</p>
<p>데이터 다 가져와서 선택하는 방식</p>
<p><code>-</code> RNN, LSTM의 변수들 비교 테이블</p>
<table class="table">
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">과거정보</th>
<th style="text-align: center;">현재정보</th>
<th style="text-align: center;">과거와 현재의 결합방식</th>
<th style="text-align: center;">활성화</th>
<th style="text-align: center;">느낌</th>
<th style="text-align: center;">비고</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">RNN-<span class="math inline">\({\boldsymbol h}_t\)</span></td>
<td style="text-align: center;"><span class="math inline">\({\boldsymbol h}_{t-1}\)</span></td>
<td style="text-align: center;"><span class="math inline">\({\boldsymbol x}_t\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\times\)</span> W <span class="math inline">\(\to\)</span> <span class="math inline">\(+\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\tanh\)</span></td>
<td style="text-align: center;">간장</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">LSTM-<span class="math inline">\({\boldsymbol g}_t\)</span></td>
<td style="text-align: center;"><span class="math inline">\({\boldsymbol h}_{t-1}\)</span></td>
<td style="text-align: center;"><span class="math inline">\({\boldsymbol x}_t\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\times\)</span>W <span class="math inline">\(\to\)</span> <span class="math inline">\(+\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\tanh\)</span></td>
<td style="text-align: center;">1차간장</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">LSTM-<span class="math inline">\({\boldsymbol c}_t\)</span></td>
<td style="text-align: center;"><span class="math inline">\({\boldsymbol c}_{t-1}\)</span></td>
<td style="text-align: center;"><span class="math inline">\({\boldsymbol g}_t\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\odot\)</span> W<span class="math inline">\(\to\)</span> <span class="math inline">\(+\)</span></td>
<td style="text-align: center;">None</td>
<td style="text-align: center;">2차간장</td>
<td style="text-align: center;">gate를 열림정도를 판단할때 <span class="math inline">\({\boldsymbol x}_t\)</span>와 <span class="math inline">\({\boldsymbol h}_{t-1}\)</span>을 이용</td>
</tr>
<tr class="odd">
<td style="text-align: center;">LSTM-<span class="math inline">\({\boldsymbol h}_t\)</span></td>
<td style="text-align: center;">None</td>
<td style="text-align: center;"><span class="math inline">\({\boldsymbol c}_t\)</span></td>
<td style="text-align: center;">None</td>
<td style="text-align: center;"><span class="math inline">\(\tanh\)</span>, <span class="math inline">\(\odot\)</span></td>
<td style="text-align: center;">3차간장</td>
<td style="text-align: center;">gate를 열림정도를 판단할때 <span class="math inline">\({\boldsymbol x}_t\)</span>와 <span class="math inline">\({\boldsymbol h}_{t-1}\)</span>을 이용</td>
</tr>
</tbody>
</table>
<ul>
<li>RNN은 기억할 과거정보가 <span class="math inline">\({\boldsymbol h}_{t-1}\)</span> 하나이지만 LSTM은 <span class="math inline">\({\boldsymbol c}_{t-1}\)</span>, <span class="math inline">\({\boldsymbol h}_{t-1}\)</span> 2개이다.</li>
</ul>
<p><code>-</code> 알고리즘리뷰 :</p>
<ul>
<li>콩물<span class="math inline">\(x_t\)</span>,과거3차간장<span class="math inline">\(h_{t-1}\)</span> <span class="math inline">\(\overset{\times,+,\tanh}{\longrightarrow}\)</span> 현재1차간장<span class="math inline">\(g_t\)</span></li>
<li>현재1차간장<span class="math inline">\(c_{t-1}\)</span>, 과거2차간장 <span class="math inline">\(\overset{\odot,+,\tanh}{\longrightarrow}\)</span> 현재2차간장</li>
<li>현재2차간장<span class="math inline">\(c_t\)</span> <span class="math inline">\(\overset{\tanh,\odot}{\longrightarrow}\)</span> 현재3차간장<span class="math inline">\(h_t\)</span></li>
</ul>
</section>
<section id="lstm이-강한이유" class="level3">
<h3 class="anchored" data-anchor-id="lstm이-강한이유">LSTM이 강한이유</h3>
<p><code>-</code> LSTM이 장기기억에 유리함. 그 이유는 input, forget, output gate 들이 과거기억을 위한 역할을 하기 때문.</p>
<ul>
<li>비판: 아키텍처에 대한 이론적 근거는 없음. 장기기억을 위하여 꼭 LSTM같은 구조일 필요는 없음. (왜 3차간장을 만들때 tanh를 써야하는지? 게이트는 꼭3개이어야 하는지?)</li>
</ul>
<p><code>-</code> 저는 사실 아까 살펴본 아래의 이유로 이해하고 있습니다.</p>
<ul>
<li>실험적으로 살펴보니 LSTM이 RNN보다 장기기억에 유리했음.</li>
<li>그 이유: RRN은 <span class="math inline">\({\boldsymbol h}_t\)</span>의 값이 -1 혹은 1로 결정되는 경우가 많았음. 그러나 경우에 따라서는 <span class="math inline">\({\boldsymbol h}_t\)</span>이 -1~1의 값을 가지는 것이 문맥적 뉘앙스를 포착하기에는 유리한데 LSTM이 이러한 방식으로 학습되는 경우가 많았음.</li>
<li>왜 LSTM의 <span class="math inline">\({\boldsymbol h}_t\)</span>은 -1,1 이외의 값을 쉽게 가질 수 있는가? (1) gate들의 역할 (2) 마지막에 취해지는 tanh 때문</li>
</ul>
<p>문잭적으로 이해 -&gt;유리하다 칭함</p>
</section>
</section>
<section id="참고자료들" class="level2">
<h2 class="anchored" data-anchor-id="참고자료들">참고자료들</h2>
<ul>
<li><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" class="uri">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></li>
<li><a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html" class="uri">https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html</a></li>
<li><a href="https://arxiv.org/abs/1402.1128" class="uri">https://arxiv.org/abs/1402.1128</a></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>