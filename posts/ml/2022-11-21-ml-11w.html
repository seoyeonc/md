<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.527">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="SEOYEON CHOI">
<meta name="dcterms.date" content="2022-11-21">

<title>Seoyeon’s Blog for classes - RNN (11주차)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Seoyeon’s Blog for classes</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://seoyeonc.github.io/sy_hub/"> 
<span class="menu-text">Main_Blog</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../about.html" aria-current="page"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/seoyeonc/md/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../posts/ml_basic/index.html">Posts</a></li><li class="breadcrumb-item"><a href="../../posts/ml/index.html">Special Topics in Machine Learning</a></li><li class="breadcrumb-item"><a href="../../posts/ml/2022-11-21-ml-11w.html">RNN (11주차)</a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../posts/ml_basic/index.html">Posts</a></li><li class="breadcrumb-item"><a href="../../posts/ml/index.html">Special Topics in Machine Learning</a></li><li class="breadcrumb-item"><a href="../../posts/ml/2022-11-21-ml-11w.html">RNN (11주차)</a></li></ol></nav>
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">RNN (11주차)</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Special Topics in Machine Learning</div>
                <div class="quarto-category">순환신경망</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>SEOYEON CHOI </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 21, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Posts</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ml_basic/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Machine Learning basic</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-23-Support Vector Machine.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Machine</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-28-Linear Regression, Logistic Regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-28-Principal Component Analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Principal Component Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-29-Lasso and Ridge.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lasso and Ridge</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-03-31-Ridge Regression_note3_0331.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ridge Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-04-02-Ensemble and Random Forest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ensemble and Random Forest</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-04-09-Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-05-09-EM_algorithm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Expectation Maximization(EM algorithm)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-05-20-Manifold learning Embedding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Manifold learning Embedding</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-05-28-Attention Mechanism.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Attention Mechanism</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-05-28-Sequence-to-Sequence, seq2seq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sequence-to-Sequence, seq2seq</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-05-28-Transformer Chatbot Tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Transformer Chatbot Tutorial</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-05-28-Transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Transformers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml_basic/2023-06-15-Laplace.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Laplace Distribution</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/rl/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Regression Analysis</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-09-21-rl_CH03, CH04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">고급회귀분석 실습 CH03, CH04</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-09-21-rl_HW1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regression HW 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-10-23-rl-HW2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regression HW 2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-14-rl_CH06, CH07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">고급회귀분석 실습 CH06, CH07</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-21-rl-HW3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regression HW 3</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-23-rl-CH10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">고급회귀분석 실습 CH10</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-28-rl-CH13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">고급회귀분석 실습 CH13</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-12-05-rl-CH11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">고급회귀분석 실습 CH11</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-12-08-rl-HW4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regression HW 4</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-12-11-rl-Ch10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">고급회귀분석 CH10</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2023-02-22-rl-mid_term.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Regression Analysis Mid Term</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2023-02-23-rl-final_term.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Regression Analysis Final Term</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2023-03-02-graduation_test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Regression Analysis GT</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ml/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Special Topics in Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-07-ml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-07-ml_1w.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DNN (1주차)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-14-ml_2w.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DNN (2주차)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-19-Assignment-1-Copy1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-21-ml_3w.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DNN (3주차)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-29-ml_4w.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DNN (4주차)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-05-ml-5w.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DNN (5주차)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-05-ml-HW.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-12-ml-6w.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DNN (6주차)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-19-ml_7w.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CNN (7주차)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-26-ml_8w_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CNN (8주차) 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-26-ml_8w_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CNN (8주차) 2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-02-ml_9w.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">RNN (9주차)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-02-ml-midterm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Midterm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-09-ml-10w.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">RNN (10주차)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-21-ml-11w.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">RNN (11주차)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-29-13wk-2-final.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deep Learning final example</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-30-12wk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">RNN (12주차)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-08-13wk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">RNN (13주차)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-13-final_seoyeon.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Finalterm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-14-study.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">study</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-21-Extra-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Extra-1: 추천시스템</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-21-Extra-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Extra-2: 생성모형(GAN)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-12-23-Extra-3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Extra-3: 딥러닝의 기초 (5)</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ap/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Probability Theory</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-07-1wk-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">01wk-2: 강의소개</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-07-ap_1wk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1주차: 측도론</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-09-2wk-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">02wk-1: 측도론 intro (1)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-14-2wk-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">02wk-2: 측도론 intro (2)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-14-ap-02wk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">02wk: 측도론 intro (2)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-16-3wk-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">03wk-1: 측도론 intro (3)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-21-3wk-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">03wk-2: 측도론 intro (4)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-21-ap-03wk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">03wk: 측도론 intro (3)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-23-4wk-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">04wk-1: 측도론 intro (5)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-28-4wk-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">04wk-2: 측도론 intro (6)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-28-ap-04wk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">04wk: 측도론 intro (4)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-29-5wk-2-hw1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">05wk-2: HW1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-03-30-5wk-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">05wk-1: 마코프체인 (1)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-04-05-ap-05wk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">05wk: 측도론 (1)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-04-10-6wk-2-mid.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">06wk-2: 중간고사</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-04-11-ap-06wk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">06wk: 측도론 (2)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-04-13-7wk-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">07wk-1: 마코프체인 (2)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-04-13-7wk-2.out.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">07wk-2: 마코프체인 (3)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-04-18-ap-07wk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7wk: 측도론 (3)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-04-20-8wk-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">08wk-1: 마코프체인 (4)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-04-25-8wk-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">08wk-2: 마코프체인 (5)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-04-25-ap-08wk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">08wk: 측도론 (4)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-04-27-9wk-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">09wk-1: 마코프체인 (6)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-05-02-ap-09wk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">09wk: 확률변수</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-05-09-10wk-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10wk-2: 마코프체인 (7)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-05-09-ap-10wk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10wk: 분포, 분포함수</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-05-11-11wk-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11wk-1: 마코프체인 (8)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-05-16-11wk-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11wk-2: 마코프체인 (9)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-05-16-ap-11wk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11wk: 적분 (1)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-05-18-12wk-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12wk-1: 마코프체인 (10)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-05-23-12wk-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12wk-2: 마코프체인 (11)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-05-23-ap-12wk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12wk: 적분 (2)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-05-25-13wk-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13wk-1: 마코프체인 (12)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-05-30-13wk-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13wk-2: MCMC (1)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-05-30-ap-13wk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13wk: 밀도함수</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-06-01-14wk-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">14wk-1,2: MCMC (2)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-06-06-ap-14wk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">14wk: 이산형과 연속형의 통합</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-06-08-15wk-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">15wk-1: MCMC (3)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-06-13-fin.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">15wk: 기말고사</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ap/2023-06-20-15wk-2-fin.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">15wk-2: 기말고사</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/anything/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Anything</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/2023-04-17-Survival_Analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Survival Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/2023-04-20-hazard_ratio,odds_ratio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hazard ratio, Odds ratio</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/2023-04-27-Clinical Trial Data and Survival Analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clinical Trial Data and Survival Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/2023-05-04-questions of pytorch geometric temporal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Questions of PyTorch Geometric Temporal</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/2023-06-01-Survival_R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Survival Analysis Tutorial with R</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/2023-06-12-post_hoc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Post Hoc Tests</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/2023-06-12-Steady State.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Steady State</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/2023-06-15-PK Analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Pharmacokinetic Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/2023-11-15-DV2023-09wk-1-mid.out.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">STBDA2023 09wk-1: 중간고사_sy</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/2023-12-07_any_tip.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">정리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/A1.out.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A1: 강화학습 (1) – bandit</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/A2.out.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A2: 강화학습 (2) – 4x4 grid</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/anything/A3.out.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A3: 강화학습 (3) – LunarLander</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/as/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Special Topics in Applied Statistics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/as/2023-07-30-multicollinearity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multicollinearity</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ct/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coding Test</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-01-Coding_Test_Greedy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 03 Greedy</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-15-Coding_Test_Algorithm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Algorithm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-15-Coding_Test_interfunction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">내장함수</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-21-Coding_Test_Q1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">성격 유형 검사하기(Done)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-23-Coding_Test_Q2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">두 큐 합 같게 만들기(Done)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-01-30-Coding_Test_Q3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">코딩 테스트 공부(Done)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-02-12-Coding_Test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ArrayList &amp; LinkedList</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-03-05-Coding_Test_Stack.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Stack</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-03-12-Coding_Test_Queue.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Queue</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-03-22-Coding_Test_Tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tree</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ct/2023-08-26-Coding_Test_pp_hw.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>[Coding Test]</strong>Python Programming HW review</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ts/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Theoritical Statistics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2022-12-31-ts_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률변수와 확률분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-05-ts_HW1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Theoritical Statistics HW1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-05-ts_HW2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Theoritical Statistics HW2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-05-ts_HW3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Theoritical Statistics HW3</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-09-ts_HW4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Theoritical Statistics HW4</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-12-ts_HW5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Theoritical Statistics HW5</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-14-ts_HW6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Theoritical Statistics HW6</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-14-ts_Mid term.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Theoritical Statistics Mid term</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-18-ts_HW7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Theoritical Statistics HW7</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-18-ts-HW8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Theoritical Statistics HW8</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-21-ts-HW9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Theoritical Statistics HW9</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-01-25-ts-final term.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Theoritical Statistics Final term</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-03-03-graduation_test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Theoritical Statistics GT</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ts/2023-03-03-ts-final_qanda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Theoritical Statistics Final term 6 Explanation</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="false">
 <span class="menu-text">Python</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/python/2025-08-18-supervised_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Supervised Learning</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="false">
 <span class="menu-text">Sas</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/sas/2025-08-19-SAS1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SAS Advanced Certificate</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#import" id="toc-import" class="nav-link active" data-scroll-target="#import">import</a></li>
  <li><a href="#define-some-funtions" id="toc-define-some-funtions" class="nav-link" data-scroll-target="#define-some-funtions">Define some funtions</a></li>
  <li><a href="#exam4-abacad-2" id="toc-exam4-abacad-2" class="nav-link" data-scroll-target="#exam4-abacad-2">Exam4: AbAcAd (2)</a>
  <ul class="collapse">
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data">data</a></li>
  <li><a href="#순환신경망-구현1-손으로-직접구현-리뷰" id="toc-순환신경망-구현1-손으로-직접구현-리뷰" class="nav-link" data-scroll-target="#순환신경망-구현1-손으로-직접구현-리뷰">순환신경망 구현1 (손으로 직접구현) – 리뷰</a></li>
  <li><a href="#순환신경망-구현2-with-rnncell-hidden-node-2" id="toc-순환신경망-구현2-with-rnncell-hidden-node-2" class="nav-link" data-scroll-target="#순환신경망-구현2-with-rnncell-hidden-node-2">순환신경망 구현2 (with RNNCell, hidden node 2)</a></li>
  <li><a href="#순환신경망-구현3-with-rnn-hidden-node-2-성공" id="toc-순환신경망-구현3-with-rnn-hidden-node-2-성공" class="nav-link" data-scroll-target="#순환신경망-구현3-with-rnn-hidden-node-2-성공">순환신경망 구현3 (with RNN, hidden node 2) – 성공</a></li>
  <li><a href="#순환신경망-구현4-with-rnn-hidden-node-3-성공" id="toc-순환신경망-구현4-with-rnn-hidden-node-3-성공" class="nav-link" data-scroll-target="#순환신경망-구현4-with-rnn-hidden-node-3-성공">순환신경망 구현4 (with RNN, hidden node 3) – 성공</a></li>
  </ul></li>
  <li><a href="#gpu-실험" id="toc-gpu-실험" class="nav-link" data-scroll-target="#gpu-실험">GPU 실험</a>
  <ul class="collapse">
  <li><a href="#len-20-hidden-nodes" id="toc-len-20-hidden-nodes" class="nav-link" data-scroll-target="#len-20-hidden-nodes">20000 len + 20 hidden nodes</a></li>
  <li><a href="#len-20-hidden-nodes-역전파주석처리" id="toc-len-20-hidden-nodes-역전파주석처리" class="nav-link" data-scroll-target="#len-20-hidden-nodes-역전파주석처리">20000 len + 20 hidden nodes + 역전파주석처리</a></li>
  <li><a href="#len-20-hidden-nodes-1" id="toc-len-20-hidden-nodes-1" class="nav-link" data-scroll-target="#len-20-hidden-nodes-1">2000 len + 20 hidden nodes</a></li>
  <li><a href="#len-20-hidden-nodes-역전파주석처리-1" id="toc-len-20-hidden-nodes-역전파주석처리-1" class="nav-link" data-scroll-target="#len-20-hidden-nodes-역전파주석처리-1">2000 len + 20 hidden nodes + 역전파주석처리</a></li>
  <li><a href="#len-5000-hidden-nodes" id="toc-len-5000-hidden-nodes" class="nav-link" data-scroll-target="#len-5000-hidden-nodes">2000 len + 5000 hidden nodes</a></li>
  <li><a href="#len-5000-hidden-nodes-역전파주석처리" id="toc-len-5000-hidden-nodes-역전파주석처리" class="nav-link" data-scroll-target="#len-5000-hidden-nodes-역전파주석처리">2000 len + 5000 hidden nodes + 역전파주석처리</a></li>
  <li><a href="#실험결과-요약" id="toc-실험결과-요약" class="nav-link" data-scroll-target="#실험결과-요약">실험결과 요약</a></li>
  </ul></li>
  <li><a href="#exam5-abcabc" id="toc-exam5-abcabc" class="nav-link" data-scroll-target="#exam5-abcabc">Exam5: abcabC</a>
  <ul class="collapse">
  <li><a href="#data-1" id="toc-data-1" class="nav-link" data-scroll-target="#data-1">data</a></li>
  <li><a href="#rnn" id="toc-rnn" class="nav-link" data-scroll-target="#rnn">RNN</a></li>
  <li><a href="#lstm" id="toc-lstm" class="nav-link" data-scroll-target="#lstm">LSTM</a></li>
  <li><a href="#rnn-vs-lstm-성능비교실험" id="toc-rnn-vs-lstm-성능비교실험" class="nav-link" data-scroll-target="#rnn-vs-lstm-성능비교실험">RNN vs LSTM 성능비교실험</a></li>
  </ul></li>
  <li><a href="#exam6-abcdabcd" id="toc-exam6-abcdabcd" class="nav-link" data-scroll-target="#exam6-abcdabcd">Exam6: abcdabcD</a>
  <ul class="collapse">
  <li><a href="#data-2" id="toc-data-2" class="nav-link" data-scroll-target="#data-2">data</a></li>
  <li><a href="#rnn-vs-lstm-성능비교실험-1" id="toc-rnn-vs-lstm-성능비교실험-1" class="nav-link" data-scroll-target="#rnn-vs-lstm-성능비교실험-1">RNN vs LSTM 성능비교실험</a></li>
  </ul></li>
  <li><a href="#lstm의-계산과정" id="toc-lstm의-계산과정" class="nav-link" data-scroll-target="#lstm의-계산과정">LSTM의 계산과정</a>
  <ul class="collapse">
  <li><a href="#data-abab" id="toc-data-abab" class="nav-link" data-scroll-target="#data-abab">data: abaB</a></li>
  <li><a href="#epoch-ver1-with-torch.nn.lstmcell" id="toc-epoch-ver1-with-torch.nn.lstmcell" class="nav-link" data-scroll-target="#epoch-ver1-with-torch.nn.lstmcell">1 epoch ver1 (with torch.nn.LSTMCell)</a></li>
  <li><a href="#epoch-ver2-완전-손으로-구현" id="toc-epoch-ver2-완전-손으로-구현" class="nav-link" data-scroll-target="#epoch-ver2-완전-손으로-구현">1 epoch ver2 (완전 손으로 구현)</a></li>
  <li><a href="#epoch-ver3-with-torch.nn.lstm" id="toc-epoch-ver3-with-torch.nn.lstm" class="nav-link" data-scroll-target="#epoch-ver3-with-torch.nn.lstm">1 epoch ver3 (with torch.nn.LSTM)</a></li>
  </ul></li>
  <li><a href="#lstm은-왜-강한가" id="toc-lstm은-왜-강한가" class="nav-link" data-scroll-target="#lstm은-왜-강한가">LSTM은 왜 강한가?</a>
  <ul class="collapse">
  <li><a href="#data-abab-1" id="toc-data-abab-1" class="nav-link" data-scroll-target="#data-abab-1">data: abaB</a></li>
  <li><a href="#epoch" id="toc-epoch" class="nav-link" data-scroll-target="#epoch">1000 epoch</a></li>
  <li><a href="#시각화" id="toc-시각화" class="nav-link" data-scroll-target="#시각화">시각화</a></li>
  <li><a href="#시각화의-해석i" id="toc-시각화의-해석i" class="nav-link" data-scroll-target="#시각화의-해석i">시각화의 해석I</a></li>
  <li><a href="#시각화의-해석ii" id="toc-시각화의-해석ii" class="nav-link" data-scroll-target="#시각화의-해석ii">시각화의 해석II</a></li>
  <li><a href="#lstm의-알고리즘-리뷰-i-수식위주" id="toc-lstm의-알고리즘-리뷰-i-수식위주" class="nav-link" data-scroll-target="#lstm의-알고리즘-리뷰-i-수식위주">LSTM의 알고리즘 리뷰 I (수식위주)</a></li>
  <li><a href="#lstm의-알고리즘-리뷰-ii-느낌위주" id="toc-lstm의-알고리즘-리뷰-ii-느낌위주" class="nav-link" data-scroll-target="#lstm의-알고리즘-리뷰-ii-느낌위주">LSTM의 알고리즘 리뷰 II (느낌위주)</a></li>
  <li><a href="#lstm이-강한이유" id="toc-lstm이-강한이유" class="nav-link" data-scroll-target="#lstm이-강한이유">LSTM이 강한이유</a></li>
  </ul></li>
  <li><a href="#참고자료들" id="toc-참고자료들" class="nav-link" data-scroll-target="#참고자료들">참고자료들</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="2022-11-21-ml-11w.out.ipynb" download="2022-11-21-ml-11w.out.ipynb"><i class="bi bi-journal-code"></i>Jupyter</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>기계학습 특강 (11주차) 11월16일 [순환신경망– abc예제, abdc예제, abcde예제, AbAcAd예제]</p>
<section id="import" class="level2">
<h2 class="anchored" data-anchor-id="import">import</h2>
<div id="ec063325-2a8b-46a1-b8ec-4d2301c2ce7b" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code></pre></div>
</div>
</section>
<section id="define-some-funtions" class="level2">
<h2 class="anchored" data-anchor-id="define-some-funtions">Define some funtions</h2>
<div id="15025b87-2f4d-4906-b3d4-ea0d5428b3b1" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(txt,mapping):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [mapping[key] <span class="cf">for</span> key <span class="kw">in</span> txt] </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>soft <span class="op">=</span> torch.nn.Softmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>tanh <span class="op">=</span> torch.nn.Tanh()</span></code></pre></div>
</div>
</section>
<section id="exam4-abacad-2" class="level2">
<h2 class="anchored" data-anchor-id="exam4-abacad-2">Exam4: AbAcAd (2)</h2>
<section id="data" class="level3">
<h3 class="anchored" data-anchor-id="data">data</h3>
<p><code>-</code> 기존의 정리방식</p>
<div id="53f35a3d-20c2-4ea3-8aa4-9a82964b8190" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'AbAcAd'</span>)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>txt[:<span class="dv">10</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']</code></pre>
</div>
</div>
<div id="7705fe04-ed96-4c86-b749-06c09abb54a0" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>txt_x <span class="op">=</span> txt[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>txt_y <span class="op">=</span> txt[<span class="dv">1</span>:]</span></code></pre></div>
</div>
<div id="7251bb06-0cd1-400a-a3f7-0f38aef58859" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>txt_x[:<span class="dv">5</span>],txt_y[:<span class="dv">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])</code></pre>
</div>
</div>
<div id="3eb7194c-7f67-4d21-ada6-f01637ad34e3" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_x,{<span class="st">'A'</span>:<span class="dv">0</span>,<span class="st">'b'</span>:<span class="dv">1</span>,<span class="st">'c'</span>:<span class="dv">2</span>,<span class="st">'d'</span>:<span class="dv">3</span>}))).<span class="bu">float</span>()</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_y,{<span class="st">'A'</span>:<span class="dv">0</span>,<span class="st">'b'</span>:<span class="dv">1</span>,<span class="st">'c'</span>:<span class="dv">2</span>,<span class="st">'d'</span>:<span class="dv">3</span>}))).<span class="bu">float</span>()</span></code></pre></div>
</div>
<div id="335c56cd-ff19-449d-a50f-f35f8f8ab830" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>x,y</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>(tensor([[1., 0., 0., 0.],
         [0., 1., 0., 0.],
         [1., 0., 0., 0.],
         ...,
         [1., 0., 0., 0.],
         [0., 0., 1., 0.],
         [1., 0., 0., 0.]]),
 tensor([[0., 1., 0., 0.],
         [1., 0., 0., 0.],
         [0., 0., 1., 0.],
         ...,
         [0., 0., 1., 0.],
         [1., 0., 0., 0.],
         [0., 0., 0., 1.]]))</code></pre>
</div>
</div>
</section>
<section id="순환신경망-구현1-손으로-직접구현-리뷰" class="level3">
<h3 class="anchored" data-anchor-id="순환신경망-구현1-손으로-직접구현-리뷰">순환신경망 구현1 (손으로 직접구현) – 리뷰</h3>
<p><code>(1)</code> 숙성담당 네트워크</p>
<div id="dd870cc2-2d7d-4129-8568-3569f4cf8c41" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> rNNCell(torch.nn.Module):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.i2h <span class="op">=</span> torch.nn.Linear(<span class="dv">4</span>,<span class="dv">2</span>) </span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.h2h <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">2</span>) </span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tanh <span class="op">=</span> torch.nn.Tanh()</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,x,hidden):</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        hidden <span class="op">=</span> <span class="va">self</span>.tanh(<span class="va">self</span>.i2h(x)<span class="op">+</span><span class="va">self</span>.h2h(hidden))</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> hidden</span></code></pre></div>
</div>
<div id="27940560-4a81-427a-a12a-dcd877c5761b" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>rnncell <span class="op">=</span> rNNCell() <span class="co"># 숙성담당 네트워크 </span></span></code></pre></div>
</div>
<p><code>(2)</code> 조리담당 네트워크</p>
<div id="0eb0d231-8f3e-415b-b8be-21699741fa9f" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>cook <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">4</span>) </span></code></pre></div>
</div>
<p><code>(3)</code> 손실함수, 옵티마이저 설계</p>
<div id="0ee8e986-3291-4148-a2e9-7b2a90595aed" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() </span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnncell.parameters())<span class="op">+</span><span class="bu">list</span>(cook.parameters()))</span></code></pre></div>
</div>
<p><code>(4)</code> 학습 (6분정도 걸림)</p>
<div id="81ad4564-5060-43fb-8c95-6c5b3d4c92e1" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>x[[<span class="dv">2</span>]].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>torch.Size([1, 4])</code></pre>
</div>
</div>
<div id="6c6a42f3-1418-44d1-a93c-cefc173e6e30" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="bu">len</span>(x) </span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>): </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1~2</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    ht <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>) </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>        xt,yt <span class="op">=</span> x[[t]], y[[t]]</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        ht <span class="op">=</span> rnncell(xt,ht) </span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>        ot <span class="op">=</span> cook(ht) </span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss <span class="op">+</span> loss_fn(ot,yt) </span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<p><code>(5)</code> 시각화</p>
<div id="0979a565-dc50-4c2c-b62e-76b64f026813" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="bu">len</span>(x) </span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>hidden <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>) <span class="co"># 599년치 h를 담을 변수 </span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>) <span class="co"># 맹물 </span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>hidden[[<span class="dv">0</span>]] <span class="op">=</span> rnncell(x[[<span class="dv">0</span>]],_water) </span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,T):</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    hidden[[t]] <span class="op">=</span> rnncell(x[[t]],hidden[[t<span class="op">-</span><span class="dv">1</span>]]) </span></code></pre></div>
</div>
<div id="4e07845c-2d97-4add-a07c-0a445b70158f" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(cook(hidden))</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>yhat</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>tensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],
        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],
        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],
        ...,
        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],
        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],
        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],
       grad_fn=&lt;SoftmaxBackward0&gt;)</code></pre>
</div>
</div>
<div id="2a691864-38ef-4f09-871a-9fe790c217a9" class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(yhat.data[<span class="op">-</span><span class="dv">15</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="순환신경망-구현2-with-rnncell-hidden-node-2" class="level3">
<h3 class="anchored" data-anchor-id="순환신경망-구현2-with-rnncell-hidden-node-2">순환신경망 구현2 (with RNNCell, hidden node 2)</h3>
<p>ref: <a href="https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html" class="uri">https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html</a></p>
<section id="구현1과-같은-초기값-확인용" class="level4">
<h4 class="anchored" data-anchor-id="구현1과-같은-초기값-확인용">구현1과 같은 초기값 (확인용)</h4>
<p><code>(1)</code> 숙성네트워크</p>
<div id="912e7492-e89b-43e4-af20-10c21734a89a" class="cell" data-execution_count="114">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>_rnncell <span class="op">=</span> rNNCell() <span class="co"># 숙성담당 네트워크 </span></span></code></pre></div>
</div>
<div id="427dc3ff-dabc-4832-8eb7-9efe9eb30b57" class="cell" data-execution_count="115">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>rnncell <span class="op">=</span> torch.nn.RNNCell(<span class="dv">4</span>,<span class="dv">2</span>)</span></code></pre></div>
</div>
<ul>
<li>input_size = 4</li>
<li>hindden_size = 2</li>
</ul>
<p><code>rNNCell()</code> 는 사실 <code>torch.nn.RNNCell()</code>와 같은 동작을 하도록 설계를 하였음.</p>
<p>같은동작을 하는지 확인하기 위해서 동일한 초기상태에서 <code>rNNCell()</code>에 의하여 학습된 결과와 <code>torch.nn.RNNCell()</code>에 의하여 학습된 결과를 비교해보자.</p>
<div id="04a0c43e-97fb-484c-8935-a525c78df496" class="cell" data-execution_count="116">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>rnncell.weight_ih.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="116">
<pre><code>torch.Size([2, 4])</code></pre>
</div>
</div>
<div id="3e47d369-7787-456a-a80f-0bd89847a1e3" class="cell" data-execution_count="117">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>rnncell.bias_ih.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="117">
<pre><code>torch.Size([2])</code></pre>
</div>
</div>
<div id="4ce45c73-6828-49a5-8e9c-37b352059923" class="cell" data-execution_count="118">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>rnncell.weight_hh.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="118">
<pre><code>torch.Size([2, 2])</code></pre>
</div>
</div>
<div id="a0189fcb-fcbd-480a-a5a8-3698949590e8" class="cell" data-execution_count="119">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>rnncell.bias_hh.shape </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="119">
<pre><code>torch.Size([2])</code></pre>
</div>
</div>
<div id="6df5a3a8-d8bb-4972-9abf-9cfbc6dfba8c" class="cell" data-execution_count="120">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>rnncell.weight_ih.data <span class="op">=</span> _rnncell.i2h.weight.data</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>rnncell.bias_ih.data <span class="op">=</span> _rnncell.i2h.bias.data</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>rnncell.weight_hh.data <span class="op">=</span> _rnncell.h2h.weight.data</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>rnncell.bias_hh.data <span class="op">=</span> _rnncell.h2h.bias.data</span></code></pre></div>
</div>
<p>_rnncell 초기값을 rnncell에 넣어주기</p>
<p><code>(2)</code> 조리네트워크</p>
<div id="b7dcb6cd-662e-4849-a7cd-7bf072afc0eb" class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>cook <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">4</span>) <span class="co"># 숙성된 2차원의 단어를 다시 4차원으로 바꿔줘야지 나중에 softmax취할 수 있음</span></span></code></pre></div>
</div>
<p><code>(3)</code> 손실함수와 옵티마이저</p>
<div id="3df2a7ad-3dca-480f-b8eb-267f85550c4a" class="cell" data-execution_count="122">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnncell.parameters())<span class="op">+</span><span class="bu">list</span>(cook.parameters()))</span></code></pre></div>
</div>
<p><code>(4)</code> 학습</p>
<div id="3da3ff3e-cc6d-41ca-b356-09689378fc93" class="cell" data-execution_count="123">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="bu">len</span>(x) </span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>):</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1~2</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    ht <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>) </span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>        xt,yt <span class="op">=</span> x[[t]], y[[t]]</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>        ht <span class="op">=</span> rnncell(xt,ht)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>        ot <span class="op">=</span> cook(ht)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss <span class="op">+</span> loss_fn(ot,yt) </span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<p><code>(5)</code> 시각화</p>
<div id="12b9ec09-0331-42bc-bb01-2fed1935e768" class="cell" data-execution_count="124">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>hidden <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>) </span></code></pre></div>
</div>
<div id="dd76fb29-8944-4916-9225-be9b4680403d" class="cell" data-execution_count="125">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># t=0 </span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>hidden[[<span class="dv">0</span>]] <span class="op">=</span> rnncell(x[[<span class="dv">0</span>]],_water)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="co"># t=1~T </span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,T):</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>    hidden[[t]] <span class="op">=</span> rnncell(x[[t]],hidden[[t<span class="op">-</span><span class="dv">1</span>]])</span></code></pre></div>
</div>
<div id="eefd7307-5710-4475-b6fb-c831e075fc0c" class="cell" data-execution_count="126">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(cook(hidden))</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>yhat</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="126">
<pre><code>tensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],
        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],
        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],
        ...,
        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],
        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],
        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],
       grad_fn=&lt;SoftmaxBackward0&gt;)</code></pre>
</div>
</div>
<div id="db0b8220-8e2f-4fc5-8060-31a3b7deb86c" class="cell" data-execution_count="127">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(yhat[:<span class="dv">15</span>].data,cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-31-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="9ebbdb60-0732-4db1-8dfa-78774b2b267b" class="cell" data-execution_count="128">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(yhat[<span class="op">-</span><span class="dv">15</span>:].data,cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-32-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>뒷부분갈수록 잘 맞음</p>
</section>
<section id="새로운-초기값" class="level4">
<h4 class="anchored" data-anchor-id="새로운-초기값">새로운 초기값</h4>
<p><code>(1)</code> 숙성네트워크</p>
<div id="c374dfe9-c6a9-4d36-94c2-c7dfe3608064" class="cell" data-execution_count="129">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>torch.nn.RNNCell(<span class="dv">4</span>,<span class="dv">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="129">
<pre><code>RNNCell(4, 2)</code></pre>
</div>
</div>
<p>앞 부분은 잘 맞지 않고 뒷부분은 잘 맞을 것!</p>
<p><code>(2)</code> 조리네트워크</p>
<div id="13e0f035-94ad-4410-aa59-56233a3a9af1" class="cell" data-execution_count="130">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>cook <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">4</span>) <span class="co"># 숙성된 2차원의 단어를 다시 4차원으로 바꿔줘야지 나중에 softmax취할 수 있음</span></span></code></pre></div>
</div>
<p><code>(3)</code> 손실함수와 옵티마이저</p>
<div id="f76fc9c2-e220-4a39-9664-3e3b206d13ad" class="cell" data-execution_count="131">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnncell.parameters())<span class="op">+</span><span class="bu">list</span>(cook.parameters()))</span></code></pre></div>
</div>
<p><code>(4)</code> 학습</p>
<div id="1636446c-840f-4bc2-8b32-1ba985c7f2b3" class="cell" data-execution_count="132">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="bu">len</span>(x) </span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>):</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1~2</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>    ht <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>) </span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>        xt,yt <span class="op">=</span> x[[t]], y[[t]]</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>        ht <span class="op">=</span> rnncell(xt,ht)</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>        ot <span class="op">=</span> cook(ht)</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss <span class="op">+</span> loss_fn(ot,yt) </span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<p><code>(5)</code> 시각화</p>
<p>x -&gt; h -&gt; o -&gt; yhat(softmax(o))</p>
<p>네트워크만 학습된 상태, 따라서 hiddenlayer를 재구성해줘야 한다.</p>
</section>
</section>
<section id="순환신경망-구현3-with-rnn-hidden-node-2-성공" class="level3">
<h3 class="anchored" data-anchor-id="순환신경망-구현3-with-rnn-hidden-node-2-성공">순환신경망 구현3 (with RNN, hidden node 2) – 성공</h3>
<p>(예비학습)</p>
<p><code>-</code> 네트워크학습이후 yhat을 구하려면 번거로웠음</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>hidden <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>) </span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>hidden[[<span class="dv">0</span>]] <span class="op">=</span> rnncell(x[[<span class="dv">0</span>]],_water)</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,T):</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>    hidden[[t]] <span class="op">=</span> rnncell(x[[t]],hidden[[t<span class="op">-</span><span class="dv">1</span>]])</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(cook(hidden))</span></code></pre></div>
<p><code>-</code> 이렇게 하면 쉽게(?) 구할 수 있음</p>
<div id="77f04ace-59b1-4b5b-9773-9929d51bd59c" class="cell" data-execution_count="133">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">2</span>)</span></code></pre></div>
</div>
<div id="73ecf1be-4a22-41ee-a747-1956475ee53c" class="cell" data-execution_count="134">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>rnn.weight_hh_l0.data <span class="op">=</span> rnncell.weight_hh.data </span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>rnn.weight_ih_l0.data <span class="op">=</span> rnncell.weight_ih.data</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>rnn.bias_hh_l0.data <span class="op">=</span> rnncell.bias_hh.data</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>rnn.bias_ih_l0.data <span class="op">=</span> rnncell.bias_ih.data</span></code></pre></div>
</div>
<p><code>-</code> rnn(x,_water)의 결과는 (1) 599년치 간장 (2) 599번째 간장 이다</p>
<div id="e53dc2c8-0e1e-4cb9-b5c9-e645540e86bc" class="cell" data-execution_count="135">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>rnn(x,_water), hidden</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="135">
<pre><code>((tensor([[-0.1271,  0.9965],
          [-1.0000, -0.9987],
          [ 0.9962,  1.0000],
          ...,
          [ 0.9962,  1.0000],
          [-1.0000, -0.9897],
          [ 0.9959,  1.0000]], grad_fn=&lt;SqueezeBackward1&gt;),
  tensor([[0.9959, 1.0000]], grad_fn=&lt;SqueezeBackward1&gt;)),
 tensor([[-0.2232,  0.9769],
         [-0.9999, -0.9742],
         [ 0.9154,  0.9992],
         ...,
         [ 0.9200,  0.9992],
         [-0.9978, -0.0823],
         [-0.9154,  0.9965]], grad_fn=&lt;IndexPutBackward0&gt;))</code></pre>
</div>
</div>
<div id="6f50b73a-35d8-4a7c-a07e-574574b40c42" class="cell" data-execution_count="136">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>soft(cook(rnn(x,_water)[<span class="dv">0</span>]))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="136">
<pre><code>tensor([[6.0688e-02, 4.2958e-01, 2.9885e-01, 2.1088e-01],
        [9.9700e-01, 8.2096e-04, 1.3663e-03, 8.1039e-04],
        [2.2782e-03, 3.3203e-01, 3.3260e-01, 3.3309e-01],
        ...,
        [2.2779e-03, 3.3203e-01, 3.3260e-01, 3.3309e-01],
        [9.9692e-01, 8.4633e-04, 1.4012e-03, 8.3072e-04],
        [2.2803e-03, 3.3206e-01, 3.3260e-01, 3.3306e-01]],
       grad_fn=&lt;SoftmaxBackward0&gt;)</code></pre>
</div>
</div>
<p><strong><em>(예비학습결론) torch.nn.RNN(4,2)는 torch.nn.RNNCell(4,2)의 batch 버전이다. (for문이 포함된 버전이다)</em></strong></p>
<hr>
<p>torch.nn.RNN(4,2)를 이용하여 구현하자.</p>
<p><code>(1)</code> 숙성네트워크</p>
<p>선언</p>
<div id="5a4b35c7-12cb-4d8f-8583-76f2bf260b0a" class="cell" data-execution_count="137">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">2</span>)</span></code></pre></div>
</div>
<p>가중치초기화</p>
<div id="b31d7b41-6794-48df-b74c-a539a458bf35" class="cell" data-execution_count="138">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>_rnncell <span class="op">=</span> torch.nn.RNNCell(<span class="dv">4</span>,<span class="dv">2</span>)</span></code></pre></div>
</div>
<div id="1e1c6f16-9ac5-4e6d-9f3d-26868968d886" class="cell" data-execution_count="139">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>rnn.weight_hh_l0.data <span class="op">=</span> _rnncell.weight_hh.data </span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>rnn.weight_ih_l0.data <span class="op">=</span> _rnncell.weight_ih.data</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>rnn.bias_hh_l0.data <span class="op">=</span> _rnncell.bias_hh.data</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>rnn.bias_ih_l0.data <span class="op">=</span> _rnncell.bias_ih.data</span></code></pre></div>
</div>
<p><code>(2)</code> 조리네트워크</p>
<div id="c7458907-7b80-4981-871d-d477fe9daeaf" class="cell" data-execution_count="140">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>cook <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">4</span>) </span></code></pre></div>
</div>
<p><code>(3)</code> 손실함수와 옵티마이저</p>
<div id="4d56f314-a8cd-4c85-8f7c-ba0081aefb42" class="cell" data-execution_count="141">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(cook.parameters()))</span></code></pre></div>
</div>
<p><code>(4)</code> 학습</p>
<div id="193b2256-2898-4f7a-8bd7-30c6f36adcf2" class="cell" data-execution_count="142">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>) </span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>):</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>    hidden,hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> cook(hidden) </span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y)</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<p>결과는 같을 것</p>
<p><code>(5)</code> 시각화1: yhat</p>
<div id="2d3ba732-9f22-40cd-960b-5ee7256d4e1f" class="cell" data-execution_count="143">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span></code></pre></div>
</div>
<div id="b80f712d-3921-4095-8d4e-008f94c6847b" class="cell" data-execution_count="144">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(yhat.data[:<span class="dv">15</span>],cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-48-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>처음은 좀 틀렸음 ㅎㅎ</li>
</ul>
<div id="a28eb333-7d11-49ba-97d0-864b518067b2" class="cell" data-execution_count="145">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(yhat.data[<span class="op">-</span><span class="dv">15</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-49-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>뒤에는 잘맞음</li>
</ul>
<p><strong>실전팁: <code>_water</code> 대신에 <code>hT</code>를 대입 (사실 큰 차이는 없음)</strong></p>
<p>hT는 이미 값이 저장되어 있잖아</p>
<div id="877bf41c-1797-477b-b695-c9382529948a" class="cell" data-execution_count="146">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>rnn(x[:<span class="dv">6</span>],_water),rnn(x[:<span class="dv">6</span>],hT)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="146">
<pre><code>((tensor([[-0.9912, -0.9117],
          [ 0.0698, -1.0000],
          [-0.9927, -0.9682],
          [ 0.5761, -1.0000],
          [-0.9960, -0.0173],
          [ 0.9960, -1.0000]], grad_fn=&lt;SqueezeBackward1&gt;),
  tensor([[ 0.9960, -1.0000]], grad_fn=&lt;SqueezeBackward1&gt;)),
 (tensor([[-0.9713, -1.0000],
          [ 0.0535, -1.0000],
          [-0.9925, -0.9720],
          [ 0.5759, -1.0000],
          [-0.9960, -0.0180],
          [ 0.9960, -1.0000]], grad_fn=&lt;SqueezeBackward1&gt;),
  tensor([[ 0.9960, -1.0000]], grad_fn=&lt;SqueezeBackward1&gt;)))</code></pre>
</div>
</div>
<p><code>(6)</code> 시각화2: hidden, yhat</p>
<div id="69e24656-dbf6-4b54-adb8-de36b9bb21e7" class="cell" data-execution_count="147">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>combinded <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div id="5fac9052-170e-45be-9321-e09607543146" class="cell" data-execution_count="148">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">15</span>:].data,cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-52-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>히든노드의 해석이 어려움.</li>
</ul>
<p>hidden layer-&gt;layer 더 있음 좋겠다</p>
</section>
<section id="순환신경망-구현4-with-rnn-hidden-node-3-성공" class="level3">
<h3 class="anchored" data-anchor-id="순환신경망-구현4-with-rnn-hidden-node-3-성공">순환신경망 구현4 (with RNN, hidden node 3) – 성공</h3>
<p><code>(1)</code> 숙성네트워크~ <code>(2)</code> 조리네트워크</p>
<div id="6cae8682-9dd8-4e4b-82a0-b76d4e3b694b" class="cell" data-execution_count="149">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">2</span>) <span class="co">#1 </span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">3</span>) </span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>cook <span class="op">=</span> torch.nn.Linear(<span class="dv">3</span>,<span class="dv">4</span>) </span></code></pre></div>
</div>
<p><code>(3)</code> 손실함수와 옵티마이저</p>
<div id="f5768d12-3489-45f7-9c3f-ae0acf462e25" class="cell" data-execution_count="150">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(cook.parameters()))</span></code></pre></div>
</div>
<p><code>(4)</code> 학습</p>
<div id="da35acd3-8e40-41c3-8f74-0dcc53f053c5" class="cell" data-execution_count="151">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>) </span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>):</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1</span></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>    hidden,hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> cook(hidden) </span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<p><code>(5)</code> 시각화1: yhat</p>
<div id="835fc173-ad58-4b46-beac-d7470e29e885" class="cell" data-execution_count="152">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span></code></pre></div>
</div>
<div id="db46c3fe-5442-414a-96e9-3a0a6520ab38" class="cell" data-execution_count="153">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(yhat[<span class="op">-</span><span class="dv">15</span>:].data,cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-57-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><code>(6)</code> 시각화2: hidden, yhat</p>
<div id="77c59be7-3afb-4a58-93a9-d78d17f42ce9" class="cell" data-execution_count="154">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>combinded <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div id="2f2d7c58-70ee-4249-93f2-195a2d51d9f7" class="cell" data-execution_count="155">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">15</span>:].data,cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-59-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>세번째 히든노드 = 대소문자(a/A)를 구분</li>
<li>1,2 히든노드 = bcd를 구분</li>
</ul>
</section>
</section>
<section id="gpu-실험" class="level2">
<h2 class="anchored" data-anchor-id="gpu-실험">GPU 실험</h2>
<section id="len-20-hidden-nodes" class="level3">
<h3 class="anchored" data-anchor-id="len-20-hidden-nodes">20000 len + 20 hidden nodes</h3>
<p><strong><em>cpu</em></strong></p>
<div id="fadf44a4-a5ee-4374-a93a-615d21f90df7" class="cell" data-execution_count="164">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span></code></pre></div>
</div>
<div id="c2edfd2f-4228-4594-9880-b3dad45aacb0" class="cell" data-execution_count="161">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">20000</span>,<span class="dv">4</span>]) </span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">20000</span>,<span class="dv">4</span>]) </span></code></pre></div>
</div>
<div id="4e889187-0496-4142-a1d6-16327113fe53" class="cell" data-execution_count="162">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">20</span>) </span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">4</span>) </span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div id="311918e5-1ddc-4837-b73c-f817ae9fe6b4" class="cell" data-execution_count="165">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>)</span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb77-10"><a href="#cb77-10" aria-hidden="true" tabindex="-1"></a>    loss.backward() </span>
<span id="cb77-11"><a href="#cb77-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb77-12"><a href="#cb77-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb77-13"><a href="#cb77-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb77-14"><a href="#cb77-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb77-15"><a href="#cb77-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="165">
<pre><code>228.14399337768555</code></pre>
</div>
</div>
<p>왕 느려</p>
<p><strong><em>gpu</em></strong></p>
<div id="9e751aaf-fe3f-4cf0-8c20-dca68c32bc62" class="cell" data-execution_count="166">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">20000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">20000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div id="b814897c-f144-4781-b14a-0ef3d6a27278" class="cell" data-execution_count="167">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div id="e76c8e27-6c5d-41b7-a668-fe8bd4a69f7f" class="cell" data-execution_count="168">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb81-10"><a href="#cb81-10" aria-hidden="true" tabindex="-1"></a>    loss.backward() </span>
<span id="cb81-11"><a href="#cb81-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb81-12"><a href="#cb81-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb81-13"><a href="#cb81-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb81-14"><a href="#cb81-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb81-15"><a href="#cb81-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="168">
<pre><code>6.0587098598480225</code></pre>
</div>
</div>
<ul>
<li>왜 빠른지?</li>
</ul>
</section>
<section id="len-20-hidden-nodes-역전파주석처리" class="level3">
<h3 class="anchored" data-anchor-id="len-20-hidden-nodes-역전파주석처리">20000 len + 20 hidden nodes + 역전파주석처리</h3>
<p><strong><em>cpu</em></strong></p>
<div id="de0fb966-afd2-484e-b5e2-f24314fda6e4" class="cell" data-execution_count="169">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">20000</span>,<span class="dv">4</span>]) </span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">20000</span>,<span class="dv">4</span>]) </span></code></pre></div>
</div>
<div id="2bbfcdbe-c0e2-4436-9499-9d9b0634850a" class="cell" data-execution_count="170">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">20</span>) </span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">4</span>) </span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div id="8b321c6a-6e25-48b6-b4ae-8caca0b345c6" class="cell" data-execution_count="171">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>)</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#loss.backward() </span></span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb85-13"><a href="#cb85-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb85-14"><a href="#cb85-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb85-15"><a href="#cb85-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="171">
<pre><code>28.451032400131226</code></pre>
</div>
</div>
<p>loss 미분할 때 시간 많이 잡음ㅁ</p>
<p><strong><em>gpu</em></strong></p>
<div id="147541e7-f167-4fd7-af97-5e1aa0cd8f1b" class="cell" data-execution_count="172">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">20000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">20000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div id="5c762990-9114-496b-9508-9fbbf9af4ba9" class="cell" data-execution_count="173">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div id="dd5dedb2-6a93-4158-9123-13f7593eab99" class="cell" data-execution_count="174">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#loss.backward() </span></span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb89-12"><a href="#cb89-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb89-13"><a href="#cb89-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb89-14"><a href="#cb89-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb89-15"><a href="#cb89-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="174">
<pre><code>1.6839873790740967</code></pre>
</div>
</div>
</section>
<section id="len-20-hidden-nodes-1" class="level3">
<h3 class="anchored" data-anchor-id="len-20-hidden-nodes-1">2000 len + 20 hidden nodes</h3>
<p><strong><em>cpu</em></strong></p>
<div id="2d407adf-742d-4e3d-9173-cf1632d88284" class="cell" data-execution_count="175">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]) </span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]) </span></code></pre></div>
</div>
<div id="7443b00a-aa9d-450e-bedc-112615b20bcf" class="cell" data-execution_count="176">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">20</span>) </span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">4</span>) </span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div id="19c4d305-8ee8-4ab9-9d0d-c11b55871b8b" class="cell" data-execution_count="177">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>)</span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a>    loss.backward() </span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb93-12"><a href="#cb93-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb93-13"><a href="#cb93-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb93-14"><a href="#cb93-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb93-15"><a href="#cb93-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="177">
<pre><code>10.069071292877197</code></pre>
</div>
</div>
<p><strong><em>gpu</em></strong></p>
<div id="1d6e1191-4e46-49ea-be00-9b2a94597b46" class="cell" data-execution_count="178">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div id="e14f4b6e-ca6a-4acc-b9e0-deb8dae73fca" class="cell" data-execution_count="179">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div id="e6241bba-ff10-46d8-878c-1f36b72e1efa" class="cell" data-execution_count="180">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb97-6"><a href="#cb97-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb97-7"><a href="#cb97-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb97-8"><a href="#cb97-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb97-9"><a href="#cb97-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb97-10"><a href="#cb97-10" aria-hidden="true" tabindex="-1"></a>    loss.backward() </span>
<span id="cb97-11"><a href="#cb97-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb97-12"><a href="#cb97-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb97-13"><a href="#cb97-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb97-14"><a href="#cb97-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb97-15"><a href="#cb97-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="180">
<pre><code>1.7792012691497803</code></pre>
</div>
</div>
</section>
<section id="len-20-hidden-nodes-역전파주석처리-1" class="level3">
<h3 class="anchored" data-anchor-id="len-20-hidden-nodes-역전파주석처리-1">2000 len + 20 hidden nodes + 역전파주석처리</h3>
<p><strong><em>cpu</em></strong></p>
<div id="3525c566-0ad7-4b43-b8ce-e851e529ae06" class="cell" data-execution_count="181">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]) </span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]) </span></code></pre></div>
</div>
<div id="47da22d8-e369-4d5f-9680-74ad76734f76" class="cell" data-execution_count="182">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">20</span>) </span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">4</span>) </span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div id="774d1d8d-1a3d-49ea-9b8a-49ea026c1a30" class="cell" data-execution_count="183">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>)</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb101-8"><a href="#cb101-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb101-9"><a href="#cb101-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb101-10"><a href="#cb101-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#loss.backward() </span></span>
<span id="cb101-11"><a href="#cb101-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb101-12"><a href="#cb101-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb101-13"><a href="#cb101-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb101-14"><a href="#cb101-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb101-15"><a href="#cb101-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="183">
<pre><code>2.7720658779144287</code></pre>
</div>
</div>
<p><strong><em>gpu</em></strong></p>
<div id="22bdbd8a-b434-493a-a98d-6b2af96a8bc6" class="cell" data-execution_count="184">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div id="a6d6daa9-3c71-4179-b9c1-4420fc2de7c1" class="cell" data-execution_count="185">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">20</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div id="edb9dc49-ba63-4bc0-aad5-19a6cde24784" class="cell" data-execution_count="186">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">20</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb105-9"><a href="#cb105-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb105-10"><a href="#cb105-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#loss.backward() </span></span>
<span id="cb105-11"><a href="#cb105-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb105-12"><a href="#cb105-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb105-13"><a href="#cb105-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb105-14"><a href="#cb105-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb105-15"><a href="#cb105-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="186">
<pre><code>0.2116107940673828</code></pre>
</div>
</div>
</section>
<section id="len-5000-hidden-nodes" class="level3">
<h3 class="anchored" data-anchor-id="len-5000-hidden-nodes">2000 len + 5000 hidden nodes</h3>
<p><strong><em>cpu</em></strong></p>
<div id="c994fa99-73c5-4f2e-a4d1-8a9a0a73bc2d" class="cell" data-execution_count="187">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]) </span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]) </span></code></pre></div>
</div>
<div id="1aac74c9-624b-4287-8492-62ca4f943740" class="cell" data-execution_count="188">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">1000</span>) </span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">1000</span>,<span class="dv">4</span>) </span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div id="ecf8ef0b-7aae-4e5b-bc39-3a2b5368b802" class="cell" data-execution_count="189">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">1000</span>)</span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb109-7"><a href="#cb109-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb109-8"><a href="#cb109-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb109-9"><a href="#cb109-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb109-10"><a href="#cb109-10" aria-hidden="true" tabindex="-1"></a>    loss.backward() </span>
<span id="cb109-11"><a href="#cb109-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb109-12"><a href="#cb109-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb109-13"><a href="#cb109-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb109-14"><a href="#cb109-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb109-15"><a href="#cb109-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="189">
<pre><code>34.20541262626648</code></pre>
</div>
</div>
<p><strong><em>gpu</em></strong></p>
<div id="b7f66f68-7dfc-422b-8051-a565a697a78e" class="cell" data-execution_count="190">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div id="a06d413a-9dac-4cb9-abdd-6e8a1f3880b5" class="cell" data-execution_count="191">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">1000</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">1000</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div id="1ef5cc24-a4a5-496a-857b-5dfe1907aa78" class="cell" data-execution_count="192">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">1000</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb113-5"><a href="#cb113-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb113-6"><a href="#cb113-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb113-7"><a href="#cb113-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb113-8"><a href="#cb113-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb113-9"><a href="#cb113-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb113-10"><a href="#cb113-10" aria-hidden="true" tabindex="-1"></a>    loss.backward() </span>
<span id="cb113-11"><a href="#cb113-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb113-12"><a href="#cb113-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb113-13"><a href="#cb113-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb113-14"><a href="#cb113-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb113-15"><a href="#cb113-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="192">
<pre><code>4.586683511734009</code></pre>
</div>
</div>
</section>
<section id="len-5000-hidden-nodes-역전파주석처리" class="level3">
<h3 class="anchored" data-anchor-id="len-5000-hidden-nodes-역전파주석처리">2000 len + 5000 hidden nodes + 역전파주석처리</h3>
<p><strong><em>cpu</em></strong></p>
<div id="e40ca082-3d35-40a9-9bbb-6c03630b2825" class="cell" data-execution_count="193">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]) </span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]) </span></code></pre></div>
</div>
<div id="01165127-d221-4455-a297-0123b406cf39" class="cell" data-execution_count="194">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">1000</span>) </span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">1000</span>,<span class="dv">4</span>) </span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div id="ef68ecb1-8802-46dc-b5dd-c82407af2ec3" class="cell" data-execution_count="195">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">1000</span>)</span>
<span id="cb117-5"><a href="#cb117-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb117-6"><a href="#cb117-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb117-7"><a href="#cb117-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb117-8"><a href="#cb117-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb117-9"><a href="#cb117-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb117-10"><a href="#cb117-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#loss.backward() </span></span>
<span id="cb117-11"><a href="#cb117-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb117-12"><a href="#cb117-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb117-13"><a href="#cb117-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb117-14"><a href="#cb117-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb117-15"><a href="#cb117-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="195">
<pre><code>8.695780992507935</code></pre>
</div>
</div>
<p><strong><em>gpu</em></strong></p>
<div id="f3b98eb0-d3da-4e26-8b21-a1af3280c9c9" class="cell" data-execution_count="196">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.randn([<span class="dv">2000</span>,<span class="dv">4</span>]).to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
<div id="12ac0d6a-7ab5-43d9-b11b-3f4088385fbe" class="cell" data-execution_count="197">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">1000</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">1000</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()))</span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span></code></pre></div>
</div>
<div id="e3885504-99fc-47af-9f62-68d9f41295f1" class="cell" data-execution_count="198">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> time.time()</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">1000</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water) </span>
<span id="cb121-6"><a href="#cb121-6" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> linr(hidden) </span>
<span id="cb121-7"><a href="#cb121-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb121-8"><a href="#cb121-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y) </span>
<span id="cb121-9"><a href="#cb121-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3</span></span>
<span id="cb121-10"><a href="#cb121-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#loss.backward() </span></span>
<span id="cb121-11"><a href="#cb121-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb121-12"><a href="#cb121-12" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb121-13"><a href="#cb121-13" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span>
<span id="cb121-14"><a href="#cb121-14" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> time.time()</span>
<span id="cb121-15"><a href="#cb121-15" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">-</span> t1 </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="198">
<pre><code>2.3646719455718994</code></pre>
</div>
</div>
</section>
<section id="실험결과-요약" class="level3">
<h3 class="anchored" data-anchor-id="실험결과-요약">실험결과 요약</h3>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">len</th>
<th style="text-align: center;"># of hidden nodes</th>
<th style="text-align: center;">backward</th>
<th style="text-align: center;">cpu</th>
<th style="text-align: center;">gpu</th>
<th style="text-align: center;">ratio</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">20000</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">O</td>
<td style="text-align: center;">93.02</td>
<td style="text-align: center;">3.26</td>
<td style="text-align: center;">28.53</td>
</tr>
<tr class="even">
<td style="text-align: center;">20000</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">X</td>
<td style="text-align: center;">18.85</td>
<td style="text-align: center;">1.29</td>
<td style="text-align: center;">14.61</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2000</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">O</td>
<td style="text-align: center;">6.53</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">8.70</td>
</tr>
<tr class="even">
<td style="text-align: center;">2000</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">X</td>
<td style="text-align: center;">1.25</td>
<td style="text-align: center;">0.14</td>
<td style="text-align: center;">8.93</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2000</td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">O</td>
<td style="text-align: center;">58.99</td>
<td style="text-align: center;">4.75</td>
<td style="text-align: center;">12.41</td>
</tr>
<tr class="even">
<td style="text-align: center;">2000</td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">X</td>
<td style="text-align: center;">13.16</td>
<td style="text-align: center;">2.29</td>
<td style="text-align: center;">5.74</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="exam5-abcabc" class="level2">
<h2 class="anchored" data-anchor-id="exam5-abcabc">Exam5: abcabC</h2>
<section id="data-1" class="level3">
<h3 class="anchored" data-anchor-id="data-1">data</h3>
<div id="6a480dbf-ebb1-4d52-aa20-e2890b8567d5" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'abcabC'</span>)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a>txt[:<span class="dv">8</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>['a', 'b', 'c', 'a', 'b', 'C', 'a', 'b']</code></pre>
</div>
</div>
<div id="6ae31cde-c409-4428-8fae-1c280617e84c" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>txt_x <span class="op">=</span> txt[:<span class="op">-</span><span class="dv">1</span>] </span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>txt_y <span class="op">=</span> txt[<span class="dv">1</span>:]</span></code></pre></div>
</div>
<div id="96a4fc28-0579-4851-823f-a44a0e4809e8" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>mapping <span class="op">=</span> {<span class="st">'a'</span>:<span class="dv">0</span>,<span class="st">'b'</span>:<span class="dv">1</span>,<span class="st">'c'</span>:<span class="dv">2</span>,<span class="st">'C'</span>:<span class="dv">3</span>} </span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).<span class="bu">float</span>()</span>
<span id="cb126-3"><a href="#cb126-3" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).<span class="bu">float</span>()</span></code></pre></div>
</div>
<div id="1bcf35b4-346b-4b82-b066-736286443324" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.to(<span class="st">"cuda:0"</span>)</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y.to(<span class="st">"cuda:0"</span>) </span></code></pre></div>
</div>
<div id="7b1123b7-dc13-48f5-a85d-67fa27da8eb5" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>x.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>torch.Size([599, 4])</code></pre>
</div>
</div>
</section>
<section id="rnn" class="level3">
<h3 class="anchored" data-anchor-id="rnn">RNN</h3>
<ul>
<li>bc</li>
<li>bC</li>
<li>b의 수준이 2개</li>
<li>abc</li>
<li>amC</li>
<li>문맥 고려해서 <span class="math inline">\(\to\)</span> hiddenlayer = 3</li>
</ul>
<div id="cec0314b-6a56-408c-b11f-88ef07dfb831" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a>rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">3</span>) </span>
<span id="cb130-3"><a href="#cb130-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">3</span>,<span class="dv">4</span>) </span>
<span id="cb130-4"><a href="#cb130-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb130-5"><a href="#cb130-5" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span> <span class="bu">list</span>(linr.parameters()))</span></code></pre></div>
</div>
<div id="5059f17e-e717-4c86-bb0c-6b53f1fc538d" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>rnn.to(<span class="st">"cuda:0"</span>) </span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a>linr.to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>Linear(in_features=3, out_features=4, bias=True)</code></pre>
</div>
</div>
<p><code>-</code> 3000 epochs</p>
<div id="3d9bb188-5ab6-42e9-a5e2-f87fa485d054" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb133-4"><a href="#cb133-4" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb133-5"><a href="#cb133-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb133-6"><a href="#cb133-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb133-7"><a href="#cb133-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb133-8"><a href="#cb133-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb133-9"><a href="#cb133-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb133-10"><a href="#cb133-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb133-11"><a href="#cb133-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb133-12"><a href="#cb133-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div id="4ef1f6c0-05f6-4af0-bbd0-f4d9ba637e59" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>combinded  <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>).data.to(<span class="st">"cpu"</span>)</span></code></pre></div>
</div>
<ul>
<li>어차피 시각화하려면 cpu에 있어야해</li>
<li>나중 기억!</li>
</ul>
<div id="6cb508f4-1e36-4300-b96e-bbfa06f80486" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-106-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><code>-</code> 6000 epochs</p>
<ul>
<li>3: a일 확률</li>
<li>4: b일 확률</li>
<li>5: c일 확률</li>
<li>6: C일 확률</li>
</ul>
<div id="1cbb8179-7b22-40c9-8f09-d6aafc82cbe3" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb136-5"><a href="#cb136-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb136-6"><a href="#cb136-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb136-7"><a href="#cb136-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb136-8"><a href="#cb136-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb136-9"><a href="#cb136-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb136-10"><a href="#cb136-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb136-11"><a href="#cb136-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb136-12"><a href="#cb136-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div id="4fe809a4-5d4c-4eb5-a570-acae816596aa" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>combinded  <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>).data.to(<span class="st">"cpu"</span>)</span></code></pre></div>
</div>
<div id="2c128df9-9ee9-4c0e-85e4-6492a8fa7a82" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-109-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><code>-</code> 9000 epochs</p>
<div id="a7d78b0b-a199-42c5-a9a6-320f2e72efb2" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb139-4"><a href="#cb139-4" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb139-5"><a href="#cb139-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb139-6"><a href="#cb139-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb139-7"><a href="#cb139-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb139-8"><a href="#cb139-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb139-9"><a href="#cb139-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb139-10"><a href="#cb139-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb139-11"><a href="#cb139-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb139-12"><a href="#cb139-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div id="8d02fa77-21b9-4f57-8b72-a3080e3fe0ff" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>combinded  <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>).data.to(<span class="st">"cpu"</span>)</span></code></pre></div>
</div>
<div id="82a11798-fa16-4ee6-93a3-41937ac5b089" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-112-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><code>-</code> 12000 epochs</p>
<div id="ffd832b0-0bcb-45c2-95b6-2603a1ffa63c" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb142-5"><a href="#cb142-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb142-6"><a href="#cb142-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb142-7"><a href="#cb142-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb142-8"><a href="#cb142-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb142-9"><a href="#cb142-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb142-10"><a href="#cb142-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb142-11"><a href="#cb142-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb142-12"><a href="#cb142-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div id="0ed46f48-1c2d-43fb-9590-b34866a7a635" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a>combinded  <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>).data.to(<span class="st">"cpu"</span>)</span></code></pre></div>
</div>
<div id="7a806190-325d-4acd-9501-1ef36df9fc5b" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-115-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><code>-</code> 15000 epochs</p>
<div id="f7d84ebb-8a0e-45d6-b0f1-3a74902cc441" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb145-2"><a href="#cb145-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb145-3"><a href="#cb145-3" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb145-4"><a href="#cb145-4" aria-hidden="true" tabindex="-1"></a>    hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb145-5"><a href="#cb145-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb145-6"><a href="#cb145-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb145-7"><a href="#cb145-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb145-8"><a href="#cb145-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb145-9"><a href="#cb145-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb145-10"><a href="#cb145-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb145-11"><a href="#cb145-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb145-12"><a href="#cb145-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div id="3089374c-5aa3-42d4-b7eb-2c846a90bc8f" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a>combinded  <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>).data.to(<span class="st">"cpu"</span>)</span></code></pre></div>
</div>
<div id="80862486-8405-49ba-9f5d-c85aa8ba8eaa" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">12</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-118-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>15,000번 정도 하니 c와 C를 구분하는 모습</li>
<li>hidden layer(0,1,2)의 색 순서에 따라 문맥상 다른 것을 알 수 있고 학습도 되는 모습을 볼 수 있다.</li>
</ul>
</section>
<section id="lstm" class="level3">
<h3 class="anchored" data-anchor-id="lstm">LSTM</h3>
<p><code>-</code> LSTM</p>
<div id="f8eab5d8-310e-46b5-84f1-0ce6ab9c6ea7" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">4</span>,<span class="dv">3</span>) </span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">3</span>,<span class="dv">4</span>) </span>
<span id="cb148-4"><a href="#cb148-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb148-5"><a href="#cb148-5" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters())<span class="op">+</span> <span class="bu">list</span>(linr.parameters()))</span></code></pre></div>
</div>
<div id="62a30416-d6bd-4a2c-9ae5-ecc094e17a2c" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>lstm.to(<span class="st">"cuda:0"</span>) </span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a>linr.to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>Linear(in_features=3, out_features=4, bias=True)</code></pre>
</div>
</div>
<p><code>-</code> 3000 epochs</p>
<div id="96599c52-6c3a-4b2e-9bf4-b37049cdab9b" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb151-3"><a href="#cb151-3" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb151-4"><a href="#cb151-4" aria-hidden="true" tabindex="-1"></a>    hidden, (hT,cT) <span class="op">=</span> lstm(x,(_water,_water))</span>
<span id="cb151-5"><a href="#cb151-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb151-6"><a href="#cb151-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb151-7"><a href="#cb151-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb151-8"><a href="#cb151-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb151-9"><a href="#cb151-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb151-10"><a href="#cb151-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb151-11"><a href="#cb151-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb151-12"><a href="#cb151-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div id="aa80ace3-11aa-40aa-871e-ede03f087731" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a>combinded  <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>).data.to(<span class="st">"cpu"</span>)</span></code></pre></div>
</div>
<div id="fa207fdf-91fe-45a1-a550-1eef16af10c2" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-123-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>하얀부분이 0 파란 부분이 -1 빨간 부분이 +1</li>
</ul>
<p><code>-</code> 6000 epochs</p>
<div id="0d42d3bd-f5bb-4ac5-bf7d-7559252b9e93" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1 </span></span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a>    _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb154-4"><a href="#cb154-4" aria-hidden="true" tabindex="-1"></a>    hidden, (hT,cT) <span class="op">=</span> lstm(x,(_water,_water))</span>
<span id="cb154-5"><a href="#cb154-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden) </span>
<span id="cb154-6"><a href="#cb154-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2 </span></span>
<span id="cb154-7"><a href="#cb154-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb154-8"><a href="#cb154-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb154-9"><a href="#cb154-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb154-10"><a href="#cb154-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb154-11"><a href="#cb154-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb154-12"><a href="#cb154-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<div id="aed4b075-afad-4b28-8512-a62a0f6805a1" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> soft(output)</span>
<span id="cb155-2"><a href="#cb155-2" aria-hidden="true" tabindex="-1"></a>combinded  <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>).data.to(<span class="st">"cpu"</span>)</span></code></pre></div>
</div>
<div id="2ab9dd13-19b6-407d-8552-27fdce5f9504" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-126-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>rnn에 비해 lstm은 조금 돌려도 어느정도 비교 잘 해낸다</li>
</ul>
</section>
<section id="rnn-vs-lstm-성능비교실험" class="level3">
<h3 class="anchored" data-anchor-id="rnn-vs-lstm-성능비교실험">RNN vs LSTM 성능비교실험</h3>
<p><code>-</code> RNN</p>
<div id="741ff270-be56-400d-b5e4-83aa6282acd9" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb157-3"><a href="#cb157-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb157-4"><a href="#cb157-4" aria-hidden="true" tabindex="-1"></a>        rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">4</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb157-5"><a href="#cb157-5" aria-hidden="true" tabindex="-1"></a>        linr <span class="op">=</span> torch.nn.Linear(<span class="dv">3</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb157-6"><a href="#cb157-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb157-7"><a href="#cb157-7" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb157-8"><a href="#cb157-8" aria-hidden="true" tabindex="-1"></a>        _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb157-9"><a href="#cb157-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb157-10"><a href="#cb157-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1</span></span>
<span id="cb157-11"><a href="#cb157-11" aria-hidden="true" tabindex="-1"></a>            hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb157-12"><a href="#cb157-12" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> linr(hidden)</span>
<span id="cb157-13"><a href="#cb157-13" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2</span></span>
<span id="cb157-14"><a href="#cb157-14" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(output,y)</span>
<span id="cb157-15"><a href="#cb157-15" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3</span></span>
<span id="cb157-16"><a href="#cb157-16" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb157-17"><a href="#cb157-17" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb157-18"><a href="#cb157-18" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb157-19"><a href="#cb157-19" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb157-20"><a href="#cb157-20" aria-hidden="true" tabindex="-1"></a>        yhat<span class="op">=</span>soft(output)    </span>
<span id="cb157-21"><a href="#cb157-21" aria-hidden="true" tabindex="-1"></a>        combind <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb157-22"><a href="#cb157-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(combind.to(<span class="st">"cpu"</span>).data[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb157-23"><a href="#cb157-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="vs">r"$RNN$"</span>,size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb157-24"><a href="#cb157-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-127-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><code>-</code> LSTM</p>
<div id="d909cf43-c949-40ab-ae54-dab63cfcec60" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb158-2"><a href="#cb158-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb158-3"><a href="#cb158-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb158-4"><a href="#cb158-4" aria-hidden="true" tabindex="-1"></a>        lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">4</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb158-5"><a href="#cb158-5" aria-hidden="true" tabindex="-1"></a>        linr <span class="op">=</span> torch.nn.Linear(<span class="dv">3</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb158-6"><a href="#cb158-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb158-7"><a href="#cb158-7" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb158-8"><a href="#cb158-8" aria-hidden="true" tabindex="-1"></a>        _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">3</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb158-9"><a href="#cb158-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb158-10"><a href="#cb158-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1</span></span>
<span id="cb158-11"><a href="#cb158-11" aria-hidden="true" tabindex="-1"></a>            hidden, (hT,cT) <span class="op">=</span> lstm(x,(_water,_water))</span>
<span id="cb158-12"><a href="#cb158-12" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> linr(hidden)</span>
<span id="cb158-13"><a href="#cb158-13" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2</span></span>
<span id="cb158-14"><a href="#cb158-14" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(output,y)</span>
<span id="cb158-15"><a href="#cb158-15" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3</span></span>
<span id="cb158-16"><a href="#cb158-16" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb158-17"><a href="#cb158-17" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb158-18"><a href="#cb158-18" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb158-19"><a href="#cb158-19" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb158-20"><a href="#cb158-20" aria-hidden="true" tabindex="-1"></a>        yhat<span class="op">=</span>soft(output)    </span>
<span id="cb158-21"><a href="#cb158-21" aria-hidden="true" tabindex="-1"></a>        combind <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb158-22"><a href="#cb158-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(combind.to(<span class="st">"cpu"</span>).data[<span class="op">-</span><span class="dv">6</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb158-23"><a href="#cb158-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="vs">r"$LSTM$"</span>,size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb158-24"><a href="#cb158-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-128-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>lstm이 rnn보다 이런 상황에서는 더 잘 학습해낸다.</li>
<li>linear 의 hiddenlayer로 구분되어 있다.</li>
</ul>
</section>
</section>
<section id="exam6-abcdabcd" class="level2">
<h2 class="anchored" data-anchor-id="exam6-abcdabcd">Exam6: abcdabcD</h2>
<section id="data-2" class="level3">
<h3 class="anchored" data-anchor-id="data-2">data</h3>
<div id="69d6b468-bfea-4a61-b6cc-34dcabc97184" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'abcdabcD'</span>)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb159-2"><a href="#cb159-2" aria-hidden="true" tabindex="-1"></a>txt[:<span class="dv">8</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>['a', 'b', 'c', 'd', 'a', 'b', 'c', 'D']</code></pre>
</div>
</div>
<div id="bc893a67-a21a-439e-adc1-c3be5fb384e9" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb161"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a>txt_x <span class="op">=</span> txt[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb161-2"><a href="#cb161-2" aria-hidden="true" tabindex="-1"></a>txt_y <span class="op">=</span> txt[<span class="dv">1</span>:]</span></code></pre></div>
</div>
<div id="6ba613cd-e0ff-4d80-b984-8a323869b0fe" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb162"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a>mapping <span class="op">=</span> {<span class="st">'a'</span>:<span class="dv">0</span>, <span class="st">'b'</span>:<span class="dv">1</span>, <span class="st">'c'</span>:<span class="dv">2</span>, <span class="st">'d'</span>:<span class="dv">3</span>, <span class="st">'D'</span>:<span class="dv">4</span>}</span>
<span id="cb162-2"><a href="#cb162-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).<span class="bu">float</span>()</span>
<span id="cb162-3"><a href="#cb162-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).<span class="bu">float</span>()</span></code></pre></div>
</div>
<div id="c7daadce-c0b4-49c4-bfa2-b3dd018c11b5" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb163"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>x.to(<span class="st">"cuda:0"</span>)</span>
<span id="cb163-2"><a href="#cb163-2" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>y.to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
</div>
</section>
<section id="rnn-vs-lstm-성능비교실험-1" class="level3">
<h3 class="anchored" data-anchor-id="rnn-vs-lstm-성능비교실험-1">RNN vs LSTM 성능비교실험</h3>
<p><code>-</code> RNN</p>
<div id="38243df5-bcbc-45fb-93d2-71c4dd4c5a48" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb164"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb164-2"><a href="#cb164-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb164-3"><a href="#cb164-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb164-4"><a href="#cb164-4" aria-hidden="true" tabindex="-1"></a>        rnn <span class="op">=</span> torch.nn.RNN(<span class="dv">5</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb164-5"><a href="#cb164-5" aria-hidden="true" tabindex="-1"></a>        linr <span class="op">=</span> torch.nn.Linear(<span class="dv">4</span>,<span class="dv">5</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb164-6"><a href="#cb164-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb164-7"><a href="#cb164-7" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(rnn.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb164-8"><a href="#cb164-8" aria-hidden="true" tabindex="-1"></a>        _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb164-9"><a href="#cb164-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb164-10"><a href="#cb164-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1</span></span>
<span id="cb164-11"><a href="#cb164-11" aria-hidden="true" tabindex="-1"></a>            hidden, hT <span class="op">=</span> rnn(x,_water)</span>
<span id="cb164-12"><a href="#cb164-12" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> linr(hidden)</span>
<span id="cb164-13"><a href="#cb164-13" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2</span></span>
<span id="cb164-14"><a href="#cb164-14" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(output,y)</span>
<span id="cb164-15"><a href="#cb164-15" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3</span></span>
<span id="cb164-16"><a href="#cb164-16" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb164-17"><a href="#cb164-17" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb164-18"><a href="#cb164-18" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb164-19"><a href="#cb164-19" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb164-20"><a href="#cb164-20" aria-hidden="true" tabindex="-1"></a>        yhat<span class="op">=</span>soft(output)    </span>
<span id="cb164-21"><a href="#cb164-21" aria-hidden="true" tabindex="-1"></a>        combind <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb164-22"><a href="#cb164-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(combind.to(<span class="st">"cpu"</span>).data[<span class="op">-</span><span class="dv">8</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb164-23"><a href="#cb164-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="vs">r"$RNN$"</span>,size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb164-24"><a href="#cb164-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-133-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><code>-</code> LSTM</p>
<div id="ef3aa264-2428-450c-bb69-1341bd7a6a24" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb165-2"><a href="#cb165-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb165-3"><a href="#cb165-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb165-4"><a href="#cb165-4" aria-hidden="true" tabindex="-1"></a>        lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">5</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb165-5"><a href="#cb165-5" aria-hidden="true" tabindex="-1"></a>        linr <span class="op">=</span> torch.nn.Linear(<span class="dv">4</span>,<span class="dv">5</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb165-6"><a href="#cb165-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb165-7"><a href="#cb165-7" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb165-8"><a href="#cb165-8" aria-hidden="true" tabindex="-1"></a>        _water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">4</span>).to(<span class="st">"cuda:0"</span>)</span>
<span id="cb165-9"><a href="#cb165-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb165-10"><a href="#cb165-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1</span></span>
<span id="cb165-11"><a href="#cb165-11" aria-hidden="true" tabindex="-1"></a>            hidden, (hT,cT) <span class="op">=</span> lstm(x,(_water,_water))</span>
<span id="cb165-12"><a href="#cb165-12" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> linr(hidden)</span>
<span id="cb165-13"><a href="#cb165-13" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2</span></span>
<span id="cb165-14"><a href="#cb165-14" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(output,y)</span>
<span id="cb165-15"><a href="#cb165-15" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3</span></span>
<span id="cb165-16"><a href="#cb165-16" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb165-17"><a href="#cb165-17" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb165-18"><a href="#cb165-18" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb165-19"><a href="#cb165-19" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb165-20"><a href="#cb165-20" aria-hidden="true" tabindex="-1"></a>        yhat<span class="op">=</span>soft(output)    </span>
<span id="cb165-21"><a href="#cb165-21" aria-hidden="true" tabindex="-1"></a>        combind <span class="op">=</span> torch.concat([hidden,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb165-22"><a href="#cb165-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(combind.to(<span class="st">"cpu"</span>).data[<span class="op">-</span><span class="dv">8</span>:],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb165-23"><a href="#cb165-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="vs">r"$LSTM$"</span>,size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb165-24"><a href="#cb165-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-134-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><code>-</code> 관찰1: LSTM이 확실히 장기기억에 강하다.</p>
<p><code>-</code> 관찰2: LSTM은 hidden에 0이 잘 나온다.</p>
<ul>
<li>사실 확실히 구분되는 특징을 판별할때는 -1,1 로 히든레이어 값들이 설정되면 명확하다.</li>
<li>히든레이어에 -1~1사이의 값이 나온다면 애매한 판단이 내려지게 된다.</li>
<li>그런데 이 애매한 판단이 어떻게 보면 문맥의 뉘앙스를 이해하는데 더 잘 맞다.</li>
<li>그런데 RNN은 -1,1로 셋팅된 상황에서 -1~1로의 변화가 더디다는 것이 문제임.</li>
</ul>
</section>
</section>
<section id="lstm의-계산과정" class="level2">
<h2 class="anchored" data-anchor-id="lstm의-계산과정">LSTM의 계산과정</h2>
<section id="data-abab" class="level3">
<h3 class="anchored" data-anchor-id="data-abab">data: abaB</h3>
<div id="f90f83e0-1148-4ecd-a6a9-4055f46c5564" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb166"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'abaB'</span>)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb166-2"><a href="#cb166-2" aria-hidden="true" tabindex="-1"></a>txt[:<span class="dv">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>['a', 'b', 'a', 'B', 'a']</code></pre>
</div>
</div>
<ul>
<li>ab</li>
<li>aB</li>
<li>로서 a의 수준이 2개로 나뉨 <span class="math inline">\(\to\)</span> hidden node = 2</li>
</ul>
<div id="790d03b1-492c-41fd-8628-1596935616c5" class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb168"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a>txt_x <span class="op">=</span> txt[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb168-2"><a href="#cb168-2" aria-hidden="true" tabindex="-1"></a>txt_y <span class="op">=</span> txt[<span class="dv">1</span>:]</span></code></pre></div>
</div>
<div id="595daacb-29f7-41d0-8772-abe5b83ea718" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a>mapping <span class="op">=</span> {<span class="st">'a'</span>:<span class="dv">0</span>, <span class="st">'b'</span>:<span class="dv">1</span>, <span class="st">'B'</span>:<span class="dv">2</span>}</span>
<span id="cb169-2"><a href="#cb169-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).<span class="bu">float</span>()</span>
<span id="cb169-3"><a href="#cb169-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).<span class="bu">float</span>()</span></code></pre></div>
</div>
</section>
<section id="epoch-ver1-with-torch.nn.lstmcell" class="level3">
<h3 class="anchored" data-anchor-id="epoch-ver1-with-torch.nn.lstmcell">1 epoch ver1 (with torch.nn.LSTMCell)</h3>
<div id="d9fa4342-7618-499f-9a56-0c3ba1497ae0" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb170"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb170-2"><a href="#cb170-2" aria-hidden="true" tabindex="-1"></a>lstm_cell <span class="op">=</span> torch.nn.LSTMCell(<span class="dv">3</span>,<span class="dv">2</span>) </span>
<span id="cb170-3"><a href="#cb170-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb170-4"><a href="#cb170-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() </span>
<span id="cb170-5"><a href="#cb170-5" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm_cell.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div id="fdc32fdb-8ee2-4133-82ce-87894a8f46f6" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb171"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="bu">len</span>(x) </span>
<span id="cb171-2"><a href="#cb171-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>):</span>
<span id="cb171-3"><a href="#cb171-3" aria-hidden="true" tabindex="-1"></a>    ht <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb171-4"><a href="#cb171-4" aria-hidden="true" tabindex="-1"></a>    ct <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb171-5"><a href="#cb171-5" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb171-6"><a href="#cb171-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1~2</span></span>
<span id="cb171-7"><a href="#cb171-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb171-8"><a href="#cb171-8" aria-hidden="true" tabindex="-1"></a>        xt,yt <span class="op">=</span> x[[t]], y[[t]]</span>
<span id="cb171-9"><a href="#cb171-9" aria-hidden="true" tabindex="-1"></a>        ht,ct <span class="op">=</span> lstm_cell(xt,(ht,ct))</span>
<span id="cb171-10"><a href="#cb171-10" aria-hidden="true" tabindex="-1"></a>        ot <span class="op">=</span> linr(ht) </span>
<span id="cb171-11"><a href="#cb171-11" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss <span class="op">+</span> loss_fn(ot,yt)</span>
<span id="cb171-12"><a href="#cb171-12" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss <span class="op">/</span> T</span>
<span id="cb171-13"><a href="#cb171-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3 </span></span>
<span id="cb171-14"><a href="#cb171-14" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb171-15"><a href="#cb171-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 4 </span></span>
<span id="cb171-16"><a href="#cb171-16" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb171-17"><a href="#cb171-17" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code></pre></div>
</div>
<ul>
<li>데이터 적으니까 cpu로 할 것임</li>
</ul>
<div id="c1b19e4a-c8fc-4424-8900-f55d7ccfd1f2" class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a>ht,ct </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>(tensor([[-0.0406,  0.2505]], grad_fn=&lt;MulBackward0&gt;),
 tensor([[-0.0975,  0.7134]], grad_fn=&lt;AddBackward0&gt;))</code></pre>
</div>
</div>
<ul>
<li>hidden node가 많고 len 이 클수록 GPU가 효율이 좋다</li>
</ul>
</section>
<section id="epoch-ver2-완전-손으로-구현" class="level3">
<h3 class="anchored" data-anchor-id="epoch-ver2-완전-손으로-구현">1 epoch ver2 (완전 손으로 구현)</h3>
<section id="t0-to-t1" class="level4">
<h4 class="anchored" data-anchor-id="t0-to-t1"><strong><em>t=0 <span class="math inline">\(\to\)</span> t=1</em></strong></h4>
<p><code>-</code> lstm_cell 을 이용한 계산 (결과비교용)</p>
<div id="ec8b2c8a-e65e-48b4-8d24-570a3b77802c" class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb174"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb174-1"><a href="#cb174-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb174-2"><a href="#cb174-2" aria-hidden="true" tabindex="-1"></a>lstm_cell <span class="op">=</span> torch.nn.LSTMCell(<span class="dv">3</span>,<span class="dv">2</span>) </span>
<span id="cb174-3"><a href="#cb174-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb174-4"><a href="#cb174-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() </span>
<span id="cb174-5"><a href="#cb174-5" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm_cell.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div id="0a5fd7ca-e106-44dd-8bbc-cac748535e2d" class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="bu">len</span>(x) </span>
<span id="cb175-2"><a href="#cb175-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>):</span>
<span id="cb175-3"><a href="#cb175-3" aria-hidden="true" tabindex="-1"></a>    ht <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb175-4"><a href="#cb175-4" aria-hidden="true" tabindex="-1"></a>    ct <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb175-5"><a href="#cb175-5" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb175-6"><a href="#cb175-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1~2</span></span>
<span id="cb175-7"><a href="#cb175-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>):</span>
<span id="cb175-8"><a href="#cb175-8" aria-hidden="true" tabindex="-1"></a>        xt,yt <span class="op">=</span> x[[t]], y[[t]]</span>
<span id="cb175-9"><a href="#cb175-9" aria-hidden="true" tabindex="-1"></a>        ht,ct <span class="op">=</span> lstm_cell(xt,(ht,ct))</span>
<span id="cb175-10"><a href="#cb175-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     ot = linr(ht) </span></span>
<span id="cb175-11"><a href="#cb175-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     loss = loss + loss_fn(ot,yt)</span></span>
<span id="cb175-12"><a href="#cb175-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loss = loss / T</span></span>
<span id="cb175-13"><a href="#cb175-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ## 3 </span></span>
<span id="cb175-14"><a href="#cb175-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loss.backward()</span></span>
<span id="cb175-15"><a href="#cb175-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ## 4 </span></span>
<span id="cb175-16"><a href="#cb175-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># optimizr.step()</span></span>
<span id="cb175-17"><a href="#cb175-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># optimizr.zero_grad()</span></span></code></pre></div>
</div>
<div id="9aca0b32-7d50-4359-b4e6-5a724f49177d" class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb176"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb176-1"><a href="#cb176-1" aria-hidden="true" tabindex="-1"></a>ht,ct </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>(tensor([[-0.0541,  0.0892]], grad_fn=&lt;MulBackward0&gt;),
 tensor([[-0.1347,  0.2339]], grad_fn=&lt;AddBackward0&gt;))</code></pre>
</div>
</div>
<ul>
<li>이런결과를 어떻게 만드는걸까?</li>
<li><a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html" class="uri">https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html</a></li>
</ul>
<p><span class="math inline">\(i_t = \sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi})\)</span></p>
<p><span class="math inline">\(f_t = \sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf})\)</span></p>
<p><span class="math inline">\(g_t = \tanh (W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg})\)</span></p>
<p><span class="math inline">\(o_t = \sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{hg})\)</span></p>
<p><span class="math inline">\(o_t = \sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho})\)</span></p>
<p><span class="math inline">\(c_t = f_t \odot c_{t-1} + i_t \odot g_t\)</span></p>
<p><span class="math inline">\(h_t = o_t \odot \tanh (c_t)\)</span></p>
<p><span class="math inline">\(\sigma = \text{ Sigmoid }\)</span></p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ }\circ \text{ }\underrightarrow{sig} \text{ }i_t\)</span></p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ }\square \text{ } \underrightarrow{sig} \text{ }f_t\)</span></p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ }\star \text{ } \underrightarrow{tanh} \text{ }g_t\)</span></p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ } \triangleleft \text{ }\underrightarrow{sig} \text{ }o_t\)</span></p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ }\circ \text{ , } \square \text{, } \star \text{, } \triangleleft \text{ } \to \sigma(circ) \text{, }\sigma(\square) \text{ , }\tanh(\star)\text{ , } \sigma(\triangleleft) \sim i_t, f_t, g_t, o_t\)</span></p>
<ul>
<li>위에 나온 W가 어떻게 계산되나</li>
</ul>
<p>weight_ih_l[k] – the learnable input-hidden weights of the <span class="math inline">\(\text{k}^{th}\)</span> layer <span class="math inline">\((W_ii|W_if|W_ig|W_io)\)</span>, of shape (4<em>hidden_size, input_size) for <span class="math inline">\(k = 0\)</span>. Otherwise, the shape is (4</em>hidden_size, num_directions * hidden_size). If proj_size &gt; 0 was specified, the shape will be (4<em>hidden_size, num_directions </em> proj_size) for <span class="math inline">\(k &gt; 0\)</span></p>
<p>weight_hh_l[k] – the learnable hidden-hidden weights of the <span class="math inline">\(\text{k}^{th}\)</span>layer <span class="math inline">\((W_hi|W_hf|W_hg|W_ho)\)</span>, of shape (4<em>hidden_size, hidden_size). If proj_size &gt; 0 was specified, the shape will be (4</em>hidden_size, proj_size).</p>
<p><code>-</code> 직접계산</p>
<ul>
<li><span class="math inline">\(o_t\)</span> = output_gate</li>
<li><span class="math inline">\(f_t\)</span> = forget_gate</li>
<li><span class="math inline">\(i_t\)</span> = input_gate</li>
</ul>
<div id="071cee7d-a92a-446c-98fd-84b4d92cb4b4" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb178"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a>ht <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb178-2"><a href="#cb178-2" aria-hidden="true" tabindex="-1"></a>ct <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span></code></pre></div>
</div>
<div id="00b7a640-2cc6-4caa-8453-c8525e7131a0" class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb179"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a>_ifgo <span class="op">=</span> xt <span class="op">@</span> lstm_cell.weight_ih.T <span class="op">+</span> ht <span class="op">@</span> lstm_cell.weight_hh.T <span class="op">+</span> lstm_cell.bias_ih <span class="op">+</span> lstm_cell.bias_hh</span>
<span id="cb179-2"><a href="#cb179-2" aria-hidden="true" tabindex="-1"></a>_ifgo</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>tensor([[ 0.0137,  0.1495,  0.0879,  0.6436, -0.2615,  0.3974, -0.3506, -0.4550]],
       grad_fn=&lt;AddBackward0&gt;)</code></pre>
</div>
</div>
<p><span class="math inline">\(\circ \text{ , } \square \text{, } \star \text{, } \triangleleft\)</span>각 두 개씩</p>
<div id="4c928a1d-c98b-4412-8d84-0189f8e1cbf5" class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb181"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a>input_gate <span class="op">=</span> sig(_ifgo[:,<span class="dv">0</span>:<span class="dv">2</span>])</span>
<span id="cb181-2"><a href="#cb181-2" aria-hidden="true" tabindex="-1"></a>forget_gate <span class="op">=</span> sig(_ifgo[:,<span class="dv">2</span>:<span class="dv">4</span>])</span>
<span id="cb181-3"><a href="#cb181-3" aria-hidden="true" tabindex="-1"></a>gt <span class="op">=</span> tanh(_ifgo[:,<span class="dv">4</span>:<span class="dv">6</span>])</span>
<span id="cb181-4"><a href="#cb181-4" aria-hidden="true" tabindex="-1"></a>output_gate <span class="op">=</span> sig(_ifgo[:,<span class="dv">6</span>:<span class="dv">8</span>])</span></code></pre></div>
</div>
<div id="43c3a6b8-9665-4d62-924c-4026fd30e771" class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb182"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a>ct <span class="op">=</span> forget_gate <span class="op">*</span> ct <span class="op">+</span> input_gate <span class="op">*</span> gt</span>
<span id="cb182-2"><a href="#cb182-2" aria-hidden="true" tabindex="-1"></a>ht <span class="op">=</span> output_gate <span class="op">*</span> tanh(ct)</span></code></pre></div>
</div>
<div id="6c473da7-59de-4dc4-a6a8-2a3c164dddaf" class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb183"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a>ht,ct</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>(tensor([[-0.0812,  0.1327]], grad_fn=&lt;MulBackward0&gt;),
 tensor([[-0.1991,  0.3563]], grad_fn=&lt;AddBackward0&gt;))</code></pre>
</div>
</div>
</section>
<section id="t0-to-tt" class="level4">
<h4 class="anchored" data-anchor-id="t0-to-tt"><strong><em>t=0 <span class="math inline">\(\to\)</span> t=T</em></strong></h4>
<div id="7b3f0bf8-f390-4585-b333-df9d8e648f4a" class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb185"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb185-1"><a href="#cb185-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb185-2"><a href="#cb185-2" aria-hidden="true" tabindex="-1"></a>lstm_cell <span class="op">=</span> torch.nn.LSTMCell(<span class="dv">3</span>,<span class="dv">2</span>) </span>
<span id="cb185-3"><a href="#cb185-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb185-4"><a href="#cb185-4" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() </span>
<span id="cb185-5"><a href="#cb185-5" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm_cell.parameters())<span class="op">+</span><span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div id="e878d569-3dee-43de-b794-cde107b941b8" class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb186"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="bu">len</span>(x) </span>
<span id="cb186-2"><a href="#cb186-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>):</span>
<span id="cb186-3"><a href="#cb186-3" aria-hidden="true" tabindex="-1"></a>    ht <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb186-4"><a href="#cb186-4" aria-hidden="true" tabindex="-1"></a>    ct <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb186-5"><a href="#cb186-5" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb186-6"><a href="#cb186-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1~2</span></span>
<span id="cb186-7"><a href="#cb186-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb186-8"><a href="#cb186-8" aria-hidden="true" tabindex="-1"></a>        xt,yt <span class="op">=</span> x[[t]], y[[t]]</span>
<span id="cb186-9"><a href="#cb186-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb186-10"><a href="#cb186-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">## lstm_cell step1: calculate _ifgo </span></span>
<span id="cb186-11"><a href="#cb186-11" aria-hidden="true" tabindex="-1"></a>        _ifgo <span class="op">=</span> xt <span class="op">@</span> lstm_cell.weight_ih.T <span class="op">+</span> ht <span class="op">@</span> lstm_cell.weight_hh.T <span class="op">+</span> lstm_cell.bias_ih <span class="op">+</span> lstm_cell.bias_hh</span>
<span id="cb186-12"><a href="#cb186-12" aria-hidden="true" tabindex="-1"></a>        <span class="co">## lstm_cell step2: decompose _ifgo </span></span>
<span id="cb186-13"><a href="#cb186-13" aria-hidden="true" tabindex="-1"></a>        input_gate <span class="op">=</span> sig(_ifgo[:,<span class="dv">0</span>:<span class="dv">2</span>])</span>
<span id="cb186-14"><a href="#cb186-14" aria-hidden="true" tabindex="-1"></a>        forget_gate <span class="op">=</span> sig(_ifgo[:,<span class="dv">2</span>:<span class="dv">4</span>])</span>
<span id="cb186-15"><a href="#cb186-15" aria-hidden="true" tabindex="-1"></a>        gt <span class="op">=</span> tanh(_ifgo[:,<span class="dv">4</span>:<span class="dv">6</span>])</span>
<span id="cb186-16"><a href="#cb186-16" aria-hidden="true" tabindex="-1"></a>        output_gate <span class="op">=</span> sig(_ifgo[:,<span class="dv">6</span>:<span class="dv">8</span>])</span>
<span id="cb186-17"><a href="#cb186-17" aria-hidden="true" tabindex="-1"></a>        <span class="co">## lstm_cell step3: calculate ht,ct </span></span>
<span id="cb186-18"><a href="#cb186-18" aria-hidden="true" tabindex="-1"></a>        ct <span class="op">=</span> forget_gate <span class="op">*</span> ct <span class="op">+</span> input_gate <span class="op">*</span> gt</span>
<span id="cb186-19"><a href="#cb186-19" aria-hidden="true" tabindex="-1"></a>        ht <span class="op">=</span> output_gate <span class="op">*</span> tanh(ct)</span>
<span id="cb186-20"><a href="#cb186-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb186-21"><a href="#cb186-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     ot = linr(ht) </span></span>
<span id="cb186-22"><a href="#cb186-22" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     loss = loss + loss_fn(ot,yt)</span></span>
<span id="cb186-23"><a href="#cb186-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loss = loss / T</span></span>
<span id="cb186-24"><a href="#cb186-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ## 3 </span></span>
<span id="cb186-25"><a href="#cb186-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loss.backward()</span></span>
<span id="cb186-26"><a href="#cb186-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ## 4 </span></span>
<span id="cb186-27"><a href="#cb186-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># optimizr.step()</span></span>
<span id="cb186-28"><a href="#cb186-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># optimizr.zero_grad()</span></span></code></pre></div>
</div>
<div id="b1529f2d-50e0-4d6c-b7b4-11d11aa8f98a" class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb187"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a>ht,ct</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="72">
<pre><code>(tensor([[-0.0406,  0.2505]], grad_fn=&lt;MulBackward0&gt;),
 tensor([[-0.0975,  0.7134]], grad_fn=&lt;AddBackward0&gt;))</code></pre>
</div>
</div>
</section>
</section>
<section id="epoch-ver3-with-torch.nn.lstm" class="level3">
<h3 class="anchored" data-anchor-id="epoch-ver3-with-torch.nn.lstm">1 epoch ver3 (with torch.nn.LSTM)</h3>
<div id="db57b1d2-62dd-419c-be8e-4ecd86ddf7a7" class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb189"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb189-2"><a href="#cb189-2" aria-hidden="true" tabindex="-1"></a>lstm_cell <span class="op">=</span> torch.nn.LSTMCell(<span class="dv">3</span>,<span class="dv">2</span>)</span>
<span id="cb189-3"><a href="#cb189-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">3</span>) </span></code></pre></div>
</div>
<div id="cda1f85d-2684-4132-8a77-2963dc8c506d" class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb190"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb190-1"><a href="#cb190-1" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">3</span>,<span class="dv">2</span>) </span></code></pre></div>
</div>
<div id="949f680d-6f97-4d1b-9eb3-c1bac8a00c6d" class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb191"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb191-1"><a href="#cb191-1" aria-hidden="true" tabindex="-1"></a>lstm.weight_hh_l0.data <span class="op">=</span> lstm_cell.weight_hh.data </span>
<span id="cb191-2"><a href="#cb191-2" aria-hidden="true" tabindex="-1"></a>lstm.bias_hh_l0.data <span class="op">=</span> lstm_cell.bias_hh.data </span>
<span id="cb191-3"><a href="#cb191-3" aria-hidden="true" tabindex="-1"></a>lstm.weight_ih_l0.data <span class="op">=</span> lstm_cell.weight_ih.data </span>
<span id="cb191-4"><a href="#cb191-4" aria-hidden="true" tabindex="-1"></a>lstm.bias_ih_l0.data <span class="op">=</span> lstm_cell.bias_ih.data </span></code></pre></div>
</div>
<ul>
<li>초기화된 가중치값들로 덮어씌우기</li>
</ul>
<div id="6c438c59-63cf-475b-ab57-8fbad3df5ab9" class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb192"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb192-1"><a href="#cb192-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb192-2"><a href="#cb192-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters()) <span class="op">+</span> <span class="bu">list</span>(linr.parameters()), lr<span class="op">=</span><span class="fl">0.1</span>) </span></code></pre></div>
</div>
<div id="8a4321ef-3ca7-4c79-80c9-9a6d2e3fbbb6" class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb193"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb193-1"><a href="#cb193-1" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>) </span>
<span id="cb193-2"><a href="#cb193-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>): </span>
<span id="cb193-3"><a href="#cb193-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## step1 </span></span>
<span id="cb193-4"><a href="#cb193-4" aria-hidden="true" tabindex="-1"></a>    hidden, (ht,ct) <span class="op">=</span> lstm(x,(_water,_water))</span>
<span id="cb193-5"><a href="#cb193-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden)</span>
<span id="cb193-6"><a href="#cb193-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ## step2</span></span>
<span id="cb193-7"><a href="#cb193-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loss = loss_fn(output,y) </span></span>
<span id="cb193-8"><a href="#cb193-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ## step3</span></span>
<span id="cb193-9"><a href="#cb193-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loss.backward()</span></span>
<span id="cb193-10"><a href="#cb193-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ## step4 </span></span>
<span id="cb193-11"><a href="#cb193-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># optimizr.step()</span></span>
<span id="cb193-12"><a href="#cb193-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># optimizr.zero_grad() </span></span></code></pre></div>
</div>
<div id="a7e9f401-9d45-4824-8b2c-5d871006b7e3" class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb194"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb194-1"><a href="#cb194-1" aria-hidden="true" tabindex="-1"></a>ht,ct</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>(tensor([[-0.0406,  0.2505]], grad_fn=&lt;SqueezeBackward1&gt;),
 tensor([[-0.0975,  0.7134]], grad_fn=&lt;SqueezeBackward1&gt;))</code></pre>
</div>
</div>
</section>
</section>
<section id="lstm은-왜-강한가" class="level2">
<h2 class="anchored" data-anchor-id="lstm은-왜-강한가">LSTM은 왜 강한가?</h2>
<section id="data-abab-1" class="level3">
<h3 class="anchored" data-anchor-id="data-abab-1">data: abaB</h3>
<div id="c64b3d7c-2e66-4629-9ad4-1e3bd9138029" class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb196"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb196-1"><a href="#cb196-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'abaB'</span>)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb196-2"><a href="#cb196-2" aria-hidden="true" tabindex="-1"></a>txt[:<span class="dv">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="79">
<pre><code>['a', 'b', 'a', 'B', 'a']</code></pre>
</div>
</div>
<div id="e819e299-9a38-40d2-9407-7d251aecd9e3" class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb198"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb198-1"><a href="#cb198-1" aria-hidden="true" tabindex="-1"></a>n_words <span class="op">=</span> <span class="dv">3</span></span></code></pre></div>
</div>
<div id="19407661-7cba-4b4e-ba92-f32773664c57" class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb199"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb199-1"><a href="#cb199-1" aria-hidden="true" tabindex="-1"></a>mapping <span class="op">=</span> {<span class="st">'a'</span>:<span class="dv">0</span>, <span class="st">'b'</span>:<span class="dv">1</span>, <span class="st">'B'</span>:<span class="dv">2</span>}</span></code></pre></div>
</div>
<div id="fd27f9f6-7122-493e-8415-34b61b1bddb6" class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb200"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb200-1"><a href="#cb200-1" aria-hidden="true" tabindex="-1"></a>txt_x <span class="op">=</span> txt[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb200-2"><a href="#cb200-2" aria-hidden="true" tabindex="-1"></a>txt_y <span class="op">=</span> txt[<span class="dv">1</span>:]</span></code></pre></div>
</div>
<div id="40bb3e23-c7e8-44d2-99f3-012f881aaa6a" class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb201"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a>txt_x[:<span class="dv">10</span>],txt_y[:<span class="dv">10</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="83">
<pre><code>(['a', 'b', 'a', 'B', 'a', 'b', 'a', 'B', 'a', 'b'],
 ['b', 'a', 'B', 'a', 'b', 'a', 'B', 'a', 'b', 'a'])</code></pre>
</div>
</div>
<div id="03493d19-ab7c-4285-8460-02a8e29f7113" class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb203"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb203-1"><a href="#cb203-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).<span class="bu">float</span>()</span>
<span id="cb203-2"><a href="#cb203-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).<span class="bu">float</span>()</span></code></pre></div>
</div>
<div id="cc4701aa-99d0-4366-8a3a-70623a31d496" class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb204"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb204-1"><a href="#cb204-1" aria-hidden="true" tabindex="-1"></a>x,y</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<pre><code>(tensor([[1., 0., 0.],
         [0., 1., 0.],
         [1., 0., 0.],
         ...,
         [1., 0., 0.],
         [0., 1., 0.],
         [1., 0., 0.]]),
 tensor([[0., 1., 0.],
         [1., 0., 0.],
         [0., 0., 1.],
         ...,
         [0., 1., 0.],
         [1., 0., 0.],
         [0., 0., 1.]]))</code></pre>
</div>
</div>
</section>
<section id="epoch" class="level3">
<h3 class="anchored" data-anchor-id="epoch">1000 epoch</h3>
<div id="adad7d35-775c-4345-9588-6468464ce000" class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb206"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb206-1"><a href="#cb206-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>) </span>
<span id="cb206-2"><a href="#cb206-2" aria-hidden="true" tabindex="-1"></a>lstm <span class="op">=</span> torch.nn.LSTM(<span class="dv">3</span>,<span class="dv">2</span>) </span>
<span id="cb206-3"><a href="#cb206-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">3</span>) </span></code></pre></div>
</div>
<div id="2284658b-aa94-4d9b-b0d6-470cf27b48e9" class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb207"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb207-1"><a href="#cb207-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() </span>
<span id="cb207-2"><a href="#cb207-2" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(<span class="bu">list</span>(lstm.parameters())<span class="op">+</span> <span class="bu">list</span>(linr.parameters()),lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div id="8eeb1b3c-000e-4047-b09d-bb1d211c2e3b" class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb208"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb208-1"><a href="#cb208-1" aria-hidden="true" tabindex="-1"></a>_water <span class="op">=</span> torch.zeros(<span class="dv">1</span>,<span class="dv">2</span>) </span>
<span id="cb208-2"><a href="#cb208-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>): </span>
<span id="cb208-3"><a href="#cb208-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">## step1 </span></span>
<span id="cb208-4"><a href="#cb208-4" aria-hidden="true" tabindex="-1"></a>    hidden, (ht,ct) <span class="op">=</span> lstm(x,(_water,_water))</span>
<span id="cb208-5"><a href="#cb208-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> linr(hidden)</span>
<span id="cb208-6"><a href="#cb208-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## step2</span></span>
<span id="cb208-7"><a href="#cb208-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output,y) </span>
<span id="cb208-8"><a href="#cb208-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">## step3</span></span>
<span id="cb208-9"><a href="#cb208-9" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb208-10"><a href="#cb208-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## step4 </span></span>
<span id="cb208-11"><a href="#cb208-11" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb208-12"><a href="#cb208-12" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad() </span></code></pre></div>
</div>
</section>
<section id="시각화" class="level3">
<h3 class="anchored" data-anchor-id="시각화">시각화</h3>
<div id="0ec0724b-0298-4a61-b0d0-6cb4ca86cac6" class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb209"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb209-2"><a href="#cb209-2" aria-hidden="true" tabindex="-1"></a>input_gate <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>)</span>
<span id="cb209-3"><a href="#cb209-3" aria-hidden="true" tabindex="-1"></a>forget_gate <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>)</span>
<span id="cb209-4"><a href="#cb209-4" aria-hidden="true" tabindex="-1"></a>output_gate <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>)</span>
<span id="cb209-5"><a href="#cb209-5" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>)</span>
<span id="cb209-6"><a href="#cb209-6" aria-hidden="true" tabindex="-1"></a>cell <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>)</span>
<span id="cb209-7"><a href="#cb209-7" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> torch.zeros(T,<span class="dv">2</span>) </span></code></pre></div>
</div>
<ul>
<li>변수를 담을 빈 셋 설정</li>
</ul>
<div id="70d0fdf3-5e08-4f87-ba53-a329ee9599c2" class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb210"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb210-1"><a href="#cb210-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T): </span>
<span id="cb210-2"><a href="#cb210-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1: calculate _ifgo </span></span>
<span id="cb210-3"><a href="#cb210-3" aria-hidden="true" tabindex="-1"></a>    _ifgo <span class="op">=</span> x[[t]] <span class="op">@</span> lstm.weight_ih_l0.T <span class="op">+</span> h[[t]] <span class="op">@</span> lstm.weight_hh_l0.T <span class="op">+</span> lstm.bias_ih_l0 <span class="op">+</span> lstm.bias_hh_l0 </span>
<span id="cb210-4"><a href="#cb210-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2: decompose _ifgo </span></span>
<span id="cb210-5"><a href="#cb210-5" aria-hidden="true" tabindex="-1"></a>    input_gate[[t]] <span class="op">=</span> sig(_ifgo[:,<span class="dv">0</span>:<span class="dv">2</span>])</span>
<span id="cb210-6"><a href="#cb210-6" aria-hidden="true" tabindex="-1"></a>    forget_gate[[t]] <span class="op">=</span> sig(_ifgo[:,<span class="dv">2</span>:<span class="dv">4</span>])</span>
<span id="cb210-7"><a href="#cb210-7" aria-hidden="true" tabindex="-1"></a>    g[[t]] <span class="op">=</span> tanh(_ifgo[:,<span class="dv">4</span>:<span class="dv">6</span>])</span>
<span id="cb210-8"><a href="#cb210-8" aria-hidden="true" tabindex="-1"></a>    output_gate[[t]] <span class="op">=</span> sig(_ifgo[:,<span class="dv">6</span>:<span class="dv">8</span>])</span>
<span id="cb210-9"><a href="#cb210-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3: calculate ht,ct </span></span>
<span id="cb210-10"><a href="#cb210-10" aria-hidden="true" tabindex="-1"></a>    cell[[t]] <span class="op">=</span> forget_gate[[t]] <span class="op">*</span> cell[[t]] <span class="op">+</span> input_gate[[t]] <span class="op">*</span> g[[t]]</span>
<span id="cb210-11"><a href="#cb210-11" aria-hidden="true" tabindex="-1"></a>    h[[t]] <span class="op">=</span> output_gate[[t]] <span class="op">*</span> tanh(cell[[t]])</span></code></pre></div>
</div>
<div id="62770c91-377d-43d7-b24b-76a578cb66a4" class="cell" data-execution_count="91">
<div class="sourceCode cell-code" id="cb211"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb211-1"><a href="#cb211-1" aria-hidden="true" tabindex="-1"></a>combinded1 <span class="op">=</span> torch.concat([input_gate,forget_gate,output_gate],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb211-2"><a href="#cb211-2" aria-hidden="true" tabindex="-1"></a>combinded2 <span class="op">=</span> torch.concat([g,cell,h,soft(output)],axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div id="49415b83-4996-4f4e-9bc8-b934df5e8921" class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb212"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb212-1"><a href="#cb212-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded1[<span class="op">-</span><span class="dv">8</span>:].data,cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)<span class="op">;</span></span>
<span id="cb212-2"><a href="#cb212-2" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(combinded1.shape[<span class="op">-</span><span class="dv">1</span>]),labels<span class="op">=</span>[<span class="st">'i'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'f'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'o'</span>]<span class="op">*</span><span class="dv">2</span>)<span class="op">;</span></span>
<span id="cb212-3"><a href="#cb212-3" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded2[<span class="op">-</span><span class="dv">8</span>:].data,cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb212-4"><a href="#cb212-4" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(combinded2.shape[<span class="op">-</span><span class="dv">1</span>]),labels<span class="op">=</span>[<span class="st">'g'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'c'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'h'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'yhat'</span>]<span class="op">*</span><span class="dv">3</span>)<span class="op">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-171-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-171-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>상단그림은 게이트의 값들만 시각화, 하단그림은 게이트 이외의 값들을 시각화</li>
</ul>
</section>
<section id="시각화의-해석i" class="level3">
<h3 class="anchored" data-anchor-id="시각화의-해석i">시각화의 해석I</h3>
<div id="80049493-28cc-49ef-83df-2260d674ff98" class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb213"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb213-1"><a href="#cb213-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded1[<span class="op">-</span><span class="dv">8</span>:].data,cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)<span class="op">;</span></span>
<span id="cb213-2"><a href="#cb213-2" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(combinded1.shape[<span class="op">-</span><span class="dv">1</span>]),labels<span class="op">=</span>[<span class="st">'i'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'f'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'o'</span>]<span class="op">*</span><span class="dv">2</span>)<span class="op">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-172-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><code>-</code> input_gate, forget_gate, output_gate는 모두 0~1 사이의 값을 가진다.</p>
<p><code>-</code> 이 값들은 각각 모두 <span class="math inline">\({\boldsymbol g}_t, {\boldsymbol c}_{t-1}, \tanh({\boldsymbol c}_t)\)</span>에 곱해진다. 따라서 input_gate, forget_gate, output_gate 는 gate의 역할로 비유가능하다. (1이면 통과, 0이면 차단)</p>
<ul>
<li>input_gate: <span class="math inline">\({\boldsymbol g}_t\)</span>의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정</li>
<li>forget_gate: <span class="math inline">\({\boldsymbol c}_{t-1}\)</span>의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정</li>
<li>output_gate: <span class="math inline">\(\tanh({\boldsymbol c}_t)\)</span>의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정</li>
</ul>
<p>(서연 필기)</p>
<ul>
<li>값들이 0과 1사이의 값을 가진다</li>
<li>파 -1 흰 0 빨 1</li>
<li>0 곱하면 어떤 값이든 0이 되니까 차단한다 표현</li>
</ul>
</section>
<section id="시각화의-해석ii" class="level3">
<h3 class="anchored" data-anchor-id="시각화의-해석ii">시각화의 해석II</h3>
<div id="e8cedd7d-aa54-4843-9cfb-86c8b431536d" class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb214"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb214-1"><a href="#cb214-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(combinded2[<span class="op">-</span><span class="dv">8</span>:].data,cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb214-2"><a href="#cb214-2" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(combinded2.shape[<span class="op">-</span><span class="dv">1</span>]),labels<span class="op">=</span>[<span class="st">'g'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'c'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'h'</span>]<span class="op">*</span><span class="dv">2</span> <span class="op">+</span> [<span class="st">'yhat'</span>]<span class="op">*</span><span class="dv">3</span>)<span class="op">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-11-21-ml-11w_files/figure-html/cell-173-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><code>-</code> 결국 <span class="math inline">\({\boldsymbol g}_t\to {\boldsymbol c}_t \to {\boldsymbol h}_t \to \hat{\boldsymbol y}\)</span> 의 느낌이다. (<span class="math inline">\({\boldsymbol h}_t\)</span>를 계산하기 위해서는 <span class="math inline">\({\boldsymbol c}_t\)</span>가 필요했고 <span class="math inline">\({\boldsymbol c}_t\)</span>를 계산하기 위해서는 <span class="math inline">\({\boldsymbol c}_{t-1}\)</span>과 <span class="math inline">\({\boldsymbol g}_t\)</span>가 필요했음)</p>
<ul>
<li><span class="math inline">\({\boldsymbol h}_t= \tanh({\boldsymbol c}_t) \odot {\boldsymbol o}_t\)</span></li>
<li><span class="math inline">\({\boldsymbol c}_t ={\boldsymbol c}_{t-1} \odot {\boldsymbol f}_t + {\boldsymbol g}_{t} \odot {\boldsymbol i}_t\)</span></li>
</ul>
<p><code>-</code> <span class="math inline">\({\boldsymbol g}_t,{\boldsymbol c}_t,{\boldsymbol h}_t\)</span> 모두 <span class="math inline">\({\boldsymbol x}_t\)</span>의 정보를 숙성시켜 가지고 있는 느낌이 든다.</p>
<p><code>-</code> <span class="math inline">\({\boldsymbol g}_t\)</span> 특징: 보통 -1,1 중 하나의 값을 가지도록 학습되어 있다. (마치 RNN의 hidden node처럼!)</p>
<ul>
<li><span class="math inline">\(\boldsymbol{g}_t = \tanh({\boldsymbol x}_t {\bf W}_{ig} + {\boldsymbol h}_{t-1} {\bf W}_{hg}+ {\boldsymbol b}_{ig}+{\boldsymbol b}_{hg})\)</span></li>
</ul>
<p><code>-</code> <span class="math inline">\({\boldsymbol c}_t\)</span> 특징: <span class="math inline">\({\boldsymbol g}_t\)</span>와 매우 비슷하지만 약간 다른값을 가진다. 그래서 <span class="math inline">\({\boldsymbol g}_t\)</span>와는 달리 -1,1 이외의 값도 종종 등장.</p>
<div id="e47ea880-23e0-4e32-9516-62c07a4512fa" class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb215"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb215-1"><a href="#cb215-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"first row: gt=</span><span class="sc">{}</span><span class="st">, ct=</span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(g[<span class="op">-</span><span class="dv">8</span>].data, cell[<span class="op">-</span><span class="dv">8</span>].data))</span>
<span id="cb215-2"><a href="#cb215-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"second row: gt=</span><span class="sc">{}</span><span class="st">, ct=</span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(g[<span class="op">-</span><span class="dv">7</span>].data, cell[<span class="op">-</span><span class="dv">7</span>].data))</span>
<span id="cb215-3"><a href="#cb215-3" aria-hidden="true" tabindex="-1"></a><span class="co">#g[-7], cell[-7]</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>first row: gt=tensor([ 0.9999, -0.9999]), ct=tensor([ 0.9647, -0.9984])
second row: gt=tensor([ 0.9970, -0.9554]), ct=tensor([ 0.3592, -0.9373])</code></pre>
</div>
</div>
<p><code>-</code> <span class="math inline">\({\boldsymbol h}_t\)</span> 특징: (1) <span class="math inline">\({\boldsymbol c}_t\)</span>의 느낌이 있음 하지만 약간의 변형이 있음. (2) -1~1 사이에의 값을 훨씬 다양하게 가진다. (tanh때문)</p>
<p>(서연 필기)</p>
<ul>
<li>comparison of g,c part
<ul>
<li>보니까 빨간 색은 1에 가까운 값, 파란색은 -1에 가까운 값들을 띄었다.</li>
<li>그리고 연한 빨간색인 부분은 0.3592로 낮았고, g부분과 c부분이 열별로 보았을 때 달랐다</li>
</ul></li>
</ul>
<div id="888cd827-2546-4836-aa95-89ac7dcf7eac" class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb217"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb217-1"><a href="#cb217-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"first row: gt=</span><span class="sc">{}</span><span class="st">, ct=</span><span class="sc">{}</span><span class="st">, ht=</span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(g[<span class="op">-</span><span class="dv">8</span>].data, cell[<span class="op">-</span><span class="dv">8</span>].data,h[<span class="op">-</span><span class="dv">8</span>].data))</span>
<span id="cb217-2"><a href="#cb217-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"second row: gt=</span><span class="sc">{}</span><span class="st">, ct=</span><span class="sc">{}</span><span class="st">, ht=</span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(g[<span class="op">-</span><span class="dv">7</span>].data, cell[<span class="op">-</span><span class="dv">7</span>].data,h[<span class="op">-</span><span class="dv">7</span>].data))</span>
<span id="cb217-3"><a href="#cb217-3" aria-hidden="true" tabindex="-1"></a><span class="co">#g[-7], cell[-7]</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>first row: gt=tensor([ 0.9999, -0.9999]), ct=tensor([ 0.9647, -0.9984]), ht=tensor([ 0.7370, -0.3323])
second row: gt=tensor([ 0.9970, -0.9554]), ct=tensor([ 0.3592, -0.9373]), ht=tensor([ 0.0604, -0.6951])</code></pre>
</div>
</div>
<p>(서연 필기)</p>
<ul>
<li>comparison of c,h part
<ul>
<li>h는 c와 무관해보이지 않는다.</li>
<li>단지 어떤 변형이 있는 것 같다.</li>
</ul></li>
</ul>
<p><code>-</code> 예전의문 해결</p>
<ul>
<li>실험적으로 살펴보니 LSTM이 RNN보다 장기기억에 유리했음.</li>
<li>그 이유: RRN은 <span class="math inline">\({\boldsymbol h}_t\)</span>의 값이 -1 혹은 1로 결정되는 경우가 많았음. 그러나 경우에 따라서는 <span class="math inline">\({\boldsymbol h}_t\)</span>이 -1~1의 값을 가지는 것이 문맥적 뉘앙스를 포착하기에는 유리한데 LSTM이 이러한 방식으로 학습되는 경우가 많았음.</li>
<li>왜 LSTM의 <span class="math inline">\({\boldsymbol h}_t\)</span>은 -1,1 이외의 값을 쉽게 가질 수 있는가? (1) gate들의 역할 (2) 마지막에 취해지는 tanh 때문</li>
</ul>
</section>
<section id="lstm의-알고리즘-리뷰-i-수식위주" class="level3">
<h3 class="anchored" data-anchor-id="lstm의-알고리즘-리뷰-i-수식위주">LSTM의 알고리즘 리뷰 I (수식위주)</h3>
<p><strong>(step1)</strong> calculate <span class="math inline">\({\tt ifgo}\)</span></p>
<p><span class="math inline">\({\tt ifgo} = {\boldsymbol x}_t \big[{\bf W}_{ii} | {\bf W}_{if}| {\bf W}_{ig} |{\bf W}_{io}\big] + {\boldsymbol h}_{t-1} \big[ {\bf W}_{hi}|{\bf W}_{hf} |{\bf W}_{hg} | {\bf W}_{ho} \big] + bias\)</span></p>
<p><span class="math inline">\(=\big[{\boldsymbol x}_t{\bf W}_{ii} + {\boldsymbol h}_{t-1}{\bf W}_{hi} ~\big|~ {\boldsymbol x}_t{\bf W}_{if}+ {\boldsymbol h}_{t-1}{\bf W}_{hf}~ \big|~ {\boldsymbol x}_t{\bf W}_{ig} + {\boldsymbol h}_{t-1}{\bf W}_{hg} ~\big|~ {\boldsymbol x}_t{\bf W}_{io} + {\boldsymbol h}_{t-1}{\bf W}_{ho} \big] + bias\)</span></p>
<p>참고: 위의 수식은 아래코드에 해당하는 부분</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb219-1"><a href="#cb219-1" aria-hidden="true" tabindex="-1"></a>ifgo <span class="op">=</span> xt <span class="op">@</span> lstm_cell.weight_ih.T <span class="op">+</span> ht <span class="op">@</span> lstm_cell.weight_hh.T <span class="op">+</span> lstm_cell.bias_ih <span class="op">+</span> lstm_cell.bias_hh</span></code></pre></div>
<p><strong>(step2)</strong> decompose <span class="math inline">\({\tt ifgo}\)</span> and get <span class="math inline">\({\boldsymbol i}_t\)</span>, <span class="math inline">\({\boldsymbol f}_t\)</span>, <span class="math inline">\({\boldsymbol g}_t\)</span>, <span class="math inline">\({\boldsymbol o}_t\)</span></p>
<p><span class="math inline">\({\boldsymbol i}_t = \sigma({\boldsymbol x}_t {\bf W}_{ii} + {\boldsymbol h}_{t-1} {\bf W}_{hi} +bias )\)</span></p>
<p><span class="math inline">\({\boldsymbol f}_t = \sigma({\boldsymbol x}_t {\bf W}_{if} + {\boldsymbol h}_{t-1} {\bf W}_{hf} +bias )\)</span></p>
<p><span class="math inline">\({\boldsymbol g}_t = \tanh({\boldsymbol x}_t {\bf W}_{ig} + {\boldsymbol h}_{t-1} {\bf W}_{hg} +bias )\)</span></p>
<p><span class="math inline">\({\boldsymbol o}_t = \sigma({\boldsymbol x}_t {\bf W}_{io} + {\boldsymbol h}_{t-1} {\bf W}_{ho} +bias )\)</span></p>
<p><strong>(step3)</strong> calculate <span class="math inline">\({\boldsymbol c}_t\)</span> and <span class="math inline">\({\boldsymbol h}_t\)</span></p>
<p><span class="math inline">\({\boldsymbol c}_t = {\boldsymbol i}_t \odot {\boldsymbol g}_t+ {\boldsymbol f}_t \odot {\boldsymbol c}_{t-1}\)</span></p>
<p><span class="math inline">\({\boldsymbol h}_t = \tanh({\boldsymbol o}_t \odot {\boldsymbol c}_t)\)</span></p>
</section>
<section id="lstm의-알고리즘-리뷰-ii-느낌위주" class="level3">
<h3 class="anchored" data-anchor-id="lstm의-알고리즘-리뷰-ii-느낌위주">LSTM의 알고리즘 리뷰 II (느낌위주)</h3>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ } \triangleleft \text{ }\underrightarrow{sig} \text{ }o_t\)</span></p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ }\circ \text{ , } \square \text{, } \star \text{, } \triangleleft \text{ } \to \sigma(circ) \text{, }\sigma(\square) \text{ , }\tanh(\star)\text{ , } \sigma(\triangleleft) \sim i_t, f_t, g_t, o_t\)</span></p>
<ul>
<li>이해 및 암기를 돕기위해서 비유적으로 설명한 챕터입니다..</li>
</ul>
<p><code>-</code> 느낌1: RNN이 콩물에서 간장을 한번에 숙성시키는 방법이라면 LSTM은 콩물에서 간장을 3차로 나누어 숙성하는 느낌이다.</p>
<ul>
<li>콩물: <span class="math inline">\({\boldsymbol x}_t\)</span></li>
<li>1차숙성: <span class="math inline">\({\boldsymbol g}_t\)</span></li>
<li>2차숙성: <span class="math inline">\({\boldsymbol c}_t\)</span></li>
<li>3차숙성: <span class="math inline">\({\boldsymbol h}_t\)</span></li>
</ul>
<p><code>-</code> 느낌2: <span class="math inline">\({\boldsymbol g}_t\)</span>에 대하여</p>
<ul>
<li>계산방법: <span class="math inline">\({\boldsymbol x}_t\)</span>와 <span class="math inline">\({\boldsymbol h}_{t-1}\)</span>를 <span class="math inline">\({\bf W}_{ig}, {\bf W}_{hg}\)</span>를 이용해 선형결합하고 <span class="math inline">\(\tanh\)</span>를 취한 결과</li>
<li>RNN에서 간장을 만들던 그 수식에서 <span class="math inline">\(h_t\)</span>를 <span class="math inline">\(g_t\)</span>로 바꾼것</li>
<li>크게 2가지의 의미를 가진다 (1) 과거와 현재의 결합 (2) 활성화함수 <span class="math inline">\(\tanh\)</span>를 적용</li>
</ul>
<p>(서연 필기)</p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ }\circ \text{ }\underrightarrow{sig} \text{ }i_t\)</span></p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ }\square \text{ } \underrightarrow{sig} \text{ }f_t\)</span></p>
<p><span class="math inline">\(x_t, h_{t-1} \underrightarrow{lin} \text{ }\star \text{ } \underrightarrow{tanh} \text{ }g_t\)</span></p>
<p>를 풀어서 쓰면</p>
<p><span class="math inline">\(\tanh(x_t W_{ig} + h_{t-1} W_{hg} + bias)\)</span></p>
<p>RNN: <span class="math inline">\(h_t = \tanh(x_t W + h_{t-1} W + bias)\)</span></p>
<p>LSTM: <span class="math inline">\(g_t = \tanh(x_t W + h_{t-1} W + bias)\)</span> - 과거<span class="math inline">\(h_{t-1}\)</span>와 현재<span class="math inline">\(x_t\)</span>의 결합</p>
<p><code>-</code> 느낌3: <span class="math inline">\({\boldsymbol c}_t\)</span>에 대하여 (1)</p>
<ul>
<li>계산방법: <span class="math inline">\({\boldsymbol g}_{t}\)</span>와 <span class="math inline">\({\boldsymbol c}_{t-1}\)</span>를 요소별로 선택하고 더하는 과정</li>
<li><span class="math inline">\(g_t\)</span>는 (1) 과거와 현재의 결합 (2) 활성화함수 tanh를 적용으로 나누어지는데 이중에서 (1) 과거와 현재의 정보를 결합하는 과정만 해당한다. 차이점은 요소별 선택 후 덧셈
<ul>
<li><span class="math inline">\(g_t\)</span>는 선형 결합</li>
</ul></li>
<li>이러한 결합을 쓰는 이유? 게이트를 이용하여 과거와 현재의 정보를 제어 (일반적인 설명, 솔직히 내가 좋아하는 설명은 아님)</li>
</ul>
<p>(서연 필기)</p>
<p><span class="math inline">\(c_t = g_t \odot Input + c_{t-1} \odot Forget\)</span></p>
<p><code>-</code> 느낌4: <span class="math inline">\({\boldsymbol c}_t\)</span>에 대하여 (2) // <span class="math inline">\({\boldsymbol c}_t\)</span>는 왜 과거와 현재의 정보를 제어한다고 볼 수 있는가?</p>
<p><span class="math inline">\(t=1\)</span> 시점 계산과정관찰</p>
<div id="44a73c0b-bc72-4c57-babe-fec6c3de45f7" class="cell" data-execution_count="98">
<div class="sourceCode cell-code" id="cb220"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb220-1"><a href="#cb220-1" aria-hidden="true" tabindex="-1"></a>input_gate[<span class="dv">1</span>],g[<span class="dv">1</span>],forget_gate[<span class="dv">1</span>],cell[<span class="dv">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="98">
<pre><code>(tensor([0.9065, 0.9999], grad_fn=&lt;SelectBackward0&gt;),
 tensor([0.9931, 0.9999], grad_fn=&lt;SelectBackward0&gt;),
 tensor([0.9931, 0.0014], grad_fn=&lt;SelectBackward0&gt;),
 tensor([ 0.3592, -0.9373], grad_fn=&lt;SelectBackward0&gt;))</code></pre>
</div>
</div>
<p><span class="math inline">\([0.9,1.0] \odot {\boldsymbol g}_t + [1.0,0.0] \odot {\boldsymbol c}_{t-1}\)</span></p>
<p>(서연 필기)</p>
<p>여기서 곱은 element별 곱 - <span class="math inline">\([0.9,1.0] \odot g_t = [0.9,1.0]\odot [g_1,g_2] = [0.9g_1(현재)_,1.0g_2(과거)]\)</span> - 여기서 0이 현재에 곱해지면 현재를 기억하지 않고 과거에 0이 곱해지면 과거를 기억하지 않도록 조정할 수 있음</p>
<p><span class="math inline">\(\star\)</span> gate없으면 조정 못 하나??<span class="math inline">\(\to\)</span> no, weigjht로도 조정할 수 있지 않을까?</p>
<ul>
<li>forget_gate는 <span class="math inline">\(c_{t-1}\)</span>의 첫번째 원소는 기억하고, 두번째 원소는 잊으라고 말하고 있음 // forget_gate는 과거(<span class="math inline">\(c_{t-1}\)</span>)의 정보를 얼마나 잊을지 (= 얼마나 기억할지) 를 결정한다고 해석할 수 있다.</li>
<li>input_gate는 <span class="math inline">\(g_{t}\)</span>의 첫번째 원소와 두번째 원소를 모두 기억하되 두번째 원소를 좀 더 중요하게 기억하라고 말하고 있음 // input_gate는 현재(<span class="math inline">\(g_{t}\)</span>)의 정보를 얼만큼 강하게 반영할지 결정한다.</li>
<li>이 둘을 조합하면 <span class="math inline">\({\boldsymbol c}_t\)</span>가 현재와 과거의 정보중 어떠한 정보를 더 중시하면서 기억할지 결정한다고 볼 수 있다.</li>
</ul>
<blockquote class="blockquote">
<p>이 설명은 제가 좀 싫어해요, 싫어하는 이유는 (1) “기억의 정도를 조절한다”와 “망각의 정도를 조절한다”는 사실 같은말임. 그래서 forget_gate의 용어가 모호함. (2) 기억과 망각을 조정하는 방식으로 꼭 gate의 개념을 사용해야 하는건 아님</p>
</blockquote>
<p><code>-</code> 느낌5: <span class="math inline">\({\boldsymbol c}_t\)</span>에 대하여 (3)</p>
<ul>
<li>사실상 LSTM 알고리즘의 꽃이라 할 수 있음.</li>
<li>LSTM은 long short term memory의 약자임. 기존의 RNN은 장기기억을 활용함에 약점이 있는데 LSTM은 단기기억/장기기억 모두 잘 활용함.</li>
<li>LSTM이 장기기억을 잘 활용하는 비법은 바로 <span class="math inline">\({\boldsymbol c}_t\)</span>에 있다.</li>
</ul>
<p>(서연필기) <span class="math inline">\(c_t\)</span>로 과거, 현재 기억 조절할 수 있기 때문에</p>
<p><code>-</code> 느낌6: <span class="math inline">\({\boldsymbol h}_t\)</span>에 대하여 - 계산방법: <span class="math inline">\(\tanh({\boldsymbol c}_t)\)</span>를 요소별로 선택</p>
<p>데이터 다 가져와서 선택하는 방식</p>
<p><code>-</code> RNN, LSTM의 변수들 비교 테이블</p>
<table class="table">
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">과거정보</th>
<th style="text-align: center;">현재정보</th>
<th style="text-align: center;">과거와 현재의 결합방식</th>
<th style="text-align: center;">활성화</th>
<th style="text-align: center;">느낌</th>
<th style="text-align: center;">비고</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">RNN-<span class="math inline">\({\boldsymbol h}_t\)</span></td>
<td style="text-align: center;"><span class="math inline">\({\boldsymbol h}_{t-1}\)</span></td>
<td style="text-align: center;"><span class="math inline">\({\boldsymbol x}_t\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\times\)</span> W <span class="math inline">\(\to\)</span> <span class="math inline">\(+\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\tanh\)</span></td>
<td style="text-align: center;">간장</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">LSTM-<span class="math inline">\({\boldsymbol g}_t\)</span></td>
<td style="text-align: center;"><span class="math inline">\({\boldsymbol h}_{t-1}\)</span></td>
<td style="text-align: center;"><span class="math inline">\({\boldsymbol x}_t\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\times\)</span>W <span class="math inline">\(\to\)</span> <span class="math inline">\(+\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\tanh\)</span></td>
<td style="text-align: center;">1차간장</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">LSTM-<span class="math inline">\({\boldsymbol c}_t\)</span></td>
<td style="text-align: center;"><span class="math inline">\({\boldsymbol c}_{t-1}\)</span></td>
<td style="text-align: center;"><span class="math inline">\({\boldsymbol g}_t\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\odot\)</span> W<span class="math inline">\(\to\)</span> <span class="math inline">\(+\)</span></td>
<td style="text-align: center;">None</td>
<td style="text-align: center;">2차간장</td>
<td style="text-align: center;">gate를 열림정도를 판단할때 <span class="math inline">\({\boldsymbol x}_t\)</span>와 <span class="math inline">\({\boldsymbol h}_{t-1}\)</span>을 이용</td>
</tr>
<tr class="odd">
<td style="text-align: center;">LSTM-<span class="math inline">\({\boldsymbol h}_t\)</span></td>
<td style="text-align: center;">None</td>
<td style="text-align: center;"><span class="math inline">\({\boldsymbol c}_t\)</span></td>
<td style="text-align: center;">None</td>
<td style="text-align: center;"><span class="math inline">\(\tanh\)</span>, <span class="math inline">\(\odot\)</span></td>
<td style="text-align: center;">3차간장</td>
<td style="text-align: center;">gate를 열림정도를 판단할때 <span class="math inline">\({\boldsymbol x}_t\)</span>와 <span class="math inline">\({\boldsymbol h}_{t-1}\)</span>을 이용</td>
</tr>
</tbody>
</table>
<ul>
<li>RNN은 기억할 과거정보가 <span class="math inline">\({\boldsymbol h}_{t-1}\)</span> 하나이지만 LSTM은 <span class="math inline">\({\boldsymbol c}_{t-1}\)</span>, <span class="math inline">\({\boldsymbol h}_{t-1}\)</span> 2개이다.</li>
</ul>
<p><code>-</code> 알고리즘리뷰 :</p>
<ul>
<li>콩물<span class="math inline">\(x_t\)</span>,과거3차간장<span class="math inline">\(h_{t-1}\)</span> <span class="math inline">\(\overset{\times,+,\tanh}{\longrightarrow}\)</span> 현재1차간장<span class="math inline">\(g_t\)</span></li>
<li>현재1차간장<span class="math inline">\(c_{t-1}\)</span>, 과거2차간장 <span class="math inline">\(\overset{\odot,+,\tanh}{\longrightarrow}\)</span> 현재2차간장</li>
<li>현재2차간장<span class="math inline">\(c_t\)</span> <span class="math inline">\(\overset{\tanh,\odot}{\longrightarrow}\)</span> 현재3차간장<span class="math inline">\(h_t\)</span></li>
</ul>
</section>
<section id="lstm이-강한이유" class="level3">
<h3 class="anchored" data-anchor-id="lstm이-강한이유">LSTM이 강한이유</h3>
<p><code>-</code> LSTM이 장기기억에 유리함. 그 이유는 input, forget, output gate 들이 과거기억을 위한 역할을 하기 때문.</p>
<ul>
<li>비판: 아키텍처에 대한 이론적 근거는 없음. 장기기억을 위하여 꼭 LSTM같은 구조일 필요는 없음. (왜 3차간장을 만들때 tanh를 써야하는지? 게이트는 꼭3개이어야 하는지?)</li>
</ul>
<p><code>-</code> 저는 사실 아까 살펴본 아래의 이유로 이해하고 있습니다.</p>
<ul>
<li>실험적으로 살펴보니 LSTM이 RNN보다 장기기억에 유리했음.</li>
<li>그 이유: RRN은 <span class="math inline">\({\boldsymbol h}_t\)</span>의 값이 -1 혹은 1로 결정되는 경우가 많았음. 그러나 경우에 따라서는 <span class="math inline">\({\boldsymbol h}_t\)</span>이 -1~1의 값을 가지는 것이 문맥적 뉘앙스를 포착하기에는 유리한데 LSTM이 이러한 방식으로 학습되는 경우가 많았음.</li>
<li>왜 LSTM의 <span class="math inline">\({\boldsymbol h}_t\)</span>은 -1,1 이외의 값을 쉽게 가질 수 있는가? (1) gate들의 역할 (2) 마지막에 취해지는 tanh 때문</li>
</ul>
<p>문잭적으로 이해 -&gt;유리하다 칭함</p>
</section>
</section>
<section id="참고자료들" class="level2">
<h2 class="anchored" data-anchor-id="참고자료들">참고자료들</h2>
<ul>
<li><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" class="uri">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></li>
<li><a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html" class="uri">https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html</a></li>
<li><a href="https://arxiv.org/abs/1402.1128" class="uri">https://arxiv.org/abs/1402.1128</a></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="seoyeonc/md" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->




</body></html>