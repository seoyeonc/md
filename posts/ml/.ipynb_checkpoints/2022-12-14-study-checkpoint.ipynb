{
 "cells": [
  {
   "cell_type": "raw",
   "id": "eedfb6e5-8840-49c7-8dcb-63eb6f4d65e8",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"study\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2022-12-08\"\n",
    "categories:\n",
    "  - Special Topics in Machine Learning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fab262-9beb-49db-926a-f8797d5be691",
   "metadata": {},
   "source": [
    "> study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a96385-9b4b-4a8a-9fbb-4b7036564cca",
   "metadata": {},
   "source": [
    "# a,b,c,d,e 를 표현함에 있어서 3개의 은닉노드면 충분하다. \n",
    "- 1개의 은닉노드 -> 2개의 문자를 표현할 수 있음. \n",
    "- 2개의 은닉노드 -> 4개의 문자를 표현할 수 있음. \n",
    "- 3개의 은닉노드 -> 8개의 문자를 표현할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5bc620-6d7e-448d-a802-33b7b2af97b3",
   "metadata": {},
   "source": [
    "# torch.nn.RNN(4,2)는 torch.nn.RNNCell(4,2)의 batch 버전이다. \n",
    "\n",
    "(for문이 포함된 버전이다)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a0277e-096c-4c2f-8fec-4d45807d5c13",
   "metadata": {},
   "source": [
    "# torch.nn.LSTM에서 batch size\n",
    "\n",
    " batch size = 전체데이터는 몇 개의 시계열이 있는지 = 전체 데이터를 몇개의 시계열로 쪼갤지\n",
    " \n",
    " - fastai, Dataloader의 batchsize 는 한 뭉치에 몇 개 있는지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fbdcdd-5802-45b5-b9cc-faf552a7d995",
   "metadata": {},
   "source": [
    "# 원래 1은 단순히 observation의 차원이 아니다. 즉 $x_{n \\times p}$ 에서 $n$에 대응하는 차원으로 생각할 수 없다.\n",
    "\n",
    "- 그런데 (1) 단방향 (2) 조각내지 않은 시계열 (3) 중첩하지 않은 순환망에 한정하여서는 observation 처럼 생각해도 무방하다.\n",
    "\n",
    "- 현실적으로 (1)-(3)이 아닌 조건에서는 Cell 단위로 연산을 이용할 일이 없다. (느리거든요) // 그냥 이해용으로 구현\n",
    "\n",
    "- torch.nn.RNN 혹은 torch.nn.LSTM 으로 네트워크를 구성할시 _water의 dim을 명시할 일도 없다.\n",
    "\n",
    "- 오로지 고려해야 할 것은 입력시계열을 조각낼지 조각내지 않을지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed350a3-3b24-4f46-8b09-4d932c070f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "146b03a8-7847-4be7-9c55-ebf217af2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = torch.nn.Sigmoid()\n",
    "soft = torch.nn.Softmax(dim=1)\n",
    "tanh = torch.nn.Tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4444e97-576d-4ec3-bb38-01283de440d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(txt,mapping):\n",
    "    return [mapping[key] for key in txt] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fb33ede-92a6-4f3f-970a-c0a57e43533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = list('ab')*100\n",
    "txt_x = txt[:-1]\n",
    "txt_y = txt[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9203df12-bd96-4193-aa9a-17dc676d3d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'a':[1,0],'b':[0,1]}\n",
    "x = torch.tensor(f(txt_x,mapping)).float().reshape(-1,2)\n",
    "y = torch.tensor(f(txt_y,mapping)).float().reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a75d95b-cfed-46dc-a30f-ee45ae11b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mynet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ## 우리가 사용할 레이어를 정의 \n",
    "        self.l1 = torch.nn.Linear(in_features=2,out_features=1,bias=True)\n",
    "        self.a1 = torch.nn.Tanh()\n",
    "        self.l2 = torch.nn.Linear(in_features=1,out_features=2,bias=False)\n",
    "        ## 레이어 정의 끝\n",
    "    def forward(self,x):\n",
    "        ## yhat을 어떻게 구할것인지 정의 \n",
    "        yhat = self.l2(self.a1(self.l1(x)))\n",
    "        ## 정의 끝\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6e23f25-a66b-4358-8b3c-cf7d6c7ada75",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mynet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a114826a-065c-4f1c-b0d7-93638b2acc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c26bb2d-5d45-40f5-967e-9e0b9bf07551",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoc in range(5000):\n",
    "    yhat = net(x)\n",
    "    loss = loss_fn(yhat,y)\n",
    "    loss.backward()\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5354340f-9773-4693-99a0-fd329845dd71",
   "metadata": {},
   "source": [
    "## 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02048300-2ff2-49d7-9a19-06b2762fc71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 0, 1, 0]), tensor([1, 0, 1, 0, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {'a':0,'b':1}\n",
    "x = torch.tensor(f(txt_x,mapping))\n",
    "y = torch.tensor(f(txt_y,mapping))\n",
    "x[:5],y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc5f457e-b4f8-422b-b1af-7de5b35853c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mynet2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ## 우리가 사용할 레이어를 정의 \n",
    "        self.l1 = torch.nn.Embedding(num_embeddings=2,embedding_dim=1)\n",
    "        self.a1 = torch.nn.Tanh()\n",
    "        self.l2 = torch.nn.Linear(in_features=1,out_features=2)\n",
    "        ## 레이어 정의 끝\n",
    "    def forward(self,x):\n",
    "        ## yhat을 어떻게 구할것인지 정의 \n",
    "        yhat = self.l2(self.a1(self.l1(x)))\n",
    "        ## 정의 끝\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e8b5b2f-37f0-4a31-b242-f70c7be07ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mynet2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4146115f-fc77-41e9-8a2e-12e50815bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d982ca7-c9c1-44eb-b20f-7fb16645bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoc in range(5000):\n",
    "    yhat = net(x)\n",
    "    loss = loss_fn(yhat,y)\n",
    "    loss.backward()\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba716ad9-828d-463e-bc47-fb0bab93f6cc",
   "metadata": {},
   "source": [
    "## 두 개의 은닉노드 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6750eff3-3957-4b2e-ae90-9b97fd8a656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = list('abcd')*100\n",
    "txt_x = txt[:-1]\n",
    "txt_y = txt[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a595c890-4b47-4919-9e09-f06b684b8404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 0]), tensor([1, 2, 3, 0, 1]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {'a':0,'b':1,'c':2,'d':3}\n",
    "x = torch.tensor(f(txt_x,mapping))\n",
    "y = torch.tensor(f(txt_y,mapping))\n",
    "x[:5],y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bef382fc-4458-4036-b273-4cb428fa07c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=torch.nn.Embedding(num_embeddings=4,embedding_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aeb54070-36ae-484e-b4e3-ff4fb5adede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = torch.nn.Tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "404dd0e4-c67d-43ac-977c-19ba8e0978b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = torch.nn.Linear(in_features=2,out_features=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ca48e0c-887a-4eb1-8be7-986d6cf97cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    l1,a1,l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af9b4ed8-7bd9-4631-9b9f-4bdc79739572",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dafc316-27c4-429f-bba4-1d1ea3d8cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoc in range(5000):\n",
    "    yhat=net(x)\n",
    "    loss = loss_fn(yhat,y)\n",
    "    loss.backward()\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55575dae-6bae-4150-828d-5cfb4d7502e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = net[:-1](x).data\n",
    "yhat = soft(net(x)).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e043e863-68d1-451e-9e98-4d22b3170cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Embedding(4, 2)\n",
       "  (1): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319cbf87-f135-428b-98f7-8651bea429bc",
   "metadata": {},
   "source": [
    "결과 시각화 코드 10주"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc31f3f-e11f-4636-b541-0fc790cbb161",
   "metadata": {},
   "source": [
    "## 순환신경망 Class 사용 RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386ad318-305d-49ce-94a1-4a5cb7a7e225",
   "metadata": {},
   "source": [
    "10주"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "940a3851-e94a-4947-875f-3ffcc9aa2d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = list('AbAcAd')*100\n",
    "txt_x = txt[:-1]\n",
    "txt_y = txt[1:]\n",
    "x = torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))\n",
    "y = torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))\n",
    "x= torch.nn.functional.one_hot(x).float()\n",
    "y= torch.nn.functional.one_hot(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9b925f7-2dc6-4c0a-b55c-103c71dbed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rNNCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.i2h = torch.nn.Linear(4,2) \n",
    "        self.h2h = torch.nn.Linear(2,2) \n",
    "        self.tanh = torch.nn.Tanh()\n",
    "    def forward(self,x,hidden):\n",
    "        hidden = self.tanh(self.i2h(x)+self.h2h(hidden))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e575357-dafb-4e96-aabf-4467318f5b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43052)\n",
    "rnncell = rNNCell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "417b7245-f31e-4b69-917b-6bc67b19e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43052)\n",
    "cook = torch.nn.Linear(2,4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c33f594-6aef-4e68-973f-ea2996a0fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss() \n",
    "optimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56f07469-fa54-4024-8716-7c0ffe2a2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = len(x) \n",
    "for epoc in range(100): \n",
    "    ## 1~2\n",
    "    loss = 0 \n",
    "    ht = torch.zeros(1,2) \n",
    "    for t in range(T):\n",
    "        xt,yt = x[[t]], y[[t]]\n",
    "        ht = rnncell(xt,ht) \n",
    "        ot = cook(ht) \n",
    "        loss = loss + loss_fn(ot,yt) \n",
    "    ## 3 \n",
    "    loss.backward()\n",
    "    ## 4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55ea51d-6534-43b7-a6e9-84e19ecc7efd",
   "metadata": {},
   "source": [
    "시각화코드는 10주_순환신경망구현1-성공에"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda5a489-1753-41f5-938a-9dbeebfb7cee",
   "metadata": {},
   "source": [
    "## 순환신경망 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7185df05-b142-49c5-af1d-93753c3cdc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = list('AbAcAd')*100\n",
    "txt_x = txt[:-1]\n",
    "txt_y = txt[1:]\n",
    "x = torch.nn.functional.one_hot(torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))).float()\n",
    "y = torch.nn.functional.one_hot(torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e503c10-3314-4d61-a07d-119f3ecf970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2) #1 \n",
    "rnn = torch.nn.RNN(4,3).to(\"cuda:0\") \n",
    "cook = torch.nn.Linear(3,4).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd203254-cfec-4a71-a44c-50be9768b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01b1980c-f3b6-4541-8715-84bc9e631a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_water = torch.zeros(1,3).to(\"cuda:0\") \n",
    "for epoc in range(500):\n",
    "    ## 1\n",
    "    hidden,hT = rnn(x.to(\"cuda:0\"),_water) \n",
    "    output = cook(hidden) \n",
    "    ## 2 \n",
    "    loss = loss_fn(output,y.to(\"cuda:0\")) \n",
    "    ## 3 \n",
    "    loss.backward()\n",
    "    ## 4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2fc1534-2479-4a5f-93d6-aedc02715c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = soft(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f98dc1-f627-4708-abde-796ed6a37575",
   "metadata": {},
   "source": [
    "## 순환신경망 Class 사용 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7641d5ec-84a7-4449-b2f3-8fb35dfb9f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = list('hi?hello!!')*100 \n",
    "txt_x = txt[:-1]\n",
    "txt_y = txt[1:]\n",
    "mapping = {'!':0, '?':1,'h':2,'i':3,'e':4,'l':5,'o':6} \n",
    "x= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\n",
    "y= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc657cc3-158a-4b9b-a2d5-feab87c8a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lSTMCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.i2h = torch.nn.Linear(7,16)\n",
    "        self.h2h = torch.nn.Linear(4,16) \n",
    "        self.tanh = torch.nn.Tanh()\n",
    "    def forward(self,xt,past):\n",
    "        ht,ct = past \n",
    "        ifgo = self.i2h(xt) + self.h2h(ht) \n",
    "        it = sig(ifgo[0:4])\n",
    "        ft = sig(ifgo[4:8])\n",
    "        gt = tanh(ifgo[8:12])\n",
    "        ot = sig(ifgo[12:16])\n",
    "        ct = ft*ct + it*gt\n",
    "        ht = ot*self.tanh(ct) \n",
    "        return ht,ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "647d6137-976d-4882-8b54-ab9214f19d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmcell = lSTMCell().to(\"cuda:0\")\n",
    "linr = torch.nn.Linear(4,7).to(\"cuda:0\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(list(lstmcell.parameters())+list(linr.parameters()),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d04170c8-5b0d-4f9c-9ae7-2b815327b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기값셋팅\n",
    "torch.manual_seed(43052) \n",
    "_lstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\")\n",
    "_linr = torch.nn.Linear(4,7).to(\"cuda:0\")\n",
    "lstmcell.i2h.weight.data = _lstmcell.weight_ih.data \n",
    "lstmcell.h2h.weight.data = _lstmcell.weight_hh.data \n",
    "lstmcell.i2h.bias.data = _lstmcell.bias_ih.data\n",
    "lstmcell.h2h.bias.data = _lstmcell.bias_hh.data\n",
    "linr.weight.data = _linr.weight.data \n",
    "linr.bias.data = _linr.bias.data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02012f71-dedd-4450-ad85-fcd42fa5e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoc in range(10):\n",
    "    ## 1\n",
    "    hidden = []     \n",
    "    ht = torch.zeros(4).to(\"cuda:0\")\n",
    "    ct = torch.zeros(4).to(\"cuda:0\")\n",
    "    for xt,yt in zip(x,y): \n",
    "        ht,ct = lstmcell(xt,(ht,ct))\n",
    "        hidden.append(ht) \n",
    "    hidden = torch.stack(hidden)\n",
    "    output = linr(hidden) \n",
    "    ## 2 \n",
    "    loss = loss_fn(output,y)\n",
    "    ## 3 \n",
    "    loss.backward()\n",
    "    ## 4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "feeccbf6-6025-4162-ac5a-a2ff03e27ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = soft(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc2d93d6-394d-492b-8afc-2616d1917452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0909, 0.0859, 0.0356,  ..., 0.1820, 0.2308, 0.1257],\n",
       "        [0.3443, 0.1629, 0.2108,  ..., 0.1008, 0.0506, 0.0774],\n",
       "        [0.3998, 0.0325, 0.5100,  ..., 0.0133, 0.0269, 0.0119],\n",
       "        ...,\n",
       "        [0.0655, 0.0525, 0.0455,  ..., 0.1652, 0.2569, 0.2828],\n",
       "        [0.3850, 0.0844, 0.3754,  ..., 0.0464, 0.0423, 0.0478],\n",
       "        [0.4012, 0.0217, 0.5328,  ..., 0.0084, 0.0254, 0.0065]],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199dc3a5-4de0-40e2-88e6-dc9f65df4827",
   "metadata": {},
   "source": [
    "## 순환신경망 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ab09ce9-4277-4bdc-aada-9edaa5eaefcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = (['one',',','two',',','three',',','four',',','five',',']*100)[:-1]\n",
    "mapping = {',':0, 'one':1, 'two':2, 'three':3, 'four':4, 'five':5} \n",
    "txt_x = txt[:-1]\n",
    "txt_y = txt[1:] \n",
    "x = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\n",
    "y = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c94d7f4c-d938-47cc-a616-271298425e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43052) \n",
    "lstm = torch.nn.LSTM(6,20).to(\"cuda:0\") \n",
    "linr = torch.nn.Linear(20,6).to(\"cuda:0\") \n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "809e310a-b4e0-4b9f-a7db-1e60c74d712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_water = torch.zeros(1,20).to(\"cuda:0\")\n",
    "for epoc in range(50):\n",
    "    ## 1 \n",
    "    hidden, (hT,cT) =lstm(x,(_water,_water))\n",
    "    output = linr(hidden) \n",
    "    ## 2 \n",
    "    loss = loss_fn(output,y) \n",
    "    ## 3 \n",
    "    loss.backward()\n",
    "    ## 4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5135956-d1e8-49e1-bbec-d0621a06c390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9875e-01, 1.5434e-06, 6.5715e-04, 1.8973e-05, 9.5753e-05, 4.7651e-04],\n",
       "        [3.0184e-06, 3.7971e-05, 9.8694e-01, 3.6741e-03, 3.6129e-04, 8.9867e-03],\n",
       "        [9.9999e-01, 2.9932e-06, 5.9745e-07, 8.3266e-06, 1.0668e-07, 4.8888e-07],\n",
       "        ...,\n",
       "        [3.9604e-05, 8.6161e-06, 1.5918e-03, 1.1244e-07, 9.9808e-01, 2.7556e-04],\n",
       "        [9.9993e-01, 3.3252e-07, 9.5155e-06, 4.8129e-07, 2.7274e-05, 3.2102e-05],\n",
       "        [8.0918e-07, 8.0716e-03, 5.9763e-04, 7.7044e-05, 6.8931e-05, 9.9118e-01]],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc7b70e-70de-453e-9a38-b0949c36b3b7",
   "metadata": {},
   "source": [
    "### 조각난 시계열"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07a0ea1-d718-45df-a01b-bce352dde79e",
   "metadata": {},
   "source": [
    "12주차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9a082a74-1ef5-435d-ac3f-e13e96a8d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = list('hi!')*3 + list('hi?')*3\n",
    "txt_x = txt[:-1] \n",
    "txt_y = txt[1:] \n",
    "mapping = {'!':0, '?':1, 'h':2, 'i':3} \n",
    "x = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\n",
    "y = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9c3fefca-06cc-4ca6-9ac0-c4529585fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43052) \n",
    "lstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\n",
    "linr = torch.nn.Linear(10,4).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f051b2ad-ce86-4e41-822c-4758594dfe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss() \n",
    "optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "60c23932-b0a2-4f28-93f1-b972e19e0963",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoc in range(100):\n",
    "    ## 1 \n",
    "    hidden, _ = lstm(x) \n",
    "    output = linr(hidden) \n",
    "    ## 2 \n",
    "    loss = loss_fn(output,y) \n",
    "    ## 3 \n",
    "    loss.backward() \n",
    "    ## 4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c68be896-7c52-460d-a972-9bdac274253b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1462eb7510>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden, _ = lstm(x)\n",
    "plt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "20ad105a-a951-42ca-a730-5d209dafb8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = list('hi!')*3 + list('hi?')*3\n",
    "txt1= txt[:9]\n",
    "txt2= txt[9:]\n",
    "txt1_x = txt1[:-1] \n",
    "txt1_y = txt1[1:] \n",
    "txt2_x = txt2[:-1] \n",
    "txt2_y = txt2[1:] \n",
    "mapping = {'!':0, '?':1, 'h':2, 'i':3} \n",
    "x1 = torch.nn.functional.one_hot(torch.tensor(f(txt1_x,mapping))).float().to(\"cuda:0\")\n",
    "y1 = torch.nn.functional.one_hot(torch.tensor(f(txt1_y,mapping))).float().to(\"cuda:0\")\n",
    "x2 = torch.nn.functional.one_hot(torch.tensor(f(txt2_x,mapping))).float().to(\"cuda:0\")\n",
    "y2 = torch.nn.functional.one_hot(torch.tensor(f(txt2_y,mapping))).float().to(\"cuda:0\")\n",
    "xx = torch.stack([x1,x2],axis=1)\n",
    "yy = torch.stack([y1,y2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fe103fad-9474-4d38-b113-b239cabc1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43052) \n",
    "lstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\n",
    "linr = torch.nn.Linear(10,4).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2f380908-eaa5-46dd-81ce-1d3546983bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss() \n",
    "optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f7179b88-2bd9-4d98-906e-67c3d0d9a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoc in range(100):\n",
    "    ## 1 \n",
    "    hidden, _ = lstm(xx) \n",
    "    output = linr(hidden) \n",
    "    ## 2 \n",
    "    loss = loss_fn(output[:,0,:],yy[:,0,:]) + loss_fn(output[:,1,:],yy[:,1,:])\n",
    "    ## 3 \n",
    "    loss.backward() \n",
    "    ## 4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cd994fc6-c625-42a8-8a41-0b3b88c3ac50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1462e93690>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig , ax = plt.subplots(1,2) \n",
    "ax[0].matshow(soft(output[:,0,:]).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n",
    "ax[1].matshow(soft(output[:,1,:]).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
