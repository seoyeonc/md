<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="SEOYEON CHOI">
<meta name="dcterms.date" content="2022-10-26">

<title>Seoyeon’s Blog for classes - CNN (8주차) 2</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Seoyeon’s Blog for classes</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../about.html" aria-current="page">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/seoyeonc/md"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">CNN (8주차) 2</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title d-none d-lg-block">CNN (8주차) 2</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Special Topics in Machine Learning</div>
                <div class="quarto-category">이미지자료분석</div>
                <div class="quarto-category">Transfer Learning</div>
                <div class="quarto-category">CAM</div>
                <div class="quarto-category">XAI</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>SEOYEON CHOI </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 26, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../about.html" class="sidebar-item-text sidebar-link">About</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Posts</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/rl/index.html" class="sidebar-item-text sidebar-link">Advanced Regression Analysis</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-09-21-rl_HW1.html" class="sidebar-item-text sidebar-link">Regression HW 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-10-23-rl-HW2.html" class="sidebar-item-text sidebar-link">Regression HW 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-21-rl-HW3.html" class="sidebar-item-text sidebar-link">Regression HW 3</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-09-21-rl_CH03, CH04.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH03, CH04</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-14-rl_CH06, CH07.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH06, CH07</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/rl/2022-11-28-rl-CH13.html" class="sidebar-item-text sidebar-link">고급회귀분석 실습 CH13</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/ml/index.html" class="sidebar-item-text sidebar-link">Special Topics in Machine Learning</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-19-Assignment-1-Copy1.html" class="sidebar-item-text sidebar-link">Assignment 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-19-ml_7w.html" class="sidebar-item-text sidebar-link">CNN (7주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-26-ml_8w_1.html" class="sidebar-item-text sidebar-link">CNN (8주차) 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-26-ml_8w_2.html" class="sidebar-item-text sidebar-link active">CNN (8주차) 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-29-13wk-2-final.html" class="sidebar-item-text sidebar-link">Deep Learning final example</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-07-ml_1w.html" class="sidebar-item-text sidebar-link">DNN (1주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-14-ml_2w.html" class="sidebar-item-text sidebar-link">DNN (2주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-21-ml_3w.html" class="sidebar-item-text sidebar-link">DNN (3주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-29-ml_4w.html" class="sidebar-item-text sidebar-link">DNN (4주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-05-ml-5w.html" class="sidebar-item-text sidebar-link">DNN (5주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-12-ml-6w.html" class="sidebar-item-text sidebar-link">DNN (6주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-10-05-ml-HW.html" class="sidebar-item-text sidebar-link">Homework</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-09-07-ml.html" class="sidebar-item-text sidebar-link">Intro</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-02-ml-midterm.html" class="sidebar-item-text sidebar-link">Midterm</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-09-ml-10w.html" class="sidebar-item-text sidebar-link">RNN (10주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-21-ml-11w.html" class="sidebar-item-text sidebar-link">RNN (11주차)</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ml/2022-11-02-ml_9w.html" class="sidebar-item-text sidebar-link">RNN (9주차)</a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#imports" id="toc-imports" class="nav-link active" data-scroll-target="#imports">imports</a></li>
  <li><a href="#transfer-learning" id="toc-transfer-learning" class="nav-link" data-scroll-target="#transfer-learning">Transfer Learning</a>
  <ul class="collapse">
  <li><a href="#수제네트워크" id="toc-수제네트워크" class="nav-link" data-scroll-target="#수제네트워크">수제네트워크</a></li>
  <li><a href="#전이학습-남이-만든-네트워크" id="toc-전이학습-남이-만든-네트워크" class="nav-link" data-scroll-target="#전이학습-남이-만든-네트워크">전이학습 (남이 만든 네트워크)</a></li>
  <li><a href="#전이학습-다른-구현-순수-fastai-이용" id="toc-전이학습-다른-구현-순수-fastai-이용" class="nav-link" data-scroll-target="#전이학습-다른-구현-순수-fastai-이용">전이학습 다른 구현: 순수 fastai 이용</a></li>
  </ul></li>
  <li><a href="#cam" id="toc-cam" class="nav-link" data-scroll-target="#cam">CAM</a>
  <ul class="collapse">
  <li><a href="#cam이란" id="toc-cam이란" class="nav-link" data-scroll-target="#cam이란">CAM이란?</a></li>
  <li><a href="#학습에-사용할-데이터-load" id="toc-학습에-사용할-데이터-load" class="nav-link" data-scroll-target="#학습에-사용할-데이터-load">학습에 사용할 데이터 Load</a></li>
  <li><a href="#구현0단계-예비학습" id="toc-구현0단계-예비학습" class="nav-link" data-scroll-target="#구현0단계-예비학습">구현0단계– 예비학습</a></li>
  <li><a href="#구현1단계-이미지분류-잘하는-네트워크-선택" id="toc-구현1단계-이미지분류-잘하는-네트워크-선택" class="nav-link" data-scroll-target="#구현1단계-이미지분류-잘하는-네트워크-선택">구현1단계– 이미지분류 잘하는 네트워크 선택</a></li>
  <li><a href="#구현2단계-네트워크의-끝-부분-수정" id="toc-구현2단계-네트워크의-끝-부분-수정" class="nav-link" data-scroll-target="#구현2단계-네트워크의-끝-부분-수정">구현2단계– 네트워크의 끝 부분 수정</a></li>
  <li><a href="#구현3단계-수정된-net2에서-linear와-ap의-순서를-바꿈" id="toc-구현3단계-수정된-net2에서-linear와-ap의-순서를-바꿈" class="nav-link" data-scroll-target="#구현3단계-수정된-net2에서-linear와-ap의-순서를-바꿈">구현3단계– 수정된 net2에서 Linear와 AP의 순서를 바꿈</a></li>
  <li><a href="#잠깐-멈추고-생각" id="toc-잠깐-멈추고-생각" class="nav-link" data-scroll-target="#잠깐-멈추고-생각">잠깐 멈추고 생각</a></li>
  <li><a href="#구현4단계-cam-시각화" id="toc-구현4단계-cam-시각화" class="nav-link" data-scroll-target="#구현4단계-cam-시각화">구현4단계– CAM 시각화</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>기계학습 특강 (8주차) 10월26일–(2) [이미지자료분석 - Transfer Learning, CAM (설명가능한 인공지능모형, XAI)]</p>
<section id="imports" class="level2">
<h2 class="anchored" data-anchor-id="imports">imports</h2>
<div class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.vision.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span> </span></code></pre></div>
</div>
</section>
<section id="transfer-learning" class="level2">
<h2 class="anchored" data-anchor-id="transfer-learning">Transfer Learning</h2>
<div class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.CIFAR)</span></code></pre></div>
</div>
<div class="cell" data-outputid="47370d00-e62e-4e9f-f64d-83cb34ec2597" data-execution_count="94">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>path.ls()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="94">
<pre><code>(#3) [Path('/home/csy/.fastai/data/cifar10/train'),Path('/home/csy/.fastai/data/cifar10/labels.txt'),Path('/home/csy/.fastai/data/cifar10/test')]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>ls <span class="st">'/home/csy/.fastai/data/cifar10/train'</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>airplane  automobile  bird  cat  deer  dog  frog  horse  ship  truck</code></pre>
</div>
</div>
<section id="수제네트워크" class="level3">
<h3 class="anchored" data-anchor-id="수제네트워크">수제네트워크</h3>
<ol type="1">
<li>dls</li>
</ol>
<div class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> ImageDataLoaders.from_folder(path,train<span class="op">=</span><span class="st">'train'</span>,valid<span class="op">=</span><span class="st">'test'</span>) </span></code></pre></div>
</div>
<div class="cell" data-outputid="43b555ad-6877-4b90-b080-2ac92e3adb1d" data-execution_count="97">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>_X,_y <span class="op">=</span> dls.one_batch()</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>_X.shape, _y.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<pre><code>(torch.Size([64, 3, 32, 32]), torch.Size([64]))</code></pre>
</div>
</div>
<div class="cell" data-outputid="d1f42712-75fb-4216-999f-0f851753f3df" data-execution_count="98">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>ls <span class="st">'/home/csy/.fastai/data/cifar10/train'</span> <span class="co"># 10개의 클래스</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>airplane  automobile  bird  cat  deer  dog  frog  horse  ship  truck</code></pre>
</div>
</div>
<div class="cell" data-outputid="b4a2d663-454b-4a04-db74-59b8c9587eb0">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>dls.show_batch()</span></code></pre></div>
</div>
<ol start="2" type="1">
<li>lrnr 생성</li>
</ol>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>net1 <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    torch.nn.Conv2d(<span class="dv">3</span>,<span class="dv">128</span>,(<span class="dv">5</span>,<span class="dv">5</span>)),</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.MaxPool2d((<span class="dv">2</span>,<span class="dv">2</span>)),</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Flatten()</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<p>net는 cpu에 있고 X는 gpu에 있으니 cpu로 불러오자</p>
<div class="cell" data-outputid="42a2896f-3ebf-4eaf-fd3d-fbd7f9b7943a" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">#net1(_X.to("cpu")).shape</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    net1, </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">25088</span>,<span class="dv">10</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() </span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>lrnr <span class="op">=</span> Learner(dls,net,loss_fn,metrics<span class="op">=</span>accuracy) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>net.to(<span class="st">"cuda:0"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>Sequential(
  (0): Sequential(
    (0): Conv2d(3, 128, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
    (3): Flatten(start_dim=1, end_dim=-1)
  )
  (1): Linear(in_features=25088, out_features=10, bias=True)
)</code></pre>
</div>
</div>
<ol start="3" type="1">
<li>학습</li>
</ol>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>X,y<span class="op">=</span>dls.one_batch()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>lrnr.model(X).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>torch.Size([64, 10])</code></pre>
</div>
</div>
<div class="cell" data-outputid="93b4785f-208c-4935-fbb0-e43dede2d6d1" data-execution_count="15">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>lrnr.fit(<span class="dv">10</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.266191</td>
      <td>1.226523</td>
      <td>0.572100</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.128916</td>
      <td>1.124115</td>
      <td>0.609800</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.025027</td>
      <td>1.076060</td>
      <td>0.629600</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.956499</td>
      <td>1.071469</td>
      <td>0.636600</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.852002</td>
      <td>1.033129</td>
      <td>0.650600</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.811420</td>
      <td>1.071609</td>
      <td>0.641600</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.735469</td>
      <td>1.074108</td>
      <td>0.648300</td>
      <td>00:04</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.703909</td>
      <td>1.094982</td>
      <td>0.648800</td>
      <td>00:04</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.623525</td>
      <td>1.132971</td>
      <td>0.645000</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.589313</td>
      <td>1.157667</td>
      <td>0.637900</td>
      <td>00:05</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<ul>
<li>이게 생각보다 잘 안맞아요.. 70넘기 힘듬</li>
</ul>
</section>
<section id="전이학습-남이-만든-네트워크" class="level3">
<h3 class="anchored" data-anchor-id="전이학습-남이-만든-네트워크">전이학습 (남이 만든 네트워크)</h3>
<ol start="2" type="1">
<li>lrnr 생성</li>
</ol>
<p>학습되어 있는 파라메터까지 같이 가져오기</p>
<div class="cell" data-outputid="37894740-39a2-4c1a-b12c-4c280567a88f" data-execution_count="16">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse_output</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torchvision.models.resnet18(weights<span class="op">=</span>torchvision.models.resnet.ResNet18_Weights.IMAGENET1K_V1)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>net</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1000, bias=True)
)</code></pre>
</div>
</div>
<ul>
<li><span class="math inline">\(k=1000\)</span> 즉 1000개의 물체를 구분하는 모형임</li>
</ul>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>net.fc <span class="op">=</span> torch.nn.Linear(in_features<span class="op">=</span><span class="dv">512</span>, out_features<span class="op">=</span><span class="dv">10</span>) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() </span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>lrnr <span class="op">=</span> Learner(dls,net,loss_fn,metrics<span class="op">=</span>accuracy)</span></code></pre></div>
</div>
<ol start="3" type="1">
<li>학습</li>
</ol>
<div class="cell" data-outputid="18237e98-9491-4119-b109-449207207996" data-execution_count="19">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>lrnr.fit(<span class="dv">10</span>) </span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.813206</td>
      <td>0.955131</td>
      <td>0.677300</td>
      <td>00:21</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.636926</td>
      <td>0.719258</td>
      <td>0.760700</td>
      <td>00:21</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.538001</td>
      <td>0.802607</td>
      <td>0.765500</td>
      <td>00:21</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.446174</td>
      <td>0.591965</td>
      <td>0.804200</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.339985</td>
      <td>0.677038</td>
      <td>0.786200</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.283703</td>
      <td>0.664880</td>
      <td>0.797400</td>
      <td>00:21</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.221962</td>
      <td>0.734830</td>
      <td>0.787000</td>
      <td>00:21</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.183193</td>
      <td>0.720297</td>
      <td>0.798000</td>
      <td>00:21</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.160181</td>
      <td>0.785769</td>
      <td>0.790900</td>
      <td>00:21</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.144745</td>
      <td>0.745676</td>
      <td>0.804400</td>
      <td>00:21</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<ul>
<li>CIFAR10을 맞추기 위한 네트워크가 아님에도 불구하고 상당히 잘맞음</li>
<li>일반인이 거의 밑바닥에서 설계하는것보다 전이학습을 이용하는 것이 효율적일 경우가 많다.</li>
</ul>
</section>
<section id="전이학습-다른-구현-순수-fastai-이용" class="level3">
<h3 class="anchored" data-anchor-id="전이학습-다른-구현-순수-fastai-이용">전이학습 다른 구현: 순수 fastai 이용</h3>
<p><code>-</code> 예전코드 복습</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.PETS)<span class="op">/</span><span class="st">'images'</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>files<span class="op">=</span> get_image_files(path)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> label_func(fname):</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> fname[<span class="dv">0</span>].isupper():</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">'cat'</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">'dog'</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> ImageDataLoaders.from_name_func(path,files,label_func,item_tfms<span class="op">=</span>Resize(<span class="dv">512</span>)) </span></code></pre></div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>lrnr <span class="op">=</span> vision_learner(dls,resnet34,metrics<span class="op">=</span>accuracy) </span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  f"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, "
/home/csy/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)</code></pre>
</div>
</div>
<p>lrnr = cnn_learner(dls,resnet34,metrics=accuracy)</p>
<div class="cell" data-outputid="dc1dab17-bbcf-40d8-cb6e-fe31fe57804e" data-execution_count="25">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>lrnr.fine_tune(<span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.204861</td>
      <td>0.011182</td>
      <td>0.995940</td>
      <td>00:32</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.056896</td>
      <td>0.009584</td>
      <td>0.996617</td>
      <td>00:44</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p><code>-</code> 사실 위의 코드가 transfer learning 이었음.</p>
<div class="cell" data-outputid="966396b8-e2b6-496c-c656-eda4a2211738" data-execution_count="26">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse_output</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>lrnr.model</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>Sequential(
  (0): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (1): Sequential(
    (0): AdaptiveConcatPool2d(
      (ap): AdaptiveAvgPool2d(output_size=1)
      (mp): AdaptiveMaxPool2d(output_size=1)
    )
    (1): fastai.layers.Flatten(full=False)
    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=1024, out_features=512, bias=False)
    (5): ReLU(inplace=True)
    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=512, out_features=2, bias=False)
  )
)</code></pre>
</div>
</div>
<section id="xai설명가능한-인공지능" class="level4">
<h4 class="anchored" data-anchor-id="xai설명가능한-인공지능">XAI(설명가능한 인공지능)</h4>
<p><strong>딥러닝 연구의 네가지 축</strong> - step 1. 아키텍처 - 최근 연구 특징 : 비전문가 + 블랙박스(안 보이는 의미) - 설명가능한 딥러닝에 대한 요구 - step 2. 손실함수 - step 3. 미분계산 - step 4. 옵티마이저</p>
</section>
</section>
</section>
<section id="cam" class="level2">
<h2 class="anchored" data-anchor-id="cam">CAM</h2>
<section id="cam이란" class="level3">
<h3 class="anchored" data-anchor-id="cam이란">CAM이란?</h3>
<ul>
<li>ref: http://cnnlocalization.csail.mit.edu/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf</li>
</ul>
<p><code>-</code> Class Activation Mapping (CAM)은 설명가능한 인공지능모형 (eXplainable Artificial Intelligence, XAI) 중 하나로 CNN의 판단근거를 시각화하는 기술</p>
</section>
<section id="학습에-사용할-데이터-load" class="level3">
<h3 class="anchored" data-anchor-id="학습에-사용할-데이터-load">학습에 사용할 데이터 Load</h3>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.PETS)<span class="op">/</span><span class="st">'images'</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="e7155dfc-71aa-42eb-ff92-3c1046f2b790" data-execution_count="28">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>path.ls()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>(#7393) [Path('/home/csy/.fastai/data/oxford-iiit-pet/images/Bombay_13.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/beagle_193.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/Ragdoll_8.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/boxer_106.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/keeshond_56.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_162.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/saint_bernard_136.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_76.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/pug_173.jpg'),Path('/home/csy/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_117.jpg')...]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>files<span class="op">=</span> get_image_files(path)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> label_func(fname):</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> fname[<span class="dv">0</span>].isupper():</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">'cat'</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">'dog'</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> ImageDataLoaders.from_name_func(path,files,label_func,item_tfms<span class="op">=</span>Resize(<span class="dv">512</span>)) </span></code></pre></div>
</div>
</section>
<section id="구현0단계-예비학습" class="level3">
<h3 class="anchored" data-anchor-id="구현0단계-예비학습">구현0단계– 예비학습</h3>
<section id="하나의-이미지-선택" class="level4">
<h4 class="anchored" data-anchor-id="하나의-이미지-선택"><code>#</code> 하나의 이미지 선택</h4>
<div class="cell" data-outputid="f10f5f4d-9aa1-4de6-9eef-1b6720dc43af" data-execution_count="30">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>ximg <span class="op">=</span> PILImage.create(<span class="st">'/home/csy/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_106.jpg'</span>)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>ximg</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<p><img src="2022-10-26-ml_8w_2_files/figure-html/cell-31-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="cc3755eb-2be7-425a-83ed-a0c2f5dd7e09" data-execution_count="31">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> first(dls.test_dl([ximg]))[<span class="dv">0</span>]</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>x,x.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>(TensorImage([[[[0.9059, 0.9059, 0.9098,  ..., 0.9059, 0.9059, 0.9059],
                [0.9059, 0.9059, 0.9098,  ..., 0.9059, 0.9059, 0.9059],
                [0.9059, 0.9059, 0.9098,  ..., 0.9059, 0.9059, 0.9059],
                ...,
                [0.8745, 0.8784, 0.8824,  ..., 0.8902, 0.8863, 0.8824],
                [0.9059, 0.8980, 0.8902,  ..., 0.8824, 0.8863, 0.8824],
                [0.8863, 0.8863, 0.8824,  ..., 0.8784, 0.8863, 0.8863]],
 
               [[0.9137, 0.9137, 0.9176,  ..., 0.9059, 0.9059, 0.9059],
                [0.9137, 0.9137, 0.9176,  ..., 0.9059, 0.9059, 0.9059],
                [0.9137, 0.9137, 0.9176,  ..., 0.9059, 0.9059, 0.9059],
                ...,
                [0.8784, 0.8824, 0.8863,  ..., 0.8745, 0.8667, 0.8588],
                [0.9098, 0.9020, 0.8902,  ..., 0.8745, 0.8706, 0.8627],
                [0.8902, 0.8902, 0.8784,  ..., 0.8784, 0.8745, 0.8706]],
 
               [[0.9098, 0.9098, 0.9137,  ..., 0.9137, 0.9137, 0.9137],
                [0.9098, 0.9098, 0.9137,  ..., 0.9137, 0.9137, 0.9137],
                [0.9098, 0.9098, 0.9137,  ..., 0.9137, 0.9137, 0.9137],
                ...,
                [0.8863, 0.8902, 0.8980,  ..., 0.8784, 0.8706, 0.8667],
                [0.9176, 0.9137, 0.9059,  ..., 0.8745, 0.8706, 0.8667],
                [0.8980, 0.9020, 0.8980,  ..., 0.8745, 0.8706, 0.8667]]]],
             device='cuda:0'),
 torch.Size([1, 3, 512, 512]))</code></pre>
</div>
</div>
</section>
<section id="ap-layer" class="level4">
<h4 class="anchored" data-anchor-id="ap-layer"><code>#</code> AP layer</h4>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>ap <span class="op">=</span> torch.nn.AdaptiveAvgPool2d(output_size<span class="op">=</span><span class="dv">1</span>) </span></code></pre></div>
</div>
<div class="cell" data-outputid="8d26d87e-c690-4cb4-d5c3-83daa2701324" data-execution_count="33">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.arange(<span class="dv">48</span>).reshape(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">4</span>)<span class="op">*</span><span class="fl">1.0</span> </span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>X</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>tensor([[[[ 0.,  1.,  2.,  3.],
          [ 4.,  5.,  6.,  7.],
          [ 8.,  9., 10., 11.],
          [12., 13., 14., 15.]],

         [[16., 17., 18., 19.],
          [20., 21., 22., 23.],
          [24., 25., 26., 27.],
          [28., 29., 30., 31.]],

         [[32., 33., 34., 35.],
          [36., 37., 38., 39.],
          [40., 41., 42., 43.],
          [44., 45., 46., 47.]]]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="e712475c-5443-4def-a0e1-26207ca164b8" data-execution_count="34">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>ap(X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>tensor([[[[ 7.5000]],

         [[23.5000]],

         [[39.5000]]]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="9cea48a0-25cb-4463-e784-05189a731e61" data-execution_count="35">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>X[<span class="dv">0</span>,<span class="dv">0</span>,...].mean(),X[<span class="dv">0</span>,<span class="dv">1</span>,...].mean(),X[<span class="dv">0</span>,<span class="dv">2</span>,...].mean()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>(tensor(7.5000), tensor(23.5000), tensor(39.5000))</code></pre>
</div>
</div>
</section>
<section id="torch.einsum" class="level4">
<h4 class="anchored" data-anchor-id="torch.einsum"><code>#</code> torch.einsum</h4>
<p>(예시1)</p>
<div class="cell" data-outputid="e60f3e74-199e-4cc6-e3c5-dbe9b2c4cbf3" data-execution_count="36">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>tsr <span class="op">=</span> torch.arange(<span class="dv">12</span>).reshape(<span class="dv">4</span>,<span class="dv">3</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>tsr</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>tensor([[ 0,  1,  2],
        [ 3,  4,  5],
        [ 6,  7,  8],
        [ 9, 10, 11]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="1fe4fed9-d116-4355-b915-af060c6aceb4" data-execution_count="37">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>torch.einsum(<span class="st">'ij-&gt;ji'</span>,tsr)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor([[ 0,  3,  6,  9],
        [ 1,  4,  7, 10],
        [ 2,  5,  8, 11]])</code></pre>
</div>
</div>
<p>(예시2)</p>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>tsr1 <span class="op">=</span> torch.arange(<span class="dv">12</span>).reshape(<span class="dv">4</span>,<span class="dv">3</span>).<span class="bu">float</span>()</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>tsr2 <span class="op">=</span> torch.arange(<span class="dv">15</span>).reshape(<span class="dv">3</span>,<span class="dv">5</span>).<span class="bu">float</span>()</span></code></pre></div>
</div>
<div class="cell" data-outputid="abbb208e-91f6-48f2-d23f-88e51ccd54af" data-execution_count="39">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>tsr1 <span class="op">@</span> tsr2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>tensor([[ 25.,  28.,  31.,  34.,  37.],
        [ 70.,  82.,  94., 106., 118.],
        [115., 136., 157., 178., 199.],
        [160., 190., 220., 250., 280.]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="bdae9588-ceef-4b74-81fa-f251b6ccb79d" data-execution_count="40">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>torch.einsum(<span class="st">'ij,jk -&gt; ik'</span>,tsr1,tsr2) </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>tensor([[ 25.,  28.,  31.,  34.,  37.],
        [ 70.,  82.,  94., 106., 118.],
        [115., 136., 157., 178., 199.],
        [160., 190., 220., 250., 280.]])</code></pre>
</div>
</div>
<p>(예시3)</p>
<div class="cell" data-outputid="28f1a8b3-de4e-4c02-bc10-b91783dd77fd" data-execution_count="41">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>x.to(<span class="st">"cpu"</span>).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>torch.Size([1, 3, 512, 512])</code></pre>
</div>
</div>
<p><code>torch,einsum</code>을 사용하여 shape을 아래로 변경</p>
<div class="cell" data-outputid="c554ffd2-9b6d-419f-89dc-9ab94e19919c" data-execution_count="42">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>torch.einsum(<span class="st">'ocij -&gt; ijc'</span>,x.to(<span class="st">"cpu"</span>)).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>torch.Size([512, 512, 3])</code></pre>
</div>
</div>
<div class="cell" data-outputid="f61a5e5b-7b20-4fcb-e19c-2870ab488f4d" data-execution_count="43">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>plt.imshow(torch.einsum(<span class="st">'ocij -&gt; ijc'</span>,x.to(<span class="st">"cpu"</span>)))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7fe60eea0e50&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-26-ml_8w_2_files/figure-html/cell-44-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="구현1단계-이미지분류-잘하는-네트워크-선택" class="level3">
<h3 class="anchored" data-anchor-id="구현1단계-이미지분류-잘하는-네트워크-선택">구현1단계– 이미지분류 잘하는 네트워크 선택</h3>
<div class="cell" data-outputid="d6ce0073-529e-4f51-8038-b9b7b3ed5e2f" data-execution_count="44">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>lrnr <span class="op">=</span> vision_learner(dls,resnet34,metrics<span class="op">=</span>accuracy) </span></code></pre></div>
</div>
<p>lrnr = cnn_learner(dls,resnet34,metrics=accuracy)</p>
<div class="cell" data-outputid="7d07245d-887d-445a-a975-7f3b60bfed00" data-execution_count="45">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>lrnr.fine_tune(<span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.180252</td>
      <td>0.032132</td>
      <td>0.989851</td>
      <td>00:32</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.053625</td>
      <td>0.008279</td>
      <td>0.997970</td>
      <td>00:44</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</section>
<section id="구현2단계-네트워크의-끝-부분-수정" class="level3">
<h3 class="anchored" data-anchor-id="구현2단계-네트워크의-끝-부분-수정">구현2단계– 네트워크의 끝 부분 수정</h3>
<p><code>-</code> 모형의 분해</p>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>net1<span class="op">=</span> lrnr.model[<span class="dv">0</span>]</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>net2<span class="op">=</span> lrnr.model[<span class="dv">1</span>]</span></code></pre></div>
</div>
<p>net1이 2d part, net1이 1d part</p>
<p><code>-</code> net2를 좀더 살펴보자.</p>
<div class="cell" data-outputid="c401952e-22c3-4785-b95d-af571a625d45" data-execution_count="47">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>net2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>Sequential(
  (0): AdaptiveConcatPool2d(
    (ap): AdaptiveAvgPool2d(output_size=1)
    (mp): AdaptiveMaxPool2d(output_size=1)
  )
  (1): fastai.layers.Flatten(full=False)
  (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (3): Dropout(p=0.25, inplace=False)
  (4): Linear(in_features=1024, out_features=512, bias=False)
  (5): ReLU(inplace=True)
  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (7): Dropout(p=0.5, inplace=False)
  (8): Linear(in_features=512, out_features=2, bias=False)
)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>_X, _y <span class="op">=</span> dls.one_batch() </span></code></pre></div>
</div>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>net1.to(<span class="st">"cpu"</span>)</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>net2.to(<span class="st">"cpu"</span>) </span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>_X <span class="op">=</span> _X.to(<span class="st">"cpu"</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="a6904aa2-206e-4e0c-f6b0-757a88d5b896" data-execution_count="50">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(net1(_X).shape)</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(net2[<span class="dv">0</span>](net1(_X)).shape)</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(net2[<span class="dv">1</span>](net2[<span class="dv">0</span>](net1(_X))).shape)</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(net2[<span class="dv">2</span>](net2[<span class="dv">1</span>](net2[<span class="dv">0</span>](net1(_X)))).shape)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([64, 512, 16, 16])
torch.Size([64, 1024, 1, 1])
torch.Size([64, 1024])
torch.Size([64, 1024])</code></pre>
</div>
</div>
<p><code>-</code> net2를 아래와 같이 수정하고 재학습하자 (왜?)</p>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>net2<span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>    torch.nn.AdaptiveAvgPool2d(output_size<span class="op">=</span><span class="dv">1</span>), <span class="co"># (64,512,16,16) -&gt; (64,512,1,1) </span></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Flatten(), <span class="co"># (64,512,1,1) -&gt; (64,512) </span></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">512</span>,<span class="dv">2</span>,bias<span class="op">=</span><span class="va">False</span>) <span class="co"># (64,512) -&gt; (64,2) </span></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>    net1,</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>    net2</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>lrnr2<span class="op">=</span> Learner(dls,net,metrics<span class="op">=</span>accuracy) <span class="co"># loss_fn??</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="f5ee2133-cf8a-4f4b-8d12-06a946b73e72" data-execution_count="54">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>lrnr2.loss_func, lrnr.loss_func <span class="co">## 알아서 기존의 loss function으로 잘 들어가 있음. </span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>(FlattenedLoss of CrossEntropyLoss(), FlattenedLoss of CrossEntropyLoss())</code></pre>
</div>
</div>
<div class="cell" data-outputid="0db1f7a7-8263-4a48-db39-d63fd8eef2da" data-execution_count="55">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>lrnr2.fine_tune(<span class="dv">5</span>) <span class="co"># net2를 수정해서 accuracy가 안좋아지긴 했는데 그래도 쓸만함 </span></span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.240225</td>
      <td>0.521585</td>
      <td>0.826793</td>
      <td>00:44</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.139931</td>
      <td>0.159443</td>
      <td>0.940460</td>
      <td>00:44</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.123673</td>
      <td>0.396028</td>
      <td>0.864682</td>
      <td>00:44</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.094375</td>
      <td>0.136513</td>
      <td>0.952639</td>
      <td>00:44</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.052172</td>
      <td>0.057100</td>
      <td>0.977673</td>
      <td>00:44</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.028230</td>
      <td>0.041083</td>
      <td>0.985792</td>
      <td>00:44</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</section>
<section id="구현3단계-수정된-net2에서-linear와-ap의-순서를-바꿈" class="level3">
<h3 class="anchored" data-anchor-id="구현3단계-수정된-net2에서-linear와-ap의-순서를-바꿈">구현3단계– 수정된 net2에서 Linear와 AP의 순서를 바꿈</h3>
<p><code>-</code> 1개의 observation을 고정하였을 경우 출력과정 상상</p>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>ximg <span class="op">=</span> PILImage.create(<span class="st">'/home/csy/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_106.jpg'</span>)</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> first(dls.test_dl([ximg]))[<span class="dv">0</span>]</span></code></pre></div>
</div>
<div class="cell" data-outputid="e62279ee-2b99-4768-a541-68b4fdace126" data-execution_count="57">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>net2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>Sequential(
  (0): AdaptiveAvgPool2d(output_size=1)
  (1): Flatten(start_dim=1, end_dim=-1)
  (2): Linear(in_features=512, out_features=2, bias=False)
)</code></pre>
</div>
</div>
<div class="cell" data-outputid="e04fa9f2-28ea-4009-aa95-2a5d854df878" data-execution_count="58">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(net1(x).shape)</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(net2[<span class="dv">0</span>](net1(x)).shape)</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(net2[<span class="dv">1</span>](net2[<span class="dv">0</span>](net1(x))).shape)</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(net2[<span class="dv">2</span>](net2[<span class="dv">1</span>](net2[<span class="dv">0</span>](net1(x)))).shape)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 512, 16, 16])
torch.Size([1, 512, 1, 1])
torch.Size([1, 512])
torch.Size([1, 2])</code></pre>
</div>
</div>
<p><code>-</code> 최종결과 확인</p>
<div class="cell" data-outputid="e8fd99cc-d32f-42a1-c0fe-f67111900c46" data-execution_count="59">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>net(x)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>TensorImage([[-6.7946,  8.0881]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)</code></pre>
</div>
</div>
<p>아마 모델 달라서 값이 다른 것일까..!</p>
<div class="cell" data-outputid="d411b610-64a1-41b8-91bb-90a3b8e1234f" data-execution_count="60">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>dls.vocab</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>['cat', 'dog']</code></pre>
</div>
</div>
<ul>
<li>net(x)에서 뒤쪽의 값이 클수록 ’dog’를 의미한다.</li>
</ul>
<p><code>-</code> net2의 순서 바꾸기 전 전체 네트워크:</p>
<p><span class="math display">\[\underset{(1,3,512,512)}{\boldsymbol x} \overset{net_1}{\to} \left( \underset{(1,512,16,16)}{\tilde{\boldsymbol x}} \overset{ap}{\to} \underset{(1,512,1,1)}{{\boldsymbol \sharp}}\overset{flatten}{\to} \underset{(1,512)}{{\boldsymbol \sharp}}\overset{linear}{\to} \underset{(1,2)}{\hat{\boldsymbol y}}\right) = [-9.0358,  9.0926]\]</span></p>
<p><code>-</code> 아래와 같이 순서를 바꿔서 한번 계산해보고 싶다. (왜???..)</p>
<p><span class="math display">\[\underset{(1,3,224,224)}{\boldsymbol x} \overset{net_1}{\to} \left( \underset{(1,512,16,16)}{\tilde{\boldsymbol x}} \overset{linear}{\to} \underset{(1,2,16,16)}{{\bf why}}\overset{ap}{\to} \underset{(1,2,1,1)}{{\boldsymbol \sharp}}\overset{flatten}{\to} \underset{(1,2)}{\hat{\boldsymbol y}}\right) = [−9.0358,9.0926]\]</span></p>
<ul>
<li>여기에서 (1,512,16,16) -&gt; (1,2,16,16) 로 가는 선형변환을 적용하는 방법? <strong>(16,16) each pixel에 대하여 (512 <span class="math inline">\(\to\)</span> 2)로 가는 변환을 수행</strong></li>
</ul>
<p><code>-</code> 통찰: 이 경우 특이하게도 레이어의 순서를 바꿨을때 출력이 동일함 (선형변환하고 평균내거나 평균내고 선형변환하는건 같으니까)</p>
<div class="cell" data-outputid="534227a1-8618-4e37-c8e2-062231de8857" data-execution_count="61">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>_x <span class="op">=</span>torch.tensor([<span class="dv">1</span>,<span class="dv">2</span>,<span class="fl">3.14</span>,<span class="dv">4</span>]).reshape(<span class="dv">4</span>,<span class="dv">1</span>)</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>_x </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>tensor([[1.0000],
        [2.0000],
        [3.1400],
        [4.0000]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="a50e0ecd-804f-476e-f51b-2331321d39d0" data-execution_count="62">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>_l1 <span class="op">=</span> torch.nn.Linear(<span class="dv">1</span>,<span class="dv">1</span>,bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>_l1(_x).mean() <span class="co"># _x -&gt; 선형변환 -&gt; 평균 </span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>tensor(-0.2621, grad_fn=&lt;MeanBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell" data-outputid="9876d274-a019-420a-82da-2c78dec2e1f3" data-execution_count="63">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>_l1(_x.mean().reshape(<span class="dv">1</span>,<span class="dv">1</span>)) <span class="co"># _x -&gt; 평균 -&gt; 선형변환</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>tensor([[-0.2621]], grad_fn=&lt;MmBackward0&gt;)</code></pre>
</div>
</div>
<p><code>-</code> 구현해보자.</p>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>net2[<span class="dv">2</span>].weight.shape,net1(x).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>(torch.Size([2, 512]), torch.Size([1, 512, 16, 16]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>why <span class="op">=</span> torch.einsum(<span class="st">'cb,abij-&gt;acij'</span>,net2[<span class="dv">2</span>].weight,net1(x))</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>why.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>torch.Size([1, 2, 16, 16])</code></pre>
</div>
</div>
<div class="cell" data-outputid="f5259fe3-30ff-43ab-b9ef-2898539d0d9e" data-execution_count="66">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>net2[<span class="dv">0</span>](why)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>TensorImage([[[[-6.7946]],

              [[ 8.0881]]]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell" data-outputid="78880c52-1ed1-4111-97c5-0ebc3cc68bec" data-execution_count="67">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>net(x)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>TensorImage([[-6.7946,  8.0881]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)</code></pre>
</div>
</div>
</section>
<section id="잠깐-멈추고-생각" class="level3">
<h3 class="anchored" data-anchor-id="잠깐-멈추고-생각">잠깐 멈추고 생각</h3>
<p><code>-</code> 이미지</p>
<div class="cell" data-outputid="7de3ebbe-5139-467e-b8f2-05dc00805786" data-execution_count="68">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>ximg</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="68">
<p><img src="2022-10-26-ml_8w_2_files/figure-html/cell-69-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 네트워크의 결과</p>
<div class="cell" data-outputid="10f4f355-62b7-4f73-f02f-dba7f44dd99b" data-execution_count="69">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>net2(net1(x))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>TensorImage([[-6.7946,  8.0881]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)</code></pre>
</div>
</div>
<ul>
<li>-9.0358 &lt;&lt; 9.0926 이므로 ’ximg’는 높은 확률로 개라는 뜻이다.</li>
</ul>
<p>내거에서는 9.0926이 10.2985</p>
<p><code>-</code> 아래의 네트워크를 관찰</p>
<p><span class="math display">\[\underset{(1,2,16,16)}{{\bf why}}\overset{ap}{\to} \underset{(1,2,1,1)}{{\boldsymbol \sharp}}\overset{flatten}{\to} \underset{(1,2)}{\hat{\boldsymbol y}} = [-9.0358,9.0926]\]</span></p>
<div class="cell" data-outputid="1377554d-cf69-4148-c388-347a9bbd46e5" data-execution_count="70">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>net2[<span class="dv">0</span>](why)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<pre><code>TensorImage([[[[-6.7946]],

              [[ 8.0881]]]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)</code></pre>
</div>
</div>
<p>더 파고들어서 분석해보자.</p>
<div class="cell" data-outputid="ed14f0d8-90bf-4a4d-c720-cbed4c3ae060" data-execution_count="71">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>why.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>torch.Size([1, 2, 16, 16])</code></pre>
</div>
</div>
<div class="cell" data-outputid="7829fde5-bf2e-4906-dbe3-3f0777233c27" data-execution_count="72">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>(why[<span class="dv">0</span>,<span class="dv">0</span>,:,:]).mean(), (why[<span class="dv">0</span>,<span class="dv">1</span>,:,:]).mean()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="72">
<pre><code>(TensorImage(-6.7946, device='cuda:0', grad_fn=&lt;AliasBackward0&gt;),
 TensorImage(8.0881, device='cuda:0', grad_fn=&lt;AliasBackward0&gt;))</code></pre>
</div>
</div>
<p><strong><em><code>why[0,0,:,:]</code></em></strong></p>
<div class="cell" data-outputid="8560177e-c42b-42a0-c3b5-9f039a9acaf3" data-execution_count="73">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse_output</span></span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>(why[<span class="dv">0</span>,<span class="dv">0</span>,:,:]).to(torch.int64)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>TensorImage([[   0,    0,    0,    0,    0,    0,    0,   -1,   -1,    0,    0,
                 0,    0,    0,    0,    0],
             [   0,    0,    0,    0,    0,   -1,   -9,  -18,  -18,   -9,   -2,
                 0,    0,    0,    0,    0],
             [   0,    0,    0,    0,    0,   -8,  -31,  -51,  -44,  -25,   -8,
                 0,    0,    0,    0,    0],
             [   0,    0,    0,    0,    0,  -16,  -50,  -82,  -73,  -45,  -14,
                 0,    0,    0,    0,    0],
             [   0,    0,    0,    0,   -1,  -21,  -59,  -98, -111,  -63,  -18,
                -1,    0,    0,    0,    0],
             [   0,    0,    0,    0,    0,  -17,  -53,  -94, -100,  -60,  -18,
                -2,    0,    0,    0,    0],
             [   0,    0,    0,    0,    0,  -10,  -37,  -65,  -66,  -40,  -13,
                -2,   -1,    0,    0,    0],
             [   0,    0,    0,    0,    0,   -6,  -25,  -43,  -34,  -16,   -4,
                -2,   -1,   -1,    0,    0],
             [   0,    0,    0,    0,    0,   -5,  -17,  -22,  -15,   -4,   -1,
                -1,   -1,    0,    0,    0],
             [   0,    0,    0,    0,    0,   -4,  -11,  -11,   -7,   -1,    0,
                 0,    0,    0,    0,    0],
             [   0,    0,    0,    0,   -1,   -2,   -3,   -2,    0,    0,    0,
                 0,    1,    0,    0,    0],
             [   0,    0,    0,    0,    0,   -1,    0,    1,    2,    1,    0,
                 0,    0,    0,    0,    0],
             [   0,    0,    0,    0,    0,   -3,    0,    1,    4,    3,    0,
                -1,    0,    0,    0,    0],
             [   0,   -1,    0,    0,   -1,   -2,   -1,    1,    3,    2,   -1,
                -2,   -1,    0,    0,    0],
             [  -1,   -1,    0,   -1,   -1,   -5,   -3,    0,    0,    0,   -2,
                -2,   -2,   -1,   -1,   -1],
             [  -1,   -1,    0,    0,   -1,   -7,   -5,    0,   -1,   -1,   -1,
                -1,   -2,   -1,   -1,   -1]], device='cuda:0')</code></pre>
</div>
</div>
<ul>
<li>이 값들의 평균은 -9.0358 이다. (이 값이 클수록 이 그림이 고양이라는 의미 = 이 값이 작을수록 이 그림이 고양이가 아니라는 의미)</li>
<li>그런데 살펴보니 대부분의 위치에서 0에 가까운 값을 가짐. 다만 특정위치에서 엄청 큰 작은값이 있어서 -9.0358이라는 평균값이 나옴 <span class="math inline">\(\to\)</span> 특정위치에 존재하는 엄청 작은 값들은 ximg가 고양이가 아니라고 판단하는 근거가 된다.</li>
</ul>
<p><strong><em><code>why[0,1,:,:]</code></em></strong></p>
<div class="cell" data-outputid="74e1fc07-e2d7-4b62-a91f-8078f1879e91" data-execution_count="74">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse_output</span></span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>(why[<span class="dv">0</span>,<span class="dv">1</span>,:,:]).to(torch.int64)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>TensorImage([[  0,   0,   0,   0,   0,   0,   0,   2,   2,   1,   0,   0,   0,
                0,   0,   0],
             [  0,   0,   0,   0,   0,   1,  11,  21,  21,  11,   3,   0,   0,
                0,   0,   0],
             [  0,   0,   0,   0,   0,   9,  35,  61,  53,  30,  11,   1,   0,
                0,   0,   0],
             [  0,   0,   0,   0,   0,  19,  58,  95,  87,  54,  17,   1,   0,
                0,   0,   0],
             [  0,   0,   0,   0,   1,  24,  68, 114, 132,  75,  22,   1,   0,
                0,   0,   0],
             [  0,   0,   0,   0,   1,  20,  61, 109, 118,  72,  21,   2,   0,
                0,   0,   0],
             [  0,   0,   0,   0,   0,  12,  43,  75,  77,  46,  15,   3,   1,
                0,   0,   0],
             [  0,   0,   0,   0,   0,   7,  28,  50,  39,  18,   5,   2,   2,
                1,   0,   0],
             [  0,   0,   0,   0,   0,   6,  19,  26,  17,   5,   1,   1,   1,
                0,   0,   0],
             [  0,   0,   0,   0,   0,   5,  12,  13,   9,   2,   0,   0,   0,
                0,   0,   0],
             [  0,   0,   0,   0,   1,   2,   3,   3,   1,   0,   0,   0,  -1,
                0,   0,   0],
             [  0,   0,   0,   0,   1,   1,   1,  -1,  -2,  -1,   1,   0,   0,
                0,   0,   0],
             [  0,   0,   0,   0,   1,   4,   0,  -1,  -5,  -3,   0,   1,   0,
                0,   0,   0],
             [  0,   1,   0,   0,   1,   3,   1,  -1,  -3,  -3,   1,   2,   1,
                0,   0,   1],
             [  1,   1,   1,   1,   1,   6,   4,   0,   0,   0,   2,   3,   2,
                1,   1,   1],
             [  1,   1,   1,   1,   1,   8,   6,   1,   1,   1,   1,   1,   2,
                1,   1,   1]], device='cuda:0')</code></pre>
</div>
</div>
<ul>
<li>이 값들의 평균은 9.0926 이다. (이 값이 클수록 이 그림이 강아지라는 의미)</li>
<li>그런데 살펴보니 대부분의 위치에서 0에 가까운 값을 가짐. 다만 특정위치에서 엄청 큰 값들이 있어서 9.0926이라는 평균값이 나옴 <span class="math inline">\(\to\)</span> 특정위치에 존재하는 엄청 큰 값들은 결국 ximg를 강아지라고 판단하는 근거가 된다.</li>
</ul>
<p><code>-</code> 시각화</p>
<div class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>why_cat <span class="op">=</span> why[<span class="dv">0</span>,<span class="dv">0</span>,:,:]</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>why_dog <span class="op">=</span> why[<span class="dv">0</span>,<span class="dv">1</span>,:,:]</span></code></pre></div>
</div>
<div class="cell" data-outputid="f80d34e6-bf82-47c4-df43-fb547438aa7d" data-execution_count="76">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">3</span>,figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">4</span>))</span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].imshow(torch.einsum(<span class="st">'ocij -&gt; ijc'</span>,dls.decode((x,))[<span class="dv">0</span>]).to(<span class="st">"cpu"</span>))</span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].imshow(why_cat.to(<span class="st">"cpu"</span>).detach(),cmap<span class="op">=</span><span class="st">'magma'</span>)</span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">2</span>].imshow(why_dog.to(<span class="st">"cpu"</span>).detach(),cmap<span class="op">=</span><span class="st">'magma'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="76">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7fe61ad76350&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-26-ml_8w_2_files/figure-html/cell-77-output-2.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>magma = 검은색 &lt; 보라색 &lt; 빨간색 &lt; 노란색</li>
<li>왼쪽그림의 검은 부분은 고양이가 아니라는 근거, 오른쪽그림의 노란부분은 강아지라는 근거</li>
</ul>
<p><code>-</code> why_cat, why_dog를 (16,16) <span class="math inline">\(\to\)</span> (512,512) 로 resize</p>
<div class="cell" data-outputid="7b94f23a-e94a-481f-b518-8c2338bc11f6" data-execution_count="77">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">3</span>,figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">4</span>))</span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].imshow(torch.einsum(<span class="st">'ocij -&gt; ijc'</span>,dls.decode((x,))[<span class="dv">0</span>]).to(<span class="st">"cpu"</span>))</span>
<span id="cb119-3"><a href="#cb119-3" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].imshow(why_cat.to(<span class="st">"cpu"</span>).detach(),cmap<span class="op">=</span><span class="st">'magma'</span>,extent<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">511</span>,<span class="dv">511</span>,<span class="dv">0</span>),interpolation<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb119-4"><a href="#cb119-4" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">2</span>].imshow(why_dog.to(<span class="st">"cpu"</span>).detach(),cmap<span class="op">=</span><span class="st">'magma'</span>,extent<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">511</span>,<span class="dv">511</span>,<span class="dv">0</span>),interpolation<span class="op">=</span><span class="st">'bilinear'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="77">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7fe616821f10&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-26-ml_8w_2_files/figure-html/cell-78-output-2.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 겹쳐그리기</p>
<div class="cell" data-outputid="476ab61a-697c-41bd-94cb-12c70f17c633" data-execution_count="78">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>,figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">4</span>))</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].imshow(torch.einsum(<span class="st">'ocij -&gt; ijc'</span>,dls.decode((x,))[<span class="dv">0</span>]).to(<span class="st">"cpu"</span>))</span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].imshow(why_cat.to(<span class="st">"cpu"</span>).detach(),cmap<span class="op">=</span><span class="st">'magma'</span>,extent<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">511</span>,<span class="dv">511</span>,<span class="dv">0</span>),interpolation<span class="op">=</span><span class="st">'bilinear'</span>,alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].imshow(torch.einsum(<span class="st">'ocij -&gt; ijc'</span>,dls.decode((x,))[<span class="dv">0</span>]).to(<span class="st">"cpu"</span>))</span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].imshow(why_dog.to(<span class="st">"cpu"</span>).detach(),cmap<span class="op">=</span><span class="st">'magma'</span>,extent<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">511</span>,<span class="dv">511</span>,<span class="dv">0</span>),interpolation<span class="op">=</span><span class="st">'bilinear'</span>,alpha<span class="op">=</span><span class="fl">0.5</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7fe5eac7af10&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-26-ml_8w_2_files/figure-html/cell-79-output-2.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 하니이미지 시각화</p>
<div class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>wget https:<span class="op">//</span>github.com<span class="op">/</span>guebin<span class="op">/</span>DL2022<span class="op">/</span>blob<span class="op">/</span>master<span class="op">/</span>_notebooks<span class="op">/</span><span class="dv">2022</span><span class="op">-</span><span class="dv">0</span><span class="er">9</span><span class="op">-</span><span class="dv">0</span><span class="er">6</span><span class="op">-</span>hani01.jpeg</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--2022-11-02 23:41:24--  https://github.com/guebin/DL2022/blob/master/_notebooks/2022-09-06-hani01.jpeg
Resolving github.com (github.com)... 20.200.245.247
Connecting to github.com (github.com)|20.200.245.247|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: unspecified [text/html]
Saving to: ‘2022-09-06-hani01.jpeg’

2022-09-06-hani01.j     [ &lt;=&gt;                ] 134.25K  --.-KB/s    in 0.02s   

2022-11-02 23:41:24 (8.09 MB/s) - ‘2022-09-06-hani01.jpeg’ saved [137470]
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a><span class="co">#!wget https://github.com/guebin/DL2022/blob/master/_notebooks/2022-09-06-hani01.jpeg?raw=true</span></span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a>ximg<span class="op">=</span> PILImage.create(<span class="st">'2022-09-07-dogs.jpeg'</span>)</span>
<span id="cb125-4"><a href="#cb125-4" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span> first(dls.test_dl([ximg]))[<span class="dv">0</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>why <span class="op">=</span> torch.einsum(<span class="st">'cb,abij-&gt;acij'</span>,net2[<span class="dv">2</span>].weight,net1(x))</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>why_cat <span class="op">=</span> why[<span class="dv">0</span>,<span class="dv">0</span>,:,:]</span>
<span id="cb126-3"><a href="#cb126-3" aria-hidden="true" tabindex="-1"></a>why_dog <span class="op">=</span> why[<span class="dv">0</span>,<span class="dv">1</span>,:,:]</span></code></pre></div>
</div>
<div class="cell" data-outputid="00d46041-ea0a-4085-b4d2-68aea8a7677f" data-execution_count="82">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>,figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">4</span>))</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].imshow(torch.einsum(<span class="st">'ocij -&gt; ijc'</span>,dls.decode((x,))[<span class="dv">0</span>]).to(<span class="st">"cpu"</span>))</span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].imshow(why_cat.to(<span class="st">"cpu"</span>).detach(),cmap<span class="op">=</span><span class="st">'magma'</span>,extent<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">511</span>,<span class="dv">511</span>,<span class="dv">0</span>),interpolation<span class="op">=</span><span class="st">'bilinear'</span>,alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].imshow(torch.einsum(<span class="st">'ocij -&gt; ijc'</span>,dls.decode((x,))[<span class="dv">0</span>]).to(<span class="st">"cpu"</span>))</span>
<span id="cb127-5"><a href="#cb127-5" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].imshow(why_dog.to(<span class="st">"cpu"</span>).detach(),cmap<span class="op">=</span><span class="st">'magma'</span>,extent<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">511</span>,<span class="dv">511</span>,<span class="dv">0</span>),interpolation<span class="op">=</span><span class="st">'bilinear'</span>,alpha<span class="op">=</span><span class="fl">0.5</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="82">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7fe61ae94190&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-26-ml_8w_2_files/figure-html/cell-83-output-2.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 하니이미지 시각화 with prob</p>
<div class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>sftmax<span class="op">=</span>torch.nn.Softmax(dim<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="129b2edd-ce38-4c15-e6c6-8ebef7cfd8ee" data-execution_count="84">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>sftmax(net(x))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="84">
<pre><code>TensorImage([[1.1767e-09, 1.0000e+00]], device='cuda:0',
            grad_fn=&lt;AliasBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>catprob, dogprob <span class="op">=</span> sftmax(net(x))[<span class="dv">0</span>,<span class="dv">0</span>].item(), sftmax(net(x))[<span class="dv">0</span>,<span class="dv">1</span>].item()</span></code></pre></div>
</div>
<div class="cell" data-outputid="e3123bcb-2df2-4c5a-f375-9cb161c334aa" data-execution_count="86">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>,figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">4</span>))</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].imshow(torch.einsum(<span class="st">'ocij -&gt; ijc'</span>,dls.decode((x,))[<span class="dv">0</span>]).to(<span class="st">"cpu"</span>))</span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].imshow(why_cat.to(<span class="st">"cpu"</span>).detach(),cmap<span class="op">=</span><span class="st">'magma'</span>,extent<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">511</span>,<span class="dv">511</span>,<span class="dv">0</span>),interpolation<span class="op">=</span><span class="st">'bilinear'</span>,alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb133-4"><a href="#cb133-4" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_title(<span class="st">'catprob= </span><span class="sc">%f</span><span class="st">'</span> <span class="op">%</span> catprob) </span>
<span id="cb133-5"><a href="#cb133-5" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].imshow(torch.einsum(<span class="st">'ocij -&gt; ijc'</span>,dls.decode((x,))[<span class="dv">0</span>]).to(<span class="st">"cpu"</span>))</span>
<span id="cb133-6"><a href="#cb133-6" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].imshow(why_dog.to(<span class="st">"cpu"</span>).detach(),cmap<span class="op">=</span><span class="st">'magma'</span>,extent<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">511</span>,<span class="dv">511</span>,<span class="dv">0</span>),interpolation<span class="op">=</span><span class="st">'bilinear'</span>,alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb133-7"><a href="#cb133-7" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_title(<span class="st">'dogprob=</span><span class="sc">%f</span><span class="st">'</span> <span class="op">%</span> dogprob)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>Text(0.5, 1.0, 'dogprob=1.000000')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-26-ml_8w_2_files/figure-html/cell-87-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="구현4단계-cam-시각화" class="level3">
<h3 class="anchored" data-anchor-id="구현4단계-cam-시각화">구현4단계– CAM 시각화</h3>
<div class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>sftmax <span class="op">=</span> torch.nn.Softmax(dim<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="63a4d22b-8422-4c66-c5f2-b722121bc91a" data-execution_count="88">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>) </span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>k<span class="op">=</span><span class="dv">0</span> </span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>): </span>
<span id="cb136-5"><a href="#cb136-5" aria-hidden="true" tabindex="-1"></a>        x, <span class="op">=</span> first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))</span>
<span id="cb136-6"><a href="#cb136-6" aria-hidden="true" tabindex="-1"></a>        why <span class="op">=</span> torch.einsum(<span class="st">'cb,abij -&gt; acij'</span>, net2[<span class="dv">2</span>].weight, net1(x))</span>
<span id="cb136-7"><a href="#cb136-7" aria-hidden="true" tabindex="-1"></a>        why_cat <span class="op">=</span> why[<span class="dv">0</span>,<span class="dv">0</span>,:,:] </span>
<span id="cb136-8"><a href="#cb136-8" aria-hidden="true" tabindex="-1"></a>        why_dog <span class="op">=</span> why[<span class="dv">0</span>,<span class="dv">1</span>,:,:] </span>
<span id="cb136-9"><a href="#cb136-9" aria-hidden="true" tabindex="-1"></a>        catprob, dogprob <span class="op">=</span> sftmax(net(x))[<span class="dv">0</span>][<span class="dv">0</span>].item(), sftmax(net(x))[<span class="dv">0</span>][<span class="dv">1</span>].item()</span>
<span id="cb136-10"><a href="#cb136-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> catprob<span class="op">&gt;</span>dogprob: </span>
<span id="cb136-11"><a href="#cb136-11" aria-hidden="true" tabindex="-1"></a>            dls.train.decode((x,))[<span class="dv">0</span>].squeeze().show(ax<span class="op">=</span>ax[i][j])</span>
<span id="cb136-12"><a href="#cb136-12" aria-hidden="true" tabindex="-1"></a>            ax[i][j].imshow(why_cat.to(<span class="st">"cpu"</span>).detach(),alpha<span class="op">=</span><span class="fl">0.5</span>,extent<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">511</span>,<span class="dv">511</span>,<span class="dv">0</span>),interpolation<span class="op">=</span><span class="st">'bilinear'</span>,cmap<span class="op">=</span><span class="st">'magma'</span>)</span>
<span id="cb136-13"><a href="#cb136-13" aria-hidden="true" tabindex="-1"></a>            ax[i][j].set_title(<span class="st">"cat(</span><span class="sc">%2f</span><span class="st">)"</span> <span class="op">%</span> catprob)</span>
<span id="cb136-14"><a href="#cb136-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>: </span>
<span id="cb136-15"><a href="#cb136-15" aria-hidden="true" tabindex="-1"></a>            dls.train.decode((x,))[<span class="dv">0</span>].squeeze().show(ax<span class="op">=</span>ax[i][j])</span>
<span id="cb136-16"><a href="#cb136-16" aria-hidden="true" tabindex="-1"></a>            ax[i][j].imshow(why_dog.to(<span class="st">"cpu"</span>).detach(),alpha<span class="op">=</span><span class="fl">0.5</span>,extent<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">511</span>,<span class="dv">511</span>,<span class="dv">0</span>),interpolation<span class="op">=</span><span class="st">'bilinear'</span>,cmap<span class="op">=</span><span class="st">'magma'</span>)</span>
<span id="cb136-17"><a href="#cb136-17" aria-hidden="true" tabindex="-1"></a>            ax[i][j].set_title(<span class="st">"dog(</span><span class="sc">%2f</span><span class="st">)"</span> <span class="op">%</span> dogprob)</span>
<span id="cb136-18"><a href="#cb136-18" aria-hidden="true" tabindex="-1"></a>        k<span class="op">=</span>k<span class="op">+</span><span class="dv">1</span> </span>
<span id="cb136-19"><a href="#cb136-19" aria-hidden="true" tabindex="-1"></a>fig.set_figwidth(<span class="dv">16</span>)            </span>
<span id="cb136-20"><a href="#cb136-20" aria-hidden="true" tabindex="-1"></a>fig.set_figheight(<span class="dv">16</span>)</span>
<span id="cb136-21"><a href="#cb136-21" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-26-ml_8w_2_files/figure-html/cell-89-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="4a25a8c7-c637-4e83-8a29-aba84dcfb182" data-execution_count="89">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>) </span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>k<span class="op">=</span><span class="dv">25</span></span>
<span id="cb137-3"><a href="#cb137-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb137-4"><a href="#cb137-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>): </span>
<span id="cb137-5"><a href="#cb137-5" aria-hidden="true" tabindex="-1"></a>        x, <span class="op">=</span> first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))</span>
<span id="cb137-6"><a href="#cb137-6" aria-hidden="true" tabindex="-1"></a>        why <span class="op">=</span> torch.einsum(<span class="st">'cb,abij -&gt; acij'</span>, net2[<span class="dv">2</span>].weight, net1(x))</span>
<span id="cb137-7"><a href="#cb137-7" aria-hidden="true" tabindex="-1"></a>        why_cat <span class="op">=</span> why[<span class="dv">0</span>,<span class="dv">0</span>,:,:] </span>
<span id="cb137-8"><a href="#cb137-8" aria-hidden="true" tabindex="-1"></a>        why_dog <span class="op">=</span> why[<span class="dv">0</span>,<span class="dv">1</span>,:,:] </span>
<span id="cb137-9"><a href="#cb137-9" aria-hidden="true" tabindex="-1"></a>        catprob, dogprob <span class="op">=</span> sftmax(net(x))[<span class="dv">0</span>][<span class="dv">0</span>].item(), sftmax(net(x))[<span class="dv">0</span>][<span class="dv">1</span>].item()</span>
<span id="cb137-10"><a href="#cb137-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> catprob<span class="op">&gt;</span>dogprob: </span>
<span id="cb137-11"><a href="#cb137-11" aria-hidden="true" tabindex="-1"></a>            dls.train.decode((x,))[<span class="dv">0</span>].squeeze().show(ax<span class="op">=</span>ax[i][j])</span>
<span id="cb137-12"><a href="#cb137-12" aria-hidden="true" tabindex="-1"></a>            ax[i][j].imshow(why_cat.to(<span class="st">"cpu"</span>).detach(),alpha<span class="op">=</span><span class="fl">0.5</span>,extent<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">511</span>,<span class="dv">511</span>,<span class="dv">0</span>),interpolation<span class="op">=</span><span class="st">'bilinear'</span>,cmap<span class="op">=</span><span class="st">'magma'</span>)</span>
<span id="cb137-13"><a href="#cb137-13" aria-hidden="true" tabindex="-1"></a>            ax[i][j].set_title(<span class="st">"cat(</span><span class="sc">%2f</span><span class="st">)"</span> <span class="op">%</span> catprob)</span>
<span id="cb137-14"><a href="#cb137-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>: </span>
<span id="cb137-15"><a href="#cb137-15" aria-hidden="true" tabindex="-1"></a>            dls.train.decode((x,))[<span class="dv">0</span>].squeeze().show(ax<span class="op">=</span>ax[i][j])</span>
<span id="cb137-16"><a href="#cb137-16" aria-hidden="true" tabindex="-1"></a>            ax[i][j].imshow(why_dog.to(<span class="st">"cpu"</span>).detach(),alpha<span class="op">=</span><span class="fl">0.5</span>,extent<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">511</span>,<span class="dv">511</span>,<span class="dv">0</span>),interpolation<span class="op">=</span><span class="st">'bilinear'</span>,cmap<span class="op">=</span><span class="st">'magma'</span>)</span>
<span id="cb137-17"><a href="#cb137-17" aria-hidden="true" tabindex="-1"></a>            ax[i][j].set_title(<span class="st">"dog(</span><span class="sc">%2f</span><span class="st">)"</span> <span class="op">%</span> dogprob)</span>
<span id="cb137-18"><a href="#cb137-18" aria-hidden="true" tabindex="-1"></a>        k<span class="op">=</span>k<span class="op">+</span><span class="dv">1</span> </span>
<span id="cb137-19"><a href="#cb137-19" aria-hidden="true" tabindex="-1"></a>fig.set_figwidth(<span class="dv">16</span>)            </span>
<span id="cb137-20"><a href="#cb137-20" aria-hidden="true" tabindex="-1"></a>fig.set_figheight(<span class="dv">16</span>)</span>
<span id="cb137-21"><a href="#cb137-21" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-26-ml_8w_2_files/figure-html/cell-90-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="2bb73b69-3e6b-4d15-c74a-7e8625aa694f" data-execution_count="90">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>) </span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a>k<span class="op">=</span><span class="dv">50</span></span>
<span id="cb138-3"><a href="#cb138-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb138-4"><a href="#cb138-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>): </span>
<span id="cb138-5"><a href="#cb138-5" aria-hidden="true" tabindex="-1"></a>        x, <span class="op">=</span> first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))</span>
<span id="cb138-6"><a href="#cb138-6" aria-hidden="true" tabindex="-1"></a>        why <span class="op">=</span> torch.einsum(<span class="st">'cb,abij -&gt; acij'</span>, net2[<span class="dv">2</span>].weight, net1(x))</span>
<span id="cb138-7"><a href="#cb138-7" aria-hidden="true" tabindex="-1"></a>        why_cat <span class="op">=</span> why[<span class="dv">0</span>,<span class="dv">0</span>,:,:] </span>
<span id="cb138-8"><a href="#cb138-8" aria-hidden="true" tabindex="-1"></a>        why_dog <span class="op">=</span> why[<span class="dv">0</span>,<span class="dv">1</span>,:,:] </span>
<span id="cb138-9"><a href="#cb138-9" aria-hidden="true" tabindex="-1"></a>        catprob, dogprob <span class="op">=</span> sftmax(net(x))[<span class="dv">0</span>][<span class="dv">0</span>].item(), sftmax(net(x))[<span class="dv">0</span>][<span class="dv">1</span>].item()</span>
<span id="cb138-10"><a href="#cb138-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> catprob<span class="op">&gt;</span>dogprob: </span>
<span id="cb138-11"><a href="#cb138-11" aria-hidden="true" tabindex="-1"></a>            dls.train.decode((x,))[<span class="dv">0</span>].squeeze().show(ax<span class="op">=</span>ax[i][j])</span>
<span id="cb138-12"><a href="#cb138-12" aria-hidden="true" tabindex="-1"></a>            ax[i][j].imshow(why_cat.to(<span class="st">"cpu"</span>).detach(),alpha<span class="op">=</span><span class="fl">0.5</span>,extent<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">511</span>,<span class="dv">511</span>,<span class="dv">0</span>),interpolation<span class="op">=</span><span class="st">'bilinear'</span>,cmap<span class="op">=</span><span class="st">'magma'</span>)</span>
<span id="cb138-13"><a href="#cb138-13" aria-hidden="true" tabindex="-1"></a>            ax[i][j].set_title(<span class="st">"cat(</span><span class="sc">%2f</span><span class="st">)"</span> <span class="op">%</span> catprob)</span>
<span id="cb138-14"><a href="#cb138-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>: </span>
<span id="cb138-15"><a href="#cb138-15" aria-hidden="true" tabindex="-1"></a>            dls.train.decode((x,))[<span class="dv">0</span>].squeeze().show(ax<span class="op">=</span>ax[i][j])</span>
<span id="cb138-16"><a href="#cb138-16" aria-hidden="true" tabindex="-1"></a>            ax[i][j].imshow(why_dog.to(<span class="st">"cpu"</span>).detach(),alpha<span class="op">=</span><span class="fl">0.5</span>,extent<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">511</span>,<span class="dv">511</span>,<span class="dv">0</span>),interpolation<span class="op">=</span><span class="st">'bilinear'</span>,cmap<span class="op">=</span><span class="st">'magma'</span>)</span>
<span id="cb138-17"><a href="#cb138-17" aria-hidden="true" tabindex="-1"></a>            ax[i][j].set_title(<span class="st">"dog(</span><span class="sc">%2f</span><span class="st">)"</span> <span class="op">%</span> dogprob)</span>
<span id="cb138-18"><a href="#cb138-18" aria-hidden="true" tabindex="-1"></a>        k<span class="op">=</span>k<span class="op">+</span><span class="dv">1</span> </span>
<span id="cb138-19"><a href="#cb138-19" aria-hidden="true" tabindex="-1"></a>fig.set_figwidth(<span class="dv">16</span>)            </span>
<span id="cb138-20"><a href="#cb138-20" aria-hidden="true" tabindex="-1"></a>fig.set_figheight(<span class="dv">16</span>)</span>
<span id="cb138-21"><a href="#cb138-21" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-26-ml_8w_2_files/figure-html/cell-91-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="39932f9f-239e-4334-eda6-cfe1cb17fa8c" data-execution_count="91">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>) </span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>k<span class="op">=</span><span class="dv">75</span></span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb139-4"><a href="#cb139-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>): </span>
<span id="cb139-5"><a href="#cb139-5" aria-hidden="true" tabindex="-1"></a>        x, <span class="op">=</span> first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))</span>
<span id="cb139-6"><a href="#cb139-6" aria-hidden="true" tabindex="-1"></a>        why <span class="op">=</span> torch.einsum(<span class="st">'cb,abij -&gt; acij'</span>, net2[<span class="dv">2</span>].weight, net1(x))</span>
<span id="cb139-7"><a href="#cb139-7" aria-hidden="true" tabindex="-1"></a>        why_cat <span class="op">=</span> why[<span class="dv">0</span>,<span class="dv">0</span>,:,:] </span>
<span id="cb139-8"><a href="#cb139-8" aria-hidden="true" tabindex="-1"></a>        why_dog <span class="op">=</span> why[<span class="dv">0</span>,<span class="dv">1</span>,:,:] </span>
<span id="cb139-9"><a href="#cb139-9" aria-hidden="true" tabindex="-1"></a>        catprob, dogprob <span class="op">=</span> sftmax(net(x))[<span class="dv">0</span>][<span class="dv">0</span>].item(), sftmax(net(x))[<span class="dv">0</span>][<span class="dv">1</span>].item()</span>
<span id="cb139-10"><a href="#cb139-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> catprob<span class="op">&gt;</span>dogprob: </span>
<span id="cb139-11"><a href="#cb139-11" aria-hidden="true" tabindex="-1"></a>            dls.train.decode((x,))[<span class="dv">0</span>].squeeze().show(ax<span class="op">=</span>ax[i][j])</span>
<span id="cb139-12"><a href="#cb139-12" aria-hidden="true" tabindex="-1"></a>            ax[i][j].imshow(why_cat.to(<span class="st">"cpu"</span>).detach(),alpha<span class="op">=</span><span class="fl">0.5</span>,extent<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">511</span>,<span class="dv">511</span>,<span class="dv">0</span>),interpolation<span class="op">=</span><span class="st">'bilinear'</span>,cmap<span class="op">=</span><span class="st">'magma'</span>)</span>
<span id="cb139-13"><a href="#cb139-13" aria-hidden="true" tabindex="-1"></a>            ax[i][j].set_title(<span class="st">"cat(</span><span class="sc">%2f</span><span class="st">)"</span> <span class="op">%</span> catprob)</span>
<span id="cb139-14"><a href="#cb139-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>: </span>
<span id="cb139-15"><a href="#cb139-15" aria-hidden="true" tabindex="-1"></a>            dls.train.decode((x,))[<span class="dv">0</span>].squeeze().show(ax<span class="op">=</span>ax[i][j])</span>
<span id="cb139-16"><a href="#cb139-16" aria-hidden="true" tabindex="-1"></a>            ax[i][j].imshow(why_dog.to(<span class="st">"cpu"</span>).detach(),alpha<span class="op">=</span><span class="fl">0.5</span>,extent<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">511</span>,<span class="dv">511</span>,<span class="dv">0</span>),interpolation<span class="op">=</span><span class="st">'bilinear'</span>,cmap<span class="op">=</span><span class="st">'magma'</span>)</span>
<span id="cb139-17"><a href="#cb139-17" aria-hidden="true" tabindex="-1"></a>            ax[i][j].set_title(<span class="st">"dog(</span><span class="sc">%2f</span><span class="st">)"</span> <span class="op">%</span> dogprob)</span>
<span id="cb139-18"><a href="#cb139-18" aria-hidden="true" tabindex="-1"></a>        k<span class="op">=</span>k<span class="op">+</span><span class="dv">1</span> </span>
<span id="cb139-19"><a href="#cb139-19" aria-hidden="true" tabindex="-1"></a>fig.set_figwidth(<span class="dv">16</span>)            </span>
<span id="cb139-20"><a href="#cb139-20" aria-hidden="true" tabindex="-1"></a>fig.set_figheight(<span class="dv">16</span>)</span>
<span id="cb139-21"><a href="#cb139-21" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-26-ml_8w_2_files/figure-html/cell-92-output-1.png" class="img-fluid"></p>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>