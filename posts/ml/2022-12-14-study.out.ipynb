{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# study\n",
        "\n",
        "SEOYEON CHOI  \n",
        "12/8/22\n",
        "\n",
        "> study\n",
        "\n",
        "# a,b,c,d,e 를 표현함에 있어서 3개의 은닉노드면 충분하다.\n",
        "\n",
        "-   1개의 은닉노드 -\\> 2개의 문자를 표현할 수 있음.\n",
        "-   2개의 은닉노드 -\\> 4개의 문자를 표현할 수 있음.\n",
        "-   3개의 은닉노드 -\\> 8개의 문자를 표현할 수 있음.\n",
        "\n",
        "# torch.nn.RNN(4,2)는 torch.nn.RNNCell(4,2)의 batch 버전이다.\n",
        "\n",
        "(for문이 포함된 버전이다)\n",
        "\n",
        "# torch.nn.LSTM에서 batch size\n",
        "\n",
        "batch size = 전체데이터는 몇 개의 시계열이 있는지 = 전체 데이터를 몇개의\n",
        "시계열로 쪼갤지\n",
        "\n",
        "-   fastai, Dataloader의 batchsize 는 한 뭉치에 몇 개 있는지\n",
        "\n",
        "# 원래 1은 단순히 observation의 차원이 아니다. 즉 $x_{n \\times p}$ 에서 $n$에 대응하는 차원으로 생각할 수 없다.\n",
        "\n",
        "-   그런데 (1) 단방향 (2) 조각내지 않은 시계열 (3) 중첩하지 않은\n",
        "    순환망에 한정하여서는 observation 처럼 생각해도 무방하다.\n",
        "\n",
        "-   현실적으로 (1)-(3)이 아닌 조건에서는 Cell 단위로 연산을 이용할 일이\n",
        "    없다. (느리거든요) // 그냥 이해용으로 구현\n",
        "\n",
        "-   torch.nn.RNN 혹은 torch.nn.LSTM 으로 네트워크를 구성할시 \\_water의\n",
        "    dim을 명시할 일도 없다.\n",
        "\n",
        "-   오로지 고려해야 할 것은 입력시계열을 조각낼지 조각내지 않을지"
      ],
      "id": "b60a86bb-8ee7-4a93-a728-f809c9980bad"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "751edd8a-51f6-4dd7-9924-8b8def4d9ab2"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "sig = torch.nn.Sigmoid()\n",
        "soft = torch.nn.Softmax(dim=1)\n",
        "tanh = torch.nn.Tanh()"
      ],
      "id": "e54dcd7e-d124-4801-80f6-e77623660ce0"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f(txt,mapping):\n",
        "    return [mapping[key] for key in txt] "
      ],
      "id": "9044775e-ce3c-4a27-beb1-c7b7fb0638c8"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = list('ab')*100\n",
        "txt_x = txt[:-1]\n",
        "txt_y = txt[1:]"
      ],
      "id": "2fe49f2f-fd08-4def-8d2f-1b5471f2c0a2"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "mapping = {'a':[1,0],'b':[0,1]}\n",
        "x = torch.tensor(f(txt_x,mapping)).float().reshape(-1,2)\n",
        "y = torch.tensor(f(txt_y,mapping)).float().reshape(-1,2)"
      ],
      "id": "f3fee3c6-46a9-452e-a279-7820ce391419"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class mynet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ## 우리가 사용할 레이어를 정의 \n",
        "        self.l1 = torch.nn.Linear(in_features=2,out_features=1,bias=True)\n",
        "        self.a1 = torch.nn.Tanh()\n",
        "        self.l2 = torch.nn.Linear(in_features=1,out_features=2,bias=False)\n",
        "        ## 레이어 정의 끝\n",
        "    def forward(self,x):\n",
        "        ## yhat을 어떻게 구할것인지 정의 \n",
        "        yhat = self.l2(self.a1(self.l1(x)))\n",
        "        ## 정의 끝\n",
        "        return yhat"
      ],
      "id": "cc38f2d7-0cd8-4321-9a00-67a0ca8322e5"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = mynet()"
      ],
      "id": "b700b87c-69ea-47ad-90e2-92e900a575a2"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())"
      ],
      "id": "e39bb98b-031f-4620-b06b-c482bbe3e586"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoc in range(5000):\n",
        "    yhat = net(x)\n",
        "    loss = loss_fn(yhat,y)\n",
        "    loss.backward()\n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "18387b74-9f54-43bb-a34d-352f73a892e3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 임베딩"
      ],
      "id": "137fdbfd-5fd9-4179-8934-a31998f50fc4"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(tensor([0, 1, 0, 1, 0]), tensor([1, 0, 1, 0, 1]))"
            ]
          }
        }
      ],
      "source": [
        "mapping = {'a':0,'b':1}\n",
        "x = torch.tensor(f(txt_x,mapping))\n",
        "y = torch.tensor(f(txt_y,mapping))\n",
        "x[:5],y[:5]"
      ],
      "id": "95b28691-67b9-4e10-89a3-40541ad554cf"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class mynet2(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ## 우리가 사용할 레이어를 정의 \n",
        "        self.l1 = torch.nn.Embedding(num_embeddings=2,embedding_dim=1)\n",
        "        self.a1 = torch.nn.Tanh()\n",
        "        self.l2 = torch.nn.Linear(in_features=1,out_features=2)\n",
        "        ## 레이어 정의 끝\n",
        "    def forward(self,x):\n",
        "        ## yhat을 어떻게 구할것인지 정의 \n",
        "        yhat = self.l2(self.a1(self.l1(x)))\n",
        "        ## 정의 끝\n",
        "        return yhat"
      ],
      "id": "ac8aba49-8fa9-4be4-9179-2a21cca5469a"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = mynet2()"
      ],
      "id": "30be1282-a2d0-40a1-a316-e849597f18a7"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())"
      ],
      "id": "c9fff91c-9526-4a62-874b-f740f077e1e7"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoc in range(5000):\n",
        "    yhat = net(x)\n",
        "    loss = loss_fn(yhat,y)\n",
        "    loss.backward()\n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "b2d14057-a251-4cd1-878f-b1a74767c80e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 두 개의 은닉노드 이용"
      ],
      "id": "50491edd-1bf5-45cd-8e71-c412fa8e039b"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = list('abcd')*100\n",
        "txt_x = txt[:-1]\n",
        "txt_y = txt[1:]"
      ],
      "id": "4db00d17-7350-43a8-b36c-f61b6721f42b"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3, 0]), tensor([1, 2, 3, 0, 1]))"
            ]
          }
        }
      ],
      "source": [
        "mapping = {'a':0,'b':1,'c':2,'d':3}\n",
        "x = torch.tensor(f(txt_x,mapping))\n",
        "y = torch.tensor(f(txt_y,mapping))\n",
        "x[:5],y[:5]"
      ],
      "id": "3224b36f-3400-4bef-af19-df25388e4676"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "l1=torch.nn.Embedding(num_embeddings=4,embedding_dim=2)"
      ],
      "id": "ea3aed89-1b4f-4680-8bea-a0d86b770bb3"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "a1 = torch.nn.Tanh()"
      ],
      "id": "3f25f102-e256-434b-b5dd-6874fcc1e5c9"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "l2 = torch.nn.Linear(in_features=2,out_features=4)"
      ],
      "id": "72cec570-56fa-422f-8a0c-57a93da6516f"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = torch.nn.Sequential(\n",
        "    l1,a1,l2)"
      ],
      "id": "66ff0dfa-f5b3-4bff-948a-2989344ae431"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())"
      ],
      "id": "199f1167-7422-4a56-bb71-6f6fddc85aac"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoc in range(5000):\n",
        "    yhat=net(x)\n",
        "    loss = loss_fn(yhat,y)\n",
        "    loss.backward()\n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "517df6c5-8434-4381-b78a-09502ccdecb4"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "hidden = net[:-1](x).data\n",
        "yhat = soft(net(x)).data"
      ],
      "id": "2154fca7-ded8-4b52-bf0c-0a30cbcedc7d"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Embedding(4, 2)\n",
              "  (1): Tanh()\n",
              ")"
            ]
          }
        }
      ],
      "source": [
        "net[:-1]"
      ],
      "id": "e0c123ce-518f-473f-b3b5-dc7d5bba09fa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "결과 시각화 코드 10주\n",
        "\n",
        "## 순환신경망 Class 사용 RNN\n",
        "\n",
        "10주"
      ],
      "id": "90b77a77-bae0-4b84-825f-0c96e321a934"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = list('AbAcAd')*100\n",
        "txt_x = txt[:-1]\n",
        "txt_y = txt[1:]\n",
        "x = torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))\n",
        "y = torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))\n",
        "x= torch.nn.functional.one_hot(x).float()\n",
        "y= torch.nn.functional.one_hot(y).float()"
      ],
      "id": "7833f126-8b8e-4962-988d-a317601f230e"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "class rNNCell(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i2h = torch.nn.Linear(4,2) \n",
        "        self.h2h = torch.nn.Linear(2,2) \n",
        "        self.tanh = torch.nn.Tanh()\n",
        "    def forward(self,x,hidden):\n",
        "        hidden = self.tanh(self.i2h(x)+self.h2h(hidden))\n",
        "        return hidden"
      ],
      "id": "3d72d672-e651-4d67-b00a-7eed1cb78e20"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(43052)\n",
        "rnncell = rNNCell()"
      ],
      "id": "c5bf5f3d-d371-49e8-a3ba-2c3cf9f4de85"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(43052)\n",
        "cook = torch.nn.Linear(2,4) "
      ],
      "id": "e71ffb79-938b-495d-ad73-f285781acb87"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss() \n",
        "optimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))"
      ],
      "id": "b72c3e0f-bcc3-4e0b-a6f5-f132d01c7ec7"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "T = len(x) \n",
        "for epoc in range(100): \n",
        "    ## 1~2\n",
        "    loss = 0 \n",
        "    ht = torch.zeros(1,2) \n",
        "    for t in range(T):\n",
        "        xt,yt = x[[t]], y[[t]]\n",
        "        ht = rnncell(xt,ht) \n",
        "        ot = cook(ht) \n",
        "        loss = loss + loss_fn(ot,yt) \n",
        "    ## 3 \n",
        "    loss.backward()\n",
        "    ## 4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "5d418ae7-3ebd-4478-88c1-0ebdf86756ad"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "시각화코드는 10주_순환신경망구현1-성공에\n",
        "\n",
        "## 순환신경망 RNN"
      ],
      "id": "f56baad0-480d-43ce-b1b1-63eb00bee3b4"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = list('AbAcAd')*100\n",
        "txt_x = txt[:-1]\n",
        "txt_y = txt[1:]\n",
        "x = torch.nn.functional.one_hot(torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))).float()\n",
        "y = torch.nn.functional.one_hot(torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))).float()"
      ],
      "id": "4d8bc7cf-b0b8-4d19-a6c5-f3f8a2c6af59"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(2) #1 \n",
        "rnn = torch.nn.RNN(4,3).to(\"cuda:0\") \n",
        "cook = torch.nn.Linear(3,4).to(\"cuda:0\")"
      ],
      "id": "83ac829d-0694-4a06-b28b-3c88e4b55c74"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters()))"
      ],
      "id": "38d7b643-0bde-4d31-8ac7-3e3d5b6cd153"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "_water = torch.zeros(1,3).to(\"cuda:0\") \n",
        "for epoc in range(500):\n",
        "    ## 1\n",
        "    hidden,hT = rnn(x.to(\"cuda:0\"),_water) \n",
        "    output = cook(hidden) \n",
        "    ## 2 \n",
        "    loss = loss_fn(output,y.to(\"cuda:0\")) \n",
        "    ## 3 \n",
        "    loss.backward()\n",
        "    ## 4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "14c8002b-b943-40ce-abb7-5f0bb8b02237"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "yhat = soft(output)"
      ],
      "id": "10f7a604-b424-4dc3-a0aa-db2d74103d69"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 순환신경망 Class 사용 LSTM"
      ],
      "id": "5e7f0559-39b7-4cc3-ad2d-f5b88b398ae8"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = list('hi?hello!!')*100 \n",
        "txt_x = txt[:-1]\n",
        "txt_y = txt[1:]\n",
        "mapping = {'!':0, '?':1,'h':2,'i':3,'e':4,'l':5,'o':6} \n",
        "x= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\n",
        "y= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
      ],
      "id": "79aa780c-a402-4002-ac6d-c02c56ab6a14"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "class lSTMCell(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i2h = torch.nn.Linear(7,16)\n",
        "        self.h2h = torch.nn.Linear(4,16) \n",
        "        self.tanh = torch.nn.Tanh()\n",
        "    def forward(self,xt,past):\n",
        "        ht,ct = past \n",
        "        ifgo = self.i2h(xt) + self.h2h(ht) \n",
        "        it = sig(ifgo[0:4])\n",
        "        ft = sig(ifgo[4:8])\n",
        "        gt = tanh(ifgo[8:12])\n",
        "        ot = sig(ifgo[12:16])\n",
        "        ct = ft*ct + it*gt\n",
        "        ht = ot*self.tanh(ct) \n",
        "        return ht,ct"
      ],
      "id": "e3f87c6c-49a2-4e5d-9ea5-13756fbf9e6f"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "lstmcell = lSTMCell().to(\"cuda:0\")\n",
        "linr = torch.nn.Linear(4,7).to(\"cuda:0\")\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(list(lstmcell.parameters())+list(linr.parameters()),lr=0.1)"
      ],
      "id": "0e2a1e14-1a75-4af7-865f-6fc4e6635ec4"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 초기값셋팅\n",
        "torch.manual_seed(43052) \n",
        "_lstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\")\n",
        "_linr = torch.nn.Linear(4,7).to(\"cuda:0\")\n",
        "lstmcell.i2h.weight.data = _lstmcell.weight_ih.data \n",
        "lstmcell.h2h.weight.data = _lstmcell.weight_hh.data \n",
        "lstmcell.i2h.bias.data = _lstmcell.bias_ih.data\n",
        "lstmcell.h2h.bias.data = _lstmcell.bias_hh.data\n",
        "linr.weight.data = _linr.weight.data \n",
        "linr.bias.data = _linr.bias.data "
      ],
      "id": "153b33ba-634b-41f3-a618-e8001ca07cf1"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoc in range(10):\n",
        "    ## 1\n",
        "    hidden = []     \n",
        "    ht = torch.zeros(4).to(\"cuda:0\")\n",
        "    ct = torch.zeros(4).to(\"cuda:0\")\n",
        "    for xt,yt in zip(x,y): \n",
        "        ht,ct = lstmcell(xt,(ht,ct))\n",
        "        hidden.append(ht) \n",
        "    hidden = torch.stack(hidden)\n",
        "    output = linr(hidden) \n",
        "    ## 2 \n",
        "    loss = loss_fn(output,y)\n",
        "    ## 3 \n",
        "    loss.backward()\n",
        "    ## 4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "ea922513-6b1c-4017-bdbb-7f5008586f04"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "yhat = soft(output)"
      ],
      "id": "60611267-99b5-4e31-99d9-d41b043dbdf4"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([[0.0909, 0.0859, 0.0356,  ..., 0.1820, 0.2308, 0.1257],\n",
              "        [0.3443, 0.1629, 0.2108,  ..., 0.1008, 0.0506, 0.0774],\n",
              "        [0.3998, 0.0325, 0.5100,  ..., 0.0133, 0.0269, 0.0119],\n",
              "        ...,\n",
              "        [0.0655, 0.0525, 0.0455,  ..., 0.1652, 0.2569, 0.2828],\n",
              "        [0.3850, 0.0844, 0.3754,  ..., 0.0464, 0.0423, 0.0478],\n",
              "        [0.4012, 0.0217, 0.5328,  ..., 0.0084, 0.0254, 0.0065]],\n",
              "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          }
        }
      ],
      "source": [
        "yhat"
      ],
      "id": "b5d78a86-0df5-4dc7-a6b7-5fb7c926ec90"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 순환신경망 LSTM"
      ],
      "id": "cc4c77c7-2584-4d6a-80a4-c637c3e50728"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = (['one',',','two',',','three',',','four',',','five',',']*100)[:-1]\n",
        "mapping = {',':0, 'one':1, 'two':2, 'three':3, 'four':4, 'five':5} \n",
        "txt_x = txt[:-1]\n",
        "txt_y = txt[1:] \n",
        "x = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\n",
        "y = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
      ],
      "id": "cee79c3f-cf54-41fe-a8ee-96072b597600"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(43052) \n",
        "lstm = torch.nn.LSTM(6,20).to(\"cuda:0\") \n",
        "linr = torch.nn.Linear(20,6).to(\"cuda:0\") \n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)"
      ],
      "id": "6d32ef41-1896-4a27-9410-c9ecbedcad40"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "_water = torch.zeros(1,20).to(\"cuda:0\")\n",
        "for epoc in range(50):\n",
        "    ## 1 \n",
        "    hidden, (hT,cT) =lstm(x,(_water,_water))\n",
        "    output = linr(hidden) \n",
        "    ## 2 \n",
        "    loss = loss_fn(output,y) \n",
        "    ## 3 \n",
        "    loss.backward()\n",
        "    ## 4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()     "
      ],
      "id": "f639801b-878d-4474-bb96-38cb924a6450"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([[9.9875e-01, 1.5434e-06, 6.5715e-04, 1.8973e-05, 9.5753e-05, 4.7651e-04],\n",
              "        [3.0184e-06, 3.7971e-05, 9.8694e-01, 3.6741e-03, 3.6129e-04, 8.9867e-03],\n",
              "        [9.9999e-01, 2.9932e-06, 5.9745e-07, 8.3266e-06, 1.0668e-07, 4.8888e-07],\n",
              "        ...,\n",
              "        [3.9604e-05, 8.6161e-06, 1.5918e-03, 1.1244e-07, 9.9808e-01, 2.7556e-04],\n",
              "        [9.9993e-01, 3.3252e-07, 9.5155e-06, 4.8129e-07, 2.7274e-05, 3.2102e-05],\n",
              "        [8.0918e-07, 8.0716e-03, 5.9763e-04, 7.7044e-05, 6.8931e-05, 9.9118e-01]],\n",
              "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          }
        }
      ],
      "source": [
        "soft(output)"
      ],
      "id": "77f28940-d15e-4649-9497-8ad5f82439ca"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 조각난 시계열\n",
        "\n",
        "12주차"
      ],
      "id": "aafb3040-1f2f-435c-9609-8cfd14b8521d"
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = list('hi!')*3 + list('hi?')*3\n",
        "txt_x = txt[:-1] \n",
        "txt_y = txt[1:] \n",
        "mapping = {'!':0, '?':1, 'h':2, 'i':3} \n",
        "x = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\n",
        "y = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\") "
      ],
      "id": "62c9011a-89b7-40c7-b5f7-f366ab570a40"
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(43052) \n",
        "lstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\n",
        "linr = torch.nn.Linear(10,4).to(\"cuda:0\")"
      ],
      "id": "7c04d20c-0824-4182-afb2-b59d94bdac7a"
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss() \n",
        "optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)"
      ],
      "id": "987872bb-012d-4018-8228-855179f4b63d"
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoc in range(100):\n",
        "    ## 1 \n",
        "    hidden, _ = lstm(x) \n",
        "    output = linr(hidden) \n",
        "    ## 2 \n",
        "    loss = loss_fn(output,y) \n",
        "    ## 3 \n",
        "    loss.backward() \n",
        "    ## 4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "e9540bb9-8684-4b82-9ae0-05fa798352df"
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1462eb7510>"
            ]
          }
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPQAAAOfCAYAAAD/9O76AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nn/msLkgAAAAASUVORK5CYII=\n"
          }
        }
      ],
      "source": [
        "hidden, _ = lstm(x)\n",
        "plt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)"
      ],
      "id": "85915728-2f59-4878-ae0a-55949040d412"
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = list('hi!')*3 + list('hi?')*3\n",
        "txt1= txt[:9]\n",
        "txt2= txt[9:]\n",
        "txt1_x = txt1[:-1] \n",
        "txt1_y = txt1[1:] \n",
        "txt2_x = txt2[:-1] \n",
        "txt2_y = txt2[1:] \n",
        "mapping = {'!':0, '?':1, 'h':2, 'i':3} \n",
        "x1 = torch.nn.functional.one_hot(torch.tensor(f(txt1_x,mapping))).float().to(\"cuda:0\")\n",
        "y1 = torch.nn.functional.one_hot(torch.tensor(f(txt1_y,mapping))).float().to(\"cuda:0\")\n",
        "x2 = torch.nn.functional.one_hot(torch.tensor(f(txt2_x,mapping))).float().to(\"cuda:0\")\n",
        "y2 = torch.nn.functional.one_hot(torch.tensor(f(txt2_y,mapping))).float().to(\"cuda:0\")\n",
        "xx = torch.stack([x1,x2],axis=1)\n",
        "yy = torch.stack([y1,y2],axis=1)"
      ],
      "id": "c1277e27-b77b-41f4-8625-311cf2b9ae33"
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(43052) \n",
        "lstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\n",
        "linr = torch.nn.Linear(10,4).to(\"cuda:0\")"
      ],
      "id": "a5918668-1f36-43a9-a042-3c86ab52b6da"
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss() \n",
        "optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)"
      ],
      "id": "bab941d6-6209-4a82-9644-dde28115817f"
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoc in range(100):\n",
        "    ## 1 \n",
        "    hidden, _ = lstm(xx) \n",
        "    output = linr(hidden) \n",
        "    ## 2 \n",
        "    loss = loss_fn(output[:,0,:],yy[:,0,:]) + loss_fn(output[:,1,:],yy[:,1,:])\n",
        "    ## 3 \n",
        "    loss.backward() \n",
        "    ## 4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "02cc9962-4287-4af6-8408-f813b8478580"
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1462e93690>"
            ]
          }
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAD8CAYAAAABraMFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\naGzQMQAAAABJRU5ErkJggg==\n"
          }
        }
      ],
      "source": [
        "fig , ax = plt.subplots(1,2) \n",
        "ax[0].matshow(soft(output[:,0,:]).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n",
        "ax[1].matshow(soft(output[:,1,:]).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)"
      ],
      "id": "4cba8ff3-9713-4908-9b01-0c5807ba2022"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  }
}