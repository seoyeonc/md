{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# study\n",
        "\n",
        "SEOYEON CHOI  \n",
        "2022-12-08\n",
        "\n",
        "> study\n",
        "\n",
        "# a,b,c,d,e 를 표현함에 있어서 3개의 은닉노드면 충분하다.\n",
        "\n",
        "-   1개의 은닉노드 -\\> 2개의 문자를 표현할 수 있음.\n",
        "-   2개의 은닉노드 -\\> 4개의 문자를 표현할 수 있음.\n",
        "-   3개의 은닉노드 -\\> 8개의 문자를 표현할 수 있음.\n",
        "\n",
        "# torch.nn.RNN(4,2)는 torch.nn.RNNCell(4,2)의 batch 버전이다.\n",
        "\n",
        "(for문이 포함된 버전이다)\n",
        "\n",
        "# torch.nn.LSTM에서 batch size\n",
        "\n",
        "batch size = 전체데이터는 몇 개의 시계열이 있는지 = 전체 데이터를 몇개의\n",
        "시계열로 쪼갤지\n",
        "\n",
        "-   fastai, Dataloader의 batchsize 는 한 뭉치에 몇 개 있는지\n",
        "\n",
        "# 원래 1은 단순히 observation의 차원이 아니다. 즉 $x_{n \\times p}$ 에서 $n$에 대응하는 차원으로 생각할 수 없다.\n",
        "\n",
        "-   그런데 (1) 단방향 (2) 조각내지 않은 시계열 (3) 중첩하지 않은\n",
        "    순환망에 한정하여서는 observation 처럼 생각해도 무방하다.\n",
        "\n",
        "-   현실적으로 (1)-(3)이 아닌 조건에서는 Cell 단위로 연산을 이용할 일이\n",
        "    없다. (느리거든요) // 그냥 이해용으로 구현\n",
        "\n",
        "-   torch.nn.RNN 혹은 torch.nn.LSTM 으로 네트워크를 구성할시 \\_water의\n",
        "    dim을 명시할 일도 없다.\n",
        "\n",
        "-   오로지 고려해야 할 것은 입력시계열을 조각낼지 조각내지 않을지"
      ],
      "id": "e0d90b2c-e055-4ee5-a4d4-a313b928e4a9"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "1ed350a3-3b24-4f46-8b09-4d932c070f02"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "sig = torch.nn.Sigmoid()\n",
        "soft = torch.nn.Softmax(dim=1)\n",
        "tanh = torch.nn.Tanh()"
      ],
      "id": "146b03a8-7847-4be7-9c55-ebf217af2429"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f(txt,mapping):\n",
        "    return [mapping[key] for key in txt] "
      ],
      "id": "a4444e97-576d-4ec3-bb38-01283de440d9"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = list('ab')*100\n",
        "txt_x = txt[:-1]\n",
        "txt_y = txt[1:]"
      ],
      "id": "3fb33ede-92a6-4f3f-970a-c0a57e43533b"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "mapping = {'a':[1,0],'b':[0,1]}\n",
        "x = torch.tensor(f(txt_x,mapping)).float().reshape(-1,2)\n",
        "y = torch.tensor(f(txt_y,mapping)).float().reshape(-1,2)"
      ],
      "id": "9203df12-bd96-4193-aa9a-17dc676d3d1f"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class mynet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ## 우리가 사용할 레이어를 정의 \n",
        "        self.l1 = torch.nn.Linear(in_features=2,out_features=1,bias=True)\n",
        "        self.a1 = torch.nn.Tanh()\n",
        "        self.l2 = torch.nn.Linear(in_features=1,out_features=2,bias=False)\n",
        "        ## 레이어 정의 끝\n",
        "    def forward(self,x):\n",
        "        ## yhat을 어떻게 구할것인지 정의 \n",
        "        yhat = self.l2(self.a1(self.l1(x)))\n",
        "        ## 정의 끝\n",
        "        return yhat"
      ],
      "id": "3a75d95b-cfed-46dc-a30f-ee45ae11b63b"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = mynet()"
      ],
      "id": "c6e23f25-a66b-4358-8b3c-cf7d6c7ada75"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())"
      ],
      "id": "a114826a-065c-4f1c-b0d7-93638b2acc6a"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoc in range(5000):\n",
        "    yhat = net(x)\n",
        "    loss = loss_fn(yhat,y)\n",
        "    loss.backward()\n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "4c26bb2d-5d45-40f5-967e-9e0b9bf07551"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 임베딩"
      ],
      "id": "94d7ecb7-8184-4203-b1c0-19fb71334d76"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(tensor([0, 1, 0, 1, 0]), tensor([1, 0, 1, 0, 1]))"
            ]
          }
        }
      ],
      "source": [
        "mapping = {'a':0,'b':1}\n",
        "x = torch.tensor(f(txt_x,mapping))\n",
        "y = torch.tensor(f(txt_y,mapping))\n",
        "x[:5],y[:5]"
      ],
      "id": "02048300-2ff2-49d7-9a19-06b2762fc71d"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class mynet2(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ## 우리가 사용할 레이어를 정의 \n",
        "        self.l1 = torch.nn.Embedding(num_embeddings=2,embedding_dim=1)\n",
        "        self.a1 = torch.nn.Tanh()\n",
        "        self.l2 = torch.nn.Linear(in_features=1,out_features=2)\n",
        "        ## 레이어 정의 끝\n",
        "    def forward(self,x):\n",
        "        ## yhat을 어떻게 구할것인지 정의 \n",
        "        yhat = self.l2(self.a1(self.l1(x)))\n",
        "        ## 정의 끝\n",
        "        return yhat"
      ],
      "id": "bc5f457e-b4f8-422b-b1af-7de5b35853c1"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = mynet2()"
      ],
      "id": "1e8b5b2f-37f0-4a31-b242-f70c7be07ceb"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())"
      ],
      "id": "4146115f-fc77-41e9-8a2e-12e50815bdfa"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoc in range(5000):\n",
        "    yhat = net(x)\n",
        "    loss = loss_fn(yhat,y)\n",
        "    loss.backward()\n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "5d982ca7-c9c1-44eb-b20f-7fb16645bcf7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 두 개의 은닉노드 이용"
      ],
      "id": "bc1c8bfe-2f22-4d52-96f5-f3b223d371ae"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = list('abcd')*100\n",
        "txt_x = txt[:-1]\n",
        "txt_y = txt[1:]"
      ],
      "id": "6750eff3-3957-4b2e-ae90-9b97fd8a656e"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3, 0]), tensor([1, 2, 3, 0, 1]))"
            ]
          }
        }
      ],
      "source": [
        "mapping = {'a':0,'b':1,'c':2,'d':3}\n",
        "x = torch.tensor(f(txt_x,mapping))\n",
        "y = torch.tensor(f(txt_y,mapping))\n",
        "x[:5],y[:5]"
      ],
      "id": "a595c890-4b47-4919-9e09-f06b684b8404"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "l1=torch.nn.Embedding(num_embeddings=4,embedding_dim=2)"
      ],
      "id": "bef382fc-4458-4036-b273-4cb428fa07c3"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "a1 = torch.nn.Tanh()"
      ],
      "id": "aeb54070-36ae-484e-b4e3-ff4fb5adede1"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "l2 = torch.nn.Linear(in_features=2,out_features=4)"
      ],
      "id": "404dd0e4-c67d-43ac-977c-19ba8e0978b9"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = torch.nn.Sequential(\n",
        "    l1,a1,l2)"
      ],
      "id": "4ca48e0c-887a-4eb1-8be7-986d6cf97cc2"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())"
      ],
      "id": "af9b4ed8-7bd9-4631-9b9f-4bdc79739572"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoc in range(5000):\n",
        "    yhat=net(x)\n",
        "    loss = loss_fn(yhat,y)\n",
        "    loss.backward()\n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "1dafc316-27c4-429f-bba4-1d1ea3d8cf4f"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "hidden = net[:-1](x).data\n",
        "yhat = soft(net(x)).data"
      ],
      "id": "55575dae-6bae-4150-828d-5cfb4d7502e1"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Embedding(4, 2)\n",
              "  (1): Tanh()\n",
              ")"
            ]
          }
        }
      ],
      "source": [
        "net[:-1]"
      ],
      "id": "e043e863-68d1-451e-9e98-4d22b3170cb2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "결과 시각화 코드 10주\n",
        "\n",
        "## 순환신경망 Class 사용 RNN\n",
        "\n",
        "10주"
      ],
      "id": "d85834b9-0a65-4154-9ca8-6e25e4c1385c"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = list('AbAcAd')*100\n",
        "txt_x = txt[:-1]\n",
        "txt_y = txt[1:]\n",
        "x = torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))\n",
        "y = torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))\n",
        "x= torch.nn.functional.one_hot(x).float()\n",
        "y= torch.nn.functional.one_hot(y).float()"
      ],
      "id": "940a3851-e94a-4947-875f-3ffcc9aa2d04"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "class rNNCell(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i2h = torch.nn.Linear(4,2) \n",
        "        self.h2h = torch.nn.Linear(2,2) \n",
        "        self.tanh = torch.nn.Tanh()\n",
        "    def forward(self,x,hidden):\n",
        "        hidden = self.tanh(self.i2h(x)+self.h2h(hidden))\n",
        "        return hidden"
      ],
      "id": "f9b925f7-2dc6-4c0a-b55c-103c71dbed57"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(43052)\n",
        "rnncell = rNNCell()"
      ],
      "id": "1e575357-dafb-4e96-aabf-4467318f5b1d"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(43052)\n",
        "cook = torch.nn.Linear(2,4) "
      ],
      "id": "417b7245-f31e-4b69-917b-6bc67b19e366"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss() \n",
        "optimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))"
      ],
      "id": "5c33f594-6aef-4e68-973f-ea2996a0fc03"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "T = len(x) \n",
        "for epoc in range(100): \n",
        "    ## 1~2\n",
        "    loss = 0 \n",
        "    ht = torch.zeros(1,2) \n",
        "    for t in range(T):\n",
        "        xt,yt = x[[t]], y[[t]]\n",
        "        ht = rnncell(xt,ht) \n",
        "        ot = cook(ht) \n",
        "        loss = loss + loss_fn(ot,yt) \n",
        "    ## 3 \n",
        "    loss.backward()\n",
        "    ## 4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "56f07469-fa54-4024-8716-7c0ffe2a2f30"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "시각화코드는 10주_순환신경망구현1-성공에\n",
        "\n",
        "## 순환신경망 RNN"
      ],
      "id": "7d9e806b-c8fe-464f-8c19-32d7f1100f93"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = list('AbAcAd')*100\n",
        "txt_x = txt[:-1]\n",
        "txt_y = txt[1:]\n",
        "x = torch.nn.functional.one_hot(torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))).float()\n",
        "y = torch.nn.functional.one_hot(torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))).float()"
      ],
      "id": "7185df05-b142-49c5-af1d-93753c3cdc92"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(2) #1 \n",
        "rnn = torch.nn.RNN(4,3).to(\"cuda:0\") \n",
        "cook = torch.nn.Linear(3,4).to(\"cuda:0\")"
      ],
      "id": "7e503c10-3314-4d61-a07d-119f3ecf970c"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters()))"
      ],
      "id": "dd203254-cfec-4a71-a44c-50be9768b967"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "_water = torch.zeros(1,3).to(\"cuda:0\") \n",
        "for epoc in range(500):\n",
        "    ## 1\n",
        "    hidden,hT = rnn(x.to(\"cuda:0\"),_water) \n",
        "    output = cook(hidden) \n",
        "    ## 2 \n",
        "    loss = loss_fn(output,y.to(\"cuda:0\")) \n",
        "    ## 3 \n",
        "    loss.backward()\n",
        "    ## 4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "01b1980c-f3b6-4541-8715-84bc9e631a9c"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "yhat = soft(output)"
      ],
      "id": "c2fc1534-2479-4a5f-93d6-aedc02715c0b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 순환신경망 Class 사용 LSTM"
      ],
      "id": "2c2f9a97-8e2f-4f36-ad5c-355a465db178"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = list('hi?hello!!')*100 \n",
        "txt_x = txt[:-1]\n",
        "txt_y = txt[1:]\n",
        "mapping = {'!':0, '?':1,'h':2,'i':3,'e':4,'l':5,'o':6} \n",
        "x= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\n",
        "y= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
      ],
      "id": "7641d5ec-84a7-4449-b2f3-8fb35dfb9f81"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "class lSTMCell(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i2h = torch.nn.Linear(7,16)\n",
        "        self.h2h = torch.nn.Linear(4,16) \n",
        "        self.tanh = torch.nn.Tanh()\n",
        "    def forward(self,xt,past):\n",
        "        ht,ct = past \n",
        "        ifgo = self.i2h(xt) + self.h2h(ht) \n",
        "        it = sig(ifgo[0:4])\n",
        "        ft = sig(ifgo[4:8])\n",
        "        gt = tanh(ifgo[8:12])\n",
        "        ot = sig(ifgo[12:16])\n",
        "        ct = ft*ct + it*gt\n",
        "        ht = ot*self.tanh(ct) \n",
        "        return ht,ct"
      ],
      "id": "cc657cc3-158a-4b9b-a2d5-feab87c8a915"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "lstmcell = lSTMCell().to(\"cuda:0\")\n",
        "linr = torch.nn.Linear(4,7).to(\"cuda:0\")\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(list(lstmcell.parameters())+list(linr.parameters()),lr=0.1)"
      ],
      "id": "647d6137-976d-4882-8b54-ab9214f19d5e"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 초기값셋팅\n",
        "torch.manual_seed(43052) \n",
        "_lstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\")\n",
        "_linr = torch.nn.Linear(4,7).to(\"cuda:0\")\n",
        "lstmcell.i2h.weight.data = _lstmcell.weight_ih.data \n",
        "lstmcell.h2h.weight.data = _lstmcell.weight_hh.data \n",
        "lstmcell.i2h.bias.data = _lstmcell.bias_ih.data\n",
        "lstmcell.h2h.bias.data = _lstmcell.bias_hh.data\n",
        "linr.weight.data = _linr.weight.data \n",
        "linr.bias.data = _linr.bias.data "
      ],
      "id": "d04170c8-5b0d-4f9c-9ae7-2b815327b339"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoc in range(10):\n",
        "    ## 1\n",
        "    hidden = []     \n",
        "    ht = torch.zeros(4).to(\"cuda:0\")\n",
        "    ct = torch.zeros(4).to(\"cuda:0\")\n",
        "    for xt,yt in zip(x,y): \n",
        "        ht,ct = lstmcell(xt,(ht,ct))\n",
        "        hidden.append(ht) \n",
        "    hidden = torch.stack(hidden)\n",
        "    output = linr(hidden) \n",
        "    ## 2 \n",
        "    loss = loss_fn(output,y)\n",
        "    ## 3 \n",
        "    loss.backward()\n",
        "    ## 4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "02012f71-dedd-4450-ad85-fcd42fa5e5ce"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "yhat = soft(output)"
      ],
      "id": "feeccbf6-6025-4162-ac5a-a2ff03e27ae6"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([[0.0909, 0.0859, 0.0356,  ..., 0.1820, 0.2308, 0.1257],\n",
              "        [0.3443, 0.1629, 0.2108,  ..., 0.1008, 0.0506, 0.0774],\n",
              "        [0.3998, 0.0325, 0.5100,  ..., 0.0133, 0.0269, 0.0119],\n",
              "        ...,\n",
              "        [0.0655, 0.0525, 0.0455,  ..., 0.1652, 0.2569, 0.2828],\n",
              "        [0.3850, 0.0844, 0.3754,  ..., 0.0464, 0.0423, 0.0478],\n",
              "        [0.4012, 0.0217, 0.5328,  ..., 0.0084, 0.0254, 0.0065]],\n",
              "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          }
        }
      ],
      "source": [
        "yhat"
      ],
      "id": "bc2d93d6-394d-492b-8afc-2616d1917452"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 순환신경망 LSTM"
      ],
      "id": "6b6bf0f8-74ee-48b4-bd47-ff7d3a6a51ab"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = (['one',',','two',',','three',',','four',',','five',',']*100)[:-1]\n",
        "mapping = {',':0, 'one':1, 'two':2, 'three':3, 'four':4, 'five':5} \n",
        "txt_x = txt[:-1]\n",
        "txt_y = txt[1:] \n",
        "x = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\n",
        "y = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
      ],
      "id": "9ab09ce9-4277-4bdc-aada-9edaa5eaefcd"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(43052) \n",
        "lstm = torch.nn.LSTM(6,20).to(\"cuda:0\") \n",
        "linr = torch.nn.Linear(20,6).to(\"cuda:0\") \n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)"
      ],
      "id": "c94d7f4c-d938-47cc-a616-271298425e5c"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "_water = torch.zeros(1,20).to(\"cuda:0\")\n",
        "for epoc in range(50):\n",
        "    ## 1 \n",
        "    hidden, (hT,cT) =lstm(x,(_water,_water))\n",
        "    output = linr(hidden) \n",
        "    ## 2 \n",
        "    loss = loss_fn(output,y) \n",
        "    ## 3 \n",
        "    loss.backward()\n",
        "    ## 4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()     "
      ],
      "id": "809e310a-b4e0-4b9f-a7db-1e60c74d712c"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([[9.9875e-01, 1.5434e-06, 6.5715e-04, 1.8973e-05, 9.5753e-05, 4.7651e-04],\n",
              "        [3.0184e-06, 3.7971e-05, 9.8694e-01, 3.6741e-03, 3.6129e-04, 8.9867e-03],\n",
              "        [9.9999e-01, 2.9932e-06, 5.9745e-07, 8.3266e-06, 1.0668e-07, 4.8888e-07],\n",
              "        ...,\n",
              "        [3.9604e-05, 8.6161e-06, 1.5918e-03, 1.1244e-07, 9.9808e-01, 2.7556e-04],\n",
              "        [9.9993e-01, 3.3252e-07, 9.5155e-06, 4.8129e-07, 2.7274e-05, 3.2102e-05],\n",
              "        [8.0918e-07, 8.0716e-03, 5.9763e-04, 7.7044e-05, 6.8931e-05, 9.9118e-01]],\n",
              "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          }
        }
      ],
      "source": [
        "soft(output)"
      ],
      "id": "c5135956-d1e8-49e1-bbec-d0621a06c390"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 조각난 시계열\n",
        "\n",
        "12주차"
      ],
      "id": "d0b503cf-2207-4f23-975a-a9c7ce0bd79b"
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = list('hi!')*3 + list('hi?')*3\n",
        "txt_x = txt[:-1] \n",
        "txt_y = txt[1:] \n",
        "mapping = {'!':0, '?':1, 'h':2, 'i':3} \n",
        "x = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\n",
        "y = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\") "
      ],
      "id": "9a082a74-1ef5-435d-ac3f-e13e96a8d038"
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(43052) \n",
        "lstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\n",
        "linr = torch.nn.Linear(10,4).to(\"cuda:0\")"
      ],
      "id": "9c3fefca-06cc-4ca6-9ac0-c4529585fe82"
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss() \n",
        "optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)"
      ],
      "id": "f051b2ad-ce86-4e41-822c-4758594dfe6d"
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoc in range(100):\n",
        "    ## 1 \n",
        "    hidden, _ = lstm(x) \n",
        "    output = linr(hidden) \n",
        "    ## 2 \n",
        "    loss = loss_fn(output,y) \n",
        "    ## 3 \n",
        "    loss.backward() \n",
        "    ## 4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "60c23932-b0a2-4f28-93f1-b972e19e0963"
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPQAAAOfCAYAAAD/9O76AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nn/msLkgAAAAASUVORK5CYII=\n"
          }
        }
      ],
      "source": [
        "hidden, _ = lstm(x)\n",
        "plt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)"
      ],
      "id": "c68be896-7c52-460d-a972-9bdac274253b"
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = list('hi!')*3 + list('hi?')*3\n",
        "txt1= txt[:9]\n",
        "txt2= txt[9:]\n",
        "txt1_x = txt1[:-1] \n",
        "txt1_y = txt1[1:] \n",
        "txt2_x = txt2[:-1] \n",
        "txt2_y = txt2[1:] \n",
        "mapping = {'!':0, '?':1, 'h':2, 'i':3} \n",
        "x1 = torch.nn.functional.one_hot(torch.tensor(f(txt1_x,mapping))).float().to(\"cuda:0\")\n",
        "y1 = torch.nn.functional.one_hot(torch.tensor(f(txt1_y,mapping))).float().to(\"cuda:0\")\n",
        "x2 = torch.nn.functional.one_hot(torch.tensor(f(txt2_x,mapping))).float().to(\"cuda:0\")\n",
        "y2 = torch.nn.functional.one_hot(torch.tensor(f(txt2_y,mapping))).float().to(\"cuda:0\")\n",
        "xx = torch.stack([x1,x2],axis=1)\n",
        "yy = torch.stack([y1,y2],axis=1)"
      ],
      "id": "20ad105a-a951-42ca-a730-5d209dafb8b0"
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(43052) \n",
        "lstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\n",
        "linr = torch.nn.Linear(10,4).to(\"cuda:0\")"
      ],
      "id": "fe103fad-9474-4d38-b113-b239cabc1cb0"
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss() \n",
        "optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)"
      ],
      "id": "2f380908-eaa5-46dd-81ce-1d3546983bab"
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoc in range(100):\n",
        "    ## 1 \n",
        "    hidden, _ = lstm(xx) \n",
        "    output = linr(hidden) \n",
        "    ## 2 \n",
        "    loss = loss_fn(output[:,0,:],yy[:,0,:]) + loss_fn(output[:,1,:],yy[:,1,:])\n",
        "    ## 3 \n",
        "    loss.backward() \n",
        "    ## 4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "f7179b88-2bd9-4d98-906e-67c3d0d9a656"
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAD8CAYAAAABraMFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\naGzQMQAAAABJRU5ErkJggg==\n"
          }
        }
      ],
      "source": [
        "fig , ax = plt.subplots(1,2) \n",
        "ax[0].matshow(soft(output[:,0,:]).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n",
        "ax[1].matshow(soft(output[:,1,:]).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)"
      ],
      "id": "cd994fc6-c625-42a8-8a41-0b3b88c3ac50"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  }
}