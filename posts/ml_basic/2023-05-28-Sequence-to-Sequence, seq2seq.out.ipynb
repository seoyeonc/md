{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sequence-to-Sequence, seq2seq\n",
        "\n",
        "SEOYEON CHOI  \n",
        "5/28/23\n",
        "\n",
        "> Sequence-to-Sequence, seq2seq\n",
        "\n",
        "Ref: [딥러닝을 이용한 자연어 처리 입문](https://wikidocs.net/24996),\n",
        "[keras](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)\n",
        "\n",
        "# Seq2seq\n",
        "\n",
        "*기본 디자인*"
      ],
      "id": "41edd3b9-269b-4277-a11e-d88942e73b8f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "</p>"
            ]
          }
        }
      ],
      "source": [],
      "id": "060c3ac9-09ba-4fb9-9523-5ab21d4b5507"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "인코더\n",
        "\n",
        "-   모든 단어들을 순차적으로 입력받은 뒤에 마지막에 이 모든 단어\n",
        "    정보들을 압축해서 하나의 벡터로 만듦(컨텍스트 벡터)\n",
        "-   이 컨텍스트 벡터[1]를 디코더로 전달\n",
        "\n",
        "디코더\n",
        "\n",
        "-   컨텍스트 벡터를 받아서 번역된 단어를 하나씩 순차적으로 출력\n",
        "\n",
        "*내부 확대*\n",
        "\n",
        "[1] 컨텍스트 벡터는 보통 수백차원 이상"
      ],
      "id": "ed6d12ee-3a24-4771-8570-80486ffb5dd4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "</p>"
            ]
          }
        }
      ],
      "source": [],
      "id": "7169152e-9428-43d0-a2aa-ac46ba3eb186"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   인코더와 디코더는 두 개의 RNN 아키텍처로 이루어져 있음.\n",
        "-   인코더: 입력 문장을 받는 RNN 셀\n",
        "-   디코더: 출력 문장을 받는 RNN 셀\n",
        "\n",
        "**RNN, LSTM, GRU 중 무엇을 사용하느냐는 모델에 따라, 성능에 따라 달리\n",
        "선택**\n",
        "\n",
        "-   인코더는 단어 토큰화를 통해 단어들을 RNN 셀의 각 시점으로 입력하는데\n",
        "    그 후에 인코더 RNN 셀의 마지막 시점의 은닉 상태(컨텍스트벡터)를\n",
        "    디코더 RNN 셀로 넘겨줌.\n",
        "\n",
        "**컨텍스트 벡터는 디코더의 첫번째 은닉 상태에 사용**\n",
        "\n",
        "-   초기값인 sos가 들어가면 순차적으로 다음에 올 단어를 예측 후 다음\n",
        "    타임스템에 전달, eos가 나올때까지 진행됨\n",
        "\n",
        "> **Tip**\n",
        ">\n",
        "> $\\star$ sos\n",
        ">\n",
        "> -   디코더의 초기 입력, 문장의 시작을 의미\n",
        "> -   다음 등장할 확률이 높은 단어를 예측\n",
        ">\n",
        "> $\\star$ eos\n",
        ">\n",
        "> -   디코더의 끝 값, 문장의 끝을 의미\n",
        "\n",
        "-   각 RNNLM(RNN Language Model)은 단어 토큰을 입력 받을 때 임베딩\n",
        "    과정을 거쳐서 텍스트를 벡터로 바꿈(단, 사이즈는 수백 개의 차원을\n",
        "    가질 수 있음)\n",
        "\n",
        "**하나의 RNN 셀 확대**\n",
        "\n",
        "-   입력\n",
        "    -   time step t-1에서의 은닉 상태\n",
        "    -   현재 time-step t에서의 입력 벡터\n",
        "-   은닉 상태(입력으로 만들어낸, 필요없으면 값 무시 가능)\n",
        "    -   time step t에서의 은닉 상태\n",
        "    -   현재 time-step t에서의 은닉 상태\n",
        "-   의미하는 바\n",
        "    -   현재 시점 t에서의 은닉 상태는 과거 시점의 동일한 RNN 셀에서의\n",
        "        모든 은닉 상태의 값들의 영향을 누적해서 받아온 값\n",
        "    -   입력 문장의 단어 토큰들의 정보를 요약해서 담고 있다고 할 수 있음"
      ],
      "id": "75878d8f-5812-49aa-abe8-36fe444b2cb3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "</p>"
            ]
          }
        }
      ],
      "source": [],
      "id": "ecc0de57-902d-4ab7-9074-800022cc5c85"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 실습"
      ],
      "id": "a85a633f-3a38-4b3d-bb20-36359488c32a"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import urllib3\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "id": "6dea47da-d0c9-4190-a6ad-99ec7e3b426e"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "http = urllib3.PoolManager()\n",
        "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
        "filename = 'fra-eng.zip'"
      ],
      "id": "89865cdc-b7f9-4b7e-a4ee-9b13312b9ad9"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = os.getcwd()"
      ],
      "id": "60201cb8-6d59-4776-b422-e980d8472f14"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "'/home/csy/Dropbox/md/posts/ml_basic'"
            ]
          }
        }
      ],
      "source": [
        "path"
      ],
      "id": "3bb22ed3-a9ab-4b29-bcb1-0e3746ccc13c"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "zipfilename = os.path.join(path, filename)"
      ],
      "id": "4664434a-7c63-4afb-8f80-30ba0f8b0528"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "'/home/csy/Dropbox/md/posts/ml_basic/fra-eng.zip'"
            ]
          }
        }
      ],
      "source": [
        "zipfilename"
      ],
      "id": "f4920373-e1e7-492e-b6b3-e68517e443d9"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
        "    shutil.copyfileobj(r, out_file)"
      ],
      "id": "9338b81e-a778-4536-8587-83a2ab958f65"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "with zipfile.ZipFile(zipfilename, ‘r’) as zip_ref:\n",
        "zip_ref.extractall(path)"
      ],
      "id": "8e1e3e43-ab5b-4925-b8ec-6887a0212ddd"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "lines = pd.read_csv('./fra.txt', names=['src', 'tar', 'lic'], sep='\\t')"
      ],
      "id": "f0def91f-7605-4352-935f-bd9056e6fca9"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플의 개수 : 217975"
          ]
        }
      ],
      "source": [
        "del lines['lic']\n",
        "print('전체 샘플의 개수 :',len(lines))"
      ],
      "id": "bffea795-c9aa-40b3-96d4-c8305a305316"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>57809</th>\n",
              "      <td>There are no examples.</td>\n",
              "      <td>Il n'y a pas d'exemples.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57733</th>\n",
              "      <td>The problem isn't new.</td>\n",
              "      <td>Le problème n'est pas nouveau.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39939</th>\n",
              "      <td>I use worms as bait.</td>\n",
              "      <td>J'utilise des vers comme appât.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28156</th>\n",
              "      <td>That's irrelevant.</td>\n",
              "      <td>Ça n'a rien à voir.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31341</th>\n",
              "      <td>Everyone has voted.</td>\n",
              "      <td>Tout le monde a voté.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47860</th>\n",
              "      <td>I'm feeling fine now.</td>\n",
              "      <td>Maintenant je me sens bien.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2181</th>\n",
              "      <td>I'm pooped.</td>\n",
              "      <td>Je suis crevé.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30174</th>\n",
              "      <td>You can't just go.</td>\n",
              "      <td>Tu ne peux pas simplement t'en aller comme ça.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14843</th>\n",
              "      <td>I didn't scream.</td>\n",
              "      <td>Je n'ai pas hurlé.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28558</th>\n",
              "      <td>They're separated.</td>\n",
              "      <td>Ils sont séparés.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "lines = lines.loc[:, 'src':'tar']\n",
        "lines = lines[0:60000] # 6만개만 저장\n",
        "lines.sample(10)"
      ],
      "id": "734867b2-11e5-440a-b8a6-071d29cb3297"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*sos, eos 대신 `\\t`,`\\n`를 입력*"
      ],
      "id": "db17db7e-7cbe-4ad7-bbe2-4f16199e1feb"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20466</th>\n",
              "      <td>I think I got it.</td>\n",
              "      <td>\\t Je crois avoir compris. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46024</th>\n",
              "      <td>His blood is boiling.</td>\n",
              "      <td>\\t Son sang bout. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18508</th>\n",
              "      <td>You're too slow.</td>\n",
              "      <td>\\t Tu es trop lente. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31397</th>\n",
              "      <td>Everything's wrong.</td>\n",
              "      <td>\\t Tout va mal. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8888</th>\n",
              "      <td>Stop shooting.</td>\n",
              "      <td>\\t Arrêtez de tirer. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16664</th>\n",
              "      <td>Spring has come.</td>\n",
              "      <td>\\t Le printemps est arrivé. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47044</th>\n",
              "      <td>I meant the opposite.</td>\n",
              "      <td>\\t Je voulais dire le contraire. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11988</th>\n",
              "      <td>Leave it there.</td>\n",
              "      <td>\\t Laissez-le là. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44016</th>\n",
              "      <td>You are such a liar.</td>\n",
              "      <td>\\t Tu es un sacré menteur. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55752</th>\n",
              "      <td>I'm a biology student.</td>\n",
              "      <td>\\t Je suis étudiant en biologie. \\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
        "lines.sample(10)"
      ],
      "id": "6b374e88-e7a7-442d-8e05-1fedf38cd068"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 문자 집합 구축\n",
        "src_vocab = set()\n",
        "for line in lines.src: # 1줄씩 읽음\n",
        "    for char in line: # 1개의 문자씩 읽음\n",
        "        src_vocab.add(char)\n",
        "\n",
        "tar_vocab = set()\n",
        "for line in lines.tar:\n",
        "    for char in line:\n",
        "        tar_vocab.add(char)"
      ],
      "id": "7e34f594-b18f-49e0-aceb-2352575380ae"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 char 집합 : 80\n",
            "target 문장의 char 집합 : 103"
          ]
        }
      ],
      "source": [
        "src_vocab_size = len(src_vocab)+1\n",
        "tar_vocab_size = len(tar_vocab)+1\n",
        "print('source 문장의 char 집합 :',src_vocab_size)\n",
        "print('target 문장의 char 집합 :',tar_vocab_size)"
      ],
      "id": "10173359-abe6-4b7a-861f-56106949108b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "sorted 된 상태에서 인덱스 출력해야 함"
      ],
      "id": "41e95747-1719-452f-add9-79bb3a7dd280"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "['T', 'U', 'V', 'W', 'X', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x']"
          ]
        }
      ],
      "source": [
        "src_vocab = sorted(list(src_vocab))\n",
        "tar_vocab = sorted(list(tar_vocab))\n",
        "print(src_vocab[45:75])\n",
        "print(tar_vocab[45:75])"
      ],
      "id": "96ac7406-9607-423e-85de-01adde83a00f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*문장에 인덱스 부여*"
      ],
      "id": "8ffd0182-e26b-45ef-a1d7-44174c8ab1d4"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, '°': 76, 'é': 77, '’': 78, '€': 79}\n",
            "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'a': 52, 'b': 53, 'c': 54, 'd': 55, 'e': 56, 'f': 57, 'g': 58, 'h': 59, 'i': 60, 'j': 61, 'k': 62, 'l': 63, 'm': 64, 'n': 65, 'o': 66, 'p': 67, 'q': 68, 'r': 69, 's': 70, 't': 71, 'u': 72, 'v': 73, 'w': 74, 'x': 75, 'y': 76, 'z': 77, '\\xa0': 78, '«': 79, '»': 80, 'À': 81, 'Ç': 82, 'É': 83, 'Ê': 84, 'Ô': 85, 'à': 86, 'â': 87, 'ç': 88, 'è': 89, 'é': 90, 'ê': 91, 'ë': 92, 'î': 93, 'ï': 94, 'ô': 95, 'ù': 96, 'û': 97, 'œ': 98, '\\u2009': 99, '‘': 100, '’': 101, '\\u202f': 102}"
          ]
        }
      ],
      "source": [
        "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
        "print(src_to_index)\n",
        "print(tar_to_index)"
      ],
      "id": "3e007824-95a9-425e-b76d-cc986975bc06"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "train 데이터의 인코더에 정수 인코딩"
      ],
      "id": "2cb291fc-eba1-48b8-a5b6-23929f1c9cf8"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 정수 인코딩 : [[30, 64, 10], [30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10]]"
          ]
        }
      ],
      "source": [
        "encoder_input = []\n",
        "\n",
        "# 1개의 문장\n",
        "for line in lines.src:\n",
        "    encoded_line = []\n",
        "  # 각 줄에서 1개의 char\n",
        "    for char in line:\n",
        "    # 각 char을 정수로 변환\n",
        "        encoded_line.append(src_to_index[char])\n",
        "    encoder_input.append(encoded_line)\n",
        "print('source 문장의 정수 인코딩 :',encoder_input[:5])"
      ],
      "id": "6a6b324f-7910-49d0-9476-0d53cb7dd1be"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "디코더에 정수 인코딩"
      ],
      "id": "d98b7b96-dc22-40dd-8515-ad1e3a54ddbe"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 문장의 정수 인코딩 : [[1, 3, 48, 52, 3, 4, 3, 2], [1, 3, 39, 52, 69, 54, 59, 56, 14, 3, 2], [1, 3, 31, 65, 3, 69, 66, 72, 71, 56, 3, 4, 3, 2], [1, 3, 28, 66, 72, 58, 56, 3, 4, 3, 2], [1, 3, 45, 52, 63, 72, 71, 3, 4, 3, 2]]"
          ]
        }
      ],
      "source": [
        "decoder_input = []\n",
        "for line in lines.tar:\n",
        "    encoded_line = []\n",
        "    for char in line:\n",
        "        encoded_line.append(tar_to_index[char])\n",
        "    decoder_input.append(encoded_line)\n",
        "print('target 문장의 정수 인코딩 :',decoder_input[:5])"
      ],
      "id": "088d019f-90da-4449-bf80-78c19e115c43"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**디코더를 예측한 후 그 값과 비교하기 위한 실제 값을 위해 위에 추가한\n",
        "`\\t`를 없애주는 과정으로서 앞의 `1` 삭제**"
      ],
      "id": "a2f305ff-9d2e-46bb-9f47-0ec0105f5c26"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 문장 레이블의 정수 인코딩 : [[3, 48, 52, 3, 4, 3, 2], [3, 39, 52, 69, 54, 59, 56, 14, 3, 2], [3, 31, 65, 3, 69, 66, 72, 71, 56, 3, 4, 3, 2], [3, 28, 66, 72, 58, 56, 3, 4, 3, 2], [3, 45, 52, 63, 72, 71, 3, 4, 3, 2]]"
          ]
        }
      ],
      "source": [
        "decoder_target = []\n",
        "for line in lines.tar:\n",
        "    timestep = 0\n",
        "    encoded_line = []\n",
        "    for char in line:\n",
        "        if timestep > 0:\n",
        "            encoded_line.append(tar_to_index[char])\n",
        "        timestep = timestep + 1\n",
        "    decoder_target.append(encoded_line)\n",
        "print('target 문장 레이블의 정수 인코딩 :',decoder_target[:5])"
      ],
      "id": "3c5b0ff8-24af-4f52-a84c-87f90738e1eb"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 최대 길이 : 22\n",
            "target 문장의 최대 길이 : 76"
          ]
        }
      ],
      "source": [
        "max_src_len = max([len(line) for line in lines.src])\n",
        "max_tar_len = max([len(line) for line in lines.tar])\n",
        "print('source 문장의 최대 길이 :',max_src_len)\n",
        "print('target 문장의 최대 길이 :',max_tar_len)"
      ],
      "id": "e4c64812-e3ef-4129-9b40-01d3a437b348"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "영어 데이터끼리, 프랑스어 데이터끼리 길이를 맞추어 패딩 진행"
      ],
      "id": "ce55e696-3f12-4664-977b-b89f71c38c29"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
      ],
      "id": "f2688e37-144d-4c33-8b7e-0a8650741f75"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "원핫인코딩(문자 단위 번역기라 워드 임베딩은 별도로 사용하지 않음)"
      ],
      "id": "7a51508b-79f8-4ca4-887c-a8165e246803"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)"
      ],
      "id": "8e873c08-220a-4203-8ea9-22123b44a5ec"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Teacher Forcing 교사 강요\n",
        "\n",
        "-   train에서는 이전 시점의 디코더 셀의 출력을 현재 시점의 디코더 셀의\n",
        "    입력으로 넣어주지 않음.\n",
        "-   이전 시점의 실제값을 현재 시점의 디코더 셀의 입력값으로 하는 방법\n",
        "    사용\n",
        "    -   이전 시점의 디코더 셀의 예측이 틀렸는데 이를 현재 시점의 디코더\n",
        "        셀의 입력으로 사용하면 현재 시점의 디코더 셀의 예측에도 잘못될\n",
        "        가능성이 높음\n",
        "    -   이는 연쇄 작용으로 디코더 전체의 예측을 어렵게 함\n",
        "    -   이런 상황이 반복되면 훈련 시간이 느려질 수 있음\n",
        "\n",
        "**교사 강요**\n",
        "\n",
        "-   RNN의 모든 시점에 대해서 이전 시점의 예측값 대신 실제값을 입력으로\n",
        "    주는 방법\n",
        "\n",
        "## seq2seq 기계 번역기 훈련"
      ],
      "id": "f460de55-cb52-46cf-9aa1-3d2d5069efcb"
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "id": "3a56b0ea-41e5-45d7-9406-ce8c2704e5fe"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`encoder_states` 가 바로 컨텍스트 벡터"
      ],
      "id": "4fff0131-6f9f-4d94-9ff0-953d3bc506d2"
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "encoder_lstm = LSTM(units=256, return_state=True)\n",
        "\n",
        "# encoder_outputs은 여기서는 불필요\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 은닉 상태와 셀 상태.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "id": "39187e28-f922-43ae-bb2c-73f15a2d806a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``` python\n",
        "return_state=True\n",
        "```\n",
        "\n",
        "인코더의 내부 상태를 디코더로 넘겨주기 위해, False면 리턴하지 않음"
      ],
      "id": "50bbd51f-7597-41ce-9aae-27905df97aec"
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
        "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
        "\n",
        "# 디코더에게 인코더의 은닉 상태, 셀 상태를 전달.\n",
        "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
      ],
      "id": "946a47bd-fcb3-4f92-b01b-ebf9987787e8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "디코더는 은닉상태, 셀 상태를 사용하지 않기 때문에 `_`로 받아줌"
      ],
      "id": "f17bacb1-f710-43bd-aef6-18c3aa818367"
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "750/750 [==============================] - 100s 131ms/step - loss: 0.8574 - val_loss: 0.7819\n",
            "Epoch 2/40\n",
            "750/750 [==============================] - 98s 131ms/step - loss: 0.5758 - val_loss: 0.6667\n",
            "Epoch 3/40\n",
            "750/750 [==============================] - 144s 191ms/step - loss: 0.5051 - val_loss: 0.6056\n",
            "Epoch 4/40\n",
            "750/750 [==============================] - 171s 229ms/step - loss: 0.4589 - val_loss: 0.5569\n",
            "Epoch 5/40\n",
            "750/750 [==============================] - 159s 213ms/step - loss: 0.4232 - val_loss: 0.5200\n",
            "Epoch 6/40\n",
            "750/750 [==============================] - 154s 205ms/step - loss: 0.3958 - val_loss: 0.4920\n",
            "Epoch 7/40\n",
            "750/750 [==============================] - 109s 145ms/step - loss: 0.3745 - val_loss: 0.4701\n",
            "Epoch 8/40\n",
            "750/750 [==============================] - 105s 140ms/step - loss: 0.3572 - val_loss: 0.4552\n",
            "Epoch 9/40\n",
            "750/750 [==============================] - 119s 159ms/step - loss: 0.3429 - val_loss: 0.4391\n",
            "Epoch 10/40\n",
            "750/750 [==============================] - 163s 218ms/step - loss: 0.3306 - val_loss: 0.4275\n",
            "Epoch 11/40\n",
            "750/750 [==============================] - 164s 219ms/step - loss: 0.3201 - val_loss: 0.4184\n",
            "Epoch 12/40\n",
            "750/750 [==============================] - 160s 213ms/step - loss: 0.3111 - val_loss: 0.4119\n",
            "Epoch 13/40\n",
            "750/750 [==============================] - 133s 177ms/step - loss: 0.3031 - val_loss: 0.4011\n",
            "Epoch 14/40\n",
            "750/750 [==============================] - 101s 135ms/step - loss: 0.2959 - val_loss: 0.3956\n",
            "Epoch 15/40\n",
            "750/750 [==============================] - 101s 135ms/step - loss: 0.2893 - val_loss: 0.3928\n",
            "Epoch 16/40\n",
            "750/750 [==============================] - 141s 188ms/step - loss: 0.2832 - val_loss: 0.3868\n",
            "Epoch 17/40\n",
            "750/750 [==============================] - 173s 230ms/step - loss: 0.2778 - val_loss: 0.3798\n",
            "Epoch 18/40\n",
            "750/750 [==============================] - 161s 215ms/step - loss: 0.2727 - val_loss: 0.3781\n",
            "Epoch 19/40\n",
            "750/750 [==============================] - 152s 202ms/step - loss: 0.2679 - val_loss: 0.3755\n",
            "Epoch 20/40\n",
            "750/750 [==============================] - 117s 156ms/step - loss: 0.2635 - val_loss: 0.3704\n",
            "Epoch 21/40\n",
            "750/750 [==============================] - 105s 140ms/step - loss: 0.2593 - val_loss: 0.3687\n",
            "Epoch 22/40\n",
            "750/750 [==============================] - 123s 164ms/step - loss: 0.2553 - val_loss: 0.3656\n",
            "Epoch 23/40\n",
            "750/750 [==============================] - 162s 216ms/step - loss: 0.2517 - val_loss: 0.3626\n",
            "Epoch 24/40\n",
            "750/750 [==============================] - 162s 217ms/step - loss: 0.2482 - val_loss: 0.3618\n",
            "Epoch 25/40\n",
            "750/750 [==============================] - 157s 209ms/step - loss: 0.2448 - val_loss: 0.3602\n",
            "Epoch 26/40\n",
            "750/750 [==============================] - 135s 180ms/step - loss: 0.2414 - val_loss: 0.3577\n",
            "Epoch 27/40\n",
            "750/750 [==============================] - 98s 131ms/step - loss: 0.2385 - val_loss: 0.3569\n",
            "Epoch 28/40\n",
            "750/750 [==============================] - 98s 131ms/step - loss: 0.2355 - val_loss: 0.3562\n",
            "Epoch 29/40\n",
            "750/750 [==============================] - 150s 200ms/step - loss: 0.2325 - val_loss: 0.3536\n",
            "Epoch 30/40\n",
            "750/750 [==============================] - 172s 229ms/step - loss: 0.2299 - val_loss: 0.3517\n",
            "Epoch 31/40\n",
            "750/750 [==============================] - 161s 214ms/step - loss: 0.2271 - val_loss: 0.3520\n",
            "Epoch 32/40\n",
            "750/750 [==============================] - 156s 208ms/step - loss: 0.2246 - val_loss: 0.3518\n",
            "Epoch 33/40\n",
            "750/750 [==============================] - 110s 147ms/step - loss: 0.2222 - val_loss: 0.3504\n",
            "Epoch 34/40\n",
            "750/750 [==============================] - 107s 143ms/step - loss: 0.2199 - val_loss: 0.3494\n",
            "Epoch 35/40\n",
            "750/750 [==============================] - 128s 171ms/step - loss: 0.2177 - val_loss: 0.3502\n",
            "Epoch 36/40\n",
            "750/750 [==============================] - 168s 224ms/step - loss: 0.2152 - val_loss: 0.3493\n",
            "Epoch 37/40\n",
            "750/750 [==============================] - 166s 221ms/step - loss: 0.2131 - val_loss: 0.3479\n",
            "Epoch 38/40\n",
            "750/750 [==============================] - 154s 205ms/step - loss: 0.2111 - val_loss: 0.3492\n",
            "Epoch 39/40\n",
            "750/750 [==============================] - 122s 162ms/step - loss: 0.2091 - val_loss: 0.3499\n",
            "Epoch 40/40\n",
            "750/750 [==============================] - 98s 131ms/step - loss: 0.2070 - val_loss: 0.3497"
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe721864a30>"
            ]
          }
        }
      ],
      "source": [
        "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=40, validation_split=0.2)"
      ],
      "id": "f5e72e0f-352d-4ff3-aaee-6ba16b083f79"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## seq2seq 기계 번역기 동작\n",
        "\n",
        "STEP 1. 번역하고자 하는 입력 문장이 인코더에 들어가 은닉 상태와 셀\n",
        "상태를 얻는다.\n",
        "\n",
        "STEP 2. 상태와 `<sos>`에 해당하는 `\\t` 를 디코더로 보낸다.\n",
        "\n",
        "STEP 3. elzhejrk `<eos>`에 해당하는 `\\n`이 나올 때까지 다음 문자를\n",
        "예측하는 행동을 반복한다."
      ],
      "id": "4f1894c3-0279-44eb-bacc-26b865fde510"
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
      ],
      "id": "c3d114b2-67b7-4b4c-a35e-24353bfdb226"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "인코더 정의"
      ],
      "id": "dc0f8094-834d-4ed8-bf41-9b86157894ed"
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용.\n",
        "# 뒤의 함수 decode_sequence()에 동작을 구현 예정\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태를 버리지 않음.\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
      ],
      "id": "a0ecc7bd-d777-4dfa-bfda-82202d2cb9ac"
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, None, 103) dtype=float32 (created by layer 'input_2')>"
            ]
          }
        }
      ],
      "source": [
        "decoder_inputs"
      ],
      "id": "12a68e42-4c9d-49ba-aed0-2a08c9eec60a"
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "[<KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'input_5')>,\n",
              " <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'input_6')>]"
            ]
          }
        }
      ],
      "source": [
        "decoder_states_inputs"
      ],
      "id": "e880ad96-8dbe-4eba-8a7a-3cdf49396ef1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "디코더 설계"
      ],
      "id": "86c1137d-0d0f-4f7e-bcd3-ad7bf7531cad"
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
      ],
      "id": "2411af0c-6919-45eb-b13f-8b3a6d278e02"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "인덱스에서 단어를 얻을 수 있도록 `index_to_~`설계"
      ],
      "id": "c8c28dd0-4493-47e6-8276-0e15dcb71e37"
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "\n",
        "    # stop_condition이 True가 될 때까지 루프 반복\n",
        "    while not stop_condition:\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # 예측 결과를 문자로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "    if (sampled_char == '\\n' or\n",
        "        len(decoded_sentence) > max_tar_len):\n",
        "        stop_condition = True\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "    target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "id": "6af82e3c-ed73-4345-97e4-dacab5e69086"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### step by step"
      ],
      "id": "72c58ba0-ecc7-4f2a-bbf0-6bbd551d7026"
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_seq = encoder_input[5:10]"
      ],
      "id": "bec68542-c935-4ead-a923-a752bb639181"
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step"
          ]
        }
      ],
      "source": [
        "states_value = encoder_model.predict(input_seq)"
      ],
      "id": "4bcc9643-4ff3-4ca7-9925-8d6e38a36f3c"
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [],
      "source": [
        "# <SOS>에 해당하는 원-핫 벡터 생성\n",
        "target_seq = np.zeros((1, 1, tar_vocab_size))"
      ],
      "id": "5584f284-f421-4486-9531-f8ef2c58c7be"
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          }
        }
      ],
      "source": [
        "target_seq"
      ],
      "id": "313d92f3-c7ef-401b-9ac3-2cfe25ee33fc"
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_seq[0, 0, tar_to_index['\\t']] = 1."
      ],
      "id": "b6d3a0df-c8f6-47aa-9b2f-97b008364cc8"
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          }
        }
      ],
      "source": [
        "target_seq"
      ],
      "id": "e4d86f4d-a125-472e-b9b5-15f017df78d8"
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [],
      "source": [
        "stop_condition = False"
      ],
      "id": "0aa2f6bd-84b2-4cce-9ecd-bdef42ac6eb6"
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [],
      "source": [
        "decoded_sentence = \"\""
      ],
      "id": "3e8e5a61-4cd6-43e2-b099-4c5ee74ef6d5"
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 103)\n",
            "(5, 256)\n",
            "(5, 256)\n",
            "(1, 256)\n",
            "(1, 256)"
          ]
        }
      ],
      "source": [
        "# Check dimensions of input arrays\n",
        "print(target_seq.shape)            # Shape of target_seq\n",
        "print(states_value[0].shape)       # Shape of states_value[0]\n",
        "print(states_value[1].shape)       # Shape of states_value[1]\n",
        "print(states_value[0][1,:].reshape(1,-1).shape)\n",
        "print(states_value[1][1,:].reshape(1,-1).shape)"
      ],
      "id": "31aaf946-cc8e-4160-a72b-f0a47133a10f"
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [],
      "source": [
        "states_value_tmp = [states_value[0][1,:].reshape(1,-1), states_value[1][1,:].reshape(1,-1)]"
      ],
      "id": "e762e5e9-6366-4840-aa0b-26ca8eb29206"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# stop_condition이 True가 될 때까지 루프 반복\n",
        "while not stop_condition:\n",
        "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value_tmp)"
      ],
      "id": "05df7ebc-2cf4-4297-968d-3b7f39eeff64"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_tokens, h, c = decoder_model.predict([target_seq] + states_value_tmp)"
      ],
      "id": "0d82a898-ffa7-440e-82f0-e26622ae2138"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 예측 결과를 문자로 변환\n",
        "sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "sampled_token_index"
      ],
      "id": "4c684435-034a-429e-907b-b5eb442eaf4d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sampled_char = index_to_tar[sampled_token_index]\n",
        "sampled_char"
      ],
      "id": "68f68990-eba6-4fc2-b204-24f37e9c5774"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "decoded_sentence += sampled_char"
      ],
      "id": "b33ee852-4e9e-4bd4-a37d-512dc3d38cab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "if (sampled_char == '\\n' or\n",
        "    len(decoded_sentence) > max_tar_len):\n",
        "    stop_condition = True"
      ],
      "id": "fc541ee3-2812-41fd-93c7-4c0721527c0b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "target_seq"
      ],
      "id": "af290dd0-5ca2-40a1-979f-833b3d112181"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_seq[0, 0, sampled_token_index] = 1."
      ],
      "id": "99184341-5393-4831-ba56-4e02d168f991"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "states_value = [h, c]"
      ],
      "id": "55336058-76b7-41ea-9132-f76b79c0f716"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('입력 문장:', lines.src[5])\n",
        "print('정답 문장:', lines.tar[5][2:len(lines.tar[5])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
        "print('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
      ],
      "id": "7b96630d-d68c-488b-b35f-8eb5210094ee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for seq_index in [3,4]: # 입력 문장의 인덱스\n",
        "    input_seq = encoder_input[seq_index:seq_index+1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    # print(35 * \"-\")\n",
        "    print('입력 문장:', lines.src[seq_index])\n",
        "    print('정답 문장:', lines.tar[seq_index][2:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
        "    print('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
      ],
      "id": "d3b6b74e-9b52-468d-a796-89efc6dc9279"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  }
}