{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0e38dbb7-cf22-436d-b098-fd5ac1889d5a",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"Transformers\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-05-24\"\n",
    "categories:\n",
    "  - Transformers\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4296be-9d8f-4664-9c84-b0ea0ad1d6e7",
   "metadata": {},
   "source": [
    "> Attention is all you need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10edc928-aabd-41f9-bd3d-5b1ddc0e9cb4",
   "metadata": {},
   "source": [
    "ref: [딥 러닝을 이용한 자연어 처리 입문](https://wikidocs.net/31379), [Attention is all you need](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a00176-ec1b-445c-96fb-d44ba975e4df",
   "metadata": {},
   "source": [
    "$\\star$ seq2seq 구조인 인코더-디코더를 따르면서 어텐션만으로 구현한 모델, RNN을 사용하지 않고 인코더-디코더 구조로 설계하였지만 RNN보다 우수한 성능을 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9754537-002f-4b78-847b-d63138917d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b38772-5044-4190-9128-af31b3235006",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/huggingface/transformers/blob/main/README_ko.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e26d23-5ebf-4f51-95f4-dca89f886860",
   "metadata": {},
   "source": [
    "# seq2seq 의 한계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830e2f05-ce18-4420-bbaa-40c11fb3c130",
   "metadata": {},
   "source": [
    "- 인코더, 디코더로 구성되어 있는 seq2seq\n",
    "- 인코더는 입력 시퀀스를 하나의 벡터 표현으로 압축\n",
    "    - $\\to$ 입력 시퀀스의 정보가 일부 손실된다는 단점 존재\n",
    "    - $\\to$ 이를 위해 어텐션 메카니즘 등장\n",
    "- 디코더는 이 벡터 표현을 통해 출력 시퀀스를 만듦\n",
    "\n",
    "\n",
    "- $\\star$ 어텐션을 RNN의 보정을 위한 용도로 사용하는 것이 아니라 어텐션만으로 인코더와 디코더를 만든다면??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef67fbb0-8aeb-4641-a17b-cdb4a083e27c",
   "metadata": {},
   "source": [
    "# 트랜스포머의 주요 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8d509c-2f64-4a53-a642-8bdfb3041628",
   "metadata": {},
   "source": [
    "각 값은 논문의 설정으로서, 바뀔 수 있음\n",
    "\n",
    "$d_{model} = 512$\n",
    "\n",
    "- 인코더와 디코더에서의 정해진 입력 및 출력의 크기\n",
    "- 임베딩 벡터의 차원도 이와 같음\n",
    "- 각 인코더와 디코더가 다음 층의 인코더와 디코더로 값을 보낼 때도 유지\n",
    "\n",
    "$num_layers = 6$\n",
    "\n",
    "- 하나의 인코더와 디코더를 층으로 생각하였을때, 모델에서 인코더와 디코더가 몇 층으로 구성되어 있는지를 의미\n",
    "\n",
    "$num_heads = 8$\n",
    "\n",
    "- 어텐션을 병렬로 수행하고 결과값을 다시 합치는 방식을 수행하기 위함, 즉 병렬의 개수\n",
    "\n",
    "$d_{ff} = 2048$\n",
    "\n",
    "- 트랜스포머 내부에 피드 포워드 신경망이 존재, 그 신경망의 은닉층의 크기를 의미\n",
    "- 단, 피드 포워드 신경망의 입력층과 출력층의 크기는 $d_{model}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6b65fb-4f75-45c6-b7b2-7ba95951e6a2",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e274d43-ff5a-46df-b4e3-e81684e74d19",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "flowchart LR\n",
    "  subgraph _\n",
    "    direction LR\n",
    "    subgraph Transformer\n",
    "        direction LR\n",
    "        Encoders -->Decoders\n",
    "    end\n",
    "  end\n",
    "  Text1(\"'I am a student`\") --> _ --> Text2(\"'je suis étudiant`\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e8f30-0510-4cf9-b40a-028ea49ba45e",
   "metadata": {},
   "source": [
    "- 인코더-디코더 구조를 가진 트랜스포머\n",
    "- 인코더와 디코더라는 단위가 N개로 구성되는 구조 $\\to$ Encoders, Decoders로 표현\n",
    "    - seq2seq에서는 인코더와 디코더에서 각각 하나의 RNN이 t개의 시점time step을 가지는 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb4ac8e-1c1f-4322-b6d2-0e3232b640ae",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "flowchart LR\n",
    "    _-->__\n",
    "    __-->out\n",
    "    subgraph _\n",
    "    direction BT\n",
    "    Embedding1-->Encoders\n",
    "        subgraph Encoders\n",
    "        Encoder\n",
    "        end\n",
    "        subgraph Embedding1\n",
    "        Text1(\"'I|am|a|student'\")\n",
    "        end\n",
    "    end\n",
    "    subgraph __\n",
    "    direction BT\n",
    "    Embedding2-->Decoders\n",
    "        subgraph Decoders\n",
    "        Decoder\n",
    "        end\n",
    "        subgraph Embedding2\n",
    "        Text2(\"'<\\br>sos|je|suis|étudiant'\")\n",
    "        end\n",
    "    end\n",
    "    out(\"'je|suis|étudiant|eos'\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213eeea-c3ed-4838-951f-0f5321b8dac3",
   "metadata": {},
   "source": [
    "- symbol인 sos를 입력받아 eos symbol 나올때까지 연산을 진행하는, RNN을 사용하지 않지만 인코더 디코더 구조 유지되는 모습을 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b073a-b419-4840-affc-cba56233b88e",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acba1a09-9a63-4f5a-af93-9e5862c9aa6a",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "\n",
    "RNN이 자연어 처리에서 유용했던 이유\n",
    "\n",
    "- 단어의 위치에 따라 단어를 순차적으로 입력받아서 처리하는 RNN의 특성으로 인해 각 단어의 위치 정보 position information을 가질 수 있어서\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606849fe-c847-48b7-b7cd-7490385c22ed",
   "metadata": {},
   "source": [
    "**포지셔널 인코딩**\n",
    "\n",
    "- 트랜스포머는 단어의 위치 정보를 얻기 위해서 각 단어의 임베딩 벡터에 위치 정보들을 더하여 모델의 입력으로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49df96f-a7dc-42f5-bb77-d84113d448e4",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "flowchart LR\n",
    "    _-->__\n",
    "    __-->out\n",
    "    subgraph _\n",
    "    direction BT\n",
    "    Embedding_en-->Positional\\nEncoding_en\n",
    "    Positional\\nEncoding_en-->Encoders\n",
    "        subgraph Encoders\n",
    "        Encoder\n",
    "        end\n",
    "        subgraph Embedding_en\n",
    "        Text1(\"'I|am|a|student'\")\n",
    "        end\n",
    "    end\n",
    "    subgraph __\n",
    "    direction BT\n",
    "    Embedding_de-->Positional\\nEncoding_de\n",
    "    Positional\\nEncoding_de-->Decoders\n",
    "        subgraph Decoders\n",
    "        Decoder\n",
    "        end\n",
    "        subgraph Embedding_de\n",
    "        Text2(\"'<\\br>sos|je|suis|étudiant'\")\n",
    "        end\n",
    "    end\n",
    "    out(\"'je|suis|étudiant|eos'\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723a0e35-fb96-4196-b52b-db3af39ac9c4",
   "metadata": {},
   "source": [
    "- 입력으로 사용되는 임베딩 벡터들이 트랜스포머의 입력으로 사용되기 전에 포지셔널 인코딩 값이 더해지는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd295342-94fd-4943-bd50-7c8023edc7a3",
   "metadata": {},
   "source": [
    "$$PE_{(pos, 2i)} = \\sin(pos/10000^{2i/d_{model}})$$\n",
    "\n",
    "$$PE_{(pos, 2i+1)} = \\cos(pos/10000^{2i/d_{model}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba547ee-ea78-43f0-b7de-9e70df6702e5",
   "metadata": {},
   "source": [
    "- 트랜스포머가 위치 정보를 가진 값을 만들기 위해 사용하는 두 개의 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "055e6853-785e-47d8-8bb7-e698e1c44a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69cd8f4f-b618-42e7-9976-4fcc173b068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = pd.DataFrame(np.empty((4, 4), dtype=str), index=['I', 'am', 'a', 'student'])\n",
    "\n",
    "values = ['pos1,i1', 'pos1,i2', 'pos1,i3', 'pos1,i4',\n",
    "          'pos2,i1', 'pos2,i2', 'pos2,i3', 'pos2,i4',\n",
    "          'pos3,i1', 'pos3,i2', 'pos3,i3', 'pos3,i4',\n",
    "          'pos4,i1', 'pos4,i2', 'pos4,i3', 'pos4,i4']\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        d_model.iloc[i, j] = values[i * 4 + j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "587f7559-dc79-498b-a00b-8f3fd2544dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>pos1,i1</td>\n",
       "      <td>pos1,i2</td>\n",
       "      <td>pos1,i3</td>\n",
       "      <td>pos1,i4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am</th>\n",
       "      <td>pos2,i1</td>\n",
       "      <td>pos2,i2</td>\n",
       "      <td>pos2,i3</td>\n",
       "      <td>pos2,i4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>pos3,i1</td>\n",
       "      <td>pos3,i2</td>\n",
       "      <td>pos3,i3</td>\n",
       "      <td>pos3,i4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>pos4,i1</td>\n",
       "      <td>pos4,i2</td>\n",
       "      <td>pos4,i3</td>\n",
       "      <td>pos4,i4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0        1        2        3\n",
       "I        pos1,i1  pos1,i2  pos1,i3  pos1,i4\n",
       "am       pos2,i1  pos2,i2  pos2,i3  pos2,i4\n",
       "a        pos3,i1  pos3,i2  pos3,i3  pos3,i4\n",
       "student  pos4,i1  pos4,i2  pos4,i3  pos4,i4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8335c4ee-f0c5-46a2-827c-5e16338f18ca",
   "metadata": {},
   "source": [
    "- pos는 입력 문장에서 임베딩 벡터의 위치\n",
    "- i는 임베딩 벡터 내의 차원의 인덱스를 의미\n",
    "- 위 식에 따르면\n",
    "    - **짝수**면 *sin*함수 사용 $\\to$ (pos,2i)\n",
    "    - **홀수**면 *cos*함수 사용 $\\to$ (pos,2i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7864e8e5-649c-4401-9ec5-2c028094108a",
   "metadata": {},
   "source": [
    "- 여기서 $d_{model}$은 트랜스포머의 모든 층의 출력 차원을 의미하는 하이퍼파라미터\n",
    "- 임베딩 벡터도 같은 차원임\n",
    "- 이와 깉은 포지셔널 인코딩 방법을 사용하면 순서 정보가 보존됨.\n",
    "    - **각 임베딩 멕터에 포지셔널 인코딩의 값을 더하면(차원 같음!) 같은 단어라도 문장 내의 위치에 따라 트랜스포머의 입력으로 들어가는 임베딩 벡터의 값이 달라짐**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "978989a7-1b82-4862-9fc1-643863211881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53ed6687-1698-425f-ba60-6b25b50bbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "\n",
    "        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        angle_rads = np.zeros(angle_rads.shape)\n",
    "        angle_rads[:, 0::2] = sines\n",
    "        angle_rads[:, 1::2] = cosines\n",
    "        pos_encoding = tf.constant(angle_rads)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "\n",
    "        print(pos_encoding.shape)\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e97f9d1-db54-444c-9a8a-14e408172cae",
   "metadata": {},
   "source": [
    "포지셔널 인코딩 행렬 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be497287-1f0b-4fb2-918e-383c75db8e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 128)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 문장의 길이 50, 임베딩 벡터의 차원 128\n",
    "sample_pos_encoding = PositionalEncoding(50, 128)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 128))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db6253-03d8-4455-b156-5aff3da1545e",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f2181-6b97-4b43-898b-39a4cbb817cc",
   "metadata": {},
   "source": [
    "**Encoder Self-Attention**\n",
    "\n",
    "- 인코더에서 이루어짐\n",
    "- Query = Key = Value(값이 같다는 말이 아님)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b133cfb-8ef3-48b6-934b-274060ee75d1",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "flowchart LR\n",
    "    Encoder1 --> Encoder2 \n",
    "    Encoder2 --> Encoder1\n",
    "    Encoder2 --> Encoder3\n",
    "    Encoder3 --> Encoder2\n",
    "    Encoder1 --> Encoder3\n",
    "    Encoder3 --> Encoder1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e20da-793b-4724-8c01-79b6084aa7d1",
   "metadata": {},
   "source": [
    "**Masked Decoder Self-Attention**\n",
    "\n",
    "- 디코더에서 이루어짐\n",
    "- Query = Key = Value(값이 같다는 말이 아님)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca3cfe5-de6a-419f-b2b2-c5f180780c2c",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "flowchart RL\n",
    "    Decoder1\n",
    "    Decoder2 --> Decoder1\n",
    "    Decoder3 --> Decoder1\n",
    "    Decoder3 --> Decoder2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f291c789-7050-475f-94f1-d0626e2fa9f1",
   "metadata": {},
   "source": [
    "**Encoder-Decoder Attention**\n",
    "\n",
    "- 디코더에서 이루어짐\n",
    "- Query = 디코더 벡터, Key = Value = 인코더 벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a524d030-a53c-47bc-912b-33575bebdf7f",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "flowchart RL\n",
    "    Encoder1\n",
    "    Encoder2\n",
    "    Encoder3\n",
    "    Decoder --> Encoder1\n",
    "    Decoder --> Encoder2\n",
    "    Decoder --> Encoder3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c6d9fd-340a-4735-9efc-e0058f1b8bc7",
   "metadata": {},
   "source": [
    "::: {.callout-important}\n",
    "\n",
    "셀프 어텐션은 Query, Key, Value가 동일한 경우를 말함\n",
    "\n",
    "Encoder-Decoder Attention의 경우 Query가 디코더의 벡터인 반면에 Key와 Value가 인코더의 벡터이므로 셀프 어텐션이라고 부르지 않음\n",
    "\n",
    "**여기서 Query, Key 등이 같다는 것은 벡터의 값이 같다는 것이 아닌 벡터의 출처가 같다는 의미**\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a33c3-cc26-48d2-a4cc-5588f4e6eea6",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "flowchart BT\n",
    "  subgraph Encoders\n",
    "    direction BT\n",
    "        direction BT\n",
    "        Multi-head\\nSelf-Attention -->Position-wise\\nFFNN_en\n",
    "    end\n",
    "    subgraph Decoders\n",
    "    direction BT\n",
    "        direction BT\n",
    "        Masked\\nMulti-head\\nSelf-Attention -->Multi-head\\nAttention --> Position-wise\\nFFNN_de\n",
    "    end\n",
    "  Position-wise\\nFFNN_en --> Multi-head\\nAttention\n",
    "  embedding_en-->Positional\\nencoding_en-->Multi-head\\nSelf-Attention\n",
    "  embedding_de-->Positional\\nencoding_de-->Masked\\nMulti-head\\nSelf-Attention \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a574c5-da1c-4c82-aeaa-b56ef8af33ce",
   "metadata": {},
   "source": [
    "위(각각 하나의 층으로 봄)의 인코더, 디코더가 num_layer지정한 수만큼 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d5dd57-8039-4a00-9d85-b09f4b6938f3",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8557ee-29d4-4956-9acf-aaf56576d39c",
   "metadata": {},
   "source": [
    "- 하나의 인코더 층은 크게 두 개의 서브층sublayer로 나뉨\n",
    "    - 셀프 어텐션 Self Attention\n",
    "    - 피드 포워드 신경망 Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcba1394-c1d2-41ca-aa70-73a50a0e2896",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "\n",
    "**Multi-head Self Attention**\n",
    "\n",
    "- 셀프 어텐션을 병렬적으로 사용하였다는 의미\n",
    "\n",
    "**Position-wise FFNN**\n",
    "\n",
    "- 순방향신경망\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e553e82b-08be-47b1-9cdd-78f4b3a7c9c6",
   "metadata": {},
   "source": [
    "# Self Attention of Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f80a94-2685-4532-b7eb-fac2704f651d",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "\n",
    "Remind\n",
    "\n",
    "- 어텐션 함수는 주어진 Query에 대해 모든 Key와의 유사도를 구함\n",
    "- 유사도를 가중치로 하여 Key와 맴핑되어 있는 각각의 Value에 반영해 좀\n",
    "- 이 유사도가 반영된 Value를 모두 가중합하여 Return\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db55743-77df-46b9-bb03-d72216d03a06",
   "metadata": {},
   "source": [
    "- seq2seq에서의 Q,K,V의 정의\n",
    "    - Q = Query, t 시점의 디코더 셀에서의 은닉상태\n",
    "    - K = Key, 모든 시점의 인코더 셀의 은닉상태들\n",
    "    - V = Value, 모든 시점의 인코더 셀의 은닉상태들\n",
    "    \n",
    "$\\to$ t 시점의~의 의미는 변하면서 반복적으로 쿼리 수행하니까 결국은 전체 시점에 대해서 일반화 가능\n",
    "\n",
    "- seq2seq에서의 Q,K,V의 정의\n",
    "    - Q = Query, 모든 시점의 디코더 셀에서의 은닉상태들\n",
    "    - K = Key, 모든 시점의 인코더 셀의 은닉상태들\n",
    "    - V = Value, 모든 시점의 인코더 셀의 은닉상태들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab0de5e-f623-4998-8f22-23868796ef01",
   "metadata": {},
   "source": [
    "## 1. Self Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49644d7-e403-42d5-b7df-726eda7c40f0",
   "metadata": {},
   "source": [
    "- *셀프 어텐션*\n",
    "    - Q = 입력 문장의 모든 단어 벡터들\n",
    "    - K = 입력 문장의 모든 단어 벡터들\n",
    "    - V = 입력 문장의 모든 단어 벡터들\n",
    "    \n",
    "- **연속된 문장들에 대하여 지칭하는 단어가 다르지만 의미는 같을 수 있는데, 셀프 어텐션은 이 유사도를 구하여서 연관 가능성을 찾아낸다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da320dc-e4ec-4b8d-9177-4c8c0ada292d",
   "metadata": {},
   "source": [
    "## 2. Q, K, V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368cec24-01d6-4df4-8b93-73f5bf2b1195",
   "metadata": {},
   "source": [
    "- 셀프 어텐션은 일단 문장의 각 단어 벡터로부터 Q벡터, K벡터, V벡터를 얻음.\n",
    "    - Q벡터, K벡터, V벡터는 $d_{model}$ 차원을 가지는 단어 벡터들보다 더 작은 차원을 가짐\n",
    "    - 논문을 예로 들면 $d_{model}$의 차원은 512, Q벡터, K벡터, V벡터의 차원은 각각 64\n",
    "    - 이 64는 또 다른 하이퍼파라미터인 num_heads로 결정되는데, 트랜스포머는 $d_{model}$을 num_heads로 나눈 값을 Q벡터, K벡터, V벡터의 차원으로 결정.\n",
    "    - 논문의 num_heads = 8이었으니까 $512/8 = 64$로 결정된 것\n",
    "    - 이 Q벡터, K벡터, V벡터는 단어마다, 벡터마다 서로 다른 가중치 행렬을 곱하여 얻음\n",
    "    - 각 단어마다 Q벡터, K벡터, V벡터 각각의 가중치, Q벡터, K벡터, V벡터 각각이 존재하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc9720-1082-4b82-9092-31c7cb9752cd",
   "metadata": {},
   "source": [
    "## 3. Scaled dot-product Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3f0df7-525b-48f0-b971-dc97df76af50",
   "metadata": {},
   "source": [
    "각 단어 별로 Q벡터, K벡터, V벡터를 구한 후 각 Q벡터는 모든 K벡터에 대해서 어텐션 스코어를 구하고, 어텐션 분포를 구한 뒤 이를 사용하여 모든 V벡터를 가중합하여 어텐션 값 또는 컨텍스트 벡터를 구함-> 모든 Q벡터에 대해 반복\n",
    "\n",
    "- 내적한 후 특정값을 나눔으로써 값을 조정하는 과정 추가한 스케일드 갓-프로덕트 어텐션"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7012c46-38df-4f15-8559-b25eca06cfda",
   "metadata": {},
   "source": [
    "$$score(q,k) = \\frac{q k}{\\sqrt{n}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2c7d15-316e-4b7d-9466-dd64e2a9df6f",
   "metadata": {},
   "source": [
    "$\\sqrt{n}$이 결정되는 과정\n",
    "\n",
    "- 논문을 예로 들면 $d_{model}$의 차원이 512, num_heads가 8, Q,K,V의 차원 $d_k$가 64(512/8) 이었음, 여기서 64에 root 취한 8으로 결정되는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b744b945-b7c4-4868-9dd6-2857ca10964b",
   "metadata": {},
   "source": [
    "## 4. 행렬 연산으로 일괄 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb1573-e616-44b6-b8a3-39ef2adea3eb",
   "metadata": {},
   "source": [
    "Q 벡터마다 3을 연산하는 것을 피하기 위함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cbe995-32fd-40c4-87da-a40dbf1c0324",
   "metadata": {},
   "source": [
    "1. 문장 행렬에 가중치 행렬을 곱하여 Q행렬, K행렬, V행렬을 구한다(단지 벡터를 행렬화한 것 뿐).\n",
    "2. 각 단어의 Q벡터와 전치한 K벡터의 내적이 각 행렬의 원소가 되는 행렬을 결과로 추출.\n",
    "3. 2번의 결과에 $\\sqrt{d_k}$를 나누어 softmax취한 후 V행렬을 곱하여 각 행과 열이 어텐션 스코어 값을 가지는 행렬을 구함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d5eba6-9468-4e00-b1e9-287210dd5801",
   "metadata": {},
   "source": [
    "\n",
    "$$Attention(Q,K,V) = softmax(\\frac{QK^\\top}{\\sqrt{d_k}})V$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a9f77-0774-4660-8755-055e774b8a93",
   "metadata": {},
   "source": [
    "입력 문장의 길이가 seq_len이라면, 문장 행렬의 크기는 (seq_len,$d_{model}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990b90f9-4644-4433-9b9b-4dab09f775d7",
   "metadata": {},
   "source": [
    "*차원 정리*\n",
    "\n",
    "- $Q$ = (seq_len, $d_k)$\n",
    "    - $W^Q = (d_{model},d_k)$\n",
    "- $K^\\top$ = ($d_k$, seq_len)\n",
    "    - $W^K = (d_{model},d_k)$\n",
    "- $V$ = (seq_len, $d_v)$\n",
    "    - $W^V = (d_{model},d_v)$\n",
    "- 논문에서는 $d_k,d_v$의 차원이 $d_{model}$/num_heads로 같게 설정함\n",
    "- attention score matrix = (seq_len, $d_v$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68673f9b-1533-42b8-b79e-1ed71bf7f2a7",
   "metadata": {},
   "source": [
    "## 5. Scaled dot-product attention 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0d50db6-25a1-4707-ae41-729459cf12b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "    # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 스케일링\n",
    "    # dk의 루트값으로 나눠준다.\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77945268-c7eb-455a-aba7-aa6724c280b0",
   "metadata": {},
   "source": [
    "scaled_dot_product_attention 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6934d835-610a-4e83-9e25-7e6f73446d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 Query, Key, Value인 Q, K, V 행렬 생성\n",
    "np.set_printoptions(suppress=True)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff90d7f-beac-4cea-b610-66f618e59fc7",
   "metadata": {},
   "source": [
    "query에 해당하는 [0,10,0]은 key에 해당하는 두 번째 값과 일치해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fcb9498f-f1f5-467e-9ae9-ae571ae68ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 함수 실행\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05776046-9204-453d-8c38-e3c456f5409d",
   "metadata": {},
   "source": [
    "두 번째 값과 일치했어서 두 번째가 1인 값을 반환, 결과적으로 [10,0]의 어텐션 값 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "35a9a9ee-70b4-4042-a45c-d637135d3300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e8148-9c11-4494-84e7-8b9c69454dd0",
   "metadata": {},
   "source": [
    "세 번째 값과 네 번째 값이 같이 일치하다면? 합이 1이되게 나눠서 0.5,0.5씩 나눠짐\n",
    "\n",
    "- [100,5] * 0.5 + [1000,6] * 0.5 = [550,5.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9109bb59-034d-4977-8982-e2334b2874d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[550.0, 5.5]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[100*0.5 + 1000*0.5,5*0.5 + 6*0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "56ab8cb8-b474-466f-aaf0-566fcdbff102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b881d2-a1b1-41dd-9335-0fae8c7249a7",
   "metadata": {},
   "source": [
    "## 6. Multi-head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33154ca2-7fed-493b-a6c6-b01b6956bba6",
   "metadata": {},
   "source": [
    "왜 스케일링하여 어텐션 스코어를 구했을까?\n",
    "\n",
    "- 논문에서는 한 번의 어텐션보다 여러번의 어텐션을 병렬로 사용하는 것이 더 효과적이라고 판단\n",
    "- 그래서 $d_{model}$의 차원을 num_heads로 나누어 $d_{model}$/num_heads의 차원을 가지는 Q,K,V에 대해서 num_heads 개의 병렬 어텐션 수행\n",
    "- num_heads만큼 병렬이 이뤄지는데, 이 때 나오는 각각의 **어텐션 값 행렬을 어텐션 헤드**라고 함.\n",
    "    - 이 때 가중치 행렬의 값$W^Q,W^K,W^V$은 num_heads의 어텐션 해드마다 전부 다름\n",
    "    \n",
    "병렬로 수행한 효과?\n",
    "\n",
    "- 어텐션을 병렬로 수행하여 다른 시각으로 정보를 수집할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4582be89-9210-492c-af86-c18b2ac89039",
   "metadata": {},
   "source": [
    "## 7. Multi-head Attention 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57494d02-4c16-4a01-b83a-d1c33e4827b4",
   "metadata": {},
   "source": [
    "가중치 행렬\n",
    "\n",
    "- Q, K, V 행렬을 만들기 위한 가중치 행렬 $W^Q,W^K,W^V$\n",
    "- 어텐션 헤드들을 연결concatenation 후에 곱해주는 행렬 $W^O$\n",
    "\n",
    "가중치 행렬을 곱하는 것은 Dense layer 지나게 하여 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b87461-f81a-4b7d-8c7e-e3a3376daa7e",
   "metadata": {},
   "source": [
    "1. $W^Q,W^K,W^V$에 해당하는 $d_{model}$의 크기의 밀집층(Dense layer)을 지나게 한다.\n",
    "2. 지정된 헤드수 num_heads 만큼 나눈다(split).\n",
    "3. scaled dot-product attention\n",
    "4. 나눠졌던 헤드들을 연결concatenatetion한다.\n",
    "5. $W^O$에 해당하는 밀집층을 지나게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "72364367-2de9-4bdf-8b4e-a5584f8638a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        # d_model을 num_heads로 나눈 값.\n",
    "        # 논문 기준 : 64\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        # WO에 해당하는 밀집층 정의\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "        # q : (batch_size, query의 문장 길이, d_model)\n",
    "        # k : (batch_size, key의 문장 길이, d_model)\n",
    "        # v : (batch_size, value의 문장 길이, d_model)\n",
    "        # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 2. 헤드 나누기\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "        # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 4. 헤드 연결(concatenate)하기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 5. WO에 해당하는 밀집층 지나기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335095f6-086b-4953-97ca-12c981cab4a5",
   "metadata": {},
   "source": [
    "## 8. Padding Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5b341b-2353-4f70-a321-af972f22bffb",
   "metadata": {},
   "source": [
    "어텐션에서 제외하기 위해 값을 가리는 역할\n",
    "\n",
    "- 방법: 어텐션 스코어 행렬의 마스킹 위치에 매우 작은 음수값을 넣어주기\n",
    "    - 소프트맥스 함수를 지나면 값이 0이 되어 유사도 구할때 반영되지 않름."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c61087ec-60de-4d62-a4c6-14e993ca662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, key의 문장 길이)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "19ae654c-aab8-4379-b26d-0bb09747ddef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac122ce4-931a-40cc-b9ef-f465597e89ac",
   "metadata": {},
   "source": [
    "# Position-wise Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d24c44f-4ce1-4cdb-8e4d-4c17833d5220",
   "metadata": {},
   "source": [
    "인코더와 디코더에서 공통적으로 가지고 있는 서브층\n",
    "\n",
    "= FFNN(Fully Connected FFNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bbc414-3e83-4152-aebd-655eac7b7316",
   "metadata": {},
   "source": [
    "$$FFNN(x) = MAX(0,xW-1 + b_1)W_2 + b_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f84083-b102-4d3a-a3a4-2023d9b0b8eb",
   "metadata": {},
   "source": [
    "$x$ -> $F_1 = xW_1 + b_1$ -> 활성화 함수:ReLU $F_2 = max(0,F_1)$ -> $F_3 = F_2W_2 + b_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba83cf05-eb9c-4740-93a9-ce513c5d0419",
   "metadata": {},
   "source": [
    "- 여기서 $x$는 멀티 헤드 어텐션의 결과로 나온 (seq_len, $d_{model}$)의 차원을 가지는 행렬\n",
    "- 가중치 행렬 $W_1$ = ($d_{model}, d_{ff}$)\n",
    "- 가중치 행렬 $W_2$ = ($d_{ff},d_{model}$)\n",
    "- 논문은 $d_{ff}$를 2048로 정의\n",
    "- 매개변수 $W_1,W_2,b_1,b_2$는 각 인코더 층마다 동일하게 계산되지만 값은 층마다 다 다르다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0331bd4-ac3f-475f-96c3-8a7864349788",
   "metadata": {},
   "source": [
    "```python\n",
    "# 다음의 코드는 인코더와 디코더 내부에서 사용할 예정입니다.\n",
    "outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c88fdf8-98bd-48e5-9760-f7f2ae5efebe",
   "metadata": {},
   "source": [
    "# Residual connection and Layer Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76b6768-0c42-4b80-a3da-921b416ef0a1",
   "metadata": {},
   "source": [
    "## 1. 잔차 연결"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db5156a-ba51-4d2f-9ae7-b28759fc473e",
   "metadata": {},
   "source": [
    "$$H(x) = x + F(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa59a1d-e3d4-4553-99ca-df3a9043296d",
   "metadata": {},
   "source": [
    "- $F(x)$는 트랜스포머에서 서브층에 해당\n",
    "- 즉, 장차 연결은 서브층의 입력과 출력을 더하는 것\n",
    "- 서브층의 입력과 출력은 동일한 차원을 갖고 있어서 가능\n",
    "- 그래서 재귀하는 것처럼 다이어그램 그려보면 화살표가 출력층에서 나와 입력층으로 들어가는 모습\n",
    "- *잔차 연결은 컴퓨터 비전 분야에서 주로 사용되는 모델의 학습을 돕는 기법*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d34f16-c9c8-412d-bf2b-7c6dda8aa59a",
   "metadata": {},
   "source": [
    "식으로 표현 -> $x + Sublayer(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaeefbc-7216-4761-9e7f-f4e1be7c7195",
   "metadata": {},
   "source": [
    "서브층이 멀티 헤드 어텐션이었다면 $H(x) - x + Multi - head Attention(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f1883-06a9-4809-8c7c-b7fe2c287f93",
   "metadata": {},
   "source": [
    "참고 : [잔차연결 관련 논문](https://arxiv.org/pdf/1512.03385.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ce422-c340-48ad-b185-75c8361ac388",
   "metadata": {},
   "source": [
    "## 2. 층 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c297ec-094e-4b8d-8a1b-999c3df48755",
   "metadata": {},
   "source": [
    "잔차연결과 층 정규화 모두 수행한 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ff96dd-e95b-4bbc-a3f5-367d1f03209a",
   "metadata": {},
   "source": [
    "$$LN = LayerNorm(x+Sublayer(x))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cfc545-5af9-44c4-bb19-1fc7364800d9",
   "metadata": {},
   "source": [
    "텐서의 마지막 차원에 대하여 평균과 분산을 구하고, 이를 가지고 어떤 수식을 통해 값을 정규화하여 학습을 도움\n",
    "\n",
    "- 텐서의 마지막 차원 = 트랜스포머에서는 $d_{model}$ 차원을 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eb17f3-69aa-4539-b99b-874ac9df2e72",
   "metadata": {},
   "source": [
    "1. 평균과 분산을 통한 벡터 $x_i$ 정규화\n",
    "\n",
    "    - 스칼라인 평균과 분산 도출\n",
    "    - $\\epsilon$은 분모가 0이 되는 것을 방지\n",
    "    \n",
    "$$\\hat{x}_{i,k} = \\frac{x_{i,k} - \\mu_i}{\\sqrt{\\sigma^2_i + \\epsilon}}$$\n",
    "    \n",
    "2. 감마와 베타 도입\n",
    "\n",
    "- LayerNormalization(케라스에 내장되어 있음)\n",
    "\n",
    "$$ln_i = \\gamma \\hat{x}_i + \\beta = LayerNorm(x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b94f2-d3dd-4f22-94ac-5eac522b8fe4",
   "metadata": {},
   "source": [
    "참고: [층 정규화 관련 논문](https://arxiv.org/pdf/1607.06450.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4706d23f-36b1-4d1b-88c6-0757a58e20ee",
   "metadata": {},
   "source": [
    "# Encoder 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c607a51-c064-4b54-ba11-0a3127a61ee3",
   "metadata": {},
   "source": [
    "인코더 입력으로 들어가는 문장에는 패딩이 있을 수 있으므로 어텐션 시 패딩 토큰을 제외하도록 패딩 마스크를 사용\n",
    "\n",
    "- multiheadattention 함수의 mask 인자값으로 padding_mask가 사용되는 이유\n",
    "- 인코더는 두 개의 서브층으로 이루어짐\n",
    "    - 멀티 헤드 어텐션\n",
    "    - 피드 포워드 신경망\n",
    "- 서브층 이후 드롭 아웃, 잔차 연결, 층 정규화 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3ae96cd5-114b-4be9-8e7d-4ef4e89ea339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "          'mask': padding_mask # 패딩 마스크 사용\n",
    "      })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ef6304-8a12-473c-9d1f-23b19f7677d3",
   "metadata": {},
   "source": [
    "# Encoder 쌓기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7f3d13e3-1bb1-49df-855f-d450527e6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 인코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "            dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7d7052-1254-4831-90bb-cc87eaffa764",
   "metadata": {},
   "source": [
    "인코더 층을 num_layers 만큼 쌓는 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1f8597-fdf1-49d3-a0b5-49b245feeea6",
   "metadata": {},
   "source": [
    "# Encoder에서 Decoder로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca3bc94-f6e6-41a0-bd4b-f5348918cee8",
   "metadata": {},
   "source": [
    "인코더에서 num_layers만큼 총 연산을 순차적으로 한 후 마지막 층의 인코더의 출력을 디코더로 전달"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e081a73a-9854-45e5-9341-c54aee574e64",
   "metadata": {},
   "source": [
    "# Decoder: Self-Attention and Look-ahead Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76eb2f0-c989-48f3-97f1-0931066e1bb9",
   "metadata": {},
   "source": [
    "트랜스포머는 문장 행렬로 입력을 한 번에 받기 때문에 현재 시점의 단어를 예측하고자 할 때 입력 문장 행렬로부터 미래 시점의 단어까지 참고하느 현상이 발생\n",
    "\n",
    "이를 위해 디코더에서 현재 시점의 예측에서 현재 시점보다 미래에 있는 단어들을 참고하지 못하도록 룩-어헤드 마스크 도입\n",
    "\n",
    "**디코더의 첫번때 서브층에서 이루어짐**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe62c26-d1e7-4818-b118-c3b1cd0a420f",
   "metadata": {},
   "source": [
    "**디코더의 셀프 어텐션은 인코더의 멀티 헤드 셀프 어텐션과 동일한 연산을 수행하나, 어텐션 스코어 행렬에서 마스킹을 적용하는 점이 다름**\n",
    "\n",
    "-> 미리보기 방지를 위함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275945dc-b62b-4a4e-99e3-aa68b35c95bc",
   "metadata": {},
   "source": [
    "트랜스포머 마스킹의 종류\n",
    "\n",
    "1. 인코더의 셀프 어텐션 = 패딩 마스크를 전달\n",
    "2. 디코더의 첫번째 서브층인 마스크드 셀프 어텐션 = 룩-어헤드 마스크를 전달\n",
    "3. 디코더의 두번째 서브층인 인코더-디코더 어텐션 = 패딩 마스크를 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1319658c-8e9c-4d32-adcd-62faa5d79c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4264cf-6779-4f9e-8358-24d66cdd5a60",
   "metadata": {},
   "source": [
    "마스킹을 하고자 하는 위치에 1, 마스킹을 하지 않고자 하는 위이에 0을 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9af79fef-0b4b-4ac1-9cf2-28a3641ff4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 0. 1.]\n",
      "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ffdb3c-8c81-407e-8774-b6297288ed46",
   "metadata": {},
   "source": [
    "## 2nd Decoder sublayer : Encoder-Decoder Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b47e72a-6182-47e4-a9a6-5ad6b7f36521",
   "metadata": {},
   "source": [
    "디코더 두번째 서브층은 멀티 헤드 어텐션을 수행한다는 점에서 이전의 어텐션들(인코더와 디코더의 첫번째 서브층)과는 공통점이 있으나 이건 **셀프 어텐션이 아님!**\n",
    "\n",
    "- **셀프 어텐션은 Query, Key, Value가 출처가 같은 경우를 말하는데, 인코더-디코더 어텐션은 Query가 디코더인 행렬인 반면, Key, Value가 인코더 행렬이기 때문**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91dd001-6a70-413b-a1b1-7ec50683260f",
   "metadata": {},
   "source": [
    "- 인코더의 첫번째 서브층 = Query = Key = Value\n",
    "- 디코더의 첫번째 서브층 = Query = Key = Value\n",
    "- 디코더의 두번째 서브층 = Query = 디코더 행렬(의 첫번째 서브층 결과), Key = Value = 인코더 행렬(의 마지막 층에서 얻은 값)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4616f481-f4b5-466a-9aad-ccfd529e5e4a",
   "metadata": {},
   "source": [
    "# Decoder 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64de39f-0a92-4be8-940c-c5de32adff0b",
   "metadata": {},
   "source": [
    "첫번째 서브층은 mask 인자값으로 look_ahead_mask가 들어가고, 두 번째 서브층은 mask의 인자값으로 padding_mask가 들어가있음\n",
    "\n",
    "세 개의 서브층 모두 서브층 연산 후에는 드롭 아웃, 잔차 연결, 층 정규화가 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ba3ac2e9-e459-4533-8964-29a2438f96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "    # 룩어헤드 마스크(첫번째 서브층)\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "    # 패딩 마스크(두번째 서브층)\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "          'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "      })\n",
    "\n",
    "    # 잔차 연결과 층 정규화\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "          'mask': padding_mask # 패딩 마스크\n",
    "      })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f14b84-4c0f-4030-9031-7cb5b741eece",
   "metadata": {},
   "source": [
    "# Decoder 쌓기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07498b49-a6b7-403a-9852-15145ff4ed97",
   "metadata": {},
   "source": [
    "num_layers 개수만큼 쌓기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9ac2fec8-f01b-4e52-87b9-c21b330c0de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 디코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "            dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1304a96-2279-46fc-9125-8036c0938736",
   "metadata": {},
   "source": [
    "# Transformer 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95320f8-7866-4d63-ac98-fd929c4ea4f2",
   "metadata": {},
   "source": [
    "vocab_size는 다중 클래스 분류 문제를 풀 수 있도록 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d0705418-7667-416b-83f2-85e3547721cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                d_model, num_heads, dropout,\n",
    "                name=\"transformer\"):\n",
    "\n",
    "    # 인코더의 입력\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 디코더의 입력\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더의 패딩 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask, output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 디코더의 패딩 마스크(두번째 서브층)\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "    enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "    # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "    dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 다음 단어 예측을 위한 출력층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39136775-dba7-4064-9f18-420f5843c01f",
   "metadata": {},
   "source": [
    "# Transformer hyperparameter 정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6315520c-95c1-4f74-984c-631a8f1af336",
   "metadata": {},
   "source": [
    "예제\n",
    "- num_layers = 4 # 인코더,디코더 층의 개수\n",
    "- $d_{ff}$ = 128 # 포지션 와이즈 피드 포워드 신경망의 은닉층\n",
    "- $d_{model}$ = 128 # 인코더와 디코더의 입, 출력의 차원\n",
    "- num_heads = 4 # 멀티-헤드 어텐션에서 병렬적으로 사용할 헤드의 수\n",
    "    - $d_v$ = 128 / 4 = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "66dcc913-8656-49a9-9850-3855d84810ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9000, 128)\n",
      "(1, 9000, 128)\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "small_transformer = transformer(\n",
    "    vocab_size = 9000,\n",
    "    num_layers = 4,\n",
    "    dff = 512,\n",
    "    d_model = 128,\n",
    "    num_heads = 4,\n",
    "    dropout = 0.3,\n",
    "    name=\"small_transformer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    small_transformer, to_file='small_transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee94c0a-e627-4cc8-920c-d63a8c7e1e17",
   "metadata": {},
   "source": [
    "# Loss Function 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692f90a9-b98c-4bdd-a3e4-553a4c1abef1",
   "metadata": {},
   "source": [
    "예제가 다중 클래스라 크로스 엔트로피 함수를 손실 함수로 정의함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b8cf5176-d8fe-42cf-84f9-7c031f227ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b703f40-1b0c-4992-b696-a47fcbe289e1",
   "metadata": {},
   "source": [
    "# 학습률"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a994a0-0b2c-4316-bf22-fd60be9a084a",
   "metadata": {},
   "source": [
    "$$lrate = d^{-0.5}_{model} \\times min(step_num^{-0.5} , step_num \\times warmup_steps^{-1/4})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8a9f37fc-bfa3-4aa6-8188-b3118a4930f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e00e59c8-a11e-4bc6-8c40-859ac9eb7981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d196b998-c240-4e5f-844f-cc4091738923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
