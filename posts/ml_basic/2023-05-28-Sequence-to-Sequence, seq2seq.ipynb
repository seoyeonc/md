{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2947993f-78f6-4c0c-92d9-14d0f69c071c",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"Sequence-to-Sequence, seq2seq\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-05-28\"\n",
    "categories:\n",
    "  - seq2seq\n",
    "  - teacher forcing 교사 강요\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc6073-149f-47f4-9ee5-8f19a89e7a1d",
   "metadata": {},
   "source": [
    "> Sequence-to-Sequence, seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4825fe-1323-4110-a169-c237e2cc20f2",
   "metadata": {},
   "source": [
    "Ref: [딥러닝을 이용한 자연어 처리 입문](https://wikidocs.net/24996), [keras](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b571dd3-c15d-4503-aca5-1b0a8e176bb8",
   "metadata": {},
   "source": [
    "# Seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239c78bf-e9ba-45d1-9265-e0d676c58762",
   "metadata": {},
   "source": [
    "*기본 디자인*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39774f06-7c53-4462-b22d-556b01529bbc",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "%%| fig-width: 6.5\n",
    "flowchart LR\n",
    "  A[I am a student] --> B{Encoder}\n",
    "  B --> C{Context}\n",
    "  C --> D{Decoder}\n",
    "  D --> E[je suis étudiant]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5bcd3c-3559-442e-af56-92b66ea20704",
   "metadata": {},
   "source": [
    "인코더\n",
    "\n",
    "- 모든 단어들을 순차적으로 입력받은 뒤에 마지막에 이 모든 단어 정보들을 압축해서 하나의 벡터로 만듦(컨텍스트 벡터)\n",
    "- 이 컨텍스트 벡터^[컨텍스트 벡터는 보통 수백차원 이상]를 디코더로 전달\n",
    "\n",
    "디코더\n",
    "\n",
    "- 컨텍스트 벡터를 받아서 번역된 단어를 하나씩 순차적으로 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a313b327-a59b-4bbc-9347-7a91e82a9cc6",
   "metadata": {},
   "source": [
    "*내부 확대*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647f9238-6058-4003-9fa8-3583a035e678",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "flowchart LR\n",
    "    a4-->b1\n",
    "    b1-->c1\n",
    "    subgraph Encoder\n",
    "    a1[LSTM \\n I]-->a2[LSTM \\n am]\n",
    "    a2-->a3[LSTM \\n a]\n",
    "    a3-->a4[LSTM \\n student]\n",
    "    end\n",
    "    subgraph context\n",
    "    b1\n",
    "    end\n",
    "    subgraph Decoder\n",
    "    c1[LSTM \\n eos]-->c2[LSTM \\n je]\n",
    "    c2-->c3[LSTM \\n suis]\n",
    "    c3-->c4[LSTM \\n étudiant]\n",
    "    end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e953a7f-2dea-4289-9b2e-bdb09ccf4543",
   "metadata": {},
   "source": [
    "- 인코더와 디코더는 두 개의 RNN 아키텍처로 이루어져 있음.\n",
    "- 인코더: 입력 문장을 받는 RNN 셀\n",
    "- 디코더: 출력 문장을 받는 RNN 셀\n",
    "\n",
    "**RNN, LSTM, GRU 중 무엇을 사용하느냐는 모델에 따라, 성능에 따라 달리 선택**\n",
    "\n",
    "- 인코더는 단어 토큰화를 통해 단어들을 RNN 셀의 각 시점으로 입력하는데 그 후에 인코더 RNN 셀의 마지막 시점의 은닉 상태(컨텍스트벡터)를 디코더 RNN 셀로 넘겨줌.\n",
    "\n",
    "**컨텍스트 벡터는 디코더의 첫번째 은닉 상태에 사용**\n",
    "\n",
    "- 초기값인 sos가 들어가면 순차적으로 다음에 올 단어를 예측 후 다음 타임스템에 전달, eos가 나올때까지 진행됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68726dc-6772-4c45-9d80-32b922405180",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "\n",
    "$\\star$ sos\n",
    "\n",
    "- 디코더의 초기 입력, 문장의 시작을 의미\n",
    "- 다음 등장할 확률이 높은 단어를 예측\n",
    "\n",
    "$\\star$ eos\n",
    "\n",
    "- 디코더의 끝 값, 문장의 끝을 의미\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0d6834-82f7-492a-a424-e8388cc70a80",
   "metadata": {},
   "source": [
    "- 각 RNNLM(RNN Language Model)은 단어 토큰을 입력 받을 때 임베딩 과정을 거쳐서 텍스트를 벡터로 바꿈(단, 사이즈는 수백 개의 차원을 가질 수 있음)\n",
    "\n",
    "**하나의 RNN 셀 확대**\n",
    "\n",
    "- 입력\n",
    "    - time step t-1에서의 은닉 상태\n",
    "    - 현재 time-step t에서의 입력 벡터\n",
    "- 은닉 상태(입력으로 만들어낸, 필요없으면 값 무시 가능)\n",
    "    - time step t에서의 은닉 상태\n",
    "    - 현재 time-step t에서의 은닉 상태\n",
    "- 의미하는 바\n",
    "    - 현재 시점 t에서의 은닉 상태는 과거 시점의 동일한 RNN 셀에서의 모든 은닉 상태의 값들의 영향을 누적해서 받아온 값\n",
    "    - 입력 문장의 단어 토큰들의 정보를 요약해서 담고 있다고 할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e50d07-cbf6-42d1-8a87-cb024a0d0856",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "classDiagram\n",
    "    Decoder <|-- sos\n",
    "    Decoder <|-- je\n",
    "    Decoder <|-- suis\n",
    "    Decoder <|-- étudiant\n",
    "    je_out <|-- Decoder\n",
    "    suis_out <|-- Decoder\n",
    "    étudiant_out <|-- Decoder\n",
    "    eos <|-- Decoder\n",
    "    Decoder : LSTM\n",
    "    class sos{\n",
    "      embedding\n",
    "    }\n",
    "    class je{\n",
    "      embedding\n",
    "    }\n",
    "    class suis{\n",
    "      embedding\n",
    "    }\n",
    "     class étudiant{\n",
    "      embedding\n",
    "    }\n",
    "    class je_out{\n",
    "      softmax\n",
    "      Dense\n",
    "    }\n",
    "    class suis_out{\n",
    "      softmax\n",
    "      Dense\n",
    "    }\n",
    "     class étudiant_out{\n",
    "      softmax\n",
    "      Dense\n",
    "    }\n",
    "    class eos{\n",
    "      softmax\n",
    "      Dense\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a62f9-8fad-4a26-ae08-f0d2108d0c66",
   "metadata": {},
   "source": [
    "# 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be8122dc-37af-4699-858d-ba254429437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import urllib3\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d66b9b81-7d0e-4695-9c05-742461bfade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
    "filename = 'fra-eng.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28ab47ab-55c2-4a50-b364-776b0ace03ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f1c7304-3248-4ded-928e-21871d48b1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/csy/Dropbox/md/posts/ml_basic'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4507e63-118d-4329-95c5-ad3e003544e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipfilename = os.path.join(path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94936cbe-902d-4840-802f-7a967179a46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/csy/Dropbox/md/posts/ml_basic/fra-eng.zip'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipfilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5099912-a688-4757-8988-cf783c72fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "    shutil.copyfileobj(r, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea420cca-6734-45f8-85f3-3bcdc0e8b350",
   "metadata": {},
   "source": [
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4092d377-117e-4d3c-a439-bfe5cdbcfa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = pd.read_csv('./fra.txt', names=['src', 'tar', 'lic'], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e24478a1-1c55-4dcc-8ce4-ce677d2aa304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 개수 : 217975\n"
     ]
    }
   ],
   "source": [
    "del lines['lic']\n",
    "print('전체 샘플의 개수 :',len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bec5972d-66b0-4c86-99f9-a0ec47436a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57809</th>\n",
       "      <td>There are no examples.</td>\n",
       "      <td>Il n'y a pas d'exemples.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57733</th>\n",
       "      <td>The problem isn't new.</td>\n",
       "      <td>Le problème n'est pas nouveau.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39939</th>\n",
       "      <td>I use worms as bait.</td>\n",
       "      <td>J'utilise des vers comme appât.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28156</th>\n",
       "      <td>That's irrelevant.</td>\n",
       "      <td>Ça n'a rien à voir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31341</th>\n",
       "      <td>Everyone has voted.</td>\n",
       "      <td>Tout le monde a voté.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47860</th>\n",
       "      <td>I'm feeling fine now.</td>\n",
       "      <td>Maintenant je me sens bien.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>I'm pooped.</td>\n",
       "      <td>Je suis crevé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30174</th>\n",
       "      <td>You can't just go.</td>\n",
       "      <td>Tu ne peux pas simplement t'en aller comme ça.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14843</th>\n",
       "      <td>I didn't scream.</td>\n",
       "      <td>Je n'ai pas hurlé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28558</th>\n",
       "      <td>They're separated.</td>\n",
       "      <td>Ils sont séparés.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          src                                             tar\n",
       "57809  There are no examples.                        Il n'y a pas d'exemples.\n",
       "57733  The problem isn't new.                  Le problème n'est pas nouveau.\n",
       "39939    I use worms as bait.                 J'utilise des vers comme appât.\n",
       "28156      That's irrelevant.                             Ça n'a rien à voir.\n",
       "31341     Everyone has voted.                           Tout le monde a voté.\n",
       "47860   I'm feeling fine now.                     Maintenant je me sens bien.\n",
       "2181              I'm pooped.                                  Je suis crevé.\n",
       "30174      You can't just go.  Tu ne peux pas simplement t'en aller comme ça.\n",
       "14843        I didn't scream.                              Je n'ai pas hurlé.\n",
       "28558      They're separated.                               Ils sont séparés."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines.loc[:, 'src':'tar']\n",
    "lines = lines[0:60000] # 6만개만 저장\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570df87d-ee61-4b50-90bc-b72c6cfd4e7e",
   "metadata": {},
   "source": [
    "*sos, eos 대신 `\\t`,`\\n`를 입력*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99813976-40b9-4f32-93fe-ea51ad2b8834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20466</th>\n",
       "      <td>I think I got it.</td>\n",
       "      <td>\\t Je crois avoir compris. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46024</th>\n",
       "      <td>His blood is boiling.</td>\n",
       "      <td>\\t Son sang bout. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18508</th>\n",
       "      <td>You're too slow.</td>\n",
       "      <td>\\t Tu es trop lente. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31397</th>\n",
       "      <td>Everything's wrong.</td>\n",
       "      <td>\\t Tout va mal. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8888</th>\n",
       "      <td>Stop shooting.</td>\n",
       "      <td>\\t Arrêtez de tirer. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16664</th>\n",
       "      <td>Spring has come.</td>\n",
       "      <td>\\t Le printemps est arrivé. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47044</th>\n",
       "      <td>I meant the opposite.</td>\n",
       "      <td>\\t Je voulais dire le contraire. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>Leave it there.</td>\n",
       "      <td>\\t Laissez-le là. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44016</th>\n",
       "      <td>You are such a liar.</td>\n",
       "      <td>\\t Tu es un sacré menteur. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55752</th>\n",
       "      <td>I'm a biology student.</td>\n",
       "      <td>\\t Je suis étudiant en biologie. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          src                                  tar\n",
       "20466       I think I got it.        \\t Je crois avoir compris. \\n\n",
       "46024   His blood is boiling.                 \\t Son sang bout. \\n\n",
       "18508        You're too slow.              \\t Tu es trop lente. \\n\n",
       "31397     Everything's wrong.                   \\t Tout va mal. \\n\n",
       "8888           Stop shooting.              \\t Arrêtez de tirer. \\n\n",
       "16664        Spring has come.       \\t Le printemps est arrivé. \\n\n",
       "47044   I meant the opposite.  \\t Je voulais dire le contraire. \\n\n",
       "11988         Leave it there.                 \\t Laissez-le là. \\n\n",
       "44016    You are such a liar.        \\t Tu es un sacré menteur. \\n\n",
       "55752  I'm a biology student.  \\t Je suis étudiant en biologie. \\n"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6156f8aa-6665-4f61-a62a-2ecbc8586921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자 집합 구축\n",
    "src_vocab = set()\n",
    "for line in lines.src: # 1줄씩 읽음\n",
    "    for char in line: # 1개의 문자씩 읽음\n",
    "        src_vocab.add(char)\n",
    "\n",
    "tar_vocab = set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0ea5df35-122c-417c-a7c0-3872a6c6475d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장의 char 집합 : 80\n",
      "target 문장의 char 집합 : 103\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab)+1\n",
    "tar_vocab_size = len(tar_vocab)+1\n",
    "print('source 문장의 char 집합 :',src_vocab_size)\n",
    "print('target 문장의 char 집합 :',tar_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aa173a-d86f-4835-a11c-6e4504243699",
   "metadata": {},
   "source": [
    "sorted 된 상태에서 인덱스 출력해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78cfd924-deb6-4fb4-a414-57c2bdf40783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['T', 'U', 'V', 'W', 'X', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "print(src_vocab[45:75])\n",
    "print(tar_vocab[45:75])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f7ae3-ff2d-449b-85af-b38c0e9d2625",
   "metadata": {},
   "source": [
    "*문장에 인덱스 부여*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a16b9c9c-f2d1-47bc-8ef8-09b69c4a761f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, '°': 76, 'é': 77, '’': 78, '€': 79}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'a': 52, 'b': 53, 'c': 54, 'd': 55, 'e': 56, 'f': 57, 'g': 58, 'h': 59, 'i': 60, 'j': 61, 'k': 62, 'l': 63, 'm': 64, 'n': 65, 'o': 66, 'p': 67, 'q': 68, 'r': 69, 's': 70, 't': 71, 'u': 72, 'v': 73, 'w': 74, 'x': 75, 'y': 76, 'z': 77, '\\xa0': 78, '«': 79, '»': 80, 'À': 81, 'Ç': 82, 'É': 83, 'Ê': 84, 'Ô': 85, 'à': 86, 'â': 87, 'ç': 88, 'è': 89, 'é': 90, 'ê': 91, 'ë': 92, 'î': 93, 'ï': 94, 'ô': 95, 'ù': 96, 'û': 97, 'œ': 98, '\\u2009': 99, '‘': 100, '’': 101, '\\u202f': 102}\n"
     ]
    }
   ],
   "source": [
    "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
    "print(src_to_index)\n",
    "print(tar_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160ebfab-2f7d-4501-b73c-7568059c9dd7",
   "metadata": {},
   "source": [
    "train 데이터의 인코더에 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e47a5f49-3170-4464-bbad-a788bbc6c142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장의 정수 인코딩 : [[30, 64, 10], [30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "\n",
    "# 1개의 문장\n",
    "for line in lines.src:\n",
    "    encoded_line = []\n",
    "  # 각 줄에서 1개의 char\n",
    "    for char in line:\n",
    "    # 각 char을 정수로 변환\n",
    "        encoded_line.append(src_to_index[char])\n",
    "    encoder_input.append(encoded_line)\n",
    "print('source 문장의 정수 인코딩 :',encoder_input[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90634e2d-522e-4ca3-8056-1734b0f4ebef",
   "metadata": {},
   "source": [
    "디코더에 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b4312905-0449-47d0-bd2b-218fe76d04e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 문장의 정수 인코딩 : [[1, 3, 48, 52, 3, 4, 3, 2], [1, 3, 39, 52, 69, 54, 59, 56, 14, 3, 2], [1, 3, 31, 65, 3, 69, 66, 72, 71, 56, 3, 4, 3, 2], [1, 3, 28, 66, 72, 58, 56, 3, 4, 3, 2], [1, 3, 45, 52, 63, 72, 71, 3, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines.tar:\n",
    "    encoded_line = []\n",
    "    for char in line:\n",
    "        encoded_line.append(tar_to_index[char])\n",
    "    decoder_input.append(encoded_line)\n",
    "print('target 문장의 정수 인코딩 :',decoder_input[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e409a4d8-2be4-4b8d-b0a6-2f9a4c80f503",
   "metadata": {},
   "source": [
    "**디코더를 예측한 후 그 값과 비교하기 위한 실제 값을 위해 위에 추가한 `\\t`를 없애주는 과정으로서 앞의 `1` 삭제**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a08f10af-89f3-4cf1-bb56-0e24487d8c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 문장 레이블의 정수 인코딩 : [[3, 48, 52, 3, 4, 3, 2], [3, 39, 52, 69, 54, 59, 56, 14, 3, 2], [3, 31, 65, 3, 69, 66, 72, 71, 56, 3, 4, 3, 2], [3, 28, 66, 72, 58, 56, 3, 4, 3, 2], [3, 45, 52, 63, 72, 71, 3, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_target = []\n",
    "for line in lines.tar:\n",
    "    timestep = 0\n",
    "    encoded_line = []\n",
    "    for char in line:\n",
    "        if timestep > 0:\n",
    "            encoded_line.append(tar_to_index[char])\n",
    "        timestep = timestep + 1\n",
    "    decoder_target.append(encoded_line)\n",
    "print('target 문장 레이블의 정수 인코딩 :',decoder_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "58308bab-cadb-437e-8f4c-599647160eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장의 최대 길이 : 22\n",
      "target 문장의 최대 길이 : 76\n"
     ]
    }
   ],
   "source": [
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "print('source 문장의 최대 길이 :',max_src_len)\n",
    "print('target 문장의 최대 길이 :',max_tar_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9869c6-3449-4824-bee0-ca73bff8e96c",
   "metadata": {},
   "source": [
    "영어 데이터끼리, 프랑스어 데이터끼리 길이를 맞추어 패딩 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ce0f1f8e-c4f8-46a8-9fc2-2eb92943cfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24a67d8-7ef5-4701-b900-38e027ed3c54",
   "metadata": {},
   "source": [
    "원핫인코딩(문자 단위 번역기라 워드 임베딩은 별도로 사용하지 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b994df0a-aff2-4944-9de4-fc80a488f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e745bb2-4366-4953-8da9-f554800edb64",
   "metadata": {},
   "source": [
    "## Teacher Forcing 교사 강요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36392549-3747-4102-9491-83e6c4b91021",
   "metadata": {},
   "source": [
    "- train에서는 이전 시점의 디코더 셀의 출력을 현재 시점의 디코더 셀의 입력으로 넣어주지 않음.\n",
    "- 이전 시점의 실제값을 현재 시점의 디코더 셀의 입력값으로 하는 방법 사용\n",
    "    - 이전 시점의 디코더 셀의 예측이 틀렸는데 이를 현재 시점의 디코더 셀의 입력으로 사용하면 현재 시점의 디코더 셀의 예측에도 잘못될 가능성이 높음\n",
    "    - 이는 연쇄 작용으로 디코더 전체의 예측을 어렵게 함\n",
    "    - 이런 상황이 반복되면 훈련 시간이 느려질 수 있음\n",
    "    \n",
    "    \n",
    "**교사 강요**\n",
    "\n",
    "- RNN의 모든 시점에 대해서 이전 시점의 예측값 대신 실제값을 입력으로 주는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d9385-f472-4c0c-973b-f370321529d0",
   "metadata": {},
   "source": [
    "## seq2seq 기계 번역기 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bd4ab2e2-d433-4bbf-ba7b-b84445c629c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2614300f-1567-4c5d-b000-a44228ff1923",
   "metadata": {},
   "source": [
    "`encoder_states` 가 바로 컨텍스트 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cb982fe1-1a7e-41be-89b4-7055c68a7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "\n",
    "# encoder_outputs은 여기서는 불필요\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 은닉 상태와 셀 상태.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590987c7-42dd-412d-9809-313b3d021ea5",
   "metadata": {},
   "source": [
    "```python\n",
    "return_state=True\n",
    "```\n",
    "인코더의 내부 상태를 디코더로 넘겨주기 위해, False면 리턴하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8cae11d3-3c36-4782-972d-f9525d785af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "\n",
    "# 디코더에게 인코더의 은닉 상태, 셀 상태를 전달.\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96af33a2-cc17-413f-be44-4e0685ac61d7",
   "metadata": {},
   "source": [
    "디코더는 은닉상태, 셀 상태를 사용하지 않기 때문에 `_`로 받아줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0127341b-1810-4933-bb0e-4730ffffb9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "750/750 [==============================] - 100s 131ms/step - loss: 0.8574 - val_loss: 0.7819\n",
      "Epoch 2/40\n",
      "750/750 [==============================] - 98s 131ms/step - loss: 0.5758 - val_loss: 0.6667\n",
      "Epoch 3/40\n",
      "750/750 [==============================] - 144s 191ms/step - loss: 0.5051 - val_loss: 0.6056\n",
      "Epoch 4/40\n",
      "750/750 [==============================] - 171s 229ms/step - loss: 0.4589 - val_loss: 0.5569\n",
      "Epoch 5/40\n",
      "750/750 [==============================] - 159s 213ms/step - loss: 0.4232 - val_loss: 0.5200\n",
      "Epoch 6/40\n",
      "750/750 [==============================] - 154s 205ms/step - loss: 0.3958 - val_loss: 0.4920\n",
      "Epoch 7/40\n",
      "750/750 [==============================] - 109s 145ms/step - loss: 0.3745 - val_loss: 0.4701\n",
      "Epoch 8/40\n",
      "750/750 [==============================] - 105s 140ms/step - loss: 0.3572 - val_loss: 0.4552\n",
      "Epoch 9/40\n",
      "750/750 [==============================] - 119s 159ms/step - loss: 0.3429 - val_loss: 0.4391\n",
      "Epoch 10/40\n",
      "750/750 [==============================] - 163s 218ms/step - loss: 0.3306 - val_loss: 0.4275\n",
      "Epoch 11/40\n",
      "750/750 [==============================] - 164s 219ms/step - loss: 0.3201 - val_loss: 0.4184\n",
      "Epoch 12/40\n",
      "750/750 [==============================] - 160s 213ms/step - loss: 0.3111 - val_loss: 0.4119\n",
      "Epoch 13/40\n",
      "750/750 [==============================] - 133s 177ms/step - loss: 0.3031 - val_loss: 0.4011\n",
      "Epoch 14/40\n",
      "750/750 [==============================] - 101s 135ms/step - loss: 0.2959 - val_loss: 0.3956\n",
      "Epoch 15/40\n",
      "750/750 [==============================] - 101s 135ms/step - loss: 0.2893 - val_loss: 0.3928\n",
      "Epoch 16/40\n",
      "750/750 [==============================] - 141s 188ms/step - loss: 0.2832 - val_loss: 0.3868\n",
      "Epoch 17/40\n",
      "750/750 [==============================] - 173s 230ms/step - loss: 0.2778 - val_loss: 0.3798\n",
      "Epoch 18/40\n",
      "750/750 [==============================] - 161s 215ms/step - loss: 0.2727 - val_loss: 0.3781\n",
      "Epoch 19/40\n",
      "750/750 [==============================] - 152s 202ms/step - loss: 0.2679 - val_loss: 0.3755\n",
      "Epoch 20/40\n",
      "750/750 [==============================] - 117s 156ms/step - loss: 0.2635 - val_loss: 0.3704\n",
      "Epoch 21/40\n",
      "750/750 [==============================] - 105s 140ms/step - loss: 0.2593 - val_loss: 0.3687\n",
      "Epoch 22/40\n",
      "750/750 [==============================] - 123s 164ms/step - loss: 0.2553 - val_loss: 0.3656\n",
      "Epoch 23/40\n",
      "750/750 [==============================] - 162s 216ms/step - loss: 0.2517 - val_loss: 0.3626\n",
      "Epoch 24/40\n",
      "750/750 [==============================] - 162s 217ms/step - loss: 0.2482 - val_loss: 0.3618\n",
      "Epoch 25/40\n",
      "750/750 [==============================] - 157s 209ms/step - loss: 0.2448 - val_loss: 0.3602\n",
      "Epoch 26/40\n",
      "750/750 [==============================] - 135s 180ms/step - loss: 0.2414 - val_loss: 0.3577\n",
      "Epoch 27/40\n",
      "750/750 [==============================] - 98s 131ms/step - loss: 0.2385 - val_loss: 0.3569\n",
      "Epoch 28/40\n",
      "750/750 [==============================] - 98s 131ms/step - loss: 0.2355 - val_loss: 0.3562\n",
      "Epoch 29/40\n",
      "750/750 [==============================] - 150s 200ms/step - loss: 0.2325 - val_loss: 0.3536\n",
      "Epoch 30/40\n",
      "750/750 [==============================] - 172s 229ms/step - loss: 0.2299 - val_loss: 0.3517\n",
      "Epoch 31/40\n",
      "750/750 [==============================] - 161s 214ms/step - loss: 0.2271 - val_loss: 0.3520\n",
      "Epoch 32/40\n",
      "750/750 [==============================] - 156s 208ms/step - loss: 0.2246 - val_loss: 0.3518\n",
      "Epoch 33/40\n",
      "750/750 [==============================] - 110s 147ms/step - loss: 0.2222 - val_loss: 0.3504\n",
      "Epoch 34/40\n",
      "750/750 [==============================] - 107s 143ms/step - loss: 0.2199 - val_loss: 0.3494\n",
      "Epoch 35/40\n",
      "750/750 [==============================] - 128s 171ms/step - loss: 0.2177 - val_loss: 0.3502\n",
      "Epoch 36/40\n",
      "750/750 [==============================] - 168s 224ms/step - loss: 0.2152 - val_loss: 0.3493\n",
      "Epoch 37/40\n",
      "750/750 [==============================] - 166s 221ms/step - loss: 0.2131 - val_loss: 0.3479\n",
      "Epoch 38/40\n",
      "750/750 [==============================] - 154s 205ms/step - loss: 0.2111 - val_loss: 0.3492\n",
      "Epoch 39/40\n",
      "750/750 [==============================] - 122s 162ms/step - loss: 0.2091 - val_loss: 0.3499\n",
      "Epoch 40/40\n",
      "750/750 [==============================] - 98s 131ms/step - loss: 0.2070 - val_loss: 0.3497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe721864a30>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=40, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a794cf-db28-4296-a6be-af8296eb352a",
   "metadata": {},
   "source": [
    "## seq2seq 기계 번역기 동작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d059eaf-8028-4c49-a340-eb714b74210f",
   "metadata": {},
   "source": [
    "STEP 1. 번역하고자 하는 입력 문장이 인코더에 들어가 은닉 상태와 셀 상태를 얻는다.\n",
    "\n",
    "STEP 2. 상태와 `<sos>`에 해당하는 `\\t` 를 디코더로 보낸다.\n",
    "\n",
    "STEP 3. elzhejrk `<eos>`에 해당하는 `\\n`이 나올 때까지 다음 문자를 예측하는 행동을 반복한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5f81e147-c586-4326-bee7-770c0cd8fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e202f0-b921-4e95-ae39-7927aa564058",
   "metadata": {},
   "source": [
    "인코더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7b81d034-ee68-4e8d-a1c8-13683fd82fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용.\n",
    "# 뒤의 함수 decode_sequence()에 동작을 구현 예정\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태를 버리지 않음.\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c2c071a5-0f23-4a06-a71a-5682a8ccae34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 103) dtype=float32 (created by layer 'input_2')>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c5a0485f-c183-44c0-b18a-827bcbe5c8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'input_5')>,\n",
       " <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'input_6')>]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_states_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ec86f4-0f16-44e7-ace4-f7cd72defcc7",
   "metadata": {},
   "source": [
    "디코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0cd875b4-a599-4812-982c-cc01d1d038fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
    "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b915665d-4b5d-455c-8ff4-5d271ae945ba",
   "metadata": {},
   "source": [
    "인덱스에서 단어를 얻을 수 있도록 `index_to_~`설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "17805aa6-a544-4888-95f7-e648ba716a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "    # 예측 결과를 문자로 변환\n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "    decoded_sentence += sampled_char\n",
    "\n",
    "    # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "    if (sampled_char == '\\n' or\n",
    "        len(decoded_sentence) > max_tar_len):\n",
    "        stop_condition = True\n",
    "\n",
    "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "    states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244468fe-3316-4c9b-80eb-bd1e3047e343",
   "metadata": {},
   "source": [
    "#### step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9c85d69a-9df7-4332-9d44-b842e16d7263",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = encoder_input[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fe35f896-e20b-47a0-80c4-dabf1d4f8985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "states_value = encoder_model.predict(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c152c756-0203-46ea-bf61-d8494d154657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <SOS>에 해당하는 원-핫 벡터 생성\n",
    "target_seq = np.zeros((1, 1, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "15f1360e-4546-45e9-a096-2ac45a0b35e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d0c88865-16f0-44bb-a343-8389569256cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq[0, 0, tar_to_index['\\t']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1e6adb28-63c2-4c59-85cb-1232bb42658d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8546a35e-0097-435e-b880-0f42932feb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_condition = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2b2ef73e-c88f-4e6d-9815-8d53c5ba2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_sentence = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ac5e7fa9-2a3b-47e4-8628-be2f7acc264d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 103)\n",
      "(5, 256)\n",
      "(5, 256)\n",
      "(1, 256)\n",
      "(1, 256)\n"
     ]
    }
   ],
   "source": [
    "# Check dimensions of input arrays\n",
    "print(target_seq.shape)            # Shape of target_seq\n",
    "print(states_value[0].shape)       # Shape of states_value[0]\n",
    "print(states_value[1].shape)       # Shape of states_value[1]\n",
    "print(states_value[0][1,:].reshape(1,-1).shape)\n",
    "print(states_value[1][1,:].reshape(1,-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "53f8343d-2e81-420e-9876-46c8a02a82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_value_tmp = [states_value[0][1,:].reshape(1,-1), states_value[1][1,:].reshape(1,-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce6227-4e68-446c-acef-f7b5b50c5024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stop_condition이 True가 될 때까지 루프 반복\n",
    "while not stop_condition:\n",
    "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d632e9-5eb4-40be-b654-afcf34d4af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens, h, c = decoder_model.predict([target_seq] + states_value_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2a77e-e4f5-455e-bfc1-f3fed81eeb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과를 문자로 변환\n",
    "sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "sampled_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff35c6d-5a87-4f8f-8d9c-7bf3f03f0c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_char = index_to_tar[sampled_token_index]\n",
    "sampled_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad37c5c-14f0-456f-866c-69caf09a1076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "decoded_sentence += sampled_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa71c8c5-bfa1-43ac-9dc1-778b49d37dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "if (sampled_char == '\\n' or\n",
    "    len(decoded_sentence) > max_tar_len):\n",
    "    stop_condition = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aaaadd-d496-4daa-b247-b5d57ee14049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e79c77-4aa5-4244-8bbd-f40822c60d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq[0, 0, sampled_token_index] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5726d0-ab91-42c8-8cf9-3f5673669aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "states_value = [h, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622a69a0-cdea-417d-9abd-a7c605d27f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('입력 문장:', lines.src[5])\n",
    "print('정답 문장:', lines.tar[5][2:len(lines.tar[5])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "print('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67dab2-1d75-4cfe-9bc1-cd78f67a59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_index in [3,4]: # 입력 문장의 인덱스\n",
    "    input_seq = encoder_input[seq_index:seq_index+1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    # print(35 * \"-\")\n",
    "    print('입력 문장:', lines.src[seq_index])\n",
    "    print('정답 문장:', lines.tar[seq_index][2:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481c0266-965b-434d-8758-d355f9c6816b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
